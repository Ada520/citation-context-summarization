<paper>
<cited id="Q0">
<title id=" P02-1044.xml">word translation disambiguation using bilingual bootstrapping </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>corresponds to the sense of factory?
</prevsent>
<prevsent>and zhiwu?
</prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
corresponds to the sense of vegetation?).1 yarowsky (1995) <papid> P95-1026 </papid>proposes method for word sense (translation) disambiguation that is based on bootstrapping technique, which we refer to here as monolingual bootstrapping (mb)?.</citsent>
<aftsection>
<nextsent>in this paper, we propose new method for word translation disambiguation using bootstrapping technique we have developed.
</nextsent>
<nextsent>we refer to the technique as bilingual bootstrapping (bb)?.
</nextsent>
<nextsent>in order to evaluate the performance of bb, we conducted some experiments on word translation disambiguation using the bb technique and the mb technique.
</nextsent>
<nextsent>all of the results indicate that bb consistently and significantly outperforms mb.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2">
<title id=" P02-1044.xml">word translation disambiguation using bilingual bootstrapping </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in such learning method, for instance, an english sentence containing an ambiguous english word corresponds to an example, and the chinese translation of the word under the context corresponds to classification decision (a label).
</prevsent>
<prevsent>many methods for word sense disambiguation using supervised learning technique have been proposed.
</prevsent>
</prevsection>
<citsent citstr=" H92-1045 ">
they include those using nave bayes (gale et al 1992<papid> H92-1045 </papid>a), decision list (yarowsky 1994), <papid> P94-1013 </papid>nearest neighbor (ng and lee 1996), <papid> P96-1006 </papid>transformation based learning (mangu and brill 1997), neural network (towell and 1 in this paper, we take english-chinese translation as example; it is relatively easy process, however, to extend the discussions to translations between other language pairs.</citsent>
<aftsection>
<nextsent>computational linguistics (acl), philadelphia, july 2002, pp.
</nextsent>
<nextsent>343-351.
</nextsent>
<nextsent>proceedings of the 40th annual meeting of the association for voor hess 1998), winnow (golding and roth 1999), boosting (escudero et al 2000), and nave bayesian ensemble (pedersen 2000).<papid> A00-2009 </papid></nextsent>
<nextsent>among these methods, the one using nave bayesian ensemble (i.e., an ensemble of nave bayesian classifiers) is reported to perform the best for word sense disambiguation with respect to benchmark dataset (pedersen 2000).<papid> A00-2009 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4">
<title id=" P02-1044.xml">word translation disambiguation using bilingual bootstrapping </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in such learning method, for instance, an english sentence containing an ambiguous english word corresponds to an example, and the chinese translation of the word under the context corresponds to classification decision (a label).
</prevsent>
<prevsent>many methods for word sense disambiguation using supervised learning technique have been proposed.
</prevsent>
</prevsection>
<citsent citstr=" P94-1013 ">
they include those using nave bayes (gale et al 1992<papid> H92-1045 </papid>a), decision list (yarowsky 1994), <papid> P94-1013 </papid>nearest neighbor (ng and lee 1996), <papid> P96-1006 </papid>transformation based learning (mangu and brill 1997), neural network (towell and 1 in this paper, we take english-chinese translation as example; it is relatively easy process, however, to extend the discussions to translations between other language pairs.</citsent>
<aftsection>
<nextsent>computational linguistics (acl), philadelphia, july 2002, pp.
</nextsent>
<nextsent>343-351.
</nextsent>
<nextsent>proceedings of the 40th annual meeting of the association for voor hess 1998), winnow (golding and roth 1999), boosting (escudero et al 2000), and nave bayesian ensemble (pedersen 2000).<papid> A00-2009 </papid></nextsent>
<nextsent>among these methods, the one using nave bayesian ensemble (i.e., an ensemble of nave bayesian classifiers) is reported to perform the best for word sense disambiguation with respect to benchmark dataset (pedersen 2000).<papid> A00-2009 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5">
<title id=" P02-1044.xml">word translation disambiguation using bilingual bootstrapping </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in such learning method, for instance, an english sentence containing an ambiguous english word corresponds to an example, and the chinese translation of the word under the context corresponds to classification decision (a label).
</prevsent>
<prevsent>many methods for word sense disambiguation using supervised learning technique have been proposed.
</prevsent>
</prevsection>
<citsent citstr=" P96-1006 ">
they include those using nave bayes (gale et al 1992<papid> H92-1045 </papid>a), decision list (yarowsky 1994), <papid> P94-1013 </papid>nearest neighbor (ng and lee 1996), <papid> P96-1006 </papid>transformation based learning (mangu and brill 1997), neural network (towell and 1 in this paper, we take english-chinese translation as example; it is relatively easy process, however, to extend the discussions to translations between other language pairs.</citsent>
<aftsection>
<nextsent>computational linguistics (acl), philadelphia, july 2002, pp.
</nextsent>
<nextsent>343-351.
</nextsent>
<nextsent>proceedings of the 40th annual meeting of the association for voor hess 1998), winnow (golding and roth 1999), boosting (escudero et al 2000), and nave bayesian ensemble (pedersen 2000).<papid> A00-2009 </papid></nextsent>
<nextsent>among these methods, the one using nave bayesian ensemble (i.e., an ensemble of nave bayesian classifiers) is reported to perform the best for word sense disambiguation with respect to benchmark dataset (pedersen 2000).<papid> A00-2009 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q6">
<title id=" P02-1044.xml">word translation disambiguation using bilingual bootstrapping </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>computational linguistics (acl), philadelphia, july 2002, pp.
</prevsent>
<prevsent>343-351.
</prevsent>
</prevsection>
<citsent citstr=" A00-2009 ">
proceedings of the 40th annual meeting of the association for voor hess 1998), winnow (golding and roth 1999), boosting (escudero et al 2000), and nave bayesian ensemble (pedersen 2000).<papid> A00-2009 </papid></citsent>
<aftsection>
<nextsent>among these methods, the one using nave bayesian ensemble (i.e., an ensemble of nave bayesian classifiers) is reported to perform the best for word sense disambiguation with respect to benchmark dataset (pedersen 2000).<papid> A00-2009 </papid></nextsent>
<nextsent>the assumption behind the proposed methods is that it is nearly always possible to determine the translation of word by referring to its context, and thus all of the methods actually manage to build classifier (i.e., classification program) using features representing context information (e.g., co-occurring words).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q20">
<title id=" P02-1044.xml">word translation disambiguation using bilingual bootstrapping </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>(gale et al 1992<papid> H92-1045 </papid>b) to further classify unclassified sentences.</prevsent>
<prevsent>by repeating the above processes, it can create an accurate classifier for word translation disambiguation.</prevsent>
</prevsection>
<citsent citstr=" P91-1034 ">
for other related work, see, for example, (brown et al 1991; <papid> P91-1034 </papid>dagan and itai 1994; <papid> J94-4003 </papid>pedersen and bruce 1997; <papid> W97-0322 </papid>schutze 1998; kikui 1999; <papid> W99-0905 </papid>mihalcea and moldovan 1999).<papid> P99-1020 </papid></citsent>
<aftsection>
<nextsent>3.1 overview.
</nextsent>
<nextsent>instead of using monolingual bootstrapping, we propose new method for word translation disambiguation using bilingual bootstrapping.
</nextsent>
<nextsent>in translation from english to chinese, for instance, bb makes use of not only unclassified data in english, but also unclassified data in chinese.
</nextsent>
<nextsent>it also uses small number of classified data in english and, optionally, small number of classified data in chinese.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q21">
<title id=" P02-1044.xml">word translation disambiguation using bilingual bootstrapping </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>(gale et al 1992<papid> H92-1045 </papid>b) to further classify unclassified sentences.</prevsent>
<prevsent>by repeating the above processes, it can create an accurate classifier for word translation disambiguation.</prevsent>
</prevsection>
<citsent citstr=" J94-4003 ">
for other related work, see, for example, (brown et al 1991; <papid> P91-1034 </papid>dagan and itai 1994; <papid> J94-4003 </papid>pedersen and bruce 1997; <papid> W97-0322 </papid>schutze 1998; kikui 1999; <papid> W99-0905 </papid>mihalcea and moldovan 1999).<papid> P99-1020 </papid></citsent>
<aftsection>
<nextsent>3.1 overview.
</nextsent>
<nextsent>instead of using monolingual bootstrapping, we propose new method for word translation disambiguation using bilingual bootstrapping.
</nextsent>
<nextsent>in translation from english to chinese, for instance, bb makes use of not only unclassified data in english, but also unclassified data in chinese.
</nextsent>
<nextsent>it also uses small number of classified data in english and, optionally, small number of classified data in chinese.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q22">
<title id=" P02-1044.xml">word translation disambiguation using bilingual bootstrapping </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>(gale et al 1992<papid> H92-1045 </papid>b) to further classify unclassified sentences.</prevsent>
<prevsent>by repeating the above processes, it can create an accurate classifier for word translation disambiguation.</prevsent>
</prevsection>
<citsent citstr=" W97-0322 ">
for other related work, see, for example, (brown et al 1991; <papid> P91-1034 </papid>dagan and itai 1994; <papid> J94-4003 </papid>pedersen and bruce 1997; <papid> W97-0322 </papid>schutze 1998; kikui 1999; <papid> W99-0905 </papid>mihalcea and moldovan 1999).<papid> P99-1020 </papid></citsent>
<aftsection>
<nextsent>3.1 overview.
</nextsent>
<nextsent>instead of using monolingual bootstrapping, we propose new method for word translation disambiguation using bilingual bootstrapping.
</nextsent>
<nextsent>in translation from english to chinese, for instance, bb makes use of not only unclassified data in english, but also unclassified data in chinese.
</nextsent>
<nextsent>it also uses small number of classified data in english and, optionally, small number of classified data in chinese.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q23">
<title id=" P02-1044.xml">word translation disambiguation using bilingual bootstrapping </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>(gale et al 1992<papid> H92-1045 </papid>b) to further classify unclassified sentences.</prevsent>
<prevsent>by repeating the above processes, it can create an accurate classifier for word translation disambiguation.</prevsent>
</prevsection>
<citsent citstr=" W99-0905 ">
for other related work, see, for example, (brown et al 1991; <papid> P91-1034 </papid>dagan and itai 1994; <papid> J94-4003 </papid>pedersen and bruce 1997; <papid> W97-0322 </papid>schutze 1998; kikui 1999; <papid> W99-0905 </papid>mihalcea and moldovan 1999).<papid> P99-1020 </papid></citsent>
<aftsection>
<nextsent>3.1 overview.
</nextsent>
<nextsent>instead of using monolingual bootstrapping, we propose new method for word translation disambiguation using bilingual bootstrapping.
</nextsent>
<nextsent>in translation from english to chinese, for instance, bb makes use of not only unclassified data in english, but also unclassified data in chinese.
</nextsent>
<nextsent>it also uses small number of classified data in english and, optionally, small number of classified data in chinese.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q24">
<title id=" P02-1044.xml">word translation disambiguation using bilingual bootstrapping </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>(gale et al 1992<papid> H92-1045 </papid>b) to further classify unclassified sentences.</prevsent>
<prevsent>by repeating the above processes, it can create an accurate classifier for word translation disambiguation.</prevsent>
</prevsection>
<citsent citstr=" P99-1020 ">
for other related work, see, for example, (brown et al 1991; <papid> P91-1034 </papid>dagan and itai 1994; <papid> J94-4003 </papid>pedersen and bruce 1997; <papid> W97-0322 </papid>schutze 1998; kikui 1999; <papid> W99-0905 </papid>mihalcea and moldovan 1999).<papid> P99-1020 </papid></citsent>
<aftsection>
<nextsent>3.1 overview.
</nextsent>
<nextsent>instead of using monolingual bootstrapping, we propose new method for word translation disambiguation using bilingual bootstrapping.
</nextsent>
<nextsent>in translation from english to chinese, for instance, bb makes use of not only unclassified data in english, but also unclassified data in chinese.
</nextsent>
<nextsent>it also uses small number of classified data in english and, optionally, small number of classified data in chinese.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q47">
<title id=" P01-1007.xml">guided parsing of range concatenation languages </title>
<section> parsing with guide.  </section>
<citcontext>
<prevsection>
<prevsent>superset of  ), the guide level, but also it may depend on the parsed sentence itself.
</prevsent>
<prevsent>thus, in our opinion, only the results of practical experiments may globally decide if using guided parser is worthwhile . another potential problem may come from thesize of the guiding grammar itself.
</prevsent>
</prevsection>
<citsent citstr=" J00-1003 ">
in particular, experiments with regular approximation of cfls related in (nederhof, 2000) <papid> J00-1003 </papid>show that most reported methods are not practical for large cf grammars, because of the high costs of obtaining the minimal dfsa.in our case, it can easily be shown that the in crease in size of the guiding grammars is bounded by constant factor and thus seems priori acceptable from practical point of view.the next section depicts the practical experiments we have performed to validate our ap proach.</citsent>
<aftsection>
<nextsent>grammar in order to compare (normal) rcl parser and its guided versions, we looked for an existing wide coverage grammar.
</nextsent>
<nextsent>we chose the grammar for english designed for the xtag system (xtag, 1995), because it both is freely available and seems rather mature.
</nextsent>
<nextsent>of course, that grammar uses the tag formalism.1 thus, we first hadto transform that english tag into an equivalent rcg.
</nextsent>
<nextsent>to perform this task, we implemented the algorithm described in (boullier, 1998) (see also (boullier, 1999)), which allows to transform any tag into an equivalent simple prcg.2 however, boulliers algorithm was designed for pure tags, while the structures used in the xtag system are not trees, but rather tree schemata, grouped into linguistically pertinent tree families, which have to be instantiated by inflected forms for each given input sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q48">
<title id=" P01-1007.xml">guided parsing of range concatenation languages </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>of course, the filtering principle related in this paper is not novel (see for example (lakshmanan and yim, 1991) for deductive databases) but, ifwe consider the various attempts of guided parsing reported in the literature, ours is one of the very few examples in which important savings are noted.
</prevsent>
<prevsent>one reason for that seems to be the extreme simplicity of the interface between the guiding and the guided process: the guide only performs direct access into the guiding structure.
</prevsent>
</prevsection>
<citsent citstr=" W98-1302 ">
moreover, this guiding structure is (part of) the usual parse forest output by the guiding parser, without any transduction (see for example in (nederhof, 1998) <papid> W98-1302 </papid>how fsa can guide cf parser).as already noted by many authors (see forex ample (carroll, 1994)), <papid> P94-1040 </papid>the choice of (parsing) algorithm, as far as its throughput is concerned, cannot rely only on its theoretical complexity but must also take into account practical experiments.</citsent>
<aftsection>
<nextsent>complexity analysis gives worst-case upper bounds which may well not be reached, and which implies constants that may have preponderant effect on the typical size ranges of the application.
</nextsent>
<nextsent>we have also noted that guiding parsers can be used in classical tag parsers, as efficient and (very) accurate tree selectors.
</nextsent>
<nextsent>more generally, we are currently investigating the possibility to use guiding parsers as shallow parsers.
</nextsent>
<nextsent>the above results also show that (guided) rclparsing is valuable alternative to classical (lex icalized) tag parsers since we have exhibited parse time savings of several orders of magnitude over the most recent xtag parser.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q49">
<title id=" P01-1007.xml">guided parsing of range concatenation languages </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>of course, the filtering principle related in this paper is not novel (see for example (lakshmanan and yim, 1991) for deductive databases) but, ifwe consider the various attempts of guided parsing reported in the literature, ours is one of the very few examples in which important savings are noted.
</prevsent>
<prevsent>one reason for that seems to be the extreme simplicity of the interface between the guiding and the guided process: the guide only performs direct access into the guiding structure.
</prevsent>
</prevsection>
<citsent citstr=" P94-1040 ">
moreover, this guiding structure is (part of) the usual parse forest output by the guiding parser, without any transduction (see for example in (nederhof, 1998) <papid> W98-1302 </papid>how fsa can guide cf parser).as already noted by many authors (see forex ample (carroll, 1994)), <papid> P94-1040 </papid>the choice of (parsing) algorithm, as far as its throughput is concerned, cannot rely only on its theoretical complexity but must also take into account practical experiments.</citsent>
<aftsection>
<nextsent>complexity analysis gives worst-case upper bounds which may well not be reached, and which implies constants that may have preponderant effect on the typical size ranges of the application.
</nextsent>
<nextsent>we have also noted that guiding parsers can be used in classical tag parsers, as efficient and (very) accurate tree selectors.
</nextsent>
<nextsent>more generally, we are currently investigating the possibility to use guiding parsers as shallow parsers.
</nextsent>
<nextsent>the above results also show that (guided) rclparsing is valuable alternative to classical (lex icalized) tag parsers since we have exhibited parse time savings of several orders of magnitude over the most recent xtag parser.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q50">
<title id=" P03-1040.xml">feature rich statistical translation of noun phrases </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>focusing on narrower problem allows not only more dedicated modeling, but also the use of computationally more expensive methods.we go on to tackle the task of noun phrase translation in maximum entropy reranking framework.
</prevsent>
<prevsent>treating translation as reranking problem instead of as search problem enables us to use features over the full translation pair.
</prevsent>
</prevsection>
<citsent citstr=" C02-1011 ">
we integrate both empirical and symbolic knowledge sources as features into our system which outperforms the best known methods in statistical machine translation.previous work on defining subtasks within statistical machine translation has been performed on, e.g., noun-noun pair (cao and li, 2002) <papid> C02-1011 </papid>and named entity translation (al-onaizan and knight, 2002).</citsent>
<aftsection>
<nextsent>in this work, we consider both noun phrases and prepositional phrases, which we will refer to as np/pps.
</nextsent>
<nextsent>we include prepositional phrases for number of reasons.
</nextsent>
<nextsent>both are attached at the clauselevel.
</nextsent>
<nextsent>also, the translation of the preposition of ten depends heavily on the noun phrase (in the morning).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q51">
<title id=" P03-1040.xml">feature rich statistical translation of noun phrases </title>
<section> noun phrase translation as subtask.  </section>
<citcontext>
<prevsection>
<prevsent>in fact, we achieved slight improvement in results due to the fact that np/pps are consistently translated as np/pps.
</prevsent>
<prevsent>a perfect np/pp subsystem would triple the number of correctly translated sentences.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
performance is also measured by the bleu score (papineni et al, 2002), <papid> P02-1040 </papid>which measures similarity to the reference translation taken from the english side of the parallel corpus.</citsent>
<aftsection>
<nextsent>these findings indicate that solving the np/pptranslation problem would be significant step toward improving overall translation quality, even if the overall system is not changed in any way.
</nextsent>
<nextsent>the findings also indicate that isolating the np/pp translation task as subtask does not harm performance.
</nextsent>
<nextsent>when translating foreign input sentence, we detect its np/pps and translate them with an np/pp translation subsystem.
</nextsent>
<nextsent>the best translation (or multiple best translations) is then passed on to the full sentence translation system which in turn translates the remaining parts of the sentence and integrates the chosen np/pp translations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q52">
<title id=" P03-1040.xml">feature rich statistical translation of noun phrases </title>
<section> framework.  </section>
<citcontext>
<prevsection>
<prevsent>to train statistical machine translation model, we need training corpus of np/pps paired with their translation.
</prevsent>
<prevsent>we create this corpus by extracting np/pps from parallel corpus.
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
first, we word-align the corpus with giza++ (ochand ney, 2000).<papid> P00-1056 </papid></citsent>
<aftsection>
<nextsent>then, we parse both sides with syntactic parsers (collins, 1997; schmidt and schulte im walde, 2000)2.
</nextsent>
<nextsent>our definition easily translates into an algorithm to detect np/pps in sentence.
</nextsent>
<nextsent>recall that in such corpus, only part of thenp/pps are translated as such into the foreign language.
</nextsent>
<nextsent>in addition, the word-alignment and syntactic parses may be faulty.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q53">
<title id=" P03-1040.xml">feature rich statistical translation of noun phrases </title>
<section> framework.  </section>
<citcontext>
<prevsection>
<prevsent>3.3 base model.
</prevsent>
<prevsent>given the np/pp corpus, we can use any general statistical machine translation method to train translation system for noun phrases.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
as baseline, we use an ibm model 4 (brown et al, 1993) <papid> J93-2003 </papid>system3 with greedy decoder4 (germann et al, 2001).<papid> P01-1030 </papid></citsent>
<aftsection>
<nextsent>we found that phrase based models achieve better translation quality than ibm model 4.
</nextsent>
<nextsent>such models segment the input sequence into number of (non-linguistic) phrases, translate each phrase using phrase translation table, and allow for reordering of phrases in the output.
</nextsent>
<nextsent>no phrases may be dropped or added.
</nextsent>
<nextsent>we use phrase translation model that extracts its phrase translation table from word alignments generated by the giza++ toolkit.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q54">
<title id=" P03-1040.xml">feature rich statistical translation of noun phrases </title>
<section> framework.  </section>
<citcontext>
<prevsection>
<prevsent>3.3 base model.
</prevsent>
<prevsent>given the np/pp corpus, we can use any general statistical machine translation method to train translation system for noun phrases.
</prevsent>
</prevsection>
<citsent citstr=" P01-1030 ">
as baseline, we use an ibm model 4 (brown et al, 1993) <papid> J93-2003 </papid>system3 with greedy decoder4 (germann et al, 2001).<papid> P01-1030 </papid></citsent>
<aftsection>
<nextsent>we found that phrase based models achieve better translation quality than ibm model 4.
</nextsent>
<nextsent>such models segment the input sequence into number of (non-linguistic) phrases, translate each phrase using phrase translation table, and allow for reordering of phrases in the output.
</nextsent>
<nextsent>no phrases may be dropped or added.
</nextsent>
<nextsent>we use phrase translation model that extracts its phrase translation table from word alignments generated by the giza++ toolkit.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q55">
<title id=" P03-1040.xml">feature rich statistical translation of noun phrases </title>
<section> framework.  </section>
<citcontext>
<prevsection>
<prevsent>no phrases may be dropped or added.
</prevsent>
<prevsent>we use phrase translation model that extracts its phrase translation table from word alignments generated by the giza++ toolkit.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
details of this model are described by koehn et al (2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>to obtain an n-best list of candidate translations, we developed beam search decoder.
</nextsent>
<nextsent>this decoder employs hypothesis recombination and stores the search states in search graph ? similar to work by ueffing et al (2002) ? <papid> W02-1021 </papid>which can be mined with standard finite state machine methods5 for n-best lists.3available at http://www-i6.informatik.rwth aachen.de/</nextsent>
<nextsent>och/software/giza++.html 4available at http://www.isi.edu/licensed-sw /rewrite-decoder/ 5we use the carmel toolkit available at http://www.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q56">
<title id=" P03-1040.xml">feature rich statistical translation of noun phrases </title>
<section> framework.  </section>
<citcontext>
<prevsection>
<prevsent>details of this model are described by koehn et al (2003).<papid> N03-1017 </papid></prevsent>
<prevsent>to obtain an n-best list of candidate translations, we developed beam search decoder.</prevsent>
</prevsection>
<citsent citstr=" W02-1021 ">
this decoder employs hypothesis recombination and stores the search states in search graph ? similar to work by ueffing et al (2002) ? <papid> W02-1021 </papid>which can be mined with standard finite state machine methods5 for n-best lists.3available at http://www-i6.informatik.rwth aachen.de/</citsent>
<aftsection>
<nextsent>och/software/giza++.html 4available at http://www.isi.edu/licensed-sw /rewrite-decoder/ 5we use the carmel toolkit available at http://www.
</nextsent>
<nextsent>isi.edu/licensed-sw/carmel/
</nextsent>
<nextsent>1 2 4 8 16 32 64 60% 70% 80% 90% 100% size of n-best list correct figure 3: acceptable np/pp translations in n-best list for different sizes  3.4 acceptable translations in the n-best list.
</nextsent>
<nextsent>one key question for our approach is how often an acceptable translation can be found in an n-best list.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q57">
<title id=" P03-1040.xml">feature rich statistical translation of noun phrases </title>
<section> framework.  </section>
<citcontext>
<prevsection>
<prevsent>( c . nice property of maximum entropy training is that it converges to global optimum.
</prevsent>
<prevsent>there are number of methods and tools available to carry out this training of feature values.
</prevsent>
</prevsection>
<citsent citstr=" W02-2018 ">
we use the toolkit7 developed by malouf (2002).<papid> W02-2018 </papid></citsent>
<aftsection>
<nextsent>berger et al (1996)<papid> J96-1002 </papid>and manning and schutze (1999) provide good introductions to maximum entropy learning.note that any other machine learning, such as support vector machines, could be used as well.</nextsent>
<nextsent>we chose maximum entropy for its ability to deal with both real-valued and binary features.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q58">
<title id=" P03-1040.xml">feature rich statistical translation of noun phrases </title>
<section> framework.  </section>
<citcontext>
<prevsection>
<prevsent>there are number of methods and tools available to carry out this training of feature values.
</prevsent>
<prevsent>we use the toolkit7 developed by malouf (2002).<papid> W02-2018 </papid></prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
berger et al (1996)<papid> J96-1002 </papid>and manning and schutze (1999) provide good introductions to maximum entropy learning.note that any other machine learning, such as support vector machines, could be used as well.</citsent>
<aftsection>
<nextsent>we chose maximum entropy for its ability to deal with both real-valued and binary features.
</nextsent>
<nextsent>this method is also similar to work by och and ney (2002), <papid> P02-1038 </papid>who use maximum entropy to tune model parameters.</nextsent>
<nextsent>we will now discuss the properties of np/pp translation that we exploit in order to improve our np/pptranslation subsystem.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q59">
<title id=" P03-1040.xml">feature rich statistical translation of noun phrases </title>
<section> framework.  </section>
<citcontext>
<prevsection>
<prevsent>berger et al (1996)<papid> J96-1002 </papid>and manning and schutze (1999) provide good introductions to maximum entropy learning.note that any other machine learning, such as support vector machines, could be used as well.</prevsent>
<prevsent>we chose maximum entropy for its ability to deal with both real-valued and binary features.</prevsent>
</prevsection>
<citsent citstr=" P02-1038 ">
this method is also similar to work by och and ney (2002), <papid> P02-1038 </papid>who use maximum entropy to tune model parameters.</citsent>
<aftsection>
<nextsent>we will now discuss the properties of np/pp translation that we exploit in order to improve our np/pptranslation subsystem.
</nextsent>
<nextsent>the first of these (compound ing of words) is addressed by preprocessing, while the others motivate features which are used in n-best list reranking.
</nextsent>
<nextsent>4.1 compound splitting.
</nextsent>
<nextsent>compounding of words, especially nouns, is common in number of languages (german, dutch, finnish, greek), and poses serious problem for machine translation: the word aktionsplan may notbe known to the system, but if the word were broken up into aktion and plan, the system could easily translate it into action plan, or plan for action.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q60">
<title id=" P03-1040.xml">feature rich statistical translation of noun phrases </title>
<section> properties of np/pp translation.  </section>
<citcontext>
<prevsection>
<prevsent>the issues for breaking up compounds are: knowing the morphological rules for joining words,resolving ambiguities of breaking up word (haupt sturm
</prevsent>
<prevsent>haupt-turm or haupt-sturm), and finding the right level of splitting granularity (frei-tag or freitag).
</prevsent>
</prevsection>
<citsent citstr=" E03-1076 ">
here, we follow an approach introduced bykoehn and knight (2003): <papid> E03-1076 </papid>first, we collect frequency statistics over words in our training cor pus.</citsent>
<aftsection>
<nextsent>compounds may be broken up only into known words in the corpus.
</nextsent>
<nextsent>for each potential compound we check if morphological splitting rules allow us to break it up into such known words.
</nextsent>
<nextsent>finally, we pick splitting option (perhaps not breaking up the compound at all).
</nextsent>
<nextsent>this decision is based on the frequency of the words involved.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q61">
<title id=" N12-1080.xml">summarization of historical articles using temporal event clustering </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>we investigate whether or not such score can be used as weight in traditional sentence ranking techniques to improve summarization quality.
</prevsent>
<prevsent>event-based summarization is recent approach to summary generation.
</prevsent>
</prevsection>
<citsent citstr=" W04-1017 ">
(filatova and hatzivassiloglou, 2004) <papid> W04-1017 </papid>introduced atomic events, which are named entities connected by relation such as verb or action noun.</citsent>
<aftsection>
<nextsent>events are selected for summary by applying maximum coverage algorithm to minimize redundancy while maintaining coverage of the major concepts of the document.
</nextsent>
<nextsent>(vanderwende et al., 2004) identify events as triples consisting of two nodes and relation.
</nextsent>
<nextsent>page rank is then used to determine the relative importance of these triples represented in graph.
</nextsent>
<nextsent>sentence generation techniques are applied towards summarization.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q62">
<title id=" N12-1080.xml">summarization of historical articles using temporal event clustering </title>
<section> approach.  </section>
<citcontext>
<prevsection>
<prevsent>d) (8) +d ? ?
</prevsent>
<prevsent>vjin(vi) wj,i ? vkout(vj) wj,k ws(vj)like several graph-based methods for sentence ranking for summarization (e.g., (erkan and radev, 2004)), we use googles page rank algorithm (equation 8) with damping factor of 0.85.
</prevsent>
</prevsection>
<citsent citstr=" W04-3252 ">
similarity(si, sj) = |{wk|wk ? si&wk; ? sj}| log(|si|) + log(|sj |) (9) we use text rank (mihalcea and tarau, 2004) <papid> W04-3252 </papid>inour experiments.</citsent>
<aftsection>
<nextsent>our similarity measure is calculated using the number of shared named entities and nouns between sentences as seen in equation 9.
</nextsent>
<nextsent>for identification of named entities, we use stanford ner (finkel et al, 2005).<papid> P05-1045 </papid></nextsent>
<nextsent>it is straightforward to weight the resulting text rank scores for each sentence using their clusters temporal importance.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q63">
<title id=" N12-1080.xml">summarization of historical articles using temporal event clustering </title>
<section> approach.  </section>
<citcontext>
<prevsection>
<prevsent>similarity(si, sj) = |{wk|wk ? si&wk; ? sj}| log(|si|) + log(|sj |) (9) we use text rank (mihalcea and tarau, 2004) <papid> W04-3252 </papid>inour experiments.</prevsent>
<prevsent>our similarity measure is calculated using the number of shared named entities and nouns between sentences as seen in equation 9.</prevsent>
</prevsection>
<citsent citstr=" P05-1045 ">
for identification of named entities, we use stanford ner (finkel et al, 2005).<papid> P05-1045 </papid></citsent>
<aftsection>
<nextsent>it is straightforward to weight the resulting text rank scores for each sentence using their clusters temporal importance.
</nextsent>
<nextsent>we test on set of 13 wikipedia articles describing historical battles.
</nextsent>
<nextsent>the average article length is189 sentences and 4,367 words.
</nextsent>
<nextsent>the longest article is 545 sentences and contains 11,563 words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q64">
<title id=" N12-1080.xml">summarization of historical articles using temporal event clustering </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>each article has at least two human annotated gold standard summaries.
</prevsent>
<prevsent>volunteers were asked to choose the most important sentences from each article.
</prevsent>
</prevsection>
<citsent citstr=" W04-1013 ">
we evaluate using rouge-2 bigram matching (lin, 2004).<papid> W04-1013 </papid></citsent>
<aftsection>
<nextsent>4.1 clustering.
</nextsent>
<nextsent>each wikipedia article contains topic sentence stating the timespan of the main event in the article.
</nextsent>
<nextsent>this provides an easy way to determine whether aclustering is successful.
</nextsent>
<nextsent>if the largest cluster contains the timespan of the main event described by the topic sentence, we consider the clustering to be successful.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q65">
<title id=" N12-1077.xml">measuring word relatedness using heterogeneous vector space models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>despite its simplicity, our system correlates with human judgements better or similarly compared to existing methods on several benchmark datasets, including wordsim353.
</prevsent>
<prevsent>measuring the semantic relatedness of words is afundamental problem in natural language processing and has many useful applications, including textual entailment, word sense disambiguation, information retrieval and automatic thesaurus discovery.
</prevsent>
</prevsection>
<citsent citstr=" J06-1003 ">
existing approaches can be roughly categorized into two kinds: knowledge-based and corpus based, where the former includes graph-based algorithms and similarity measures operating on lexical database such as wordnet (budanitsky and hirst, 2006; <papid> J06-1003 </papid>agirre et al, 2009) <papid> N09-1003 </papid>and the latter consists of various kinds of vector space models (vsms) constructed with the help of large collection of text (reisinger and mooney, 2010; <papid> N10-1013 </papid>radinsky et al, 2011).</citsent>
<aftsection>
<nextsent>in this paper, we present conceptually simple model for solving this problem.
</nextsent>
<nextsent>observing that various kinds of information sources, such as work conducted while inter ning at microsoft research.general text corpora, web search results and the sau ruses, have different word and sense coverage, we first build individual vector space models from each of them separately.
</nextsent>
<nextsent>given two words, eachvsm measures the semantic relatedness by the co sine similarity of the corresponding vectors in its space.
</nextsent>
<nextsent>the final prediction is simply the averaged cosine scores derived from these vsms.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q66">
<title id=" N12-1077.xml">measuring word relatedness using heterogeneous vector space models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>despite its simplicity, our system correlates with human judgements better or similarly compared to existing methods on several benchmark datasets, including wordsim353.
</prevsent>
<prevsent>measuring the semantic relatedness of words is afundamental problem in natural language processing and has many useful applications, including textual entailment, word sense disambiguation, information retrieval and automatic thesaurus discovery.
</prevsent>
</prevsection>
<citsent citstr=" N09-1003 ">
existing approaches can be roughly categorized into two kinds: knowledge-based and corpus based, where the former includes graph-based algorithms and similarity measures operating on lexical database such as wordnet (budanitsky and hirst, 2006; <papid> J06-1003 </papid>agirre et al, 2009) <papid> N09-1003 </papid>and the latter consists of various kinds of vector space models (vsms) constructed with the help of large collection of text (reisinger and mooney, 2010; <papid> N10-1013 </papid>radinsky et al, 2011).</citsent>
<aftsection>
<nextsent>in this paper, we present conceptually simple model for solving this problem.
</nextsent>
<nextsent>observing that various kinds of information sources, such as work conducted while inter ning at microsoft research.general text corpora, web search results and the sau ruses, have different word and sense coverage, we first build individual vector space models from each of them separately.
</nextsent>
<nextsent>given two words, eachvsm measures the semantic relatedness by the co sine similarity of the corresponding vectors in its space.
</nextsent>
<nextsent>the final prediction is simply the averaged cosine scores derived from these vsms.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q68">
<title id=" N12-1077.xml">measuring word relatedness using heterogeneous vector space models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>despite its simplicity, our system correlates with human judgements better or similarly compared to existing methods on several benchmark datasets, including wordsim353.
</prevsent>
<prevsent>measuring the semantic relatedness of words is afundamental problem in natural language processing and has many useful applications, including textual entailment, word sense disambiguation, information retrieval and automatic thesaurus discovery.
</prevsent>
</prevsection>
<citsent citstr=" N10-1013 ">
existing approaches can be roughly categorized into two kinds: knowledge-based and corpus based, where the former includes graph-based algorithms and similarity measures operating on lexical database such as wordnet (budanitsky and hirst, 2006; <papid> J06-1003 </papid>agirre et al, 2009) <papid> N09-1003 </papid>and the latter consists of various kinds of vector space models (vsms) constructed with the help of large collection of text (reisinger and mooney, 2010; <papid> N10-1013 </papid>radinsky et al, 2011).</citsent>
<aftsection>
<nextsent>in this paper, we present conceptually simple model for solving this problem.
</nextsent>
<nextsent>observing that various kinds of information sources, such as work conducted while inter ning at microsoft research.general text corpora, web search results and the sau ruses, have different word and sense coverage, we first build individual vector space models from each of them separately.
</nextsent>
<nextsent>given two words, eachvsm measures the semantic relatedness by the co sine similarity of the corresponding vectors in its space.
</nextsent>
<nextsent>the final prediction is simply the averaged cosine scores derived from these vsms.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q73">
<title id=" N12-1077.xml">measuring word relatedness using heterogeneous vector space models </title>
<section> experimental evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>first, while none of the four vsms we tested outperforms the best existing systems on the benchmark datasets, surprisingly, using the averaged cosine scores ofthese models, the performance is improved substantially.
</prevsent>
<prevsent>it achieves higher spear mans rank coefficient on ws-353 and mturk-287 than any other systems2 and are close to the state-of-the-art on mc 30 and rg-65.
</prevsent>
</prevsection>
<citsent citstr=" D07-1061 ">
unlike some approach like (hughes and ramage, 2007), <papid> D07-1061 </papid>which performs well on some datasets but poorly on others, combing the vsmsfrom heterogeneous sources is more robust.</citsent>
<aftsection>
<nextsent>individually, we notice that wikipedia context vsm provides consistently strong results, while thesaurus based models work only reasonable on mc-30 and rg-65, potentially because other datasets contain more out-of-vocabulary words or proper nouns.
</nextsent>
<nextsent>due to the inherent ambiguity of the task, there is high variance among judgements from different annotators.
</nextsent>
<nextsent>therefore, it is unrealistic to assume any of the methods can correlate perfectly to the mean human judgement scores.
</nextsent>
<nextsent>in fact, the inter-agreement study done on the ws-353 dataset indicates that the result of our approach of combining heterogeneous vsms is close to the averaged human performance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q81">
<title id=" N12-1077.xml">measuring word relatedness using heterogeneous vector space models </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>in this paper we investigated the usefulness of heterogeneous information sources in improving measures of semantic word relatedness.
</prevsent>
<prevsent>particularly, we created vector space models using 4 data sources from 3 categories (corpus-based, web-based and thesaurus-based) and found that simply averaging the cosine similarity derived from these models yields very robust measure.
</prevsent>
</prevsection>
<citsent citstr=" D11-1096 ">
other than directly applying it to measuring semantic relatedness, our approach is complementary to more sophisticated similarity measures such as developing kernel functions for different structured data (croce et al, 2011), <papid> D11-1096 </papid>where the similarity between words serves as basic component.</citsent>
<aftsection>
<nextsent>while this result is interesting and encouraging, it also raises several research questions, such as how to enhance the quality of each vector space mod eland whether the models can be combined more effectively3.
</nextsent>
<nextsent>we also would like to study whether similar techniques can be useful when comparing longer text segments like phrases or sentences, with potential applications in paraphrase detection and recognizing textual entailment.
</nextsent>
<nextsent>acknowledgment swe thank joseph reisinger for providing his prototype vectors for our initial study, silviu-petru cucerzan for helping process the wikipedia files and geoffrey zweig for preparing the bloomsbury thesaurus data.
</nextsent>
<nextsent>we are also grateful to chris meekfor valuable discussions and to anonymous reviewers for their comments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q82">
<title id=" P03-2008.xml">a ranking model of proximal and structural text retrieval based on region algebra </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>models of the retrieval specifying both structures and words are pursued by many researchers (chinenyanga and kushmerick, 2001; wolff et al, 1999; theobald and weilkum, 2000; deutsch et al, 1998; salminen and tompa, 1994; clarke et al, 1995).
</prevsent>
<prevsent>however, these models are not robust unlike keyword-based retrieval, that is, they retrieve only the exact matches for queries.
</prevsent>
</prevsection>
<citsent citstr=" N03-2020 ">
in the previous research (masuda et al, 2003), <papid> N03-2020 </papid>we proposed new ranking model that enables proximal and structural search for structured text.</citsent>
<aftsection>
<nextsent>this paper investigates an application of the ranked regional gebra to information retrieval from large scale but unannotated documents.
</nextsent>
<nextsent>we reports in detail what kind of data can be retrieved in the experiments.
</nextsent>
<nextsent>our approach is to annotate documents with document structures and semantic tags by taggers automatically, and to retrieve information by specifying both structures and words using ranked region algebra.
</nextsent>
<nextsent>in this paper, we apply our approach to the ohsumed test collection (hersh et al, 1994), which is public test collection for information retrieval in the fieldof biomedical science but not tag-annotated.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q83">
<title id=" P04-1027.xml">an empirical study of information synthesis task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the remainder of the paper, we will use the term reports?
</prevsent>
<prevsent>to refer to the summaries produced in an information synthesis task, in order to distinguish them from other kinds of summaries.
</prevsent>
</prevsection>
<citsent citstr=" W00-0403 ">
topic-oriented multi-document summarization has already been studied in other evaluation initiatives which provide test beds to compare alternative approaches (over, 2003; goldstein et al, 2000;radev et al, 2000).<papid> W00-0403 </papid></citsent>
<aftsection>
<nextsent>unfortunately, those studies have been restricted to very small summaries(around 100 words) and small document sets (10 20 documents).
</nextsent>
<nextsent>these are relevant summarization tasks, but hardly representative of the information synthesis problem we are focusing on.
</nextsent>
<nextsent>the first goal of our work has been, therefore, to create suitable testbed that permits qualitative and quantitative studies on the information synthesis task.
</nextsent>
<nextsent>section 2 describes the creation of such testbed, which includes the manual generation of 72 reports by nine different subjects across 8 complex topics with 100 relevant documents per topic.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q84">
<title id=" P04-1027.xml">an empirical study of information synthesis task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>using this testbed, our second goal has been to compare alternative similarity metrics for the information synthesis task.
</prevsent>
<prevsent>a good similarity metric provides way of evaluating information synthesis systems (comparing their output with manually generated reports), and should also shed some lighton the common properties of manually generated reports.
</prevsent>
</prevsection>
<citsent citstr=" N03-1020 ">
our working hypothesis is that the best metric will best distinguish between manual and automatically generated reports.we have compared several similarity metrics, including few baseline measures (based on document, sentence and vocabulary overlap) and stateof-the-art measure to evaluate summarization systems, rouge (lin and hovy, 2003).<papid> N03-1020 </papid></citsent>
<aftsection>
<nextsent>we also introduce another proximity measure based on key concept overlap, which turns out to be substantially better than rouge for relevant class of topics.section 3 describes these metrics and the experimental design to compare them; in section 4, we analyze the outcome of the experiment, and section 5 discusses related work.
</nextsent>
<nextsent>finally, section 6 draws the main conclusions of this work.
</nextsent>
<nextsent>testbed we refer to information synthesis as the process of generating topic-oriented report from non trivial amount of relevant, possibly interrelated documents.
</nextsent>
<nextsent>the first goal of our work is the generation of testbed (iscorpus) with manually produced reports that serve as starting point for further empirical studies and evaluation of information synthesis systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q90">
<title id=" P04-1027.xml">an empirical study of information synthesis task </title>
<section> comparison of similarity metrics.  </section>
<citcontext>
<prevsection>
<prevsent>this problem is mitigated by the fact that we are comparing reports of approximately the same size and without repeated sentences.
</prevsent>
<prevsent>3.2.4 rouge metric the distance between two summaries can be established as function of their vocabulary (unigrams) and how this vocabulary is used (n-grams).
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
from this point of view, some of the measures used in the evaluation of machine translation systems, such as bleu (papineni et al, 2002), <papid> P02-1040 </papid>have been imported into the summarization task.</citsent>
<aftsection>
<nextsent>bleu is based in the precision and n-gram co-ocurrence between an automatic translation and reference manual translation.
</nextsent>
<nextsent>(lin and hovy, 2003) <papid> N03-1020 </papid>tried to apply bleu as measure to evaluate summaries, but the results were not as good as in machine translation.</nextsent>
<nextsent>indeed, some of the characteristics that define good translation are not related with the features of goodsummary; then lin and hovy proposed recall based variation of bleu, known as rouge.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q95">
<title id=" P04-1027.xml">an empirical study of information synthesis task </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the average number of different key concepts is18.7 for tt topics and 28.5 for ie topics, difference that reveals less agreement between subjects, supporting this argument.
</prevsent>
<prevsent>besides the measures included in our experiment, there are other criteria to compare summaries which could as well be tested for information synthesis: annotation of relevant sentences in corpus.
</prevsent>
</prevsection>
<citsent citstr=" H01-1022 ">
(khandelwal et al, 2001) <papid> H01-1022 </papid>propose task, called temporal summarization?, that combines summarization and topic tracking.</citsent>
<aftsection>
<nextsent>the paper describes the creation of an evaluation corpus in which the most relevant sentences in set of related news were annotated.
</nextsent>
<nextsent>summaries are evaluated with measure called novel recall?, based in sentences selected bya summarization system and sentences manually associated to events in the corpus.
</nextsent>
<nextsent>the agreement rate between subjects in the identification of key events and the sentence annotation does not correspond with the agreement between reports that we have obtained in our experiments.
</nextsent>
<nextsent>there are, at least, two reasons to explain this: ?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q99">
<title id=" P00-1065.xml">automatic labeling of semantic roles </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>identifying these roles, for example, could allow system to determine that inthe sentence \the rst one crashed  the subject is the vehicle, but in the sentence \the rst one crashed it  the subject is the agent, which would help in information extraction inthis domain.
</prevsent>
<prevsent>another application is in word sense disambiguation, where the roles associated with word can be cues to its sense.
</prevsent>
</prevsection>
<citsent citstr=" W99-0632 ">
for example, lapata and brew (1999) <papid> W99-0632 </papid>and other shave shown that the dierent syntactic sub catgorization frames of verb like \serve  canbe used to help disambiguate particular instance of the word \serve .</citsent>
<aftsection>
<nextsent>adding semantic role subcategorization information to this syntactic information could extend this idea to use richer semantic knowledge.
</nextsent>
<nextsent>semantic roles could also act as an important intermediate representation in statistical machine translation or automatic text summarization and in the emerging eld of text data mining(tdm) (hearst, 1999).<papid> P99-1001 </papid></nextsent>
<nextsent>finally, incorporating semantic roles into probabilistic models of language should yield more accurate parser sand better language models for speech recog nition.this paper proposes an algorithm for automatic semantic analysis, assigning semantic role to constituents in sentence.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q100">
<title id=" P00-1065.xml">automatic labeling of semantic roles </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, lapata and brew (1999) <papid> W99-0632 </papid>and other shave shown that the dierent syntactic sub catgorization frames of verb like \serve  canbe used to help disambiguate particular instance of the word \serve .</prevsent>
<prevsent>adding semantic role subcategorization information to this syntactic information could extend this idea to use richer semantic knowledge.</prevsent>
</prevsection>
<citsent citstr=" P99-1001 ">
semantic roles could also act as an important intermediate representation in statistical machine translation or automatic text summarization and in the emerging eld of text data mining(tdm) (hearst, 1999).<papid> P99-1001 </papid></citsent>
<aftsection>
<nextsent>finally, incorporating semantic roles into probabilistic models of language should yield more accurate parser sand better language models for speech recog nition.this paper proposes an algorithm for automatic semantic analysis, assigning semantic role to constituents in sentence.
</nextsent>
<nextsent>our approach to semantic analysis is to treat the problem of semantic role labeling like the similar problems of parsing, part of speech tagging, and word sense disambiguation.
</nextsent>
<nextsent>we apply statistical techniques that have been successful for these tasks, including probabilistic parsing and statistical classi cation.
</nextsent>
<nextsent>our statistical algorithms are trained on hand-labeled dataset: the framenet database (baker et al, 1998).<papid> P98-1013 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q101">
<title id=" P00-1065.xml">automatic labeling of semantic roles </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our approach to semantic analysis is to treat the problem of semantic role labeling like the similar problems of parsing, part of speech tagging, and word sense disambiguation.
</prevsent>
<prevsent>we apply statistical techniques that have been successful for these tasks, including probabilistic parsing and statistical classi cation.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
our statistical algorithms are trained on hand-labeled dataset: the framenet database (baker et al, 1998).<papid> P98-1013 </papid></citsent>
<aftsection>
<nextsent>the framenet database denes tagset of semantic roles called frame elements, and includes roughly 50,000 sentences from the british national corpus which have been hand-labeled with these frame elements.
</nextsent>
<nextsent>the next section describes the set of frame elements/semantic roles used by our system.
</nextsent>
<nextsent>in the rest of this paper we report on our current system, as well as number of preliminary experiments on extensions to the system.
</nextsent>
<nextsent>historically, two types of semantic roles have been studied: abstract roles such as agent and patient, and roles speci to individual verbs such as eater and eaten for \eat .the framenet project proposes roles at an intermediate level, that of the semantic frame.frames are de ned as schematic representations of situations involving various participants, props, and other conceptual roles (fillmore, 1976).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q102">
<title id=" P00-1065.xml">automatic labeling of semantic roles </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>writing such grammars is time-consuming, and typically such systems have limited coverage.
</prevsent>
<prevsent>data-driven techniques have recently been applied to template-based semantic interpretation in limited domains by \shallow  systems that avoid complex feature structures, and often perform only shallow syntactic analysis.
</prevsent>
</prevsection>
<citsent citstr=" P96-1008 ">
for example, in the context of the air traveler information system (atis)for spoken dialogue, miller et al (1996) <papid> P96-1008 </papid>computed the probability that constituent such as \atlanta  lled semantic slot such as destination in semantic frame for airtravel.</citsent>
<aftsection>
<nextsent>in data-driven approach to information extraction, rilo (1993) builds dictionary of patterns for lling slots in spe ci domain such as terrorist attacks, and rilo and schmelzenbach (1998) extend this technique to automatically derive entire case frames for words in the domain.
</nextsent>
<nextsent>these last systems make use of limited amount of hand labor to accept or reject automatically generated hypotheses.
</nextsent>
<nextsent>they show promise for more sophisticated approach to generalize beyond the relatively small number of frames considered in the tasks.
</nextsent>
<nextsent>more recently, do main independent system has been trained on general function tags such as manner and temporal by blaheta and charniak (2000).<papid> A00-2031 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q103">
<title id=" P00-1065.xml">automatic labeling of semantic roles </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>these last systems make use of limited amount of hand labor to accept or reject automatically generated hypotheses.
</prevsent>
<prevsent>they show promise for more sophisticated approach to generalize beyond the relatively small number of frames considered in the tasks.
</prevsent>
</prevsection>
<citsent citstr=" A00-2031 ">
more recently, do main independent system has been trained on general function tags such as manner and temporal by blaheta and charniak (2000).<papid> A00-2031 </papid></citsent>
<aftsection>
<nextsent>we divide the task of labeling frame elements into two subtasks: that of identifying the boundaries of the frame elements in the sentences, and that of labeling each frame element, given its boundaries, with the correct role.
</nextsent>
<nextsent>we rst give results for system which conferv debatev conversev gossipv disputen discussionn tiffn conversationframe: protagonist1 protagonist2 protagonists topic medium frame elements: talkv domain: communication domain: cognition frame: questioning topic medium frame elements: speaker addressee message frame: topic medium frame elements: speaker addressee message statement frame: frame elements: judgment judge evaluee reason role disputen blamev faultn admirev admirationn disapprovev blamen appreciatev frame: frame elements: categorization cognizer item category criterion figure 1: sample domains and frames from the framenet lexicon.
</nextsent>
<nextsent>frame element example (in italics) with target verb example (in italics) with target noun protagonist 1 kim argued with pat kim had an argument with pat protagonist 2 kim argued with pat kim had an argument with pat protagonists kim and pat argued kim and pat had an argument topic kim and pat argued about politics kim and pat had an argument about politics medium kim and pat argued in french kim and pat had an argument in french table 1: examples of semantic roles, or frame elements, for target words \argue  and \argu ment  from the \conversation  frame labels roles using human-annotated boundaries, returning to the question of automatically identifying the boundaries in section 5.3.
</nextsent>
<nextsent>4.1 features used in assigning.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q104">
<title id=" P00-1065.xml">automatic labeling of semantic roles </title>
<section> methodology.  </section>
<citcontext>
<prevsection>
<prevsent>4.1 features used in assigning.
</prevsent>
<prevsent>semantic roles the system is statistical one, based on training classier on labeled training set, and testing on an unlabeled test set.
</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
the system is trained by rst using the collins parser(collins, 1997) <papid> P97-1003 </papid>to parse the 36,995 training sentences, matching annotated frame elements to parse constituents, and extracting various features from the string of words and the parse tree.</citsent>
<aftsection>
<nextsent>during testing, the parser isrun on the test sentences and the same features extracted.
</nextsent>
<nextsent>probabilities for each possible semantic role are then computed from the features.
</nextsent>
<nextsent>the probability computation will be described in the next section; the features include: phrase type: this feature indicates the syntactic type of the phrase expressing the semantic roles: examples include noun phrase (np), verb phrase (vp), and clause (s).
</nextsent>
<nextsent>phrase types were derived automatically from parse trees generated by the parser, as shown in figure 2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q105">
<title id=" P00-1065.xml">automatic labeling of semantic roles </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>while the distribution (rjh; t) can only be evaluated for 56.0% of the data, of those cases it gets 86.7% correct, without use of any of the syntactic features.
</prevsent>
<prevsent>5.2 lexical clustering.
</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
in order to address the sparse coverage of lexical head word statistics, an experiment was carried out using an automatic clustering of headwords of the type described in (lin,1998).<papid> P98-2127 </papid></citsent>
<aftsection>
<nextsent>a soft clustering of nouns was performed by applying the co-occurrence model of (hofmann and puzicha, 1998) to large corpus of observed direct object relationships between verbs and nouns.
</nextsent>
<nextsent>the clustering was computed from an automatically parsed version of the british national corpus, using the parser of (carroll and rooth, 1998).
</nextsent>
<nextsent>the experiment was performed using only frame elements with noun as head word.
</nextsent>
<nextsent>this allowed smoothed estimate of (rjh; nt; t) to be computed as cp (rjc; nt; t)p (cjh), summing over the automatically derived clusters to which nominal head word might belong.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q106">
<title id=" P01-1037.xml">the role of lexico semantic feedback in open domain textual question answering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>frequently, keywords extracted from the natural language question are either within the text span or inits immediate vicinity, forming text paragraph.
</prevsent>
<prevsent>since such paragraphs must be identified throughout voluminous collections, automatic and autonomous q&a; systems incorporate an index of the collection as well as paragraph retrieval mechanism.
</prevsent>
</prevsection>
<citsent citstr=" A00-1021 ">
recent results from the trec evaluations ((kwok et al, 2000) (radev et al, 2000) (<papid> A00-1021 </papid>allen 1the text retrieval conference (trec) is series of workshops organized by the national institute of standard sand technology (nist), designed to advance the state-of the-art in information retrieval (ir) et al, 2000)) show that information retrieval (ir)techniques alone are not sufficient for finding answers with high precision.</citsent>
<aftsection>
<nextsent>in fact, more and more systems adopt architectures in which the semantics of the questions are captured prior to paragraph retrieval (e.g.
</nextsent>
<nextsent>(gaizauskas and humphreys, 2000) (harabagiu et al, 2000)) <papid> C00-1043 </papid>and used later in extracting the answer (cf.</nextsent>
<nextsent>(abney et al, 2000)).<papid> A00-1041 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q108">
<title id=" P01-1037.xml">the role of lexico semantic feedback in open domain textual question answering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recent results from the trec evaluations ((kwok et al, 2000) (radev et al, 2000) (<papid> A00-1021 </papid>allen 1the text retrieval conference (trec) is series of workshops organized by the national institute of standard sand technology (nist), designed to advance the state-of the-art in information retrieval (ir) et al, 2000)) show that information retrieval (ir)techniques alone are not sufficient for finding answers with high precision.</prevsent>
<prevsent>in fact, more and more systems adopt architectures in which the semantics of the questions are captured prior to paragraph retrieval (e.g.</prevsent>
</prevsection>
<citsent citstr=" C00-1043 ">
(gaizauskas and humphreys, 2000) (harabagiu et al, 2000)) <papid> C00-1043 </papid>and used later in extracting the answer (cf.</citsent>
<aftsection>
<nextsent>(abney et al, 2000)).<papid> A00-1041 </papid></nextsent>
<nextsent>when processing natural language question two goals must be achieved.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q109">
<title id=" P01-1037.xml">the role of lexico semantic feedback in open domain textual question answering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in fact, more and more systems adopt architectures in which the semantics of the questions are captured prior to paragraph retrieval (e.g.
</prevsent>
<prevsent>(gaizauskas and humphreys, 2000) (harabagiu et al, 2000)) <papid> C00-1043 </papid>and used later in extracting the answer (cf.</prevsent>
</prevsection>
<citsent citstr=" A00-1041 ">
(abney et al, 2000)).<papid> A00-1041 </papid></citsent>
<aftsection>
<nextsent>when processing natural language question two goals must be achieved.
</nextsent>
<nextsent>first we need to know what is the expected answer type; in other words,we need to know what we are looking for.
</nextsent>
<nextsent>second, we need to know where to look for the answer, e.g. we must identify the question keywords to be used in the paragraph retrieval.
</nextsent>
<nextsent>the expected answer type is determined based on the question stem, e.g. who, where or how much and eventually one of the question concepts, when the stem is ambiguous (for example what), as described in (harabagiu et al, 2000) (<papid> C00-1043 </papid>radev et al., 2000) (<papid> A00-1021 </papid>srihari and li, 2000).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q112">
<title id=" P01-1037.xml">the role of lexico semantic feedback in open domain textual question answering </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>although simple combinations of ir and ie techniques are not practical solutions for open-domain textual q&a; because ie systems are based on domain-specific knowledge, their contribution to current open-domainq&a; methods is significant.
</prevsent>
<prevsent>for example, stateof-the-art named entity (ne) recognizers developed for ie systems were readily available to be incorporated in q&a; systems and helped recognize names of people, organizations, locations or dates.
</prevsent>
</prevsection>
<citsent citstr=" A00-1023 ">
assuming that it is very likely that the answer is named entity, (srihari and li, 2000) <papid> A00-1023 </papid>describes ne-supported q&a; system that functions quite well when the expected answer type is one of the categories covered by the ne recognizer.</citsent>
<aftsection>
<nextsent>unfortunately this system is not fully autonomous,as it depends on ir results provided by external search engines.
</nextsent>
<nextsent>answer extractions based on ne recognizers were also developed in the q&a; presented in (abney et al, 2000) (<papid> A00-1041 </papid>radev et al, 2000) (<papid> A00-1021 </papid>gaizauskas and humphreys, 2000).</nextsent>
<nextsent>asnoted in (voorhees and tice, 2000), q&a; systems that did not include ne recognizers performed poorly in the trec evaluations, especially in the short answer category.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q116">
<title id=" P01-1037.xml">the role of lexico semantic feedback in open domain textual question answering </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>answer extractions based on ne recognizers were also developed in the q&a; presented in (abney et al, 2000) (<papid> A00-1041 </papid>radev et al, 2000) (<papid> A00-1021 </papid>gaizauskas and humphreys, 2000).</prevsent>
<prevsent>asnoted in (voorhees and tice, 2000), q&a; systems that did not include ne recognizers performed poorly in the trec evaluations, especially in the short answer category.</prevsent>
</prevsection>
<citsent citstr=" P00-1071 ">
some q&a; systems, like (moldovan et al, 2000) <papid> P00-1071 </papid>relied both on ne recognizers and some empirical indicators.</citsent>
<aftsection>
<nextsent>however, the answer does not always belong to category covered by the ne recognizer.
</nextsent>
<nextsent>forsuch cases several approaches have been developed.
</nextsent>
<nextsent>the first one, presented in (harabagiu et al., 2000), <papid> C00-1043 </papid>the answer type is derived from large answer taxonomy.</nextsent>
<nextsent>a different approach, based on statistical techniques was proposed in (radev et al., 2000).<papid> A00-1021 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q120">
<title id=" P01-1037.xml">the role of lexico semantic feedback in open domain textual question answering </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the first one, presented in (harabagiu et al., 2000), <papid> C00-1043 </papid>the answer type is derived from large answer taxonomy.</prevsent>
<prevsent>a different approach, based on statistical techniques was proposed in (radev et al., 2000).<papid> A00-1021 </papid></prevsent>
</prevsection>
<citsent citstr=" A00-1025 ">
(cardie et al, 2000) <papid> A00-1025 </papid>presents method of extracting answers as noun phrases in novel way.</citsent>
<aftsection>
<nextsent>answer extraction based on grammatical information is also promoted by the system described in (clarke et al, 2000).
</nextsent>
<nextsent>one of the few q&a; systems that takes into account morphological, lexical and semantic alternations of terms is described in (ferret et al,2000).
</nextsent>
<nextsent>to our knowledge, none of the current open-domain q&a; systems use any feedback loops to generate lexico-semantic alternations.
</nextsent>
<nextsent>this paper shows that such feedback loops enhance significantly the performance of open domain textual q&a; systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q121">
<title id=" P01-1037.xml">the role of lexico semantic feedback in open domain textual question answering </title>
<section> textual q&a; feedback loops.  </section>
<citcontext>
<prevsection>
<prevsent>when no reformulations are detected, the search for answers is based on the conjecture that the eventual answer is likely to be found in atext paragraph that (a) contains the most representative question concepts and (b) includes textual concept of the same category as the expected answer.
</prevsent>
<prevsent>since the current retrieval technology does not model semantic knowledge, we break down this search into boolean retrieval, basedon some question keywords and filtering mechanism, that retains only those passages containing the expected answer type.
</prevsent>
</prevsection>
<citsent citstr=" P96-1025 ">
both the question keywords and the expected answer type are identified by using the dependencies derived from the question parse.by implementing our own version of the publicly available collins parser (collins, 1996), <papid> P96-1025 </papid>we also learned dependency model that enables the mapping of parse trees into sets of binary relations between the head-word of each constituent and its sibling-words.</citsent>
<aftsection>
<nextsent>for example, the parse tree of trec-9 question q210: how many dogs pull sled in the iditarod ??
</nextsent>
<nextsent>is: jj iditarod vp np pp np nnpdtinnn np dtvbpnns np manyhow wrb dogs pull sled in the for each possible constituent in parse tree, rules first described in (magerman, 1995) <papid> P95-1037 </papid>and (jelinek et al, 1994) <papid> H94-1052 </papid>identify the head-child and propagate the head-word to its parent.</nextsent>
<nextsent>for the parse of question q210 the propagation is: np (sled) dt nn dtin manyhow wrb dogs nnsjj np (dogs) vbp pull sled in the iditarod nnp (iditarod) np (iditarod) pp (iditarod) np (sled) vp (pull) (pull) when the propagation is over, head-modifier relations are extracted, generating the following dependency structure, called question semantic form in (harabagiu et al, 2000).<papid> C00-1043 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q122">
<title id=" P01-1037.xml">the role of lexico semantic feedback in open domain textual question answering </title>
<section> textual q&a; feedback loops.  </section>
<citcontext>
<prevsection>
<prevsent>both the question keywords and the expected answer type are identified by using the dependencies derived from the question parse.by implementing our own version of the publicly available collins parser (collins, 1996), <papid> P96-1025 </papid>we also learned dependency model that enables the mapping of parse trees into sets of binary relations between the head-word of each constituent and its sibling-words.</prevsent>
<prevsent>for example, the parse tree of trec-9 question q210: how many dogs pull sled in the iditarod ??</prevsent>
</prevsection>
<citsent citstr=" P95-1037 ">
is: jj iditarod vp np pp np nnpdtinnn np dtvbpnns np manyhow wrb dogs pull sled in the for each possible constituent in parse tree, rules first described in (magerman, 1995) <papid> P95-1037 </papid>and (jelinek et al, 1994) <papid> H94-1052 </papid>identify the head-child and propagate the head-word to its parent.</citsent>
<aftsection>
<nextsent>for the parse of question q210 the propagation is: np (sled) dt nn dtin manyhow wrb dogs nnsjj np (dogs) vbp pull sled in the iditarod nnp (iditarod) np (iditarod) pp (iditarod) np (sled) vp (pull) (pull) when the propagation is over, head-modifier relations are extracted, generating the following dependency structure, called question semantic form in (harabagiu et al, 2000).<papid> C00-1043 </papid></nextsent>
<nextsent>dogs iditarod count pull sled in the structure above, count represents the expected answer type, replacing the question stemhow many?.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q123">
<title id=" P01-1037.xml">the role of lexico semantic feedback in open domain textual question answering </title>
<section> textual q&a; feedback loops.  </section>
<citcontext>
<prevsection>
<prevsent>both the question keywords and the expected answer type are identified by using the dependencies derived from the question parse.by implementing our own version of the publicly available collins parser (collins, 1996), <papid> P96-1025 </papid>we also learned dependency model that enables the mapping of parse trees into sets of binary relations between the head-word of each constituent and its sibling-words.</prevsent>
<prevsent>for example, the parse tree of trec-9 question q210: how many dogs pull sled in the iditarod ??</prevsent>
</prevsection>
<citsent citstr=" H94-1052 ">
is: jj iditarod vp np pp np nnpdtinnn np dtvbpnns np manyhow wrb dogs pull sled in the for each possible constituent in parse tree, rules first described in (magerman, 1995) <papid> P95-1037 </papid>and (jelinek et al, 1994) <papid> H94-1052 </papid>identify the head-child and propagate the head-word to its parent.</citsent>
<aftsection>
<nextsent>for the parse of question q210 the propagation is: np (sled) dt nn dtin manyhow wrb dogs nnsjj np (dogs) vbp pull sled in the iditarod nnp (iditarod) np (iditarod) pp (iditarod) np (sled) vp (pull) (pull) when the propagation is over, head-modifier relations are extracted, generating the following dependency structure, called question semantic form in (harabagiu et al, 2000).<papid> C00-1043 </papid></nextsent>
<nextsent>dogs iditarod count pull sled in the structure above, count represents the expected answer type, replacing the question stemhow many?.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q129">
<title id=" P02-1062.xml">ranking algorithms for named entity extraction boosting and the voted perceptron </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the voted perceptron algorithm can be considerably more efficient to train, at some cost in computation on test examples.
</prevsent>
<prevsent>recent work in statistical approaches to parsing and tagging has begun to consider methods which incorporate global features of candidate structures.
</prevsent>
</prevsection>
<citsent citstr=" J97-4005 ">
examples of such techniques are markov random fields (abney 1997; <papid> J97-4005 </papid>della pietra et al 1997; johnson et al 1999), <papid> P99-1069 </papid>and boosting algorithms (freund et al. 1998; collins 2000; walker et al 2001).<papid> N01-1003 </papid></citsent>
<aftsection>
<nextsent>one appeal of these methods is their flexibility in incorporating features into model: essentially any features which might be useful in discriminating good from bad structures can be included.
</nextsent>
<nextsent>a second appeal of these methods is that their training criterion is often discriminative, attempting to explicitly push the score or probability of the correct structure for each training sentence above the score of competing structures.
</nextsent>
<nextsent>this discriminative property is shared by the methods of (johnson et al 1999; <papid> P99-1069 </papid>collins 2000), and also the conditional random field methods of (lafferty et al 2001).in previous paper (collins 2000), boosting algorithm was used to rerank the output from an existing statistical parser, giving significant improvements in parsing accuracy on wall street journal data.</nextsent>
<nextsent>similar boosting algorithms have been applied to natural language generation, with good results, in(walker et al 2001).<papid> N01-1003 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q130">
<title id=" P02-1062.xml">ranking algorithms for named entity extraction boosting and the voted perceptron </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the voted perceptron algorithm can be considerably more efficient to train, at some cost in computation on test examples.
</prevsent>
<prevsent>recent work in statistical approaches to parsing and tagging has begun to consider methods which incorporate global features of candidate structures.
</prevsent>
</prevsection>
<citsent citstr=" P99-1069 ">
examples of such techniques are markov random fields (abney 1997; <papid> J97-4005 </papid>della pietra et al 1997; johnson et al 1999), <papid> P99-1069 </papid>and boosting algorithms (freund et al. 1998; collins 2000; walker et al 2001).<papid> N01-1003 </papid></citsent>
<aftsection>
<nextsent>one appeal of these methods is their flexibility in incorporating features into model: essentially any features which might be useful in discriminating good from bad structures can be included.
</nextsent>
<nextsent>a second appeal of these methods is that their training criterion is often discriminative, attempting to explicitly push the score or probability of the correct structure for each training sentence above the score of competing structures.
</nextsent>
<nextsent>this discriminative property is shared by the methods of (johnson et al 1999; <papid> P99-1069 </papid>collins 2000), and also the conditional random field methods of (lafferty et al 2001).in previous paper (collins 2000), boosting algorithm was used to rerank the output from an existing statistical parser, giving significant improvements in parsing accuracy on wall street journal data.</nextsent>
<nextsent>similar boosting algorithms have been applied to natural language generation, with good results, in(walker et al 2001).<papid> N01-1003 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q131">
<title id=" P02-1062.xml">ranking algorithms for named entity extraction boosting and the voted perceptron </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the voted perceptron algorithm can be considerably more efficient to train, at some cost in computation on test examples.
</prevsent>
<prevsent>recent work in statistical approaches to parsing and tagging has begun to consider methods which incorporate global features of candidate structures.
</prevsent>
</prevsection>
<citsent citstr=" N01-1003 ">
examples of such techniques are markov random fields (abney 1997; <papid> J97-4005 </papid>della pietra et al 1997; johnson et al 1999), <papid> P99-1069 </papid>and boosting algorithms (freund et al. 1998; collins 2000; walker et al 2001).<papid> N01-1003 </papid></citsent>
<aftsection>
<nextsent>one appeal of these methods is their flexibility in incorporating features into model: essentially any features which might be useful in discriminating good from bad structures can be included.
</nextsent>
<nextsent>a second appeal of these methods is that their training criterion is often discriminative, attempting to explicitly push the score or probability of the correct structure for each training sentence above the score of competing structures.
</nextsent>
<nextsent>this discriminative property is shared by the methods of (johnson et al 1999; <papid> P99-1069 </papid>collins 2000), and also the conditional random field methods of (lafferty et al 2001).in previous paper (collins 2000), boosting algorithm was used to rerank the output from an existing statistical parser, giving significant improvements in parsing accuracy on wall street journal data.</nextsent>
<nextsent>similar boosting algorithms have been applied to natural language generation, with good results, in(walker et al 2001).<papid> N01-1003 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q136">
<title id=" P02-1062.xml">ranking algorithms for named entity extraction boosting and the voted perceptron </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent> . 2.2 the baseline tagger.
</prevsent>
<prevsent>the problem can be framed as tagging task ? to tag each word as being either the start of an entity, continuation of an entity, or not to be part of an entity at all (we will use the tags s, and respectively for these three cases).
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
as baseline model we used maximum entropy tagger, very similar to the ones described in (ratnaparkhi 1996; <papid> W96-0213 </papid>borthwicket.</citsent>
<aftsection>
<nextsent>al 1998; mccallum et al 2000).
</nextsent>
<nextsent>max-ent taggers have been shown to be highly competitive on anumber of tagging tasks, such as part-of-speech tagging (ratnaparkhi 1996), <papid> W96-0213 </papid>named-entity recognition (borthwick et. al 1998), <papid> W98-1118 </papid>and information extraction tasks (mccallum et al 2000).</nextsent>
<nextsent>thus the maximum entropy tagger we used represents serious baseline for the task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q139">
<title id=" P02-1062.xml">ranking algorithms for named entity extraction boosting and the voted perceptron </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>as baseline model we used maximum entropy tagger, very similar to the ones described in (ratnaparkhi 1996; <papid> W96-0213 </papid>borthwicket.</prevsent>
<prevsent>al 1998; mccallum et al 2000).</prevsent>
</prevsection>
<citsent citstr=" W98-1118 ">
max-ent taggers have been shown to be highly competitive on anumber of tagging tasks, such as part-of-speech tagging (ratnaparkhi 1996), <papid> W96-0213 </papid>named-entity recognition (borthwick et. al 1998), <papid> W98-1118 </papid>and information extraction tasks (mccallum et al 2000).</citsent>
<aftsection>
<nextsent>thus the maximum entropy tagger we used represents serious baseline for the task.
</nextsent>
<nextsent>we used the following features (sev eral of the features were inspired by the approach of (bikel et. al 1999), an hmm model which gives excellent results on named entity extraction):  the word being tagged, the previous word, and the next word. the previous tag, and the previous two tags (bi gram and trigram features).
</nextsent>
<nextsent>1in initial experiments, we found that forcing the tagger to recover categories as well as the segmentation, by exploding the number of tags, reduced performance on the segmentation task, presumably due to sparse data problems.
</nextsent>
<nextsent> compound feature of three fields: (a) is the word at the start of sentence?; (b) does the word occur in list of words which occur more frequently as lowercase rather than upper case words in large corpus of text?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q144">
<title id=" P02-1062.xml">ranking algorithms for named entity extraction boosting and the voted perceptron </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>figure 5 shows the results for the three methods on the test set.
</prevsent>
<prevsent>both ofthe reranking algorithms show significant improvements over the baseline: 15.6% relative reduction in error for boosting, and 17.7% relative error reduction for the voted perceptron.in our experiments we found the voted perceptron algorithm to be considerably more efficient intraining, at some cost in computation on test examples.
</prevsent>
</prevsection>
<citsent citstr=" P02-1034 ">
another attractive property of the voted perceptron is that it can be used with kernels, for example the kernels over parse trees described in (collins and duffy 2001; collins and duffy 2002).<papid> P02-1034 </papid></citsent>
<aftsection>
<nextsent>(collinsand duffy 2002) <papid> P02-1034 </papid>describe the voted perceptron applied to the named-entity data in this paper, but using kernel-based features rather than the explicit features described in this paper.</nextsent>
<nextsent>see (collins 2002) <papid> W02-1001 </papid>for additional work using perceptron algorithms to train tagging models, and more thorough description ofthe theory underlying the perceptron algorithm applied to ranking problems.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q146">
<title id=" P02-1062.xml">ranking algorithms for named entity extraction boosting and the voted perceptron </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>another attractive property of the voted perceptron is that it can be used with kernels, for example the kernels over parse trees described in (collins and duffy 2001; collins and duffy 2002).<papid> P02-1034 </papid></prevsent>
<prevsent>(collinsand duffy 2002) <papid> P02-1034 </papid>describe the voted perceptron applied to the named-entity data in this paper, but using kernel-based features rather than the explicit features described in this paper.</prevsent>
</prevsection>
<citsent citstr=" W02-1001 ">
see (collins 2002) <papid> W02-1001 </papid>for additional work using perceptron algorithms to train tagging models, and more thorough description ofthe theory underlying the perceptron algorithm applied to ranking problems.</citsent>
<aftsection>
<nextsent>a question regarding the approaches in this paper is whether the features we have described could be incorporated in maximum-entropy tagger, giving similar improvements inaccuracy.
</nextsent>
<nextsent>this section discusses why this is unlikely to be the case.
</nextsent>
<nextsent>the problem described here is closely related to the label bias problem described in (lafferty et al 2001).
</nextsent>
<nextsent>one straightforward way to incorporate global features into the maximum-entropy model would be to introduce new features ff  -ffi%% which indicated whether the tagging decision  in the history creates particular global feature.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q147">
<title id=" P04-2009.xml">robust vpe detection using automatically parsed text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this system is designed as the first stage of complete vpe resolution system that is input free text, detects vpes, and proceeds to find the antecedents and resolve them.
</prevsent>
<prevsent>ellipsis is linguistic phenomenon that has received considerable attention, mostly focusing on its interpretation.
</prevsent>
</prevsection>
<citsent citstr=" E93-1025 ">
most work on ellipsis (fiengo and may, 1994; lappin, 1993; dalrymple et al, 1991; kehler, 1993; <papid> E93-1025 </papid>shieber et al, 1996) is aimedat discerning the procedures and the level of language processing at which ellipsis resolution takes place, or ambiguous and difficult cases.</citsent>
<aftsection>
<nextsent>the detection of elliptical sentences or the identification of the antecedent and elided clauses within them are usually not dealt with, but taken as given.
</nextsent>
<nextsent>noisy or missing input, which is unavoidable in nlp applications, is not dealt with, and neither is focusing on specific domains or applications.
</nextsent>
<nextsent>it therefore becomes clear that robust, trainable approach is needed.
</nextsent>
<nextsent>an example of verb phrase ellipsis (vpe), which is detected by the presence of an auxiliary verb without verb phrase, is seen in example 1.vpe can also occur with semi-auxiliaries, as in example 2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q148">
<title id=" P04-2009.xml">robust vpe detection using automatically parsed text </title>
<section> identifying antecedents. for most cases of.  </section>
<citcontext>
<prevsection>
<prevsent>first, elided.
</prevsent>
<prevsent>verbs need to be found.
</prevsent>
</prevsection>
<citsent citstr=" J97-4002 ">
ellipsis, copying of the antecedent clause is enough for resolution (hardt, 1997).<papid> J97-4002 </papid></citsent>
<aftsection>
<nextsent>biguity exists, method for generating the full list of possible solutions, and suggesting the most likely one is needed.
</nextsent>
<nextsent>this paper describes the work done on the first stage, the detection of elliptical verbs.
</nextsent>
<nextsent>first, previous work done on tagged corpora will be summarised.
</nextsent>
<nextsent>then, new work on parsed corpora will be presented, showing the gains possible throughsentence-level features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q149">
<title id=" P04-2009.xml">robust vpe detection using automatically parsed text </title>
<section> resolving ambiguities. for cases where am-.  </section>
<citcontext>
<prevsection>
<prevsent>in previous work (nielsen, 2003a; nielsen, 2003b) we performed experiments on the british national corpus using variety of machine learning techniques.
</prevsent>
<prevsent>these earlier results are not directly comparable to hardts, due to the different corpora used.
</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
the expanded set of results are summarised in table 1, for transformation based learning (tbl) (brill, 1995), <papid> J95-4004 </papid>gis based maximum entropy modelling (gis-maxent) (ratna parkhi, 1998), l-bfgs based maximum entropy modelling (l-bfgs-maxent)2 (malouf, 2002), <papid> W02-2018 </papid>decision tree learning (quinlan, 1993) and memory based learning (mbl) (daelemans et al., 2002).</citsent>
<aftsection>
<nextsent>algorithm recall precision f1 tbl 69.63 85.14 76.61 decision tree 60.93 79.39 68.94 mbl 72.58 71.50 72.04 gis-maxent 71.72 63.89 67.58 l-bfgs-maxent 71.93 80.58 76.01 table 1: comparison of algorithms 1precision, recall and f1 are defined as : recall = no(correct ellipses found)no(all ellipses in test) (1) precision = no(correct ellipses found)no(all ellipses found) (2) f1 = 2?
</nextsent>
<nextsent>precisionrecallprecision+recall (3) 2downloadable from http://www.nlplab.cn/zhangle/maxent toolkit.htmlfor all of these experiments, the training features consisted of lexical forms and part of speech(pos) tags of the words in three word for ward/backward window of the auxiliary beingtested.
</nextsent>
<nextsent>this context size was determined empirically to give optimum results, and will be used throughout this paper.
</nextsent>
<nextsent>the l-bfgs-maxent uses gaussian prior smoothing which was optimized for the bnc data, while the gis-maxent has asimple smoothing option available, but this deteriorates results and is not used.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q150">
<title id=" P04-2009.xml">robust vpe detection using automatically parsed text </title>
<section> resolving ambiguities. for cases where am-.  </section>
<citcontext>
<prevsection>
<prevsent>in previous work (nielsen, 2003a; nielsen, 2003b) we performed experiments on the british national corpus using variety of machine learning techniques.
</prevsent>
<prevsent>these earlier results are not directly comparable to hardts, due to the different corpora used.
</prevsent>
</prevsection>
<citsent citstr=" W02-2018 ">
the expanded set of results are summarised in table 1, for transformation based learning (tbl) (brill, 1995), <papid> J95-4004 </papid>gis based maximum entropy modelling (gis-maxent) (ratna parkhi, 1998), l-bfgs based maximum entropy modelling (l-bfgs-maxent)2 (malouf, 2002), <papid> W02-2018 </papid>decision tree learning (quinlan, 1993) and memory based learning (mbl) (daelemans et al., 2002).</citsent>
<aftsection>
<nextsent>algorithm recall precision f1 tbl 69.63 85.14 76.61 decision tree 60.93 79.39 68.94 mbl 72.58 71.50 72.04 gis-maxent 71.72 63.89 67.58 l-bfgs-maxent 71.93 80.58 76.01 table 1: comparison of algorithms 1precision, recall and f1 are defined as : recall = no(correct ellipses found)no(all ellipses in test) (1) precision = no(correct ellipses found)no(all ellipses found) (2) f1 = 2?
</nextsent>
<nextsent>precisionrecallprecision+recall (3) 2downloadable from http://www.nlplab.cn/zhangle/maxent toolkit.htmlfor all of these experiments, the training features consisted of lexical forms and part of speech(pos) tags of the words in three word for ward/backward window of the auxiliary beingtested.
</nextsent>
<nextsent>this context size was determined empirically to give optimum results, and will be used throughout this paper.
</nextsent>
<nextsent>the l-bfgs-maxent uses gaussian prior smoothing which was optimized for the bnc data, while the gis-maxent has asimple smoothing option available, but this deteriorates results and is not used.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q151">
<title id=" P04-2009.xml">robust vpe detection using automatically parsed text </title>
<section> resolving ambiguities. for cases where am-.  </section>
<citcontext>
<prevsection>
<prevsent>the l-bfgs-maxent uses gaussian prior smoothing which was optimized for the bnc data, while the gis-maxent has asimple smoothing option available, but this deteriorates results and is not used.
</prevsent>
<prevsent>mbl was used with its default settings.
</prevsent>
</prevsection>
<citsent citstr=" W99-0705 ">
while tbl gave the best results, the software we used (lager, 1999) <papid> W99-0705 </papid>ran into memory problem sand proved problematic with larger datasets.</citsent>
<aftsection>
<nextsent>decision trees, on the other hand, tend to oversimplify due to the very sparse nature of ellipsis, and produce single rule that classifies everything as non vpe.
</nextsent>
<nextsent>this leaves maximum entropy and mbl for further experiments.
</nextsent>
<nextsent>3 corpus description.
</nextsent>
<nextsent>the british national corpus (bnc) (leech, 1992) is annotated with pos tags, using the claws-4tagset.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q152">
<title id=" P04-2009.xml">robust vpe detection using automatically parsed text </title>
<section> resolving ambiguities. for cases where am-.  </section>
<citcontext>
<prevsection>
<prevsent>a range of sections of the bnc, containing around 370k words3 with 645 samples of vpe was used as training data.
</prevsent>
<prevsent>the separate test data consists of around 74k words4 with 200 samples of vpe.
</prevsent>
</prevsection>
<citsent citstr=" H94-1020 ">
the penn treebank (marcus et al, 1994) <papid> H94-1020 </papid>has more than hundred phrase labels, and number of empty categories, but uses coarser tagset.</citsent>
<aftsection>
<nextsent>a mixture of sections from the wall street journal and brown corpus were used.
</nextsent>
<nextsent>the training sec tion5 consists of around 540k words and contains 522 samples of vpe.
</nextsent>
<nextsent>the test section6 consists of around 140k words and contains 150 samples of vpe.
</nextsent>
<nextsent>to experiment with what gains are possible through the use of more complex data such as 3sections cs6, a2u, j25, fu6, h7f, ha3, a19, a0p, g1a, ewc, fns, c8t 4sections edj, fr3 5sections wsj 00, 01, 03, 04, 15, brown cf, cg, cl, cm, cn, cp 6sections wsj 02, 10, brown ck, crparse trees, the penn treebank is used for the second round of experiments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q155">
<title id=" P04-2009.xml">robust vpe detection using automatically parsed text </title>
<section> conclusion and future work.  </section>
<citcontext>
<prevsection>
<prevsent>adding empty category information gives 88%, compared to previous results of 48% (hardt, 1997)?<papid> J97-4002 </papid></prevsent>
<prevsent>re-parsing the treebank data , top performance is 63%, raised to 68% using extra features ? parsing the bnc, top performance is 71%, raised to 72% using extra features ? combining the parsed data, top performance is 67%, raised to 71% using extra features the results demonstrate that the method can be applied to practical tasks using free text.</prevsent>
</prevsection>
<citsent citstr=" P02-1018 ">
next, we will experiment with an algorithm (johnson, 2002) <papid> P02-1018 </papid>that can insert empty-category information into data from charniaks parser, allowing replication of features that need this.</citsent>
<aftsection>
<nextsent>cross-validation experiments will be performed to negate the effects the small test set may cause.as machine learning is used to combine various features, this method can be extended to other forms of ellipsis, and other languages.
</nextsent>
<nextsent>however,a number of the features used are specific to english vpe, and would have to be adapted to such cases.
</nextsent>
<nextsent>it is difficult to extrapolate how successful mbl gis-maxent l-bfgs-maxent rec prec f1 rec prec f1 rec prec f1 charniak words + pos 54.00 62.30 57.85 38.66 79.45 52.01 56.66 71.42 63.19 + features 58.00 65.41 61.48 50.66 73.78 60.07 65.33 72.05 68.53 rasp words + pos 55.92 66.92 60.93 43.42 56.89 49.25 51.63 79.00 62.45 + features 57.23 71.31 63.50 61.84 72.30 66.66 62.74 73.84 67.84 table 9: results on re-parsed data from the treebank mbl gis-maxent l-bfgs-maxent rec prec f1 rec prec f1 rec prec f1 charniak words + pos 66.50 63.63 65.03 55.00 75.86 63.76 71.00 70.64 70.82 + features 67.50 67.16 67.33 65.00 75.58 69.89 71.00 73.19 72.08 rasp words + pos 61.92 63.21 62.56 64.46 54.04 58.79 65.34 70.96 68.04 + features 71.06 73.29 72.16 73.09 61.01 66.51 70.29 67.29 68.76 table 11: results on parsed data from the bnc mbl gis-maxent l-bfgs-maxent rec prec f1 rec prec f1 rec prec f1 charniak words + pos 62.28 69.20 65.56 54.28 77.86 63.97 65.14 69.30 67.15 + features 65.71 71.87 68.65 63.71 72.40 67.78 70.85 69.85 70.35 rasp words + pos 63.61 67.47 65.48 59.31 55.94 57.37 57.46 71.83 63.84 + features 68.48 69.88 69.17 67.61 71.47 69.48 70.14 72.17 71.14 table 13: results on parsed data using the combined dataset such approaches would be based on current work, but it can be expected that they would be feasible, albeit with lower performance.
</nextsent>

</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q156">
<title id=" N12-1069.xml">con cavity and initialization for unsupervised dependency parsing </title>
<section> abstract </section>
<citcontext>
<prevsection>

<prevsent>we investigate models for unsupervised learning with concave log-likelihood functions.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
we begin with the most well-known example, ibm model 1 for word alignment (brownet al, 1993) <papid> J93-2003 </papid>and analyze its properties, discussing why other models for unsupervised learning are so seldom concave.</citsent>
<aftsection>
<nextsent>we then present concave models for dependency grammar induction and validate them experimentally.
</nextsent>
<nextsent>we find our concave models to be effective initializers for the dependency model of klein and manning (2004) <papid> P04-1061 </papid>and show that we can encode linguistic knowledge in them for improved performance.</nextsent>
<nextsent>in nlp, unsupervised learning typically implies optimization of bumpy?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q157">
<title id=" N12-1069.xml">con cavity and initialization for unsupervised dependency parsing </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>we begin with the most well-known example, ibm model 1 for word alignment (brownet al, 1993) <papid> J93-2003 </papid>and analyze its properties, discussing why other models for unsupervised learning are so seldom concave.</prevsent>
<prevsent>we then present concave models for dependency grammar induction and validate them experimentally.</prevsent>
</prevsection>
<citsent citstr=" P04-1061 ">
we find our concave models to be effective initializers for the dependency model of klein and manning (2004) <papid> P04-1061 </papid>and show that we can encode linguistic knowledge in them for improved performance.</citsent>
<aftsection>
<nextsent>in nlp, unsupervised learning typically implies optimization of bumpy?
</nextsent>
<nextsent>objective function riddled with local maxima.
</nextsent>
<nextsent>however, one exception is ibm model 1 (brown et al, 1993) <papid> J93-2003 </papid>for word alignment,which is the only model commonly used for unsupervised learning in nlp that has concave log likelihood function.1 for other models, such as those used in unsupervised part-of-speech tagging and grammar induction, and indeed for more sophisticated word alignment models, the log-likelihood function maximized by em is non-concave.</nextsent>
<nextsent>as aresult, researchers are obligated to consider initialization in addition to model design (klein and manning, 2004; <papid> P04-1061 </papid>goldberg et al, 2008).<papid> P08-1085 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q161">
<title id=" N12-1069.xml">con cavity and initialization for unsupervised dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>objective function riddled with local maxima.
</prevsent>
<prevsent>however, one exception is ibm model 1 (brown et al, 1993) <papid> J93-2003 </papid>for word alignment,which is the only model commonly used for unsupervised learning in nlp that has concave log likelihood function.1 for other models, such as those used in unsupervised part-of-speech tagging and grammar induction, and indeed for more sophisticated word alignment models, the log-likelihood function maximized by em is non-concave.</prevsent>
</prevsection>
<citsent citstr=" P08-1085 ">
as aresult, researchers are obligated to consider initialization in addition to model design (klein and manning, 2004; <papid> P04-1061 </papid>goldberg et al, 2008).<papid> P08-1085 </papid></citsent>
<aftsection>
<nextsent>for example, consider the dependency grammar induction results shown in table 1 when training the 1it is not strictly concave (toutanova and galley, 2011).<papid> P11-2081 </papid></nextsent>
<nextsent>widely used dependency model with valence (dmv;klein and manning, 2004).<papid> P04-1061 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q162">
<title id=" N12-1069.xml">con cavity and initialization for unsupervised dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, one exception is ibm model 1 (brown et al, 1993) <papid> J93-2003 </papid>for word alignment,which is the only model commonly used for unsupervised learning in nlp that has concave log likelihood function.1 for other models, such as those used in unsupervised part-of-speech tagging and grammar induction, and indeed for more sophisticated word alignment models, the log-likelihood function maximized by em is non-concave.</prevsent>
<prevsent>as aresult, researchers are obligated to consider initialization in addition to model design (klein and manning, 2004; <papid> P04-1061 </papid>goldberg et al, 2008).<papid> P08-1085 </papid></prevsent>
</prevsection>
<citsent citstr=" P11-2081 ">
for example, consider the dependency grammar induction results shown in table 1 when training the 1it is not strictly concave (toutanova and galley, 2011).<papid> P11-2081 </papid></citsent>
<aftsection>
<nextsent>widely used dependency model with valence (dmv;klein and manning, 2004).<papid> P04-1061 </papid></nextsent>
<nextsent>using uniform distributions for initialization (unif) results in an accuracy of 17.6% on the test set, well below the base line of attaching each word to its right neighbor (attachright, 31.7%).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q166">
<title id=" N12-1069.xml">con cavity and initialization for unsupervised dependency parsing </title>
<section> concave, unsupervised models.  </section>
<citcontext>
<prevsection>
<prevsent>wefound that conditioning on direction improved per formance: we rewrite the distributions as c(ej | ei, sign(j ? i)) and denote this model by ccv1.
</prevsent>
<prevsent>578 we note that we can also include constraints in thesum over possible parents and still preserve concavity.
</prevsent>
</prevsection>
<citsent citstr=" D10-1120 ">
naseem et al (2010) <papid> D10-1120 </papid>found that adding parent child constraints to grammar induction system can improve performance dramatically.</citsent>
<aftsection>
<nextsent>we employ one simple rule: roots are likely to be verbs.2 we modify ccv1 to restrict the summation over parents to exclude e0 if the child word is not verb.
</nextsent>
<nextsent>3 we only.
</nextsent>
<nextsent>employ this restriction during em learning for sentences containing at least one verb.
</nextsent>
<nextsent>for sentences without verbs, we allow all words to be the root.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q167">
<title id=" N12-1069.xml">con cavity and initialization for unsupervised dependency parsing </title>
<section> concave, unsupervised models.  </section>
<citcontext>
<prevsection>
<prevsent>for sentences without verbs, we allow all words to be the root.
</prevsent>
<prevsent>we denote this model by ccv2.
</prevsent>
</prevsection>
<citsent citstr=" D10-1118 ">
in related work, brody (2010) <papid> D10-1118 </papid>also developed grammar induction models based on the ibm word alignment models.</citsent>
<aftsection>
<nextsent>however, while our goal is to develop concave models, brody employed bayesian nonparametrics in his version of model 1, which makes the model non-concave.
</nextsent>
<nextsent>we ran experiments to determine how well our concave grammar induction models ccv1 and ccv2 can perform on their own and when used as initializers for the dmv (klein and manning, 2004).<papid> P04-1061 </papid></nextsent>
<nextsent>the dmvis generative model of pos tag sequences and projective dependency trees over them.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q171">
<title id=" N12-1069.xml">con cavity and initialization for unsupervised dependency parsing </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>k&m; 64.3 53.3 punc/utags k&m;? - 59.1?
</prevsent>
<prevsent>table 1: english attachment accuracies on section 23, for short sentences (10 words) and all (??).
</prevsent>
</prevsection>
<citsent citstr=" N09-1009 ">
we include selected results on this same test set: shared ln = cohen and smith (2009), <papid> N09-1009 </papid>l-evg = headden iii et al (2009),feature dmv = berg-kirkpatrick et al (2010), lextsg dmv = blunsom and cohn (2010), <papid> D10-1117 </papid>posterior reg.</citsent>
<aftsection>
<nextsent>= gillenwater et al (2010), punc/utags = spitkovsky et al.
</nextsent>
<nextsent>(2011a).
</nextsent>
<nextsent>k&m;? is from spitkovsky et al (2011<papid> W11-0303 </papid>b).</nextsent>
<nextsent>accuracies are averages over 50 random initializers; ? = 10.9 for test sentences ? 10 and 8.3 for all.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q172">
<title id=" N12-1069.xml">con cavity and initialization for unsupervised dependency parsing </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>k&m; 64.3 53.3 punc/utags k&m;? - 59.1?
</prevsent>
<prevsent>table 1: english attachment accuracies on section 23, for short sentences (10 words) and all (??).
</prevsent>
</prevsection>
<citsent citstr=" D10-1117 ">
we include selected results on this same test set: shared ln = cohen and smith (2009), <papid> N09-1009 </papid>l-evg = headden iii et al (2009),feature dmv = berg-kirkpatrick et al (2010), lextsg dmv = blunsom and cohn (2010), <papid> D10-1117 </papid>posterior reg.</citsent>
<aftsection>
<nextsent>= gillenwater et al (2010), punc/utags = spitkovsky et al.
</nextsent>
<nextsent>(2011a).
</nextsent>
<nextsent>k&m;? is from spitkovsky et al (2011<papid> W11-0303 </papid>b).</nextsent>
<nextsent>accuracies are averages over 50 random initializers; ? = 10.9 for test sentences ? 10 and 8.3 for all.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q173">
<title id=" N12-1069.xml">con cavity and initialization for unsupervised dependency parsing </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>= gillenwater et al (2010), punc/utags = spitkovsky et al.
</prevsent>
<prevsent>(2011a).
</prevsent>
</prevsection>
<citsent citstr=" W11-0303 ">
k&m;? is from spitkovsky et al (2011<papid> W11-0303 </papid>b).</citsent>
<aftsection>
<nextsent>accuracies are averages over 50 random initializers; ? = 10.9 for test sentences ? 10 and 8.3 for all.
</nextsent>
<nextsent>used many random initializers with unsupervised run selection.
</nextsent>
<nextsent>used staged training with sentences ? 45 words.
</nextsent>
<nextsent>proportional to their distances, then normalizes to obtain probability distributions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q175">
<title id=" N12-1069.xml">con cavity and initialization for unsupervised dependency parsing </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>for training, sentences ? 10 words from each treebank were used.
</prevsent>
<prevsent>in order, languages are basque, bulgarian, catalan, chinese, czech, danish, dutch, english, german, greek, hungarian, italian, japanese, portuguese, slovenian, spanish, swedish, and turkish.
</prevsent>
</prevsection>
<citsent citstr=" W06-2920 ">
data we use data prepared for the conll 2006/07 shared tasks (buchholz and marsi, 2006; <papid> W06-2920 </papid>nivre et al, 2007).<papid> D07-1096 </papid>4 we follow standard practice in removing punctuation and using short sentences(?</citsent>
<aftsection>
<nextsent>10 or ? 20 words) for training.
</nextsent>
<nextsent>for all experiments, we train on separate data from that used for testing and use gold pos tags for both training and testing.
</nextsent>
<nextsent>we report accuracy on (i) test set sentences 10 words and (ii) all sentences from the test set.
</nextsent>
<nextsent>results results for english are shown in tab.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q176">
<title id=" N12-1069.xml">con cavity and initialization for unsupervised dependency parsing </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>for training, sentences ? 10 words from each treebank were used.
</prevsent>
<prevsent>in order, languages are basque, bulgarian, catalan, chinese, czech, danish, dutch, english, german, greek, hungarian, italian, japanese, portuguese, slovenian, spanish, swedish, and turkish.
</prevsent>
</prevsection>
<citsent citstr=" D07-1096 ">
data we use data prepared for the conll 2006/07 shared tasks (buchholz and marsi, 2006; <papid> W06-2920 </papid>nivre et al, 2007).<papid> D07-1096 </papid>4 we follow standard practice in removing punctuation and using short sentences(?</citsent>
<aftsection>
<nextsent>10 or ? 20 words) for training.
</nextsent>
<nextsent>for all experiments, we train on separate data from that used for testing and use gold pos tags for both training and testing.
</nextsent>
<nextsent>we report accuracy on (i) test set sentences 10 words and (ii) all sentences from the test set.
</nextsent>
<nextsent>results results for english are shown in tab.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q179">
<title id=" N12-1069.xml">con cavity and initialization for unsupervised dependency parsing </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>2.
</prevsent>
<prevsent>ccv2 leads to substantially higher likelihoods than the other initializers, suggesting that the verb-root constraint is helping em to find better local optima.5
</prevsent>
</prevsection>
<citsent citstr=" N10-1116 ">
staged training has been shown to help unsupervised learning in the past, from early work in grammar induction (lari and young, 1990) and word alignment(brown et al, 1993) <papid> J93-2003 </papid>to more recent work in dependency grammar induction (spitkovsky et al, 2010).<papid> N10-1116 </papid></citsent>
<aftsection>
<nextsent>while we do not yet offer generic procedure for extracting concave approximation from any model for unsupervised learning, our results contribute evidence in favor of the general methodology of staged training in unsupervised learning, and provide simple and powerful initialization method for dependency grammar induction.
</nextsent>
<nextsent>acknowledgments we thank shay cohen, dipanjan das, val spitkovsky,and members of the ark research group for helpful comments that improved this paper.
</nextsent>
<nextsent>this research was supported in part by the nsf through grant iis-0915187, theu.
</nextsent>
<nextsent>s. army research laboratory and the u. s. army research office under contract/grant number w911nf-10 1-0533, and sandia national laboratories (fellowship to k. gimpel).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q180">
<title id=" P01-1029.xml">word order in german a formal dependency grammar using a topological hierarchy </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for instance, non-finite verb can open two kinds of topological phrases, either phrase, which we call domain, with positions for all of its dependents, or restricted phrase, which forms the verb cluster, with no positions for dependents other than predicative elements.
</prevsent>
<prevsent>these two kinds of phrases must be placed in very different topological positions.
</prevsent>
</prevsection>
<citsent citstr=" P98-1106 ">
the fact that we pass through (topological) phrase structure in order to relate dependency and word order distinguishes our approach from usual dependency grammars (mel cuk &amp; pertsov, 1987; brker, 1998; kahane et al, 1998; <papid> P98-1106 </papid>duchier &amp; debusmann, 2001).<papid> P01-1024 </papid></citsent>
<aftsection>
<nextsent>the description of german word order closest to our analysis is the hpsg grammar of kathol (1995; see also reape 1994), who proposes linearization rules exclusively based on formalization of the topological structure.
</nextsent>
<nextsent>how ever, as required by the formalism he uses, regular phrase structure, which we do not need in our analysis, still underlies the structures obtained.
</nextsent>
<nextsent>our work constitutes syntactic module which links (unordered) syntactic structures withtopological phrase structures.
</nextsent>
<nextsent>syntactic structures are related to semantic structures,whereas topological phrase structures are related to phonological structures.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q181">
<title id=" P01-1029.xml">word order in german a formal dependency grammar using a topological hierarchy </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for instance, non-finite verb can open two kinds of topological phrases, either phrase, which we call domain, with positions for all of its dependents, or restricted phrase, which forms the verb cluster, with no positions for dependents other than predicative elements.
</prevsent>
<prevsent>these two kinds of phrases must be placed in very different topological positions.
</prevsent>
</prevsection>
<citsent citstr=" P01-1024 ">
the fact that we pass through (topological) phrase structure in order to relate dependency and word order distinguishes our approach from usual dependency grammars (mel cuk &amp; pertsov, 1987; brker, 1998; kahane et al, 1998; <papid> P98-1106 </papid>duchier &amp; debusmann, 2001).<papid> P01-1024 </papid></citsent>
<aftsection>
<nextsent>the description of german word order closest to our analysis is the hpsg grammar of kathol (1995; see also reape 1994), who proposes linearization rules exclusively based on formalization of the topological structure.
</nextsent>
<nextsent>how ever, as required by the formalism he uses, regular phrase structure, which we do not need in our analysis, still underlies the structures obtained.
</nextsent>
<nextsent>our work constitutes syntactic module which links (unordered) syntactic structures withtopological phrase structures.
</nextsent>
<nextsent>syntactic structures are related to semantic structures,whereas topological phrase structures are related to phonological structures.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q183">
<title id=" P03-1057.xml">feedback cleaning of machine translation rules using automatic evaluation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, knowledge for transfer based mt acquired from corpora contains many in correct/redundant rules due to acquisition errors or translation variety in the corpora.
</prevsent>
<prevsent>such rules conflict with other existing rules and cause implausible mt results or increase ambiguity.
</prevsent>
</prevsection>
<citsent citstr=" C00-1078 ">
if incorrect rules could be avoided, mt quality would necessarily im prove.there are two approaches to overcoming incor rect/redundant rules: ? selecting appropriate rules in disambiguation process during the translation (on-line processing, (meyers et al, 2000)).<papid> C00-1078 </papid></citsent>
<aftsection>
<nextsent>cleaning incorrect/redundant rules after automatic acquisition (off-line processing, (menezes and richardson, 2001; imamura, 2002)).
</nextsent>
<nextsent>we employ the second approach in this paper.
</nextsent>
<nextsent>the cutoff by frequency (menezes and richardson, 2001) and the hypothesis test (imamura, 2002) have been applied to clean the rules.
</nextsent>
<nextsent>the cutoff by frequency can slightly improve mt quality, but the improvement is still insufficient from the viewpoint of the large number of redundant rules.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q184">
<title id=" P03-1057.xml">feedback cleaning of machine translation rules using automatic evaluation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the cutoff by frequency can slightly improve mt quality, but the improvement is still insufficient from the viewpoint of the large number of redundant rules.
</prevsent>
<prevsent>the hypothesis test requires very large corpora in order to obtain asufficient number of rules that are statistically confident.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
another current topic of machine translation is automatic evaluation of mt quality (papineni et al, 2002; <papid> P02-1040 </papid>yasuda et al, 2001; akiba et al, 2001).</citsent>
<aftsection>
<nextsent>these methods aim to replace subjective evaluation in order to speed up the development cycle of mt systems.
</nextsent>
<nextsent>however, they can be utilized not only as de velopers?
</nextsent>
<nextsent>aids but also for automatic tuning of mt systems (su et al, 1992).<papid> C92-2067 </papid></nextsent>
<nextsent>we propose feedback cleaning that utilize san automatic evaluation for removing incor rect/redundant translation rules as tuning method training corpus automatic acquisition translation rules evaluation corpus mt engine automatic evaluation mt results rule selection/deletion feedback cleaning figure 1: structure of feedback cleaning (figure 1).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q185">
<title id=" P03-1057.xml">feedback cleaning of machine translation rules using automatic evaluation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these methods aim to replace subjective evaluation in order to speed up the development cycle of mt systems.
</prevsent>
<prevsent>however, they can be utilized not only as de velopers?
</prevsent>
</prevsection>
<citsent citstr=" C92-2067 ">
aids but also for automatic tuning of mt systems (su et al, 1992).<papid> C92-2067 </papid></citsent>
<aftsection>
<nextsent>we propose feedback cleaning that utilize san automatic evaluation for removing incor rect/redundant translation rules as tuning method training corpus automatic acquisition translation rules evaluation corpus mt engine automatic evaluation mt results rule selection/deletion feedback cleaning figure 1: structure of feedback cleaning (figure 1).
</nextsent>
<nextsent>our method evaluates the contribution of each rule to the mt results and removes inappropriate rules as way to increase the evaluation scores.
</nextsent>
<nextsent>since the automatic evaluation correlates with subjective evaluation, mt quality will im prove after cleaning.
</nextsent>
<nextsent>our method only evaluates mt results and does not consider various conditions of the mt engine,such as parameters, interference in dictionaries, disambiguation methods, and so on.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q186">
<title id=" P03-1057.xml">feedback cleaning of machine translation rules using automatic evaluation </title>
<section> mt system and problems of automatic.  </section>
<citcontext>
<prevsection>
<prevsent>when the system translates an input sentence, the sentence is first parsed by using source patterns ofthe transfer rules.
</prevsent>
<prevsent>next, tree structure of the target language is generated by mapping the source patterns to the corresponding target patterns.
</prevsent>
</prevsection>
<citsent citstr=" C94-1015 ">
whennon-terminal symbols remain in the target tree, target words are inserted by referring to translation dictionary.ambiguities, which occur during parsing or mapping, are resolved by selecting the rules that minimize the semantic distance between the input words and source examples (real examples in the training corpus) of the transfer rules (furuse and iida, 1994).<papid> C94-1015 </papid></citsent>
<aftsection>
<nextsent>for instance, when the input phrase leave at 11 a.m.?
</nextsent>
<nextsent>is translated into japanese, rule 2 in figure 2 is selected because the semantic distance from the source example (arrive, p.m.) is the shortest to the headwords of the input phrase (leave, a.m.).
</nextsent>
<nextsent>2.2 problems of automatic acquisition.
</nextsent>
<nextsent>hpat automatically acquires its transfer rules from parallel corpora by using hierarchical phrase alignment (imamura, 2001).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q189">
<title id=" P04-1079.xml">extending the bleu mt evaluation method with frequency weightings </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they are intended to yield scores that correlate with human judgments of translation quality and enable systems (machine or human) to be ranked on this basis.
</prevsent>
<prevsent>several such automatic methods have been proposed in recent years.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
some of them use human reference translations, e.g., the bleu method (papineni et al., 2002), <papid> P02-1040 </papid>which is based on comparison of n-gram models in mt output and in set of human reference translations.</citsent>
<aftsection>
<nextsent>however, serious problem for the bleu method is the lack of model for relative importance of matched and mismatched items.
</nextsent>
<nextsent>words in text usually carry an unequal informational load, and as result are of differing importance for translation.
</nextsent>
<nextsent>it is reasonable to expect that the choices of right translation equivalents for certain key items, such as expressions denoting principal events, event participants and relations in text are more important in the eyes of human evaluators then choices of function words and syntactic perspective for sentences.
</nextsent>
<nextsent>accurate rendering of these key items by an mt system boosts the quality of translation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q194">
<title id=" P02-1015.xml">parsing non recursive cfgs </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as this approach may be prohibitively expensive, it is preferable to find parsing algorithm that sharessubcomputations among different strings by working directly on the nonterminals and the rules of thenon-recursive cfg.
</prevsent>
<prevsent>in this way, parsing?
</prevsent>
</prevsection>
<citsent citstr=" A00-2023 ">
a nonterminal of the grammar amounts to shared parsing of all the sub strings encoded by that nonterminal.to give few examples, in some natural language generation systems (langkilde, 2000) <papid> A00-2023 </papid>non recursive cfgs are used to encode very large setsof candidate sentences realizing some input conceptual representation (langkilde calls such grammars forests).</citsent>
<aftsection>
<nextsent>each cfg is later parsed?
</nextsent>
<nextsent>using language model, in order to rank the sentences in the set according to their likelyhood.
</nextsent>
<nextsent>similarly, insome approaches to automatic speech understanding (corazza and lavelli, 1994) the  -best sentences obtained from the speech recognition module are compressed?
</nextsent>
<nextsent>into non-recursive cfg grammar, which is later provided as input to parser.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q203">
<title id=" P03-1042.xml">uncertainty reduction in collaborative bootstrapping measure and algorithm </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>during the process, the two classifiers help each other by exchanging the labelled data.
</prevsent>
<prevsent>in co-training, the two classifiers have different feature structures, and in bilingual bootstrapping, the two classifiers have different class structures.
</prevsent>
</prevsection>
<citsent citstr=" P02-1046 ">
dasgupta et al (2001) and abney (2002) <papid> P02-1046 </papid>conducted theoretical analyses on the performance (generalization error) of co-training.</citsent>
<aftsection>
<nextsent>their analyses, however, cannot be directly used in studies of co training in (nigam &amp; ghani, 2000) and bilingual bootstrapping.
</nextsent>
<nextsent>in this paper, we propose the use of uncertainty reduction in the study of collaborative bootstrapping (both co-training and bilingual bootstrapping).
</nextsent>
<nextsent>we point out that uncertainty reduction is an important factor for enhancing the performances of the classifiers in collaborative bootstrapping.
</nextsent>
<nextsent>here, the uncertainty of classifier is defined as the portion of instances on which it cannot make classification decisions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q205">
<title id=" P03-1042.xml">uncertainty reduction in collaborative bootstrapping measure and algorithm </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>this assumption is called view independence?.
</prevsent>
<prevsent>in their algorithm of co-training, one classifier always asks the other classifier to label the most certain instances for the collaborator.
</prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
the word sense disambiguation method proposed in yarowsky (1995) <papid> P95-1026 </papid>can also be viewed as kind of co-training.</citsent>
<aftsection>
<nextsent>since the assumption of view independence cannot always be met in practice, collins and singer (1998) proposed co-training algorithm based on agreement?
</nextsent>
<nextsent>between the classifiers.
</nextsent>
<nextsent>as for theoretical analysis, dasgupta et al  (2001) gave bound on the generalization error of co-training within the framework of pac learning.
</nextsent>
<nextsent>the generalization error is function of dis agreement?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q208">
<title id=" P03-1042.xml">uncertainty reduction in collaborative bootstrapping measure and algorithm </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>he also proposed new co-training algorithm on the basis of the constraint.
</prevsent>
<prevsent>nigam and ghani (2000) empirically demonstrated that bootstrapping with random feature split (i.e. co-training), even violating the view independence assumption, can still work better than bootstrapping without feature split (i.e., bootstrapping with single classifier).
</prevsent>
</prevsection>
<citsent citstr=" W01-0501 ">
for other work on co-training, see (muslea et al  200; pierce and cardie 2001).<papid> W01-0501 </papid></citsent>
<aftsection>
<nextsent>li and li (2002) <papid> P02-1044 </papid>proposed an algorithm for word sense disambiguation in translation between two languages, which they called bilingual boot strapping?.</nextsent>
<nextsent>instead of making an assumption on the features, bilingual bootstrapping makes an assumption on the classes.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q209">
<title id=" P03-1042.xml">uncertainty reduction in collaborative bootstrapping measure and algorithm </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>nigam and ghani (2000) empirically demonstrated that bootstrapping with random feature split (i.e. co-training), even violating the view independence assumption, can still work better than bootstrapping without feature split (i.e., bootstrapping with single classifier).
</prevsent>
<prevsent>for other work on co-training, see (muslea et al  200; pierce and cardie 2001).<papid> W01-0501 </papid></prevsent>
</prevsection>
<citsent citstr=" P02-1044 ">
li and li (2002) <papid> P02-1044 </papid>proposed an algorithm for word sense disambiguation in translation between two languages, which they called bilingual boot strapping?.</citsent>
<aftsection>
<nextsent>instead of making an assumption on the features, bilingual bootstrapping makes an assumption on the classes.
</nextsent>
<nextsent>specifically, it assumes that the classes of the classifiers in bootstrapping do not overlap.
</nextsent>
<nextsent>thus, bilingual bootstrapping is different from co-training.
</nextsent>
<nextsent>because the notion of agreement is not involved in bootstrapping in (nigam &amp; ghani 2000) and bilingual bootstrapping, dasgupta et aland abneys analyses cannot be directly used on them.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q213">
<title id=" N12-1089.xml">autonomous self assessment of auto corrections exploring text message dialogues </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, much of the spelling variation that appears in text messages may be produced intentionally.
</prevsent>
<prevsent>for instance, text message authors make frequent use of acronyms and abbreviations.
</prevsent>
</prevsection>
<citsent citstr=" P06-2005 ">
this motivates the task of text message normalization (aw et al, 2006; <papid> P06-2005 </papid>kobus et al, 2008), <papid> C08-1056 </papid>which attempts to transform all non-standard spellings in text message into their standard form.</citsent>
<aftsection>
<nextsent>the style of misspelling in text messages is often quite different from that of standard prose.
</nextsent>
<nextsent>for instance, whitelaw et. al.
</nextsent>
<nextsent>(2009) applied the aspell spell checker1 on corpus of mistakes in english prose and achieved an error rate of under 5%.
</nextsent>
<nextsent>conversely, the same spell checker was found to have an error rate of over 75% on text message data (choudhury et al, 2007).autocorrection in text messaging is similar to predictive texting and word completion technologies (dunlop and crossan, 2000).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q214">
<title id=" N12-1089.xml">autonomous self assessment of auto corrections exploring text message dialogues </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, much of the spelling variation that appears in text messages may be produced intentionally.
</prevsent>
<prevsent>for instance, text message authors make frequent use of acronyms and abbreviations.
</prevsent>
</prevsection>
<citsent citstr=" C08-1056 ">
this motivates the task of text message normalization (aw et al, 2006; <papid> P06-2005 </papid>kobus et al, 2008), <papid> C08-1056 </papid>which attempts to transform all non-standard spellings in text message into their standard form.</citsent>
<aftsection>
<nextsent>the style of misspelling in text messages is often quite different from that of standard prose.
</nextsent>
<nextsent>for instance, whitelaw et. al.
</nextsent>
<nextsent>(2009) applied the aspell spell checker1 on corpus of mistakes in english prose and achieved an error rate of under 5%.
</nextsent>
<nextsent>conversely, the same spell checker was found to have an error rate of over 75% on text message data (choudhury et al, 2007).autocorrection in text messaging is similar to predictive texting and word completion technologies (dunlop and crossan, 2000).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q215">
<title id=" P04-1040.xml">enriching the output of a parser using memory based learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for dependency corpus derived from the penn treebank and the parsers we considered, these transformations correspond to adding penn functional tags (e.g., -sbj, -tmp, -loc), empty nodes (e.g., np pro)and non-local dependencies (controlled traces, wh extraction, etc.).
</prevsent>
<prevsent>for these specific sub-tasks our method achieves state of the art performance.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
the evaluation of the transformed output of the parsers of charniak (2000)<papid> A00-2018 </papid>and collins (1999) gives 90% un labelled and 84% labelled accuracy with respect to dependencies, when measured against dependency corpus derived from the penn treebank.the paper is organized as follows.</citsent>
<aftsection>
<nextsent>after providing some background and motivation in section 2,we give the general overview of our method in section 3.
</nextsent>
<nextsent>in sections 4 through 8, we describe all stages of the transformation process, providing evaluation results and comparing our methods to earlier work.
</nextsent>
<nextsent>we discuss the results in section 9.
</nextsent>
<nextsent>state of the art statistical parsers, e.g., parsers trained on the penn treebank, produce syntactic parse trees with bare phrase labels, such as np, pp, s, although the training corpora are usually much richer and often contain additional grammatical and semantic information (distinguishing various modifiers, complements, subjects, objects, etc.), including non-local dependencies, i.e., relations between phrases not adjacent in the parse tree.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q217">
<title id=" P04-1040.xml">enriching the output of a parser using memory based learning </title>
<section> background and motivation.  </section>
<citcontext>
<prevsection>
<prevsent>state of the art statistical parsers, e.g., parsers trained on the penn treebank, produce syntactic parse trees with bare phrase labels, such as np, pp, s, although the training corpora are usually much richer and often contain additional grammatical and semantic information (distinguishing various modifiers, complements, subjects, objects, etc.), including non-local dependencies, i.e., relations between phrases not adjacent in the parse tree.
</prevsent>
<prevsent>while this information may be explicitly annotated in treebank,it is rarely used or delivered by parsers.1 the reason is that bringing in more information of this type usually makes the underlying parsing model more complicated: more parameters need to be estimated and independence assumptions may no longer hold.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
klein and manning (2003), <papid> P03-1054 </papid>for example, mention that using functional tags of the penn treebank (temporal, location, subject, predicate, etc.) with simple un lexicalized pcfg generally had negative effect on the parsers performance.</citsent>
<aftsection>
<nextsent>currently, there are no parsers trained on the penn treebank that use the structure of the treebank in full and that are thus 1some notable exceptions are the ccg parser described in(hockenmaier, 2003), <papid> P03-1046 </papid>which incorporates non-local dependencies into the parsers statistical model, and the parser of collins(1999), which uses wh traces and argument/modifier distinc tions.</nextsent>
<nextsent>capable of producing syntactic structures containing all or nearly all of the information annotated in the corpus.in recent years there has been growing interest in getting more information from parsers than just bare phrase trees.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q218">
<title id=" P04-1040.xml">enriching the output of a parser using memory based learning </title>
<section> background and motivation.  </section>
<citcontext>
<prevsection>
<prevsent>while this information may be explicitly annotated in treebank,it is rarely used or delivered by parsers.1 the reason is that bringing in more information of this type usually makes the underlying parsing model more complicated: more parameters need to be estimated and independence assumptions may no longer hold.
</prevsent>
<prevsent>klein and manning (2003), <papid> P03-1054 </papid>for example, mention that using functional tags of the penn treebank (temporal, location, subject, predicate, etc.) with simple un lexicalized pcfg generally had negative effect on the parsers performance.</prevsent>
</prevsection>
<citsent citstr=" P03-1046 ">
currently, there are no parsers trained on the penn treebank that use the structure of the treebank in full and that are thus 1some notable exceptions are the ccg parser described in(hockenmaier, 2003), <papid> P03-1046 </papid>which incorporates non-local dependencies into the parsers statistical model, and the parser of collins(1999), which uses wh traces and argument/modifier distinc tions.</citsent>
<aftsection>
<nextsent>capable of producing syntactic structures containing all or nearly all of the information annotated in the corpus.in recent years there has been growing interest in getting more information from parsers than just bare phrase trees.
</nextsent>
<nextsent>blaheta and charniak (2000)<papid> A00-2031 </papid>presented the first method for assigning penn functional tags to constituents identified by parser.pattern-matching approaches were used in (john son, 2002) <papid> P02-1018 </papid>and (jijkoun, 2003) <papid> P03-2006 </papid>to recover non-localdependencies in phrase trees.</nextsent>
<nextsent>furthermore, experiments described in (dienes and dubey, 2003) <papid> W03-1005 </papid>show that the latter task can be successfully addressed by shallow preprocessing methods.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q220">
<title id=" P04-1040.xml">enriching the output of a parser using memory based learning </title>
<section> background and motivation.  </section>
<citcontext>
<prevsection>
<prevsent>currently, there are no parsers trained on the penn treebank that use the structure of the treebank in full and that are thus 1some notable exceptions are the ccg parser described in(hockenmaier, 2003), <papid> P03-1046 </papid>which incorporates non-local dependencies into the parsers statistical model, and the parser of collins(1999), which uses wh traces and argument/modifier distinc tions.</prevsent>
<prevsent>capable of producing syntactic structures containing all or nearly all of the information annotated in the corpus.in recent years there has been growing interest in getting more information from parsers than just bare phrase trees.</prevsent>
</prevsection>
<citsent citstr=" A00-2031 ">
blaheta and charniak (2000)<papid> A00-2031 </papid>presented the first method for assigning penn functional tags to constituents identified by parser.pattern-matching approaches were used in (john son, 2002) <papid> P02-1018 </papid>and (jijkoun, 2003) <papid> P03-2006 </papid>to recover non-localdependencies in phrase trees.</citsent>
<aftsection>
<nextsent>furthermore, experiments described in (dienes and dubey, 2003) <papid> W03-1005 </papid>show that the latter task can be successfully addressed by shallow preprocessing methods.</nextsent>
<nextsent>in this section we give high-level overview of our method for transforming parsers output and describe the different steps of the process.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q223">
<title id=" P04-1040.xml">enriching the output of a parser using memory based learning </title>
<section> background and motivation.  </section>
<citcontext>
<prevsection>
<prevsent>currently, there are no parsers trained on the penn treebank that use the structure of the treebank in full and that are thus 1some notable exceptions are the ccg parser described in(hockenmaier, 2003), <papid> P03-1046 </papid>which incorporates non-local dependencies into the parsers statistical model, and the parser of collins(1999), which uses wh traces and argument/modifier distinc tions.</prevsent>
<prevsent>capable of producing syntactic structures containing all or nearly all of the information annotated in the corpus.in recent years there has been growing interest in getting more information from parsers than just bare phrase trees.</prevsent>
</prevsection>
<citsent citstr=" P02-1018 ">
blaheta and charniak (2000)<papid> A00-2031 </papid>presented the first method for assigning penn functional tags to constituents identified by parser.pattern-matching approaches were used in (john son, 2002) <papid> P02-1018 </papid>and (jijkoun, 2003) <papid> P03-2006 </papid>to recover non-localdependencies in phrase trees.</citsent>
<aftsection>
<nextsent>furthermore, experiments described in (dienes and dubey, 2003) <papid> W03-1005 </papid>show that the latter task can be successfully addressed by shallow preprocessing methods.</nextsent>
<nextsent>in this section we give high-level overview of our method for transforming parsers output and describe the different steps of the process.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q224">
<title id=" P04-1040.xml">enriching the output of a parser using memory based learning </title>
<section> background and motivation.  </section>
<citcontext>
<prevsection>
<prevsent>currently, there are no parsers trained on the penn treebank that use the structure of the treebank in full and that are thus 1some notable exceptions are the ccg parser described in(hockenmaier, 2003), <papid> P03-1046 </papid>which incorporates non-local dependencies into the parsers statistical model, and the parser of collins(1999), which uses wh traces and argument/modifier distinc tions.</prevsent>
<prevsent>capable of producing syntactic structures containing all or nearly all of the information annotated in the corpus.in recent years there has been growing interest in getting more information from parsers than just bare phrase trees.</prevsent>
</prevsection>
<citsent citstr=" P03-2006 ">
blaheta and charniak (2000)<papid> A00-2031 </papid>presented the first method for assigning penn functional tags to constituents identified by parser.pattern-matching approaches were used in (john son, 2002) <papid> P02-1018 </papid>and (jijkoun, 2003) <papid> P03-2006 </papid>to recover non-localdependencies in phrase trees.</citsent>
<aftsection>
<nextsent>furthermore, experiments described in (dienes and dubey, 2003) <papid> W03-1005 </papid>show that the latter task can be successfully addressed by shallow preprocessing methods.</nextsent>
<nextsent>in this section we give high-level overview of our method for transforming parsers output and describe the different steps of the process.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q225">
<title id=" P04-1040.xml">enriching the output of a parser using memory based learning </title>
<section> background and motivation.  </section>
<citcontext>
<prevsection>
<prevsent>capable of producing syntactic structures containing all or nearly all of the information annotated in the corpus.in recent years there has been growing interest in getting more information from parsers than just bare phrase trees.
</prevsent>
<prevsent>blaheta and charniak (2000)<papid> A00-2031 </papid>presented the first method for assigning penn functional tags to constituents identified by parser.pattern-matching approaches were used in (john son, 2002) <papid> P02-1018 </papid>and (jijkoun, 2003) <papid> P03-2006 </papid>to recover non-localdependencies in phrase trees.</prevsent>
</prevsection>
<citsent citstr=" W03-1005 ">
furthermore, experiments described in (dienes and dubey, 2003) <papid> W03-1005 </papid>show that the latter task can be successfully addressed by shallow preprocessing methods.</citsent>
<aftsection>
<nextsent>in this section we give high-level overview of our method for transforming parsers output and describe the different steps of the process.
</nextsent>
<nextsent>in the experiments we used the parsers described in (char niak, 2000) <papid> A00-2018 </papid>and (collins, 1999).</nextsent>
<nextsent>for collins?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q262">
<title id=" P04-1040.xml">enriching the output of a parser using memory based learning </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>during further experiments with our method on different corpora, wefound that quite different settings led to better performance.
</prevsent>
<prevsent>it is clear that more careful and systematic parameter tuning and the analysis of the contribution of different features have to be addressed.finally, our method is not restricted to syntactic structures.
</prevsent>
</prevsection>
<citsent citstr=" W04-0814 ">
it has been successfully applied to the identification of semantic relations (ahn et al., 2004), <papid> W04-0814 </papid>using framenet as the training corpus.</citsent>
<aftsection>
<nextsent>for this task, we viewed semantic relations (e.g.,speaker, topic, addressee) as dependencies between predicate and its arguments.
</nextsent>
<nextsent>adding such semantic relations to syntactic dependency graphs was simply an additional graph transformation step.
</nextsent>
<nextsent>we presented method to automatically enrich the output of parser with information that is not provided by the parser itself, but is available in tree bank.
</nextsent>
<nextsent>using the method with two state of the art statistical parsers and the penn treebank allowed us to recover functional tags (grammatical and se mantic), empty nodes and traces.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q263">
<title id=" P03-2029.xml">word sense disambiguation using pairwise alignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we proposed new supervised word sense disambiguation (wsd) method based on pairwise alignment technique, which is used generally to measure similarity between dna sequences.
</prevsent>
<prevsent>the new method obtained 2.8%-14.2%improvements of the accuracy in our experiment for wsd.
</prevsent>
</prevsection>
<citsent citstr=" J98-1001 ">
wsd has been recognized as one of the most important subjects in natural language processing, especially in machine translation, information retrieval,and so on (ide and veronis, 1998).<papid> J98-1001 </papid></citsent>
<aftsection>
<nextsent>most of previous supervised methods can be classified into two major ones; approach based on association, and approach based on selectional restriction.
</nextsent>
<nextsent>the former uses some words around target word, represented by n-word window.
</nextsent>
<nextsent>the latter uses some syntactic relations, say, verb-object, including necessarily target word.
</nextsent>
<nextsent>however, there are some words that one approach gets good result for them while another gets worse, and vice versa.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q264">
<title id=" P03-2029.xml">word sense disambiguation using pairwise alignment </title>
<section> our method.  </section>
<citcontext>
<prevsection>
<prevsent>in the paths are the elements added automatically using some rules in order to make remarkable difference between verb-subject and verb object.
</prevsent>
<prevsent>we think this sequence structure of word would serve as clue to wsd very well, and we regard set of the sequences obtained from an input sentence as the context of target word.
</prevsent>
</prevsection>
<citsent citstr=" P97-1009 ">
the general intuition for wsd is that words with similar context have the same sense (charniak,1993; lin, 1997).<papid> P97-1009 </papid></citsent>
<aftsection>
<nextsent>that is, once we prepare the prototype sequences for each sense, we can determine the sense of the target word as one with the most similar prototype set.
</nextsent>
<nextsent>we measure similarity between set of prototype sequences and set of sequences from input sentence   . let and t.   have set of sequences, pt
</nextsent>
<nextsent> p1  p2  pn  and 2we assume that we can get the correct syntactic structure here.
</nextsent>
<nextsent>(see section 4) fire: go off or discharge fire, sub, person fire, obj, [weapon, rocket] fire, [on, upon, at], physical object fire, *, load, [into, with], weapon fire, *, set up, obj, weapon fire: terminate the employment fire, sub, company fire, obj, [person, people, staff] fire, from, organization fire, *, hire fire, *, job figure 1: prototype sequence for verb fire?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q265">
<title id=" P03-1050.xml">unsupervised learning of arabic stemming using a parallel corpus </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the problem of unsupervised stemming or morphology has been studied using several different approaches.
</prevsent>
<prevsent>for arabic, good results have been obtained for plural detection (clark, 2001).
</prevsent>
</prevsection>
<citsent citstr=" J01-2001 ">
(gold smith, 2001) <papid> J01-2001 </papid>used minimum description length paradigm to build linguist ica, system for which the reported accuracy for european languages is cca.83%.</citsent>
<aftsection>
<nextsent>note that the results in this section are not directly comparable to ours, since we are focusing on arabic.
</nextsent>
<nextsent>a notable contribution was published by snover (snover, 2002), who defines an objective function to be optimized and performs search for the stemmed configuration that optimizes the function over all stemming possibilities of given text.
</nextsent>
<nextsent>rule-based stemming for arabic is problem studied by many researchers; an excellent overview is provided by (larkey et al, ).morphology is not limited to prefix and suffix re moval; it can also be seen as mapping from word to an arbitrary meaning carrying token.
</nextsent>
<nextsent>using an lsi approach, (schone and jurafsky, ) obtained 88% accuracy for english.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q266">
<title id=" P03-1050.xml">unsupervised learning of arabic stemming using a parallel corpus </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for parallel corpus of comparable size with the one used in our results, the reported accuracy was 93% for french (when the english portion was also avail able); however, this result only covers 90% of the tokens.
</prevsent>
<prevsent>accuracy was later improved using suffix trees.
</prevsent>
</prevsection>
<citsent citstr=" P02-1033 ">
(diab and resnik, 2002) <papid> P02-1033 </papid>used parallel corpus for word sense disambiguation, exploiting the fact that different meanings of the same word tend to be translated into distinct words.</citsent>
<aftsection>
<nextsent>figure 1: approach overview our approach is based on the availability of the following three resources: ? small parallel corpus ? an english stemmer ? an optional unannotated arabic corpus our goal is to train an arabic stemmer using these resources.
</nextsent>
<nextsent>the resulting stemmer will simply stem arabic without needing its english equivalent.
</nextsent>
<nextsent>we divide the training into two logical steps: ? step 1: use the small parallel corpus ? step 2: (optional) use the monolingual corpus the two steps are described in detail in the following subsections.
</nextsent>
<nextsent>2.1 step 1: using the small parallel corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q267">
<title id=" P03-1050.xml">unsupervised learning of arabic stemming using a parallel corpus </title>
<section> approach.  </section>
<citcontext>
<prevsection>
<prevsent>it also constitutes surprisingly high base line.
</prevsent>
<prevsent>2.2 the translation model ?.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
we adapted model 1 (brown et al, 1993) <papid> J93-2003 </papid>to our purposes.</citsent>
<aftsection>
<nextsent>model 1 uses the concept of alignment between two sentences and in parallel corpus; the alignment is defined as an object indicating foreach word ei which word fj generated it.
</nextsent>
<nextsent>to obtain the probability of an foreign sentence given the english sentence e, model 1 sums the products ofthe translation probabilities over all possible align ments: pr(f |e) ? ?
</nextsent>
<nextsent>{a} ? j=1 t(fj|eaj ) the alignment variable ai controls which english word the foreign word fi is aligned with.
</nextsent>
<nextsent>t(f |e) is simply the translation probability which is refinediteratively using em.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q268">
<title id=" P03-1017.xml">constructing semantic space models from parsed corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper we present novel approach for constructing semantic spaces that takes syntactic relations into account.
</prevsent>
<prevsent>we introduce formalisation for this class of model sand evaluate their adequacy on two modelling tasks: semantic priming and automatic discrimination of lexical relations.
</prevsent>
</prevsection>
<citsent citstr=" W01-0514 ">
vector-based models of word co-occurrence have proved useful representational framework for variety of natural language processing (nlp) tasks such as word sense discrimination (schtze, 1998), text segmentation (choi et al, 2001), <papid> W01-0514 </papid>contextual spelling correction (jones and martin, 1997), <papid> A97-1025 </papid>automatic thesaurus extraction (grefenstette, 1994), and notably information retrieval (salton et al, 1975).</citsent>
<aftsection>
<nextsent>vector-based representations of lexical meaning have been also popular in cognitive science and figure prominently in variety of modelling studies ranging from similarity judgements (mcdonald, 2000) to semantic priming (lund and burgess, 1996; lowe and mcdonald, 2000) and text comprehension (landauer and dumais, 1997).
</nextsent>
<nextsent>in this approach semantic information is extracted from large bodies of text under the assumption thatthe context surrounding given word provides important information about its meaning.
</nextsent>
<nextsent>the semantic properties of words are represented by vectors thatare constructed from the observed distributional patterns of co-occurrence of their neighbouring words.
</nextsent>
<nextsent>co-occurrence information is typically collected infrequency matrix, where each row corresponds to unique target word and each column represents its linguistic context.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q269">
<title id=" P03-1017.xml">constructing semantic space models from parsed corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper we present novel approach for constructing semantic spaces that takes syntactic relations into account.
</prevsent>
<prevsent>we introduce formalisation for this class of model sand evaluate their adequacy on two modelling tasks: semantic priming and automatic discrimination of lexical relations.
</prevsent>
</prevsection>
<citsent citstr=" A97-1025 ">
vector-based models of word co-occurrence have proved useful representational framework for variety of natural language processing (nlp) tasks such as word sense discrimination (schtze, 1998), text segmentation (choi et al, 2001), <papid> W01-0514 </papid>contextual spelling correction (jones and martin, 1997), <papid> A97-1025 </papid>automatic thesaurus extraction (grefenstette, 1994), and notably information retrieval (salton et al, 1975).</citsent>
<aftsection>
<nextsent>vector-based representations of lexical meaning have been also popular in cognitive science and figure prominently in variety of modelling studies ranging from similarity judgements (mcdonald, 2000) to semantic priming (lund and burgess, 1996; lowe and mcdonald, 2000) and text comprehension (landauer and dumais, 1997).
</nextsent>
<nextsent>in this approach semantic information is extracted from large bodies of text under the assumption thatthe context surrounding given word provides important information about its meaning.
</nextsent>
<nextsent>the semantic properties of words are represented by vectors thatare constructed from the observed distributional patterns of co-occurrence of their neighbouring words.
</nextsent>
<nextsent>co-occurrence information is typically collected infrequency matrix, where each row corresponds to unique target word and each column represents its linguistic context.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q270">
<title id=" P03-1017.xml">constructing semantic space models from parsed corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>co-occurrence information is typically collected infrequency matrix, where each row corresponds to unique target word and each column represents its linguistic context.
</prevsent>
<prevsent>contexts are defined as small number of words surrounding the target word (lund and burgess,1996; lowe and mcdonald, 2000) or as entire paragraphs, even documents (landauer and dumais, 1997).
</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
context is typically treated as set of unordered words, although in some cases syntactic information is taken into account (lin, 1998; <papid> P98-2127 </papid>grefenstette, 1994; lee, 1999).<papid> P99-1004 </papid></citsent>
<aftsection>
<nextsent>a word can be thus viewed as point in an n-dimensional semantic space.
</nextsent>
<nextsent>the semantic similarity between words can be then mathematically computed by measuring the distance between points in the semantic space using metric such as cosine or euclidean distance.
</nextsent>
<nextsent>in the variants of vector-based models where no linguistic knowledge is used, differences among parts of speech for the same word (e.g., to drinkvs.
</nextsent>
<nextsent>a drink ) are not taken into account in the construction of the semantic space, although in some cases word lexemes are used rather than word surface forms (lowe and mcdonald, 2000; mcdonald, 2000).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q271">
<title id=" P03-1017.xml">constructing semantic space models from parsed corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>co-occurrence information is typically collected infrequency matrix, where each row corresponds to unique target word and each column represents its linguistic context.
</prevsent>
<prevsent>contexts are defined as small number of words surrounding the target word (lund and burgess,1996; lowe and mcdonald, 2000) or as entire paragraphs, even documents (landauer and dumais, 1997).
</prevsent>
</prevsection>
<citsent citstr=" P99-1004 ">
context is typically treated as set of unordered words, although in some cases syntactic information is taken into account (lin, 1998; <papid> P98-2127 </papid>grefenstette, 1994; lee, 1999).<papid> P99-1004 </papid></citsent>
<aftsection>
<nextsent>a word can be thus viewed as point in an n-dimensional semantic space.
</nextsent>
<nextsent>the semantic similarity between words can be then mathematically computed by measuring the distance between points in the semantic space using metric such as cosine or euclidean distance.
</nextsent>
<nextsent>in the variants of vector-based models where no linguistic knowledge is used, differences among parts of speech for the same word (e.g., to drinkvs.
</nextsent>
<nextsent>a drink ) are not taken into account in the construction of the semantic space, although in some cases word lexemes are used rather than word surface forms (lowe and mcdonald, 2000; mcdonald, 2000).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q274">
<title id=" P03-1017.xml">constructing semantic space models from parsed corpora </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>i x2i ? y2i skew divergence s?(~x,~y) = xi log xixi+(1??)yi figure 2: distance measures the dependency-based semantic space was constructed with the word-based path equivalence function from section 2.3.
</prevsent>
<prevsent>as basis elements for our semantic space the 1000 most frequent words in thebnc were used.
</prevsent>
</prevsection>
<citsent citstr=" J93-1003 ">
each element of the resulting vector was replaced with its log-likelihood value (seedefinition 10 in section 2.3) which can be considered as an estimate of how surprising or distinctive co-occurrence pair is (dunning, 1993).<papid> J93-1003 </papid>we experimented with variety of distance measures such as cosine, euclidean distance, l1 norm, jac cards coefficient, kullback-leibler divergence and the skew divergence (see lee 1999 <papid> P99-1004 </papid>for anoverview).</citsent>
<aftsection>
<nextsent>we obtained the best results for cosine (experiment 1) and skew divergence (experi ment 2).
</nextsent>
<nextsent>the two measures are shown in figure 2.
</nextsent>
<nextsent>the skew divergence represents generalisation of the kullback-leibler divergence and was proposed by lee (1999) <papid> P99-1004 </papid>as linguistically motivated distance measure.</nextsent>
<nextsent>we use value of ? = .99.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q279">
<title id=" P04-1031.xml">balancing clarity and efficiency in typed feature logic through delaying </title>
<section> modularity: the cost in clarity.  </section>
<citcontext>
<prevsection>
<prevsent>arg2 : ? arg3 : l. append rec =?
</prevsent>
<prevsent>arg1 : [h |l1] ? arg2 : l2 ? arg3 : [h |l3] ? junk : (append ? a1 : l1 ? a2 : l2 ? arg3 : l3).figure 2: implementing sld resolution over the append relation as sort resolution.ample, we can perform proof resolution by attempting to sort resolve every tfs to maximally specific type.
</prevsent>
</prevsection>
<citsent citstr=" P01-1054 ">
this is actually consistent with hpsgs use of feature logic, although most tfs-based nlp systems do not sort resolve because type inference under sort resolution is np-complete (penn, 2001).<papid> P01-1054 </papid></citsent>
<aftsection>
<nextsent>phrase structure rules, on the other hand, while they can be encoded inside logic programming relation, are more naturally viewed as algebraic generators.
</nextsent>
<nextsent>in this respect, they are more similar to the immediate sub typing declarations that grammar writers use to specify type signatures ? both chart parsing and transitive closure are instances of all source shortest-path problems on the same kind of algebraic structure, called closed semi-ring.
</nextsent>
<nextsent>the only notion of modularity ever proven to hold of phrase structure rule systems (wintner, 2002), furthermore, is an algebraic one.
</nextsent>
<nextsent>functionality if relations are used in the absence of recursive data structures, grammar could be specified using relations, and the relations could then be unfolded off line into relation-free descriptions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q283">
<title id=" P01-1049.xml">building semantic perceptron net for topic spotting </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>most of these methods are word-based and consider only the relationships between the features and topics, but not the relationships among features.
</prevsent>
<prevsent>it is well known that the performance of the word-based methods is greatly affected by the lack of linguistic understanding, and, in particular, the inability to handle synonymy and polysemy.
</prevsent>
</prevsection>
<citsent citstr=" J98-1003 ">
a number of simple linguistic techniques has been developed to alleviate such problems, ranging from the use of stemming, lexical chain and thesaurus (jing &amp; tzoukermann, 1999; green, 1999), to word-sense disambiguation (chen &amp; chang, 1998; <papid> J98-1003 </papid>leacock et al 1998; <papid> J98-1006 </papid>ide &amp; veronis, 1998) <papid> J98-1001 </papid>and context (cohen &amp; singer, 1999; jing &amp; tzoukermann, 1999).</citsent>
<aftsection>
<nextsent>the connection ist approach has been widely used to extract knowledge in wide range of information processing tasks including natural language processing, information retrieval and image understanding (anderson, 1983; lee &amp; dubin, 1999; sarkas &amp; boyer, 1995; wang &amp; terman, 1995).
</nextsent>
<nextsent>because the connection ist approach closely resembling human cognition process in text processing, it seems natural to adopt this approach, in conjunction with linguistic analysis, to perform topic spotting.
</nextsent>
<nextsent>however, there have been few attempts in this direction.
</nextsent>
<nextsent>this is mainly because of difficulties in automatically constructing the semantic networks for the topics.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q284">
<title id=" P01-1049.xml">building semantic perceptron net for topic spotting </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>most of these methods are word-based and consider only the relationships between the features and topics, but not the relationships among features.
</prevsent>
<prevsent>it is well known that the performance of the word-based methods is greatly affected by the lack of linguistic understanding, and, in particular, the inability to handle synonymy and polysemy.
</prevsent>
</prevsection>
<citsent citstr=" J98-1006 ">
a number of simple linguistic techniques has been developed to alleviate such problems, ranging from the use of stemming, lexical chain and thesaurus (jing &amp; tzoukermann, 1999; green, 1999), to word-sense disambiguation (chen &amp; chang, 1998; <papid> J98-1003 </papid>leacock et al 1998; <papid> J98-1006 </papid>ide &amp; veronis, 1998) <papid> J98-1001 </papid>and context (cohen &amp; singer, 1999; jing &amp; tzoukermann, 1999).</citsent>
<aftsection>
<nextsent>the connection ist approach has been widely used to extract knowledge in wide range of information processing tasks including natural language processing, information retrieval and image understanding (anderson, 1983; lee &amp; dubin, 1999; sarkas &amp; boyer, 1995; wang &amp; terman, 1995).
</nextsent>
<nextsent>because the connection ist approach closely resembling human cognition process in text processing, it seems natural to adopt this approach, in conjunction with linguistic analysis, to perform topic spotting.
</nextsent>
<nextsent>however, there have been few attempts in this direction.
</nextsent>
<nextsent>this is mainly because of difficulties in automatically constructing the semantic networks for the topics.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q285">
<title id=" P01-1049.xml">building semantic perceptron net for topic spotting </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>most of these methods are word-based and consider only the relationships between the features and topics, but not the relationships among features.
</prevsent>
<prevsent>it is well known that the performance of the word-based methods is greatly affected by the lack of linguistic understanding, and, in particular, the inability to handle synonymy and polysemy.
</prevsent>
</prevsection>
<citsent citstr=" J98-1001 ">
a number of simple linguistic techniques has been developed to alleviate such problems, ranging from the use of stemming, lexical chain and thesaurus (jing &amp; tzoukermann, 1999; green, 1999), to word-sense disambiguation (chen &amp; chang, 1998; <papid> J98-1003 </papid>leacock et al 1998; <papid> J98-1006 </papid>ide &amp; veronis, 1998) <papid> J98-1001 </papid>and context (cohen &amp; singer, 1999; jing &amp; tzoukermann, 1999).</citsent>
<aftsection>
<nextsent>the connection ist approach has been widely used to extract knowledge in wide range of information processing tasks including natural language processing, information retrieval and image understanding (anderson, 1983; lee &amp; dubin, 1999; sarkas &amp; boyer, 1995; wang &amp; terman, 1995).
</nextsent>
<nextsent>because the connection ist approach closely resembling human cognition process in text processing, it seems natural to adopt this approach, in conjunction with linguistic analysis, to perform topic spotting.
</nextsent>
<nextsent>however, there have been few attempts in this direction.
</nextsent>
<nextsent>this is mainly because of difficulties in automatically constructing the semantic networks for the topics.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q286">
<title id=" P01-1049.xml">building semantic perceptron net for topic spotting </title>
<section> semantic correlations.  </section>
<citcontext>
<prevsection>
<prevsent>b) the same word, such as water?, may appear in both the context node and the basic semantic node.
</prevsent>
<prevsent>c) some words use context to resolve their meanings, while many do not need context.
</prevsent>
</prevsection>
<citsent citstr=" P99-1004 ">
although there exists many methods to derive the semantic correlations between words (lee, 1999; <papid> P99-1004 </papid>lin, 1998; <papid> P98-2127 </papid>karov &amp; edelman, 1998; <papid> J98-1002 </papid>resnik, 1995; dagan et al 1995), we adopt relatively simple and yet practical and effective approach to derive three topic -oriented semantic correlations: thesaurus-based, co-occurrence-based and context based correlation.</citsent>
<aftsection>
<nextsent>3.1 thesaurus based correlation.
</nextsent>
<nextsent>wordnet is an electronic thesaurus popularly used in many researches on lexical semantic acquisition, and word sense disambiguation (green, 1999; leacock et al 1998).<papid> J98-1006 </papid></nextsent>
<nextsent>in wordnet, the sense of word is represented by list of synonyms (synset), and the lexical information is represented in the form of semantic network.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q287">
<title id=" P01-1049.xml">building semantic perceptron net for topic spotting </title>
<section> semantic correlations.  </section>
<citcontext>
<prevsection>
<prevsent>b) the same word, such as water?, may appear in both the context node and the basic semantic node.
</prevsent>
<prevsent>c) some words use context to resolve their meanings, while many do not need context.
</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
although there exists many methods to derive the semantic correlations between words (lee, 1999; <papid> P99-1004 </papid>lin, 1998; <papid> P98-2127 </papid>karov &amp; edelman, 1998; <papid> J98-1002 </papid>resnik, 1995; dagan et al 1995), we adopt relatively simple and yet practical and effective approach to derive three topic -oriented semantic correlations: thesaurus-based, co-occurrence-based and context based correlation.</citsent>
<aftsection>
<nextsent>3.1 thesaurus based correlation.
</nextsent>
<nextsent>wordnet is an electronic thesaurus popularly used in many researches on lexical semantic acquisition, and word sense disambiguation (green, 1999; leacock et al 1998).<papid> J98-1006 </papid></nextsent>
<nextsent>in wordnet, the sense of word is represented by list of synonyms (synset), and the lexical information is represented in the form of semantic network.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q288">
<title id=" P01-1049.xml">building semantic perceptron net for topic spotting </title>
<section> semantic correlations.  </section>
<citcontext>
<prevsection>
<prevsent>b) the same word, such as water?, may appear in both the context node and the basic semantic node.
</prevsent>
<prevsent>c) some words use context to resolve their meanings, while many do not need context.
</prevsent>
</prevsection>
<citsent citstr=" J98-1002 ">
although there exists many methods to derive the semantic correlations between words (lee, 1999; <papid> P99-1004 </papid>lin, 1998; <papid> P98-2127 </papid>karov &amp; edelman, 1998; <papid> J98-1002 </papid>resnik, 1995; dagan et al 1995), we adopt relatively simple and yet practical and effective approach to derive three topic -oriented semantic correlations: thesaurus-based, co-occurrence-based and context based correlation.</citsent>
<aftsection>
<nextsent>3.1 thesaurus based correlation.
</nextsent>
<nextsent>wordnet is an electronic thesaurus popularly used in many researches on lexical semantic acquisition, and word sense disambiguation (green, 1999; leacock et al 1998).<papid> J98-1006 </papid></nextsent>
<nextsent>in wordnet, the sense of word is represented by list of synonyms (synset), and the lexical information is represented in the form of semantic network.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q290">
<title id=" P01-1049.xml">building semantic perceptron net for topic spotting </title>
<section> semantic groups &amp; topic tree.  </section>
<citcontext>
<prevsection>
<prevsent>and corp? are context-related words within the topic acq?.
</prevsent>
<prevsent>this is because they have very similar context of say, header, acquire, contract?.
</prevsent>
</prevsection>
<citsent citstr=" P93-1024 ">
there are many methods that attempt to construct the conceptual representation of topic from the original dataset (veling &amp; vander weerd, 1999; baker &amp; mccallum, 1998; pereira et al 1993).<papid> P93-1024 </papid></citsent>
<aftsection>
<nextsent>in this section, we will describe our semantic -based approach to finding basic semantic groups and constructing the topic tree.
</nextsent>
<nextsent>given set of training documents, the stages involved in finding the semantic groups for each topic are given below.
</nextsent>
<nextsent>a) extract all distinct terms {t1, t2, ..tn} from the training document set for topic ti.
</nextsent>
<nextsent>for each term tj, compute its df(i)(tj) and cv(i)(t j), where df(i)(tj) is defined as the fraction of documents in i that contain tj.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q291">
<title id=" P04-1047.xml">largescale induction and evaluation of lexical resources from the pennii treebank </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>subj)(?
</prevsent>
<prevsent>oblon)?).
</prevsent>
</prevsection>
<citsent citstr=" P04-1041 ">
our approach isbased on earlier work on lfg semantic form extraction (van genabith et al, 1999) and recent progress in automatically annotating the penn-ii treebank with lfg f-structures (cahill et al, 2004<papid> P04-1041 </papid>b).</citsent>
<aftsection>
<nextsent>depending on the quality of the f-structures, reliable lfg semantic forms can then be generated quite simply by recursively reading off the subcategoris able grammatical functions for each local pred value at each level of embedding in the f-structures.
</nextsent>
<nextsent>the work reported in (van genabith et al, 1999) was small scale (100 trees), proof of concept and required considerable manual annotation work.
</nextsent>
<nextsent>in this paper we show how the extraction process can be scaled to the complete wall street journal (wsj)section of the penn-ii treebank, with about 1 million words in 50,000 sentences, based on the automatic lfg f-structure annotation algorithm described in (cahill et al, 2004<papid> P04-1041 </papid>b).</nextsent>
<nextsent>in addition to extracting grammatical function-based subcategorisation frames, we also include the syntactic categories of the predicate and its sub categorised arguments, as well as additional details such as the prepositions required by obliques, and particles accompanying particle verbs.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q303">
<title id=" P04-1047.xml">largescale induction and evaluation of lexical resources from the pennii treebank </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our methodology and its implementation are presented in section 3.
</prevsent>
<prevsent>section 4 presents the results of our lexical extraction.
</prevsent>
</prevsection>
<citsent citstr=" H94-1003 ">
in section 5 we evaluate the complete extracted lexicon against the comlexresource (macleod et al, 1994).<papid> H94-1003 </papid></citsent>
<aftsection>
<nextsent>to our knowledge, this is the largest evaluation of subcategorisation frames for english.
</nextsent>
<nextsent>in section 6, we conclude and give suggestions for future work.
</nextsent>
<nextsent>creating (subcategorisation) lexicon by hand is time-consuming, error-prone, requires considerable linguistic expertise and is rarely, if ever, complete.in addition, system incorporating manually constructed lexicon cannot easily be adapted to specificdomains.
</nextsent>
<nextsent>accordingly, many researchers have attempted to construct lexicons automatically, especially for english.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q305">
<title id=" P04-1047.xml">largescale induction and evaluation of lexical resources from the pennii treebank </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>creating (subcategorisation) lexicon by hand is time-consuming, error-prone, requires considerable linguistic expertise and is rarely, if ever, complete.in addition, system incorporating manually constructed lexicon cannot easily be adapted to specificdomains.
</prevsent>
<prevsent>accordingly, many researchers have attempted to construct lexicons automatically, especially for english.
</prevsent>
</prevsection>
<citsent citstr=" J93-2002 ">
(brent, 1993) <papid> J93-2002 </papid>relies on local morphosyntactic cues (such as the -ing suffix, except where such word follows determiner or preposition other than to) in the untagged brown corpus as probabilistic indicators of six different predefined subcategorisation frames.</citsent>
<aftsection>
<nextsent>the frames do not include details of specific prepositions.
</nextsent>
<nextsent>(manning, 1993) <papid> P93-1032 </papid>observes that brents recognition technique is rather simplistic and inadequate approach to verb detection, with very high error rate?.</nextsent>
<nextsent>manning feeds the output from stochastic tagger into finite state parser, and applies statistical filtering to the parsing results.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q306">
<title id=" P04-1047.xml">largescale induction and evaluation of lexical resources from the pennii treebank </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>(brent, 1993) <papid> J93-2002 </papid>relies on local morphosyntactic cues (such as the -ing suffix, except where such word follows determiner or preposition other than to) in the untagged brown corpus as probabilistic indicators of six different predefined subcategorisation frames.</prevsent>
<prevsent>the frames do not include details of specific prepositions.</prevsent>
</prevsection>
<citsent citstr=" P93-1032 ">
(manning, 1993) <papid> P93-1032 </papid>observes that brents recognition technique is rather simplistic and inadequate approach to verb detection, with very high error rate?.</citsent>
<aftsection>
<nextsent>manning feeds the output from stochastic tagger into finite state parser, and applies statistical filtering to the parsing results.
</nextsent>
<nextsent>he pre defines 19 different subcategorisation frames, including details of prepositions.
</nextsent>
<nextsent>applying this technique to approx.
</nextsent>
<nextsent>4 million words of newyork times newswire, manning acquires 4900 subcategorisation frames for 3104 verbs, an average of 1.6 per verb.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q308">
<title id=" P04-1047.xml">largescale induction and evaluation of lexical resources from the pennii treebank </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>applying this technique to approx.
</prevsent>
<prevsent>4 million words of newyork times newswire, manning acquires 4900 subcategorisation frames for 3104 verbs, an average of 1.6 per verb.
</prevsent>
</prevsection>
<citsent citstr=" W93-0109 ">
(ushioda et al, 1993) <papid> W93-0109 </papid>run finite state np parser on pos-tagged corpus to calculate the relative frequency of just six subcategorisation verb classes.</citsent>
<aftsection>
<nextsent>in addition, all prepositional phrases are treated as adjuncts.
</nextsent>
<nextsent>for 1565 tokens of 33 selected verbs, they report an accuracy rate of 83%.
</nextsent>
<nextsent>(briscoe and carroll, 1997) <papid> A97-1052 </papid>observe that in thework of (brent, 1993), (<papid> J93-2002 </papid>manning, 1993) <papid> P93-1032 </papid>and (ush ioda et al, 1993), <papid> W93-0109 </papid>the maximum number of distinct subcategorization classes recognized is sixteen, andonly ushioda et al attempt to derive relative subcategorization frequency for individual predicates?.</nextsent>
<nextsent>in contrast, the system of (briscoe and carroll, 1997) <papid> A97-1052 </papid>distinguishes 163 verbal subcategorisation classes by means of statistical shallow parser, classifier of subcategorisation classes, and priori estimates of the probability that any verb will be member of those classes.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q309">
<title id=" P04-1047.xml">largescale induction and evaluation of lexical resources from the pennii treebank </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in addition, all prepositional phrases are treated as adjuncts.
</prevsent>
<prevsent>for 1565 tokens of 33 selected verbs, they report an accuracy rate of 83%.
</prevsent>
</prevsection>
<citsent citstr=" A97-1052 ">
(briscoe and carroll, 1997) <papid> A97-1052 </papid>observe that in thework of (brent, 1993), (<papid> J93-2002 </papid>manning, 1993) <papid> P93-1032 </papid>and (ush ioda et al, 1993), <papid> W93-0109 </papid>the maximum number of distinct subcategorization classes recognized is sixteen, andonly ushioda et al attempt to derive relative subcategorization frequency for individual predicates?.</citsent>
<aftsection>
<nextsent>in contrast, the system of (briscoe and carroll, 1997) <papid> A97-1052 </papid>distinguishes 163 verbal subcategorisation classes by means of statistical shallow parser, classifier of subcategorisation classes, and priori estimates of the probability that any verb will be member of those classes.</nextsent>
<nextsent>more recent work by korhonen (2002) on the filtering phase of this approach has improved results.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q317">
<title id=" P04-1047.xml">largescale induction and evaluation of lexical resources from the pennii treebank </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>arguments were then mapped to traditional syntactic functions.
</prevsent>
<prevsent>as they do not include an evaluation, currently it is impossible to say how effective this technique is.
</prevsent>
</prevsection>
<citsent citstr=" W00-1307 ">
(xia et al, 2000) <papid> W00-1307 </papid>and (chen and vijay-shanker,2000) extract lexicalised tags from the penn tree bank.</citsent>
<aftsection>
<nextsent>both techniques implement variations on the approaches of (magerman, 1994) and (collins, 1997) <papid> P97-1003 </papid>for the purpose of differentiating between complement and adjunct.</nextsent>
<nextsent>in the case of (xia et al, 2000), <papid> W00-1307 </papid>invalid elementary trees produced as result of annotation errors in the treebank are filtered out using linguistic heuristics.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q318">
<title id=" P04-1047.xml">largescale induction and evaluation of lexical resources from the pennii treebank </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>as they do not include an evaluation, currently it is impossible to say how effective this technique is.
</prevsent>
<prevsent>(xia et al, 2000) <papid> W00-1307 </papid>and (chen and vijay-shanker,2000) extract lexicalised tags from the penn tree bank.</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
both techniques implement variations on the approaches of (magerman, 1994) and (collins, 1997) <papid> P97-1003 </papid>for the purpose of differentiating between complement and adjunct.</citsent>
<aftsection>
<nextsent>in the case of (xia et al, 2000), <papid> W00-1307 </papid>invalid elementary trees produced as result of annotation errors in the treebank are filtered out using linguistic heuristics.</nextsent>
<nextsent>(hockenmaier et al, 2002) outline method for the automatic extraction of large syntactic ccg lexicon from penn-ii.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q343">
<title id=" P04-1047.xml">largescale induction and evaluation of lexical resources from the pennii treebank </title>
<section> comlex evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>5.2 lexical accession rates.
</prevsent>
<prevsent>as well as evaluating the quality of our extracted semantic forms, we also examine the rate at which they are induced.
</prevsent>
</prevsection>
<citsent citstr=" P98-1115 ">
(charniak, 1996) and (krotov et al., 1998) <papid> P98-1115 </papid>observed that treebank grammars (cfgs extracted from treebanks) are very large and grow with the size of the treebank.</citsent>
<aftsection>
<nextsent>we were interested in discovering whether the acquisition of lexical material on the same data displays similar propensity.figure 3 displays the accession rates for the semantic forms induced by our method for sections 024 of the wsj section of the penn-ii treebank.
</nextsent>
<nextsent>when we do not distinguish semantic forms by category,all semantic forms together with those for verbs display smaller accession rates than for the pcfg.
</nextsent>
<nextsent>we also examined the coverage of our system ina similar way to (hockenmaier et al, 2002).
</nextsent>
<nextsent>we extracted verb-only reference lexicon from sections 02-21 of the wsj and subsequently compared this to test lexicon constructed in the same way from 0 5000 10000 15000 20000 25000 0 5 10 15 20 25 o. f fs /r ul es wsj section all sf frames all verbs all sf frames, no category all verbs, no category pcfg figure 3: accession rates for semantic forms and cfg rules entries also in reference lexicon: 89.89% entries not in reference lexicon: 10.11% known words: 7.85% - known words, known frames: 7.85%- known words, unknown frames: unknown words: 2.32% - unknown words, known frames: 2.32%- unknown words, unknown frames: table 8: coverage of induced lexicon on unseen data (verbs only)section 23.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q350">
<title id=" P04-1044.xml">combining acoustic and pragmatic features to predict recognition performance in spoken dialogue systems </title>
<section> relation to previous work.  </section>
<citcontext>
<prevsection>
<prevsent>after short relation to previous work, section 3 introduces the witas multimodal dialogue system, which we useto collect data (section 4) and to derive baseline results (section 5).
</prevsent>
<prevsent>section 6 describes our learning experiments for classifying and selecting from best recognition hypotheses and section 7 reports our results.
</prevsent>
</prevsection>
<citsent citstr=" A00-2029 ">
(litman et al, 2000) <papid> A00-2029 </papid>use acoustic-prosodic information extracted from speech waveforms, together with information derived from their speech recognizer, to automatically predict mis recognized turns in corpus of train-timetable information dialogues.in our experiments, we also use recognizer confidence scores and limited number of acoustic prosodic features (e.g. amplitude in the speech sig nal) for hypothesis classification.</citsent>
<aftsection>
<nextsent>(walker et al, 2000) use combination of features from the speech recognizer, natural language understanding, and dialogue manager/discourse history to classify hypotheses as correct, partially correct, or misrecog nized.
</nextsent>
<nextsent>our work is related to these experiments inthat we also combine confidence scores and higher level features for classification.
</nextsent>
<nextsent>however, both (litman et al, 2000) <papid> A00-2029 </papid>and (walker et al, 2000) consider only single-best recognition results and thus use their classifiers as filters?</nextsent>
<nextsent>to decide whether the best recognition hypothesis for user utterance is correct or not.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q354">
<title id=" P04-1044.xml">combining acoustic and pragmatic features to predict recognition performance in spoken dialogue systems </title>
<section> the witas dialogue system.  </section>
<citcontext>
<prevsection>
<prevsent>the human operator is provided with gui ? an interactive (i.e. mouse clickable) map ? and specifies mission goals using natural language commands spoken into headset, or by using combinations of gui actions and spokencommands.
</prevsent>
<prevsent>the simulated uav can carry out different activities such as flying to locations, following vehicles, and delivering objects.
</prevsent>
</prevsection>
<citsent citstr=" P93-1008 ">
the dialogue system uses the nuance 8.0 speech recognizer with language models compiled from grammar (written using the gemini system (dowding et al, 1993)), <papid> P93-1008 </papid>which is also used for parsing and generation.</citsent>
<aftsection>
<nextsent>3.1 witas information states.
</nextsent>
<nextsent>the witas dialogue system is part of larger family of systems that implement the information state update (isu) approach to dialogue management (traum et al, 1999).
</nextsent>
<nextsent>the isu approach hasbeen used to formalize different theories of dialogue and forms the basis of several dialogue system implementations in domains such as route planning, home automation, and tutorial dialogue.
</nextsent>
<nextsent>the isu approach is particularly useful testbed forour technique because it collects information relevant to dialogue context in central data structure from which it can be easily extracted.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q355">
<title id=" P04-1044.xml">combining acoustic and pragmatic features to predict recognition performance in spoken dialogue systems </title>
<section> classifying and selecting n-best.  </section>
<citcontext>
<prevsection>
<prevsent>wer as an indicator for whether hypotheses should be 3the witas dialogue system currently does not support this type of clarification dialogue; the wer annotations are therefore only of theoretical interest.
</prevsent>
<prevsent>however, an extended system could easily use this information to decide when clarification should be initiated.clarified or rejected.
</prevsent>
</prevsection>
<citsent citstr=" P03-2004 ">
this is adopted from (gabs dil, 2003), <papid> P03-2004 </papid>based on the fact that wer correlates with concept accuracy (ca, (boros et al, 1996)).</citsent>
<aftsection>
<nextsent>the wer threshold can be set differently according to the needs of an application.
</nextsent>
<nextsent>however, one would ideally set threshold directly on ca scores for this labeling, but these are currently not available for our data.we also introduce the distinction between out-of grammar (wer ? 50) and out-of-grammar (wer   50) in the gold standard for the classification of (whole) user utterances.
</nextsent>
<nextsent>we split the out-of grammar class into two sub-classes depending on whether the 10-best recognition results include at least one hypothesis with wer ? 50 compared to the corresponding transcription.
</nextsent>
<nextsent>thus, if there isa recognition hypothesis which is close to the transcription, an utterance is labeled as oog (wer 50).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q357">
<title id=" P04-1044.xml">combining acoustic and pragmatic features to predict recognition performance in spoken dialogue systems </title>
<section> results and evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>7.1 optimizing timbl parameters.
</prevsent>
<prevsent>in all of the above experiments we ran the machine learners with their default parameter settings.
</prevsent>
</prevsection>
<citsent citstr=" P03-1062 ">
however, recent research (daelemans and hoste, 2002; marsi et al, 2003) <papid> P03-1062 </papid>has shown that machine learners often profit from parameter optimization (i.e. finding the best performing parameters on some development data).</citsent>
<aftsection>
<nextsent>we therefore selected 40 possible parameter combinations for timbl (varying the number of nearest neighbors, feature weighting, and class voting weights) and nested aparameter optimization step into the leave-one out?
</nextsent>
<nextsent>evaluation paradigm (cf.
</nextsent>
<nextsent>figure 2).5note that our optimization method is not as sophisticated as the iterative deepening?
</nextsent>
<nextsent>approach5we only optimized parameters for timbl because it performed better with default settings than ripper and because the findings in (daelemans and hoste, 2002) indicate that timbl profits more from parameter optimization.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q361">
<title id=" P00-1039.xml">an algorithm for onepage summarization of a long text based on thematic hierarchy detection </title>
<section> problems in one-page.  </section>
<citcontext>
<prevsection>
<prevsent>moreover, the logical structure of text does not always correspond to its thematic hierarchy, especially if section consists of an overview clause followed by other clauses that can be divided into several groups by their subtopics.
</prevsent>
<prevsent>since then, based on hearst work (1994),an algorithm for detecting the thematic hierarchy of text using only lexical cohesion (haliday and hasan, 1976) measured by term repetitions was developed (nakao, 1999).
</prevsent>
</prevsection>
<citsent citstr=" W98-0204 ">
in comparison with some alternatives (salton et al., 1996; yaari, 1998), <papid> W98-0204 </papid>one of the features of the algorithm is that it can decompose atext into thematic textual units of approximately the same size, ranging from units just smaller than the entire text to units of abou tone paragraph.</citsent>
<aftsection>
<nextsent>in this paper, summarization algorithm based on this feature is pro posed.the second problem is related to the textual coherence of one-page summary itself.
</nextsent>
<nextsent>a three-sentence extract of large text, which the proposed algorithm is designed to generate for an appropriate grading topic, tend to form collection of unrelated sentences if it is generated by simple extraction of important sentences.
</nextsent>
<nextsent>furthermore, the summary should provides new information to reader, so an introduction is necessary to help reader understand it.
</nextsent>
<nextsent>figure 4 shows summary example of technical survey report consisting ofone hundred thousand characters.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q365">
<title id=" P04-1054.xml">dependency tree kernels for relation extraction </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>our contributions are richer sentence representation, more general framework to allow feature weighting, as well as the use of composite kernels to reduce kernel sparsity.
</prevsent>
<prevsent>brin (1998) and agichtein and gravano (2000) apply pattern matching and wrapper techniques for relation extraction, but these approaches do not scale well to fastly evolving corpora.
</prevsent>
</prevsection>
<citsent citstr=" A00-2030 ">
miller et al(2000) <papid> A00-2030 </papid>propose an integrated statistical parsing technique that augments parse trees with semantic labels denoting entity and relation types.</citsent>
<aftsection>
<nextsent>whereas miller et al (2000) <papid> A00-2030 </papid>use generative model to produce parse information as well as relation information, we hypothesize that technique discriminatively trained to classify relations will achieve better performance.</nextsent>
<nextsent>also, roth and yih (2002) <papid> C02-1151 </papid>learn bayesian network to tag entities and their relationssimultaneously.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q367">
<title id=" P04-1054.xml">dependency tree kernels for relation extraction </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>miller et al(2000) <papid> A00-2030 </papid>propose an integrated statistical parsing technique that augments parse trees with semantic labels denoting entity and relation types.</prevsent>
<prevsent>whereas miller et al (2000) <papid> A00-2030 </papid>use generative model to produce parse information as well as relation information, we hypothesize that technique discriminatively trained to classify relations will achieve better performance.</prevsent>
</prevsection>
<citsent citstr=" C02-1151 ">
also, roth and yih (2002) <papid> C02-1151 </papid>learn bayesian network to tag entities and their relationssimultaneously.</citsent>
<aftsection>
<nextsent>we experiment with more challenging set of relation types and larger corpus.
</nextsent>
<nextsent>in traditional machine learning, we are provided set of training instances = {x1 . . .
</nextsent>
<nextsent>xn},where each instance xi is represented by some dimensional feature vector.
</nextsent>
<nextsent>much time is spent on the task of feature engineering ? searching for the optimal feature set either manually by consulting domain experts or automatically through feature induction and selection (scott and matwin, 1999).for example, in entity detection the original instance representation is generally word vector corresponding to sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q368">
<title id=" P01-1028.xml">generating with a grammar based on tree descriptions a constraint based approach </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>how can we design model generators which work efficiently on natural language input i.e. on the type of information delivered by logic based grammars?
</prevsent>
<prevsent>(duchier and gardent, 1999) shows that constraint programming can be used to implement model generator for tree logic (back ofen et al, 1995).
</prevsent>
</prevsection>
<citsent citstr=" P95-1021 ">
further, (duchier and thater, 1999) shows that this model generator can be usedto parse with descriptions based grammars (ram bow et al, 1995; <papid> P95-1021 </papid>kallmeyer, 1999) that is, on logic based grammars where lexical entries are descriptions of trees expressed in some tree logic.</citsent>
<aftsection>
<nextsent>in this paper, we build on (duchier and thater,1999) and show that modulo some minor modifications, the same model generator can be used to generate with description based grammars.
</nextsent>
<nextsent>we describe the workings of the algorithm and compare it with standard existing top-down and bottom-up generation algorithms.
</nextsent>
<nextsent>in specific, we argue that the change of perspective offered bythe constraint-based, axiomatic approach to processing presents some interesting differences with the more traditional generative approach usually pursued in tactical generation and further, that the combination of this static view with tag-like grammar and flat semantics results in system which combines the positive aspects of both top down and bottom-up generators.the paper is structured as follows.
</nextsent>
<nextsent>section 2 presents the grammars we are working with namely, description grammars (dg), section 3 summarises the parsing model presented in (duchier and thater, 1999) and section 4 shows that this model can be extended to generate with dgs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q370">
<title id=" P01-1028.xml">generating with a grammar based on tree descriptions a constraint based approach </title>
<section> description grammars.  </section>
<citcontext>
<prevsection>
<prevsent>in section 5, we compare our generator with top-down and bottom-up generators, section 6 reports on proof-of-concept implementation and section 7 concludes with pointers for further research.
</prevsent>
<prevsent>there is range of grammar formalisms which depart from tree adjoining grammar (tag) by taking as basic building blocks tree descriptions rather than trees.
</prevsent>
</prevsection>
<citsent citstr=" C00-2087 ">
d-tree grammar (dtg) is proposed in (rambow et al, 1995) <papid> P95-1021 </papid>to remedy some empirical and theoretical shortcomings of tag; tree description grammar (tdg) is introduced in (kallmeyer, 1999) to support syntactic and semantic under specification and interaction grammar is presented in (perrier, 2000) <papid> C00-2087 </papid>as an alternative way of formulating linear logic grammars.like all these frameworks, dg uses tree descriptions and thereby benefits first, from the extended domain of locality which makes tag particularly suitable for generation (cf.</citsent>
<aftsection>
<nextsent>(joshi, 1987))and second, from the monotonicity which differentiates descriptions from trees with respect to adjunction (cf.
</nextsent>
<nextsent>(vijay-shanker, 1992)).
</nextsent>
<nextsent>dg differs from dtg and tdg however inthat it adopts an axiomatic rather than generative view of grammar: whereas in dtg and tdg, derived trees are constructed through sequence of rewriting steps, in dg derived trees are models satisfying conjunction of elementary tree descriptions.
</nextsent>
<nextsent>moreover, dg differs from interaction grammars in that it uses flat rather than montague style recursive semantics thereby permitting simple syntax/semantics interface (see below).a description grammar is set of lexical entries of the form
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q371">
<title id=" P01-1028.xml">generating with a grammar based on tree descriptions a constraint based approach </title>
<section> description grammars.  </section>
<citcontext>
<prevsection>
<prevsent>this guarantees that in saturated model, tree fragments that belong to the denota tion of distinct tree descriptions do not overlap.second, we require that every lexical tree description has single minimal free model, which essentially means that the lexical descriptions must be tree shaped.
</prevsent>
<prevsent>semantic representation.
</prevsent>
</prevsection>
<citsent citstr=" P97-1026 ">
following (stone and doran, 1997), <papid> P97-1026 </papid>we represent meaning using flat semantic representation, i.e. as multi sets, or conjunctions, of non-recursive propositions.</citsent>
<aftsection>
<nextsent>this treatment offers simple syntax-semantics interface in that the meaning of tree is just the conjunction of meanings of the lexical tree descriptions used to derive it once the free variables occurring in the propositions are instantiated.
</nextsent>
<nextsent>a free variable is instantiated as follows: each free variable labels syntactic node variable ? and is unified with the label of any node variable identified with ? .
</nextsent>
<nextsent>for the purpose of this paper, simple semantic representation language is adopted whichin particular, does not include handles?
</nextsent>
<nextsent>i.e. labels on propositions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q372">
<title id=" P01-1028.xml">generating with a grammar based on tree descriptions a constraint based approach </title>
<section> generating with dg.  </section>
<citcontext>
<prevsection>
<prevsent>or infiniti val to?
</prevsent>
<prevsent>whose semantic contribution is void.
</prevsent>
</prevsection>
<citsent citstr=" C88-2128 ">
as (shieber, 1988) <papid> C88-2128 </papid>showed, the problem with such words is that they cannot be selected on the basis of the input semantics.</citsent>
<aftsection>
<nextsent>to circumvent this problem, we take advantage of the tag extended domain of locality to avoid having such entries in the grammar.
</nextsent>
<nextsent>for instance,complementizer that?
</nextsent>
<nextsent>does not anchor tree description by itself but occurs in all lexical tree descriptions providing an appropriate syntactic context for it, e.g. in the tree description for say?.
</nextsent>
<nextsent>multiple propositions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q373">
<title id=" P01-1028.xml">generating with a grammar based on tree descriptions a constraint based approach </title>
<section> comparison with related work.  </section>
<citcontext>
<prevsection>
<prevsent>no other solution is found as for any other conjunction of descriptions made available by the matrix, no saturated model exists.
</prevsent>
<prevsent>our generator presents three main characteristics:(i) it is based on an axiomatic rather than generative view of grammar, (ii) it uses tag-like grammar in which the basic linguistic units are trees rather than categories and (iii) it assumes flat semantics.in what follows we show that this combination of features results in generator which integrates the positive aspects of both top-down andbottom-up generators.
</prevsent>
</prevsection>
<citsent citstr=" J90-1004 ">
in this sense, it is not unlike (shieber et al, 1990)<papid> J90-1004 </papid>s semantic-head-drivengeneration.</citsent>
<aftsection>
<nextsent>as will become clear in the following section however, it differs from it in that it integrates stronger lexical ist (i.e. bottom-up) information.
</nextsent>
<nextsent>5.1 bottom-up generation.
</nextsent>
<nextsent>bottom-up or lexically-driven?
</nextsent>
<nextsent>generators (e.g.,(shieber, 1988; <papid> C88-2128 </papid>whitelock, 1992; <papid> C92-2117 </papid>kay, 1996; <papid> P96-1027 </papid>car roll et al, 1999)) start from bag of lexical items with instantiated semantics and generates syntactic tree by applying grammar rules whose right hand side matches sequence of phrases in the current input.there are two known disadvantages to bottom up generators.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q375">
<title id=" P01-1028.xml">generating with a grammar based on tree descriptions a constraint based approach </title>
<section> comparison with related work.  </section>
<citcontext>
<prevsection>
<prevsent>5.1 bottom-up generation.
</prevsent>
<prevsent>bottom-up or lexically-driven?
</prevsent>
</prevsection>
<citsent citstr=" C92-2117 ">
generators (e.g.,(shieber, 1988; <papid> C88-2128 </papid>whitelock, 1992; <papid> C92-2117 </papid>kay, 1996; <papid> P96-1027 </papid>car roll et al, 1999)) start from bag of lexical items with instantiated semantics and generates syntactic tree by applying grammar rules whose right hand side matches sequence of phrases in the current input.there are two known disadvantages to bottom up generators.</citsent>
<aftsection>
<nextsent>on the one hand, they require that the grammar be semantically monotonic that is, that the semantics of each daughter in rule subsumes some portion of the mother semantics.on the other hand, they are often overly non deterministic (though see (carroll et al, 1999) for an exception).
</nextsent>
<nextsent>we now show how these problems are dealt with in the present algorithm.non-determinism.
</nextsent>
<nextsent>two main sources of non determinism affect the performance of bottom-up generators: the lack of an indexing scheme and the presence of intersec tive modifiers.
</nextsent>
<nextsent>in (shieber, 1988), <papid> C88-2128 </papid>chart-based bottom-upgenerator is presented which is devoid of an indexing scheme: all word edges leave and enter the same vertex and as result, interactions must be considered explicitly between new edges and all edges currently in the chart.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q376">
<title id=" P01-1028.xml">generating with a grammar based on tree descriptions a constraint based approach </title>
<section> comparison with related work.  </section>
<citcontext>
<prevsection>
<prevsent>5.1 bottom-up generation.
</prevsent>
<prevsent>bottom-up or lexically-driven?
</prevsent>
</prevsection>
<citsent citstr=" P96-1027 ">
generators (e.g.,(shieber, 1988; <papid> C88-2128 </papid>whitelock, 1992; <papid> C92-2117 </papid>kay, 1996; <papid> P96-1027 </papid>car roll et al, 1999)) start from bag of lexical items with instantiated semantics and generates syntactic tree by applying grammar rules whose right hand side matches sequence of phrases in the current input.there are two known disadvantages to bottom up generators.</citsent>
<aftsection>
<nextsent>on the one hand, they require that the grammar be semantically monotonic that is, that the semantics of each daughter in rule subsumes some portion of the mother semantics.on the other hand, they are often overly non deterministic (though see (carroll et al, 1999) for an exception).
</nextsent>
<nextsent>we now show how these problems are dealt with in the present algorithm.non-determinism.
</nextsent>
<nextsent>two main sources of non determinism affect the performance of bottom-up generators: the lack of an indexing scheme and the presence of intersec tive modifiers.
</nextsent>
<nextsent>in (shieber, 1988), <papid> C88-2128 </papid>chart-based bottom-upgenerator is presented which is devoid of an indexing scheme: all word edges leave and enter the same vertex and as result, interactions must be considered explicitly between new edges and all edges currently in the chart.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q379">
<title id=" P01-1028.xml">generating with a grammar based on tree descriptions a constraint based approach </title>
<section> comparison with related work.  </section>
<citcontext>
<prevsection>
<prevsent>(1) the fierce black cat, the fierce little cat, the little black cat, the black cat, the fierce cat, the little cat, the cat.
</prevsent>
<prevsent>to remedy this shortcoming, various heuristics and parsing strategies have been proposed.
</prevsent>
</prevsection>
<citsent citstr=" C92-2092 ">
(brew,1992) <papid> C92-2092 </papid>combines constraint-propagation mechanism with shift-reduce generator, propagating constraints after every reduction step.</citsent>
<aftsection>
<nextsent>(carroll etal., 1999) advocate two-step generation algorithm in which first, the basic structure of the sentence is generated and second, intersec tive modifiers are adjoined in.
</nextsent>
<nextsent>and (poznanski et al, 1995) <papid> P95-1035 </papid>make use of tree reconstruction method which incrementally improves the syntactic tree until it is accepted by the grammar.</nextsent>
<nextsent>in effect, the constraint-based encoding of the axiomatic view of generation proposed here takes advantage of brews observation that constraint propagation can be very effective in pruning the search space involved in the generation process.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q380">
<title id=" P01-1028.xml">generating with a grammar based on tree descriptions a constraint based approach </title>
<section> comparison with related work.  </section>
<citcontext>
<prevsection>
<prevsent>(brew,1992) <papid> C92-2092 </papid>combines constraint-propagation mechanism with shift-reduce generator, propagating constraints after every reduction step.</prevsent>
<prevsent>(carroll etal., 1999) advocate two-step generation algorithm in which first, the basic structure of the sentence is generated and second, intersec tive modifiers are adjoined in.</prevsent>
</prevsection>
<citsent citstr=" P95-1035 ">
and (poznanski et al, 1995) <papid> P95-1035 </papid>make use of tree reconstruction method which incrementally improves the syntactic tree until it is accepted by the grammar.</citsent>
<aftsection>
<nextsent>in effect, the constraint-based encoding of the axiomatic view of generation proposed here takes advantage of brews observation that constraint propagation can be very effective in pruning the search space involved in the generation process.
</nextsent>
<nextsent>in constraint programming, the solutions to constraint satisfaction problem (csp) are found by alternating propagation with distribution steps.propagation is process of deterministic inference which fills out the consequences of given choice by removing all the variable values which can be inferred to be inconsistent with the problem constraint while distribution is search process which enumerates possible values for the problem variables.
</nextsent>
<nextsent>by specifying global properties of the output and letting constraint propagation fill out the consequences of choice, situations in which no suitable trees can be built can be detected early.
</nextsent>
<nextsent>specifically, the global constraint stating that the semantics of solution tree must be identical with the goal semantics rules out the generation of the phrases in (1b).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q382">
<title id=" P03-2013.xml">approaches to zero adnominal recognition </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>recall precision pos only 2/34 ( 5.88%) 2/4 (50.00%) semantic only 30/34 (88.23%) 31/35 (88.57%) pos/semantic 32/34 (94.11%) 32/33 (96.96%) table 5: revised-algorithm evaluation the revised algorithm, with both syntactic/semantic heuristics and the additional idiom filtering rule, achieved precision of 96.96%.
</prevsent>
<prevsent>the result still includes some over/under-detecting errors, which will require future attention.
</prevsent>
</prevsection>
<citsent citstr=" J98-2001 ">
associative anaphora (e.g., poesio and vieira, 1998) <papid> J98-2001 </papid>and indirect anaphora (e.g., murata and na gao, 2000) are virtually the same phenomena that this paper is concerned with, as illustrated in (6).</citsent>
<aftsection>
<nextsent>6 vieira and poesio (2000) <papid> J00-4003 </papid>also list idiom?</nextsent>
<nextsent>as one use of defi-.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q383">
<title id=" P03-2013.xml">approaches to zero adnominal recognition </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the result still includes some over/under-detecting errors, which will require future attention.
</prevsent>
<prevsent>associative anaphora (e.g., poesio and vieira, 1998) <papid> J98-2001 </papid>and indirect anaphora (e.g., murata and na gao, 2000) are virtually the same phenomena that this paper is concerned with, as illustrated in (6).</prevsent>
</prevsection>
<citsent citstr=" J00-4003 ">
6 vieira and poesio (2000) <papid> J00-4003 </papid>also list idiom?</citsent>
<aftsection>
<nextsent>as one use of defi-.
</nextsent>
<nextsent>nite descriptions (english equivalent to japanese bare nouns), along with same head/associative anaphora, etc. 7 the list currently includes eight idiomatic samples from the.
</nextsent>
<nextsent>test data, but it should of course be expanded in the future.
</nextsent>
<nextsent>(6) a. house ? the roof b. ie house?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q385">
<title id=" P03-2013.xml">approaches to zero adnominal recognition </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, insights from other approaches are worth attention.
</prevsent>
<prevsent>there is strong resemblance between bare nouns (that zero adnominals co-occur with) in japanese and definite descriptions in english in their behaviors, especially in their referential properties (sakahara, 2000).
</prevsent>
</prevsection>
<citsent citstr=" P99-1048 ">
the task of classifying several different uses of definite descriptions (vieira and poesio, 2000; <papid> J00-4003 </papid>bean and riloff, 1999) <papid> P99-1048 </papid>is somewhat analogous to that for bare nouns.</citsent>
<aftsection>
<nextsent>determining definite ness of japanese noun phrases (heine, 1998; <papid> P98-1085 </papid>bond et al, 1995; murata and nagao, 1993)8 is also relevant to atn (which is definite in nature) recognition.</nextsent>
<nextsent>we have proposed an atn (hence zero adnominal) recognition algorithm, with lexicon-based heuristics that were inferred from our corpus investigation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q386">
<title id=" P03-2013.xml">approaches to zero adnominal recognition </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>there is strong resemblance between bare nouns (that zero adnominals co-occur with) in japanese and definite descriptions in english in their behaviors, especially in their referential properties (sakahara, 2000).
</prevsent>
<prevsent>the task of classifying several different uses of definite descriptions (vieira and poesio, 2000; <papid> J00-4003 </papid>bean and riloff, 1999) <papid> P99-1048 </papid>is somewhat analogous to that for bare nouns.</prevsent>
</prevsection>
<citsent citstr=" P98-1085 ">
determining definite ness of japanese noun phrases (heine, 1998; <papid> P98-1085 </papid>bond et al, 1995; murata and nagao, 1993)8 is also relevant to atn (which is definite in nature) recognition.</citsent>
<aftsection>
<nextsent>we have proposed an atn (hence zero adnominal) recognition algorithm, with lexicon-based heuristics that were inferred from our corpus investigation.
</nextsent>
<nextsent>the evaluation result shows that the syntactic/semantic feature-based generalization (using gt) is capable of identifying potential atns.
</nextsent>
<nextsent>the evaluation on larger corpus, of course, is essential to verify this claim.
</nextsent>
<nextsent>implementation of the algorithm is also in our future agenda.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q387">
<title id=" N12-1088.xml">low dimensional discriminative reranking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>experiments on part-of-speech tagging task in four languages show significant improvements over baseline decoder and existing reranking approaches.
</prevsent>
<prevsent>mapping inputs to outputs lies at the heart of many natural language processing applications.
</prevsent>
</prevsection>
<citsent citstr=" P99-1023 ">
forex ample, given sentence as input: part-of-speech (pos) tagging involves finding the appropriate postag sequence (thede and harper, 1999); <papid> P99-1023 </papid>parsing involves finding the appropriate tree structure(kubler et al, 2009) and statistical machine translation (smt) involves finding correct target language translation (brown et al, 1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>the accuracy achieved on such tasks can often be improved significantly with the help of discriminative reranking step (collins and koo, 2005; <papid> J05-1003 </papid>charniak and johnson, 2005; <papid> P05-1022 </papid>shen et al, 2004; <papid> N04-1023 </papid>watanabe et al, 2007).<papid> D07-1080 </papid>for the pos tagging, reranking is relative less explored due to the already higher accuracies in english (collins, 2002), <papid> P02-1062 </papid>but it is shown to improve accuracies in other languages such as chinese (huanget al, 2007).<papid> D07-1117 </papid></nextsent>
<nextsent>in this paper, we propose novel approach to discriminative reranking and show its effectiveness in pos tagging.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q388">
<title id=" N12-1088.xml">low dimensional discriminative reranking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>experiments on part-of-speech tagging task in four languages show significant improvements over baseline decoder and existing reranking approaches.
</prevsent>
<prevsent>mapping inputs to outputs lies at the heart of many natural language processing applications.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
forex ample, given sentence as input: part-of-speech (pos) tagging involves finding the appropriate postag sequence (thede and harper, 1999); <papid> P99-1023 </papid>parsing involves finding the appropriate tree structure(kubler et al, 2009) and statistical machine translation (smt) involves finding correct target language translation (brown et al, 1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>the accuracy achieved on such tasks can often be improved significantly with the help of discriminative reranking step (collins and koo, 2005; <papid> J05-1003 </papid>charniak and johnson, 2005; <papid> P05-1022 </papid>shen et al, 2004; <papid> N04-1023 </papid>watanabe et al, 2007).<papid> D07-1080 </papid>for the pos tagging, reranking is relative less explored due to the already higher accuracies in english (collins, 2002), <papid> P02-1062 </papid>but it is shown to improve accuracies in other languages such as chinese (huanget al, 2007).<papid> D07-1117 </papid></nextsent>
<nextsent>in this paper, we propose novel approach to discriminative reranking and show its effectiveness in pos tagging.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q389">
<title id=" N12-1088.xml">low dimensional discriminative reranking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>mapping inputs to outputs lies at the heart of many natural language processing applications.
</prevsent>
<prevsent>forex ample, given sentence as input: part-of-speech (pos) tagging involves finding the appropriate postag sequence (thede and harper, 1999); <papid> P99-1023 </papid>parsing involves finding the appropriate tree structure(kubler et al, 2009) and statistical machine translation (smt) involves finding correct target language translation (brown et al, 1993).<papid> J93-2003 </papid></prevsent>
</prevsection>
<citsent citstr=" J05-1003 ">
the accuracy achieved on such tasks can often be improved significantly with the help of discriminative reranking step (collins and koo, 2005; <papid> J05-1003 </papid>charniak and johnson, 2005; <papid> P05-1022 </papid>shen et al, 2004; <papid> N04-1023 </papid>watanabe et al, 2007).<papid> D07-1080 </papid>for the pos tagging, reranking is relative less explored due to the already higher accuracies in english (collins, 2002), <papid> P02-1062 </papid>but it is shown to improve accuracies in other languages such as chinese (huanget al, 2007).<papid> D07-1117 </papid></citsent>
<aftsection>
<nextsent>in this paper, we propose novel approach to discriminative reranking and show its effectiveness in pos tagging.
</nextsent>
<nextsent>reranking allows us to use arbitrary features defined jointly on input and output spaces that are often difficult to incorporate into the baseline decoder due to the computational tract ability issues.
</nextsent>
<nextsent>the effectiveness of reranking depends on the joint features defined over both input and output spaces.
</nextsent>
<nextsent>this has led the community to spend substantial efforts in defining joint features for reranking (fraser et al, 2009; <papid> E09-1033 </papid>chiang et al, 2009).<papid> N09-1025 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q391">
<title id=" N12-1088.xml">low dimensional discriminative reranking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>mapping inputs to outputs lies at the heart of many natural language processing applications.
</prevsent>
<prevsent>forex ample, given sentence as input: part-of-speech (pos) tagging involves finding the appropriate postag sequence (thede and harper, 1999); <papid> P99-1023 </papid>parsing involves finding the appropriate tree structure(kubler et al, 2009) and statistical machine translation (smt) involves finding correct target language translation (brown et al, 1993).<papid> J93-2003 </papid></prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
the accuracy achieved on such tasks can often be improved significantly with the help of discriminative reranking step (collins and koo, 2005; <papid> J05-1003 </papid>charniak and johnson, 2005; <papid> P05-1022 </papid>shen et al, 2004; <papid> N04-1023 </papid>watanabe et al, 2007).<papid> D07-1080 </papid>for the pos tagging, reranking is relative less explored due to the already higher accuracies in english (collins, 2002), <papid> P02-1062 </papid>but it is shown to improve accuracies in other languages such as chinese (huanget al, 2007).<papid> D07-1117 </papid></citsent>
<aftsection>
<nextsent>in this paper, we propose novel approach to discriminative reranking and show its effectiveness in pos tagging.
</nextsent>
<nextsent>reranking allows us to use arbitrary features defined jointly on input and output spaces that are often difficult to incorporate into the baseline decoder due to the computational tract ability issues.
</nextsent>
<nextsent>the effectiveness of reranking depends on the joint features defined over both input and output spaces.
</nextsent>
<nextsent>this has led the community to spend substantial efforts in defining joint features for reranking (fraser et al, 2009; <papid> E09-1033 </papid>chiang et al, 2009).<papid> N09-1025 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q392">
<title id=" N12-1088.xml">low dimensional discriminative reranking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>mapping inputs to outputs lies at the heart of many natural language processing applications.
</prevsent>
<prevsent>forex ample, given sentence as input: part-of-speech (pos) tagging involves finding the appropriate postag sequence (thede and harper, 1999); <papid> P99-1023 </papid>parsing involves finding the appropriate tree structure(kubler et al, 2009) and statistical machine translation (smt) involves finding correct target language translation (brown et al, 1993).<papid> J93-2003 </papid></prevsent>
</prevsection>
<citsent citstr=" N04-1023 ">
the accuracy achieved on such tasks can often be improved significantly with the help of discriminative reranking step (collins and koo, 2005; <papid> J05-1003 </papid>charniak and johnson, 2005; <papid> P05-1022 </papid>shen et al, 2004; <papid> N04-1023 </papid>watanabe et al, 2007).<papid> D07-1080 </papid>for the pos tagging, reranking is relative less explored due to the already higher accuracies in english (collins, 2002), <papid> P02-1062 </papid>but it is shown to improve accuracies in other languages such as chinese (huanget al, 2007).<papid> D07-1117 </papid></citsent>
<aftsection>
<nextsent>in this paper, we propose novel approach to discriminative reranking and show its effectiveness in pos tagging.
</nextsent>
<nextsent>reranking allows us to use arbitrary features defined jointly on input and output spaces that are often difficult to incorporate into the baseline decoder due to the computational tract ability issues.
</nextsent>
<nextsent>the effectiveness of reranking depends on the joint features defined over both input and output spaces.
</nextsent>
<nextsent>this has led the community to spend substantial efforts in defining joint features for reranking (fraser et al, 2009; <papid> E09-1033 </papid>chiang et al, 2009).<papid> N09-1025 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q393">
<title id=" N12-1088.xml">low dimensional discriminative reranking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>mapping inputs to outputs lies at the heart of many natural language processing applications.
</prevsent>
<prevsent>forex ample, given sentence as input: part-of-speech (pos) tagging involves finding the appropriate postag sequence (thede and harper, 1999); <papid> P99-1023 </papid>parsing involves finding the appropriate tree structure(kubler et al, 2009) and statistical machine translation (smt) involves finding correct target language translation (brown et al, 1993).<papid> J93-2003 </papid></prevsent>
</prevsection>
<citsent citstr=" D07-1080 ">
the accuracy achieved on such tasks can often be improved significantly with the help of discriminative reranking step (collins and koo, 2005; <papid> J05-1003 </papid>charniak and johnson, 2005; <papid> P05-1022 </papid>shen et al, 2004; <papid> N04-1023 </papid>watanabe et al, 2007).<papid> D07-1080 </papid>for the pos tagging, reranking is relative less explored due to the already higher accuracies in english (collins, 2002), <papid> P02-1062 </papid>but it is shown to improve accuracies in other languages such as chinese (huanget al, 2007).<papid> D07-1117 </papid></citsent>
<aftsection>
<nextsent>in this paper, we propose novel approach to discriminative reranking and show its effectiveness in pos tagging.
</nextsent>
<nextsent>reranking allows us to use arbitrary features defined jointly on input and output spaces that are often difficult to incorporate into the baseline decoder due to the computational tract ability issues.
</nextsent>
<nextsent>the effectiveness of reranking depends on the joint features defined over both input and output spaces.
</nextsent>
<nextsent>this has led the community to spend substantial efforts in defining joint features for reranking (fraser et al, 2009; <papid> E09-1033 </papid>chiang et al, 2009).<papid> N09-1025 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q394">
<title id=" N12-1088.xml">low dimensional discriminative reranking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>mapping inputs to outputs lies at the heart of many natural language processing applications.
</prevsent>
<prevsent>forex ample, given sentence as input: part-of-speech (pos) tagging involves finding the appropriate postag sequence (thede and harper, 1999); <papid> P99-1023 </papid>parsing involves finding the appropriate tree structure(kubler et al, 2009) and statistical machine translation (smt) involves finding correct target language translation (brown et al, 1993).<papid> J93-2003 </papid></prevsent>
</prevsection>
<citsent citstr=" P02-1062 ">
the accuracy achieved on such tasks can often be improved significantly with the help of discriminative reranking step (collins and koo, 2005; <papid> J05-1003 </papid>charniak and johnson, 2005; <papid> P05-1022 </papid>shen et al, 2004; <papid> N04-1023 </papid>watanabe et al, 2007).<papid> D07-1080 </papid>for the pos tagging, reranking is relative less explored due to the already higher accuracies in english (collins, 2002), <papid> P02-1062 </papid>but it is shown to improve accuracies in other languages such as chinese (huanget al, 2007).<papid> D07-1117 </papid></citsent>
<aftsection>
<nextsent>in this paper, we propose novel approach to discriminative reranking and show its effectiveness in pos tagging.
</nextsent>
<nextsent>reranking allows us to use arbitrary features defined jointly on input and output spaces that are often difficult to incorporate into the baseline decoder due to the computational tract ability issues.
</nextsent>
<nextsent>the effectiveness of reranking depends on the joint features defined over both input and output spaces.
</nextsent>
<nextsent>this has led the community to spend substantial efforts in defining joint features for reranking (fraser et al, 2009; <papid> E09-1033 </papid>chiang et al, 2009).<papid> N09-1025 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q395">
<title id=" N12-1088.xml">low dimensional discriminative reranking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>mapping inputs to outputs lies at the heart of many natural language processing applications.
</prevsent>
<prevsent>forex ample, given sentence as input: part-of-speech (pos) tagging involves finding the appropriate postag sequence (thede and harper, 1999); <papid> P99-1023 </papid>parsing involves finding the appropriate tree structure(kubler et al, 2009) and statistical machine translation (smt) involves finding correct target language translation (brown et al, 1993).<papid> J93-2003 </papid></prevsent>
</prevsection>
<citsent citstr=" D07-1117 ">
the accuracy achieved on such tasks can often be improved significantly with the help of discriminative reranking step (collins and koo, 2005; <papid> J05-1003 </papid>charniak and johnson, 2005; <papid> P05-1022 </papid>shen et al, 2004; <papid> N04-1023 </papid>watanabe et al, 2007).<papid> D07-1080 </papid>for the pos tagging, reranking is relative less explored due to the already higher accuracies in english (collins, 2002), <papid> P02-1062 </papid>but it is shown to improve accuracies in other languages such as chinese (huanget al, 2007).<papid> D07-1117 </papid></citsent>
<aftsection>
<nextsent>in this paper, we propose novel approach to discriminative reranking and show its effectiveness in pos tagging.
</nextsent>
<nextsent>reranking allows us to use arbitrary features defined jointly on input and output spaces that are often difficult to incorporate into the baseline decoder due to the computational tract ability issues.
</nextsent>
<nextsent>the effectiveness of reranking depends on the joint features defined over both input and output spaces.
</nextsent>
<nextsent>this has led the community to spend substantial efforts in defining joint features for reranking (fraser et al, 2009; <papid> E09-1033 </papid>chiang et al, 2009).<papid> N09-1025 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q396">
<title id=" N12-1088.xml">low dimensional discriminative reranking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>reranking allows us to use arbitrary features defined jointly on input and output spaces that are often difficult to incorporate into the baseline decoder due to the computational tract ability issues.
</prevsent>
<prevsent>the effectiveness of reranking depends on the joint features defined over both input and output spaces.
</prevsent>
</prevsection>
<citsent citstr=" E09-1033 ">
this has led the community to spend substantial efforts in defining joint features for reranking (fraser et al, 2009; <papid> E09-1033 </papid>chiang et al, 2009).<papid> N09-1025 </papid></citsent>
<aftsection>
<nextsent>unfortunately, developing joint features over the input and output space can be challenging, especially in problems for which the exact mapping between the input and the output is unclear (for instance, in automatic caption generation for images,semantic parsing or non-literal translation).
</nextsent>
<nextsent>in contrast to prior work, our approach uses features defined separately within the input and output spaces,and learns mapping function that can map an object from one space into the other.
</nextsent>
<nextsent>since our approach requires within-space features, it makes the feature engineering relatively easy.
</nextsent>
<nextsent>for clarity, we will discuss our approach in the context of pos tagging, though of course it generalizes to any reranking problem.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q397">
<title id=" N12-1088.xml">low dimensional discriminative reranking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>reranking allows us to use arbitrary features defined jointly on input and output spaces that are often difficult to incorporate into the baseline decoder due to the computational tract ability issues.
</prevsent>
<prevsent>the effectiveness of reranking depends on the joint features defined over both input and output spaces.
</prevsent>
</prevsection>
<citsent citstr=" N09-1025 ">
this has led the community to spend substantial efforts in defining joint features for reranking (fraser et al, 2009; <papid> E09-1033 </papid>chiang et al, 2009).<papid> N09-1025 </papid></citsent>
<aftsection>
<nextsent>unfortunately, developing joint features over the input and output space can be challenging, especially in problems for which the exact mapping between the input and the output is unclear (for instance, in automatic caption generation for images,semantic parsing or non-literal translation).
</nextsent>
<nextsent>in contrast to prior work, our approach uses features defined separately within the input and output spaces,and learns mapping function that can map an object from one space into the other.
</nextsent>
<nextsent>since our approach requires within-space features, it makes the feature engineering relatively easy.
</nextsent>
<nextsent>for clarity, we will discuss our approach in the context of pos tagging, though of course it generalizes to any reranking problem.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q399">
<title id=" N12-1088.xml">low dimensional discriminative reranking </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>8k 2k 1431# words 137k 31k 28k table 1: training and test data statistics.
</prevsent>
<prevsent>swedish.
</prevsent>
</prevsection>
<citsent citstr=" W06-2920 ">
the data in all these languages is obtained from the conll 2006 shared task on multilingual dependency parsing (buchholz and marsi, 2006).<papid> W06-2920 </papid></citsent>
<aftsection>
<nextsent>we only consider the word and its fine grained pos tag (columns 2 and 5 respectively) and ignore the dependency links in the data.
</nextsent>
<nextsent>table 1 shows the data statistics in each of these languages.
</nextsent>
<nextsent>we use second order hidden markov model (thede and harper, 1999) <papid> P99-1023 </papid>based tagger as baseline tagger in our experiments.</nextsent>
<nextsent>this model uses trigram transition and emission probabilities and is shownto achieve good accuracies in english and other languages (huang et al, 2007).<papid> D07-1117 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q416">
<title id=" N12-1088.xml">low dimensional discriminative reranking </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>as shown, the performance drops significantly and is in accordance with the behavior observed elsewhere (collins and koo, 2005).<papid> J05-1003 </papid></prevsent>
<prevsent>in this section, we discuss approaches that are most relevant to our problem and the approach.</prevsent>
</prevsection>
<citsent citstr=" W03-0402 ">
in nlp literature, discriminative reranking has been well explored for parsing (collins and koo, 2005; <papid> J05-1003 </papid>charniak and johnson, 2005; <papid> P05-1022 </papid>shen and joshi, 2003; <papid> W03-0402 </papid>mcdonald et al, 2005; <papid> P05-1012 </papid>johnson and ural, 2010) <papid> N10-1095 </papid>and statistical machine translation (shen et al., 2004; <papid> N04-1023 </papid>watanabe et al, 2007; <papid> D07-1080 </papid>liang et al, 2006).<papid> P06-1096 </papid></citsent>
<aftsection>
<nextsent>collins (2002) <papid> P02-1062 </papid>proposed two reranking approaches, namely boosting algorithm and voted perceptron, for the pos tagging task.</nextsent>
<nextsent>later huang et al (2007) <papid> D07-1117 </papid>propose regularized version of the objective usedby collins (2002) <papid> P02-1062 </papid>and show an improved performance for chinese.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q417">
<title id=" N12-1088.xml">low dimensional discriminative reranking </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>as shown, the performance drops significantly and is in accordance with the behavior observed elsewhere (collins and koo, 2005).<papid> J05-1003 </papid></prevsent>
<prevsent>in this section, we discuss approaches that are most relevant to our problem and the approach.</prevsent>
</prevsection>
<citsent citstr=" P05-1012 ">
in nlp literature, discriminative reranking has been well explored for parsing (collins and koo, 2005; <papid> J05-1003 </papid>charniak and johnson, 2005; <papid> P05-1022 </papid>shen and joshi, 2003; <papid> W03-0402 </papid>mcdonald et al, 2005; <papid> P05-1012 </papid>johnson and ural, 2010) <papid> N10-1095 </papid>and statistical machine translation (shen et al., 2004; <papid> N04-1023 </papid>watanabe et al, 2007; <papid> D07-1080 </papid>liang et al, 2006).<papid> P06-1096 </papid></citsent>
<aftsection>
<nextsent>collins (2002) <papid> P02-1062 </papid>proposed two reranking approaches, namely boosting algorithm and voted perceptron, for the pos tagging task.</nextsent>
<nextsent>later huang et al (2007) <papid> D07-1117 </papid>propose regularized version of the objective usedby collins (2002) <papid> P02-1062 </papid>and show an improved performance for chinese.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q418">
<title id=" N12-1088.xml">low dimensional discriminative reranking </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>as shown, the performance drops significantly and is in accordance with the behavior observed elsewhere (collins and koo, 2005).<papid> J05-1003 </papid></prevsent>
<prevsent>in this section, we discuss approaches that are most relevant to our problem and the approach.</prevsent>
</prevsection>
<citsent citstr=" N10-1095 ">
in nlp literature, discriminative reranking has been well explored for parsing (collins and koo, 2005; <papid> J05-1003 </papid>charniak and johnson, 2005; <papid> P05-1022 </papid>shen and joshi, 2003; <papid> W03-0402 </papid>mcdonald et al, 2005; <papid> P05-1012 </papid>johnson and ural, 2010) <papid> N10-1095 </papid>and statistical machine translation (shen et al., 2004; <papid> N04-1023 </papid>watanabe et al, 2007; <papid> D07-1080 </papid>liang et al, 2006).<papid> P06-1096 </papid></citsent>
<aftsection>
<nextsent>collins (2002) <papid> P02-1062 </papid>proposed two reranking approaches, namely boosting algorithm and voted perceptron, for the pos tagging task.</nextsent>
<nextsent>later huang et al (2007) <papid> D07-1117 </papid>propose regularized version of the objective usedby collins (2002) <papid> P02-1062 </papid>and show an improved performance for chinese.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q421">
<title id=" N12-1088.xml">low dimensional discriminative reranking </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>as shown, the performance drops significantly and is in accordance with the behavior observed elsewhere (collins and koo, 2005).<papid> J05-1003 </papid></prevsent>
<prevsent>in this section, we discuss approaches that are most relevant to our problem and the approach.</prevsent>
</prevsection>
<citsent citstr=" P06-1096 ">
in nlp literature, discriminative reranking has been well explored for parsing (collins and koo, 2005; <papid> J05-1003 </papid>charniak and johnson, 2005; <papid> P05-1022 </papid>shen and joshi, 2003; <papid> W03-0402 </papid>mcdonald et al, 2005; <papid> P05-1012 </papid>johnson and ural, 2010) <papid> N10-1095 </papid>and statistical machine translation (shen et al., 2004; <papid> N04-1023 </papid>watanabe et al, 2007; <papid> D07-1080 </papid>liang et al, 2006).<papid> P06-1096 </papid></citsent>
<aftsection>
<nextsent>collins (2002) <papid> P02-1062 </papid>proposed two reranking approaches, namely boosting algorithm and voted perceptron, for the pos tagging task.</nextsent>
<nextsent>later huang et al (2007) <papid> D07-1117 </papid>propose regularized version of the objective usedby collins (2002) <papid> P02-1062 </papid>and show an improved performance for chinese.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q427">
<title id=" N12-1088.xml">low dimensional discriminative reranking </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in all of the above reranking approaches, the feature functions are defined jointly on the input and output, whereas in our approach, the features are defined separately within each view and the algorithm learns the relationship between them automatically.
</prevsent>
<prevsent>this is the primary difference between our approach and the existing rerankers.
</prevsent>
</prevsection>
<citsent citstr=" N07-2047 ">
in principle, our margin formulations are similar to the max margin formulations of cca (szedmaket al, 2007) and maximum margin regression (szedmak et al, 2006; wang et al, 2007).<papid> N07-2047 </papid></citsent>
<aftsection>
<nextsent>these approaches solve the following optimization problem: min w2 + c1t ?
</nextsent>
<nextsent>(16) s.t. yi,w?(x)i? ? 1?
</nextsent>
<nextsent>i = 1 ? ?
</nextsent>
<nextsent>n our approach differs from these formulations in two main ways: the score assigned by our generative model (equivalent to cca) for an input-output pair (xti abtyi) can be converted into this format by substituting ? bat but in doing so we are ignoring the rank constraint.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q428">
<title id=" N12-1088.xml">low dimensional discriminative reranking </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>here, we restricted our scope to showing the utility of our technique and, hence, did not experiment with different features, though it is an important direction.
</prevsent>
<prevsent>by using only within space features, our models are able to beat the reranking approaches that use potentially more informative alignment-based features.
</prevsent>
</prevsection>
<citsent citstr=" D11-1086 ">
it is also possible to include alignment-based features into our models by posing the problem as feature selection problem on the co variance matrices (jagarlamudi et al, 2011).<papid> D11-1086 </papid></citsent>
<aftsection>
<nextsent>our approach involves an inverse computation and an eigenvalue problem.
</nextsent>
<nextsent>although our models scale to medium size datasets (our chinese dataset has 50k examples and 33k features), these operation scan be expensive.
</nextsent>
<nextsent>but there are alternative approximation techniques that scale well to large datasets (halko et al, 2009).
</nextsent>
<nextsent>we leave this for future work.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q429">
<title id=" P04-1020.xml">learning noun phrase anaphoricity to improve conference resolution issues in representation and optimization </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one significant constraint on coreference, thenon-anaphoricity constraint, specifies that non anaphoric np cannot be co referent with any of its preceding nps in given text.
</prevsent>
<prevsent>given the potential usefulness of knowledge of (non-)anaphoricity for coreference resolution, anaphoricity determination has been studied fairly extensively.
</prevsent>
</prevsection>
<citsent citstr=" J94-4002 ">
one common approach involves the design of heuristic rules to identify specific typesof (non-)anaphoric nps such as pleonastic pronouns (e.g., paice and husk (1987), lappin and leass (1994), <papid> J94-4002 </papid>kennedy and boguraev (1996), <papid> C96-1021 </papid>den ber (1998)) and definite descriptions (e.g., vieira and poesio (2000)).<papid> J00-4003 </papid></citsent>
<aftsection>
<nextsent>more recently, the problem has been tackled using unsupervised (e.g., bean and riloff (1999)) <papid> P99-1048 </papid>and supervised (e.g., evans (2001), ng and cardie (2002<papid> P02-1014 </papid>a)) approaches.interestingly, existing machine learning approaches to coreference resolution have performed reasonably well without anaphoricity determination (e.g., soon et al (2001), <papid> J01-4004 </papid>ng and cardie (2002<papid> P02-1014 </papid>b),strube and muller (2003), yang et al (2003)).<papid> P03-1023 </papid></nextsent>
<nextsent>nevertheless, there is empirical evidence that resolution systems might further be improved with anaphoricity information.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q430">
<title id=" P04-1020.xml">learning noun phrase anaphoricity to improve conference resolution issues in representation and optimization </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one significant constraint on coreference, thenon-anaphoricity constraint, specifies that non anaphoric np cannot be co referent with any of its preceding nps in given text.
</prevsent>
<prevsent>given the potential usefulness of knowledge of (non-)anaphoricity for coreference resolution, anaphoricity determination has been studied fairly extensively.
</prevsent>
</prevsection>
<citsent citstr=" C96-1021 ">
one common approach involves the design of heuristic rules to identify specific typesof (non-)anaphoric nps such as pleonastic pronouns (e.g., paice and husk (1987), lappin and leass (1994), <papid> J94-4002 </papid>kennedy and boguraev (1996), <papid> C96-1021 </papid>den ber (1998)) and definite descriptions (e.g., vieira and poesio (2000)).<papid> J00-4003 </papid></citsent>
<aftsection>
<nextsent>more recently, the problem has been tackled using unsupervised (e.g., bean and riloff (1999)) <papid> P99-1048 </papid>and supervised (e.g., evans (2001), ng and cardie (2002<papid> P02-1014 </papid>a)) approaches.interestingly, existing machine learning approaches to coreference resolution have performed reasonably well without anaphoricity determination (e.g., soon et al (2001), <papid> J01-4004 </papid>ng and cardie (2002<papid> P02-1014 </papid>b),strube and muller (2003), yang et al (2003)).<papid> P03-1023 </papid></nextsent>
<nextsent>nevertheless, there is empirical evidence that resolution systems might further be improved with anaphoricity information.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q431">
<title id=" P04-1020.xml">learning noun phrase anaphoricity to improve conference resolution issues in representation and optimization </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one significant constraint on coreference, thenon-anaphoricity constraint, specifies that non anaphoric np cannot be co referent with any of its preceding nps in given text.
</prevsent>
<prevsent>given the potential usefulness of knowledge of (non-)anaphoricity for coreference resolution, anaphoricity determination has been studied fairly extensively.
</prevsent>
</prevsection>
<citsent citstr=" J00-4003 ">
one common approach involves the design of heuristic rules to identify specific typesof (non-)anaphoric nps such as pleonastic pronouns (e.g., paice and husk (1987), lappin and leass (1994), <papid> J94-4002 </papid>kennedy and boguraev (1996), <papid> C96-1021 </papid>den ber (1998)) and definite descriptions (e.g., vieira and poesio (2000)).<papid> J00-4003 </papid></citsent>
<aftsection>
<nextsent>more recently, the problem has been tackled using unsupervised (e.g., bean and riloff (1999)) <papid> P99-1048 </papid>and supervised (e.g., evans (2001), ng and cardie (2002<papid> P02-1014 </papid>a)) approaches.interestingly, existing machine learning approaches to coreference resolution have performed reasonably well without anaphoricity determination (e.g., soon et al (2001), <papid> J01-4004 </papid>ng and cardie (2002<papid> P02-1014 </papid>b),strube and muller (2003), yang et al (2003)).<papid> P03-1023 </papid></nextsent>
<nextsent>nevertheless, there is empirical evidence that resolution systems might further be improved with anaphoricity information.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q432">
<title id=" P04-1020.xml">learning noun phrase anaphoricity to improve conference resolution issues in representation and optimization </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>given the potential usefulness of knowledge of (non-)anaphoricity for coreference resolution, anaphoricity determination has been studied fairly extensively.
</prevsent>
<prevsent>one common approach involves the design of heuristic rules to identify specific typesof (non-)anaphoric nps such as pleonastic pronouns (e.g., paice and husk (1987), lappin and leass (1994), <papid> J94-4002 </papid>kennedy and boguraev (1996), <papid> C96-1021 </papid>den ber (1998)) and definite descriptions (e.g., vieira and poesio (2000)).<papid> J00-4003 </papid></prevsent>
</prevsection>
<citsent citstr=" P99-1048 ">
more recently, the problem has been tackled using unsupervised (e.g., bean and riloff (1999)) <papid> P99-1048 </papid>and supervised (e.g., evans (2001), ng and cardie (2002<papid> P02-1014 </papid>a)) approaches.interestingly, existing machine learning approaches to coreference resolution have performed reasonably well without anaphoricity determination (e.g., soon et al (2001), <papid> J01-4004 </papid>ng and cardie (2002<papid> P02-1014 </papid>b),strube and muller (2003), yang et al (2003)).<papid> P03-1023 </papid></citsent>
<aftsection>
<nextsent>nevertheless, there is empirical evidence that resolution systems might further be improved with anaphoricity information.
</nextsent>
<nextsent>for instance, our coreference system mistakenly identifies an antecedent for many non-anaphoric common nouns in the absence of anaphoricity information (ng and cardie, 2002<papid> P02-1014 </papid>a).our goal in this paper is to improve learning based coreference systems using automatically computed anaphoricity information.</nextsent>
<nextsent>in particular, we examine two important, yet largely unexplored, issues in anaphoricity determination for coreference resolution: representation and optimization.constraint-based vs. feature-based representa tion.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q433">
<title id=" P04-1020.xml">learning noun phrase anaphoricity to improve conference resolution issues in representation and optimization </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>given the potential usefulness of knowledge of (non-)anaphoricity for coreference resolution, anaphoricity determination has been studied fairly extensively.
</prevsent>
<prevsent>one common approach involves the design of heuristic rules to identify specific typesof (non-)anaphoric nps such as pleonastic pronouns (e.g., paice and husk (1987), lappin and leass (1994), <papid> J94-4002 </papid>kennedy and boguraev (1996), <papid> C96-1021 </papid>den ber (1998)) and definite descriptions (e.g., vieira and poesio (2000)).<papid> J00-4003 </papid></prevsent>
</prevsection>
<citsent citstr=" P02-1014 ">
more recently, the problem has been tackled using unsupervised (e.g., bean and riloff (1999)) <papid> P99-1048 </papid>and supervised (e.g., evans (2001), ng and cardie (2002<papid> P02-1014 </papid>a)) approaches.interestingly, existing machine learning approaches to coreference resolution have performed reasonably well without anaphoricity determination (e.g., soon et al (2001), <papid> J01-4004 </papid>ng and cardie (2002<papid> P02-1014 </papid>b),strube and muller (2003), yang et al (2003)).<papid> P03-1023 </papid></citsent>
<aftsection>
<nextsent>nevertheless, there is empirical evidence that resolution systems might further be improved with anaphoricity information.
</nextsent>
<nextsent>for instance, our coreference system mistakenly identifies an antecedent for many non-anaphoric common nouns in the absence of anaphoricity information (ng and cardie, 2002<papid> P02-1014 </papid>a).our goal in this paper is to improve learning based coreference systems using automatically computed anaphoricity information.</nextsent>
<nextsent>in particular, we examine two important, yet largely unexplored, issues in anaphoricity determination for coreference resolution: representation and optimization.constraint-based vs. feature-based representa tion.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q445">
<title id=" P04-1020.xml">learning noun phrase anaphoricity to improve conference resolution issues in representation and optimization </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>given the potential usefulness of knowledge of (non-)anaphoricity for coreference resolution, anaphoricity determination has been studied fairly extensively.
</prevsent>
<prevsent>one common approach involves the design of heuristic rules to identify specific typesof (non-)anaphoric nps such as pleonastic pronouns (e.g., paice and husk (1987), lappin and leass (1994), <papid> J94-4002 </papid>kennedy and boguraev (1996), <papid> C96-1021 </papid>den ber (1998)) and definite descriptions (e.g., vieira and poesio (2000)).<papid> J00-4003 </papid></prevsent>
</prevsection>
<citsent citstr=" J01-4004 ">
more recently, the problem has been tackled using unsupervised (e.g., bean and riloff (1999)) <papid> P99-1048 </papid>and supervised (e.g., evans (2001), ng and cardie (2002<papid> P02-1014 </papid>a)) approaches.interestingly, existing machine learning approaches to coreference resolution have performed reasonably well without anaphoricity determination (e.g., soon et al (2001), <papid> J01-4004 </papid>ng and cardie (2002<papid> P02-1014 </papid>b),strube and muller (2003), yang et al (2003)).<papid> P03-1023 </papid></citsent>
<aftsection>
<nextsent>nevertheless, there is empirical evidence that resolution systems might further be improved with anaphoricity information.
</nextsent>
<nextsent>for instance, our coreference system mistakenly identifies an antecedent for many non-anaphoric common nouns in the absence of anaphoricity information (ng and cardie, 2002<papid> P02-1014 </papid>a).our goal in this paper is to improve learning based coreference systems using automatically computed anaphoricity information.</nextsent>
<nextsent>in particular, we examine two important, yet largely unexplored, issues in anaphoricity determination for coreference resolution: representation and optimization.constraint-based vs. feature-based representa tion.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q458">
<title id=" P04-1020.xml">learning noun phrase anaphoricity to improve conference resolution issues in representation and optimization </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>given the potential usefulness of knowledge of (non-)anaphoricity for coreference resolution, anaphoricity determination has been studied fairly extensively.
</prevsent>
<prevsent>one common approach involves the design of heuristic rules to identify specific typesof (non-)anaphoric nps such as pleonastic pronouns (e.g., paice and husk (1987), lappin and leass (1994), <papid> J94-4002 </papid>kennedy and boguraev (1996), <papid> C96-1021 </papid>den ber (1998)) and definite descriptions (e.g., vieira and poesio (2000)).<papid> J00-4003 </papid></prevsent>
</prevsection>
<citsent citstr=" P03-1023 ">
more recently, the problem has been tackled using unsupervised (e.g., bean and riloff (1999)) <papid> P99-1048 </papid>and supervised (e.g., evans (2001), ng and cardie (2002<papid> P02-1014 </papid>a)) approaches.interestingly, existing machine learning approaches to coreference resolution have performed reasonably well without anaphoricity determination (e.g., soon et al (2001), <papid> J01-4004 </papid>ng and cardie (2002<papid> P02-1014 </papid>b),strube and muller (2003), yang et al (2003)).<papid> P03-1023 </papid></citsent>
<aftsection>
<nextsent>nevertheless, there is empirical evidence that resolution systems might further be improved with anaphoricity information.
</nextsent>
<nextsent>for instance, our coreference system mistakenly identifies an antecedent for many non-anaphoric common nouns in the absence of anaphoricity information (ng and cardie, 2002<papid> P02-1014 </papid>a).our goal in this paper is to improve learning based coreference systems using automatically computed anaphoricity information.</nextsent>
<nextsent>in particular, we examine two important, yet largely unexplored, issues in anaphoricity determination for coreference resolution: representation and optimization.constraint-based vs. feature-based representa tion.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q487">
<title id=" P04-1020.xml">learning noun phrase anaphoricity to improve conference resolution issues in representation and optimization </title>
<section> the anaphoricity determination.  </section>
<citcontext>
<prevsection>
<prevsent>we can now design parametric anaphoricity model based on this definition.
</prevsent>
<prevsent>first, we train in supervised fashion probablistic model ofanaphoricity pa(c | i), where is an instance representing an np and is one of the two possible anaphoricity values.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
(in our experiments, we use maximum entropy classification (maxent) (berger et al, 1996) <papid> J96-1002 </papid>to train this probability model.)</citsent>
<aftsection>
<nextsent>then,we can construct parametric model making binary anaphoricity decisions from pa by introducing threshold parameter as follows.
</nextsent>
<nextsent>given specific (0 ? ? 1) and new instance i, we define an anaphoricity model ta in which ta(i) = not anaphoric if and only if pa(c = not anaphoric | i) ? t. it should be easy to see that increasing yields progressively more conservative anaphoricity models.
</nextsent>
<nextsent>again, can be tuned using held-out development data.global optimization for feature-based representation.
</nextsent>
<nextsent>we can similarly optimize our proposed conservativeness-based anaphoricity model for coreference performance when anaphoricity information is represented as feature for the coreference system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q517">
<title id=" P04-1020.xml">learning noun phrase anaphoricity to improve conference resolution issues in representation and optimization </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>5.1 coreference without anaphoricity.
</prevsent>
<prevsent>as mentioned above, we use our coreference syst emas the baseline system where no explicit anaphoricity determination system is employed.
</prevsent>
</prevsection>
<citsent citstr=" M95-1005 ">
results using ripper and maxent as the underlying learners are shown in rows 1 and 2 of table 2 where performance is reported in terms of recall, precision, and f-measure using the model-theoretic muc scoring program (vilain et al, 1995).<papid> M95-1005 </papid></citsent>
<aftsection>
<nextsent>with ripper, the system achieves an f-measure of 56.3 for bnews,61.8 for npaper, and 51.7 for nwire.
</nextsent>
<nextsent>the performance of maxent is comparable to that of ripper for the bnews and npaper datasets but slightly worse for the nwire dataset.
</nextsent>
<nextsent>5.2 coreference with anaphoricity.
</nextsent>
<nextsent>the constraint-based, locally-optimized (cblo) approach.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q518">
<title id=" P01-1069.xml">text chunking using regularized winnow </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we show that this method achieves state of the art performance with significantly less computation than previous approaches.
</prevsent>
<prevsent>recently there has been considerable interest in applying machine learning techniques to problems in natural language processing.
</prevsent>
</prevsection>
<citsent citstr=" W97-0306 ">
one method that has been quite successful in many applications is the snow architecture (dagan et al, 1997; <papid> W97-0306 </papid>khardon et al, 1999).</citsent>
<aftsection>
<nextsent>this architecture is based on the winnow algorithm (littlestone, 1988; grove and roth, 2001), which in theory is suitable for problems with many irrelevant attributes.
</nextsent>
<nextsent>in natural language processing, one of ten encounters very high dimensional feature space, although most of the features are irrelevant.
</nextsent>
<nextsent>therefore the robustness of winnow to high dimensional feature space is considered an important reason why it is suitable for nlp tasks.however, the convergence of the winnow algorithm is only guaranteed for linearly separabledata.
</nextsent>
<nextsent>in practical nlp applications, data are often linearly non-separable.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q519">
<title id=" P02-1035.xml">parsing the wall street journal using a lexical functional grammar and discriminative estimation techniques </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, such attempts have so far been confined to relatively small scale for various reasons.
</prevsent>
<prevsent>firstly, the rudimentary character of functional annotations in standard treebanks has hindered the direct use of such data for statistical estimation of linguistically fine-grainedstatistical parsing systems.
</prevsent>
</prevsection>
<citsent citstr=" P00-1061 ">
rather, parameter estimation for such models had to resort to unsupervised techniques (bouma et al , 2000; riezler et al , 2000), <papid> P00-1061 </papid>or training corpora tailored to the specific gramm arshad to be created by parsing and manual disambiguation, resulting in relatively small training sets of around 1,000 sentences (johnson et al , 1999).<papid> P99-1069 </papid>furthermore, the effort involved in coding broad coverage grammars by hand has often led to the specialization of grammars to relatively small domains,thus sacrificing grammar coverage (i.e. the percentage of sentences for which at least one analysis is found) on free text.</citsent>
<aftsection>
<nextsent>the approach presented in this paper is first attempt to scale up stochastic parsing systems based on linguistically fine-grained hand coded grammars to the upenn wall street journal (henceforth wsj) treebank (marcus et al , 1994).<papid> H94-1020 </papid></nextsent>
<nextsent>the problem of grammar coverage, i.e. the fact that not all sentences receive an analysis, is tackled in our approach by an extension of full fledged lexical-functional grammar (lfg) and aconstraint-based parser with partial parsing techniques.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q520">
<title id=" P02-1035.xml">parsing the wall street journal using a lexical functional grammar and discriminative estimation techniques </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, such attempts have so far been confined to relatively small scale for various reasons.
</prevsent>
<prevsent>firstly, the rudimentary character of functional annotations in standard treebanks has hindered the direct use of such data for statistical estimation of linguistically fine-grainedstatistical parsing systems.
</prevsent>
</prevsection>
<citsent citstr=" P99-1069 ">
rather, parameter estimation for such models had to resort to unsupervised techniques (bouma et al , 2000; riezler et al , 2000), <papid> P00-1061 </papid>or training corpora tailored to the specific gramm arshad to be created by parsing and manual disambiguation, resulting in relatively small training sets of around 1,000 sentences (johnson et al , 1999).<papid> P99-1069 </papid>furthermore, the effort involved in coding broad coverage grammars by hand has often led to the specialization of grammars to relatively small domains,thus sacrificing grammar coverage (i.e. the percentage of sentences for which at least one analysis is found) on free text.</citsent>
<aftsection>
<nextsent>the approach presented in this paper is first attempt to scale up stochastic parsing systems based on linguistically fine-grained hand coded grammars to the upenn wall street journal (henceforth wsj) treebank (marcus et al , 1994).<papid> H94-1020 </papid></nextsent>
<nextsent>the problem of grammar coverage, i.e. the fact that not all sentences receive an analysis, is tackled in our approach by an extension of full fledged lexical-functional grammar (lfg) and aconstraint-based parser with partial parsing techniques.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q521">
<title id=" P02-1035.xml">parsing the wall street journal using a lexical functional grammar and discriminative estimation techniques </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>firstly, the rudimentary character of functional annotations in standard treebanks has hindered the direct use of such data for statistical estimation of linguistically fine-grainedstatistical parsing systems.
</prevsent>
<prevsent>rather, parameter estimation for such models had to resort to unsupervised techniques (bouma et al , 2000; riezler et al , 2000), <papid> P00-1061 </papid>or training corpora tailored to the specific gramm arshad to be created by parsing and manual disambiguation, resulting in relatively small training sets of around 1,000 sentences (johnson et al , 1999).<papid> P99-1069 </papid>furthermore, the effort involved in coding broad coverage grammars by hand has often led to the specialization of grammars to relatively small domains,thus sacrificing grammar coverage (i.e. the percentage of sentences for which at least one analysis is found) on free text.</prevsent>
</prevsection>
<citsent citstr=" H94-1020 ">
the approach presented in this paper is first attempt to scale up stochastic parsing systems based on linguistically fine-grained hand coded grammars to the upenn wall street journal (henceforth wsj) treebank (marcus et al , 1994).<papid> H94-1020 </papid></citsent>
<aftsection>
<nextsent>the problem of grammar coverage, i.e. the fact that not all sentences receive an analysis, is tackled in our approach by an extension of full fledged lexical-functional grammar (lfg) and aconstraint-based parser with partial parsing techniques.
</nextsent>
<nextsent>in the absence of complete parse, so called fragment grammar?
</nextsent>
<nextsent>allows the input to be analyzed as sequence of well-formed chunks.
</nextsent>
<nextsent>the set of fragment parses is then chosen on the basis of fewest-chunk method.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q522">
<title id=" P02-1035.xml">parsing the wall street journal using a lexical functional grammar and discriminative estimation techniques </title>
<section> robust parsing using lfg.  </section>
<citcontext>
<prevsection>
<prevsent>the c-structures encode constituency.
</prevsent>
<prevsent>f-structures encode predicate-argument relations and other grammatical information, e.g.,number, tense.
</prevsent>
</prevsection>
<citsent citstr=" J93-4001 ">
the xle parser (maxwell and kaplan, 1993) <papid> J93-4001 </papid>was used to produce packed representations, specifying all possible grammar analyses of the input.the grammar has 314 rules with regular expression right-hand sides which compile into collection of finite-state machines with total of 8,759 states and 19,695 arcs.</citsent>
<aftsection>
<nextsent>the grammar uses several lexicons and two guessers: one guesser for words recognized by the morphological analyzer but not in the lexicons and one for those not recognized.
</nextsent>
<nextsent>as such, most nouns, adjectives, and adverbs haveno explicit lexical entry.
</nextsent>
<nextsent>the main verb lexicon contains 9,652 verb stems and 23,525 subcategorization frame-verb stem entries; there are also lexicons for adjectives and nouns with subcategorization frames and for closed class items.
</nextsent>
<nextsent>for estimation purposes using the wsj treebank, the grammar was modified to parse part of speech tags and labeled bracketing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q526">
<title id=" P02-1035.xml">parsing the wall street journal using a lexical functional grammar and discriminative estimation techniques </title>
<section> discriminative statistical estimation.  </section>
<citcontext>
<prevsection>
<prevsent>i=1 2i 22i = ? m? j=1 log ? x(yj ,zj) ef(x) + m?
</prevsent>
<prevsent>j=1 log ? x(yj) ef(x) + n?
</prevsent>
</prevsection>
<citsent citstr=" P92-1017 ">
i=1 2i 22i .intuitively, the goal of estimation is to find model pa1an earlier approach using partially labeled data for estimating stochastics parsers is pereira and schabess (1992) <papid> P92-1017 </papid>work on training pcfg from partially bracketed data.</citsent>
<aftsection>
<nextsent>their approach differs from the one we use here in that pereira and schabes take an em-based approach maximizing the joint likelihood of the parses and strings of their training data, while we maximize the conditional likelihood of the sets of parses given the corresponding strings in discriminative estimation setting.
</nextsent>
<nextsent>rameters which make the two expectations in the last equation equal, i.e. which adjust the model parameters to put all the weight on the parses consistent with the annotations, modulo penalty term from the gaussian prior for too large or too small weights.since closed form solution for such parameters is not available, numerical optimization methods have to be used.
</nextsent>
<nextsent>in our experiments, we applieda conjugate gradient routine, yielding fast converging optimization algorithm where at each iteration the negative log-likelihood (?)
</nextsent>
<nextsent>and the gradient vector have to be evaluated.2 for our task the gradient takes the form: (?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q527">
<title id=" P02-1035.xml">parsing the wall street journal using a lexical functional grammar and discriminative estimation techniques </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>as such, it is more appropriate to assess the disambiguator in terms of reduction in error rate (36% relative to the upper bound) than in terms of absolute f-score.
</prevsent>
<prevsent>both the dr and lfg annotations broadly agree in their measure of error reduction.
</prevsent>
</prevsection>
<citsent citstr=" W01-0521 ">
the lower reduction in error rate relative to the upper bound for dr evaluation on the brown corpus can be attributed to corpus effect that has also been observed by gildea (2001) <papid> W01-0521 </papid>for training and testing pcfgs on the wsj and brown corpora.5 breaking down results according to parse quality shows that irrespective of evaluation measure and corpus, around 4% overall performance is lost due to non-full parses, i.e. fragment, or skimmed, or skimmed+fragment parses.</citsent>
<aftsection>
<nextsent>due to the lack of standard evaluation measure sand gold standards for predicate-argument matching, comparison of our results to other stochastic parsing systems is difficult.
</nextsent>
<nextsent>to our knowledge, so far the only direct point of comparison is the parser of carroll et al  (1999) which is also evaluated on carroll et al test corpus.
</nextsent>
<nextsent>they report an f-score5gildea reports decrease from 86.1%/86.6% re call/precision on labeled bracketing to 80.3%/81% when going from training and testing on the wsj to training on the wsj and testing on the brown corpus.
</nextsent>
<nextsent>table 2: lfg f-scores for the 700 wsj test examples and dr f-scores for the 500 brown test examples broken down according to parse quality.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q528">
<title id=" P04-1074.xml">applying machine learning to chinese temporal relation resolution </title>
<section> machine learning approaches for relative.  </section>
<citcontext>
<prevsection>
<prevsent>for example, adverbs affect tense/aspect as well as discourse structure.
</prevsent>
<prevsent>for another example, tense/aspect can be affected by auxiliary words, trend verbs, etc. this shows that classification of temporal indicators based on part of-speech (pos) information alone cannot determine relative temporal relations.
</prevsent>
</prevsection>
<citsent citstr=" P94-1013 ">
relation resolution previous efforts in corpus-based natural language processing have incorporated machine learning methods to coordinate multiple linguistic features for example in accent restoration (yarowsky, 1994) <papid> P94-1013 </papid>and event classification (siegel and mckeown, 1998), etc. relative relation resolution can be modeled as relation classification task.</citsent>
<aftsection>
<nextsent>we model the thirteen relative temporal relations (see figure 1) as the classes to be decided by classifier.
</nextsent>
<nextsent>the resolution process is to assign an event pair (i.e. the two events under concern)2 to one class according to their linguistic features.
</nextsent>
<nextsent>for this purpose, we train two classifiers, probabilistic decision tree classifier (pdt) and nave bayesian classifier (nbc).
</nextsent>
<nextsent>we then combine the results by the collaborative bootstrapping (cb) technique which is used to mediate the sparse data problem arose due to the limited number of training cases.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q529">
<title id=" P00-1060.xml">an informationtheorybased feature type analysis for the modeling of statistical parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our experiment quantitatively analyzes several feature types?
</prevsent>
<prevsent>power for syntactic structure prediction and draws series of interesting conclusions.
</prevsent>
</prevsection>
<citsent citstr=" P96-1025 ">
in the field of statistical parsing, various probabilistic evaluation models have been proposed where different models use different feature types [black, 1992] [briscoe, 1993] [brown, 1991] [charniak, 1997] [collins, 1996] [<papid> P96-1025 </papid>collins, 1997] [<papid> P97-1003 </papid>magerman, 1991] [magerman, 1992] [magerman, 1995] [<papid> P95-1037 </papid>eisner, 1996].<papid> C96-1058 </papid></citsent>
<aftsection>
<nextsent>how to evaluate the different feature types?
</nextsent>
<nextsent>effects for syntactic parsing?
</nextsent>
<nextsent>the paper proposes an information-theory-based feature types analysis model, which uses the measures of predictive information quantity, predictive information gain, predictive information redundancy and predictive information summation to quantitatively analyse the different contextual feature types?
</nextsent>
<nextsent>or feature types combinations predictive power for syntactic structure.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q531">
<title id=" P00-1060.xml">an informationtheorybased feature type analysis for the modeling of statistical parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our experiment quantitatively analyzes several feature types?
</prevsent>
<prevsent>power for syntactic structure prediction and draws series of interesting conclusions.
</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
in the field of statistical parsing, various probabilistic evaluation models have been proposed where different models use different feature types [black, 1992] [briscoe, 1993] [brown, 1991] [charniak, 1997] [collins, 1996] [<papid> P96-1025 </papid>collins, 1997] [<papid> P97-1003 </papid>magerman, 1991] [magerman, 1992] [magerman, 1995] [<papid> P95-1037 </papid>eisner, 1996].<papid> C96-1058 </papid></citsent>
<aftsection>
<nextsent>how to evaluate the different feature types?
</nextsent>
<nextsent>effects for syntactic parsing?
</nextsent>
<nextsent>the paper proposes an information-theory-based feature types analysis model, which uses the measures of predictive information quantity, predictive information gain, predictive information redundancy and predictive information summation to quantitatively analyse the different contextual feature types?
</nextsent>
<nextsent>or feature types combinations predictive power for syntactic structure.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q533">
<title id=" P00-1060.xml">an informationtheorybased feature type analysis for the modeling of statistical parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our experiment quantitatively analyzes several feature types?
</prevsent>
<prevsent>power for syntactic structure prediction and draws series of interesting conclusions.
</prevsent>
</prevsection>
<citsent citstr=" P95-1037 ">
in the field of statistical parsing, various probabilistic evaluation models have been proposed where different models use different feature types [black, 1992] [briscoe, 1993] [brown, 1991] [charniak, 1997] [collins, 1996] [<papid> P96-1025 </papid>collins, 1997] [<papid> P97-1003 </papid>magerman, 1991] [magerman, 1992] [magerman, 1995] [<papid> P95-1037 </papid>eisner, 1996].<papid> C96-1058 </papid></citsent>
<aftsection>
<nextsent>how to evaluate the different feature types?
</nextsent>
<nextsent>effects for syntactic parsing?
</nextsent>
<nextsent>the paper proposes an information-theory-based feature types analysis model, which uses the measures of predictive information quantity, predictive information gain, predictive information redundancy and predictive information summation to quantitatively analyse the different contextual feature types?
</nextsent>
<nextsent>or feature types combinations predictive power for syntactic structure.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q535">
<title id=" P00-1060.xml">an informationtheorybased feature type analysis for the modeling of statistical parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our experiment quantitatively analyzes several feature types?
</prevsent>
<prevsent>power for syntactic structure prediction and draws series of interesting conclusions.
</prevsent>
</prevsection>
<citsent citstr=" C96-1058 ">
in the field of statistical parsing, various probabilistic evaluation models have been proposed where different models use different feature types [black, 1992] [briscoe, 1993] [brown, 1991] [charniak, 1997] [collins, 1996] [<papid> P96-1025 </papid>collins, 1997] [<papid> P97-1003 </papid>magerman, 1991] [magerman, 1992] [magerman, 1995] [<papid> P95-1037 </papid>eisner, 1996].<papid> C96-1058 </papid></citsent>
<aftsection>
<nextsent>how to evaluate the different feature types?
</nextsent>
<nextsent>effects for syntactic parsing?
</nextsent>
<nextsent>the paper proposes an information-theory-based feature types analysis model, which uses the measures of predictive information quantity, predictive information gain, predictive information redundancy and predictive information summation to quantitatively analyse the different contextual feature types?
</nextsent>
<nextsent>or feature types combinations predictive power for syntactic structure.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q543">
<title id=" N12-2003.xml">beauty before age applying subjectivity to automatic english adjective ordering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(1) he poked it with long metal fork (2) ? he poked it with metal long fork the problem of determining the principles that govern adjective ordering (henceforth, ao) in english has been studied from range of academic perspectives, including philosophy, linguistics, psychology and neuroscience.
</prevsent>
<prevsent>ao is also of interest in the field of natural language processing (nlp), since method that consistently selects felicitous orders would serve to improve the output of language modeling and generation systems.
</prevsent>
</prevsection>
<citsent citstr=" P99-1018 ">
previous nlp approaches to ao infer the ordering of adjective combinations from instances of the same, or superficially similar, combinations in training corpora (shaw &amp; hatzivassiloglou, 1999) (<papid> P99-1018 </papid>malouf, 2000), <papid> P00-1012 </papid>or from distributional tendencies of the adjectives in multiple-modifier strings (mitchell, 2009) (<papid> W09-0608 </papid>dunlop, mitchell, &amp; roark, 2010).</citsent>
<aftsection>
<nextsent>such methods are susceptible to data sparseness, since the combinations from which they learn are rare in everyday language.
</nextsent>
<nextsent>by contrast, the approach taken here determines ao based on semantic features of adjectives, guided by the theoretical observation that the cognitive notion of subjectivity governs ordering in the general case (adamson, 2000).
</nextsent>
<nextsent>the semantic features developed are each highly significant predictors of ao, and they combine to classify combinations with 73.0% accuracy.
</nextsent>
<nextsent>these preliminary results indicate that semantic ao systems can perform comparably to existing systems, and that classifiers exploiting semantic and direct evidence might surpass the current best-performing systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q544">
<title id=" N12-2003.xml">beauty before age applying subjectivity to automatic english adjective ordering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(1) he poked it with long metal fork (2) ? he poked it with metal long fork the problem of determining the principles that govern adjective ordering (henceforth, ao) in english has been studied from range of academic perspectives, including philosophy, linguistics, psychology and neuroscience.
</prevsent>
<prevsent>ao is also of interest in the field of natural language processing (nlp), since method that consistently selects felicitous orders would serve to improve the output of language modeling and generation systems.
</prevsent>
</prevsection>
<citsent citstr=" P00-1012 ">
previous nlp approaches to ao infer the ordering of adjective combinations from instances of the same, or superficially similar, combinations in training corpora (shaw &amp; hatzivassiloglou, 1999) (<papid> P99-1018 </papid>malouf, 2000), <papid> P00-1012 </papid>or from distributional tendencies of the adjectives in multiple-modifier strings (mitchell, 2009) (<papid> W09-0608 </papid>dunlop, mitchell, &amp; roark, 2010).</citsent>
<aftsection>
<nextsent>such methods are susceptible to data sparseness, since the combinations from which they learn are rare in everyday language.
</nextsent>
<nextsent>by contrast, the approach taken here determines ao based on semantic features of adjectives, guided by the theoretical observation that the cognitive notion of subjectivity governs ordering in the general case (adamson, 2000).
</nextsent>
<nextsent>the semantic features developed are each highly significant predictors of ao, and they combine to classify combinations with 73.0% accuracy.
</nextsent>
<nextsent>these preliminary results indicate that semantic ao systems can perform comparably to existing systems, and that classifiers exploiting semantic and direct evidence might surpass the current best-performing systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q545">
<title id=" N12-2003.xml">beauty before age applying subjectivity to automatic english adjective ordering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(1) he poked it with long metal fork (2) ? he poked it with metal long fork the problem of determining the principles that govern adjective ordering (henceforth, ao) in english has been studied from range of academic perspectives, including philosophy, linguistics, psychology and neuroscience.
</prevsent>
<prevsent>ao is also of interest in the field of natural language processing (nlp), since method that consistently selects felicitous orders would serve to improve the output of language modeling and generation systems.
</prevsent>
</prevsection>
<citsent citstr=" W09-0608 ">
previous nlp approaches to ao infer the ordering of adjective combinations from instances of the same, or superficially similar, combinations in training corpora (shaw &amp; hatzivassiloglou, 1999) (<papid> P99-1018 </papid>malouf, 2000), <papid> P00-1012 </papid>or from distributional tendencies of the adjectives in multiple-modifier strings (mitchell, 2009) (<papid> W09-0608 </papid>dunlop, mitchell, &amp; roark, 2010).</citsent>
<aftsection>
<nextsent>such methods are susceptible to data sparseness, since the combinations from which they learn are rare in everyday language.
</nextsent>
<nextsent>by contrast, the approach taken here determines ao based on semantic features of adjectives, guided by the theoretical observation that the cognitive notion of subjectivity governs ordering in the general case (adamson, 2000).
</nextsent>
<nextsent>the semantic features developed are each highly significant predictors of ao, and they combine to classify combinations with 73.0% accuracy.
</nextsent>
<nextsent>these preliminary results indicate that semantic ao systems can perform comparably to existing systems, and that classifiers exploiting semantic and direct evidence might surpass the current best-performing systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q549">
<title id=" N12-2003.xml">beauty before age applying subjectivity to automatic english adjective ordering </title>
<section> previous research.  </section>
<citcontext>
<prevsection>
<prevsent>approach, clustering adjectives based on their position in multiple-modifier strings.
</prevsent>
<prevsent>although mitchells classifier requires no direct evidence, data sparseness is still an issue because the strings from which the system learns are relatively infrequent in everyday language.
</prevsent>
</prevsection>
<citsent citstr=" N10-1085 ">
dunlop et al (2010) <papid> N10-1085 </papid>apply multiple sequence alignment (msa), statistical technique for automatic sequence ordering, which, as with maloufs system, quantifies word similarity based solely on morphological features.</citsent>
<aftsection>
<nextsent>despite the greater sophistication of these more recent approaches, mitchell et al (2011) <papid> P11-2041 </papid>showed that simple n-gram (direct evidence) classifier trained on 170 million words of new york times and wall street journal text and tested on the brown corpus (82.3% accuracy) outperforms both the clustering (69.0%) and msa (81.8%) methods.</nextsent>
<nextsent>wulff (2003) uses linear discriminant analysis (lda) to quantify the effects of various potential ao correlates, and confirms that semantic features are better predictors than morphological and syntactic features.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q550">
<title id=" N12-2003.xml">beauty before age applying subjectivity to automatic english adjective ordering </title>
<section> previous research.  </section>
<citcontext>
<prevsection>
<prevsent>although mitchells classifier requires no direct evidence, data sparseness is still an issue because the strings from which the system learns are relatively infrequent in everyday language.
</prevsent>
<prevsent>dunlop et al (2010) <papid> N10-1085 </papid>apply multiple sequence alignment (msa), statistical technique for automatic sequence ordering, which, as with maloufs system, quantifies word similarity based solely on morphological features.</prevsent>
</prevsection>
<citsent citstr=" P11-2041 ">
despite the greater sophistication of these more recent approaches, mitchell et al (2011) <papid> P11-2041 </papid>showed that simple n-gram (direct evidence) classifier trained on 170 million words of new york times and wall street journal text and tested on the brown corpus (82.3% accuracy) outperforms both the clustering (69.0%) and msa (81.8%) methods.</citsent>
<aftsection>
<nextsent>wulff (2003) uses linear discriminant analysis (lda) to quantify the effects of various potential ao correlates, and confirms that semantic features are better predictors than morphological and syntactic features.
</nextsent>
<nextsent>the features, extracted from the 10-million word spoken british national corpus (bnc) and weighted by lda, combine to predict unseen adjective orders with 72% accuracy.
</nextsent>
<nextsent>wulffs study is unique in applying semantics to the problem, although her focus is theoretical and several features are implemented manually.
</nextsent>
<nextsent>the next section describes the theoretical basis for fully-automated semantic approach to ao that could help to resolve the issues of data sparsity and domain dependence associated with the direct evidence methods described above.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q551">
<title id=" N12-2003.xml">beauty before age applying subjectivity to automatic english adjective ordering </title>
<section> system design.  </section>
<citcontext>
<prevsection>
<prevsent>steps 3-5 were repeated 4 times (5-fold cross-validation), with the scores averaged.
</prevsent>
<prevsent>3.1 the features.
</prevsent>
</prevsection>
<citsent citstr=" C00-1044 ">
of the features included in the model, comparability and polarity are shown to correlate with human subjectivity judgments by wiebe and colleagues (see e.g. hatzivassiloglou &amp; wiebe, 2000).<papid> C00-1044 </papid></citsent>
<aftsection>
<nextsent>the remainder are motivated by observations in the theoretical literature.
</nextsent>
<nextsent>modifiability: grad able adjectives, such as hot or happy, tend to be more subjective than pro to typically categorical adjectives, such as square or black (hetzron, 1978).
</nextsent>
<nextsent>unlike categorical adjectives they admit modification by intensifiers (paradis, 1997).
</nextsent>
<nextsent>therefore, the feature modifiability is defined as the conditional probability that an adjective occurs immediately following an intensifier given that it occurs at all.2  ! # = ? &amp; ( ),  #*?,&amp; ( #  =
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q552">
<title id=" N12-2003.xml">beauty before age applying subjectivity to automatic english adjective ordering </title>
<section> system design.  </section>
<citcontext>
<prevsection>
<prevsent>     7   &amp;).
</prevsent>
<prevsent>polarity: an adjective is said to be polar if it typically attributes positive (kind, healthy, strong) or negative (poor, selfish, rotten) characteristic.
</prevsent>
</prevsection>
<citsent citstr=" P97-1023 ">
semi-supervised methods for automatically detecting adjective polarity have been developed (hatzivassiloglou &amp; mckeown, 1997), <papid> P97-1023 </papid>and applied to subjectivity analysis by wiebe (2000).</citsent>
<aftsection>
<nextsent>polarity is implemented as binary feature, whose value depends on whether or not the adjective appears in list of 1,300 polar adjectives extracted by hatzivassiloglou &amp; mackeown.
</nextsent>
<nextsent>:&amp; ! # = ? 1   ? ac0   ? ac a =
</nextsent>
<nextsent>g 7 8 .
</nextsent>
<nextsent>3. 8  =
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q554">
<title id=" P04-1036.xml">finding predominant word senses in untagged text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the first sense heuristic which is often used as baseline for supervised wsd systems outperforms many of these systems which take surrounding context into account.
</prevsent>
<prevsent>this is shown by the results ofthe english all-words task in senseval-2 (cot ton et al, 1998) in figure 1 below, where the first sense is that listed in wordnet for the pos given by the penn treebank (palmer et al, 2001).
</prevsent>
</prevsection>
<citsent citstr=" H93-1061 ">
the senses in wordnet are ordered according to the frequency data in the manually tagged resource semcor (miller et al, 1993).<papid> H93-1061 </papid></citsent>
<aftsection>
<nextsent>senses that have not occurred in semcor are ordered arbitrarily and after those senses of the word that have occurred.
</nextsent>
<nextsent>the figure distinguishes systems which make use of hand-tagged data (using htd) such as semcor,from those that do not (without htd).
</nextsent>
<nextsent>the high performance of the first sense baseline is due to the skewed frequency distribution of word senses.
</nextsent>
<nextsent>even systems which show superior performance to this heuristic often make use of the heuristic where evidence from the context is not sufficient (hoste et al., 2001).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q555">
<title id=" P04-1036.xml">finding predominant word senses in untagged text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there are only couple of instances of tiger within semcor.
</prevsent>
<prevsent>another example is embryo, which does not occur at all in semcor and the first sense is listed as rudimentary plant rather than the anticipated fertilised egg meaning.
</prevsent>
</prevsection>
<citsent citstr=" W97-0808 ">
we believe that an automatic means of finding predominant sense would be useful for systems that use it as means of backing-off (wilks and stevenson, 1998;hoste et al, 2001) and for systems that use it in lexical acquisition (mccarthy, 1997; <papid> W97-0808 </papid>merlo and leybold, 2001; <papid> W01-0715 </papid>korhonen, 2002) <papid> W02-0907 </papid>because of the limited size of hand-tagged resources.</citsent>
<aftsection>
<nextsent>more importantly, when working within specific domain one would wish to tune the first sense heuristic to the domain at hand.
</nextsent>
<nextsent>the first sense of star in semcor is celestial body, however, if one were disambiguating popular news celebrity would be preferred.
</nextsent>
<nextsent>assuming that one had an accurate wsd system then one could obtain frequency counts for senses and rank them with these counts.
</nextsent>
<nextsent>however, the most accurate wsd systems are those which require manually sense tagged data in the first place, and their accuracy depends on the quantity of training examples (yarowsky and florian, 2002) available.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q556">
<title id=" P04-1036.xml">finding predominant word senses in untagged text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there are only couple of instances of tiger within semcor.
</prevsent>
<prevsent>another example is embryo, which does not occur at all in semcor and the first sense is listed as rudimentary plant rather than the anticipated fertilised egg meaning.
</prevsent>
</prevsection>
<citsent citstr=" W01-0715 ">
we believe that an automatic means of finding predominant sense would be useful for systems that use it as means of backing-off (wilks and stevenson, 1998;hoste et al, 2001) and for systems that use it in lexical acquisition (mccarthy, 1997; <papid> W97-0808 </papid>merlo and leybold, 2001; <papid> W01-0715 </papid>korhonen, 2002) <papid> W02-0907 </papid>because of the limited size of hand-tagged resources.</citsent>
<aftsection>
<nextsent>more importantly, when working within specific domain one would wish to tune the first sense heuristic to the domain at hand.
</nextsent>
<nextsent>the first sense of star in semcor is celestial body, however, if one were disambiguating popular news celebrity would be preferred.
</nextsent>
<nextsent>assuming that one had an accurate wsd system then one could obtain frequency counts for senses and rank them with these counts.
</nextsent>
<nextsent>however, the most accurate wsd systems are those which require manually sense tagged data in the first place, and their accuracy depends on the quantity of training examples (yarowsky and florian, 2002) available.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q557">
<title id=" P04-1036.xml">finding predominant word senses in untagged text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there are only couple of instances of tiger within semcor.
</prevsent>
<prevsent>another example is embryo, which does not occur at all in semcor and the first sense is listed as rudimentary plant rather than the anticipated fertilised egg meaning.
</prevsent>
</prevsection>
<citsent citstr=" W02-0907 ">
we believe that an automatic means of finding predominant sense would be useful for systems that use it as means of backing-off (wilks and stevenson, 1998;hoste et al, 2001) and for systems that use it in lexical acquisition (mccarthy, 1997; <papid> W97-0808 </papid>merlo and leybold, 2001; <papid> W01-0715 </papid>korhonen, 2002) <papid> W02-0907 </papid>because of the limited size of hand-tagged resources.</citsent>
<aftsection>
<nextsent>more importantly, when working within specific domain one would wish to tune the first sense heuristic to the domain at hand.
</nextsent>
<nextsent>the first sense of star in semcor is celestial body, however, if one were disambiguating popular news celebrity would be preferred.
</nextsent>
<nextsent>assuming that one had an accurate wsd system then one could obtain frequency counts for senses and rank them with these counts.
</nextsent>
<nextsent>however, the most accurate wsd systems are those which require manually sense tagged data in the first place, and their accuracy depends on the quantity of training examples (yarowsky and florian, 2002) available.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q558">
<title id=" P04-1036.xml">finding predominant word senses in untagged text </title>
<section> method.  </section>
<citcontext>
<prevsection>
<prevsent>in section 5 we present results of the meth odon two domain specific sections of the reuters corpus for sample of words.
</prevsent>
<prevsent>we describe some related work in section 6 and conclude in section 7.
</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
in order to find the predominant sense of target word we use thesaurus acquired from automatically parsed text based on the method of lin (1998).<papid> P98-2127 </papid>this provides the  nearest neighbours to each target word, along with the distributional similarity score between the target word and its neighbour.</citsent>
<aftsection>
<nextsent>wethen use the wordnet similarity package (patwardhan and pedersen, 2003) to give us semantic similarity measure (hereafter referred to as the wordnet similarity measure) to weight the contribution that each neighbour makes to the various senses of the target word.
</nextsent>
<nextsent>to find the first sense of word (  ) wetake each sense in turn and obtain score reflecting the prevalence which is used for ranking.
</nextsent>
<nextsent>let       be the ordered set of the top scoring  neighbours of  fromthe thesaurus with associated distributional similarity scores ffflfififfffi !
</nextsent>
<nextsent>flfififfffi !
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q567">
<title id=" P04-1036.xml">finding predominant word senses in untagged text </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>identification of these domain labels for word senses was semiautomatic and required considerable amount of hand-labelling.
</prevsent>
<prevsent>our approach is complementary to this.
</prevsent>
</prevsection>
<citsent citstr=" J04-1003 ">
it only requires raw text from the given domain and because of this it can easily be applied to new domain, or sense inventory, given sufficient text.lapata and brew (2004) <papid> J04-1003 </papid>have recently also highlighted the importance of good prior in wsd.</citsent>
<aftsection>
<nextsent>they used syntactic evidence to find prior distribution for verb classes, based on (levin, 1993), and incorporate this in wsd system.
</nextsent>
<nextsent>lapata and brew obtain their priors for verb classes directly from subcategorisation evidence in parsed corpus, whereas we use parsed data to find distributionally similar words (nearest neighbours) to the target word which reflect the different senses of the word and have associated distributional similarity scores which canbe used for ranking the senses according to preva lence.there has been some related work on using automatic thesauruses for discovering word senses from corpora pantel and lin (2002).
</nextsent>
<nextsent>in this work the lists of neighbours are themselves clustered to bring out the various senses of the word.
</nextsent>
<nextsent>they evaluate using the lin measure described above in section 2.2 to determine the precision and recall of these discovered classes with respect to wordnet synsets.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q568">
<title id=" P04-1036.xml">finding predominant word senses in untagged text </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in contrast, we use the neighbours lists and wordnet similarity measures to im pose prevalence ranking on the wordnet senses.
</prevsent>
<prevsent>we believe automatic ranking techniques such asours will be useful for systems that relyon wordnet, for example those that use it for lexical acquisition or wsd.
</prevsent>
</prevsection>
<citsent citstr=" W03-1022 ">
it would be useful however to combine our method of finding predominant senses with one which can automatically find new senses within text and relate these to wordnet synsets, as ciaramita and johnson (2003) <papid> W03-1022 </papid>do with unknown nouns.</citsent>
<aftsection>
<nextsent>we have restricted ourselves to nouns in this work, since this pos is perhaps most affected bydomain.
</nextsent>
<nextsent>we are currently investigating the performance of the first sense heuristic, and this method, for other pos on senseval-3 data (mccarthy etal., 2004), <papid> W04-0837 </papid>although not yet with rankings from do main specific corpora.</nextsent>
<nextsent>the lesk measure can be used when ranking adjectives, and adverbs as well as nouns and verbs (which can also be ranked using jcn).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q569">
<title id=" P04-1036.xml">finding predominant word senses in untagged text </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>it would be useful however to combine our method of finding predominant senses with one which can automatically find new senses within text and relate these to wordnet synsets, as ciaramita and johnson (2003) <papid> W03-1022 </papid>do with unknown nouns.</prevsent>
<prevsent>we have restricted ourselves to nouns in this work, since this pos is perhaps most affected bydomain.</prevsent>
</prevsection>
<citsent citstr=" W04-0837 ">
we are currently investigating the performance of the first sense heuristic, and this method, for other pos on senseval-3 data (mccarthy etal., 2004), <papid> W04-0837 </papid>although not yet with rankings from do main specific corpora.</citsent>
<aftsection>
<nextsent>the lesk measure can be used when ranking adjectives, and adverbs as well as nouns and verbs (which can also be ranked using jcn).
</nextsent>
<nextsent>another major advantage that lesk has is that it is applicable to lexical resources which do not have the hierarchical structure that wordnet does, but do have definitions associated with word senses.
</nextsent>
<nextsent>we have devised method that uses raw corpus data to automatically find predominant sense for nounsin wordnet.
</nextsent>
<nextsent>we use an automatically acquired thesaurus and wordnet similarity measure.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q570">
<title id=" P04-1036.xml">finding predominant word senses in untagged text </title>
<section> conclusions.  </section>
<citcontext>
<prevsection>
<prevsent>in particular, we will use balanced and do main specific corpora to isolate words having very different neighbours, and therefore rankings, in the different corpora and to detect and target words for which there is highly skewed sense distribution in these corpora.
</prevsent>
<prevsent>there is plenty of scope for further work.
</prevsent>
</prevsection>
<citsent citstr=" C04-1146 ">
we want to investigate the effect of frequency and choice of distributional similarity measure (weeds et al, 2004).<papid> C04-1146 </papid></citsent>
<aftsection>
<nextsent>additionally, we need to determine whether senses which do not occur in wide variety of grammatical contexts fare badly using distributional measures of similarity, and what can be doneto combat this problem using relation specific the sauruses.whilst we have used wordnet as our sense inventory, it would be possible to use this method with another inventory given measure of semantic relatedness between the neighbours and the senses.
</nextsent>
<nextsent>thelesk measure for example, can be used with definitions in any standard machine readable dictionary.
</nextsent>
<nextsent>acknowledgements we would like to thank siddharth patwardhan andted pedersen for making the wn similarity package publically available.
</nextsent>
<nextsent>this work was funded by eu-2001-34460 project meaning: developing multilingual web-scale language technologies, uk epsrc project robust accurate statistical parsing (rasp) and uk epsrc studentship.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q571">
<title id=" P04-1024.xml">finding ideographic representations of japanese names written in latin script via language identification and corpus validation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for language pairs with different writing systems, such as japanese and english, and for which simple string-copying of name from one language to another is not solution, researchers have studied techniques for transliteration, i.e., phonetic translation across languages.
</prevsent>
<prevsent>for example, european names are often transcribed in japanese using the sylla bic katakana alphabet.
</prevsent>
</prevsection>
<citsent citstr=" J98-4003 ">
knight and graehl (1998) <papid> J98-4003 </papid>used bilingual english-katakana dictionary, katakana-to-english phoneme mapping, and the cmu speech pronunciation dictionary to create series of weighted finite-state transducers between english words and katakana that produce and rank transliteration candidates.</citsent>
<aftsection>
<nextsent>using similar methods, qu et al (2003) showed that integrating automatically discovered transliterations of unknown katakana sequences, i.e. those not included in large japanese-english dictionary such as edict1, improves clir results.
</nextsent>
<nextsent>transliteration of names between alphabetic and sylla bic scripts has also been studied for languages such as japanese/english (fujii &amp; ishikawa, 2001), english/korean (jeong et al, 1999), and english/arabic (al-onaizan and knight, 2002).
</nextsent>
<nextsent>in work closest to ours, meng et al(2001), working in cross-language retrieval of phonetic ally transcribed spoken text, studied how to trans literate names into chinese phonemes (though not into chinese characters).
</nextsent>
<nextsent>given list of identified names, meng et al first separated the names into chinese names and english names.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q572">
<title id=" P01-1023.xml">empirically estimating order constraints for content planning in generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in language generation system, content planner typically uses one or more plans?
</prevsent>
<prevsent>to represent the content to be included in the out put and the ordering between content elements.
</prevsent>
</prevsection>
<citsent citstr=" A97-1041 ">
some researchers relyon generic planners (e.g., (dale, 1988)) for this task, while others use plans based on rhetorical structure theory (rst) (e.g., (bouayad-aga et al, 2000; moore and paris,1993; hovy, 1993)) or schemas (e.g., (mcke own, 1985; mckeown et al, 1997)).<papid> A97-1041 </papid></citsent>
<aftsection>
<nextsent>in all cases,constraints on application of rules (e.g., plan op erators), which determine content and order, are usually hand-crafted, sometimes through manual analysis of target text.in this paper, we present method for learning the basic patterns contained within plan and the ordering among them.
</nextsent>
<nextsent>as training data, weuse semantically tagged transcripts of domain experts performing the task our system is designed to mimic, an oral briefing of patient status after undergoing coronary bypass surgery.
</nextsent>
<nextsent>given that our target output is spoken language, there issome level of variability between individual transcripts.
</nextsent>
<nextsent>it is difficult for human to see patterns in the data and thus supervised learning based on hand-tagged training sets can not be applied.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q573">
<title id=" P01-1023.xml">empirically estimating order constraints for content planning in generation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>as explained in (hudak and mcclure, 1999), motif detection is usually targeted with alignment techniques (as in (durbin et al, 1998)) or with combinatorial pattern discovery techniques such as the ones we used here.
</prevsent>
<prevsent>combinatorial pattern discovery is more appropriate for our task because it allows for matching across patterns with permutations, for representation of wild cards and for use on smaller data sets.similar techniques are used in nlp.
</prevsent>
</prevsection>
<citsent citstr=" P97-1039 ">
alignments are widely used in mt, for example (melamed, 1997), <papid> P97-1039 </papid>but the crossing problem is phenomenon that occurs repeatedly and at many levels in our task and thus, this is not suitable approach for us.</citsent>
<aftsection>
<nextsent>pattern discovery techniques are often used for information extraction (e.g., (riloff, 1993; fisher et al, 1995)), <papid> M95-1011 </papid>but most work uses data that contains patterns labelled with the semantic slot the pattern fills.</nextsent>
<nextsent>given the difficulty for humans in finding patterns systematically in our data, we needed unsupervised techniques such as those developed in computational genomics.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q574">
<title id=" P01-1023.xml">empirically estimating order constraints for content planning in generation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>combinatorial pattern discovery is more appropriate for our task because it allows for matching across patterns with permutations, for representation of wild cards and for use on smaller data sets.similar techniques are used in nlp.
</prevsent>
<prevsent>alignments are widely used in mt, for example (melamed, 1997), <papid> P97-1039 </papid>but the crossing problem is phenomenon that occurs repeatedly and at many levels in our task and thus, this is not suitable approach for us.</prevsent>
</prevsection>
<citsent citstr=" M95-1011 ">
pattern discovery techniques are often used for information extraction (e.g., (riloff, 1993; fisher et al, 1995)), <papid> M95-1011 </papid>but most work uses data that contains patterns labelled with the semantic slot the pattern fills.</citsent>
<aftsection>
<nextsent>given the difficulty for humans in finding patterns systematically in our data, we needed unsupervised techniques such as those developed in computational genomics.
</nextsent>
<nextsent>other stochastic approaches to nlg normally focus on the problem of sentence generation, including syntactic and lexical realization (e.g., (langkilde and knight, 1998; <papid> W98-1426 </papid>bangalore and rambow, 2000; <papid> C00-1007 </papid>knight and hatzivassiloglou, 1995)).<papid> P95-1034 </papid></nextsent>
<nextsent>concurrent work analyzing constraints on ordering of sentences in summarization found that coherence constraint that ensures that blocks of sentences on the same topic tend to occur together(barzilay et al, 2001).<papid> H01-1065 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q575">
<title id=" P01-1023.xml">empirically estimating order constraints for content planning in generation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>pattern discovery techniques are often used for information extraction (e.g., (riloff, 1993; fisher et al, 1995)), <papid> M95-1011 </papid>but most work uses data that contains patterns labelled with the semantic slot the pattern fills.</prevsent>
<prevsent>given the difficulty for humans in finding patterns systematically in our data, we needed unsupervised techniques such as those developed in computational genomics.</prevsent>
</prevsection>
<citsent citstr=" W98-1426 ">
other stochastic approaches to nlg normally focus on the problem of sentence generation, including syntactic and lexical realization (e.g., (langkilde and knight, 1998; <papid> W98-1426 </papid>bangalore and rambow, 2000; <papid> C00-1007 </papid>knight and hatzivassiloglou, 1995)).<papid> P95-1034 </papid></citsent>
<aftsection>
<nextsent>concurrent work analyzing constraints on ordering of sentences in summarization found that coherence constraint that ensures that blocks of sentences on the same topic tend to occur together(barzilay et al, 2001).<papid> H01-1065 </papid></nextsent>
<nextsent>this results in bottom up approach for ordering that opportunistically groups sentences together based on content features.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q576">
<title id=" P01-1023.xml">empirically estimating order constraints for content planning in generation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>pattern discovery techniques are often used for information extraction (e.g., (riloff, 1993; fisher et al, 1995)), <papid> M95-1011 </papid>but most work uses data that contains patterns labelled with the semantic slot the pattern fills.</prevsent>
<prevsent>given the difficulty for humans in finding patterns systematically in our data, we needed unsupervised techniques such as those developed in computational genomics.</prevsent>
</prevsection>
<citsent citstr=" C00-1007 ">
other stochastic approaches to nlg normally focus on the problem of sentence generation, including syntactic and lexical realization (e.g., (langkilde and knight, 1998; <papid> W98-1426 </papid>bangalore and rambow, 2000; <papid> C00-1007 </papid>knight and hatzivassiloglou, 1995)).<papid> P95-1034 </papid></citsent>
<aftsection>
<nextsent>concurrent work analyzing constraints on ordering of sentences in summarization found that coherence constraint that ensures that blocks of sentences on the same topic tend to occur together(barzilay et al, 2001).<papid> H01-1065 </papid></nextsent>
<nextsent>this results in bottom up approach for ordering that opportunistically groups sentences together based on content features.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q577">
<title id=" P01-1023.xml">empirically estimating order constraints for content planning in generation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>pattern discovery techniques are often used for information extraction (e.g., (riloff, 1993; fisher et al, 1995)), <papid> M95-1011 </papid>but most work uses data that contains patterns labelled with the semantic slot the pattern fills.</prevsent>
<prevsent>given the difficulty for humans in finding patterns systematically in our data, we needed unsupervised techniques such as those developed in computational genomics.</prevsent>
</prevsection>
<citsent citstr=" P95-1034 ">
other stochastic approaches to nlg normally focus on the problem of sentence generation, including syntactic and lexical realization (e.g., (langkilde and knight, 1998; <papid> W98-1426 </papid>bangalore and rambow, 2000; <papid> C00-1007 </papid>knight and hatzivassiloglou, 1995)).<papid> P95-1034 </papid></citsent>
<aftsection>
<nextsent>concurrent work analyzing constraints on ordering of sentences in summarization found that coherence constraint that ensures that blocks of sentences on the same topic tend to occur together(barzilay et al, 2001).<papid> H01-1065 </papid></nextsent>
<nextsent>this results in bottom up approach for ordering that opportunistically groups sentences together based on content features.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q578">
<title id=" P01-1023.xml">empirically estimating order constraints for content planning in generation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>given the difficulty for humans in finding patterns systematically in our data, we needed unsupervised techniques such as those developed in computational genomics.
</prevsent>
<prevsent>other stochastic approaches to nlg normally focus on the problem of sentence generation, including syntactic and lexical realization (e.g., (langkilde and knight, 1998; <papid> W98-1426 </papid>bangalore and rambow, 2000; <papid> C00-1007 </papid>knight and hatzivassiloglou, 1995)).<papid> P95-1034 </papid></prevsent>
</prevsection>
<citsent citstr=" H01-1065 ">
concurrent work analyzing constraints on ordering of sentences in summarization found that coherence constraint that ensures that blocks of sentences on the same topic tend to occur together(barzilay et al, 2001).<papid> H01-1065 </papid></citsent>
<aftsection>
<nextsent>this results in bottom up approach for ordering that opportunistically groups sentences together based on content features.
</nextsent>
<nextsent>in contrast, our work attempts to automatically learn plans for generation based on semantic types of the input clause, resulting in top-down planner for selecting and ordering content.
</nextsent>
<nextsent>in this paper we presented technique for extracting order constraints among plan elements that performs satisfactorily without the need of large corpora.
</nextsent>
<nextsent>using conservative set of parameters, we were able to reconstruct good portion of acarefully hand-crafted planner.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q579">
<title id=" N12-1095.xml">unsupervised translation sense clustering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>finally, we describe method for annotating clusters with usage examples.
</prevsent>
<prevsent>the ability to learn bilingual lexicon from parallel corpus was an early and influential area of success for statistical modeling techniques in natural language processing.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
probabilistic word alignment models can induce bilexical distributions over target-language translations of source-language words (brown et al, 1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>however, word-to-word correspondences do not capture the full structure of bilingual lexicon.
</nextsent>
<nextsent>consider the example bilingual dictionary entry in figure 1; in addition to enumerating the translations of word, the dictionary author has grouped those translations into three sense clusters.
</nextsent>
<nextsent>inducing such clustering would prove useful in generating bilingual dictionaries automatically or building tools to assist bilingual lexicographers.
</nextsent>
<nextsent>author was summer intern with google research while conducting this research project.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q581">
<title id=" N12-1095.xml">unsupervised translation sense clustering </title>
<section> clustering with k-means.  </section>
<citcontext>
<prevsection>
<prevsent>4.1 distributed softk-means clustering.
</prevsent>
<prevsent>as first step, we cluster all words in the target language vocabulary in way that relates words that have similar distributional features.
</prevsent>
</prevsection>
<citsent citstr=" J92-4003 ">
several methods exist for this task, such as the k-means algorithm (macqueen, 1967), the brown algorithm (brown et al, 1992) <papid> J92-4003 </papid>and the exchange algorithm (kneser and ney, 1993; martinet al, 1998; uszkoreit andbrants, 2008).<papid> P08-1086 </papid></citsent>
<aftsection>
<nextsent>we use distributed implementation of the soft?
</nextsent>
<nextsent>k-means clustering algorithm described in lin and wu (2009).<papid> P09-1116 </papid></nextsent>
<nextsent>given feature vector for each element (a word type) and the number of desired clusters k, the k-means algorithm proceeds as follows: 1.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q582">
<title id=" N12-1095.xml">unsupervised translation sense clustering </title>
<section> clustering with k-means.  </section>
<citcontext>
<prevsection>
<prevsent>4.1 distributed softk-means clustering.
</prevsent>
<prevsent>as first step, we cluster all words in the target language vocabulary in way that relates words that have similar distributional features.
</prevsent>
</prevsection>
<citsent citstr=" P08-1086 ">
several methods exist for this task, such as the k-means algorithm (macqueen, 1967), the brown algorithm (brown et al, 1992) <papid> J92-4003 </papid>and the exchange algorithm (kneser and ney, 1993; martinet al, 1998; uszkoreit andbrants, 2008).<papid> P08-1086 </papid></citsent>
<aftsection>
<nextsent>we use distributed implementation of the soft?
</nextsent>
<nextsent>k-means clustering algorithm described in lin and wu (2009).<papid> P09-1116 </papid></nextsent>
<nextsent>given feature vector for each element (a word type) and the number of desired clusters k, the k-means algorithm proceeds as follows: 1.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q583">
<title id=" N12-1095.xml">unsupervised translation sense clustering </title>
<section> clustering with k-means.  </section>
<citcontext>
<prevsection>
<prevsent>several methods exist for this task, such as the k-means algorithm (macqueen, 1967), the brown algorithm (brown et al, 1992) <papid> J92-4003 </papid>and the exchange algorithm (kneser and ney, 1993; martinet al, 1998; uszkoreit andbrants, 2008).<papid> P08-1086 </papid></prevsent>
<prevsent>we use distributed implementation of the soft?</prevsent>
</prevsection>
<citsent citstr=" P09-1116 ">
k-means clustering algorithm described in lin and wu (2009).<papid> P09-1116 </papid></citsent>
<aftsection>
<nextsent>given feature vector for each element (a word type) and the number of desired clusters k, the k-means algorithm proceeds as follows: 1.
</nextsent>
<nextsent>select elements as the initial centro ids for.
</nextsent>
<nextsent>k clusters.
</nextsent>
<nextsent>repeat 2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q591">
<title id=" N12-1095.xml">unsupervised translation sense clustering </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>to our knowledge, the translation sense clustering task has not been explored previously.
</prevsent>
<prevsent>however, much prior work has explored the related task of monolingual word and phrase clustering.
</prevsent>
</prevsection>
<citsent citstr=" W09-0210 ">
uszkoreit and brants (2008) <papid> P08-1086 </papid>uses an exchange algorithm to cluster words in language model, lin and wu (2009) <papid> P09-1116 </papid>uses distributed k-means to cluster phrases for various discriminative classification tasks, vlachos et al (2009) <papid> W09-0210 </papid>uses dirichlet process mixture models for verb clustering, and sun and korhonen (2011) <papid> D11-1095 </papid>uses hierarchical levin-style clustering to cluster verbs.</citsent>
<aftsection>
<nextsent>previous word sense induction work (diab and resnik, 2002; <papid> P02-1033 </papid>kaji, 2003; <papid> N03-1015 </papid>ng et al, 2003; <papid> P03-1058 </papid>tufis et al, 2004; apidianaki, 2009) <papid> E09-1010 </papid>relates to our workin that these approaches discover word senses automatically through clustering, even using multilingual parallel corpora.</nextsent>
<nextsent>however, our task of clustering multiple words produces different type of output from the standard word sense induction task of clustering in-context uses of single word.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q592">
<title id=" N12-1095.xml">unsupervised translation sense clustering </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>to our knowledge, the translation sense clustering task has not been explored previously.
</prevsent>
<prevsent>however, much prior work has explored the related task of monolingual word and phrase clustering.
</prevsent>
</prevsection>
<citsent citstr=" D11-1095 ">
uszkoreit and brants (2008) <papid> P08-1086 </papid>uses an exchange algorithm to cluster words in language model, lin and wu (2009) <papid> P09-1116 </papid>uses distributed k-means to cluster phrases for various discriminative classification tasks, vlachos et al (2009) <papid> W09-0210 </papid>uses dirichlet process mixture models for verb clustering, and sun and korhonen (2011) <papid> D11-1095 </papid>uses hierarchical levin-style clustering to cluster verbs.</citsent>
<aftsection>
<nextsent>previous word sense induction work (diab and resnik, 2002; <papid> P02-1033 </papid>kaji, 2003; <papid> N03-1015 </papid>ng et al, 2003; <papid> P03-1058 </papid>tufis et al, 2004; apidianaki, 2009) <papid> E09-1010 </papid>relates to our workin that these approaches discover word senses automatically through clustering, even using multilingual parallel corpora.</nextsent>
<nextsent>however, our task of clustering multiple words produces different type of output from the standard word sense induction task of clustering in-context uses of single word.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q593">
<title id=" N12-1095.xml">unsupervised translation sense clustering </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, much prior work has explored the related task of monolingual word and phrase clustering.
</prevsent>
<prevsent>uszkoreit and brants (2008) <papid> P08-1086 </papid>uses an exchange algorithm to cluster words in language model, lin and wu (2009) <papid> P09-1116 </papid>uses distributed k-means to cluster phrases for various discriminative classification tasks, vlachos et al (2009) <papid> W09-0210 </papid>uses dirichlet process mixture models for verb clustering, and sun and korhonen (2011) <papid> D11-1095 </papid>uses hierarchical levin-style clustering to cluster verbs.</prevsent>
</prevsection>
<citsent citstr=" P02-1033 ">
previous word sense induction work (diab and resnik, 2002; <papid> P02-1033 </papid>kaji, 2003; <papid> N03-1015 </papid>ng et al, 2003; <papid> P03-1058 </papid>tufis et al, 2004; apidianaki, 2009) <papid> E09-1010 </papid>relates to our workin that these approaches discover word senses automatically through clustering, even using multilingual parallel corpora.</citsent>
<aftsection>
<nextsent>however, our task of clustering multiple words produces different type of output from the standard word sense induction task of clustering in-context uses of single word.
</nextsent>
<nextsent>the underlying notion of sense?
</nextsent>
<nextsent>is shared across these tasks, but the way in which we use and evaluate induced senses is novel.
</nextsent>
<nextsent>the purpose of our experiments is to assess whether our unsupervised soft k-means clustering method can effectively recover the reference sense clusters derived from wordnet.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q594">
<title id=" N12-1095.xml">unsupervised translation sense clustering </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, much prior work has explored the related task of monolingual word and phrase clustering.
</prevsent>
<prevsent>uszkoreit and brants (2008) <papid> P08-1086 </papid>uses an exchange algorithm to cluster words in language model, lin and wu (2009) <papid> P09-1116 </papid>uses distributed k-means to cluster phrases for various discriminative classification tasks, vlachos et al (2009) <papid> W09-0210 </papid>uses dirichlet process mixture models for verb clustering, and sun and korhonen (2011) <papid> D11-1095 </papid>uses hierarchical levin-style clustering to cluster verbs.</prevsent>
</prevsection>
<citsent citstr=" N03-1015 ">
previous word sense induction work (diab and resnik, 2002; <papid> P02-1033 </papid>kaji, 2003; <papid> N03-1015 </papid>ng et al, 2003; <papid> P03-1058 </papid>tufis et al, 2004; apidianaki, 2009) <papid> E09-1010 </papid>relates to our workin that these approaches discover word senses automatically through clustering, even using multilingual parallel corpora.</citsent>
<aftsection>
<nextsent>however, our task of clustering multiple words produces different type of output from the standard word sense induction task of clustering in-context uses of single word.
</nextsent>
<nextsent>the underlying notion of sense?
</nextsent>
<nextsent>is shared across these tasks, but the way in which we use and evaluate induced senses is novel.
</nextsent>
<nextsent>the purpose of our experiments is to assess whether our unsupervised soft k-means clustering method can effectively recover the reference sense clusters derived from wordnet.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q595">
<title id=" N12-1095.xml">unsupervised translation sense clustering </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, much prior work has explored the related task of monolingual word and phrase clustering.
</prevsent>
<prevsent>uszkoreit and brants (2008) <papid> P08-1086 </papid>uses an exchange algorithm to cluster words in language model, lin and wu (2009) <papid> P09-1116 </papid>uses distributed k-means to cluster phrases for various discriminative classification tasks, vlachos et al (2009) <papid> W09-0210 </papid>uses dirichlet process mixture models for verb clustering, and sun and korhonen (2011) <papid> D11-1095 </papid>uses hierarchical levin-style clustering to cluster verbs.</prevsent>
</prevsection>
<citsent citstr=" P03-1058 ">
previous word sense induction work (diab and resnik, 2002; <papid> P02-1033 </papid>kaji, 2003; <papid> N03-1015 </papid>ng et al, 2003; <papid> P03-1058 </papid>tufis et al, 2004; apidianaki, 2009) <papid> E09-1010 </papid>relates to our workin that these approaches discover word senses automatically through clustering, even using multilingual parallel corpora.</citsent>
<aftsection>
<nextsent>however, our task of clustering multiple words produces different type of output from the standard word sense induction task of clustering in-context uses of single word.
</nextsent>
<nextsent>the underlying notion of sense?
</nextsent>
<nextsent>is shared across these tasks, but the way in which we use and evaluate induced senses is novel.
</nextsent>
<nextsent>the purpose of our experiments is to assess whether our unsupervised soft k-means clustering method can effectively recover the reference sense clusters derived from wordnet.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q596">
<title id=" N12-1095.xml">unsupervised translation sense clustering </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, much prior work has explored the related task of monolingual word and phrase clustering.
</prevsent>
<prevsent>uszkoreit and brants (2008) <papid> P08-1086 </papid>uses an exchange algorithm to cluster words in language model, lin and wu (2009) <papid> P09-1116 </papid>uses distributed k-means to cluster phrases for various discriminative classification tasks, vlachos et al (2009) <papid> W09-0210 </papid>uses dirichlet process mixture models for verb clustering, and sun and korhonen (2011) <papid> D11-1095 </papid>uses hierarchical levin-style clustering to cluster verbs.</prevsent>
</prevsection>
<citsent citstr=" E09-1010 ">
previous word sense induction work (diab and resnik, 2002; <papid> P02-1033 </papid>kaji, 2003; <papid> N03-1015 </papid>ng et al, 2003; <papid> P03-1058 </papid>tufis et al, 2004; apidianaki, 2009) <papid> E09-1010 </papid>relates to our workin that these approaches discover word senses automatically through clustering, even using multilingual parallel corpora.</citsent>
<aftsection>
<nextsent>however, our task of clustering multiple words produces different type of output from the standard word sense induction task of clustering in-context uses of single word.
</nextsent>
<nextsent>the underlying notion of sense?
</nextsent>
<nextsent>is shared across these tasks, but the way in which we use and evaluate induced senses is novel.
</nextsent>
<nextsent>the purpose of our experiments is to assess whether our unsupervised soft k-means clustering method can effectively recover the reference sense clusters derived from wordnet.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q597">
<title id=" N12-1095.xml">unsupervised translation sense clustering </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>most source words have 3 to 5 translations each.
</prevsent>
<prevsent>monolingual features for k-means clustering were computed from an english corpus of web documents with 700 billion tokens of text.
</prevsent>
</prevsection>
<citsent citstr=" C10-1124 ">
bilingual features were computed from 0.78 (se) and1.04 (je) billion tokens of parallel text, primarily extracted from the web using automated parallel document identification (uszkoreit et al, 2010).<papid> C10-1124 </papid>word alignments were induced from the hmm based alignment model (vogel et al, 1996), <papid> C96-2141 </papid>initial ized with the bilexical parameters of ibm model 1(brown et al, 1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>both models were trained using 2 iterations of the expectation maximization algorithm.
</nextsent>
<nextsent>phrase pairs were extracted from aligned sentence pairs in the same manner used in phrase based machine translation (koehn et al, 2003).
</nextsent>
<nextsent>6.2 clustering evaluation metrics.
</nextsent>
<nextsent>the quality of text clustering algorithms can be evaluated using wide set of metrics.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q598">
<title id=" N12-1095.xml">unsupervised translation sense clustering </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>most source words have 3 to 5 translations each.
</prevsent>
<prevsent>monolingual features for k-means clustering were computed from an english corpus of web documents with 700 billion tokens of text.
</prevsent>
</prevsection>
<citsent citstr=" C96-2141 ">
bilingual features were computed from 0.78 (se) and1.04 (je) billion tokens of parallel text, primarily extracted from the web using automated parallel document identification (uszkoreit et al, 2010).<papid> C10-1124 </papid>word alignments were induced from the hmm based alignment model (vogel et al, 1996), <papid> C96-2141 </papid>initial ized with the bilexical parameters of ibm model 1(brown et al, 1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>both models were trained using 2 iterations of the expectation maximization algorithm.
</nextsent>
<nextsent>phrase pairs were extracted from aligned sentence pairs in the same manner used in phrase based machine translation (koehn et al, 2003).
</nextsent>
<nextsent>6.2 clustering evaluation metrics.
</nextsent>
<nextsent>the quality of text clustering algorithms can be evaluated using wide set of metrics.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q601">
<title id=" N12-1095.xml">unsupervised translation sense clustering </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>for evaluation by set matching, the popular measures are purity (zhao and karypis, 2001) and inverse purity and their harmonic mean (f measure, see van rijsber gen (1974)).
</prevsent>
<prevsent>for evaluation by counting pairs, the popular metrics are the rand statistic and jaccard coefficient (halkidi et al, 2001; meila, 2003).
</prevsent>
</prevsection>
<citsent citstr=" D07-1043 ">
metrics based on entropy include cluster entropy (steinbach et al, 2000), class entropy (bakus et al, 2002), vi-measure (meila, 2003), q0 (dom, 2001), v-measure (rosenberg and hirschberg, 2007) <papid> D07-1043 </papid>and mutual information (xu et al, 2003).</citsent>
<aftsection>
<nextsent>lastly, there exist the bcubed metrics (bagga and baldwin,1998), family of metrics that decompose the clus 777 tering evaluation by estimating precision and recall for each item in the distribution.amigo et al (2009) compares the various clustering metrics mentioned above and their properties.
</nextsent>
<nextsent>they define four formal but intuitive constraints on such metrics that explain which aspects of clustering quality are captured by the different metric families.their analysis shows that of the wide range of metrics, only bcubed satisfies those constraints.
</nextsent>
<nextsent>after defining each constraint below, we briefly describe its relevance to the translation sense clustering task.
</nextsent>
<nextsent>homogeneity: in cluster, we should not mix items belonging to different categories.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q602">
<title id=" P03-2041.xml">learning nonisomorphic tree mappings for machine translation </title>
<section> introduction: tree-to-tree mappings.  </section>
<citcontext>
<prevsection>
<prevsent>systems for deep?
</prevsent>
<prevsent>analysis and generation might wish to learn mappings between deep and surface trees (bohmova?
</prevsent>
</prevsection>
<citsent citstr=" C90-3045 ">
et al, 2001) or between syntax and semantics (shieber and schabes, 1990).<papid> C90-3045 </papid></citsent>
<aftsection>
<nextsent>systems for summarization or paraphrase could also be trained on tree pairs (knight and marcu, 2000).non-nlp applications might include comparing student written programs to one another or to the correct solution.
</nextsent>
<nextsent>our methods can naturally extend to train on pairs of forests (including packed forests obtained by chart pars ing).
</nextsent>
<nextsent>the correct tree is presumed to be an element of the forest.
</nextsent>
<nextsent>this makes it possible to train even when the correct parse is not fully known, or not known at all.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q604">
<title id=" P03-2041.xml">learning nonisomorphic tree mappings for machine translation </title>
<section> a natural proposal: synchronous tsg </section>
<citcontext>
<prevsection>
<prevsent>the tree-peripheral insertion of quite often requires an english frontier node that is paired with french null.
</prevsent>
<prevsent>we also formulate stsgs flexibly enough that they can handle both phrase-structure trees and dependency trees.
</prevsent>
</prevsection>
<citsent citstr=" J00-1004 ">
the latter are small and simple (alshawi et al, 2000): <papid> J00-1004 </papid>tree nodes are words, and there need be no other structure to recover or align.</citsent>
<aftsection>
<nextsent>selectional preferences and other interactions can be accommodated by enriching the states.any stsg has weakly equivalent scfg that generates the same string pairs.
</nextsent>
<nextsent>so stsg (unlike stag) has no real advantage for modeling string pairs.3 but stsgs can generate wider variety of tree pairs, e.g., non-isomorphic ones.
</nextsent>
<nextsent>so when actual trees are provided for training, stsg can be more flexible in aligning them.1goodman (2002) presents efficient tsg parsing with unbounded elementary trees.
</nextsent>
<nextsent>unfortunately, that clever method does not permit arbitrary models of elementary tree probabilities, nor does it appear to generalize to our synchronous case.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q605">
<title id=" P03-2041.xml">learning nonisomorphic tree mappings for machine translation </title>
<section> a natural proposal: synchronous tsg </section>
<citcontext>
<prevsection>
<prevsent>(it would need exponentially many nonterminals to keep track of an matching of unboundedly many frontier nodes.)
</prevsent>
<prevsent>2or sister-adjunction operation, for dependency trees.
</prevsent>
</prevsection>
<citsent citstr=" J97-3002 ">
3however, the binary-branching scfgs used by wu (1997) <papid> J97-3002 </papid>and alshawi et al (2000) <papid> J00-1004 </papid>are strictly less powerful than stsg.</citsent>
<aftsection>
<nextsent>most statistical mt derives from ibm-style models(brown et al, 1993), which ignore syntax and allow arbitrary word-to-word translation.
</nextsent>
<nextsent>hence they are able to align any sentence pair, however mismatched.
</nextsent>
<nextsent>however, they have tendency to translate long sentences into word salad.
</nextsent>
<nextsent>their alignment and translation accuracy improves when they are forced to translate shallow phrases as contiguous, potentially idiomatic units (och et al, 1999).<papid> W99-0604 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q607">
<title id=" P03-2041.xml">learning nonisomorphic tree mappings for machine translation </title>
<section> past work.  </section>
<citcontext>
<prevsection>
<prevsent>hence they are able to align any sentence pair, however mismatched.
</prevsent>
<prevsent>however, they have tendency to translate long sentences into word salad.
</prevsent>
</prevsection>
<citsent citstr=" W99-0604 ">
their alignment and translation accuracy improves when they are forced to translate shallow phrases as contiguous, potentially idiomatic units (och et al, 1999).<papid> W99-0604 </papid></citsent>
<aftsection>
<nextsent>several researchers have tried putting more syntax into translation models: like us, they use statistical versions of synchronous grammars, which generate source and target sentences in parallel and so describe their cor respondence.4 this approach offers four features absent from ibm-style models: (1) recursive phrase-based translation, (2) syntax-based language model, (3) the ability to condition words translation on the translation of syntactically related words, and (4) polynomial-time optimal alignment and decoding (knight, 1999).<papid> J99-4005 </papid></nextsent>
<nextsent>previous work in statistical synchronous grammars has been limited to forms of synchronous context-free grammar (wu, 1997; <papid> J97-3002 </papid>alshawi et al, 2000; <papid> J00-1004 </papid>yamada and knight, 2001).<papid> P01-1067 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q608">
<title id=" P03-2041.xml">learning nonisomorphic tree mappings for machine translation </title>
<section> past work.  </section>
<citcontext>
<prevsection>
<prevsent>however, they have tendency to translate long sentences into word salad.
</prevsent>
<prevsent>their alignment and translation accuracy improves when they are forced to translate shallow phrases as contiguous, potentially idiomatic units (och et al, 1999).<papid> W99-0604 </papid></prevsent>
</prevsection>
<citsent citstr=" J99-4005 ">
several researchers have tried putting more syntax into translation models: like us, they use statistical versions of synchronous grammars, which generate source and target sentences in parallel and so describe their cor respondence.4 this approach offers four features absent from ibm-style models: (1) recursive phrase-based translation, (2) syntax-based language model, (3) the ability to condition words translation on the translation of syntactically related words, and (4) polynomial-time optimal alignment and decoding (knight, 1999).<papid> J99-4005 </papid></citsent>
<aftsection>
<nextsent>previous work in statistical synchronous grammars has been limited to forms of synchronous context-free grammar (wu, 1997; <papid> J97-3002 </papid>alshawi et al, 2000; <papid> J00-1004 </papid>yamada and knight, 2001).<papid> P01-1067 </papid></nextsent>
<nextsent>this means that sentence and its translation must have isomorphic syntax trees, although they may have different numbers of surface words if null words  are allowed in one or both languages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q611">
<title id=" P03-2041.xml">learning nonisomorphic tree mappings for machine translation </title>
<section> past work.  </section>
<citcontext>
<prevsection>
<prevsent>their alignment and translation accuracy improves when they are forced to translate shallow phrases as contiguous, potentially idiomatic units (och et al, 1999).<papid> W99-0604 </papid></prevsent>
<prevsent>several researchers have tried putting more syntax into translation models: like us, they use statistical versions of synchronous grammars, which generate source and target sentences in parallel and so describe their cor respondence.4 this approach offers four features absent from ibm-style models: (1) recursive phrase-based translation, (2) syntax-based language model, (3) the ability to condition words translation on the translation of syntactically related words, and (4) polynomial-time optimal alignment and decoding (knight, 1999).<papid> J99-4005 </papid></prevsent>
</prevsection>
<citsent citstr=" P01-1067 ">
previous work in statistical synchronous grammars has been limited to forms of synchronous context-free grammar (wu, 1997; <papid> J97-3002 </papid>alshawi et al, 2000; <papid> J00-1004 </papid>yamada and knight, 2001).<papid> P01-1067 </papid></citsent>
<aftsection>
<nextsent>this means that sentence and its translation must have isomorphic syntax trees, although they may have different numbers of surface words if null words  are allowed in one or both languages.
</nextsent>
<nextsent>this rigidity does not fully describe real data.
</nextsent>
<nextsent>the one exception is the synchronous dop approach of (poutsma, 2000), <papid> C00-2092 </papid>which obtains an stsg by decomposing aligned training trees in all possible ways (and using naive?</nextsent>
<nextsent>count-based probability estimates).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q612">
<title id=" P03-2041.xml">learning nonisomorphic tree mappings for machine translation </title>
<section> past work.  </section>
<citcontext>
<prevsection>
<prevsent>this means that sentence and its translation must have isomorphic syntax trees, although they may have different numbers of surface words if null words  are allowed in one or both languages.
</prevsent>
<prevsent>this rigidity does not fully describe real data.
</prevsent>
</prevsection>
<citsent citstr=" C00-2092 ">
the one exception is the synchronous dop approach of (poutsma, 2000), <papid> C00-2092 </papid>which obtains an stsg by decomposing aligned training trees in all possible ways (and using naive?</citsent>
<aftsection>
<nextsent>count-based probability estimates).
</nextsent>
<nextsent>however, we would like to estimate model from unaligned data.
</nextsent>
<nextsent>for expository reasons (and to fill gap in the literature), first we formally present non-synchronous tsg.
</nextsent>
<nextsent>let be set of states.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q613">
<title id=" P03-2041.xml">learning nonisomorphic tree mappings for machine translation </title>
<section> tree parsing algorithms for tsg.  </section>
<citcontext>
<prevsection>
<prevsent>dt.v d(t.s(d)) the ? values are inside probabilities.
</prevsent>
<prevsent>after running the algorithm, if is the root of , then r(start) is the probability that the grammar generates . p(t | q) in line 4 may be found by hash lookup if the grammar is stored explicitly, or else by some probabilistic model that analyzes the structure, labels, and states of the elementary tree to compute its probability.
</prevsent>
</prevsection>
<citsent citstr=" J99-4004 ">
one can mechanically transform this algorithm to compute outside probabilities, the viterbi parse, the parse forest, and other quantities (goodman, 1999).<papid> J99-4004 </papid></citsent>
<aftsection>
<nextsent>one can also apply agenda-based parsing strategies.
</nextsent>
<nextsent>for fixed grammar, the runtime and space are only o(n) for tree of nodes.
</nextsent>
<nextsent>the grammar constant is the number of possible fits to node of fixed tree.
</nextsent>
<nextsent>as noted above, there usually not many of these (unless the states are uncertain) and they are simple to enumerate.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q614">
<title id=" P03-2041.xml">learning nonisomorphic tree mappings for machine translation </title>
<section> extending to synchronous tsg.  </section>
<citcontext>
<prevsection>
<prevsent>decoding.
</prevsent>
<prevsent>we create forest of possible synchronous derivations (cf.
</prevsent>
</prevsection>
<citsent citstr=" A00-2023 ">
(langkilde, 2000)).<papid> A00-2023 </papid></citsent>
<aftsection>
<nextsent>we chart-parse t1 as much as in section 5, but fitting the left side of an elementary tree pair to each node.
</nextsent>
<nextsent>roughly speaking: 1.
</nextsent>
<nextsent>for c1 = null and then c1 ? t1.v , in bottom-up order 2.
</nextsent>
<nextsent>for each ? q, let c1(q) = ??
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q615">
<title id=" P03-2027.xml">dialog navigator  a spoken dialog qa system based on large text knowledge base </title>
<section> precise text retrieval.  </section>
<citcontext>
<prevsection>
<prevsent>after that, we show experimental evaluation, and then conclude this paper.
</prevsent>
<prevsent>it is critical for q-a system to retrieve relevant texts for question precisely.
</prevsent>
</prevsection>
<citsent citstr=" J94-4001 ">
in this section, we describe the score calculation method, giving large points to modifier-head relations between bunsetsu1 based on the parse results of knp (kurohashi and nagao, 1994), <papid> J94-4001 </papid>to improve precision of text retrieval.</citsent>
<aftsection>
<nextsent>our system also uses question types, product names, and synonymous expression dictionary as described in (kiyota et al, 2002).<papid> C02-1084 </papid>first, scores of all sentences in each text are calculated as shown in figure 2.</nextsent>
<nextsent>sentence score is the total points of matching keywords and modifier-headrelations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q616">
<title id=" P03-2027.xml">dialog navigator  a spoken dialog qa system based on large text knowledge base </title>
<section> precise text retrieval.  </section>
<citcontext>
<prevsection>
<prevsent>it is critical for q-a system to retrieve relevant texts for question precisely.
</prevsent>
<prevsent>in this section, we describe the score calculation method, giving large points to modifier-head relations between bunsetsu1 based on the parse results of knp (kurohashi and nagao, 1994), <papid> J94-4001 </papid>to improve precision of text retrieval.</prevsent>
</prevsection>
<citsent citstr=" C02-1084 ">
our system also uses question types, product names, and synonymous expression dictionary as described in (kiyota et al, 2002).<papid> C02-1084 </papid>first, scores of all sentences in each text are calculated as shown in figure 2.</citsent>
<aftsection>
<nextsent>sentence score is the total points of matching keywords and modifier-headrelations.
</nextsent>
<nextsent>we give 1 point to matching of key word, and 2 points to matching of modifier-head relation (these parameters were set experimentally).
</nextsent>
<nextsent>then sentence score is normalized by the maximum matching score (mms) of both sentences as follows (the mms is the sentence score with itself):
</nextsent>
<nextsent>sentence score
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q620">
<title id=" P04-1013.xml">discriminative training of a neural network statistical parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the latter model outperforms the previous two, achieving state-of the-art levels of performance (90.1% f-measure on constituents).
</prevsent>
<prevsent>much recent work has investigated the application of discriminative methods to nlp tasks, with mixed results.
</prevsent>
</prevsection>
<citsent citstr=" W02-1002 ">
klein and manning (2002) <papid> W02-1002 </papid>argue that these results show pattern where discriminative probability models are inferior to generative probability models, but that improvements can be achieved by keeping generative probability model and training according to discriminative optimization criteria.</citsent>
<aftsection>
<nextsent>we show how this approach can be applied to broad coverage natural language parsing.
</nextsent>
<nextsent>our estimation and training methods successfully balance the conflicting requirements that the training method be both computationally tractable for large datasets and good approximation to the theoretically optimal method.
</nextsent>
<nextsent>the parser which uses this approach outperforms both generative model and discriminative model, achieving state-of-the-art levels of performance (90.1% f-measure on constituents).
</nextsent>
<nextsent>to compare these different approaches, weuse neural network architecture called simple synch rony networks (ssns) (lane and henderson, 2001) to estimate the parameters of the probability models.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q622">
<title id=" P04-1013.xml">discriminative training of a neural network statistical parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>by inducing the history representations specifically to fit the chosen model and training criteria, we avoid having to choose independence assumptions which might bias our results.
</prevsent>
<prevsent>each complete parsing system we propose consists of three components, probability model for sequences of parser decisions, simple synch rony network which estimates the parameters of the probability model, and procedure which searches for the most probable parse given these parameter estimates.
</prevsent>
</prevsection>
<citsent citstr=" N03-1014 ">
this paper outlines each of these components, but more details can be found in (henderson, 2003<papid> N03-1014 </papid>b), and, for the discriminative model, in (henderson, 2003<papid> N03-1014 </papid>a).</citsent>
<aftsection>
<nextsent>we also present the training methods,and experiments on the proposed parsing models.
</nextsent>
<nextsent>model sas with many previous statistical parsers (rat naparkhi, 1999; collins, 1999; charniak, 2000),<papid> A00-2018 </papid>we use history-based model of parsing.</nextsent>
<nextsent>designing history-based model of parsing involves two steps, first choosing mapping from the set of phrase structure trees to the set of parses, and then choosing probability model in which the probability of each parser decision is conditioned on the history of previous decisions in the parse.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q636">
<title id=" P04-1013.xml">discriminative training of a neural network statistical parser </title>
<section> two history-based probability.  </section>
<citcontext>
<prevsection>
<prevsent>this paper outlines each of these components, but more details can be found in (henderson, 2003<papid> N03-1014 </papid>b), and, for the discriminative model, in (henderson, 2003<papid> N03-1014 </papid>a).</prevsent>
<prevsent>we also present the training methods,and experiments on the proposed parsing mod els.</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
model sas with many previous statistical parsers (rat naparkhi, 1999; collins, 1999; charniak, 2000),<papid> A00-2018 </papid>we use history-based model of parsing.</citsent>
<aftsection>
<nextsent>designing history-based model of parsing involves two steps, first choosing mapping from the set of phrase structure trees to the set of parses, and then choosing probability model in which the probability of each parser decision is conditioned on the history of previous decisions in the parse.
</nextsent>
<nextsent>we use the same mapping for both our probability models, but we use two different ways of conditioning the probabilities, one generative and one discriminative.
</nextsent>
<nextsent>as we will show in section 6, these two different ways of parameterizing the probability model have abig impact on the ease with which the parameters can be estimated.
</nextsent>
<nextsent>to define the mapping from phrase structure trees to parses, we use form of left-corner parsing strategy (rosenkrantz and lewis, 1970).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q644">
<title id=" P04-1013.xml">discriminative training of a neural network statistical parser </title>
<section> two history-based probability.  </section>
<citcontext>
<prevsection>
<prevsent>we take the approach of actually calculating an estimate of the conditional probability because it differs minimally from the generative probability model.
</prevsent>
<prevsent>in this form, the distinction between our two models is sometimes referred to as joint versus conditional?
</prevsent>
</prevsection>
<citsent citstr=" P01-1042 ">
(john son, 2001; <papid> P01-1042 </papid>klein and manning, 2002) <papid> W02-1002 </papid>rather than generative versus discriminative?</citsent>
<aftsection>
<nextsent>(ng and jordan, 2002).
</nextsent>
<nextsent>as with the generative model, we use the chain rule to decompose the entire conditional probability into sequence of probabilities for individual parser decisions, where yield(dj ,..., dk) is the sequence of words wi from the shift(wi) actions in dj ,..., dk.
</nextsent>
<nextsent>p (d1,..., dm|yield(d1,..., dm)) = ip (di|d1,..., di1, yield(di,..., dm)) note that d1,..., di1 specifies yield(d1,..., di1), so it is sufficient to only add yield(di,..., dm) tothe conditional in order for the entire input sentence to be included in the conditional.
</nextsent>
<nextsent>we will refer to the string yield(di,..., dm) as the look ahead string, because it represents all those words which have not yet been reached by the parse at the time when decision di is chosen.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q668">
<title id=" P04-1013.xml">discriminative training of a neural network statistical parser </title>
<section> the experiments.  </section>
<citcontext>
<prevsection>
<prevsent>setting this post-word beam width to 5 achieves fast parsing with reasonable performance in all models.
</prevsent>
<prevsent>for the parsers with generative probability models, maximum accuracy is achieved with post-word beam width of 100.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
we used the penn treebank (marcus et al, 1993) <papid> J93-2004 </papid>to perform empirical experiments on the proposed parsing models.</citsent>
<aftsection>
<nextsent>in each case the input to the network is sequence of tag-word pairs.5 5we used publicly available tagger (ratnaparkhi, 1996) <papid> W96-0213 </papid>to provide the tags.</nextsent>
<nextsent>for each tag, there is an we report results for three different vocabulary sizes, varying in the frequency with which tagword pairs must occur in the training set in order to be included explicitly in the vocabulary.a frequency threshold of 200 resulted in vocabulary of 508 tag-word pairs, threshold of 20 resulted in 4215 tag-word pairs, and threshold of 5 resulted in 11,993 tag-word pairs for the generative model we trained networks for the 508 (gssn-freq200?)</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q669">
<title id=" P04-1013.xml">discriminative training of a neural network statistical parser </title>
<section> the experiments.  </section>
<citcontext>
<prevsection>
<prevsent>for the parsers with generative probability models, maximum accuracy is achieved with post-word beam width of 100.
</prevsent>
<prevsent>we used the penn treebank (marcus et al, 1993) <papid> J93-2004 </papid>to perform empirical experiments on the proposed parsing models.</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
in each case the input to the network is sequence of tag-word pairs.5 5we used publicly available tagger (ratnaparkhi, 1996) <papid> W96-0213 </papid>to provide the tags.</citsent>
<aftsection>
<nextsent>for each tag, there is an we report results for three different vocabulary sizes, varying in the frequency with which tagword pairs must occur in the training set in order to be included explicitly in the vocabulary.a frequency threshold of 200 resulted in vocabulary of 508 tag-word pairs, threshold of 20 resulted in 4215 tag-word pairs, and threshold of 5 resulted in 11,993 tag-word pairs for the generative model we trained networks for the 508 (gssn-freq200?)
</nextsent>
<nextsent>and 4215 (gssn-freq20?)
</nextsent>
<nextsent>word vocabularies.
</nextsent>
<nextsent>theneed to calculate word predictions makes training times for the 11,993 word vocabulary very long, and as of this writing no such network training has been completed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q678">
<title id=" P04-1013.xml">discriminative training of a neural network statistical parser </title>
<section> the experiments.  </section>
<citcontext>
<prevsection>
<prevsent>ratnaparkhi99 86.3 87.5 86.9 collins99 88.1 88.3 88.2 collins&duffy02; 88.6 88.9 88.7 charniak00 89.6 89.5 89.5 collins00 89.6 89.9 89.7 dgssn-freq20, rerank 89.8 90.4 90.1 bod03 90.7 90.8 90.7 * f?=1 for previous models may have rounding errors.
</prevsent>
<prevsent>table 2: percentage labeled constituent recall (lr), precision (lp), and combination of both (f?=1) on the entire testing set.
</prevsent>
</prevsection>
<citsent citstr=" P02-1034 ">
for comparison to previous results, table 2lists the results for our best model (dgssnfreq20, rerank)9 and several other statistical parsers (ratnaparkhi, 1999; collins, 1999; collins and duffy, 2002; <papid> P02-1034 </papid>charniak, 2000; <papid> A00-2018 </papid>collins, 2000; bod, 2003) <papid> E03-1005 </papid>on the entire testingset.</citsent>
<aftsection>
<nextsent>our best performing model is more accurate than all these previous models except (bod, 2003).<papid> E03-1005 </papid></nextsent>
<nextsent>this dgssn parser achieves this result using much less lexical knowledge than other approaches, which mostly use at least the words which occur at least 5 times, plus morphological features of the remaining words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q680">
<title id=" P04-1013.xml">discriminative training of a neural network statistical parser </title>
<section> the experiments.  </section>
<citcontext>
<prevsection>
<prevsent>ratnaparkhi99 86.3 87.5 86.9 collins99 88.1 88.3 88.2 collins&duffy02; 88.6 88.9 88.7 charniak00 89.6 89.5 89.5 collins00 89.6 89.9 89.7 dgssn-freq20, rerank 89.8 90.4 90.1 bod03 90.7 90.8 90.7 * f?=1 for previous models may have rounding errors.
</prevsent>
<prevsent>table 2: percentage labeled constituent recall (lr), precision (lp), and combination of both (f?=1) on the entire testing set.
</prevsent>
</prevsection>
<citsent citstr=" E03-1005 ">
for comparison to previous results, table 2lists the results for our best model (dgssnfreq20, rerank)9 and several other statistical parsers (ratnaparkhi, 1999; collins, 1999; collins and duffy, 2002; <papid> P02-1034 </papid>charniak, 2000; <papid> A00-2018 </papid>collins, 2000; bod, 2003) <papid> E03-1005 </papid>on the entire testingset.</citsent>
<aftsection>
<nextsent>our best performing model is more accurate than all these previous models except (bod, 2003).<papid> E03-1005 </papid></nextsent>
<nextsent>this dgssn parser achieves this result using much less lexical knowledge than other approaches, which mostly use at least the words which occur at least 5 times, plus morphological features of the remaining words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q694">
<title id=" N12-1071.xml">portable features for classifying emotional text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we further show that while ngram features tend to be accurate, they are often unsuitable for use in new domains.
</prevsent>
<prevsent>on the other hand, affect lexicon features tend to generalize and produce better results than ngrams when applied to new domain.
</prevsent>
</prevsection>
<citsent citstr=" W11-1709 ">
automatically identifying emotions expressed intext has number of applications, including tracking customer satisfaction (bougie et al, 2003), determining popularity of politicians and government policies (mohammad and yang, 2011), <papid> W11-1709 </papid>depression detection (osgood and walker, 1959; pestian et al., 2008; <papid> W08-0616 </papid>matykiewicz et al, 2009; <papid> W09-1323 </papid>cherry et al, 2012), affect-based search (mohammad, 2011), <papid> W11-1514 </papid>and improving human-computer interaction (velasquez, 1997; ravaja et al, 2006).supervised methods for classifying emotions expressed in sentence tend to perform better than unsupervised ones.</citsent>
<aftsection>
<nextsent>they use features such as unigrams and bigrams (alm et al, 2005; <papid> H05-1073 </papid>aman and szpakowicz, 2007; neviarouskaya et al, 2009; chaffar and inkpen, 2011).</nextsent>
<nextsent>for example, system can learn thatthe word excruciating tends to occur in sentences labeled with sadness, and use this word as feature in classifying new sentences.approaches that do not relyon supervised training with sentence-level annotations often use affect lexicons.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q695">
<title id=" N12-1071.xml">portable features for classifying emotional text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we further show that while ngram features tend to be accurate, they are often unsuitable for use in new domains.
</prevsent>
<prevsent>on the other hand, affect lexicon features tend to generalize and produce better results than ngrams when applied to new domain.
</prevsent>
</prevsection>
<citsent citstr=" W08-0616 ">
automatically identifying emotions expressed intext has number of applications, including tracking customer satisfaction (bougie et al, 2003), determining popularity of politicians and government policies (mohammad and yang, 2011), <papid> W11-1709 </papid>depression detection (osgood and walker, 1959; pestian et al., 2008; <papid> W08-0616 </papid>matykiewicz et al, 2009; <papid> W09-1323 </papid>cherry et al, 2012), affect-based search (mohammad, 2011), <papid> W11-1514 </papid>and improving human-computer interaction (velasquez, 1997; ravaja et al, 2006).supervised methods for classifying emotions expressed in sentence tend to perform better than unsupervised ones.</citsent>
<aftsection>
<nextsent>they use features such as unigrams and bigrams (alm et al, 2005; <papid> H05-1073 </papid>aman and szpakowicz, 2007; neviarouskaya et al, 2009; chaffar and inkpen, 2011).</nextsent>
<nextsent>for example, system can learn thatthe word excruciating tends to occur in sentences labeled with sadness, and use this word as feature in classifying new sentences.approaches that do not relyon supervised training with sentence-level annotations often use affect lexicons.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q696">
<title id=" N12-1071.xml">portable features for classifying emotional text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we further show that while ngram features tend to be accurate, they are often unsuitable for use in new domains.
</prevsent>
<prevsent>on the other hand, affect lexicon features tend to generalize and produce better results than ngrams when applied to new domain.
</prevsent>
</prevsection>
<citsent citstr=" W09-1323 ">
automatically identifying emotions expressed intext has number of applications, including tracking customer satisfaction (bougie et al, 2003), determining popularity of politicians and government policies (mohammad and yang, 2011), <papid> W11-1709 </papid>depression detection (osgood and walker, 1959; pestian et al., 2008; <papid> W08-0616 </papid>matykiewicz et al, 2009; <papid> W09-1323 </papid>cherry et al, 2012), affect-based search (mohammad, 2011), <papid> W11-1514 </papid>and improving human-computer interaction (velasquez, 1997; ravaja et al, 2006).supervised methods for classifying emotions expressed in sentence tend to perform better than unsupervised ones.</citsent>
<aftsection>
<nextsent>they use features such as unigrams and bigrams (alm et al, 2005; <papid> H05-1073 </papid>aman and szpakowicz, 2007; neviarouskaya et al, 2009; chaffar and inkpen, 2011).</nextsent>
<nextsent>for example, system can learn thatthe word excruciating tends to occur in sentences labeled with sadness, and use this word as feature in classifying new sentences.approaches that do not relyon supervised training with sentence-level annotations often use affect lexicons.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q697">
<title id=" N12-1071.xml">portable features for classifying emotional text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we further show that while ngram features tend to be accurate, they are often unsuitable for use in new domains.
</prevsent>
<prevsent>on the other hand, affect lexicon features tend to generalize and produce better results than ngrams when applied to new domain.
</prevsent>
</prevsection>
<citsent citstr=" W11-1514 ">
automatically identifying emotions expressed intext has number of applications, including tracking customer satisfaction (bougie et al, 2003), determining popularity of politicians and government policies (mohammad and yang, 2011), <papid> W11-1709 </papid>depression detection (osgood and walker, 1959; pestian et al., 2008; <papid> W08-0616 </papid>matykiewicz et al, 2009; <papid> W09-1323 </papid>cherry et al, 2012), affect-based search (mohammad, 2011), <papid> W11-1514 </papid>and improving human-computer interaction (velasquez, 1997; ravaja et al, 2006).supervised methods for classifying emotions expressed in sentence tend to perform better than unsupervised ones.</citsent>
<aftsection>
<nextsent>they use features such as unigrams and bigrams (alm et al, 2005; <papid> H05-1073 </papid>aman and szpakowicz, 2007; neviarouskaya et al, 2009; chaffar and inkpen, 2011).</nextsent>
<nextsent>for example, system can learn thatthe word excruciating tends to occur in sentences labeled with sadness, and use this word as feature in classifying new sentences.approaches that do not relyon supervised training with sentence-level annotations often use affect lexicons.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q698">
<title id=" N12-1071.xml">portable features for classifying emotional text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>on the other hand, affect lexicon features tend to generalize and produce better results than ngrams when applied to new domain.
</prevsent>
<prevsent>automatically identifying emotions expressed intext has number of applications, including tracking customer satisfaction (bougie et al, 2003), determining popularity of politicians and government policies (mohammad and yang, 2011), <papid> W11-1709 </papid>depression detection (osgood and walker, 1959; pestian et al., 2008; <papid> W08-0616 </papid>matykiewicz et al, 2009; <papid> W09-1323 </papid>cherry et al, 2012), affect-based search (mohammad, 2011), <papid> W11-1514 </papid>and improving human-computer interaction (velasquez, 1997; ravaja et al, 2006).supervised methods for classifying emotions expressed in sentence tend to perform better than unsupervised ones.</prevsent>
</prevsection>
<citsent citstr=" H05-1073 ">
they use features such as unigrams and bigrams (alm et al, 2005; <papid> H05-1073 </papid>aman and szpakowicz, 2007; neviarouskaya et al, 2009; chaffar and inkpen, 2011).</citsent>
<aftsection>
<nextsent>for example, system can learn thatthe word excruciating tends to occur in sentences labeled with sadness, and use this word as feature in classifying new sentences.approaches that do not relyon supervised training with sentence-level annotations often use affect lexicons.
</nextsent>
<nextsent>an affect lexicon, in its simplest form, isa list of words and associated emotions and sentiments.
</nextsent>
<nextsent>for example, the word excruciating may be associated with the emotions of sadness and fear.
</nextsent>
<nextsent>note that such lexicons are at best indicators of probable emotions, and that in any given sentence,the full context may suggest that completely different emotion is being expressed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q699">
<title id=" N12-1071.xml">portable features for classifying emotional text </title>
<section> affect lexicons.  </section>
<citcontext>
<prevsection>
<prevsent>the wordnet affect lexicon (strapparava and valitutti, 2004) has few thousand words annotated for associations with number of affect categories.
</prevsent>
<prevsent>this includes 1536 words annotated for associations 587 with six emotions considered to be the most basic joy, sadness, fear, disgust, anger, and surprise (ek man, 1992).1 it was created by manually identifying the emotions of few seed words and then labeling all their wordnet synonyms with the same emotion.
</prevsent>
</prevsection>
<citsent citstr=" W10-0204 ">
affective norms for english words has pleasure (happyunhappy), arousal (excitedcalm), and dominance (controlledin control) ratings for 1034words.2 mohammad and turney (2010), <papid> W10-0204 </papid>mohammad and turney (2012) compiled manual annotations for eight emotions (the six of ekman, plus trust and anticipation) as well as for positive and negative sentiment.3 the lexicon was created by crowdsourcing to mechanical turk.</citsent>
<aftsection>
<nextsent>this lexicon, referred to as the nrc word-emotion lexicon (nrc-10) version 0.91, has annotations for about 14,000 words.4we evaluate the affect lexicons that have annotations for the ekman emotions the wordnet affect lexicon and the nrc-10.
</nextsent>
<nextsent>we also experimented with subset of nrc-10, which we will call nrc6, that has annotations for only the six ekman emotions (no trust and anticipation annotations; and no positive and negative sentiment annotations).
</nextsent>
<nextsent>we created binary classifiers for each of the six emotions using weka (hall et al, 2009).5 for example, the fearnotfear classifier determined whether sentence expressed fear or not.
</nextsent>
<nextsent>we experimented with logistic regression (le cessie and van houwelingen, 1992) and support vector machines (svm).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q700">
<title id=" N12-1071.xml">portable features for classifying emotional text </title>
<section> sentence classification system.  </section>
<citcontext>
<prevsection>
<prevsent># of % of emotion instances instances anger 132 13.2 0.50 disgust 43 4.3 0.45 fear 247 24.7 0.64 joy 344 34.4 0.60 sadness 283 28.3 0.68 surprise 253 25.3 0.36 simple average 0.54 frequency-based average 0.43table 1: inter-annotator agreement (pearsons correla tion) amongst 6 annotators on the 1000-headlines dataset.
</prevsent>
<prevsent>3.1 training and testing within domain.
</prevsent>
</prevsection>
<citsent citstr=" W07-2013 ">
as source of labeled data for training and testing, we used the semeval-2007 affective text corpus wherein newspaper headlines were labeled with the six ekman emotions by six annotators (strapparava and mihalcea, 2007).<papid> W07-2013 </papid></citsent>
<aftsection>
<nextsent>for each headlineemotionpair, the annotators gave scores from 0 to 100 indicating how strongly the headline expressed the emotion.
</nextsent>
<nextsent>the inter-annotator agreement as determined by calculating the pearsons product moment correlation (r) between the scores given by each annotator and the average of the other five annotators isshown in table 1.
</nextsent>
<nextsent>for our experiments, we considered scores greater than 25 to indicate that the head line expresses the corresponding emotion.the dataset was created for an unsupervised competition, and consisted of 250 sentences of trial data and 1000 sentences of test data.
</nextsent>
<nextsent>we will refer to them as the 250-headlines and the 1000-headlines datasets respectively.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q701">
<title id=" P04-2002.xml">minimizing the length of non mixed initiative dialogs </title>
<section> non-mixed initiative dialogs.  </section>
<citcontext>
<prevsection>
<prevsent>our goal in selecting sequence of questions will be to minimize the expected length of the dialog.the probabilities may be estimated by aggregating the results from all interactions, or more sophisticated individualized model might be maintained for each participant.
</prevsent>
<prevsent>some examples of how these probabilities might be estimated can be 2in addition to modeling the followers knowledge, these probabilities can also model aspects of the dialog systems performance, such as the recognition rate of an automatic speech recognizer.found in (conati et al, 2002; zukerman and albrecht, 2001).
</prevsent>
</prevsection>
<citsent citstr=" J80-3003 ">
our model of dialog derives from rule-based theories of dialog structure, such as (perrault and allen, 1980; <papid> J80-3003 </papid>grosz and kraus, 1996; lochbaum,1998).<papid> J98-4001 </papid></citsent>
<aftsection>
<nextsent>in particular, this form of the problem models exactly the missing axiom theory?
</nextsent>
<nextsent>of smit hand hipp (1994), of smit hand hipp (1995) which proposes that dialog is aimed at proving the top-level goal in theorem-proving tree and missing axioms?
</nextsent>
<nextsent>in the proof provide motivation for interactions with the dialog partner.
</nextsent>
<nextsent>the rule sets
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q702">
<title id=" P04-2002.xml">minimizing the length of non mixed initiative dialogs </title>
<section> non-mixed initiative dialogs.  </section>
<citcontext>
<prevsection>
<prevsent>our goal in selecting sequence of questions will be to minimize the expected length of the dialog.the probabilities may be estimated by aggregating the results from all interactions, or more sophisticated individualized model might be maintained for each participant.
</prevsent>
<prevsent>some examples of how these probabilities might be estimated can be 2in addition to modeling the followers knowledge, these probabilities can also model aspects of the dialog systems performance, such as the recognition rate of an automatic speech recognizer.found in (conati et al, 2002; zukerman and albrecht, 2001).
</prevsent>
</prevsection>
<citsent citstr=" J98-4001 ">
our model of dialog derives from rule-based theories of dialog structure, such as (perrault and allen, 1980; <papid> J80-3003 </papid>grosz and kraus, 1996; lochbaum,1998).<papid> J98-4001 </papid></citsent>
<aftsection>
<nextsent>in particular, this form of the problem models exactly the missing axiom theory?
</nextsent>
<nextsent>of smit hand hipp (1994), of smit hand hipp (1995) which proposes that dialog is aimed at proving the top-level goal in theorem-proving tree and missing axioms?
</nextsent>
<nextsent>in the proof provide motivation for interactions with the dialog partner.
</nextsent>
<nextsent>the rule sets
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q703">
<title id=" P00-1052.xml">the role of centering theorys rough shift in the teaching and evaluation of writing skills </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, several dierent software systems, e.g., peg page and peterson (1995), intelligent essay assessor 1 and e-rater 2 , are now being usedto perform this task fully automatically.
</prevsent>
<prevsent>furthermore, by at least one measure, these software systems evaluate student essays with the same degree of accuracy as human experts.
</prevsent>
</prevsection>
<citsent citstr=" P98-1032 ">
that is, computer-generated scores tend to match human expert scores as frequently as two human scores match each other (burstein et al, 1998).<papid> P98-1032 </papid></citsent>
<aftsection>
<nextsent>essay scoring systems such as these can provide nlp researchers with opportunities to test certain theoretical hypotheses and to explore variety of practical issues in computational linguistics.
</nextsent>
<nextsent>in this study, we employ the e-rater essay scoring system to test hy 1 http://lsa.colorado.edu.
</nextsent>
<nextsent>2 http://www.ets.org/research/erater.html pothesis related to centering theory (joshiand weinstein, 1981; grosz et al, 1983, <papid> P83-1007 </papid>inter alia).</nextsent>
<nextsent>we focus on centering theory rough-shift transition which is the least well studied among the four transition types.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q704">
<title id=" P00-1052.xml">the role of centering theorys rough shift in the teaching and evaluation of writing skills </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>essay scoring systems such as these can provide nlp researchers with opportunities to test certain theoretical hypotheses and to explore variety of practical issues in computational linguistics.
</prevsent>
<prevsent>in this study, we employ the e-rater essay scoring system to test hy 1 http://lsa.colorado.edu.
</prevsent>
</prevsection>
<citsent citstr=" P83-1007 ">
2 http://www.ets.org/research/erater.html pothesis related to centering theory (joshiand weinstein, 1981; grosz et al, 1983, <papid> P83-1007 </papid>inter alia).</citsent>
<aftsection>
<nextsent>we focus on centering theory rough-shift transition which is the least well studied among the four transition types.
</nextsent>
<nextsent>in particular, we examine whether the discourse coherence found in an essay, as de ned by measure of relative proportion of rough-shift transitions, might be signi cant contributor to the accuracy of computer-generated essay scores.
</nextsent>
<nextsent>our positive nding validates the role of the rough-shift transition and suggests aroute for exploring centering theory practical applicability to writing evaluation and instruction.
</nextsent>
<nextsent>one goal of automatic essay scoring systems such as e-rater is to represent the criteria that human experts use to evaluate essays.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q705">
<title id=" P00-1052.xml">the role of centering theorys rough shift in the teaching and evaluation of writing skills </title>
<section> overview of centering.  </section>
<citcontext>
<prevsection>
<prevsent>centering theory provides an algorithm for computing local coherence in written discourse.
</prevsent>
<prevsent>our study investigates the applicability of centering theory local coherence measure to essay evaluation by determining the eect of adding this new feature to e-rater existing array of features.
</prevsent>
</prevsection>
<citsent citstr=" J86-3001 ">
a synthesis of two dierent lines of work (joshi and kuhn, 1979; joshi and weinstein, 1981) and (sidner, 1979; grosz, 1977; grosz and sidner, 1986) <papid> J86-3001 </papid>yielded the formulation of centering theory as model for monitoring local focus in discourse.</citsent>
<aftsection>
<nextsent>the centering model was designed to account for those aspects of processing that are responsible for the dierence in the perceived coherence of discourses such as those demonstrated in (1) and (2) below (examples from hudson-d zmura (1988)).
</nextsent>
<nextsent>(1) a. john went to his favorite music store to buy piano.
</nextsent>
<nextsent>b. he had frequented the store for many years.
</nextsent>
<nextsent>c. he was excited that he could nally buy piano.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q706">
<title id=" P00-1052.xml">the role of centering theorys rough shift in the teaching and evaluation of writing skills </title>
<section> the centering model.  </section>
<citcontext>
<prevsection>
<prevsent>as mentioned earlier, the preferred center of an utterance is de ned as the highest ranked member of the cf set.
</prevsent>
<prevsent>the ranking of the cf members is determined by the salience status of the entities in the utterance and may vary crosslinguistically.
</prevsent>
</prevsection>
<citsent citstr=" P87-1022 ">
kameyama (1985) and brennan et al (1987) <papid> P87-1022 </papid>proposed that the cf ranking for english is determined by grammatical function as fol lows: (2) rule for ranking of forward-looking centers: subj ind. obj obj other slater cross linguistic studies based on empirical work (di eugenio, 1998; turan, 1995; kameyama, 1985) determined the following detailed ranking, with qis standing for quan ti ed inde nite subjects (people, everyone etc) and pro-arb (we, you) for arbitrary plural pronominals.</citsent>
<aftsection>
<nextsent>(3)revised rule for the ranking of forward-looking centers: subj ind. obj obj others qis, pro-arb.
</nextsent>
<nextsent>4.4.1 complex nps in the case of complex nps, which havethe property of evoking multiple discourse entities (e.g. his mother, software industry), the working hypothesis commonly assumed (e.g. walker and prince (1995)) is ordering from left to right.
</nextsent>
<nextsent>3
</nextsent>
<nextsent>transitions as mentioned brie earlier, the centering model includes one more rule, the pronoun rule given in (4).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q707">
<title id=" P00-1052.xml">the role of centering theorys rough shift in the teaching and evaluation of writing skills </title>
<section> the e-rater centering study.  </section>
<citcontext>
<prevsection>
<prevsent>segment boundaries are ex 4 in fact, similar modi cation has been proposed by hurewitz (1998) and walker (1998) observed that the use of in sentences such as  believe that... ,  think that...  do not aect the focus structure of the text.
</prevsent>
<prevsent>tremely hard to identify in an accurate and principled way.
</prevsent>
</prevsection>
<citsent citstr=" J91-1002 ">
furthermore, existing algorithms (morris and hirst, 1991; <papid> J91-1002 </papid>youmans, 1991; hearst, 1994; <papid> P94-1002 </papid>kozima, 1993; <papid> P93-1041 </papid>reynar,1994; <papid> P94-1050 </papid>passonneau and litman, 1997; <papid> J97-1005 </papid>passonneau, 1998) rely heavily on the assumption of textual coherence.</citsent>
<aftsection>
<nextsent>in our case, textual coherence cannot be assumed.
</nextsent>
<nextsent>given that text organization is also part of the evaluation of the essays, we decided to use the students  paragraph breaks to locate segment boundaries.
</nextsent>
<nextsent>6.2 implementation.
</nextsent>
<nextsent>for this study, we decided to manually tagcoreferring expressions despite the availability of coreference algorithms.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q708">
<title id=" P00-1052.xml">the role of centering theorys rough shift in the teaching and evaluation of writing skills </title>
<section> the e-rater centering study.  </section>
<citcontext>
<prevsection>
<prevsent>segment boundaries are ex 4 in fact, similar modi cation has been proposed by hurewitz (1998) and walker (1998) observed that the use of in sentences such as  believe that... ,  think that...  do not aect the focus structure of the text.
</prevsent>
<prevsent>tremely hard to identify in an accurate and principled way.
</prevsent>
</prevsection>
<citsent citstr=" P94-1002 ">
furthermore, existing algorithms (morris and hirst, 1991; <papid> J91-1002 </papid>youmans, 1991; hearst, 1994; <papid> P94-1002 </papid>kozima, 1993; <papid> P93-1041 </papid>reynar,1994; <papid> P94-1050 </papid>passonneau and litman, 1997; <papid> J97-1005 </papid>passonneau, 1998) rely heavily on the assumption of textual coherence.</citsent>
<aftsection>
<nextsent>in our case, textual coherence cannot be assumed.
</nextsent>
<nextsent>given that text organization is also part of the evaluation of the essays, we decided to use the students  paragraph breaks to locate segment boundaries.
</nextsent>
<nextsent>6.2 implementation.
</nextsent>
<nextsent>for this study, we decided to manually tagcoreferring expressions despite the availability of coreference algorithms.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q709">
<title id=" P00-1052.xml">the role of centering theorys rough shift in the teaching and evaluation of writing skills </title>
<section> the e-rater centering study.  </section>
<citcontext>
<prevsection>
<prevsent>segment boundaries are ex 4 in fact, similar modi cation has been proposed by hurewitz (1998) and walker (1998) observed that the use of in sentences such as  believe that... ,  think that...  do not aect the focus structure of the text.
</prevsent>
<prevsent>tremely hard to identify in an accurate and principled way.
</prevsent>
</prevsection>
<citsent citstr=" P93-1041 ">
furthermore, existing algorithms (morris and hirst, 1991; <papid> J91-1002 </papid>youmans, 1991; hearst, 1994; <papid> P94-1002 </papid>kozima, 1993; <papid> P93-1041 </papid>reynar,1994; <papid> P94-1050 </papid>passonneau and litman, 1997; <papid> J97-1005 </papid>passonneau, 1998) rely heavily on the assumption of textual coherence.</citsent>
<aftsection>
<nextsent>in our case, textual coherence cannot be assumed.
</nextsent>
<nextsent>given that text organization is also part of the evaluation of the essays, we decided to use the students  paragraph breaks to locate segment boundaries.
</nextsent>
<nextsent>6.2 implementation.
</nextsent>
<nextsent>for this study, we decided to manually tagcoreferring expressions despite the availability of coreference algorithms.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q710">
<title id=" P00-1052.xml">the role of centering theorys rough shift in the teaching and evaluation of writing skills </title>
<section> the e-rater centering study.  </section>
<citcontext>
<prevsection>
<prevsent>segment boundaries are ex 4 in fact, similar modi cation has been proposed by hurewitz (1998) and walker (1998) observed that the use of in sentences such as  believe that... ,  think that...  do not aect the focus structure of the text.
</prevsent>
<prevsent>tremely hard to identify in an accurate and principled way.
</prevsent>
</prevsection>
<citsent citstr=" P94-1050 ">
furthermore, existing algorithms (morris and hirst, 1991; <papid> J91-1002 </papid>youmans, 1991; hearst, 1994; <papid> P94-1002 </papid>kozima, 1993; <papid> P93-1041 </papid>reynar,1994; <papid> P94-1050 </papid>passonneau and litman, 1997; <papid> J97-1005 </papid>passonneau, 1998) rely heavily on the assumption of textual coherence.</citsent>
<aftsection>
<nextsent>in our case, textual coherence cannot be assumed.
</nextsent>
<nextsent>given that text organization is also part of the evaluation of the essays, we decided to use the students  paragraph breaks to locate segment boundaries.
</nextsent>
<nextsent>6.2 implementation.
</nextsent>
<nextsent>for this study, we decided to manually tagcoreferring expressions despite the availability of coreference algorithms.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q711">
<title id=" P00-1052.xml">the role of centering theorys rough shift in the teaching and evaluation of writing skills </title>
<section> the e-rater centering study.  </section>
<citcontext>
<prevsection>
<prevsent>segment boundaries are ex 4 in fact, similar modi cation has been proposed by hurewitz (1998) and walker (1998) observed that the use of in sentences such as  believe that... ,  think that...  do not aect the focus structure of the text.
</prevsent>
<prevsent>tremely hard to identify in an accurate and principled way.
</prevsent>
</prevsection>
<citsent citstr=" J97-1005 ">
furthermore, existing algorithms (morris and hirst, 1991; <papid> J91-1002 </papid>youmans, 1991; hearst, 1994; <papid> P94-1002 </papid>kozima, 1993; <papid> P93-1041 </papid>reynar,1994; <papid> P94-1050 </papid>passonneau and litman, 1997; <papid> J97-1005 </papid>passonneau, 1998) rely heavily on the assumption of textual coherence.</citsent>
<aftsection>
<nextsent>in our case, textual coherence cannot be assumed.
</nextsent>
<nextsent>given that text organization is also part of the evaluation of the essays, we decided to use the students  paragraph breaks to locate segment boundaries.
</nextsent>
<nextsent>6.2 implementation.
</nextsent>
<nextsent>for this study, we decided to manually tagcoreferring expressions despite the availability of coreference algorithms.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q712">
<title id=" P04-1038.xml">chinese verb sense discrimination using an em clustering model with rich linguistic features </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>word sense discrimination can be applied to document retrieval and similar tasks in information access, and to facilitating the building of large annotated corpora.
</prevsent>
<prevsent>in addition, since the clustering model can be trained on large unannotated corpora and evaluated on relatively small sense-tagged corpus, it can be used to find indicative features for sense distinctions through exploring huge amount of available unannotated text data.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
the em clustering algorithm (hofmann and puzicha, 1998) used here is an unsupervised machine learning algorithm that has been applied in many nlp tasks, such as inducing semantically labeled lexicon and determining lexical choice in machine translation (rooth et al , 1998), automatic acquisition of verb semantic classes (schulte im walde, 2000) and automatic semantic labeling (gildea and jurafsky, 2002).<papid> J02-3001 </papid></citsent>
<aftsection>
<nextsent>in our task, we equipped the em clustering model with rich linguistic features that capture the predicate-argument structure information of verbs and restricted the feature set for each verb using knowledge from dictionaries.
</nextsent>
<nextsent>we also semi automatically built semantic taxonomy for chinese nouns based on two chinese electronic semantic dictionaries, the hownet dictionary1 and the rocling dictionary.2 the 7 top-level categories of this taxonomy were used as semantic features for the model.
</nextsent>
<nextsent>since external knowledge is used to obtain the semantic features and guide feature selection, the model is not completely unsupervised from this perspective; however, it does not make use of any annotated training data.
</nextsent>
<nextsent>two external quality measures, purity and normalized mutual information (nmi) (strehl.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q713">
<title id=" P04-1038.xml">chinese verb sense discrimination using an em clustering model with rich linguistic features </title>
<section> clustering experiments.  </section>
<citcontext>
<prevsection>
<prevsent>however, we do include senses for conjunctional and/or prepositional usage of two words, ??|dao4?
</prevsent>
<prevsent>and ??|wei4?, since our parser cannot distinguish the verb usage from the conjunctional or prepositional usage for the two words very well.
</prevsent>
</prevsection>
<citsent citstr=" C02-1143 ">
five verbs, the first five listed in table 1, are both highly polysemous and difficult for supervised word sense classifier (dang et al , 2002).<papid> C02-1143 </papid></citsent>
<aftsection>
<nextsent>9 in our experiments, we manually grouped the verb senses for the five verbs.
</nextsent>
<nextsent>the criteria for the grouping are similar to palmer et al (to appear) work on english verbs, which considers both sense coherence and predicate-argument structure distinctions.
</nextsent>
<nextsent>figure 2 gives an example of 9 in the supervised task, their accuracies are lower.
</nextsent>
<nextsent>than 85%, and four of them are even lower than the baselines.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q717">
<title id=" P03-1012.xml">a probability model to improve word alignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this model allows easy integration of context-specific features.
</prevsent>
<prevsent>our experiments show that this model can be an effective tool for improving an existing word alignment.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
word alignments were first introduced as an intermediate result of statistical machine translation systems (brown et al, 1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>since their introduction, many researchers have become interested in word alignments as knowledge source.
</nextsent>
<nextsent>for example, alignments can be used to learn translation lexicons (melamed, 1996), transfer rules (car bonell et al, 2002; menezes and richardson, 2001), <papid> W01-1406 </papid>and classifiers to find safe sentence segmentation points (berger et al, 1996).<papid> J96-1002 </papid></nextsent>
<nextsent>in addition to the ibm models, researchers have proposed number of alternative alignment meth ods.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q718">
<title id=" P03-1012.xml">a probability model to improve word alignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>word alignments were first introduced as an intermediate result of statistical machine translation systems (brown et al, 1993).<papid> J93-2003 </papid></prevsent>
<prevsent>since their introduction, many researchers have become interested in word alignments as knowledge source.</prevsent>
</prevsection>
<citsent citstr=" W01-1406 ">
for example, alignments can be used to learn translation lexicons (melamed, 1996), transfer rules (car bonell et al, 2002; menezes and richardson, 2001), <papid> W01-1406 </papid>and classifiers to find safe sentence segmentation points (berger et al, 1996).<papid> J96-1002 </papid></citsent>
<aftsection>
<nextsent>in addition to the ibm models, researchers have proposed number of alternative alignment methods.
</nextsent>
<nextsent>these methods often involve using statistic such as 2 (gale and church, 1991) <papid> H91-1026 </papid>or the log likelihood ratio (dunning, 1993) <papid> J93-1003 </papid>to create score to measure the strength of correlation between source and target words.</nextsent>
<nextsent>such measures can then be used toguide constrained search to produce word alignments (melamed, 2000).<papid> J00-2004 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q719">
<title id=" P03-1012.xml">a probability model to improve word alignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>word alignments were first introduced as an intermediate result of statistical machine translation systems (brown et al, 1993).<papid> J93-2003 </papid></prevsent>
<prevsent>since their introduction, many researchers have become interested in word alignments as knowledge source.</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
for example, alignments can be used to learn translation lexicons (melamed, 1996), transfer rules (car bonell et al, 2002; menezes and richardson, 2001), <papid> W01-1406 </papid>and classifiers to find safe sentence segmentation points (berger et al, 1996).<papid> J96-1002 </papid></citsent>
<aftsection>
<nextsent>in addition to the ibm models, researchers have proposed number of alternative alignment methods.
</nextsent>
<nextsent>these methods often involve using statistic such as 2 (gale and church, 1991) <papid> H91-1026 </papid>or the log likelihood ratio (dunning, 1993) <papid> J93-1003 </papid>to create score to measure the strength of correlation between source and target words.</nextsent>
<nextsent>such measures can then be used toguide constrained search to produce word alignments (melamed, 2000).<papid> J00-2004 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q721">
<title id=" P03-1012.xml">a probability model to improve word alignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, alignments can be used to learn translation lexicons (melamed, 1996), transfer rules (car bonell et al, 2002; menezes and richardson, 2001), <papid> W01-1406 </papid>and classifiers to find safe sentence segmentation points (berger et al, 1996).<papid> J96-1002 </papid></prevsent>
<prevsent>in addition to the ibm models, researchers have proposed number of alternative alignment meth ods.</prevsent>
</prevsection>
<citsent citstr=" H91-1026 ">
these methods often involve using statistic such as 2 (gale and church, 1991) <papid> H91-1026 </papid>or the log likelihood ratio (dunning, 1993) <papid> J93-1003 </papid>to create score to measure the strength of correlation between source and target words.</citsent>
<aftsection>
<nextsent>such measures can then be used toguide constrained search to produce word alignments (melamed, 2000).<papid> J00-2004 </papid></nextsent>
<nextsent>it has been shown that once baseline alignment has been created, one can improve results by usinga refined scoring metric that is based on the alignment.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q722">
<title id=" P03-1012.xml">a probability model to improve word alignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, alignments can be used to learn translation lexicons (melamed, 1996), transfer rules (car bonell et al, 2002; menezes and richardson, 2001), <papid> W01-1406 </papid>and classifiers to find safe sentence segmentation points (berger et al, 1996).<papid> J96-1002 </papid></prevsent>
<prevsent>in addition to the ibm models, researchers have proposed number of alternative alignment meth ods.</prevsent>
</prevsection>
<citsent citstr=" J93-1003 ">
these methods often involve using statistic such as 2 (gale and church, 1991) <papid> H91-1026 </papid>or the log likelihood ratio (dunning, 1993) <papid> J93-1003 </papid>to create score to measure the strength of correlation between source and target words.</citsent>
<aftsection>
<nextsent>such measures can then be used toguide constrained search to produce word alignments (melamed, 2000).<papid> J00-2004 </papid></nextsent>
<nextsent>it has been shown that once baseline alignment has been created, one can improve results by usinga refined scoring metric that is based on the alignment.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q723">
<title id=" P03-1012.xml">a probability model to improve word alignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in addition to the ibm models, researchers have proposed number of alternative alignment methods.
</prevsent>
<prevsent>these methods often involve using statistic such as 2 (gale and church, 1991) <papid> H91-1026 </papid>or the log likelihood ratio (dunning, 1993) <papid> J93-1003 </papid>to create score to measure the strength of correlation between source and target words.</prevsent>
</prevsection>
<citsent citstr=" J00-2004 ">
such measures can then be used toguide constrained search to produce word alignments (melamed, 2000).<papid> J00-2004 </papid></citsent>
<aftsection>
<nextsent>it has been shown that once baseline alignment has been created, one can improve results by usinga refined scoring metric that is based on the alignment.
</nextsent>
<nextsent>for example melamed uses competitive linking along with an explicit noise model in (melamed, 2000) <papid> J00-2004 </papid>to produce new scoring metric, which in turn creates better alignments.in this paper, we present simple, flexible, statistical model that is designed to capture the information present in baseline alignment.</nextsent>
<nextsent>this model allows us to compute the probability of an alignment forgiven sentence pair.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q728">
<title id=" P03-1012.xml">a probability model to improve word alignment </title>
<section> word-alignment algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>to guide the model to correct alignments, we employ two constraints to limit our search for the most probable alignment.
</prevsent>
<prevsent>the first constraint is the one-to-one constraint (melamed, 2000): <papid> J00-2004 </papid>every word (except the null words e0 and f0) participates in exactly one link.</prevsent>
</prevsection>
<citsent citstr=" W02-1039 ">
the second constraint, known as the cohesion constraint (fox, 2002), <papid> W02-1039 </papid>uses the dependency tree (melcuk, 1987) of the english sentence to restrict possible link combinations.</citsent>
<aftsection>
<nextsent>given the dependency tree te , the alignment can induce dependency tree for (hwa et al, 2002).<papid> P02-1050 </papid></nextsent>
<nextsent>the cohesion constraint requires that this induced dependency tree does not have any crossing dependencies.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q729">
<title id=" P03-1012.xml">a probability model to improve word alignment </title>
<section> word-alignment algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>the first constraint is the one-to-one constraint (melamed, 2000): <papid> J00-2004 </papid>every word (except the null words e0 and f0) participates in exactly one link.</prevsent>
<prevsent>the second constraint, known as the cohesion constraint (fox, 2002), <papid> W02-1039 </papid>uses the dependency tree (melcuk, 1987) of the english sentence to restrict possible link combinations.</prevsent>
</prevsection>
<citsent citstr=" P02-1050 ">
given the dependency tree te , the alignment can induce dependency tree for (hwa et al, 2002).<papid> P02-1050 </papid></citsent>
<aftsection>
<nextsent>the cohesion constraint requires that this induced dependency tree does not have any crossing dependencies.
</nextsent>
<nextsent>the details about how the cohesion constraint is implemented are outside the scope of this paper.3 here we will use simple example to illustrate the effect of the constraint.
</nextsent>
<nextsent>consider the partial alignment in figure 2.
</nextsent>
<nextsent>when the system attempts to link of and de, the new link will induce the dotted dependency, which crosses previously induced dependency between service and donnees.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q730">
<title id=" P03-1012.xml">a probability model to improve word alignment </title>
<section> word-alignment algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>the first feature3the algorithm for checking the cohesion constraint is presented in separate paper which is currently under review.
</prevsent>
<prevsent>the host discovers all the devices det subj pre det obj  hte repre tous les priphriques 1 2 3 4 5 1 2 3 4 5 6 6 the host locate all the peripherals figure 3: feature extraction example type fta concerns surrounding links.
</prevsent>
</prevsection>
<citsent citstr=" C96-2141 ">
it has been observed that words close to each other in the source language tend to remain close to each other in the translation (vogel et al, 1996; <papid> C96-2141 </papid>ker and change, 1997).</citsent>
<aftsection>
<nextsent>to capture this notion, for any word pair (ei, fj), if link l(ei?
</nextsent>
<nextsent>, fj?)
</nextsent>
<nextsent>exists where i?
</nextsent>
<nextsent>2 ? i? ? + 2 and ? 2 ? j? ? + 2, then we say that the feature fta(ii?, jj?, ei?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q733">
<title id=" P03-1012.xml">a probability model to improve word alignment </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>when training from the alignments produced by our model, we normalize (s|e,f ) so that ? ss (s|e,f ) = 1.
</prevsent>
<prevsent>we then count links and features in according to these normalized probabilities.
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
we adopted the same evaluation methodology as in (och and ney, 2000), <papid> P00-1056 </papid>which compared alignment outputs with manually aligned sentences.</citsent>
<aftsection>
<nextsent>och and ney classify manual alignments into two categories: sure (s) and possible (p ) (sp ).
</nextsent>
<nextsent>they defined the following metrics to evaluate an alignment a: recall = |as||s| precision = |ap | |p | alignment error rate (aer) = |as|+|ap ||s|+|p | we trained our alignment program with the same 50k pairs of sentences as (och and ney, 2000) <papid> P00-1056 </papid>and tested it on the same 500 manually aligned sen tences.</nextsent>
<nextsent>both the training and testing sentences are from the hansard corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q746">
<title id=" P03-1012.xml">a probability model to improve word alignment </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>6.2 grammatical constraints.
</prevsent>
<prevsent>there have been many recent proposals to leverage syntactic data in word alignment.
</prevsent>
</prevsection>
<citsent citstr=" J97-3002 ">
methods such as (wu, 1997), (<papid> J97-3002 </papid>alshawi et al, 2000) <papid> J00-1004 </papid>and (lopez et al, 2002) employ synchronous parsing procedure to constrain statistical alignment.</citsent>
<aftsection>
<nextsent>the work done in (yamada and knight, 2001) <papid> P01-1067 </papid>measures statistics on operations that transform parse tree from one language into another.</nextsent>
<nextsent>the alignment algorithm described here is incapable of creating alignments that are not one-to-one.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q747">
<title id=" P03-1012.xml">a probability model to improve word alignment </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>6.2 grammatical constraints.
</prevsent>
<prevsent>there have been many recent proposals to leverage syntactic data in word alignment.
</prevsent>
</prevsection>
<citsent citstr=" J00-1004 ">
methods such as (wu, 1997), (<papid> J97-3002 </papid>alshawi et al, 2000) <papid> J00-1004 </papid>and (lopez et al, 2002) employ synchronous parsing procedure to constrain statistical alignment.</citsent>
<aftsection>
<nextsent>the work done in (yamada and knight, 2001) <papid> P01-1067 </papid>measures statistics on operations that transform parse tree from one language into another.</nextsent>
<nextsent>the alignment algorithm described here is incapable of creating alignments that are not one-to-one.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q748">
<title id=" P03-1012.xml">a probability model to improve word alignment </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>there have been many recent proposals to leverage syntactic data in word alignment.
</prevsent>
<prevsent>methods such as (wu, 1997), (<papid> J97-3002 </papid>alshawi et al, 2000) <papid> J00-1004 </papid>and (lopez et al, 2002) employ synchronous parsing procedure to constrain statistical alignment.</prevsent>
</prevsection>
<citsent citstr=" P01-1067 ">
the work done in (yamada and knight, 2001) <papid> P01-1067 </papid>measures statistics on operations that transform parse tree from one language into another.</citsent>
<aftsection>
<nextsent>the alignment algorithm described here is incapable of creating alignments that are not one-to-one.
</nextsent>
<nextsent>the model we describe, however is not limited in the same manner.
</nextsent>
<nextsent>the model is currently capable of creating many-to-one alignments so long as the null probabilities of the words added on the many?
</nextsent>
<nextsent>side are less than the probabilities of the links that would be created.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q749">
<title id=" P00-1057.xml">multicomponent tag and notions of formal power </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>vp seem vp likely : . . .
</prevsent>
<prevsent>vp likely vp  sleep : john vp to sleep  sleep likely seem figure 4: sl-mctag genera ble derivation unfortunately, unrestricted set-local multicomponent tags not only have more deriva tional generative capacity than tags, butthey also have more weak generative capacity: sl-mctags can generate the quadruple copy language wwww, for example, which does not correspond to any known linguistic phenomenon.
</prevsent>
</prevsection>
<citsent citstr=" P95-1021 ">
other formalisms aiming to model dependency correctly similarly expand weak generative capacity, notably d-tree substitution grammar (rambow et al, 1995), <papid> P95-1021 </papid>and consequently end up with much greater parsing complexity.</citsent>
<aftsection>
<nextsent>the work in this paper follows another figure 5: set-local adjunction.line of research which has focused on squeezing as much strong generative capacity as possible out of weakly tag-equivalent formalisms.
</nextsent>
<nextsent>tree-local multicomponent tag (weir, 1988), nondirectional composition(joshi and vijay-shanker, 1999), and segmented adjunction (kulick, 2000) are examples of this approach, wherein the constraint on weak generative capacity naturally limits the expressivity of these systems.
</nextsent>
<nextsent>we discuss the relation of the formalism of this paper, restricted mctag (r-mctag) with some of these in section 5.
</nextsent>
<nextsent>2.1 restricting set-local mctag.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q750">
<title id=" P00-1057.xml">multicomponent tag and notions of formal power </title>
<section> formalism.  </section>
<citcontext>
<prevsection>
<prevsent> if two tree sets adjoin into the same tree,the two site-segments must be simultaneously removable.
</prevsent>
<prevsent>that is, the two site segments must be disjoint, or one must contain the other.
</prevsent>
</prevsection>
<citsent citstr=" E91-1005 ">
because of the rst restriction, we depict tree sets with the components connected bya dominance link (dotted line), in the manner of (becker et al, 1991).<papid> E91-1005 </papid></citsent>
<aftsection>
<nextsent>as written, the above rules only allow tree-local adjunction;we can generalize them to allow set-local adjunction by treating this dominance link like an ordinary arc. but this would increase the weak generative capacity of the system.
</nextsent>
<nextsent>for present purposes it is sucient just to allow one type of set-local adjunction: adjoin the upper tree to the upper foot, and the lower tree to the lower root (see figure 5).
</nextsent>
<nextsent>this does not increase the weak generative capacity, as will be shown in section 2.3.
</nextsent>
<nextsent>observe that the set-local tag given in figure 5 obeys the above restrictions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q751">
<title id=" P00-1057.xml">multicomponent tag and notions of formal power </title>
<section> formalism.  </section>
<citcontext>
<prevsection>
<prevsent>the tree set of hg;g 0 i, (hg;g 0 i), is g [t (g 0 )], where g is the yield function of and (g 0 ) is the tree set of 0 . thus, the.
</prevsent>
<prevsent>elementary trees of 0 are combined to form derived tree, which is then interpreted as derivation tree for g, which gives instructions for combining elementary trees of into the nal derived tree.
</prevsent>
</prevsection>
<citsent citstr=" P99-1011 ">
it was shown in dras (1999) <papid> P99-1011 </papid>that when the meta-level grammar is in the regular form of rogers (1994) <papid> P94-1022 </papid>the formalism is weakly equivalent to tag.</citsent>
<aftsection>
<nextsent>2.3 reducing restricted r-mctag.
</nextsent>
<nextsent>to rf-2ltag consider the case of multicomponent tree set 1 ; 2 adjoining into an initial tree (figure 6).
</nextsent>
<nextsent>recall that we de ned site segment of pair of adjunction sites to be all the nodes which are dominated by the upper site but not the lower site.
</nextsent>
<nextsent>imagine that the site-segment  is excised from , and that 1 and 2 are fused into single elementary tree.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q752">
<title id=" P00-1057.xml">multicomponent tag and notions of formal power </title>
<section> formalism.  </section>
<citcontext>
<prevsection>
<prevsent>the tree set of hg;g 0 i, (hg;g 0 i), is g [t (g 0 )], where g is the yield function of and (g 0 ) is the tree set of 0 . thus, the.
</prevsent>
<prevsent>elementary trees of 0 are combined to form derived tree, which is then interpreted as derivation tree for g, which gives instructions for combining elementary trees of into the nal derived tree.
</prevsent>
</prevsection>
<citsent citstr=" P94-1022 ">
it was shown in dras (1999) <papid> P99-1011 </papid>that when the meta-level grammar is in the regular form of rogers (1994) <papid> P94-1022 </papid>the formalism is weakly equivalent to tag.</citsent>
<aftsection>
<nextsent>2.3 reducing restricted r-mctag.
</nextsent>
<nextsent>to rf-2ltag consider the case of multicomponent tree set 1 ; 2 adjoining into an initial tree (figure 6).
</nextsent>
<nextsent>recall that we de ned site segment of pair of adjunction sites to be all the nodes which are dominated by the upper site but not the lower site.
</nextsent>
<nextsent>imagine that the site-segment  is excised from , and that 1 and 2 are fused into single elementary tree.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q760">
<title id=" P03-1065.xml">an expert lexicon approach to identifying english phrasal verbs </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper presents finite state approach that integrates phrasal verb expert lexicon between shallow parsing and deep parsing to handle morpho-syntactic interaction.
</prevsent>
<prevsent>with precision/recall combined performance benchmarked consistently at 95.8%-97.5%, the phrasal verb identification problem has basically been solved with the presented method.
</prevsent>
</prevsection>
<citsent citstr=" C96-2182 ">
any natural language processing (nlp) system needs to address the issue of handling multiword expressions, including phrasal verbs (pv) [sag et al  2002; breidt et al  1996].<papid> C96-2182 </papid></citsent>
<aftsection>
<nextsent>this paper presents proven approach to identifying english pvs based on pattern matching using formalism called expert lexicon.
</nextsent>
<nextsent>phrasal verbs are an important feature of the english language since they form about one third of the english verb vocabulary.
</nextsent>
<nextsent>1 properly 1 for the verb vocabulary of our system based on.
</nextsent>
<nextsent>machine-readable dictionaries and two phrasal verb dictionaries, phrasal verb entries constitute 33.8% of the entries.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q761">
<title id=" P03-1065.xml">an expert lexicon approach to identifying english phrasal verbs </title>
<section> expert lexicon approach.  </section>
<citcontext>
<prevsection>
<prevsent>4 both hand-crafted rules and statistical learning.
</prevsent>
<prevsent>english parsing is divided into two tasks: shallow parsing and deep parsing.
</prevsent>
</prevsection>
<citsent citstr=" A88-1019 ">
the shallow parser constructs verb groups (vgs) and basic noun phrases (nps), also called basenps [church 1988].<papid> A88-1019 </papid></citsent>
<aftsection>
<nextsent>the deep parser utilizes syntactic subcategorization features and semantic features of head (e.g., vg) to decode both syntactic and logical dependency relationships such as verb-subject, verb-object, head-modifier, etc. part-of-speech (pos) tagging general lexicon lexical lookup named entity (ne) taggig shallow parsing pv identification deep parsing general lexicon pv expert lexicon figure 1.
</nextsent>
<nextsent>system architecture the general lexicon lookup component involves stemming that transforms regular or irregular inflected verbs into the base forms to facilitate the later phrasal verb matching.
</nextsent>
<nextsent>this component also performs indexing of the word occurrences in the processed document for subsequent expert lexicons.
</nextsent>
<nextsent>the pv identification module is placed between the shallow parser and the deep parser.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q762">
<title id=" N12-2007.xml">domain specific semantic relatedness from wikipedia can a course be transferred </title>
<section> related research.  </section>
<citcontext>
<prevsection>
<prevsent>both accuracy and correlation indicate that our approach outperforms previous work.
</prevsent>
<prevsent>semantic relatedness has been used in applications such as word sense disambiguation, named entity disambiguation, text summarization and annotation, lexical selection, automatic spelling correction, and text structure evaluation.
</prevsent>
</prevsection>
<citsent citstr=" J06-1003 ">
wordnet is commonly used as lexicographic resource to calculate semantic relatedness (budanitsky and hirst, 2006).<papid> J06-1003 </papid>a wordnet-based method uses one or more edge counting techniques in the wordnet taxonomy (lea cock and chodorow, 1998; hirst and st-onge, 1998).</citsent>
<aftsection>
<nextsent>the relatedness of two concept nodes is function of the minimum number of hops between them.
</nextsent>
<nextsent>some related work calculates co-occurrence onone or more large corpora to deduce semantic relatedness (sahami and heilman, 2006; cilibrasi and vitanyi, 2007).
</nextsent>
<nextsent>two words are likely to be related if they co-occur within similar contexts (lin, 1998).others combine lexicographic resources with corpus statistics (jiang and conrath, 1997).
</nextsent>
<nextsent>it has been shown that these composite methods generally out perform lexicographic resource- and corpus- based methods (budanitsky and hirst, 2006; <papid> J06-1003 </papid>curran, 2004; mohammad, 2008).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q764">
<title id=" N12-2007.xml">domain specific semantic relatedness from wikipedia can a course be transferred </title>
<section> related research.  </section>
<citcontext>
<prevsection>
<prevsent>it has been shown that these composite methods generally out perform lexicographic resource- and corpus- based methods (budanitsky and hirst, 2006; <papid> J06-1003 </papid>curran, 2004; mohammad, 2008).</prevsent>
<prevsent>li et al (2006) propose hybrid method based on wordnet and the brown corpus to incorporate semantic similarity between words, semantic similarity between sentences, and word order similarity to measure the overall sentence similarity.</prevsent>
</prevsection>
<citsent citstr=" W11-1418 ">
yang and heines (2011) <papid> W11-1418 </papid>modify this work to suggest transfer course equivalencies, but the experiment is based on non-technical courses.</citsent>
<aftsection>
<nextsent>due to the wordnet sparsity on technical terms, the experiment does not perform well on computer science courses.
</nextsent>
<nextsent>36 in recent years, there has been increasing interest in applying wikipedia and related resources to question answering (buscaldi and rosso, 2006), word sense disambiguation (wsd) (mihalcea and cso mai, 2007), name entity disambiguation (ni et al,2010), ontology evaluation (yu et al, 2007), semantic web (wu, 2010), and computing semantic relatedness (ponzetto and strube, 2007).
</nextsent>
<nextsent>ponzetto and strube (2007) deduce semantic relatedness of words by modeling relations on the wikipedia categorygraph.
</nextsent>
<nextsent>gabrilovich and markovitch (2009) introduce the explicit semantic analysis (esa) model which calculates tf-idf (manning et al, 2008) values for every word in wikipedia and further uses local linkage information to build second-level semantic interpreter.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q765">
<title id=" P04-1017.xml">improving pronoun resolution by incorporating coreferential information of candidates </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we further discuss how to apply our model in real resolution where the antecedents of the candidate are found by separate noun phrase resolution module.
</prevsent>
<prevsent>the experimental results show that our model still achieves better performance than the baseline.
</prevsent>
</prevsection>
<citsent citstr=" W98-1119 ">
in recent years, supervised machine learning approaches have been widely explored in reference resolution and achieved considerable success (ge et al, 1998; <papid> W98-1119 </papid>soon et al, 2001; ng and cardie, 2002; strube and muller, 2003; yang etal., 2003).</citsent>
<aftsection>
<nextsent>most learning-based pronoun resolution systems determine the reference relationship between an anaphor and its antecedent candidate only from the properties of the pair.
</nextsent>
<nextsent>the knowledge about the context of anaphora nd antecedent is nevertheless ignored.
</nextsent>
<nextsent>how ever, research in centering theory (sidner, 1981; grosz et al, 1983; <papid> P83-1007 </papid>grosz et al, 1995; <papid> J95-2003 </papid>tetreault, 2001) has revealed that the local focusing (orcentering) also has great effect on the processing of pronominal expressions.</nextsent>
<nextsent>the choices of the antecedents of pronouns usually depend on the center of attention throughout the local discourse segment (mitkov, 1999).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q766">
<title id=" P04-1017.xml">improving pronoun resolution by incorporating coreferential information of candidates </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>most learning-based pronoun resolution systems determine the reference relationship between an anaphor and its antecedent candidate only from the properties of the pair.
</prevsent>
<prevsent>the knowledge about the context of anaphora nd antecedent is nevertheless ignored.
</prevsent>
</prevsection>
<citsent citstr=" P83-1007 ">
how ever, research in centering theory (sidner, 1981; grosz et al, 1983; <papid> P83-1007 </papid>grosz et al, 1995; <papid> J95-2003 </papid>tetreault, 2001) has revealed that the local focusing (orcentering) also has great effect on the processing of pronominal expressions.</citsent>
<aftsection>
<nextsent>the choices of the antecedents of pronouns usually depend on the center of attention throughout the local discourse segment (mitkov, 1999).
</nextsent>
<nextsent>to determine the salience of candidate in the local context, we may need to check the coreferential information of the candidate,such as the existence and properties of its antecedents.
</nextsent>
<nextsent>in fact, such information has been used for pronoun resolution in many heuristic based systems.
</nextsent>
<nextsent>the s-list model (strube, 1998), for example, assumes that co-referring candidate is hearer-old discourse entity and is preferred to other hearer-new candidates.in the algorithms based on the centering theory (brennan et al, 1987; <papid> P87-1022 </papid>grosz et al, 1995), <papid> J95-2003 </papid>ifa candidate and its antecedent are the backward looking centers of two subsequent utterances respectively, the candidate would be the most preferred since the continue transition is always ranked higher than shift or retain.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q767">
<title id=" P04-1017.xml">improving pronoun resolution by incorporating coreferential information of candidates </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>most learning-based pronoun resolution systems determine the reference relationship between an anaphor and its antecedent candidate only from the properties of the pair.
</prevsent>
<prevsent>the knowledge about the context of anaphora nd antecedent is nevertheless ignored.
</prevsent>
</prevsection>
<citsent citstr=" J95-2003 ">
how ever, research in centering theory (sidner, 1981; grosz et al, 1983; <papid> P83-1007 </papid>grosz et al, 1995; <papid> J95-2003 </papid>tetreault, 2001) has revealed that the local focusing (orcentering) also has great effect on the processing of pronominal expressions.</citsent>
<aftsection>
<nextsent>the choices of the antecedents of pronouns usually depend on the center of attention throughout the local discourse segment (mitkov, 1999).
</nextsent>
<nextsent>to determine the salience of candidate in the local context, we may need to check the coreferential information of the candidate,such as the existence and properties of its antecedents.
</nextsent>
<nextsent>in fact, such information has been used for pronoun resolution in many heuristic based systems.
</nextsent>
<nextsent>the s-list model (strube, 1998), for example, assumes that co-referring candidate is hearer-old discourse entity and is preferred to other hearer-new candidates.in the algorithms based on the centering theory (brennan et al, 1987; <papid> P87-1022 </papid>grosz et al, 1995), <papid> J95-2003 </papid>ifa candidate and its antecedent are the backward looking centers of two subsequent utterances respectively, the candidate would be the most preferred since the continue transition is always ranked higher than shift or retain.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q768">
<title id=" P04-1017.xml">improving pronoun resolution by incorporating coreferential information of candidates </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>to determine the salience of candidate in the local context, we may need to check the coreferential information of the candidate,such as the existence and properties of its antecedents.
</prevsent>
<prevsent>in fact, such information has been used for pronoun resolution in many heuristic based systems.
</prevsent>
</prevsection>
<citsent citstr=" P87-1022 ">
the s-list model (strube, 1998), for example, assumes that co-referring candidate is hearer-old discourse entity and is preferred to other hearer-new candidates.in the algorithms based on the centering theory (brennan et al, 1987; <papid> P87-1022 </papid>grosz et al, 1995), <papid> J95-2003 </papid>ifa candidate and its antecedent are the backward looking centers of two subsequent utterances respectively, the candidate would be the most preferred since the continue transition is always ranked higher than shift or retain.</citsent>
<aftsection>
<nextsent>in this paper, we present supervised learning-based pronoun resolution system which incorporates coreferential information of candidates in trainable model.
</nextsent>
<nextsent>for each candidate, we take into consideration the properties of its antecedents in terms of features (hence forth backward features), and use the supervised learning method to explore their influences on pronoun resolution.
</nextsent>
<nextsent>in the study, we start our exploration on the capability of the model by applying it in an ideal environment where the antecedents of the candidates are correctly identified and the backward features are optimally set.
</nextsent>
<nextsent>the experiments on muc-6 (1995) and muc-7 (1998) corpora show that incorporating coreferential information of candidates boosts the system performance significantly.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q774">
<title id=" P04-1017.xml">improving pronoun resolution by incorporating coreferential information of candidates </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>(2003) also take into consideration the contextual clues in their coreference resolution system, by using two features to reflect the ranking order of candidate in salience reference list (srl).
</prevsent>
<prevsent>however, similar to common centering models, in their system the ranking of entities in srl is also heuristic-based.
</prevsent>
</prevsection>
<citsent citstr=" P98-2143 ">
the coreferential chain length of candidate, or its variants such as occurrence frequency and tfidf, has been used as salience factor insome learning-based reference resolution systems (iida et al, 2003; mitkov, 1998; <papid> P98-2143 </papid>paul et al., 1999; strube and muller, 2003).</citsent>
<aftsection>
<nextsent>however,for an entity, the coreferential length only reflects its global salience in the whole text(s), instead of the local salience in discourse segment which is nevertheless more informative for pronoun resolution.
</nextsent>
<nextsent>moreover, during resolution,the found coreferential length of an entity is of ten incomplete, and thus the obtained length value is usually inaccurate for the salience evaluation.
</nextsent>
<nextsent>in this paper we have proposed model which incorporates coreferential information of candidates to improve pronoun resolution.
</nextsent>
<nextsent>when evaluating candidate, the model considers its adjacent antecedent by describing its properties in terms of backward features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q775">
<title id=" P03-1054.xml">accurate un lexicalized parsing </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>we used the first 20 files (393 sentences) of section 22 as development set(devset).
</prevsent>
<prevsent>this set is small enough that there is noticeable variance in individual results, but it allowed rapid search for good features via continually repars ing the devset in partially manual hill-climb.
</prevsent>
</prevsection>
<citsent citstr=" J98-4004 ">
all of section 23 was used as test set for the final model.for each model, input trees were annotated or transformed in some way, as in johnson (1998).<papid> J98-4004 </papid></citsent>
<aftsection>
<nextsent>given set of transformed trees, we viewed the local trees as grammar rewrite rules in the standard way, and used (unsmoothed) maximum-likelihood estimates for rule probabilities.5 to parse the grammar, we used simple array-based java implementation of generalized cky parser, which, for our final best model, was able to exhaustively parse all sentence sin section 23 in 1gb of memory, taking approximately 3 sec for average length sentences.6 5the tagging probabilities were smoothed to accommodate unknown words.
</nextsent>
<nextsent>the quantity p(tag|word) was estimated as follows: words were split into one of several categories word class, based on capitalization, suffix, digit, and other character features.
</nextsent>
<nextsent>for each of these categories, we took themaximum-likelihood estimate of p(tag|wordclass).
</nextsent>
<nextsent>this distribution was used as prior against which observed taggings, if any, were taken, giving p(tag|word) = [c(tag, word) + ? p(tag|wordclass)]/[c(word)+?].
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q780">
<title id=" P03-1054.xml">accurate un lexicalized parsing </title>
<section> external vs. internal annotation.  </section>
<citcontext>
<prevsection>
<prevsent>both kinds of annotation can be useful.
</prevsent>
<prevsent>to identify split states, we add suffixes of the form -x to mark internal content features, and to mark external features.to illustrate the difference, consider unary productions.
</prevsent>
</prevsection>
<citsent citstr=" P01-1044 ">
in the raw grammar, there are many unar ies, and once any major category is constructed overa span, most others become constructible as well using unary chains (see klein and manning (2001) <papid> P01-1044 </papid>for discussion).</citsent>
<aftsection>
<nextsent>such chains are rare in real treebank trees: unary rewrites only appear in very specific contexts, for example complements of verbs where the has an empty, controlled subject.
</nextsent>
<nextsent>figure 4 shows an erroneous output of the parser, using the baseline markov ized grammar.
</nextsent>
<nextsent>intuitively, there are several reasons this parse should be ruled out, butone is that the lower slot, which is intended primarily for complements of communication verbs, is not unary rewrite position (such complements usually have subjects).
</nextsent>
<nextsent>it would therefore be natural to annotate the trees so as to confine unary productions to the contexts in which they are actually appropriate.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q781">
<title id=" P03-1054.xml">accurate un lexicalized parsing </title>
<section> head annotation.  </section>
<citcontext>
<prevsection>
<prevsent>in particular, this also accomplished charniaks gerund-vp marking.
</prevsent>
<prevsent>this was extremely useful, bringing the cumulative f1 to 85.72%, 2.66%absolute improvement (more than its solo improvement over the baseline).
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
12this is part of the explanation of why (charniak, 2000) <papid> A00-2018 </papid>finds that early generation of head tags as in (collins, 1999) is so beneficial.</citsent>
<aftsection>
<nextsent>the rest of the benefit is presumably in the availability of the tags for smoothing purposes.
</nextsent>
<nextsent>error analysis at this point suggested that many remaining errors were attachment level and conjunction scope.
</nextsent>
<nextsent>while these kinds of errors are undoubtedly profitable targets for lexical preference, most attachment mistakes were overly high attachments, indicating that the overall right-branching tendency of english was not being captured.
</nextsent>
<nextsent>indeed, this tendency is difficult trend to capture in pcfg be cause often the high and low attachments involve the very same rules.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q782">
<title id=" P03-1054.xml">accurate un lexicalized parsing </title>
<section> distance.  </section>
<citcontext>
<prevsection>
<prevsent>the concrete use of grammar rule is to take two adjacent span-marked labels and combine them (for example np[0,5] and vp[5,12] into s[0,12]).
</prevsent>
<prevsent>yet, only the labels are used to score the combination.
</prevsent>
</prevsection>
<citsent citstr=" P95-1037 ">
length ? 40 lp lr f1 exact cb 0 cb magerman (1995) <papid> P95-1037 </papid>84.9 84.6 1.26 56.6 collins (1996) <papid> P96-1025 </papid>86.3 85.8 1.14 59.9 this paper 86.9 85.7 86.3 30.9 1.10 60.3 charniak (1997) 87.4 87.5 1.00 62.1 collins (1999) 88.7 88.6 0.90 67.1 length ? 100 lp lr f1 exact cb 0 cb this paper 86.3 85.1 85.7 28.8 1.31 57.2 figure 8: results of the final model on the test set (section 23).</citsent>
<aftsection>
<nextsent>capture this, dominates-v marks all nodes which dominate any verbal node (v*, md) with -v.
</nextsent>
<nextsent>this brought the cumulative f1 to 86.91%.
</nextsent>
<nextsent>we also tried marking nodes which dominated prepositions and/orconjunctions, but these features did not help the cumulative hill-climb.
</nextsent>
<nextsent>the final distance/depth feature we used was an explicit attempt to model depth, rather than use distance and linear intervention as proxy.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q783">
<title id=" P03-1054.xml">accurate un lexicalized parsing </title>
<section> distance.  </section>
<citcontext>
<prevsection>
<prevsent>the concrete use of grammar rule is to take two adjacent span-marked labels and combine them (for example np[0,5] and vp[5,12] into s[0,12]).
</prevsent>
<prevsent>yet, only the labels are used to score the combination.
</prevsent>
</prevsection>
<citsent citstr=" P96-1025 ">
length ? 40 lp lr f1 exact cb 0 cb magerman (1995) <papid> P95-1037 </papid>84.9 84.6 1.26 56.6 collins (1996) <papid> P96-1025 </papid>86.3 85.8 1.14 59.9 this paper 86.9 85.7 86.3 30.9 1.10 60.3 charniak (1997) 87.4 87.5 1.00 62.1 collins (1999) 88.7 88.6 0.90 67.1 length ? 100 lp lr f1 exact cb 0 cb this paper 86.3 85.1 85.7 28.8 1.31 57.2 figure 8: results of the final model on the test set (section 23).</citsent>
<aftsection>
<nextsent>capture this, dominates-v marks all nodes which dominate any verbal node (v*, md) with -v.
</nextsent>
<nextsent>this brought the cumulative f1 to 86.91%.
</nextsent>
<nextsent>we also tried marking nodes which dominated prepositions and/orconjunctions, but these features did not help the cumulative hill-climb.
</nextsent>
<nextsent>the final distance/depth feature we used was an explicit attempt to model depth, rather than use distance and linear intervention as proxy.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q784">
<title id=" P00-1041.xml">headline generation based on statistical translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>it does so by building statistical models for content selection and surface realization.
</prevsent>
<prevsent>this paper reviews the framework,discusses some of the pros and cons of this approach using examples from our corpus of news wire stories, and presents an initial evaluation.
</prevsent>
</prevsection>
<citsent citstr=" W97-0713 ">
most previous work on summarization focused on extractive methods, investigating issues suchas cue phrases (luhn, 1958), positional indicators (edmundson, 1964), lexical occurrence statistics (mathis et al , 1973), probabilistic measures for token salience (salton et al , 1997), and the use of implicit discourse structure (marcu,1997).<papid> W97-0713 </papid></citsent>
<aftsection>
<nextsent>work on combining an information extraction phase followed by generation has also been reported: for instance, the frump system (dejong, 1982) used templates for both in 1: time -3.76 beam 40 2: new customers -4.41 beam 81 3: dell computer products -5.30 beam 88 4: new power macs strategy -6.04 beam 90 5: apple to sell macintosh users -8.20 beam 86 6: new power macs strategy on internet -9.35 beam 88 7: apple to sell power macs distribution strategy -10.32 beam 89 8: new power macs distribution strategy on internet products -11.81 beam 88 9: apple to sell power macs distribution strategy on internet -13.09 beam 86 figure 1: sample output from the system for variety of target summary lengths from single input document.
</nextsent>
<nextsent>formation extraction and presentation.
</nextsent>
<nextsent>more recently, summarizers using sophisticated post extraction strategies, such as revision (mckeown et al , 1999; jing and mckeown, 1999; mani etal., 1999), <papid> P99-1072 </papid>and sophisticated grammar-based generation (radev and mckeown, 1998) <papid> J98-3005 </papid>have also been presented.</nextsent>
<nextsent>the work reported in this paper is most closely related to work on statistical machine translation, particularly the ibm-style?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q785">
<title id=" P00-1041.xml">headline generation based on statistical translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>work on combining an information extraction phase followed by generation has also been reported: for instance, the frump system (dejong, 1982) used templates for both in 1: time -3.76 beam 40 2: new customers -4.41 beam 81 3: dell computer products -5.30 beam 88 4: new power macs strategy -6.04 beam 90 5: apple to sell macintosh users -8.20 beam 86 6: new power macs strategy on internet -9.35 beam 88 7: apple to sell power macs distribution strategy -10.32 beam 89 8: new power macs distribution strategy on internet products -11.81 beam 88 9: apple to sell power macs distribution strategy on internet -13.09 beam 86 figure 1: sample output from the system for variety of target summary lengths from single input document.
</prevsent>
<prevsent>formation extraction and presentation.
</prevsent>
</prevsection>
<citsent citstr=" P99-1072 ">
more recently, summarizers using sophisticated post extraction strategies, such as revision (mckeown et al , 1999; jing and mckeown, 1999; mani etal., 1999), <papid> P99-1072 </papid>and sophisticated grammar-based generation (radev and mckeown, 1998) <papid> J98-3005 </papid>have also been presented.</citsent>
<aftsection>
<nextsent>the work reported in this paper is most closely related to work on statistical machine translation, particularly the ibm-style?
</nextsent>
<nextsent>work on candide (brown et al , 1993).<papid> J93-2003 </papid></nextsent>
<nextsent>this approach was based on statistical translation model that mapped between sets of words in source language and sets of words in target language, atthe same time using an ordering model to constrain possible token sequences in target language based on likelihood.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q786">
<title id=" P00-1041.xml">headline generation based on statistical translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>work on combining an information extraction phase followed by generation has also been reported: for instance, the frump system (dejong, 1982) used templates for both in 1: time -3.76 beam 40 2: new customers -4.41 beam 81 3: dell computer products -5.30 beam 88 4: new power macs strategy -6.04 beam 90 5: apple to sell macintosh users -8.20 beam 86 6: new power macs strategy on internet -9.35 beam 88 7: apple to sell power macs distribution strategy -10.32 beam 89 8: new power macs distribution strategy on internet products -11.81 beam 88 9: apple to sell power macs distribution strategy on internet -13.09 beam 86 figure 1: sample output from the system for variety of target summary lengths from single input document.
</prevsent>
<prevsent>formation extraction and presentation.
</prevsent>
</prevsection>
<citsent citstr=" J98-3005 ">
more recently, summarizers using sophisticated post extraction strategies, such as revision (mckeown et al , 1999; jing and mckeown, 1999; mani etal., 1999), <papid> P99-1072 </papid>and sophisticated grammar-based generation (radev and mckeown, 1998) <papid> J98-3005 </papid>have also been presented.</citsent>
<aftsection>
<nextsent>the work reported in this paper is most closely related to work on statistical machine translation, particularly the ibm-style?
</nextsent>
<nextsent>work on candide (brown et al , 1993).<papid> J93-2003 </papid></nextsent>
<nextsent>this approach was based on statistical translation model that mapped between sets of words in source language and sets of words in target language, atthe same time using an ordering model to constrain possible token sequences in target language based on likelihood.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q787">
<title id=" P00-1041.xml">headline generation based on statistical translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>more recently, summarizers using sophisticated post extraction strategies, such as revision (mckeown et al , 1999; jing and mckeown, 1999; mani etal., 1999), <papid> P99-1072 </papid>and sophisticated grammar-based generation (radev and mckeown, 1998) <papid> J98-3005 </papid>have also been presented.</prevsent>
<prevsent>the work reported in this paper is most closely related to work on statistical machine translation, particularly the ibm-style?</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
work on candide (brown et al , 1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>this approach was based on statistical translation model that mapped between sets of words in source language and sets of words in target language, atthe same time using an ordering model to constrain possible token sequences in target language based on likelihood.
</nextsent>
<nextsent>in similar vein,a summarizer can be considered to be tran slat ing?
</nextsent>
<nextsent>between two languages: one verbose and the other succinct (berger and lafferty, 1999; witbrock and mittal, 1999).
</nextsent>
<nextsent>however, by definition, the translation during summarization is lossy, and consequently, somewhat easier to design and experiment with.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q788">
<title id=" P00-1041.xml">headline generation based on statistical translation </title>
<section> 0.2027 14.10% </section>
<citcontext>
<prevsection>
<prevsent>these statistics illustrate the systems performance in selecting content words for the headlines.
</prevsent>
<prevsent>actual headlines are often, also, ungrammatical, incompletephrases.
</prevsent>
</prevsection>
<citsent citstr=" P97-1064 ">
it is likely that more sophisticated language models, such as structure models (chelba,1997; <papid> P97-1064 </papid>chelba and jelinek, 1998), <papid> P98-1035 </papid>or longer gram models would lead to the system generating headlines that were more similar in phrasing to real headlines because longer range dependencies shelf carnegie mellon university summarizer, which was the top ranked extraction based summarizer for news stories at the 1998 darpa-tipster evaluation workshop (tip, 1998).</citsent>
<aftsection>
<nextsent>this summarizer uses weighted combination of sentence position, lexical features and simple syntactical measures such as sentence length to rank sentences.
</nextsent>
<nextsent>the use of this summarizer should not be taken as indicator of its value as testing standard; it has more to do with the ease of use and the fact that it was reasonable candidate.
</nextsent>
<nextsent>overlap with headline overlap with summary lex +position +pos +position+pos lex +position +pos +position+pos 1 0.37414 0.39888 0.30522 0.40538 0.61589 0.70787 0.64919 0.67741 2 0.24818 0.26923 0.27246 0.27838 0.57447 0.63905 0.57831 0.63315 3 0.21831 0.24612 0.20388 0.25048 0.55251 0.63760 0.55610 0.62726 4 0.21404 0.24011 0.18721 0.25741 0.56167 0.65819 0.52982 0.61099 5 0.20272 0.21685 0.18447 0.21947 0.55099 0.63371 0.53578 0.58584 6 0.20804 0.19886 0.17593 0.21168 0.55817 0.60511 0.51466 0.58802 table 2: overlap between terms in the generated headlines and in the original headlines and extracted summary sentences, respectively, of the article.
</nextsent>
<nextsent>using part of speech (pos) and information about atokens location in the source document, in addition to the lexical information, helps improve performance on the reuters?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q789">
<title id=" P00-1041.xml">headline generation based on statistical translation </title>
<section> 0.2027 14.10% </section>
<citcontext>
<prevsection>
<prevsent>these statistics illustrate the systems performance in selecting content words for the headlines.
</prevsent>
<prevsent>actual headlines are often, also, ungrammatical, incompletephrases.
</prevsent>
</prevsection>
<citsent citstr=" P98-1035 ">
it is likely that more sophisticated language models, such as structure models (chelba,1997; <papid> P97-1064 </papid>chelba and jelinek, 1998), <papid> P98-1035 </papid>or longer gram models would lead to the system generating headlines that were more similar in phrasing to real headlines because longer range dependencies shelf carnegie mellon university summarizer, which was the top ranked extraction based summarizer for news stories at the 1998 darpa-tipster evaluation workshop (tip, 1998).</citsent>
<aftsection>
<nextsent>this summarizer uses weighted combination of sentence position, lexical features and simple syntactical measures such as sentence length to rank sentences.
</nextsent>
<nextsent>the use of this summarizer should not be taken as indicator of its value as testing standard; it has more to do with the ease of use and the fact that it was reasonable candidate.
</nextsent>
<nextsent>overlap with headline overlap with summary lex +position +pos +position+pos lex +position +pos +position+pos 1 0.37414 0.39888 0.30522 0.40538 0.61589 0.70787 0.64919 0.67741 2 0.24818 0.26923 0.27246 0.27838 0.57447 0.63905 0.57831 0.63315 3 0.21831 0.24612 0.20388 0.25048 0.55251 0.63760 0.55610 0.62726 4 0.21404 0.24011 0.18721 0.25741 0.56167 0.65819 0.52982 0.61099 5 0.20272 0.21685 0.18447 0.21947 0.55099 0.63371 0.53578 0.58584 6 0.20804 0.19886 0.17593 0.21168 0.55817 0.60511 0.51466 0.58802 table 2: overlap between terms in the generated headlines and in the original headlines and extracted summary sentences, respectively, of the article.
</nextsent>
<nextsent>using part of speech (pos) and information about atokens location in the source document, in addition to the lexical information, helps improve performance on the reuters?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q790">
<title id=" P00-1041.xml">headline generation based on statistical translation </title>
<section> 0.2027 14.10% </section>
<citcontext>
<prevsection>
<prevsent>original term generated term original headline generated headline nations top judge rehnquist wall street stocks decline dow jones index lower kaczynski una bomber suspect 49ers roll over vikings 38-22 49ers to nfc title game er top-rated hospital drama corn, wheat prices fall soybean grain prices lower drugs cocaine many hopeful on n. ireland accord britain ireland hopeful of irish peace table 3: some pairs of target headline and generated summary terms that were counted as errors by the evaluation, but which are semantically equivalent, together with some equally good?
</prevsent>
<prevsent>generated headlines that were counted as wrong in the evaluation.
</prevsent>
</prevsection>
<citsent citstr=" W97-0704 ">
traction (hovy and lin, 1997; <papid> W97-0704 </papid>mittal et al , 1999).</citsent>
<aftsection>
<nextsent>we trained content selection model based on the position of the tokens in the training set in their respective documents.
</nextsent>
<nextsent>there are several models of positional salience that have been proposed for sentence selection; we used the simplest possibleone: estimating the probability of token appearing in the headline given that it appeared in the1st, 2nd, 3rd or 4th quartile of the body of the article.
</nextsent>
<nextsent>we then tested mixtures of the lexical and pos models, lexical and positional models, andall three models combined together.
</nextsent>
<nextsent>sample output for the article in figure 3, using both lexical and pos/positional information can be seenin figure 4.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q791">
<title id=" P01-1041.xml">japanese named entity recognition based on a simple rule generator and decision tree learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it is well known that handcrafted systems are difficult to maintain because it is not easy to predict the effect of small chang ein rule.
</prevsent>
<prevsent>the second approach employs statistical method, which is expected to be more robust and to require less human intervention.
</prevsent>
</prevsection>
<citsent citstr=" W98-1120 ">
several statistical methods have been reported in the literature (bikel et al, 1999; borthwick, 1999; sekine et al, 1998; <papid> W98-1120 </papid>sassano and utsuro, 2000).<papid> C00-2102 </papid></citsent>
<aftsection>
<nextsent>irex (information retrieval and extraction exercise, (sekine and eriguchi, 2000; <papid> C00-2167 </papid>ire,1999)) was held in 1999, and fifteen systems participated in the formal run of the japanese ne excercise.</nextsent>
<nextsent>in the formal run, participants were requested to tag two datasets (general and ar rest), and their scores were compared in terms of f-measure, i.e., the harmonic mean of recall?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q792">
<title id=" P01-1041.xml">japanese named entity recognition based on a simple rule generator and decision tree learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it is well known that handcrafted systems are difficult to maintain because it is not easy to predict the effect of small chang ein rule.
</prevsent>
<prevsent>the second approach employs statistical method, which is expected to be more robust and to require less human intervention.
</prevsent>
</prevsection>
<citsent citstr=" C00-2102 ">
several statistical methods have been reported in the literature (bikel et al, 1999; borthwick, 1999; sekine et al, 1998; <papid> W98-1120 </papid>sassano and utsuro, 2000).<papid> C00-2102 </papid></citsent>
<aftsection>
<nextsent>irex (information retrieval and extraction exercise, (sekine and eriguchi, 2000; <papid> C00-2167 </papid>ire,1999)) was held in 1999, and fifteen systems participated in the formal run of the japanese ne excercise.</nextsent>
<nextsent>in the formal run, participants were requested to tag two datasets (general and ar rest), and their scores were compared in terms of f-measure, i.e., the harmonic mean of recall?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q793">
<title id=" P01-1041.xml">japanese named entity recognition based on a simple rule generator and decision tree learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the second approach employs statistical method, which is expected to be more robust and to require less human intervention.
</prevsent>
<prevsent>several statistical methods have been reported in the literature (bikel et al, 1999; borthwick, 1999; sekine et al, 1998; <papid> W98-1120 </papid>sassano and utsuro, 2000).<papid> C00-2102 </papid></prevsent>
</prevsection>
<citsent citstr=" C00-2167 ">
irex (information retrieval and extraction exercise, (sekine and eriguchi, 2000; <papid> C00-2167 </papid>ire,1999)) was held in 1999, and fifteen systems participated in the formal run of the japanese ne excercise.</citsent>
<aftsection>
<nextsent>in the formal run, participants were requested to tag two datasets (general and ar rest), and their scores were compared in terms of f-measure, i.e., the harmonic mean of recall?
</nextsent>
<nextsent>and precision?
</nextsent>
<nextsent>defined as follows.
</nextsent>
<nextsent>  recall = x/(the number of correct nes)   precision = x/(the number of nes extracted by the system)where is the number of nes correctly extracted and classified by the system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q794">
<title id=" P01-1041.xml">japanese named entity recognition based on a simple rule generator and decision tree learning </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>borthwick (1999) explained the reason for this tendency.
</prevsent>
<prevsent>when he added lexical questions (e.g., whether the current word is fi or not) to sekines system, c4.5 crashed with crl ne.accordingly, the decision tree systems did not directly use words as features.
</prevsent>
</prevsection>
<citsent citstr=" M95-1013 ">
instead, they used words memberships in their word lists.cowie (1995) <papid> M95-1013 </papid>interprets decision tree deterministically and uses heuristic rewriting rules to get consistent results.</citsent>
<aftsection>
<nextsent>balujas system (2000) simply determines whether word is in an ne or not and does not classify it.
</nextsent>
<nextsent>on the other hand, paliouras (2000) uses decision tree learning for classification of noun phrase by assuming that named entities are noun phrases.
</nextsent>
<nextsent>gallippi (1996) <papid> C96-1072 </papid>employs hundreds of hand-crafted templates as features for decision tree learning.</nextsent>
<nextsent>brills rule generation method (brill, 2000) <papid> W00-1301 </papid>is not used for ne tasks, but it might be useful.recently, unsupervised or minimally supervised models have been proposed (collins and singer, 2000; utsuro and sassano, 2000).collins?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q795">
<title id=" P01-1041.xml">japanese named entity recognition based on a simple rule generator and decision tree learning </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>balujas system (2000) simply determines whether word is in an ne or not and does not classify it.
</prevsent>
<prevsent>on the other hand, paliouras (2000) uses decision tree learning for classification of noun phrase by assuming that named entities are noun phrases.
</prevsent>
</prevsection>
<citsent citstr=" C96-1072 ">
gallippi (1996) <papid> C96-1072 </papid>employs hundreds of hand-crafted templates as features for decision tree learning.</citsent>
<aftsection>
<nextsent>brills rule generation method (brill, 2000) <papid> W00-1301 </papid>is not used for ne tasks, but it might be useful.recently, unsupervised or minimally supervised models have been proposed (collins and singer, 2000; utsuro and sassano, 2000).collins?</nextsent>
<nextsent>system is not full ne system and utsuros score is not very good yet, but they represent interesting directions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q796">
<title id=" P01-1041.xml">japanese named entity recognition based on a simple rule generator and decision tree learning </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>on the other hand, paliouras (2000) uses decision tree learning for classification of noun phrase by assuming that named entities are noun phrases.
</prevsent>
<prevsent>gallippi (1996) <papid> C96-1072 </papid>employs hundreds of hand-crafted templates as features for decision tree learning.</prevsent>
</prevsection>
<citsent citstr=" W00-1301 ">
brills rule generation method (brill, 2000) <papid> W00-1301 </papid>is not used for ne tasks, but it might be useful.recently, unsupervised or minimally supervised models have been proposed (collins and singer, 2000; utsuro and sassano, 2000).collins?</citsent>
<aftsection>
<nextsent>system is not full ne system and utsuros score is not very good yet, but they represent interesting directions.
</nextsent>
<nextsent>as far as we can tell, japanese ne recognition technology has not yet matured.
</nextsent>
<nextsent>conventional decision tree systems have not shown good performance.
</nextsent>
<nextsent>the maximum entropy method is competitive, but adding more training data causes problems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q797">
<title id=" P00-1061.xml">lexicalized stochastic modeling of constraint based grammars using loglinear measures and em training </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>stochastic parsing models capturing contextual constraints beyond the dependencies of probabilistic context-free grammars (pcfgs) are currently the subject of intensive research.
</prevsent>
<prevsent>an interesting feature common to most such models is the incorporation of contextual dependencies on individual headwords into rule based probability models.
</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
such word-based lexicalizations of probability models are used successfully in the statistical parsing models of, e.g., collins (1997), <papid> P97-1003 </papid>charniak (1997), or ratnaparkhi (1997).<papid> W97-0301 </papid></citsent>
<aftsection>
<nextsent>however, it is stillan open question which kind of lexicalization, e.g., statistics on individual words or statistics based upon word classes, is the best choice.
</nextsent>
<nextsent>secondly, these approaches have in common the fact that the probability models are trained on treebanks, i.e., corpora of manually disambiguated sentences, and not from corpora of unannotated sentences.
</nextsent>
<nextsent>in all of the cited approaches, the penn wall street journal treebank (marcus et al, 1993) <papid> J93-2004 </papid>is used, the availability of which obviates the standardeort required for treebank traininghand annotating large corpora of specic domains of specic languages with specic parse types.</nextsent>
<nextsent>moreover, common wisdom is that training from unannotated data via the expectation maximization (em) algorithm (dempster et al., 1977) yields poor results unless atleast partial annotation is applied.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q798">
<title id=" P00-1061.xml">lexicalized stochastic modeling of constraint based grammars using loglinear measures and em training </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>stochastic parsing models capturing contextual constraints beyond the dependencies of probabilistic context-free grammars (pcfgs) are currently the subject of intensive research.
</prevsent>
<prevsent>an interesting feature common to most such models is the incorporation of contextual dependencies on individual headwords into rule based probability models.
</prevsent>
</prevsection>
<citsent citstr=" W97-0301 ">
such word-based lexicalizations of probability models are used successfully in the statistical parsing models of, e.g., collins (1997), <papid> P97-1003 </papid>charniak (1997), or ratnaparkhi (1997).<papid> W97-0301 </papid></citsent>
<aftsection>
<nextsent>however, it is stillan open question which kind of lexicalization, e.g., statistics on individual words or statistics based upon word classes, is the best choice.
</nextsent>
<nextsent>secondly, these approaches have in common the fact that the probability models are trained on treebanks, i.e., corpora of manually disambiguated sentences, and not from corpora of unannotated sentences.
</nextsent>
<nextsent>in all of the cited approaches, the penn wall street journal treebank (marcus et al, 1993) <papid> J93-2004 </papid>is used, the availability of which obviates the standardeort required for treebank traininghand annotating large corpora of specic domains of specic languages with specic parse types.</nextsent>
<nextsent>moreover, common wisdom is that training from unannotated data via the expectation maximization (em) algorithm (dempster et al., 1977) yields poor results unless atleast partial annotation is applied.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q799">
<title id=" P00-1061.xml">lexicalized stochastic modeling of constraint based grammars using loglinear measures and em training </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, it is stillan open question which kind of lexicalization, e.g., statistics on individual words or statistics based upon word classes, is the best choice.
</prevsent>
<prevsent>secondly, these approaches have in common the fact that the probability models are trained on treebanks, i.e., corpora of manually disambiguated sentences, and not from corpora of unannotated sentences.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
in all of the cited approaches, the penn wall street journal treebank (marcus et al, 1993) <papid> J93-2004 </papid>is used, the availability of which obviates the standardeort required for treebank traininghand annotating large corpora of specic domains of specic languages with specic parse types.</citsent>
<aftsection>
<nextsent>moreover, common wisdom is that training from unannotated data via the expectation maximization (em) algorithm (dempster et al., 1977) yields poor results unless atleast partial annotation is applied.
</nextsent>
<nextsent>experimental results conrming this wisdom have been presented, e.g., by elworthy (1994) <papid> A94-1009 </papid>and pereira and schabes (1992) <papid> P92-1017 </papid>for em training of hidden markov models and pcfgs.</nextsent>
<nextsent>in this paper, we present new lexicalized stochastic model for constraint-based grammars that employs combination of head word frequencies and em-based clustering for grammar lexicalization.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q800">
<title id=" P00-1061.xml">lexicalized stochastic modeling of constraint based grammars using loglinear measures and em training </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in all of the cited approaches, the penn wall street journal treebank (marcus et al, 1993) <papid> J93-2004 </papid>is used, the availability of which obviates the standardeort required for treebank traininghand annotating large corpora of specic domains of specic languages with specic parse types.</prevsent>
<prevsent>moreover, common wisdom is that training from unannotated data via the expectation maximization (em) algorithm (dempster et al., 1977) yields poor results unless atleast partial annotation is applied.</prevsent>
</prevsection>
<citsent citstr=" A94-1009 ">
experimental results conrming this wisdom have been presented, e.g., by elworthy (1994) <papid> A94-1009 </papid>and pereira and schabes (1992) <papid> P92-1017 </papid>for em training of hidden markov models and pcfgs.</citsent>
<aftsection>
<nextsent>in this paper, we present new lexicalized stochastic model for constraint-based grammars that employs combination of head word frequencies and em-based clustering for grammar lexicalization.
</nextsent>
<nextsent>furthermore, we make crucial use of em for estimating the parameters of the stochastic grammar from unannotated data.
</nextsent>
<nextsent>our usage of em was initiated by the current lack of large unicationbased treebanks for german.
</nextsent>
<nextsent>however, our experimental results also show an exception to the common wisdom of the insuciency of em for highly accurate statistical modeling.our approach to lexicalized stochastic modeling is based on the parametric family of loglinear probability models, which is used to de ne probability distribution on the parses of lexical-functional grammar (lfg) forgerman.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q801">
<title id=" P00-1061.xml">lexicalized stochastic modeling of constraint based grammars using loglinear measures and em training </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in all of the cited approaches, the penn wall street journal treebank (marcus et al, 1993) <papid> J93-2004 </papid>is used, the availability of which obviates the standardeort required for treebank traininghand annotating large corpora of specic domains of specic languages with specic parse types.</prevsent>
<prevsent>moreover, common wisdom is that training from unannotated data via the expectation maximization (em) algorithm (dempster et al., 1977) yields poor results unless atleast partial annotation is applied.</prevsent>
</prevsection>
<citsent citstr=" P92-1017 ">
experimental results conrming this wisdom have been presented, e.g., by elworthy (1994) <papid> A94-1009 </papid>and pereira and schabes (1992) <papid> P92-1017 </papid>for em training of hidden markov models and pcfgs.</citsent>
<aftsection>
<nextsent>in this paper, we present new lexicalized stochastic model for constraint-based grammars that employs combination of head word frequencies and em-based clustering for grammar lexicalization.
</nextsent>
<nextsent>furthermore, we make crucial use of em for estimating the parameters of the stochastic grammar from unannotated data.
</nextsent>
<nextsent>our usage of em was initiated by the current lack of large unicationbased treebanks for german.
</nextsent>
<nextsent>however, our experimental results also show an exception to the common wisdom of the insuciency of em for highly accurate statistical modeling.our approach to lexicalized stochastic modeling is based on the parametric family of loglinear probability models, which is used to de ne probability distribution on the parses of lexical-functional grammar (lfg) forgerman.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q802">
<title id=" P00-1061.xml">lexicalized stochastic modeling of constraint based grammars using loglinear measures and em training </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our usage of em was initiated by the current lack of large unicationbased treebanks for german.
</prevsent>
<prevsent>however, our experimental results also show an exception to the common wisdom of the insuciency of em for highly accurate statistical modeling.our approach to lexicalized stochastic modeling is based on the parametric family of loglinear probability models, which is used to de ne probability distribution on the parses of lexical-functional grammar (lfg) forgerman.
</prevsent>
</prevsection>
<citsent citstr=" P99-1069 ">
in previous work on log-linear models for lfg by johnson et al (1999), <papid> P99-1069 </papid>pseudo likelihood estimation from annotated corpora has been introduced and experimented with on small scale.</citsent>
<aftsection>
<nextsent>however, to our knowledge, to date no large lfg annotated corpora of unrestricted german text are available.
</nextsent>
<nextsent>fortunately, algorithms exist for statistical inference of log-linear models from unannotated data (riezler, 1999).
</nextsent>
<nextsent>we apply this algorithm to estimate log-linear lfg models from large corpora of newspaper text.
</nextsent>
<nextsent>in our largest experiment, we used 250,000 parses which we reproduced by parsing 36,000 newspaper sentences with the german lfg.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q805">
<title id=" P00-1061.xml">lexicalized stochastic modeling of constraint based grammars using loglinear measures and em training </title>
<section> property design and.  </section>
<citcontext>
<prevsection>
<prevsent>]] given the observed data and the current parameter value  0 . 3.2 class-based lexicalization.
</prevsent>
<prevsent>our approach to grammar lexicalization isclass-based in the sense that we use class based estimated frequencies c(v; n) of head verbs and argument head-nouns instead of pure frequency statistics or class based probabilities of head word dependencies.
</prevsent>
</prevsection>
<citsent citstr=" C00-2094 ">
class-based estimated frequencies are introduced in prescher et al (2000) <papid> C00-2094 </papid>as the frequency f(v; n) of (v; n)-pair in the training corpus, weighted by the best estimate of the class-membership probability p(cjv; n) of an em-based clustering model on (v; n)-pairs, i.e., c (v; n) = max c2c p(cjv; n)(f(v; n) + 1).</citsent>
<aftsection>
<nextsent>as is shown in prescher et al (2000) <papid> C00-2094 </papid>in an evaluation on lexical ambiguity resolution, gain of about 7% can be obtained by using the class-based estimated frequency c (v; n)as disambiguation criterion instead of class based probabilities p(njv).</nextsent>
<nextsent>in order to make the most direct use possible of this fact, we incorporated the decisions of the disambigua tor directly into 45 additional properties forthe grammatical relations of the subject, direct object, indirect object, innitival object, oblique and adjunctival dative and accusative preposition, for active and passive forms of the rst three verbs in each parse.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q811">
<title id=" P00-1061.xml">lexicalized stochastic modeling of constraint based grammars using loglinear measures and em training </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>a comparison of models with random or uniform starting values shows an increase in precision of 10% to 40% for the latter.
</prevsent>
<prevsent>in terms of maximization of likelihood, this corresponds to the fact that uniform starting values immediately push the likelihood up to nearly its nal value, whereas random starting values yield an initial likelihood which has to be increased by factors of 2 to 20 to an often lower nal value.
</prevsent>
</prevsection>
<citsent citstr=" A00-2021 ">
the most direct points of comparison of our method are the approaches of johnson et al (1999) <papid> P99-1069 </papid>and johnson and riezler (2000).<papid> A00-2021 </papid></citsent>
<aftsection>
<nextsent>in the rst approach, log-linear models on lfg grammars using about 200 congurational properties were trained on treebanks of about 400 sentences by maximum pseudo-likelihood estimation.
</nextsent>
<nextsent>precision was evaluated on anexact match task in 10-way cross validation paradigm for an ambiguity rate of 10, and achieved 59% for the rst approach.
</nextsent>
<nextsent>johnson and riezler (2000) <papid> A00-2021 </papid>achieved gainof 1% over this result by including class based lexicalization.</nextsent>
<nextsent>our best models clearly outperform these results, both in terms of precision relative to ambiguity and in terms of relative gain due to lexicalization.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q813">
<title id=" P00-1061.xml">lexicalized stochastic modeling of constraint based grammars using loglinear measures and em training </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>johnson and riezler (2000) <papid> A00-2021 </papid>achieved gainof 1% over this result by including class based lexicalization.</prevsent>
<prevsent>our best models clearly outperform these results, both in terms of precision relative to ambiguity and in terms of relative gain due to lexicalization.</prevsent>
</prevsection>
<citsent citstr=" P99-1035 ">
a comparison of performance is more dicult for the lexicalized pcfg of beil et al (1999)<papid> P99-1035 </papid>which was trained by em on 450,000 sentences of german newspaper text.</citsent>
<aftsection>
<nextsent>there, 70.4% precision is reported on verb frame recognition task on 584 examples.
</nextsent>
<nextsent>however, the gain achieved by beil et al (1999)<papid> P99-1035 </papid> due to grammar lexicalizaton is only 2%, compared to about 10% in our case.</nextsent>
<nextsent>a comparison is dicult also for most other state-of-the art pcfg-based statistical parsers, since dierent training and test data, and most importantly, dierent evaluation criteria were used.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q815">
<title id=" P02-1057.xml">a noisy channel model for document compression </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the system outperforms both baseline and sentence-based compression system that operates by simplifying sequentially all sentences in text.
</prevsent>
<prevsent>our results support the claim that discourse knowledge playsan important role in document summarization.
</prevsent>
</prevsection>
<citsent citstr=" P00-1041 ">
single document summarization systems proposed to date fall within one of the following three classes: extractive summarizers simply select and present to the user the most important sentences in text ? see (mani and maybury, 1999; marcu, 2000; mani, 2001) for comprehensive overviews of the methods and algorithms used to accomplish this.headline generators are noisy-channel probabilistic systems that are trained on large corpora of  headline, text  pairs (banko et al, 2000;<papid> P00-1041 </papid>berger and mittal, 2000).<papid> P00-1038 </papid></citsent>
<aftsection>
<nextsent>these systems produce short sequences of words that are indicative of the content of the text given as input.
</nextsent>
<nextsent>sentence simplification systems (chandrasekar et al., 1996; <papid> C96-2183 </papid>mahesh, 1997; carroll et al, 1998; grefenstette, 1998; jing, 2000; <papid> A00-1043 </papid>knight and marcu, 2000) are capable of compressing long sentences by deleting unimportant words and phrases.extraction-based summarizers often produce outputs that contain non-important sentence fragments.</nextsent>
<nextsent>for example, the hypothetical extractive summary of text (1), which is shown in table 1, can be compacted further by deleting the clause which is already almost enough to win?.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q816">
<title id=" P02-1057.xml">a noisy channel model for document compression </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the system outperforms both baseline and sentence-based compression system that operates by simplifying sequentially all sentences in text.
</prevsent>
<prevsent>our results support the claim that discourse knowledge playsan important role in document summarization.
</prevsent>
</prevsection>
<citsent citstr=" P00-1038 ">
single document summarization systems proposed to date fall within one of the following three classes: extractive summarizers simply select and present to the user the most important sentences in text ? see (mani and maybury, 1999; marcu, 2000; mani, 2001) for comprehensive overviews of the methods and algorithms used to accomplish this.headline generators are noisy-channel probabilistic systems that are trained on large corpora of  headline, text  pairs (banko et al, 2000;<papid> P00-1041 </papid>berger and mittal, 2000).<papid> P00-1038 </papid></citsent>
<aftsection>
<nextsent>these systems produce short sequences of words that are indicative of the content of the text given as input.
</nextsent>
<nextsent>sentence simplification systems (chandrasekar et al., 1996; <papid> C96-2183 </papid>mahesh, 1997; carroll et al, 1998; grefenstette, 1998; jing, 2000; <papid> A00-1043 </papid>knight and marcu, 2000) are capable of compressing long sentences by deleting unimportant words and phrases.extraction-based summarizers often produce outputs that contain non-important sentence fragments.</nextsent>
<nextsent>for example, the hypothetical extractive summary of text (1), which is shown in table 1, can be compacted further by deleting the clause which is already almost enough to win?.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q817">
<title id=" P02-1057.xml">a noisy channel model for document compression </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>single document summarization systems proposed to date fall within one of the following three classes: extractive summarizers simply select and present to the user the most important sentences in text ? see (mani and maybury, 1999; marcu, 2000; mani, 2001) for comprehensive overviews of the methods and algorithms used to accomplish this.headline generators are noisy-channel probabilistic systems that are trained on large corpora of  headline, text  pairs (banko et al, 2000;<papid> P00-1041 </papid>berger and mittal, 2000).<papid> P00-1038 </papid></prevsent>
<prevsent>these systems produce short sequences of words that are indicative of the content of the text given as input.</prevsent>
</prevsection>
<citsent citstr=" C96-2183 ">
sentence simplification systems (chandrasekar et al., 1996; <papid> C96-2183 </papid>mahesh, 1997; carroll et al, 1998; grefenstette, 1998; jing, 2000; <papid> A00-1043 </papid>knight and marcu, 2000) are capable of compressing long sentences by deleting unimportant words and phrases.extraction-based summarizers often produce outputs that contain non-important sentence fragments.</citsent>
<aftsection>
<nextsent>for example, the hypothetical extractive summary of text (1), which is shown in table 1, can be compacted further by deleting the clause which is already almost enough to win?.
</nextsent>
<nextsent>headline-based summaries, such as that shown in table 1, are usually indicative of texts content but not informative, grammatical, or coherent.
</nextsent>
<nextsent>by repeatedly applying sentence-simplification algorithm one sentence at atime, one can compress text; yet, the outputs generated in this way are likely to be incoherent andto contain unimportant information.
</nextsent>
<nextsent>when summarizing text, some sentences should be dropped altogether.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q818">
<title id=" P02-1057.xml">a noisy channel model for document compression </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>single document summarization systems proposed to date fall within one of the following three classes: extractive summarizers simply select and present to the user the most important sentences in text ? see (mani and maybury, 1999; marcu, 2000; mani, 2001) for comprehensive overviews of the methods and algorithms used to accomplish this.headline generators are noisy-channel probabilistic systems that are trained on large corpora of  headline, text  pairs (banko et al, 2000;<papid> P00-1041 </papid>berger and mittal, 2000).<papid> P00-1038 </papid></prevsent>
<prevsent>these systems produce short sequences of words that are indicative of the content of the text given as input.</prevsent>
</prevsection>
<citsent citstr=" A00-1043 ">
sentence simplification systems (chandrasekar et al., 1996; <papid> C96-2183 </papid>mahesh, 1997; carroll et al, 1998; grefenstette, 1998; jing, 2000; <papid> A00-1043 </papid>knight and marcu, 2000) are capable of compressing long sentences by deleting unimportant words and phrases.extraction-based summarizers often produce outputs that contain non-important sentence fragments.</citsent>
<aftsection>
<nextsent>for example, the hypothetical extractive summary of text (1), which is shown in table 1, can be compacted further by deleting the clause which is already almost enough to win?.
</nextsent>
<nextsent>headline-based summaries, such as that shown in table 1, are usually indicative of texts content but not informative, grammatical, or coherent.
</nextsent>
<nextsent>by repeatedly applying sentence-simplification algorithm one sentence at atime, one can compress text; yet, the outputs generated in this way are likely to be incoherent andto contain unimportant information.
</nextsent>
<nextsent>when summarizing text, some sentences should be dropped altogether.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q819">
<title id=" P02-1057.xml">a noisy channel model for document compression </title>
<section> a noisy-channel model </section>
<citcontext>
<prevsection>
<prevsent>b d ? ` a ? ? p(nuc=span ?  nuc=span sat=evaluation nuc=span ?  nuc=span) p(nuc=span ?  nuc=span | p(nuc=span ?  nuc=contrast nuc=contrast | p(root ?  sat=background nuc=span | root ?  nuc=span) nuc=span) p(nuc=span ?  nuc=contrast | nuc=span) nuc=span ?  nuc=contrast) p(nuc=contrast ?  sat=condiation nuc=span | nuc=contrast ?  nuc=span) o x z { | o q s u p(nuc=contrast ?  nuc=span | nuc=contrast)* figure 2: sequence of discourse expansions for text (1) (with probability factors).
</prevsent>
<prevsent>ally built in the style of rst.
</prevsent>
</prevsection>
<citsent citstr=" W01-1605 ">
(see (carlson et al,2001) <papid> W01-1605 </papid>for details concerning the corpus and the annotation process.)</citsent>
<aftsection>
<nextsent>from this corpus, we were able to estimate parameters for discourse pcfg using standard maximum likelihood methods.
</nextsent>
<nextsent>furthermore, 150 document from the same corpus are paired with extractive summaries on the edu level.
</nextsent>
<nextsent>human annotators were asked which eduswere most important; suppose in the example ds tree (figure 1) the annotators marked the second and fifth edus (the starred ones).
</nextsent>
<nextsent>these stars are propagated up, so that any discourse unit that hasa descend ent considered important is also considered important.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q820">
<title id=" P02-1057.xml">a noisy channel model for document compression </title>
<section> a noisy-channel model </section>
<citcontext>
<prevsection>
<prevsent>each entry in the shared-forest structure has three associated probabilities, one from the source syntax pcfg, one from the source discourse pcfg and one from the expansion-template probabilities described in section 3.2.
</prevsent>
<prevsent>once we have generated forest representing all possible compress ions of the original document, we want to extract the best (orthe ? -best) trees, taking into account both the expansion probabilities of the channel model and the bigram and syntax and discourse pcfg probabilities of the source model.
</prevsent>
</prevsection>
<citsent citstr=" A00-2023 ">
thankfully, such generic extractor has already been built (langkilde, 2000).<papid> A00-2023 </papid></citsent>
<aftsection>
<nextsent>for our purposes, the extractor selects the trees with the best combination of lm and expansion scores after performing an exhaustive search over all possible summaries.
</nextsent>
<nextsent>it returns list of such trees, one for each possible length.
</nextsent>
<nextsent>the system developed works in pipe lined fashion as shown in figure 3.
</nextsent>
<nextsent>the first step along the pipeline is to generate the discourse structure.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q822">
<title id=" P02-1057.xml">a noisy channel model for document compression </title>
<section> system.  </section>
<citcontext>
<prevsection>
<prevsent>for relation tagging.
</prevsent>
<prevsent>parser discourse syntax parser forest generator decoder chooser length output summary input document figure 3: the pipeline of system components.
</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
tactic parser (collins, 1997).<papid> P97-1003 </papid></citsent>
<aftsection>
<nextsent>the syntax trees of the edus are then merged with the discourse tree in the forest generator to create ds-tree similar tothat shown in figure 1.
</nextsent>
<nextsent>from this ds-tree wegener ate forest that subsumes all possible compressions.
</nextsent>
<nextsent>this forest is then passed on to the forest ranking system which is used as decoder (langkilde, 2000).<papid> A00-2023 </papid></nextsent>
<nextsent>the decoder gives us list of possible compress ions, for each possible length.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q825">
<title id=" P02-1057.xml">a noisy channel model for document compression </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>and ???
</prevsent>
<prevsent>words.
</prevsent>
</prevsection>
<citsent citstr=" P99-1042 ">
we call this set the mitre corpus (hirschman et al, 1999).<papid> P99-1042 </papid></citsent>
<aftsection>
<nextsent>wewould liked to have run evaluations on longer documents.
</nextsent>
<nextsent>unfortunately, the forests generated even for relatively small documents are huge.
</nextsent>
<nextsent>because there are an exponential number of summaries that can be generated for any given text4, the decoder runs outof memory for longer documents; therefore, we selected shorter subtexts from the original documents.we used both the wsj and mitre data for evaluation because we wanted to see whether the performance of our system varies with text genre.
</nextsent>
<nextsent>the mitre data consists mostly of short sentences (av erage document length from mitre is ? sentences), quite in constr ast to the typically long sentences in the wall street journal articles (average document length from wsj is ??4???
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q827">
<title id=" P04-1062.xml">annealing techniques for unsupervised statistical language learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we describe variant, skewed da, which can incorporate good initializer when it is available, and show significant improvements over em on grammar induction task.
</prevsent>
<prevsent>unlabeled data remains tantalizing potential resource for nlp researchers.
</prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
some tasks can thrive on nearly pure diet of unlabeled data (yarowsky, 1995; <papid> P95-1026 </papid>collins and singer, 1999; <papid> W99-0613 </papid>cucerzan and yarowsky, 2003).<papid> N03-1006 </papid></citsent>
<aftsection>
<nextsent>but for other tasks, such as machine translation (brown et al, 1990), <papid> J90-2002 </papid>the chief merit of unlabeled data is simply that nothing else is available; unsupervised parameter estimation is notorious for achieving mediocre results.the standard starting point is the expectation maximization (em) algorithm (dempster et al,1977).</nextsent>
<nextsent>em iteratively adjusts models parameters from an initial guess until it converges to local maximum.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q828">
<title id=" P04-1062.xml">annealing techniques for unsupervised statistical language learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we describe variant, skewed da, which can incorporate good initializer when it is available, and show significant improvements over em on grammar induction task.
</prevsent>
<prevsent>unlabeled data remains tantalizing potential resource for nlp researchers.
</prevsent>
</prevsection>
<citsent citstr=" W99-0613 ">
some tasks can thrive on nearly pure diet of unlabeled data (yarowsky, 1995; <papid> P95-1026 </papid>collins and singer, 1999; <papid> W99-0613 </papid>cucerzan and yarowsky, 2003).<papid> N03-1006 </papid></citsent>
<aftsection>
<nextsent>but for other tasks, such as machine translation (brown et al, 1990), <papid> J90-2002 </papid>the chief merit of unlabeled data is simply that nothing else is available; unsupervised parameter estimation is notorious for achieving mediocre results.the standard starting point is the expectation maximization (em) algorithm (dempster et al,1977).</nextsent>
<nextsent>em iteratively adjusts models parameters from an initial guess until it converges to local maximum.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q829">
<title id=" P04-1062.xml">annealing techniques for unsupervised statistical language learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we describe variant, skewed da, which can incorporate good initializer when it is available, and show significant improvements over em on grammar induction task.
</prevsent>
<prevsent>unlabeled data remains tantalizing potential resource for nlp researchers.
</prevsent>
</prevsection>
<citsent citstr=" N03-1006 ">
some tasks can thrive on nearly pure diet of unlabeled data (yarowsky, 1995; <papid> P95-1026 </papid>collins and singer, 1999; <papid> W99-0613 </papid>cucerzan and yarowsky, 2003).<papid> N03-1006 </papid></citsent>
<aftsection>
<nextsent>but for other tasks, such as machine translation (brown et al, 1990), <papid> J90-2002 </papid>the chief merit of unlabeled data is simply that nothing else is available; unsupervised parameter estimation is notorious for achieving mediocre results.the standard starting point is the expectation maximization (em) algorithm (dempster et al,1977).</nextsent>
<nextsent>em iteratively adjusts models parameters from an initial guess until it converges to local maximum.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q830">
<title id=" P04-1062.xml">annealing techniques for unsupervised statistical language learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>unlabeled data remains tantalizing potential resource for nlp researchers.
</prevsent>
<prevsent>some tasks can thrive on nearly pure diet of unlabeled data (yarowsky, 1995; <papid> P95-1026 </papid>collins and singer, 1999; <papid> W99-0613 </papid>cucerzan and yarowsky, 2003).<papid> N03-1006 </papid></prevsent>
</prevsection>
<citsent citstr=" J90-2002 ">
but for other tasks, such as machine translation (brown et al, 1990), <papid> J90-2002 </papid>the chief merit of unlabeled data is simply that nothing else is available; unsupervised parameter estimation is notorious for achieving mediocre results.the standard starting point is the expectation maximization (em) algorithm (dempster et al,1977).</citsent>
<aftsection>
<nextsent>em iteratively adjusts models parameters from an initial guess until it converges to local maximum.
</nextsent>
<nextsent>unfortunately, likelihood function sin practice are riddled with sub optimal local maxima (e.g., charniak, 1993, ch.
</nextsent>
<nextsent>7).
</nextsent>
<nextsent>moreover, maximizing likelihood is not equivalent to maximizing task-defined accuracy (e.g., merialdo, 1994).<papid> J94-2001 </papid>here we focus on the search error problem.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q831">
<title id=" P04-1062.xml">annealing techniques for unsupervised statistical language learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>unfortunately, likelihood function sin practice are riddled with sub optimal local maxima (e.g., charniak, 1993, ch.
</prevsent>
<prevsent>7).
</prevsent>
</prevsection>
<citsent citstr=" J94-2001 ">
moreover, maximizing likelihood is not equivalent to maximizing task-defined accuracy (e.g., merialdo, 1994).<papid> J94-2001 </papid>here we focus on the search error problem.</citsent>
<aftsection>
<nextsent>assume that one has model for which improving likelihood really will improve accuracy (e.g., at predicting hidden part-of-speech (pos) tags or parse trees).
</nextsent>
<nextsent>hence, we seek methods that tend to locate mountaintops rather than hilltops of the likelihood function.
</nextsent>
<nextsent>alternatively, we might want methods that find hilltops with other desirable properties.11wang et al (2003) suggest that one should seek high in 2 we review deterministic annealing (da) and show how it generalizes the em algorithm.
</nextsent>
<nextsent>3 shows how da can be used for parameter estimation for models of language structure that use dynamic programming to compute posteriors over hidden structure, such as hidden markov models (hmms) and stochastic context-free grammars (scfgs).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q834">
<title id=" P04-1062.xml">annealing techniques for unsupervised statistical language learning </title>
<section> part-of-speech tagging.  </section>
<citcontext>
<prevsection>
<prevsent>every distribution was smoothed using add-0.1 smoothing (at every 5with one caveat: less pruning may be appropriate because probability mass is spread more uniformly over different reconstructions of the hidden data.
</prevsent>
<prevsent>this paper uses no pruning.
</prevsent>
</prevsection>
<citsent citstr=" A94-1009 ">
6similar results were found by elworthy (1994).<papid> A94-1009 </papid></citsent>
<aftsection>
<nextsent>fig.
</nextsent>
<nextsent>3: learning curves for em and da.
</nextsent>
<nextsent>steps in das curve correspond to changes.
</nextsent>
<nextsent>the shape of theda curve is partly function of the an?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q835">
<title id=" P04-1062.xml">annealing techniques for unsupervised statistical language learning </title>
<section> grammar induction.  </section>
<citcontext>
<prevsection>
<prevsent>sda did do what it was expected to doit used the initializer, repairing da damage.
</prevsent>
<prevsent>we turn next to the problem of statistical grammar induction: inducing parse trees over unlabeled text.
</prevsent>
</prevsection>
<citsent citstr=" P02-1017 ">
an excellent recent result is by klein and manning (2002).<papid> P02-1017 </papid></citsent>
<aftsection>
<nextsent>the constituent-context model (ccm) they present is generative, deficient channel model of pos tag strings given binary tree bracketings.
</nextsent>
<nextsent>wefirst review the model and describe small modification that reduces the deficiency, then compare both models under em and da.
</nextsent>
<nextsent>6.1 constituent-context model.
</nextsent>
<nextsent>let (x, y) be (tag sequence, binary tree) pair.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q840">
<title id=" P04-1062.xml">annealing techniques for unsupervised statistical language learning </title>
<section> future work.  </section>
<citcontext>
<prevsection>
<prevsent>15binomial sign test, with significance defined as   0.05, though all significant results had   0.001.
</prevsent>
<prevsent>10% corpus 90% corpus f f ccm 1 em 65.00 1.091 66.12 0.6643 sda 63.00 4.689 53.53 0.2135 ccm 2 em 66.74 1.402 67.24 0.7077 sda 66.77 1.034 68.07 0.1193 table 3: the mean ? and standard deviation ? of -measureperformance for 10 trials using 10% of the corpus and 10 jackknifed trials using 90% of the corpus.ing systems, it will contribute to the general understanding of the likelihood surface for variety of problems (e.g., this paper has raised the question of how factors like dataset size and model deficiency affect the likelihood surface).
</prevsent>
</prevsection>
<citsent citstr=" P93-1024 ">
da provides very natural way to gradually introduce complexity to clustering models (rose et al, 1990; pereira et al, 1993).<papid> P93-1024 </papid></citsent>
<aftsection>
<nextsent>this comes about by manipulating the ? parameter; as it rises, the number of effective clusters is allowed to increase.an open question is whether the analogues of clus ters?
</nextsent>
<nextsent>in tagging and parsing model stag symbols and grammatical categories, respectively might be treated in similar manner under da.
</nextsent>
<nextsent>for instance,we might begin with the ccm, the original formulation of which posits only one distinction about constituency (whether span is constituent or not) and gradually allow splits in constituent-label space, resulting in multiple grammatical categories that, we hope, arise naturally from the data.
</nextsent>
<nextsent>in this paper, we used max = 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q841">
<title id=" P04-1062.xml">annealing techniques for unsupervised statistical language learning </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>acknowledgements this work was supported by fellowship to the first author from the fannie and john hertz foundation, and by an nsf itr grant to the second author.
</prevsent>
<prevsent>the views expressed are not necessarily endorsed by the sponsors.
</prevsent>
</prevsection>
<citsent citstr=" P04-3032 ">
the authors thank shankar kumar, charles schafer, david smith, and roy tromble for helpful comment sand discussions; three acl reviewers for advice that improved the paper; eric goldlust for keeping the dynacompiler (eisner et al, 2004) <papid> P04-3032 </papid>up to date with the demands made by this work; and dan klein for sharing details of his ccm implementation.</citsent>
<aftsection>




</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q842">
<title id=" N12-1097.xml">textual predictors of bill survival in congressional committees </title>
<section> adding text.  </section>
<citcontext>
<prevsection>
<prevsent>our third hypothesis is that committees make collective decisions by considering the contents of bills directly.
</prevsent>
<prevsent>a sensible starting point is to treat our model as document classifier and incorporate standard features of the text directly into the model, rather than deriving functional categories or proxy votes from the text.14 perhaps unsurprisingly, this approach will perform better than the previous two.
</prevsent>
</prevsection>
<citsent citstr=" P04-1035 ">
following pang and lee (2004), <papid> P04-1035 </papid>who used word and bigram features to model an authors sentiment, and kogan et al  (2009), <papid> N09-1031 </papid>who used word and bigram features to directly predict future outcome, we incorporate binary features for the presence or absence of terms in the body and (separately) in the title of the bill.</citsent>
<aftsection>
<nextsent>we include unigram features for the body and unigram and bigram features for the title.15 the result is 28,246 features, of which 24,515 are lexical.
</nextsent>
<nextsent>performance.
</nextsent>
<nextsent>combined with baseline features, word and bigram features led to nearly 18% relative error reduction compared to the baseline and 9% relative to the best model above (table 3).
</nextsent>
<nextsent>the model is very small (under 200 features), and 98% of the features in the model impacted test-time predictions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q843">
<title id=" N12-1097.xml">textual predictors of bill survival in congressional committees </title>
<section> adding text.  </section>
<citcontext>
<prevsection>
<prevsent>our third hypothesis is that committees make collective decisions by considering the contents of bills directly.
</prevsent>
<prevsent>a sensible starting point is to treat our model as document classifier and incorporate standard features of the text directly into the model, rather than deriving functional categories or proxy votes from the text.14 perhaps unsurprisingly, this approach will perform better than the previous two.
</prevsent>
</prevsection>
<citsent citstr=" N09-1031 ">
following pang and lee (2004), <papid> P04-1035 </papid>who used word and bigram features to model an authors sentiment, and kogan et al  (2009), <papid> N09-1031 </papid>who used word and bigram features to directly predict future outcome, we incorporate binary features for the presence or absence of terms in the body and (separately) in the title of the bill.</citsent>
<aftsection>
<nextsent>we include unigram features for the body and unigram and bigram features for the title.15 the result is 28,246 features, of which 24,515 are lexical.
</nextsent>
<nextsent>performance.
</nextsent>
<nextsent>combined with baseline features, word and bigram features led to nearly 18% relative error reduction compared to the baseline and 9% relative to the best model above (table 3).
</nextsent>
<nextsent>the model is very small (under 200 features), and 98% of the features in the model impacted test-time predictions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q845">
<title id=" N12-1097.xml">textual predictors of bill survival in congressional committees </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>an important research direction in political science, one in which nlp must play role, is how different types of issues are managed in legislatures.
</prevsent>
<prevsent>our results also suggest that political considerations may induce lawmakers to sponsor certain types of bills with no real expectation of seeing them enacted into law.considerable recent work has modeled text alongside data about social behavior.
</prevsent>
</prevsection>
<citsent citstr=" C08-1060 ">
this includes predictive settings (kogan et al , 2009; <papid> N09-1031 </papid>lerman etal., 2008), <papid> C08-1060 </papid>various kinds of sentiment and opinion analysis (thomas et al , 2006; <papid> W06-1639 </papid>monroe et al , 2008; oconnor et al , 2010; das et al , 2009), and exploratory models (steyvers and griffiths, 2007).</citsent>
<aftsection>
<nextsent>in political science specifically, the text as data?
</nextsent>
<nextsent>movement (grimmer and stewart, 2012; oconnor et al , 2011) has leveraged tools from nlp in quantitative research.
</nextsent>
<nextsent>for example, grimmer (2010) and quinn et al  (2006) used topic models to study, respectively, supreme court proceedings and senate speeches.
</nextsent>
<nextsent>closest to this work, gerrish and blei (2011) combined topic models with spatial roll call models to predict votes in the legislature from text alone.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q846">
<title id=" N12-1097.xml">textual predictors of bill survival in congressional committees </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>an important research direction in political science, one in which nlp must play role, is how different types of issues are managed in legislatures.
</prevsent>
<prevsent>our results also suggest that political considerations may induce lawmakers to sponsor certain types of bills with no real expectation of seeing them enacted into law.considerable recent work has modeled text alongside data about social behavior.
</prevsent>
</prevsection>
<citsent citstr=" W06-1639 ">
this includes predictive settings (kogan et al , 2009; <papid> N09-1031 </papid>lerman etal., 2008), <papid> C08-1060 </papid>various kinds of sentiment and opinion analysis (thomas et al , 2006; <papid> W06-1639 </papid>monroe et al , 2008; oconnor et al , 2010; das et al , 2009), and exploratory models (steyvers and griffiths, 2007).</citsent>
<aftsection>
<nextsent>in political science specifically, the text as data?
</nextsent>
<nextsent>movement (grimmer and stewart, 2012; oconnor et al , 2011) has leveraged tools from nlp in quantitative research.
</nextsent>
<nextsent>for example, grimmer (2010) and quinn et al  (2006) used topic models to study, respectively, supreme court proceedings and senate speeches.
</nextsent>
<nextsent>closest to this work, gerrish and blei (2011) combined topic models with spatial roll call models to predict votes in the legislature from text alone.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q847">
<title id=" P01-1068.xml">multiclass composite ngram language model for spoken language processing using multiple word clusters </title>
<section> automatic extraction of word.  </section>
<citcontext>
<prevsection>
<prevsent>in this paper, vectors areused to represent word neighboring characteristics.
</prevsent>
<prevsent>the elements of the vectors are forward or backward word 2-gram probabilities to the clustering target word after being smoothed.
</prevsent>
</prevsection>
<citsent citstr=" J92-4003 ">
and we consider that word pairs that have small distance between vectors also have similar word neighboring characteristics (brown et al, 1992) (<papid> J92-4003 </papid>bai et al., 1998).</citsent>
<aftsection>
<nextsent>in this method, the same vector is assigned to words that do not appear in the corpus, and the same word cluster will be assigned tothese words.
</nextsent>
<nextsent>to avoid excessively rough clustering over different pos, we cluster the words under the condition that only words with the samepos can belong to the same cluster.
</nextsent>
<nextsent>parts-of speech that have the same connectivity in eachmulti-class are merged.
</nextsent>
<nextsent>for example, if different parts-of-speeche are assigned to a? and an?, these parts-of-speeche are regarded as the same for the preceding word cluster.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q848">
<title id=" P03-1010.xml">reliable measures for aligning japanese english news articles and sentences </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it is also valuable for language education.
</prevsent>
<prevsent>however, no such corpus has been available to the public.we recently have obtained noisy parallel corpus of japanese and english newspapers consisting of issues published over more than decade and have tried to align their articles and sentences.
</prevsent>
</prevsection>
<citsent citstr=" P98-1041 ">
we first aligned the articles using method based on clir (collier et al, 1998; <papid> P98-1041 </papid>matsumoto and tanaka, 2002) and then aligned the sentences in these articles by using method based on dynamic programming (dp) matching (gale and church, 1993; <papid> J93-1004 </papid>utsuro etal., 1994).<papid> C94-2175 </papid></citsent>
<aftsection>
<nextsent>however, the results included many in correct alignments due to noise in the corpus.
</nextsent>
<nextsent>to remove these, we propose two measures(scores) that evaluate the validity of article and sentence alignments.
</nextsent>
<nextsent>using these, we can selectively extract valid alignments.
</nextsent>
<nextsent>in this paper, we first discuss the basic statistics on the japanese and english newspapers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q849">
<title id=" P03-1010.xml">reliable measures for aligning japanese english news articles and sentences </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it is also valuable for language education.
</prevsent>
<prevsent>however, no such corpus has been available to the public.we recently have obtained noisy parallel corpus of japanese and english newspapers consisting of issues published over more than decade and have tried to align their articles and sentences.
</prevsent>
</prevsection>
<citsent citstr=" J93-1004 ">
we first aligned the articles using method based on clir (collier et al, 1998; <papid> P98-1041 </papid>matsumoto and tanaka, 2002) and then aligned the sentences in these articles by using method based on dynamic programming (dp) matching (gale and church, 1993; <papid> J93-1004 </papid>utsuro etal., 1994).<papid> C94-2175 </papid></citsent>
<aftsection>
<nextsent>however, the results included many in correct alignments due to noise in the corpus.
</nextsent>
<nextsent>to remove these, we propose two measures(scores) that evaluate the validity of article and sentence alignments.
</nextsent>
<nextsent>using these, we can selectively extract valid alignments.
</nextsent>
<nextsent>in this paper, we first discuss the basic statistics on the japanese and english newspapers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q852">
<title id=" P03-1010.xml">reliable measures for aligning japanese english news articles and sentences </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it is also valuable for language education.
</prevsent>
<prevsent>however, no such corpus has been available to the public.we recently have obtained noisy parallel corpus of japanese and english newspapers consisting of issues published over more than decade and have tried to align their articles and sentences.
</prevsent>
</prevsection>
<citsent citstr=" C94-2175 ">
we first aligned the articles using method based on clir (collier et al, 1998; <papid> P98-1041 </papid>matsumoto and tanaka, 2002) and then aligned the sentences in these articles by using method based on dynamic programming (dp) matching (gale and church, 1993; <papid> J93-1004 </papid>utsuro etal., 1994).<papid> C94-2175 </papid></citsent>
<aftsection>
<nextsent>however, the results included many in correct alignments due to noise in the corpus.
</nextsent>
<nextsent>to remove these, we propose two measures(scores) that evaluate the validity of article and sentence alignments.
</nextsent>
<nextsent>using these, we can selectively extract valid alignments.
</nextsent>
<nextsent>in this paper, we first discuss the basic statistics on the japanese and english newspapers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q862">
<title id=" P03-1010.xml">reliable measures for aligning japanese english news articles and sentences </title>
<section> basic alignment methods.  </section>
<citcontext>
<prevsection>
<prevsent>3.2 sentence alignment.
</prevsent>
<prevsent>the sentences5 in the aligned japanese and english articles are aligned by method based on dp matching (gale and church, 1993; <papid> J93-1004 </papid>utsuro et al, 1994).<papid> C94-2175 </papid></prevsent>
</prevsection>
<citsent citstr=" A97-1004 ">
4http://trec.nist.gov/5we split the japanese articles into sentences by using simple heuristics and split the english articles into sentences by using mxterminator (reynar and ratnaparkhi, 1997).<papid> A97-1004 </papid></citsent>
<aftsection>
<nextsent>we allow 1-to-n or n-to-1 (1 ? ? 6) alignments when aligning the sentences.
</nextsent>
<nextsent>readers are referred to utsuro et al (1994) <papid> C94-2175 </papid>for concise description of the algorithm.</nextsent>
<nextsent>here, we only discuss the similarities between japanese and english sentences for align ment.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q864">
<title id=" P03-1010.xml">reliable measures for aligning japanese english news articles and sentences </title>
<section> basic alignment methods.  </section>
<citcontext>
<prevsection>
<prevsent>ji and ei are obtained as follows.
</prevsent>
<prevsent>we use chasen to morphologically analyze the japanese sentences and extract content words, which consists of ji.
</prevsent>
</prevsection>
<citsent citstr=" A92-1021 ">
we use brills tagger (brill, 1992) <papid> A92-1021 </papid>to pos-tag the english sentences, extract content words, and use wordnets library7 to obtain lemmas of the words, which consists of ei.</citsent>
<aftsection>
<nextsent>we use simple heuristics to obtain ji ? ei, i.e., one-to-one correspondence between the words in ji and ei, by looking up japanese english and english-japanese dictionaries made up by combining entries in the edr japanese-english bilingual dictionary and the edr english-japanesebilingual dictionary.
</nextsent>
<nextsent>each of the constructed dictionaries has over 300,000 entries.
</nextsent>
<nextsent>we evaluated the implemented program against corpus consisting of manually aligned japanese and english sentences.
</nextsent>
<nextsent>the source texts were japanese white papers (jeida, 2000).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q867">
<title id=" P00-1055.xml">using confidence bands for parallel texts alignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>alignment is usually done by finding correspondence points ? sequences of characters with the same form in both texts (homographs, e.g. numbers, proper names, punctuation marks), similar forms (cognates, like region and regio in english and portuguese, respectively) or even previously known translations.
</prevsent>
<prevsent>pascale fung and kathleen mckeown (1997) present an alignment algorithm that uses term translations as correspondence points between english and chinese.
</prevsent>
</prevsection>
<citsent citstr=" J99-1003 ">
melamed (1999) <papid> J99-1003 </papid>aligns texts using correspondence points taken either from orthographic cognates (michel simard et al., 1992) or from seed translation lexicon.however, although the heuristics both approaches use to filter noisy points may be intuitively quite acceptable, they are not theoretically supported by statistics.</citsent>
<aftsection>
<nextsent>the former approach considers candidate correspondence point reliable as long as, among some other constraints, ?[...]
</nextsent>
<nextsent>it is not too far away from the diagonal [...]?
</nextsent>
<nextsent>(pascale fung and kathleen mckeown, 1997, p.72) of rectangle whose sides sizes are proportional to the lengths of the texts in each language (henceforth, the golden translation diagonal?).
</nextsent>
<nextsent>the latter approach uses other filtering parameters: maximum point ambiguity level, point dispersion and angle deviation (melamed, 1999, <papid> J99-1003 </papid>pp.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q870">
<title id=" P00-1055.xml">using confidence bands for parallel texts alignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one assumes that translated texts have proportional sizes; the other tries to use lexical information in parallel texts to generate candidate correspondence points.
</prevsent>
<prevsent>both use some notion of correspondence points.
</prevsent>
</prevsection>
<citsent citstr=" P91-1022 ">
early work by peter brown et al (1991) <papid> P91-1022 </papid>and william gale and kenneth church (1991) aligned sentences which had proportional number of words and characters, respectively.</citsent>
<aftsection>
<nextsent>pairs of sentence delimiters (full stops) were used as candidate correspondence points and they ended up being selected while aligning.
</nextsent>
<nextsent>however, these algorithms tended to break down when sentence boundaries were not clearly marked.
</nextsent>
<nextsent>full stops do not always mark sentence boundaries, they may not even exist due to ocr noise and languages may not share the same punctuation policies.
</nextsent>
<nextsent>using lexical information, kenneth church (1993) <papid> P93-1001 </papid>showed that cheap alignment of text segments was still possible exploiting orthographic cognates (michel simard et al, 1992), instead of sentence delimiters.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q871">
<title id=" P00-1055.xml">using confidence bands for parallel texts alignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, these algorithms tended to break down when sentence boundaries were not clearly marked.
</prevsent>
<prevsent>full stops do not always mark sentence boundaries, they may not even exist due to ocr noise and languages may not share the same punctuation policies.
</prevsent>
</prevsection>
<citsent citstr=" P93-1001 ">
using lexical information, kenneth church (1993) <papid> P93-1001 </papid>showed that cheap alignment of text segments was still possible exploiting orthographic cognates (michel simard et al, 1992), instead of sentence delimiters.</citsent>
<aftsection>
<nextsent>they became the new candidate correspondence points.
</nextsent>
<nextsent>during the alignment, some were discarded because they lied outside an empirically estimated bounded search space, required for time and space reasons.
</nextsent>
<nextsent>martin kay and martin rscheisen (1993) <papid> J93-1006 </papid>also needed clearly delimited sentences.</nextsent>
<nextsent>words with similar distributions became the candidate correspondence points.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q872">
<title id=" P00-1055.xml">using confidence bands for parallel texts alignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they became the new candidate correspondence points.
</prevsent>
<prevsent>during the alignment, some were discarded because they lied outside an empirically estimated bounded search space, required for time and space reasons.
</prevsent>
</prevsection>
<citsent citstr=" J93-1006 ">
martin kay and martin rscheisen (1993) <papid> J93-1006 </papid>also needed clearly delimited sentences.</citsent>
<aftsection>
<nextsent>words with similar distributions became the candidate correspondence points.
</nextsent>
<nextsent>two sentences were aligned if the number of correspondence points associating them was greater than an empirically defined threshold: ?[...]
</nextsent>
<nextsent>more than some minimum number of times [...]?
</nextsent>
<nextsent>(martin kay and martin rscheisen, 1993, <papid> J93-1006 </papid>p.128).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q874">
<title id=" P00-1055.xml">using confidence bands for parallel texts alignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>more than some minimum number of times [...]?
</prevsent>
<prevsent>(martin kay and martin rscheisen, 1993, <papid> J93-1006 </papid>p.128).</prevsent>
</prevsection>
<citsent citstr=" W93-0301 ">
in ido dagan et al (1993) <papid> W93-0301 </papid>noisy points were filtered out by deleting frequent words.</citsent>
<aftsection>
<nextsent>pascale fung and kathleen mckeown (1994) dropped the requirement for sentence boundaries on case-study for english-chinese.
</nextsent>
<nextsent>instead, they used vectors that stored distances between consecutive occurrences of word (dk-vecs).
</nextsent>
<nextsent>candidate correspondence points were identified from words with similar distance vectors and noisy points were filtered using some heuristics.
</nextsent>
<nextsent>later, in pascale fung and kathleen mckeown (1997), the algorithm used extracted terms to compile list of reliable pairs of translations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q877">
<title id=" P00-1055.xml">using confidence bands for parallel texts alignment </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>it is made at whatever segment size as long as reliable correspondence points are found.
</prevsent>
<prevsent>this means that alignment can result at paragraph, sentence, phrase, term or word level.
</prevsent>
</prevsection>
<citsent citstr=" P94-1012 ">
moreover, the methodology does not depend on the way candidate correspondence points are generated, i.e. although we used homographswith equal frequencies, we could have also boot strapped the process using cognates (michel simard et al 1992) or small bilingual lexicon to identify equivalents of words or expressions (dekai wu 1994; <papid> P94-1012 </papid>pascale fung and kathleen mckeown 1997; melamed 1999).<papid> J99-1003 </papid></citsent>
<aftsection>
<nextsent>this is particularly good strategy when it comes to distant languages like english and chinese where the number of homo graphs is reduced.
</nextsent>
<nextsent>as antnioribeiro et al (2000b) showed, these tokens account for about 5% for small texts.
</nextsent>
<nextsent>aligning languages with such different alphabets requires automatic methods to identify equivalents as pascale fung and kathleen mckeown (1997) presented, increasing the number of candidate correspondence points at the beginning.
</nextsent>
<nextsent>selecting correspondence points improves the quality and reliability of parallel texts alignment.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q880">
<title id=" P01-1033.xml">towards abstract categorial grammars </title>
<section> three computational paradigms.  </section>
<citcontext>
<prevsection>
<prevsent>3.2 deductive paradigm.
</prevsent>
<prevsent>the deductive paradigm, in our setting, answers the following problem: does given term, built upon the object vocabulary of an acg, belong to the object language of this acg.
</prevsent>
</prevsection>
<citsent citstr=" C00-2091 ">
it amount sto kind of proof-search that has been described by merenciano and morrill (1997) and by pogodalla (2000).<papid> C00-2091 </papid></citsent>
<aftsection>
<nextsent>this proof-search relies on linear higher-order matching, which is decidable problem (de groote, 2000).
</nextsent>
<nextsent>3.3 transductive paradigm.
</nextsent>
<nextsent>the example deve lopped in section 2.3 suggestsa third paradigm, which is obtained as the composition of the applicative paradigm with the deductive paradigm.
</nextsent>
<nextsent>we call it the transductiveparadigm because it is reminiscent of the mathematical notion of transduction (see section 4.2).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q881">
<title id=" P01-1033.xml">towards abstract categorial grammars </title>
<section> relating acgs to other grammatical.  </section>
<citcontext>
<prevsection>
<prevsent>x. x} ? one of the keystones in the above translation is to represent an adjunction node as functional parameter of type a??
</prevsent>
<prevsent>a?.
</prevsent>
</prevsection>
<citsent citstr=" J99-2003 ">
abrusci et al (1999) <papid> J99-2003 </papid>use similar idea in their translation of the tags into non-commutative linear logic.</citsent>
<aftsection>
<nextsent>the linear ?-calculus on which we have base dour definition of an acg may be seen as rudimentary functional programming language.
</nextsent>
<nextsent>the results in section 4 indicate that, in theory, this rudimentary language is powerful enough.
</nextsent>
<nextsent>nevertheless, in practice, it would be useful to increase the expressive power of the multiplicative kernel defined in section 2 by providing features suchas records, enumerated types, conditional expressions, etc. from methodological point of view, there is systematic way of considering such extensions.
</nextsent>
<nextsent>it consists of enriching the type system of the formalism with new logical connectives.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q882">
<title id=" N12-3006.xml">msr splat a language analysis toolkit </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as we expand the tools we develop for our own research, the set of tools available in msr splat will be extended.
</prevsent>
<prevsent>the toolkit is accessible as web service, which can be used from broad set of programming languages.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
the availability of annotated datasets that have become community standards, such as the penn treebank (marcus et al, 1993) <papid> J93-2004 </papid>and propbank (palmer et al, 2005), <papid> J05-1004 </papid>has enabled many research institutions to build core natural language processing components, including part-of-speech taggers, chunk ers, and parsers.</citsent>
<aftsection>
<nextsent>there remain many differences in how these components are built, resulting in slight but noticeable variation in the component output.
</nextsent>
<nextsent>in experimental settings, it has proved sometimes difficult to distinguish between improvements contributed by specific component feature from improvements due to using differently-trained linguistic component, such as tokenization.
</nextsent>
<nextsent>the community recognizes this difficulty, and shared task organizers are now providing accompanying parses and other analyses of the shared task data.
</nextsent>
<nextsent>for instance, the bionlp shared task organizers have provided output from number of parsers1, alleviating the need for participating systems to download and run unfamiliar tools.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q883">
<title id=" N12-3006.xml">msr splat a language analysis toolkit </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as we expand the tools we develop for our own research, the set of tools available in msr splat will be extended.
</prevsent>
<prevsent>the toolkit is accessible as web service, which can be used from broad set of programming languages.
</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
the availability of annotated datasets that have become community standards, such as the penn treebank (marcus et al, 1993) <papid> J93-2004 </papid>and propbank (palmer et al, 2005), <papid> J05-1004 </papid>has enabled many research institutions to build core natural language processing components, including part-of-speech taggers, chunk ers, and parsers.</citsent>
<aftsection>
<nextsent>there remain many differences in how these components are built, resulting in slight but noticeable variation in the component output.
</nextsent>
<nextsent>in experimental settings, it has proved sometimes difficult to distinguish between improvements contributed by specific component feature from improvements due to using differently-trained linguistic component, such as tokenization.
</nextsent>
<nextsent>the community recognizes this difficulty, and shared task organizers are now providing accompanying parses and other analyses of the shared task data.
</nextsent>
<nextsent>for instance, the bionlp shared task organizers have provided output from number of parsers1, alleviating the need for participating systems to download and run unfamiliar tools.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q885">
<title id=" N12-3006.xml">msr splat a language analysis toolkit </title>
<section> parsing functionality.  </section>
<citcontext>
<prevsection>
<prevsent>is verb phrase (vp).
</prevsent>
<prevsent>using the wall street journal portion of the penn treebank, we estimate coarse grammar over the given grammar symbols.
</prevsent>
</prevsection>
<citsent citstr=" P06-1055 ">
next, we perform series of refinements to automatically learn fine-grained categories that better capture the implicit correlations in the tree using the split-merge method of petrov et al (2006).<papid> P06-1055 </papid></citsent>
<aftsection>
<nextsent>each input symbol is split into two new symbols, both with new unique symbol label, and the grammar is updated to include copy of each original rule for each such refinement, with small amount of random noise added to the probability of each production to break ties.
</nextsent>
<nextsent>we estimate new grammar parameters using an accelerated form of the em algorithm (salakhutdinov and roweis, 2003).
</nextsent>
<nextsent>then the lowest 50% of the split symbols (according to their estimated contribution to the likelihood of the data) are merged back into their original form and the parameters are again re-estimated using aem.
</nextsent>
<nextsent>we found six split-merge iterations produced optimal accuracy on the standard development set.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q887">
<title id=" N12-3006.xml">msr splat a language analysis toolkit </title>
<section> parsing functionality.  </section>
<citcontext>
<prevsection>
<prevsent>coarse-to-fine parsing with pruning at each level helps increase speed; pruning thresholds are picked for each level to have minimal impact on development set accuracy.
</prevsent>
<prevsent>however, the initial coarse pass still has runtime cubic in the length of the sentence.
</prevsent>
</prevsection>
<citsent citstr=" C08-1094 ">
thus, we limit the search space of the coarse parse by closing selected chart cells before the parse begins (roark and hollingshead, 2008).<papid> C08-1094 </papid></citsent>
<aftsection>
<nextsent>we train classifier to determine if constituents may start or end at each position in the sentence.
</nextsent>
<nextsent>for instance, constituents seldom end at the word the?
</nextsent>
<nextsent>or begin at comma.
</nextsent>
<nextsent>closing number of chart cells can substantially improve runtime with minimal impact on accuracy.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q889">
<title id=" N12-3006.xml">msr splat a language analysis toolkit </title>
<section> parsing functionality.  </section>
<citcontext>
<prevsection>
<prevsent>this implementation of an srl system follows the approach described in (xue and palmer, 04), and includes two log-linear models for argument identification and classification.
</prevsent>
<prevsent>a single syntax tree generated by the msr splat split-merge parser is used as input.
</prevsent>
</prevsection>
<citsent citstr=" J08-2002 ">
non-overlapping arguments are derived using the dynamic programming algorithm by toutanova et al (2008).<papid> J08-2002 </papid></citsent>
<aftsection>
<nextsent>3.1 sentence boundary / tokenization.
</nextsent>
<nextsent>22 this analyzer identifies sentence boundaries and breaks the input into tokens.
</nextsent>
<nextsent>both are represented as offsets of character ranges.
</nextsent>
<nextsent>each token has both raw form from the string and normalized form in the ptb specification, e.g., open and close parentheses are replaced by -lrb- and -rrb-, respectively, to remove ambiguity with parentheses indicating syntactic structure.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q890">
<title id=" N12-3006.xml">msr splat a language analysis toolkit </title>
<section> the flexibility of web service.  </section>
<citcontext>
<prevsection>
<prevsent>we are in the process of building out the tools to provide language analysis for languages other than english.
</prevsent>
<prevsent>one step in this direction is tool for transliterating between english and katakana words.
</prevsent>
</prevsection>
<citsent citstr=" D09-1111 ">
following cherry and suzuki (2009), <papid> D09-1111 </papid>the toolkit currently outputs the 10 best transliteration candidates with probabilities for both directions.</citsent>
<aftsection>
<nextsent>another included service is the triples analyzer, which returns the head of the subject, the verb, and the head of the object, whenever such triple is encountered.
</nextsent>
<nextsent>we found this functionality to be useful as we were exploring features for our system submitted to the bionlp shared task.
</nextsent>
<nextsent>5.1 web service reference.
</nextsent>
<nextsent>we have designed web service that accepts batch of text and applies series of analysis tools to that text, returning bag of analyses.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q891">
<title id=" P04-1085.xml">identifying agreement and disagreement in conversational speech use of bayesian networks to model pragmatic dependencies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, summary might resemble minutes of meetings with major decisions reached (consensus) along with highlighted points of the pros and cons for each decision.
</prevsent>
<prevsent>in this paper, we present method to automatically classify utterances as agreement, disagreement, or neither.
</prevsent>
</prevsection>
<citsent citstr=" N03-2012 ">
previous work in automatic identification of agreement/disagreement (hillard et al, 2003)<papid> N03-2012 </papid>demonstrates that this is feasible task when various textual, dura tional, and acoustic features are available.</citsent>
<aftsection>
<nextsent>we build on their approach and show that we can get an improvement inaccuracy when contextual information is taken into account.
</nextsent>
<nextsent>our approach first identifies adjacency pairs using maximum entropy ranking based on set of lexical, dura tional and structural features that look both forward and backward in the discourse.
</nextsent>
<nextsent>this allows us to acquire, and subsequently process, knowledge about who speaks to whom.
</nextsent>
<nextsent>we hypothesize that pragmatic features that center around previous agreement between speakers in the dialog will influence the determination of agreement/disagreement.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q893">
<title id=" P04-1085.xml">identifying agreement and disagreement in conversational speech use of bayesian networks to model pragmatic dependencies </title>
<section> corpus.  </section>
<citcontext>
<prevsection>
<prevsent>meetings in general run just under an hour each; they have an average of 6.5 participants.these meetings have been labeled with adja cency pairs (ap), which provide information about speaker interaction.
</prevsent>
<prevsent>they reflect the structure of conversations as paired utterances such as question answer and offer-acceptance, and their labeling isused in our work to determine who are the addressees in agreements and disagreements.
</prevsent>
</prevsection>
<citsent citstr=" W04-2319 ">
the annotation of the corpus with adjacency pairs is described in (shriberg et al, 2004; <papid> W04-2319 </papid>dhillon et al, 2004).</citsent>
<aftsection>
<nextsent>seven of those meetings were segmented into spurts, defined as periods of speech that have no pauses greater than .5 second, and each spurt was labeled with one of the four categories: agreement, disagreement, back channel, and other.1 we used spurt segmentation as our unit of analysis instead of sentence segmentation, because our ultimate goal is to build system that can be fully automated, andin that respect, spurt segmentation is easy to obtain.
</nextsent>
<nextsent>back channels (e.g. uhhuh?
</nextsent>
<nextsent>and okay?)
</nextsent>
<nextsent>we retreated as separate category, since they are generally used by listeners to indicate they are following along, while not necessarily indicating agreement.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q895">
<title id=" P04-1085.xml">identifying agreement and disagreement in conversational speech use of bayesian networks to model pragmatic dependencies </title>
<section> adjacency pairs.  </section>
<citcontext>
<prevsection>
<prevsent>the next subsection describes the machine learning framework used to significantly outperform this already quite effective baseline algorithm.
</prevsent>
<prevsent>3.2 maximum entropy ranking.
</prevsent>
</prevsection>
<citsent citstr=" W03-1209 ">
we view the problem as an instance of statistical ranking, general machine learning paradigm used for example in statistical parsing (collins, 2000) and question answering (ravichandran et al, 2003).<papid> W03-1209 </papid>3 the problem is to select, given set of   possible candidates</citsent>
<aftsection>
<nextsent>     (in our case, potential speakers), the one candidate  that maximizes given conditional probability distribution.
</nextsent>
<nextsent>we use maximum entropy modeling (berger etal., 1996) <papid> J96-1002 </papid>to directly model the conditional probability   , where each ff in flfiffiff !   ff  is an observation associated with the corresponding speaker   . ff  is represented here by only one variable for notational ease, but it possibly represents several lexical, dura tional, structural, and acoustic observations.</nextsent>
<nextsent>given # feature functions $ %&amp;  !(and # model parameters )*fi+-,.!   /,102 , the probability of the maximum entropy model is defined as: 1345 67fi 8 9;:   =@ba 0 %fe4 ,%$%&amp;  !-hg the only role of the denominator 9 6 is to ensure that 13 is proper probability distribution.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q896">
<title id=" P04-1085.xml">identifying agreement and disagreement in conversational speech use of bayesian networks to model pragmatic dependencies </title>
<section> adjacency pairs.  </section>
<citcontext>
<prevsection>
<prevsent>we view the problem as an instance of statistical ranking, general machine learning paradigm used for example in statistical parsing (collins, 2000) and question answering (ravichandran et al, 2003).<papid> W03-1209 </papid>3 the problem is to select, given set of   possible candidates</prevsent>
<prevsent>     (in our case, potential speakers), the one candidate  that maximizes given conditional probability distribution.</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
we use maximum entropy modeling (berger etal., 1996) <papid> J96-1002 </papid>to directly model the conditional probability   , where each ff in flfiffiff !   ff  is an observation associated with the corresponding speaker   . ff  is represented here by only one variable for notational ease, but it possibly represents several lexical, dura tional, structural, and acoustic observations.</citsent>
<aftsection>
<nextsent>given # feature functions $ %&amp;  !(and # model parameters )*fi+-,.!   /,102 , the probability of the maximum entropy model is defined as: 1345 67fi 8 9;:   =@ba 0 %fe4 ,%$%&amp;  !-hg the only role of the denominator 9 6 is to ensure that 13 is proper probability distribution.
</nextsent>
<nextsent>it is defined as: 9 :    fi  jike4 =@la 0 %/e4 , %$%&amp;    hg to find the most probable speaker of part a, we use the following decision rule:  fi nop qrn ? s(tu&vws5xwy;[z[z[z[y sh\.].^ 134   6_ fi nop qrn ? s(tu&vws5xwy;[z[z[z[y sh\.].^ =@la 0 %/e4 , % $ %     hgr_ note that we have also attempted to model the problem as binary classification problem where 3the approach is generally called re-ranking in cases where candidates are assigned an initial rank beforehand.
</nextsent>
<nextsent>each speaker is either classified as speaker or not, but we abandoned that approach, since it gives much worse performance.
</nextsent>
<nextsent>this finding is consistent with previous work (ravichandran et al, 2003) <papid> W03-1209 </papid>that compares maximum entropy classification and re-ranking on question answering task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q899">
<title id=" P04-1085.xml">identifying agreement and disagreement in conversational speech use of bayesian networks to model pragmatic dependencies </title>
<section> adjacency pairs.  </section>
<citcontext>
<prevsection>
<prevsent>if we hypothesize that only limited set of paired das(e.g. offer-accept, question-answer, and apology downplay) can be realized as adjacency pairs, then knowing theda category of the part and of all potential parts should help in finding the most meaningful dialog act tag among all potential aparts; for example, the question-accept pair is admittedly more likely to correspond to an ap thane.g. backchannel-accept.
</prevsent>
<prevsent>we used theda annotation that we also had available, and used theda tag sequence of part and as feature.7 when we add theda feature set, the accuracy reaches 91.34%, which is only slightly better than our 90.20% accuracy, which indicates that lexical, dura tional, and structural features capture most ofthe informative ness provided by das.
</prevsent>
</prevsection>
<citsent citstr=" J00-3003 ">
this improved accuracy with da information should of course not be considered as the actual accuracy ofour system, since da information is difficult to acquire automatically (stolcke et al, 2000).<papid> J00-3003 </papid></citsent>
<aftsection>
<nextsent>4.1 overview.
</nextsent>
<nextsent>this section focusses on the use of contextual information, in particular the influence of previous agreements and disagreements and detected adjacency pairs, to improve the classification of agreements and disagreements.
</nextsent>
<nextsent>we first define the classification problem, then describe non-contextual features, provide some empirical evidence justifying our choice of contextual features, and finally evaluate the classifier.
</nextsent>
<nextsent>4.2 agreement/disagreement classification.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q901">
<title id=" P04-1085.xml">identifying agreement and disagreement in conversational speech use of bayesian networks to model pragmatic dependencies </title>
<section> agreements and disagreements.  </section>
<citcontext>
<prevsection>
<prevsent>and right?, as listed in (cohen, 2002), general cue phrases, e.g. but?
</prevsent>
<prevsent>and alright?
</prevsent>
</prevsection>
<citsent citstr=" P97-1023 ">
(hirschberg and litman, 1994), and adjectives with positive or negative polarity (hatzivassiloglou and mckeown, 1997).<papid> P97-1023 </papid></citsent>
<aftsection>
<nextsent>we incorporated set of dura tional features that were described in the literature as good predictors of agreements:utterance length distinguishes agreement from disagreement, the latter tending to be longer since the speaker elaborates more on the reasons and circumstances of her disagreement than for an agreement (cohen, 2002).
</nextsent>
<nextsent>duration is also good predictor of back channels, since they tend to be quite short.
</nextsent>
<nextsent>finally, fair amount of silence and filled pauses is sometimes an indicator of disagreement, since it is dis preferred response in most social contexts and can be associated with hesitation (pomerantz, 1984).
</nextsent>
<nextsent>4.4 contextual features: an empirical study.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q903">
<title id=" P04-1085.xml">identifying agreement and disagreement in conversational speech use of bayesian networks to model pragmatic dependencies </title>
<section> agreements and disagreements.  </section>
<citcontext>
<prevsection>
<prevsent>such enumeration is generally prohibitive when the model incorporates many interacting features andlong-range dependencies (the reader can find discussion of the problem in (mccallum et al, 2000)).
</prevsent>
<prevsent>conditional models address these concerns.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
conditional markov models (cmm) (ratnaparkhi, 1996; <papid> W96-0213 </papid>klein and manning, 2002) have been successfully used in sequence labeling tasks incorporating rich feature sets.</citsent>
<aftsection>
<nextsent>in left-to-right cmm as shown in figure 1(a), the probability of sequence of tags   fi+   !
</nextsent>
<nextsent> is decomposed as:  1  fi
</nextsent>
<nextsent>  e4            ff    fi ff !   ff
</nextsent>
<nextsent>. is the vector of observations andeach is the index of spurt.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q911">
<title id=" P04-1087.xml">acquiring the meaning of discourse markers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper is concerned with automatically acquiring the meaning of discourse markers.
</prevsent>
<prevsent>by considering the distributions of individual tokens of discourse markers, we classify discourse markers along three dimensions upon which there is substantial agreement in the literature: polarity, veridical ity and type.
</prevsent>
</prevsection>
<citsent citstr=" P03-1059 ">
this approach of classifying linguistic types by the distribution of linguistic tokens makes this research similar in spirit to that of baldwin and bond (2003) <papid> P03-1059 </papid>and stevenson and merlo (1999).<papid> E99-1007 </papid>discourse markers signal relations between discourse units.</citsent>
<aftsection>
<nextsent>as such, discourse markers play an important role in the parsing of natural language discourse (forbes et al, 2001; marcu, 2000), and their correspondence with discourse relations canbe exploited for the unsupervised learning of discourse relations (marcu and echihabi, 2002).<papid> P02-1047 </papid></nextsent>
<nextsent>in addition, generating natural language discourse requires the appropriate selection and placement of discourse markers (moser and moore, 1995; grote and stede, 1998).<papid> W98-1414 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q912">
<title id=" P04-1087.xml">acquiring the meaning of discourse markers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper is concerned with automatically acquiring the meaning of discourse markers.
</prevsent>
<prevsent>by considering the distributions of individual tokens of discourse markers, we classify discourse markers along three dimensions upon which there is substantial agreement in the literature: polarity, veridical ity and type.
</prevsent>
</prevsection>
<citsent citstr=" E99-1007 ">
this approach of classifying linguistic types by the distribution of linguistic tokens makes this research similar in spirit to that of baldwin and bond (2003) <papid> P03-1059 </papid>and stevenson and merlo (1999).<papid> E99-1007 </papid>discourse markers signal relations between discourse units.</citsent>
<aftsection>
<nextsent>as such, discourse markers play an important role in the parsing of natural language discourse (forbes et al, 2001; marcu, 2000), and their correspondence with discourse relations canbe exploited for the unsupervised learning of discourse relations (marcu and echihabi, 2002).<papid> P02-1047 </papid></nextsent>
<nextsent>in addition, generating natural language discourse requires the appropriate selection and placement of discourse markers (moser and moore, 1995; grote and stede, 1998).<papid> W98-1414 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q913">
<title id=" P04-1087.xml">acquiring the meaning of discourse markers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>by considering the distributions of individual tokens of discourse markers, we classify discourse markers along three dimensions upon which there is substantial agreement in the literature: polarity, veridical ity and type.
</prevsent>
<prevsent>this approach of classifying linguistic types by the distribution of linguistic tokens makes this research similar in spirit to that of baldwin and bond (2003) <papid> P03-1059 </papid>and stevenson and merlo (1999).<papid> E99-1007 </papid>discourse markers signal relations between discourse units.</prevsent>
</prevsection>
<citsent citstr=" P02-1047 ">
as such, discourse markers play an important role in the parsing of natural language discourse (forbes et al, 2001; marcu, 2000), and their correspondence with discourse relations canbe exploited for the unsupervised learning of discourse relations (marcu and echihabi, 2002).<papid> P02-1047 </papid></citsent>
<aftsection>
<nextsent>in addition, generating natural language discourse requires the appropriate selection and placement of discourse markers (moser and moore, 1995; grote and stede, 1998).<papid> W98-1414 </papid></nextsent>
<nextsent>it follows that detailed account of the semantics and pragmatics of discourse markers would be useful resource for natural language processing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q914">
<title id=" P04-1087.xml">acquiring the meaning of discourse markers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this approach of classifying linguistic types by the distribution of linguistic tokens makes this research similar in spirit to that of baldwin and bond (2003) <papid> P03-1059 </papid>and stevenson and merlo (1999).<papid> E99-1007 </papid>discourse markers signal relations between discourse units.</prevsent>
<prevsent>as such, discourse markers play an important role in the parsing of natural language discourse (forbes et al, 2001; marcu, 2000), and their correspondence with discourse relations canbe exploited for the unsupervised learning of discourse relations (marcu and echihabi, 2002).<papid> P02-1047 </papid></prevsent>
</prevsection>
<citsent citstr=" W98-1414 ">
in addition, generating natural language discourse requires the appropriate selection and placement of discourse markers (moser and moore, 1995; grote and stede, 1998).<papid> W98-1414 </papid></citsent>
<aftsection>
<nextsent>it follows that detailed account of the semantics and pragmatics of discourse markers would be useful resource for natural language processing.
</nextsent>
<nextsent>rather than looking at the finer subtleties in meaning of particular discourse markers (e.g. bestgen et al (2003)), this paper aims at broad scale classification of subclass of discourse markers: structural connectives.
</nextsent>
<nextsent>this breadth of coverage is of particular importance for discourse parsing, where wide range of linguistic realisations must be catered for.
</nextsent>
<nextsent>this work can be seen as orthogonal to that of di eugenio et al (1997), <papid> P97-1011 </papid>which addresses the problem of learning if and where discourse markers should be generated.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q915">
<title id=" P04-1087.xml">acquiring the meaning of discourse markers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>rather than looking at the finer subtleties in meaning of particular discourse markers (e.g. bestgen et al (2003)), this paper aims at broad scale classification of subclass of discourse markers: structural connectives.
</prevsent>
<prevsent>this breadth of coverage is of particular importance for discourse parsing, where wide range of linguistic realisations must be catered for.
</prevsent>
</prevsection>
<citsent citstr=" P97-1011 ">
this work can be seen as orthogonal to that of di eugenio et al (1997), <papid> P97-1011 </papid>which addresses the problem of learning if and where discourse markers should be generated.</citsent>
<aftsection>
<nextsent>unfortunately, the manual classification of large numbers of discourse markers has proven to be adifficult task, and no complete classification yet exists.
</nextsent>
<nextsent>for example, knott (1996) presents list of around 350 discourse markers, but his taxonomic classification, perhaps the largest classification in the literature, accounts for only around 150 of these.a general method of automatically classifying discourse markers would therefore be of great utility,both for english and for languages with fewer manually created resources.
</nextsent>
<nextsent>this paper constitutes astep in that direction.
</nextsent>
<nextsent>it attempts to classify discourse markers whose classes are already known,and this allows the classifier to be evaluated empirically.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q916">
<title id=" P04-1087.xml">acquiring the meaning of discourse markers </title>
<section> discourse markers.  </section>
<citcontext>
<prevsection>
<prevsent>examples of discourse markers are given in tables 1, 2 and 3.
</prevsent>
<prevsent>in this paper we will focus on subclass of discourse markers known as structural connectives.
</prevsent>
</prevsection>
<citsent citstr=" J03-4002 ">
these markers, even though they may be multiword expressions, function syntactically as if they were coordinating or subordinating conjunctions (webber et al, 2003).<papid> J03-4002 </papid>the literature contains many different classifications of discourse markers, drawing upon awide range of evidence including textual cohesion (halliday and hasan, 1976), hypotacticconjunctions (martin, 1992), cognitive plausibility (sanders et al, 1992), substitutability (knott,1996), and psycho linguistic experiments (louw erse, 2001).</citsent>
<aftsection>
<nextsent>nevertheless there is also considerable agreement.
</nextsent>
<nextsent>three dimensions of classification that recur, albeit under variety of names, are polarity, veridicality and type.
</nextsent>
<nextsent>we now discuss each of these in turn.
</nextsent>
<nextsent>2.1 polarity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q918">
<title id=" P04-1087.xml">acquiring the meaning of discourse markers </title>
<section> corpus.  </section>
<citcontext>
<prevsection>
<prevsent>many discourse markers have surface forms with other usages, e.g. before in the phrase before noon.the following procedure was therefore used to select sentences for inclusion in the database.
</prevsent>
<prevsent>first,sentences containing string matching the surface form of structural connective were extracted.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
these sentences were then parsed using statistical parser (charniak, 2000).<papid> A00-2018 </papid></citsent>
<aftsection>
<nextsent>potential structural connectives were then classified on the basis of their syntactic context, in particular their proximity to nodes.
</nextsent>
<nextsent>figure 1 shows example syntactic contexts which were used to identify discourse markers.
</nextsent>
<nextsent>(s ...)
</nextsent>
<nextsent>(cc and) (s...)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q921">
<title id=" P04-1087.xml">acquiring the meaning of discourse markers </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>firstly, we used lexical co-occurrences with words of various partsof speech.
</prevsent>
<prevsent>secondly, we used range of linguistically motivated syntactic, semantic, and discourse features.
</prevsent>
</prevsection>
<citsent citstr=" N04-1020 ">
4.1.1 lexical co-occurrences lexical co-occurrences have previously been shownto be useful for discourse level learning tasks (la pata and lascarides, 2004; <papid> N04-1020 </papid>marcu and echihabi,2002).<papid> P02-1047 </papid></citsent>
<aftsection>
<nextsent>for each discourse marker, the words occur ring in their super ordinate (main) and subordinate clauses were recorded,3 along with their parts of speech.
</nextsent>
<nextsent>we manually clustered the penn treebank parts of speech together to obtain coarser grained syntactic categories, as shown in table 4.
</nextsent>
<nextsent>we then lemmatised each word and excluded alllemmas with frequency of less than 1000 per million in the bnc.
</nextsent>
<nextsent>finally, words were attached prefix of either sub or super according to whether they occurred in the sub- or super ordinate clause linked by the marker.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q923">
<title id=" P04-1087.xml">acquiring the meaning of discourse markers </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we also recorded the occurrence of set of negative polarity items (npi), such as any and ever.
</prevsent>
<prevsent>the features npi-and-neg and npi-wo-neg indicated whether an npi occurred in clause with or without verbal or subject negation.eventualities can be placed or ordered in time using not just discourse markers but also temporal expressions.
</prevsent>
</prevsection>
<citsent citstr=" P00-1010 ">
the feature tempex recorded the number of temporal expressions in each clause, as returned by temporal expression tagger (mani and wilson, 2000).<papid> P00-1010 </papid></citsent>
<aftsection>
<nextsent>if the main verb was an inflection of to be or to do we recorded this using the features be and do.
</nextsent>
<nextsent>our motivation was to capture any correlation of these verbs with states and events respectively.if the final verb was modal auxiliary, this ellipsis was evidence of strong cohesion in the text (halliday and hasan, 1976).
</nextsent>
<nextsent>we recorded this withthe feature vp-ellipsis.
</nextsent>
<nextsent>pronouns also indicate cohesion, and have been shown to correlate with subjectivity (bestgen et al, 2003).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q924">
<title id=" P04-1087.xml">acquiring the meaning of discourse markers </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>    fffiflffi   (6) the second, ! # , is smoothed variant ofthe information theoretic kullback-leibner divergence (lee, 2001, with $% &amp;)(+* , ).
</prevsent>
<prevsent>its definition is given in (7).
</prevsent>
</prevsection>
<citsent citstr=" W02-0908 ">
! #ff -   . /1032 4 ff $-ffiff65798:fi;$/  ff (7)the third metric, =6 1?@?@a , is b -test weighted adaption of the jaccard coefficient (curran and moens,2002).<papid> W02-0908 </papid></citsent>
<aftsection>
<nextsent>in it basic form, the jaccard coefficient is essentially measure of how much two distributions overlap.
</nextsent>
<nextsent>the -test variant weights co-occurrencesby the strength of their collocation, using the following function: bd cfe  / cfe ffgfih / cfe   /ff / cfe   ff this is then used define the weighted version of the jaccard coefficient, as shown in (8).
</nextsent>
<nextsent>the words associated with distributions and  are indicated by cj and clk , respectively.
</nextsent>
<nextsent>= 1m?  on prqts  bd cj ffu bm clk   p  v/ bm cj u bd clk ff  (8) ! # and =6 1?@?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q925">
<title id=" P03-1038.xml">self organizing markov models and their application to partofspeech tagging </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a series of comparative experiments show the resulting models outperform uniform memory markov models in part-of-speech tagging task.
</prevsent>
<prevsent>many major nlp tasks can be regarded as problems of finding an optimal valuation for randomprocesses.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
for example, forgiven word sequence, part-of-speech (pos) tagging involves finding an optimal sequence of syntactic classes, and np chunking involves finding iob tag sequences (eachof which represents the inside, outside and beginning of noun phrases respectively).many machine learning techniques have been developed to tackle such random process tasks, which include hidden markov models (hmms) (rabiner,1989), maximum entropy models (mes) (rat naparkhi, 1996), <papid> W96-0213 </papid>support vector machines (svms) (vapnik, 1998), etc. among them, svms have high memory capacity and show high performance, especially when the target classification requires the consideration of various features.</citsent>
<aftsection>
<nextsent>on the other hand, hmms have low memory capacity but they work very well, especially when the target task involves series of classifications that are tightly related to each other and requires global optimization of them.
</nextsent>
<nextsent>as for pos tagging, recent comparisons (brants, 2000; <papid> A00-1031 </papid>schroder, 2001) show that hmms work better than other models when they are combined with good smoothing techniques and with handling of unknown words.</nextsent>
<nextsent>while global optimization is the strong point of hmms, developers often complain that it is difficult to make hmms incorporate various features and to improve them beyond given performances.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q926">
<title id=" P03-1038.xml">self organizing markov models and their application to partofspeech tagging </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, forgiven word sequence, part-of-speech (pos) tagging involves finding an optimal sequence of syntactic classes, and np chunking involves finding iob tag sequences (eachof which represents the inside, outside and beginning of noun phrases respectively).many machine learning techniques have been developed to tackle such random process tasks, which include hidden markov models (hmms) (rabiner,1989), maximum entropy models (mes) (rat naparkhi, 1996), <papid> W96-0213 </papid>support vector machines (svms) (vapnik, 1998), etc. among them, svms have high memory capacity and show high performance, especially when the target classification requires the consideration of various features.</prevsent>
<prevsent>on the other hand, hmms have low memory capacity but they work very well, especially when the target task involves series of classifications that are tightly related to each other and requires global optimization of them.</prevsent>
</prevsection>
<citsent citstr=" A00-1031 ">
as for pos tagging, recent comparisons (brants, 2000; <papid> A00-1031 </papid>schroder, 2001) show that hmms work better than other models when they are combined with good smoothing techniques and with handling of unknown words.</citsent>
<aftsection>
<nextsent>while global optimization is the strong point of hmms, developers often complain that it is difficult to make hmms incorporate various features and to improve them beyond given performances.
</nextsent>
<nextsent>forex ample, we often find that in some cases certain lexical context can improve the performance of anhmm-based pos tagger, but incorporating such additional features is not easy and it may even degrade the overall performance.
</nextsent>
<nextsent>because markov model shave the structure of tightly coupled states, an arbitrary change without elaborate consideration can spoil the overall structure.
</nextsent>
<nextsent>this paper presents way of utilizing statistical decision trees to systematically raise the memory capacity of markov models and effectively to make markov models be able to accommodate various features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q928">
<title id=" P03-1038.xml">self organizing markov models and their application to partofspeech tagging </title>
<section> related works.  </section>
<citcontext>
<prevsection>
<prevsent>in the case of context extension from lower context to higher like the example sin figure 1, the extension involves taking more information about the same type of contextual features.we call this kind of extension homogeneous context extension.
</prevsent>
<prevsent>(brants, 1998) presents this type of context extension method through model merging and splitting, and also prediction suffix tree learning (schutze and singer, 1994; d. ron et. al, 1996)is another well-known method that can perform homogeneous context extension.on the other hand, figure 2 illustrates heterogeneous context extension, in other words, this type of extension involves taking more information about other types of contextual features.
</prevsent>
</prevsection>
<citsent citstr=" W99-0615 ">
(kim et. al, 1999)<papid> W99-0615 </papid>and (pla and molina, 2001) present this type of context extension method, so called selective lexicaliza tion.</citsent>
<aftsection>
<nextsent>the selective extension can be good alternative to the uniform extension, because the growth rate of the model size is much smaller, and thus various contextual features can be exploited.
</nextsent>
<nextsent>in the follow vp c $ $ n vp-1 $ n vfigure 3: markov model and its equivalent decision tree ing sections, we describe novel method of selective extension of context which performs both homogeneous and heterogeneous extension simultaneously.
</nextsent>
<nextsent>our approach to the selective context extension is making use of the statistical decision tree framework.
</nextsent>
<nextsent>the states of markov models are represented in statistical decision trees, and by growing the trees the context can be extended (or the states can be split).we have named the resulting models self organizing markov models to reflect their ability to automatically organize the structure.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q930">
<title id=" P04-1063.xml">multiengine machine translation with voted language model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in ir (information retrieval), we find some efforts going (under the name of distributed ir or meta-search) to selectively fuse outputs from multiple search engines on the internet (callan et al, 2003).
</prevsent>
<prevsent>so it would be curious to see whether we could do the same with mts.
</prevsent>
</prevsection>
<citsent citstr=" A94-1016 ">
now back in machine translation, we do find some work addressing such concern: frederking and nirenburg (1994) <papid> A94-1016 </papid>develop multi-engine mtor memt architecture which operates by combining outputs from three different engines based on the knowledge it has about inner workings ofeach of the component engines.</citsent>
<aftsection>
<nextsent>brown and frederking (1995) is continuation of frederking and nirenburg (1994) <papid> A94-1016 </papid>with an addition of ngram based mechanism for candidate selection.</nextsent>
<nextsent>nomoto(2003), however, explores different line of research whose goal is to combine black box mts using statistical confidence models.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q932">
<title id=" P04-1063.xml">multiengine machine translation with voted language model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>brown and frederking (1995) is continuation of frederking and nirenburg (1994) <papid> A94-1016 </papid>with an addition of ngram based mechanism for candidate selection.</prevsent>
<prevsent>nomoto(2003), however, explores different line of research whose goal is to combine black box mts using statistical confidence models.</prevsent>
</prevsection>
<citsent citstr=" C02-1076 ">
similar efforts are also found in akiba et al (2002).<papid> C02-1076 </papid></citsent>
<aftsection>
<nextsent>the present paper builds on the prior work by nomoto (2003).
</nextsent>
<nextsent>we start by reviewing his approach, and go on to demonstrate that it could be improved by capitalizing on dependence of the memt model there on language model.
</nextsent>
<nextsent>throughout the paper, we refer to commercial black box mt systems as ots (off-the-shelf) systems, or more simply, otss.
</nextsent>
<nextsent>we take it here that the business of memt is about choosing among translation outputs from multiplemt systems, whether black box or not, for each in put text.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q933">
<title id=" P04-1063.xml">multiengine machine translation with voted language model </title>
<section> confidence models.  </section>
<citcontext>
<prevsection>
<prevsent>alm extends flm to include some information on fidelity.
</prevsent>
<prevsent>that is, it pays some attention to how faithful translation is to its source text.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
alm does this by using alignment models from the statistical machine translation literature (brown et al, 1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>here is what alm looks like.
</nextsent>
<nextsent>alm(e, j) = logpl(j)q(e | j) q(e | j) is the probability estimated using ibm model 1.
</nextsent>
<nextsent>alm takes into account the fluency of translation output (given by pl(j)) and the degree of association between and (given by q(e | j)), which are in fact two features generally agreed in the mt literature to be most relevant for assessing the quality of translations (white, 2001).
</nextsent>
<nextsent>one problem with flm and alm is that they failto take into account the reliability of an ots system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q934">
<title id=" P04-1063.xml">multiengine machine translation with voted language model </title>
<section> confidence models.  </section>
<citcontext>
<prevsection>
<prevsent>this would give us the following two svr models with = 1.
</prevsent>
<prevsent>regressive flm (rflm) h(flm(e, j)) = w1 ? flm(e, j) + regressive alm (ralm) h(alm(e, j)) = w1 alm(e, j) + notice that h(?)
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
here is supposed to relate flm or alm to some independent evaluation metric suchas bleu (papineni et al, 2002), <papid> P02-1040 </papid>not the log likelihood of translation.</citsent>
<aftsection>
<nextsent>with confidence models in place, define memt model ? by: ?(e, j, l) = arg maxjj(?(e, | l))here represents source sentence, a set of translations for generated by otss, and ? denotes some confidence model under an lm l. throughout the rest of the paper, we let flm?
</nextsent>
<nextsent>and alm?
</nextsent>
<nextsent>denotememt systems based on flm and alm, respectively, and similarly for others.
</nextsent>
<nextsent>we assume here that the memt works on asentence-by-sentence basis.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q936">
<title id=" N12-1062.xml">tuning as linear regression </title>
<section> abstract </section>
<citcontext>
<prevsection>

<prevsent>we propose tuning method for statistical machine translation, based on the pairwise ranking approach.
</prevsent>
</prevsection>
<citsent citstr=" D11-1125 ">
hopkins and may (2011) <papid> D11-1125 </papid>presented method that uses binary classifier.</citsent>
<aftsection>
<nextsent>in this work, we use linear regression andshow that our approach is as effective as using binary classifier and converges faster.
</nextsent>
<nextsent>since its introduction, the minimum error rate training (mert) (och, 2003) <papid> P03-1021 </papid>method has been the most popular method used for parameter tuning in machine translation.</nextsent>
<nextsent>although mert has nice properties such as simplicity, effectiveness and speed, it isknown to not scale well for systems with large numbers of features.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q940">
<title id=" N12-1062.xml">tuning as linear regression </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>hopkins and may (2011) <papid> D11-1125 </papid>presented method that uses binary classifier.</prevsent>
<prevsent>in this work, we use linear regression andshow that our approach is as effective as using binary classifier and converges faster.</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
since its introduction, the minimum error rate training (mert) (och, 2003) <papid> P03-1021 </papid>method has been the most popular method used for parameter tuning in machine translation.</citsent>
<aftsection>
<nextsent>although mert has nice properties such as simplicity, effectiveness and speed, it isknown to not scale well for systems with large numbers of features.
</nextsent>
<nextsent>one alternative that has been used for large numbers of features is the margin infused relaxed algorithm (mira) (chiang et al, 2008).<papid> D08-1024 </papid></nextsent>
<nextsent>mira works well with large number of features,but the optimization problem is much more complicated than mert.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q941">
<title id=" N12-1062.xml">tuning as linear regression </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>since its introduction, the minimum error rate training (mert) (och, 2003) <papid> P03-1021 </papid>method has been the most popular method used for parameter tuning in machine translation.</prevsent>
<prevsent>although mert has nice properties such as simplicity, effectiveness and speed, it isknown to not scale well for systems with large numbers of features.</prevsent>
</prevsection>
<citsent citstr=" D08-1024 ">
one alternative that has been used for large numbers of features is the margin infused relaxed algorithm (mira) (chiang et al, 2008).<papid> D08-1024 </papid></citsent>
<aftsection>
<nextsent>mira works well with large number of features,but the optimization problem is much more complicated than mert.
</nextsent>
<nextsent>mira also involves some modifications to the decoder itself to produce hypotheses with high scores against gold translations.
</nextsent>
<nextsent>hopkins and may (2011) <papid> D11-1125 </papid>introduced the method of pairwise ranking optimization (pro), which casts the problem of tuning as ranking problem between pairs of translation candidates.</nextsent>
<nextsent>the problem is solved by doing binary classification between correctly ordered?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q954">
<title id=" N12-1062.xml">tuning as linear regression </title>
<section> tuning as ranking.  </section>
<citcontext>
<prevsection>
<prevsent>the most commonly used gold scoring function in machine translation is the bleu score, which is calculated for the entire corpus, rather than for individual sentences.
</prevsent>
<prevsent>to use bleu as our gold scoring function, we need to modify it to make it decomposable for single sentences.
</prevsent>
</prevsection>
<citsent citstr=" C04-1072 ">
one way to do this is to use variation of bleu called bleu+1 (lin and och, 2004), <papid> C04-1072 </papid>which is smoothed version of the bleu score.</citsent>
<aftsection>
<nextsent>we assume that our machine translation system scores translations by using scoring function which is linear combination of the features: h(e) = wtx(e) (1)where is the weight vector and is the feature vector.
</nextsent>
<nextsent>the goal of tuning as ranking is learning weights such that for every two candidate translations e1 and e2, the following inequality holds: g(e1)   g(e2) ? h(e1)   h(e2) (2) using equation 1, we can rewrite equation 2: g(e1)   g(e2) ? wt(x(e1) ? x(e2))   0 (3)this problem can be viewed as binary classification problem for learning w, where each data point is the difference vector between the feature vectors of pair of translation candidates, and the target of the point is the sign of the difference between their gold scores (bleu+1).
</nextsent>
<nextsent>pro uses the megam classifier to solve this problem.
</nextsent>
<nextsent>megam is binary maximum entropy classifier which returns the weight vectorw as linear classifier.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q956">
<title id=" N12-1062.xml">tuning as linear regression </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>they are drawn from the newswire portion of nist evaluations (2004, 2005, 2006).
</prevsent>
<prevsent>the development set and the test set only had sentences with less than 30 words for decoding speed.
</prevsent>
</prevsection>
<citsent citstr=" N04-1035 ">
we extracted general scfg (ghkm) grammar using standard methods (galley et al, 2004; <papid> N04-1035 </papid>wanget al, 2010) <papid> J10-2004 </papid>from the parallel corpus with modification to preclude any unary rules (chung et al, 2011).<papid> P11-2072 </papid></citsent>
<aftsection>
<nextsent>all rules over scope 3 are pruned (hopkinsand langmead, 2010).<papid> D10-1063 </papid></nextsent>
<nextsent>a set of nine standard features was used for the experiments, which includes globally normalized count of rules, lexical weighting (koehn et al, 2003), and length penalty.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q957">
<title id=" N12-1062.xml">tuning as linear regression </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>they are drawn from the newswire portion of nist evaluations (2004, 2005, 2006).
</prevsent>
<prevsent>the development set and the test set only had sentences with less than 30 words for decoding speed.
</prevsent>
</prevsection>
<citsent citstr=" J10-2004 ">
we extracted general scfg (ghkm) grammar using standard methods (galley et al, 2004; <papid> N04-1035 </papid>wanget al, 2010) <papid> J10-2004 </papid>from the parallel corpus with modification to preclude any unary rules (chung et al, 2011).<papid> P11-2072 </papid></citsent>
<aftsection>
<nextsent>all rules over scope 3 are pruned (hopkinsand langmead, 2010).<papid> D10-1063 </papid></nextsent>
<nextsent>a set of nine standard features was used for the experiments, which includes globally normalized count of rules, lexical weighting (koehn et al, 2003), and length penalty.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q958">
<title id=" N12-1062.xml">tuning as linear regression </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>they are drawn from the newswire portion of nist evaluations (2004, 2005, 2006).
</prevsent>
<prevsent>the development set and the test set only had sentences with less than 30 words for decoding speed.
</prevsent>
</prevsection>
<citsent citstr=" P11-2072 ">
we extracted general scfg (ghkm) grammar using standard methods (galley et al, 2004; <papid> N04-1035 </papid>wanget al, 2010) <papid> J10-2004 </papid>from the parallel corpus with modification to preclude any unary rules (chung et al, 2011).<papid> P11-2072 </papid></citsent>
<aftsection>
<nextsent>all rules over scope 3 are pruned (hopkinsand langmead, 2010).<papid> D10-1063 </papid></nextsent>
<nextsent>a set of nine standard features was used for the experiments, which includes globally normalized count of rules, lexical weighting (koehn et al, 2003), and length penalty.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q959">
<title id=" N12-1062.xml">tuning as linear regression </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the development set and the test set only had sentences with less than 30 words for decoding speed.
</prevsent>
<prevsent>we extracted general scfg (ghkm) grammar using standard methods (galley et al, 2004; <papid> N04-1035 </papid>wanget al, 2010) <papid> J10-2004 </papid>from the parallel corpus with modification to preclude any unary rules (chung et al, 2011).<papid> P11-2072 </papid></prevsent>
</prevsection>
<citsent citstr=" D10-1063 ">
all rules over scope 3 are pruned (hopkinsand langmead, 2010).<papid> D10-1063 </papid></citsent>
<aftsection>
<nextsent>a set of nine standard features was used for the experiments, which includes globally normalized count of rules, lexical weighting (koehn et al, 2003), and length penalty.
</nextsent>
<nextsent>our in-house decoder was used for experiments with trigram language model.
</nextsent>
<nextsent>the decoder is capable of both cnf parsing and earley-style parsing with cube-pruning (chiang, 2007).<papid> J07-2003 </papid></nextsent>
<nextsent>we implemented linear regression tuning using1we randomly sampled our data from various different sources (ldc2006e86, ldc2006e93, ldc2002e18, ldc2002l27, ldc2003e07, ldc2003e14, ldc2004t08, ldc2005t06, ldc2005t10, ldc2005t34, ldc2006e26, ldc2005e83, ldc2006e34, ldc2006e85, ldc2006e92, ldc2006e24, ldc2006e92, ldc2006e24) the language model is trained on the english side of entire data (1.65m sentences, which is 39.3m words.)</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q960">
<title id=" N12-1062.xml">tuning as linear regression </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>a set of nine standard features was used for the experiments, which includes globally normalized count of rules, lexical weighting (koehn et al, 2003), and length penalty.
</prevsent>
<prevsent>our in-house decoder was used for experiments with trigram language model.
</prevsent>
</prevsection>
<citsent citstr=" J07-2003 ">
the decoder is capable of both cnf parsing and earley-style parsing with cube-pruning (chiang, 2007).<papid> J07-2003 </papid></citsent>
<aftsection>
<nextsent>we implemented linear regression tuning using1we randomly sampled our data from various different sources (ldc2006e86, ldc2006e93, ldc2002e18, ldc2002l27, ldc2003e07, ldc2003e14, ldc2004t08, ldc2005t06, ldc2005t10, ldc2005t34, ldc2006e26, ldc2005e83, ldc2006e34, ldc2006e85, ldc2006e92, ldc2006e24, ldc2006e92, ldc2006e24) the language model is trained on the english side of entire data (1.65m sentences, which is 39.3m words.)
</nextsent>
<nextsent>average of max bleu max bleu dev test dev test regression 27.7 (0.91) 26.4 (0.82) 29.0 27.6 pro 26.9 (1.05) 25.6 (0.84) 28.0 27.2table 1: average of maximum bleu scores of the experiments and the maximum bleu score from the experiments.
</nextsent>
<nextsent>numbers in the parentheses indicate standard of deviations of maximum bleu scores.the method explained in section 3.
</nextsent>
<nextsent>following hopkins and may (2011), <papid> D11-1125 </papid>we used the following parameters for the sampling task: for each sentence, the decoder generates the 1500 best candidate translations (k = 1500), and the sampler samples 5000 pairs (n = 5000).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q962">
<title id=" P01-1040.xml">a common framework for syntactic annotation </title>
<section> current practice.  </section>
<citcontext>
<prevsection>
<prevsent>relations among non-contiguous elements demand aspe cial numbering mechanism to enable cross reference, as in the specification of the np-sbj of the embedded sentence by reference to the earlier np-sbj-1 node.
</prevsent>
<prevsent>although they differ in the labels and in some cases the function of various nodes in the tree, most annotation schemes provide similar constituency-based representation of relations among syntactic components (see abeille, forthcoming, for comprehensive survey of syntactic annotation schemes).
</prevsent>
</prevsection>
<citsent citstr=" A97-1011 ">
in contrast, dependency schemes (e.g., sleator and temperley, 1993; tapanainen and jarvinen, 1997; <papid> A97-1011 </papid>carroll, et al, forthcoming) do not 3 http://www.cis.upenn.edu/treebank provide constituency analysis4 but rather specify grammatical relations among elements explicitly; for example, the sentence paul intends to leave ibm?</citsent>
<aftsection>
<nextsent>could be represented as shown in figure 2, where the predicate is the relation type, the first argument is the head, the second the dependent, and additional arguments may provide category-specific information (e.g., introducer for prepositional phrases, etc.).
</nextsent>
<nextsent>((s (np-sbj-1 jones) (vp followed) (np him) (pp-dir into (np the front room)) , (s-adv (np-sbj *-1) (vp closing (np the door) (pp behind (np him))))) .)) figure 1.
</nextsent>
<nextsent>ptb annotation of jones followed him into the front room, closing the door behind him.?
</nextsent>
<nextsent>subj(intend,paul,_) xcomp(intend,leave,to) subj(leave,paul) dobj(leave,ibm,_) figure 2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q963">
<title id=" P02-1003.xml">generation as dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>indeed,initial experiments display promising run times.
</prevsent>
<prevsent>existing algorithms for realization from flat input semantics all have run times which are exponential inthe worst case.
</prevsent>
</prevsection>
<citsent citstr=" C92-2092 ">
several different approaches to improving the runtime in practice have been suggested in the literature ? e.g. heuristics (brew, 1992) <papid> C92-2092 </papid>and factorizations into smaller exponential subproblems(kay, 1996; <papid> P96-1027 </papid>carroll et al , 1999).</citsent>
<aftsection>
<nextsent>while these solutions achieve some measure of success in making realization efficient, the contrast inefficiency to parsing is striking both in theory and in practice.the problematic run times of generation algorithms are explained by the fact that realization is an np-complete problem even using just context-free grammars, as brew (1992) <papid> C92-2092 </papid>showed in the context of shake-and-bake generation.</nextsent>
<nextsent>the first contribution of our paper is proof of stronger np-completeness result: if we allow semantic indices in the grammar, realization is np-complete even if we fix single grammar.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q964">
<title id=" P02-1003.xml">generation as dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>indeed,initial experiments display promising run times.
</prevsent>
<prevsent>existing algorithms for realization from flat input semantics all have run times which are exponential inthe worst case.
</prevsent>
</prevsection>
<citsent citstr=" P96-1027 ">
several different approaches to improving the runtime in practice have been suggested in the literature ? e.g. heuristics (brew, 1992) <papid> C92-2092 </papid>and factorizations into smaller exponential subproblems(kay, 1996; <papid> P96-1027 </papid>carroll et al , 1999).</citsent>
<aftsection>
<nextsent>while these solutions achieve some measure of success in making realization efficient, the contrast inefficiency to parsing is striking both in theory and in practice.the problematic run times of generation algorithms are explained by the fact that realization is an np-complete problem even using just context-free grammars, as brew (1992) <papid> C92-2092 </papid>showed in the context of shake-and-bake generation.</nextsent>
<nextsent>the first contribution of our paper is proof of stronger np-completeness result: if we allow semantic indices in the grammar, realization is np-complete even if we fix single grammar.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q967">
<title id=" P02-1003.xml">generation as dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it has been noted in the literature that this problem, too, becomes np-complete very easily (barton et al , 1987).
</prevsent>
<prevsent>the main point of this paper is to show how to encode generation with variant of tree-adjoininggrammars (tag) as parsing problem with dependency grammars (dg).
</prevsent>
</prevsection>
<citsent citstr=" P01-1024 ">
the particular variant of dg we use, topological dependency grammar (tdg) (duchier, 2002; duchier and debusmann, 2001), <papid> P01-1024 </papid>was developed specifically with efficient parsing forfree word order languages in mind.</citsent>
<aftsection>
<nextsent>the mere existence of this encoding proves tdgs parsing problem np-complete as well, result which has been conjectured but never formally shown so far.
</nextsent>
<nextsent>but itturns out that the complexities that arise in generation problems in practice seem to be precisely of the sort that the tdg parser can handle well.
</nextsent>
<nextsent>initial experiments with generating from the xtag grammar (xtag research group, 2001) suggest that our generation system is competitive with state-of-theart chart generators, and indeed seems to run in poly nomial time in practice.next to the attractive runtime behaviour, our approach to realization is interesting because it may provide us with different angle from which tolook for tractable fragments of the general realization problem.
</nextsent>
<nextsent>as we will show, the computation that takes place in our system is very different from that in chart generator, and may be more efficient insome cases by taking into account global information to guide local choices.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q968">
<title id=" P02-1003.xml">generation as dependency parsing </title>
<section> the realization problem.  </section>
<citcontext>
<prevsection>
<prevsent>we represent the semantic input as multi set (bag) of ground atoms of predicate logic, suchas {buy(e,a,b), name(a,mary) car(b)}.
</prevsent>
<prevsent>to encode syntactic information, we use tree-adjoininggrammar without feature structures (joshi and schabes, 1997).
</prevsent>
</prevsection>
<citsent citstr=" P97-1026 ">
following stone and doran (1997) <papid> P97-1026 </papid>and kay (1996), <papid> P96-1027 </papid>we enhance this tag grammar with syntax-semantics interface in which nonterminal nodes of the elementary trees are equipped with index variables, which can be bound to individuals in the semantic input.</citsent>
<aftsection>
<nextsent>we assume that the root node,all substitution nodes, and all nodes that admit adjunction carry such index variables.
</nextsent>
<nextsent>we also assigna semantics to every elementary tree, so that lexical entries are pairs of the form (?, ), where ? is multi set of semantic atoms, and is an initial or auxiliary tree, e.g.
</nextsent>
<nextsent>( {buy(x,y,z)}, s:x np:y
</nextsent>
<nextsent>vp:x v:x buys np:z
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q972">
<title id=" P02-1003.xml">generation as dependency parsing </title>
<section> generation as dependency parsing.  </section>
<citcontext>
<prevsection>
<prevsent>first, we assume that the nodes of the elementary trees of are not labelled with feature structures.
</prevsent>
<prevsent>next, we assume that whenever we can adjoin an auxiliary tree at node, we can adjoin arbitrarily many trees at this node.
</prevsent>
</prevsection>
<citsent citstr=" J94-1004 ">
the idea of multiple adjunction is not new (schabes and shieber, 1994), <papid> J94-1004 </papid>but itis simplified here because we disregard complex adjunction constraints.</citsent>
<aftsection>
<nextsent>we will discuss these two restrictions in the conclusion.
</nextsent>
<nextsent>finally, we assume that every lexical semantics ? has precisely one member; this restriction will be lifted in section 5.4.
</nextsent>
<nextsent>now lets say we want to find the realizations of the input semantics = {?
</nextsent>
<nextsent>1 , . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q973">
<title id=" P02-1003.xml">generation as dependency parsing </title>
<section> generation as dependency parsing.  </section>
<citcontext>
<prevsection>
<prevsent>however, there are cases where an elementary tree either has anempty semantics, or semantics that contains multiple atoms.
</prevsent>
<prevsent>the first case can be avoided by exploiting tags extended domain of locality, see e.g.
</prevsent>
</prevsection>
<citsent citstr=" P01-1028 ">
(gardent and thater, 2001).<papid> P01-1028 </papid></citsent>
<aftsection>
<nextsent>the simplest possible way for dealing with the second case is to pre process the input into several 1a newer version of carroll et al system generates (1) in 420 milliseconds (copestake, p.c.).
</nextsent>
<nextsent>our times were measured on 700 mhz pentium-iii pc.
</nextsent>
<nextsent>different parsing problems.
</nextsent>
<nextsent>in first step, we collect all possible instantiations of ltag lexical entries matching subsets of the semantics.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q983">
<title id=" P03-1069.xml">probabilistic text structuring experiments with sentence ordering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the latter are ope rationalized as weights on the ordering and adjacency of facts and are derived from corpus of naturally occurring texts.
</prevsent>
<prevsent>a constraint satisfaction algorithm is used to find the tree with maximal weights from the space of all possible trees.
</prevsent>
</prevsection>
<citsent citstr=" W98-1411 ">
mellish et al  (1998) <papid> W98-1411 </papid>advocate stochastic search as an alternative to exhaustively examining the search space.</citsent>
<aftsection>
<nextsent>rather than requiring global optimum to be found, they use genetic algorithm to select tree that is coherent enough for people to understand (local optimum).the problem of finding an acceptable ordering does not arise solely in concept-to-text generation but also in the emerging field of text-to-textgeneration (barzilay, 2003).
</nextsent>
<nextsent>examples of applications that require some form of text structuring, are single- and multi document summarization as well as question answering.
</nextsent>
<nextsent>note that these applications donot typically assume rich semantic knowledge organized in tree-like structures or communicative goalsas is often the case in concept-to-text generation.
</nextsent>
<nextsent>although in single document summarization the position of sentence in document can provide cues with respect to its ordering in the summary, this is not the case in multi document summarization where sentences are selected from different documents andmust be somehow ordered so as to produce coherent summary (barzilay et al , 2002).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q987">
<title id=" P03-1069.xml">probabilistic text structuring experiments with sentence ordering </title>
<section> parameter estimation.  </section>
<citcontext>
<prevsection>
<prevsent>the parser is amaximum-entropy inspired?
</prevsent>
<prevsent>probabilistic generative model.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
it achieves 90.1% average preci sion/recall for sentences with maximum length 40 and 89.5% for sentences with maximum length 100 when trained and tested on the standard sections of the wall street journal treebank (marcus et al , 1993).<papid> J93-2004 </papid></citsent>
<aftsection>
<nextsent>we also obtained dependency-style version of the corpus using minipar (lin, 1998) broad coverage parser for english which employs manually constructed grammar and lexicon derived from wordnet with an additional dictionary of proper names (130,000 entries in total).
</nextsent>
<nextsent>the grammar is represented as network of 35 nodes (i.e., grammatical categories) and 59 edges (i.e., types of syntactic (dependency) relations).
</nextsent>
<nextsent>the output of minipar is dependency graph which represents the dependency relations between words in sentence (see table 1 for an example).
</nextsent>
<nextsent>lin (1998) evaluated the parser onthe susanne corpus (sampson, 1996), domain independent corpus of british english, and achieved arecall of 79% and precision of 89% on the dependency relations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q988">
<title id=" P03-1069.xml">probabilistic text structuring experiments with sentence ordering </title>
<section> parameter estimation.  </section>
<citcontext>
<prevsection>
<prevsent>for the lemmatized version, sentence (1) will be represented by say, will, be, ask, and approve; for the tensed version, the relevant features will be said, will be asked, and to approve.
</prevsent>
<prevsent>nouns.
</prevsent>
</prevsection>
<citsent citstr=" J95-2003 ">
centering theory (ct, grosz et al  1995) <papid> J95-2003 </papid>is an entity-based theory of local coherence, which claims that certain entities mentioned in an utterance are more central than others and that this property constrains speakers use of certain referring expressions.</citsent>
<aftsection>
<nextsent>the principles underlying ct (e.g., continuity, salience) are of interest to concept-to-text generation as they offer an entity-based model of text and sentence planning which is particularly suited for descript ional genres (kibble and power, 2000).<papid> W00-1411 </papid></nextsent>
<nextsent>we ope rationalize entity-based coherence for text-to-text generation by simply keeping track of the nouns attested in sentence without however taking personal pronouns into account.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q989">
<title id=" P03-1069.xml">probabilistic text structuring experiments with sentence ordering </title>
<section> parameter estimation.  </section>
<citcontext>
<prevsection>
<prevsent>nouns.
</prevsent>
<prevsent>centering theory (ct, grosz et al  1995) <papid> J95-2003 </papid>is an entity-based theory of local coherence, which claims that certain entities mentioned in an utterance are more central than others and that this property constrains speakers use of certain referring expressions.</prevsent>
</prevsection>
<citsent citstr=" W00-1411 ">
the principles underlying ct (e.g., continuity, salience) are of interest to concept-to-text generation as they offer an entity-based model of text and sentence planning which is particularly suited for descript ional genres (kibble and power, 2000).<papid> W00-1411 </papid></citsent>
<aftsection>
<nextsent>we ope rationalize entity-based coherence for text-to-text generation by simply keeping track of the nouns attested in sentence without however taking personal pronouns into account.
</nextsent>
<nextsent>this simplification is reasonable if one has text-to-text generation mind.
</nextsent>
<nextsent>in multi document summarization for example, sentences are extracted from different docu ments; the referents of the pronouns attested in these sentences are typically not known and in some cases identical pronouns may refer to different entities.
</nextsent>
<nextsent>so making use of noun-pronoun or pronoun-pronounco-occurrences will be uninformative or in fact misleading.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q990">
<title id=" P02-1012.xml">pronominal ization in generated discourse and dialogue </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>even worse, incorrect pronouns can lead readers to misinterpret the text or draw unsound inferences.
</prevsent>
<prevsent>furthermore, current pronominal ization strategies are ill-equipped to deal with the wide variety of reasons that pronouns are used in naturally occur ring texts.
</prevsent>
</prevsection>
<citsent citstr=" J86-3001 ">
almost without exception, they focus on anaphoric pronouns as described in focus/centeringtheory (webber, 1979; sidner, 1983; grosz and sid ner, 1986; <papid> J86-3001 </papid>walker, 1998), ignoring the multitude of other possible types.</citsent>
<aftsection>
<nextsent>however, it is certainly true that authors make use of pronouns which are not motivated by anaphoric reference.
</nextsent>
<nextsent>in addition, because such approaches are oriented towards anaphora resolution during parsing, they ignore structures such as the discourse plan which are present during generation but not parsing.
</nextsent>
<nextsent>a typical discourse plan can include vital information forpronominalization such as time and clause boundaries, ordering of propositions, and semantic details verbal arguments.
</nextsent>
<nextsent>current approaches based on centering algorithms thus attempt to recreate text coherence structure that duplicates work already done by the discourse planner.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q991">
<title id=" P02-1012.xml">pronominal ization in generated discourse and dialogue </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a typical discourse plan can include vital information forpronominalization such as time and clause boundaries, ordering of propositions, and semantic details verbal arguments.
</prevsent>
<prevsent>current approaches based on centering algorithms thus attempt to recreate text coherence structure that duplicates work already done by the discourse planner.
</prevsent>
</prevsection>
<citsent citstr=" C96-2143 ">
finally, there are significant obstacles to verifying the correctness of existing pronominal ization algorithms for any pronominal ization theory (not, 1996; <papid> C96-2143 </papid>yeh and mellish, 1997; <papid> J97-1007 </papid>mccoy and strube, 1999; henschel et al , 2000; <papid> C00-1045 </papid>kibble and power, 2000): <papid> W00-1411 </papid>the lack of natural language generation systems that can produce large enough texts to bring discourse-level processes into play.</citsent>
<aftsection>
<nextsent>because of this, researchers are forced to simulate by hand how their algorithms will work on given text.
</nextsent>
<nextsent>it is also not sufficient to use template generation systems to perform this task because they lack the low-level discourse representation needed to provide the information upon which most algorithms base their decisions.
</nextsent>
<nextsent>in this paper we first summarize related workin both anaphora resolution and anaphora generation.
</nextsent>
<nextsent>we next describe the range of pronoun types computational linguistics (acl), philadelphia, july 2002, pp.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q993">
<title id=" P02-1012.xml">pronominal ization in generated discourse and dialogue </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a typical discourse plan can include vital information forpronominalization such as time and clause boundaries, ordering of propositions, and semantic details verbal arguments.
</prevsent>
<prevsent>current approaches based on centering algorithms thus attempt to recreate text coherence structure that duplicates work already done by the discourse planner.
</prevsent>
</prevsection>
<citsent citstr=" J97-1007 ">
finally, there are significant obstacles to verifying the correctness of existing pronominal ization algorithms for any pronominal ization theory (not, 1996; <papid> C96-2143 </papid>yeh and mellish, 1997; <papid> J97-1007 </papid>mccoy and strube, 1999; henschel et al , 2000; <papid> C00-1045 </papid>kibble and power, 2000): <papid> W00-1411 </papid>the lack of natural language generation systems that can produce large enough texts to bring discourse-level processes into play.</citsent>
<aftsection>
<nextsent>because of this, researchers are forced to simulate by hand how their algorithms will work on given text.
</nextsent>
<nextsent>it is also not sufficient to use template generation systems to perform this task because they lack the low-level discourse representation needed to provide the information upon which most algorithms base their decisions.
</nextsent>
<nextsent>in this paper we first summarize related workin both anaphora resolution and anaphora generation.
</nextsent>
<nextsent>we next describe the range of pronoun types computational linguistics (acl), philadelphia, july 2002, pp.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q995">
<title id=" P02-1012.xml">pronominal ization in generated discourse and dialogue </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a typical discourse plan can include vital information forpronominalization such as time and clause boundaries, ordering of propositions, and semantic details verbal arguments.
</prevsent>
<prevsent>current approaches based on centering algorithms thus attempt to recreate text coherence structure that duplicates work already done by the discourse planner.
</prevsent>
</prevsection>
<citsent citstr=" C00-1045 ">
finally, there are significant obstacles to verifying the correctness of existing pronominal ization algorithms for any pronominal ization theory (not, 1996; <papid> C96-2143 </papid>yeh and mellish, 1997; <papid> J97-1007 </papid>mccoy and strube, 1999; henschel et al , 2000; <papid> C00-1045 </papid>kibble and power, 2000): <papid> W00-1411 </papid>the lack of natural language generation systems that can produce large enough texts to bring discourse-level processes into play.</citsent>
<aftsection>
<nextsent>because of this, researchers are forced to simulate by hand how their algorithms will work on given text.
</nextsent>
<nextsent>it is also not sufficient to use template generation systems to perform this task because they lack the low-level discourse representation needed to provide the information upon which most algorithms base their decisions.
</nextsent>
<nextsent>in this paper we first summarize related workin both anaphora resolution and anaphora generation.
</nextsent>
<nextsent>we next describe the range of pronoun types computational linguistics (acl), philadelphia, july 2002, pp.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q997">
<title id=" P02-1012.xml">pronominal ization in generated discourse and dialogue </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a typical discourse plan can include vital information forpronominalization such as time and clause boundaries, ordering of propositions, and semantic details verbal arguments.
</prevsent>
<prevsent>current approaches based on centering algorithms thus attempt to recreate text coherence structure that duplicates work already done by the discourse planner.
</prevsent>
</prevsection>
<citsent citstr=" W00-1411 ">
finally, there are significant obstacles to verifying the correctness of existing pronominal ization algorithms for any pronominal ization theory (not, 1996; <papid> C96-2143 </papid>yeh and mellish, 1997; <papid> J97-1007 </papid>mccoy and strube, 1999; henschel et al , 2000; <papid> C00-1045 </papid>kibble and power, 2000): <papid> W00-1411 </papid>the lack of natural language generation systems that can produce large enough texts to bring discourse-level processes into play.</citsent>
<aftsection>
<nextsent>because of this, researchers are forced to simulate by hand how their algorithms will work on given text.
</nextsent>
<nextsent>it is also not sufficient to use template generation systems to perform this task because they lack the low-level discourse representation needed to provide the information upon which most algorithms base their decisions.
</nextsent>
<nextsent>in this paper we first summarize related workin both anaphora resolution and anaphora generation.
</nextsent>
<nextsent>we next describe the range of pronoun types computational linguistics (acl), philadelphia, july 2002, pp.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q999">
<title id=" P02-1012.xml">pronominal ization in generated discourse and dialogue </title>
<section> background and related work.  </section>
<citcontext>
<prevsection>
<prevsent>since pronouns are more likely to be multi paragraph, discourse-level phenomenon, it has been possible to ignore their inclusion into working nlg systems which are not called upon to generate lengthy passages.
</prevsent>
<prevsent>indeed, most work on pronouns in computational linguistics has come under the heading of anaphora resolution as an element of parsing rather than the heading of pronominal ization as an element of generation.
</prevsent>
</prevsection>
<citsent citstr=" J95-2003 ">
since discourse anaphora resolution was first studied theoretically (grosz, 1977; webber, 1979; sidner, 1983; grosz and sidner, 1986), <papid> J86-3001 </papid>it has come to be dominated by centering theory (grosz et al , 1995; <papid> J95-2003 </papid>di eugenio, 1998; walker, 1998) which proposes rules for the determination of focus and salience within given segment of discourse.</citsent>
<aftsection>
<nextsent>relatively little work has been done on alternate approaches to pronoun resolution (hobbs, 1976; baldwin, 1995).
</nextsent>
<nextsent>while many nlg researchers have attempted to transfer the ideas of centering theory to generation (not, 1996; <papid> C96-2143 </papid>yeh and mellish, 1997; <papid> J97-1007 </papid>mccoy and strube, 1999; henschel et al , 2000; <papid> C00-1045 </papid>kibbleand power, 2000), <papid> W00-1411 </papid>there has yet been no substantial return contribution to the field of anaphora res olution.</nextsent>
<nextsent>there are two principal reasons for this.first, it is extremely difficult to create an nlg system that generates the large quantity of texts needed to exhibit discourse-level phenomena while consistently employing the deep linguistic representations needed to determine appropriate pronominal forms.second, centering theory is still vague on the exact definition of terms such as segment?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1007">
<title id=" P02-1012.xml">pronominal ization in generated discourse and dialogue </title>
<section> reflexive and reciprocal pronouns: most.  </section>
<citcontext>
<prevsection>
<prevsent>8.
</prevsent>
<prevsent>focused nouns: especially after vocally.
</prevsent>
</prevsection>
<citsent citstr=" C00-2133 ">
stressed discourse marker (wolters and byron, 2000) <papid> C00-2133 </papid>or some other marked shift in topic, word that normally would be pronominal ized is often not, as in this example: . . .</citsent>
<aftsection>
<nextsent>and you frequently find that mice occupy an important part of the modern medical laboratory.
</nextsent>
<nextsent>in other words, mice are especially necessary for diagnosing human cancers . . .
</nextsent>
<nextsent>9.
</nextsent>
<nextsent>semantic and syntactic considerations: a. small number of semantic relations and syntactic constructions prohibit pronominalization: * the stranger was just called him.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1011">
<title id=" P03-1036.xml">unsupervised segmentation of words using prior distributions of morph length and frequency </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>alternatively, an interesting field of research liesopen: minimally supervised algorithms can be designed that automatically discover morphemes ormorpheme-like units from data.
</prevsent>
<prevsent>there exist number of such algorithms, some of which are entirely unsupervised and others that use some knowledge ofthe language.
</prevsent>
</prevsection>
<citsent citstr=" J01-2001 ">
in the following, we discuss recent unsupervised algorithms and refer the reader to (gold smith, 2001) <papid> J01-2001 </papid>for comprehensive survey of previous research in the whole field.</citsent>
<aftsection>
<nextsent>many algorithms proceed by segmenting (i.e., splitting) words into smaller components.
</nextsent>
<nextsent>often the limiting assumption is made that words consist of only one stem followed by one (possibly empty) suffix (dejean, 1998; snover and brent, 2001; <papid> P01-1063 </papid>snover et al, 2002).<papid> W02-0602 </papid></nextsent>
<nextsent>this limitation is reduced in (goldsmith, 2001) <papid> J01-2001 </papid>by allowing recursive structure, where stems can have inner structure, so that they in turn consist of substem and suffix.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1012">
<title id=" P03-1036.xml">unsupervised segmentation of words using prior distributions of morph length and frequency </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the following, we discuss recent unsupervised algorithms and refer the reader to (gold smith, 2001) <papid> J01-2001 </papid>for comprehensive survey of previous research in the whole field.</prevsent>
<prevsent>many algorithms proceed by segmenting (i.e., splitting) words into smaller components.</prevsent>
</prevsection>
<citsent citstr=" P01-1063 ">
often the limiting assumption is made that words consist of only one stem followed by one (possibly empty) suffix (dejean, 1998; snover and brent, 2001; <papid> P01-1063 </papid>snover et al, 2002).<papid> W02-0602 </papid></citsent>
<aftsection>
<nextsent>this limitation is reduced in (goldsmith, 2001) <papid> J01-2001 </papid>by allowing recursive structure, where stems can have inner structure, so that they in turn consist of substem and suffix.</nextsent>
<nextsent>also prefixes are possible.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1013">
<title id=" P03-1036.xml">unsupervised segmentation of words using prior distributions of morph length and frequency </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the following, we discuss recent unsupervised algorithms and refer the reader to (gold smith, 2001) <papid> J01-2001 </papid>for comprehensive survey of previous research in the whole field.</prevsent>
<prevsent>many algorithms proceed by segmenting (i.e., splitting) words into smaller components.</prevsent>
</prevsection>
<citsent citstr=" W02-0602 ">
often the limiting assumption is made that words consist of only one stem followed by one (possibly empty) suffix (dejean, 1998; snover and brent, 2001; <papid> P01-1063 </papid>snover et al, 2002).<papid> W02-0602 </papid></citsent>
<aftsection>
<nextsent>this limitation is reduced in (goldsmith, 2001) <papid> J01-2001 </papid>by allowing recursive structure, where stems can have inner structure, so that they in turn consist of substem and suffix.</nextsent>
<nextsent>also prefixes are possible.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1015">
<title id=" P03-1036.xml">unsupervised segmentation of words using prior distributions of morph length and frequency </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>also prefixes are possible.
</prevsent>
<prevsent>however, for languages with agglutinative morphology this may not be enough.
</prevsent>
</prevsection>
<citsent citstr=" W00-0712 ">
in finnish, word can consist of lengthy sequences of alternating stems and affixes.some morphology discovery algorithms learn relationships between words by comparing the orthographic or semantic similarity of the words (schone and jurafsky, 2000; <papid> W00-0712 </papid>neuvel and fulop, 2002; <papid> W02-0604 </papid>baroni et al, 2002).<papid> W02-0606 </papid></citsent>
<aftsection>
<nextsent>here small number of components per word are assumed, which makes the approaches difficult to apply as such to agglutinative languages.we previously presented two segmentation algorithms suitable for agglutinative languages (creutz and lagus, 2002)<papid> W02-0603 </papid></nextsent>
<nextsent>the algorithms learn set of segments, which we call morphs, from corpus.stems and affixes are not distinguished as separate categories by the algorithms, and in that sense they resemble algorithms for text segmentation and word discovery, such as (deligne and bimbot, 1997;brent, 1999; kit and wilks, 1999; yu, 2000).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1016">
<title id=" P03-1036.xml">unsupervised segmentation of words using prior distributions of morph length and frequency </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>also prefixes are possible.
</prevsent>
<prevsent>however, for languages with agglutinative morphology this may not be enough.
</prevsent>
</prevsection>
<citsent citstr=" W02-0604 ">
in finnish, word can consist of lengthy sequences of alternating stems and affixes.some morphology discovery algorithms learn relationships between words by comparing the orthographic or semantic similarity of the words (schone and jurafsky, 2000; <papid> W00-0712 </papid>neuvel and fulop, 2002; <papid> W02-0604 </papid>baroni et al, 2002).<papid> W02-0606 </papid></citsent>
<aftsection>
<nextsent>here small number of components per word are assumed, which makes the approaches difficult to apply as such to agglutinative languages.we previously presented two segmentation algorithms suitable for agglutinative languages (creutz and lagus, 2002)<papid> W02-0603 </papid></nextsent>
<nextsent>the algorithms learn set of segments, which we call morphs, from corpus.stems and affixes are not distinguished as separate categories by the algorithms, and in that sense they resemble algorithms for text segmentation and word discovery, such as (deligne and bimbot, 1997;brent, 1999; kit and wilks, 1999; yu, 2000).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1017">
<title id=" P03-1036.xml">unsupervised segmentation of words using prior distributions of morph length and frequency </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>also prefixes are possible.
</prevsent>
<prevsent>however, for languages with agglutinative morphology this may not be enough.
</prevsent>
</prevsection>
<citsent citstr=" W02-0606 ">
in finnish, word can consist of lengthy sequences of alternating stems and affixes.some morphology discovery algorithms learn relationships between words by comparing the orthographic or semantic similarity of the words (schone and jurafsky, 2000; <papid> W00-0712 </papid>neuvel and fulop, 2002; <papid> W02-0604 </papid>baroni et al, 2002).<papid> W02-0606 </papid></citsent>
<aftsection>
<nextsent>here small number of components per word are assumed, which makes the approaches difficult to apply as such to agglutinative languages.we previously presented two segmentation algorithms suitable for agglutinative languages (creutz and lagus, 2002)<papid> W02-0603 </papid></nextsent>
<nextsent>the algorithms learn set of segments, which we call morphs, from corpus.stems and affixes are not distinguished as separate categories by the algorithms, and in that sense they resemble algorithms for text segmentation and word discovery, such as (deligne and bimbot, 1997;brent, 1999; kit and wilks, 1999; yu, 2000).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1018">
<title id=" P03-1036.xml">unsupervised segmentation of words using prior distributions of morph length and frequency </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, for languages with agglutinative morphology this may not be enough.
</prevsent>
<prevsent>in finnish, word can consist of lengthy sequences of alternating stems and affixes.some morphology discovery algorithms learn relationships between words by comparing the orthographic or semantic similarity of the words (schone and jurafsky, 2000; <papid> W00-0712 </papid>neuvel and fulop, 2002; <papid> W02-0604 </papid>baroni et al, 2002).<papid> W02-0606 </papid></prevsent>
</prevsection>
<citsent citstr=" W02-0603 ">
here small number of components per word are assumed, which makes the approaches difficult to apply as such to agglutinative languages.we previously presented two segmentation algorithms suitable for agglutinative languages (creutz and lagus, 2002)<papid> W02-0603 </papid></citsent>
<aftsection>
<nextsent>the algorithms learn set of segments, which we call morphs, from corpus.stems and affixes are not distinguished as separate categories by the algorithms, and in that sense they resemble algorithms for text segmentation and word discovery, such as (deligne and bimbot, 1997;brent, 1999; kit and wilks, 1999; yu, 2000).
</nextsent>
<nextsent>how ever, we observed that for the corpus size studied (100 000 words), our two algorithms were somewhat prone to excessive segmentation of words.
</nextsent>
<nextsent>in this paper, we aim at overcoming the problem of excessive segmentation, particularly when small corpora (up to 200 000 words) are used for training.
</nextsent>
<nextsent>we present new segmentation algorithm, which is language independent and works in an unsupervised fashion.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1035">
<title id=" P02-1030.xml">scaling context space </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, the accuracy of part of speech taggers or word sense disambiguation systems depends on the quality and quantity of contextual information these systems can extract from the training data.
</prevsent>
<prevsent>when predicting the sense of word, for instance, the immediately preceding wordis likely to be more important than the tenth previous word; similar observations can be made about pos taggers or chunkers.
</prevsent>
</prevsection>
<citsent citstr=" P01-1005 ">
a crucial part of training these systems lies in extracting from the data high-quality contextual information, in the sense of defining contexts that are both accurate and correlated with the information (the pos tags, the word senses, the chunks) the system is trying to extract.the quality of contextual information is often determined by the size of the training corpus: with less data available, extracting context information for any given phenomenon becomes less reliable.however, corpus size is no longer limiting fac tor: whereas up to now people have typically worked with corpora of around one million words, it has become feasible to build much larger document collec tions; for example, banko and brill (2001) <papid> P01-1005 </papid>report on experiments with one billion word corpus.</citsent>
<aftsection>
<nextsent>when using much larger corpus and scaling the context space, there are, however, other trade-offs to take into consideration: the size of the corpus may make it unfeasible to train some systems because of efficiency issues or hardware costs; it may also result in an unmanageable expansion of the extracted context information, reducing the performance of the systems that have to make use of this information.this paper reports on experiments that try to establish some of the trade-offs between corpus size,processing time, hardware costs and the performance of the resulting systems.
</nextsent>
<nextsent>we report on experiments with large corpus (around 300 million words).
</nextsent>
<nextsent>we trained thesaurus extraction system with range of context-extracting front-ends to demonstrate the interaction between context quality, extraction time and representation size.
</nextsent>
<nextsent>thesauri have traditionally been used in information retrieval tasks to expand words in queries with synonymous terms (e.g. ruge, (1997)).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1036">
<title id=" P02-1030.xml">scaling context space </title>
<section> automatic thesaurus extraction.  </section>
<citcontext>
<prevsection>
<prevsent>more re computational linguistics (acl), philadelphia, july 2002, pp.
</prevsent>
<prevsent>231-238.
</prevsent>
</prevsection>
<citsent citstr=" J92-4003 ">
proceedings of the 40th annual meeting of the association for cently, semantic resources have also been used in collocation discovery (pearce, 2001), smoothing and model estimation (brown et al, 1992; <papid> J92-4003 </papid>clark andweir, 2001) <papid> N01-1013 </papid>and text classification (baker and mccallum, 1998).</citsent>
<aftsection>
<nextsent>unfortunately, thesauri are very expensive and time-consuming to produce manually,and tend to suffer from problems of bias, inconsistency, and lack of coverage.
</nextsent>
<nextsent>in addition, thesaurus compilers cannot keep up with constantly evolving language use and cannot afford to build new thesauri for the many sub domains that information extraction and retrieval systems are being developed for.
</nextsent>
<nextsent>thereis clear need for methods to extract thesauri automatically or tools that assist in the manual creation and updating of these semantic resources.
</nextsent>
<nextsent>most existing work on thesaurus extraction and word clustering is based on the general observation that related terms will appear in similar contexts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1038">
<title id=" P02-1030.xml">scaling context space </title>
<section> automatic thesaurus extraction.  </section>
<citcontext>
<prevsection>
<prevsent>more re computational linguistics (acl), philadelphia, july 2002, pp.
</prevsent>
<prevsent>231-238.
</prevsent>
</prevsection>
<citsent citstr=" N01-1013 ">
proceedings of the 40th annual meeting of the association for cently, semantic resources have also been used in collocation discovery (pearce, 2001), smoothing and model estimation (brown et al, 1992; <papid> J92-4003 </papid>clark andweir, 2001) <papid> N01-1013 </papid>and text classification (baker and mccallum, 1998).</citsent>
<aftsection>
<nextsent>unfortunately, thesauri are very expensive and time-consuming to produce manually,and tend to suffer from problems of bias, inconsistency, and lack of coverage.
</nextsent>
<nextsent>in addition, thesaurus compilers cannot keep up with constantly evolving language use and cannot afford to build new thesauri for the many sub domains that information extraction and retrieval systems are being developed for.
</nextsent>
<nextsent>thereis clear need for methods to extract thesauri automatically or tools that assist in the manual creation and updating of these semantic resources.
</nextsent>
<nextsent>most existing work on thesaurus extraction and word clustering is based on the general observation that related terms will appear in similar contexts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1041">
<title id=" P02-1030.xml">scaling context space </title>
<section> automatic thesaurus extraction.  </section>
<citcontext>
<prevsection>
<prevsent>the differences tend to lie in the way context?
</prevsent>
<prevsent>is defined and in the way similarity is calculated.
</prevsent>
</prevsection>
<citsent citstr=" P93-1024 ">
most systems extract co-occurrence and syntactic information from the words surrounding the target term,which is then converted into vector-space representation of the contexts that each target term appears in (brown et al, 1992; <papid> J92-4003 </papid>pereira et al, 1993; <papid> P93-1024 </papid>ruge, 1997; lin, 1998b).</citsent>
<aftsection>
<nextsent>other systems take the whole document as the context and consider term co-occurrence at the document level (crouch, 1988; sanderson and croft, 1999).
</nextsent>
<nextsent>once these contexts have been defined, these systems then use clustering or nearest neighbour methods to find similar terms.
</nextsent>
<nextsent>finally, some systems extract synonyms directly without extracting and comparing contextual representations for each term.
</nextsent>
<nextsent>instead, these systems recognise terms within certain linguistic patterns (e.g. x, and other zs) which associate synonyms and hyponyms (hearst, 1992; <papid> C92-2082 </papid>caraballo, 1999).<papid> P99-1016 </papid>thesaurus extraction is good task to use to experiment with scaling context spaces.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1042">
<title id=" P02-1030.xml">scaling context space </title>
<section> automatic thesaurus extraction.  </section>
<citcontext>
<prevsection>
<prevsent>once these contexts have been defined, these systems then use clustering or nearest neighbour methods to find similar terms.
</prevsent>
<prevsent>finally, some systems extract synonyms directly without extracting and comparing contextual representations for each term.
</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
instead, these systems recognise terms within certain linguistic patterns (e.g. x, and other zs) which associate synonyms and hyponyms (hearst, 1992; <papid> C92-2082 </papid>caraballo, 1999).<papid> P99-1016 </papid>thesaurus extraction is good task to use to experiment with scaling context spaces.</citsent>
<aftsection>
<nextsent>the vector space model with nearest neighbour searching is simple, so we neednt worry about interactions between the contexts we select and learning algorithm (such as independence of the features).
</nextsent>
<nextsent>but also, thesaurus extraction is task where succes shas been limited when using small corpora (grefen stette, 1994); corpora of the order of 300 million words have already been shown to be more successful at this task (lin, 1998b).
</nextsent>
<nextsent>vector-space thesaurus extraction can be separated into two independent processes.
</nextsent>
<nextsent>the first step extracts the contexts from raw text and compiles the minto vector-space statistical description of the contexts each potential thesaurus term appears in.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1043">
<title id=" P02-1030.xml">scaling context space </title>
<section> automatic thesaurus extraction.  </section>
<citcontext>
<prevsection>
<prevsent>once these contexts have been defined, these systems then use clustering or nearest neighbour methods to find similar terms.
</prevsent>
<prevsent>finally, some systems extract synonyms directly without extracting and comparing contextual representations for each term.
</prevsent>
</prevsection>
<citsent citstr=" P99-1016 ">
instead, these systems recognise terms within certain linguistic patterns (e.g. x, and other zs) which associate synonyms and hyponyms (hearst, 1992; <papid> C92-2082 </papid>caraballo, 1999).<papid> P99-1016 </papid>thesaurus extraction is good task to use to experiment with scaling context spaces.</citsent>
<aftsection>
<nextsent>the vector space model with nearest neighbour searching is simple, so we neednt worry about interactions between the contexts we select and learning algorithm (such as independence of the features).
</nextsent>
<nextsent>but also, thesaurus extraction is task where succes shas been limited when using small corpora (grefen stette, 1994); corpora of the order of 300 million words have already been shown to be more successful at this task (lin, 1998b).
</nextsent>
<nextsent>vector-space thesaurus extraction can be separated into two independent processes.
</nextsent>
<nextsent>the first step extracts the contexts from raw text and compiles the minto vector-space statistical description of the contexts each potential thesaurus term appears in.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1044">
<title id=" P02-1030.xml">scaling context space </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>sextant uses generalisation of the jaccard measure to measure similarity.
</prevsent>
<prevsent>the jaccard measure is the cardinality ratio of the intersection and union of attribute sets (atts(wn) is the attribute set for wn): | atts(wm) ? atts(wn)| | atts(wm) ? atts(wn)| (1)the generalised jaccard measure allows each relation to have significance weight (based on word, attribute and relation frequencies) associated with it: ? aatts(wm)atts(wn) min(wgt(wm, a),wgt(wn, a)) ? aatts(wm)atts(wn) max(wgt(wm, a),wgt(wn, a)) (2) grefenstette originally used the weighting function: wgt(wi, j) = log2( (wi, j) + 1) log2(n(a j) + 1) (3) where (wi, j) is the frequency of the relation and n(a j) is the number of different words j appears in relations with.
</prevsent>
</prevsection>
<citsent citstr=" W02-0908 ">
name context description w(l1r1) one word to left or right w(l1) one word to the left w(l1,2) one or two words to the left w(l13) one to three words to the left table 1: window extractors however, we have found that using the t-test between the joint and independent distributions of word and its attribute: wgt(wi, j) = p(wi, j) ? p(wi)p(a j) p(wi)p(a j) (4) gives superior performance (curran and moens, 2002) <papid> W02-0908 </papid>and is therefore used for our experiments.</citsent>
<aftsection>
<nextsent>we have experimented with number of different systems for extracting the contexts for each word.
</nextsent>
<nextsent>these systems show wide range in complexity of method and implementation, and hence development effort and execution time.
</nextsent>
<nextsent>the simplest method we implemented extracts the occurrence counts of words within particular window surrounding the thesaurus term.
</nextsent>
<nextsent>these window extractors are very easy to implement and run veryquickly.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1045">
<title id=" P02-1030.xml">scaling context space </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>inverse rank is good measure of subtle differences in ranked results.
</prevsent>
<prevsent>each measure is averaged over the extracted synonym lists for all 70 thesaurus terms.
</prevsent>
</prevsection>
<citsent citstr=" W00-1427 ">
since minipar performs morphological analysis onthe context relations we have added an existing morphological analyser (minnen et al, 2000) <papid> W00-1427 </papid>to the other extractors.</citsent>
<aftsection>
<nextsent>table 4 shows the improvement gained by morphological analysis of the attributes and relations for the sextant 150m corpus.
</nextsent>
<nextsent>the improvement in results is quite significant, asis the reduction in the representation space and number of unique context relations.
</nextsent>
<nextsent>the reduction in the number of terms is result of coalescing the plural nouns with their corresponding singular nouns, which also reduces data sparseness problems.
</nextsent>
<nextsent>the remainder of the results use morphological analysis of both the words and attributes.table 5 summarises the average results of applying all of the extraction systems to the two 150m word corpora.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1047">
<title id=" P01-1008.xml">extracting paraphrases from a parallel corpus </title>
<section> related work on paraphrasing.  </section>
<citcontext>
<prevsection>
<prevsent>lexical resources are used in statistical generation, summarization and question-answering.
</prevsent>
<prevsent>the question here is what type of wordnet relations canbe considered as paraphrases.
</prevsent>
</prevsection>
<citsent citstr=" P98-1116 ">
in some applications, only synonyms are considered as paraphrases (langkilde and knight, 1998); <papid> P98-1116 </papid>in others, looser definitions are used (barzilay and elhadad, 1997).<papid> W97-0703 </papid></citsent>
<aftsection>
<nextsent>these definitions are valid in the context of particular applications; however, in general, the correspondence between paraphrasing and typesof lexical relations is not clear.
</nextsent>
<nextsent>the same question arises with automatically constructed the sauri (pereira et al, 1993; <papid> P93-1024 </papid>lin, 1998).<papid> P98-2127 </papid></nextsent>
<nextsent>while the extracted pairs are indeed similar, they are not paraphrases.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1048">
<title id=" P01-1008.xml">extracting paraphrases from a parallel corpus </title>
<section> related work on paraphrasing.  </section>
<citcontext>
<prevsection>
<prevsent>lexical resources are used in statistical generation, summarization and question-answering.
</prevsent>
<prevsent>the question here is what type of wordnet relations canbe considered as paraphrases.
</prevsent>
</prevsection>
<citsent citstr=" W97-0703 ">
in some applications, only synonyms are considered as paraphrases (langkilde and knight, 1998); <papid> P98-1116 </papid>in others, looser definitions are used (barzilay and elhadad, 1997).<papid> W97-0703 </papid></citsent>
<aftsection>
<nextsent>these definitions are valid in the context of particular applications; however, in general, the correspondence between paraphrasing and typesof lexical relations is not clear.
</nextsent>
<nextsent>the same question arises with automatically constructed the sauri (pereira et al, 1993; <papid> P93-1024 </papid>lin, 1998).<papid> P98-2127 </papid></nextsent>
<nextsent>while the extracted pairs are indeed similar, they are not paraphrases.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1049">
<title id=" P01-1008.xml">extracting paraphrases from a parallel corpus </title>
<section> related work on paraphrasing.  </section>
<citcontext>
<prevsection>
<prevsent>in some applications, only synonyms are considered as paraphrases (langkilde and knight, 1998); <papid> P98-1116 </papid>in others, looser definitions are used (barzilay and elhadad, 1997).<papid> W97-0703 </papid></prevsent>
<prevsent>these definitions are valid in the context of particular applications; however, in general, the correspondence between paraphrasing and typesof lexical relations is not clear.</prevsent>
</prevsection>
<citsent citstr=" P93-1024 ">
the same question arises with automatically constructed the sauri (pereira et al, 1993; <papid> P93-1024 </papid>lin, 1998).<papid> P98-2127 </papid></citsent>
<aftsection>
<nextsent>while the extracted pairs are indeed similar, they are not paraphrases.
</nextsent>
<nextsent>for example, while dog?
</nextsent>
<nextsent>and cat?
</nextsent>
<nextsent>are recognized as the most similar concepts by the method described in (lin, 1998), <papid> P98-2127 </papid>it is hard to imagine context in which these words would be interchangeable.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1051">
<title id=" P01-1008.xml">extracting paraphrases from a parallel corpus </title>
<section> related work on paraphrasing.  </section>
<citcontext>
<prevsection>
<prevsent>in some applications, only synonyms are considered as paraphrases (langkilde and knight, 1998); <papid> P98-1116 </papid>in others, looser definitions are used (barzilay and elhadad, 1997).<papid> W97-0703 </papid></prevsent>
<prevsent>these definitions are valid in the context of particular applications; however, in general, the correspondence between paraphrasing and typesof lexical relations is not clear.</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
the same question arises with automatically constructed the sauri (pereira et al, 1993; <papid> P93-1024 </papid>lin, 1998).<papid> P98-2127 </papid></citsent>
<aftsection>
<nextsent>while the extracted pairs are indeed similar, they are not paraphrases.
</nextsent>
<nextsent>for example, while dog?
</nextsent>
<nextsent>and cat?
</nextsent>
<nextsent>are recognized as the most similar concepts by the method described in (lin, 1998), <papid> P98-2127 </papid>it is hard to imagine context in which these words would be interchangeable.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1053">
<title id=" P01-1008.xml">extracting paraphrases from a parallel corpus </title>
<section> related work on paraphrasing.  </section>
<citcontext>
<prevsection>
<prevsent>and cat?
</prevsent>
<prevsent>are recognized as the most similar concepts by the method described in (lin, 1998), <papid> P98-2127 </papid>it is hard to imagine context in which these words would be interchangeable.</prevsent>
</prevsection>
<citsent citstr=" P97-1004 ">
the first attempt to derive paraphrasing rules from corpora was undertaken by (jacquemin et al., 1997), <papid> P97-1004 </papid>who investigated morphological and syntactic variants of technical terms.</citsent>
<aftsection>
<nextsent>while these rules achieve high accuracy in identifying term paraphrases, the techniques used have not been extended to other types of paraphrasing yet.
</nextsent>
<nextsent>statistical techniques were also successfully used by (lapata, 2001) <papid> N01-1009 </papid>to identify paraphrases of adjective-noun phrases.</nextsent>
<nextsent>in contrast, our method is not limited to particular paraphrase type.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1054">
<title id=" P01-1008.xml">extracting paraphrases from a parallel corpus </title>
<section> related work on paraphrasing.  </section>
<citcontext>
<prevsection>
<prevsent>the first attempt to derive paraphrasing rules from corpora was undertaken by (jacquemin et al., 1997), <papid> P97-1004 </papid>who investigated morphological and syntactic variants of technical terms.</prevsent>
<prevsent>while these rules achieve high accuracy in identifying term paraphrases, the techniques used have not been extended to other types of paraphrasing yet.</prevsent>
</prevsection>
<citsent citstr=" N01-1009 ">
statistical techniques were also successfully used by (lapata, 2001) <papid> N01-1009 </papid>to identify paraphrases of adjective-noun phrases.</citsent>
<aftsection>
<nextsent>in contrast, our method is not limited to particular paraphrase type.
</nextsent>
<nextsent>the corpus we use for identification of paraphrases is collection of multiple english translations from foreign source text.
</nextsent>
<nextsent>specifically, we use literary texts written by foreign authors.
</nextsent>
<nextsent>many classical texts have been translated more than once, and these translations are available on-line.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1055">
<title id=" P01-1008.xml">extracting paraphrases from a parallel corpus </title>
<section> the data.  </section>
<citcontext>
<prevsection>
<prevsent>from the sentences in figure 1 are examples of distinct translations.
</prevsent>
<prevsent>therefore, complete match between words of related sentences is impossible.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
this characteristic of our corpus is similar to problems with noisy and comparable corpora (veronis, 2000), and it prevents us from using methods developed in the mt community based on clean parallel corpora, such as (brown et al, 1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>another distinction between our corpus and parallel mt corpora is the irregularity of wordmatchings: in mt, no words in the source language are kept as is in the target language trans lation; for example, an english translation of 2free of copyright restrictions part of our corpus(9 translations) is available at http://www.cs.columbia.edu/regina /par.
</nextsent>
<nextsent>a french source does not contain untranslated french fragments.
</nextsent>
<nextsent>in contrast, in our corpus the same word is usually used in both translations, and only sometimes its paraphrases are used, which means that word paraphrase pairs will have lower co-occurrence rates than word translation pairs in mt. for example, consider occurrences of the word boy?
</nextsent>
<nextsent>in two translations of madame bovary?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1056">
<title id=" P01-1008.xml">extracting paraphrases from a parallel corpus </title>
<section> preprocessing.  </section>
<citcontext>
<prevsection>
<prevsent>during the preprocessing stage, we perform sentence alignment.
</prevsent>
<prevsent>sentences which are translations of the same source sentence contain number of identical words, which serve as strong clue to the matching process.
</prevsent>
</prevsection>
<citsent citstr=" P91-1023 ">
alignment is performed using dynamic programming (gale and church,1991) <papid> P91-1023 </papid>with weight function based on the number of common words in sentence pair.</citsent>
<aftsection>
<nextsent>this simple method achieves good results for our corpus, because 42% of the words in corresponding sentences are identical words on average.
</nextsent>
<nextsent>alignment produces 44,562 pairs of sentences with 1,798,526 words.
</nextsent>
<nextsent>to evaluate the accuracy of the alignment process, we analyzed 127 sentence pairs from the algorithms output.
</nextsent>
<nextsent>120(94.5%) alignments were identified as correct alignments.we then use part-of-speech tagger and chun ker (mikheev, 1997) to identify noun and verb phrases in the sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1059">
<title id=" P01-1008.xml">extracting paraphrases from a parallel corpus </title>
<section> method for paraphrase extraction.  </section>
<citcontext>
<prevsection>
<prevsent>generalizing from this example, we hypothesize that if the contexts surrounding two phrases look similar enough, then these two phrases are likely to be paraphrases.
</prevsent>
<prevsent>the definition of the context depends on how similar the translations are.
</prevsent>
</prevsection>
<citsent citstr=" P93-1023 ">
oncewe know which contexts are good paraphrase predictors, we can extract paraphrase patterns from our corpus.examples of such contexts are verb-object relations and noun-modifier relations, which were traditionally used in word similarity tasks fromnon-parallel corpora (pereira et al, 1993; <papid> P93-1024 </papid>hatzivassiloglou and mckeown, 1993).<papid> P93-1023 </papid></citsent>
<aftsection>
<nextsent>however, in our case, more indirect relations can also be clues for paraphrasing, because we know priori that input sentences convey the same information.
</nextsent>
<nextsent>for example, in sentences from figure 3, the verbs ringing?
</nextsent>
<nextsent>and sounding?
</nextsent>
<nextsent>do not share identical subject nouns, but the modifier of both subjects evening?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1060">
<title id=" P01-1008.xml">extracting paraphrases from a parallel corpus </title>
<section> method for paraphrase extraction.  </section>
<citcontext>
<prevsection>
<prevsent>contexts, and inturn use them to learn new paraphrases.
</prevsent>
<prevsent>identical words play two roles in this process: first,they are used to learn context rules; second, identical words are used in application of these rules, because the rules contain information about the equality of words in context.
</prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
this method of co-training has been previously applied to variety of natural language tasks, such as word sense disambiguation (yarowsky,1995), <papid> P95-1026 </papid>lexicon construction for information extraction (riloff and jones, 1999), and named entity classification (collins and singer, 1999).<papid> W99-0613 </papid></citsent>
<aftsection>
<nextsent>in our case, the co-training process creates binary classifier, which predicts whether given pair of phrases makes paraphrase or not.our model is based on the dlcotrain algorithm proposed by (collins and singer, 1999), <papid> W99-0613 </papid>which applies co-training procedure to decision list classifiers for two independent sets of fea tures.</nextsent>
<nextsent>in our case, one set of features describes the paraphrase pair itself, and another set of features corresponds to contexts in which paraphrases occur.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1061">
<title id=" P01-1008.xml">extracting paraphrases from a parallel corpus </title>
<section> method for paraphrase extraction.  </section>
<citcontext>
<prevsection>
<prevsent>contexts, and inturn use them to learn new paraphrases.
</prevsent>
<prevsent>identical words play two roles in this process: first,they are used to learn context rules; second, identical words are used in application of these rules, because the rules contain information about the equality of words in context.
</prevsent>
</prevsection>
<citsent citstr=" W99-0613 ">
this method of co-training has been previously applied to variety of natural language tasks, such as word sense disambiguation (yarowsky,1995), <papid> P95-1026 </papid>lexicon construction for information extraction (riloff and jones, 1999), and named entity classification (collins and singer, 1999).<papid> W99-0613 </papid></citsent>
<aftsection>
<nextsent>in our case, the co-training process creates binary classifier, which predicts whether given pair of phrases makes paraphrase or not.our model is based on the dlcotrain algorithm proposed by (collins and singer, 1999), <papid> W99-0613 </papid>which applies co-training procedure to decision list classifiers for two independent sets of fea tures.</nextsent>
<nextsent>in our case, one set of features describes the paraphrase pair itself, and another set of features corresponds to contexts in which paraphrases occur.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1067">
<title id=" P01-1008.xml">extracting paraphrases from a parallel corpus </title>
<section> conclusions and future work.  </section>
<citcontext>
<prevsection>
<prevsent>we showed that co-training algorithm based on contextual and lexico-syntactic features of paraphrases achieves high performance on our data.
</prevsent>
<prevsent>the wide range of paraphrases extracted by our algorithm sheds light on the paraphrasing phenomena, which has not been studied from an empirical perspective.future work will extend this approach to extract paraphrases from comparable corpora, such as multiple reports from different news agencies about the same event or different descriptions ofa disease from the medical literature.
</prevsent>
</prevsection>
<citsent citstr=" W99-0625 ">
this extension will require using more selective alignment technique (similar to that of (hatzivassiloglou etal., 1999)).<papid> W99-0625 </papid></citsent>
<aftsection>
<nextsent>we will also investigate more powerful representation of contextual features.
</nextsent>
<nextsent>fortunately, statistical parsers produce reliable result son news texts, and therefore can be used to im prove context representation.
</nextsent>
<nextsent>this will allow us to extract macro-syntactic paraphrases in addition to local paraphrases which are currently produced by the algorithm.
</nextsent>
<nextsent>acknowledgments this work was partially supported by louis morin scholarship and by darpa grant n66001 00-1-8919 under the tides program.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1068">
<title id=" P03-1046.xml">parsing with generative models of predicate argument structure </title>
<section> abstract </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" P02-1043 ">
the model used by the ccg parser of hockenmaier and steedman (2002<papid> P02-1043 </papid>b) would fail to capture the correct bilexical dependencies in language with freer word order, such as dutch.</citsent>
<aftsection>
<nextsent>this paper argues that probabilistic parsers should therefore model the dependencies in the predicate-argument structure, as in the model of clark et al (2002), <papid> P02-1042 </papid>and defines generative model for ccg derivations that captures these dependencies, including bounded and unbounded long-range dependencies.</nextsent>
<nextsent>state-of-the-art statistical parsers for penn treebank-style phrase-structure grammars (collins, 1999), (charniak, 2000), <papid> A00-2018 </papid>but also for categorial grammar (hockenmaier and steedman, 2002<papid> P02-1043 </papid>b), include models of bilexical dependencies defined in terms of local trees.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1076">
<title id=" P03-1046.xml">parsing with generative models of predicate argument structure </title>
<section> abstract </section>
<citcontext>
<prevsection>

<prevsent>the model used by the ccg parser of hockenmaier and steedman (2002<papid> P02-1043 </papid>b) would fail to capture the correct bilexical dependencies in language with freer word order, such as dutch.</prevsent>
</prevsection>
<citsent citstr=" P02-1042 ">
this paper argues that probabilistic parsers should therefore model the dependencies in the predicate-argument structure, as in the model of clark et al (2002), <papid> P02-1042 </papid>and defines generative model for ccg derivations that captures these dependencies, including bounded and unbounded long-range dependencies.</citsent>
<aftsection>
<nextsent>state-of-the-art statistical parsers for penn treebank-style phrase-structure grammars (collins, 1999), (charniak, 2000), <papid> A00-2018 </papid>but also for categorial grammar (hockenmaier and steedman, 2002<papid> P02-1043 </papid>b), include models of bilexical dependencies defined in terms of local trees.</nextsent>
<nextsent>however, this paper demonstrates that such models would be inadequate for languages with freer word order.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1080">
<title id=" P03-1046.xml">parsing with generative models of predicate argument structure </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the model used by the ccg parser of hockenmaier and steedman (2002<papid> P02-1043 </papid>b) would fail to capture the correct bilexical dependencies in language with freer word order, such as dutch.</prevsent>
<prevsent>this paper argues that probabilistic parsers should therefore model the dependencies in the predicate-argument structure, as in the model of clark et al (2002), <papid> P02-1042 </papid>and defines generative model for ccg derivations that captures these dependencies, including bounded and unbounded long-range dependencies.</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
state-of-the-art statistical parsers for penn treebank-style phrase-structure grammars (collins, 1999), (charniak, 2000), <papid> A00-2018 </papid>but also for categorial grammar (hockenmaier and steedman, 2002<papid> P02-1043 </papid>b), include models of bilexical dependencies defined in terms of local trees.</citsent>
<aftsection>
<nextsent>however, this paper demonstrates that such models would be inadequate for languages with freer word order.
</nextsent>
<nextsent>we use the example of dutch ditransitives, but our argument equally applies to other languages such as czech (see collins et al (1999)).<papid> P99-1065 </papid></nextsent>
<nextsent>we argue that this problem can be avoided if instead the bilexical dependencies in the predicate-argument structure are captured, and propose generative model for these dependencies.the focus of this paper is on models for combina tory categorial grammar (ccg, steedman (2000)).due to ccgs transparent syntax-semantics interface, the parser has direct and immediate access to the predicate-argument structure, which includes not only local, but also long-range dependencies arising through coordination, extraction and con trol.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1083">
<title id=" P03-1046.xml">parsing with generative models of predicate argument structure </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>state-of-the-art statistical parsers for penn treebank-style phrase-structure grammars (collins, 1999), (charniak, 2000), <papid> A00-2018 </papid>but also for categorial grammar (hockenmaier and steedman, 2002<papid> P02-1043 </papid>b), include models of bilexical dependencies defined in terms of local trees.</prevsent>
<prevsent>however, this paper demonstrates that such models would be inadequate for languages with freer word order.</prevsent>
</prevsection>
<citsent citstr=" P99-1065 ">
we use the example of dutch ditransitives, but our argument equally applies to other languages such as czech (see collins et al (1999)).<papid> P99-1065 </papid></citsent>
<aftsection>
<nextsent>we argue that this problem can be avoided if instead the bilexical dependencies in the predicate-argument structure are captured, and propose generative model for these dependencies.the focus of this paper is on models for combina tory categorial grammar (ccg, steedman (2000)).due to ccgs transparent syntax-semantics interface, the parser has direct and immediate access to the predicate-argument structure, which includes not only local, but also long-range dependencies arising through coordination, extraction and control.
</nextsent>
<nextsent>these dependencies can be captured by our model in sound manner, and our experimental results for english demonstrate that their inclusion improves parsing performance.
</nextsent>
<nextsent>however, since the predicate-argument structure itself depends only to degree on the grammar formalism, it is likely that parsers that are based on other grammar formalisms could equally benefit from such model.
</nextsent>
<nextsent>the conditional model used by the ccg parser of clark et al (2002) <papid> P02-1042 </papid>also captures dependencies in the predicate-argument structure; however, their model is inconsistent.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1116">
<title id=" P03-1046.xml">parsing with generative models of predicate argument structure </title>
<section> an experiment.  </section>
<citcontext>
<prevsection>
<prevsent>a better way of dealing with the space requirements of our model would be to implement packed shared parse forest, but we leave this to future work.
</prevsent>
<prevsent>we use sections 02-21 of ccgbank for training, section 00 for development, and section 23 for testing.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
the input is pos-tagged using the tagger of ratnaparkhi (1996).<papid> W96-0213 </papid></citsent>
<aftsection>
<nextsent>however, since parsing with the new model is less efficient, only sentences  40tokens only are used to test the model.
</nextsent>
<nextsent>a frequency cutoff of  20 was used to determine rare words in the training data, which are replaced with their pos-tags.
</nextsent>
<nextsent>unknown words in the test data are also replaced by their pos-tags.
</nextsent>
<nextsent>the models are evaluated according to their parseval scores andto the recovery of dependencies in the predicate argument structure.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1157">
<title id=" P02-1006.xml">learning surface text patterns for a question answering system </title>
<section> finding answers.  </section>
<citcontext>
<prevsection>
<prevsent>determine the question type of the new.
</prevsent>
<prevsent>question.
</prevsent>
</prevsection>
<citsent citstr=" C02-1042 ">
we use our existing qa system (hovy et al , 2002<papid> C02-1042 </papid>b; 2001) to do so.</citsent>
<aftsection>
<nextsent>2.
</nextsent>
<nextsent>the question term in the question is. identified, also using our existing system.
</nextsent>
<nextsent>3.
</nextsent>
<nextsent>create query from the question term and perform ir (by using given answer document corpus such as the trec-10 collection or web search otherwise).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1161">
<title id=" P02-1006.xml">learning surface text patterns for a question answering system </title>
<section> segment the documents obtained into.  </section>
<citcontext>
<prevsection>
<prevsent>these questions were run through the testing phase of the algorithm.
</prevsent>
<prevsent>two sets of experiments were performed.
</prevsent>
</prevsection>
<citsent citstr=" C02-1026 ">
in the first case, the trec corpus was used as the input source and ir was performed by their component of our qa system (lin, 2002).<papid> C02-1026 </papid></citsent>
<aftsection>
<nextsent>in the second case, the web was the input source and their was performed by the alta vista search engine.
</nextsent>
<nextsent>results of the experiments, measured by mean reciprocal rank (mrr) score (voorhees, 01), are: trec corpus question type number of questions mrr on trec docs birth year 8 0.48 inventor 6 0.17 discoverer 4 0.13 definition 102 0.34 why-famous 3 0.33 location 16 0.75 web question type number of questions mrr on the web birth year 8 0.69 inventor 6 0.58 discoverer 4 0.88 definition 102 0.39 why-famous 3 0.00 location 16 0.86 the results indicate that the system performs better on the web data than on the trec corpus.
</nextsent>
<nextsent>the abundance of data on the web makes it easier for the system to locate answers with high precision scores (the system finds many examples of correct answers among the top 20 when using the web as the input source).
</nextsent>
<nextsent>a similar result for qa was obtained by brill et al  (2001).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1162">
<title id=" P04-1048.xml">inducing frame semantic verb classes from wordnet and ldoce </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the next best performing semantic verb classes achieve 56.9% recall and 55.0% precision.
</prevsent>
<prevsent>semantic content can almost always be expressed in variety of ways.
</prevsent>
</prevsection>
<citsent citstr=" W03-1604 ">
lexical synonymy (she esteemed him highly vs. she respected him greatly), syntactic variation (john paid the bill vs. the bill was paid by john), overlapping meanings (anna turned at elm vs. anna rounded the corner at elm), and other phenomena interact to produce broad range of choices for most language generation tasks (hirst, 2003; rinaldi et al , 2003; <papid> W03-1604 </papid>kozlowski et al , 2003).<papid> W03-1601 </papid></citsent>
<aftsection>
<nextsent>at the same time, natural language understanding must recognize what remains constant across paraphrases.
</nextsent>
<nextsent>the paraphrase phenomenon affects many computational linguistic applications, including information retrieval, information extraction, question-answering, and machine translation.
</nextsent>
<nextsent>for example, documents that express the same content using different linguistic means should typically be retrieved for the same queries.
</nextsent>
<nextsent>information sought to answer question needs to be recognized no matter how it is expressed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1163">
<title id=" P04-1048.xml">inducing frame semantic verb classes from wordnet and ldoce </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the next best performing semantic verb classes achieve 56.9% recall and 55.0% precision.
</prevsent>
<prevsent>semantic content can almost always be expressed in variety of ways.
</prevsent>
</prevsection>
<citsent citstr=" W03-1601 ">
lexical synonymy (she esteemed him highly vs. she respected him greatly), syntactic variation (john paid the bill vs. the bill was paid by john), overlapping meanings (anna turned at elm vs. anna rounded the corner at elm), and other phenomena interact to produce broad range of choices for most language generation tasks (hirst, 2003; rinaldi et al , 2003; <papid> W03-1604 </papid>kozlowski et al , 2003).<papid> W03-1601 </papid></citsent>
<aftsection>
<nextsent>at the same time, natural language understanding must recognize what remains constant across paraphrases.
</nextsent>
<nextsent>the paraphrase phenomenon affects many computational linguistic applications, including information retrieval, information extraction, question-answering, and machine translation.
</nextsent>
<nextsent>for example, documents that express the same content using different linguistic means should typically be retrieved for the same queries.
</nextsent>
<nextsent>information sought to answer question needs to be recognized no matter how it is expressed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1164">
<title id=" P04-1048.xml">inducing frame semantic verb classes from wordnet and ldoce </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper explores the first task of identifying frame semantic verb classes.
</prevsent>
<prevsent>these classes have several types of uses.
</prevsent>
</prevsection>
<citsent citstr=" W04-0909 ">
first, they are the basis for identifying the internal structure of the frame proper, as set forth in green and dorr, 2004.<papid> W04-0909 </papid></citsent>
<aftsection>
<nextsent>second, they may be used to extend framenet.
</nextsent>
<nextsent>third, they support applications needing access to sets of semantically related words, for example, text segmentation and word sense disambiguation, as explored to limited degree in green, 2004.
</nextsent>
<nextsent>section 2 presents related research efforts on developing semantic verb classes.
</nextsent>
<nextsent>section 3 summarizes the features of wordnet (http://www.cogsci.princeton.edu/~wn) and ldoce (procter, 1978) that support the automatic induction of semantic verb classes, definitions and example sentences often mention while section 4 sets forth the approach taken by their participants using semantic-type-like nouns, sem frame to accomplish this task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1165">
<title id=" P04-1048.xml">inducing frame semantic verb classes from wordnet and ldoce </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>for example, the apply_heat the looseness of the minimal overlap frame in framenet includes 22 verbs: bake, criterion is tightened by also requiring that the blanch, boil, braise, broil, brown, char, coddle, names of the framenet and sem frame frames be cook, fry, grill, microwave, parboil, poach, roast, closely related.
</prevsent>
<prevsent>establishing this frame-name saute, scald, simmer, steam, steep, stew, and relatedness involves identifying individual toast, while the boiling frame in sem frame components of each frame name and augmenting includes 7 verbs: boil, coddle, jug, parboil,3 this set with morphological variants from catvar poach, seethe, and simmer.
</prevsent>
</prevsection>
<citsent citstr=" N03-1013 ">
five of these (habash and dorr 2003).<papid> N03-1013 </papid></citsent>
<aftsection>
<nextsent>the resulting set for verbs boil, coddle, parboil, poach, and each framenet and sem frame frame name is simmer are shared across the two frames and then searched in both the noun and verb wordnet constitute over half of the sem frame frameset.
</nextsent>
<nextsent>networks to find all the synsets that might therefore the two frames are deemed to correspond to the frame name.
</nextsent>
<nextsent>to these sets are correspond by meeting the majority-match also added all synsets directly related to the criterion.
</nextsent>
<nextsent>synsets corresponding to the frame names.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1167">
<title id=" P04-1072.xml">splitting complex temporal questions for question answering systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>processing this sort of questions is usually performed by identifying explicit temporal expressions in questions and relevant documents, in order to gather the necessary information to answer the queries.
</prevsent>
<prevsent>even though, it seems necessary to emphasize that the system described in (breck et al, 2000) is the only one also using implicit temporal expression recognition for q.a. purposes.
</prevsent>
</prevsection>
<citsent citstr=" P00-1010 ">
it does so by applying the temporal tagger developed by mani and wilson (2000).<papid> P00-1010 </papid></citsent>
<aftsection>
<nextsent>however, issues like addressing the temporal properties or the ordering of events in questions, remain beyond the scope of current q.a. systems:  who was spokesman of the soviet embassy in baghdad during the invasion of kuwait??
</nextsent>
<nextsent> is bill clinton currently the president of the united states??
</nextsent>
<nextsent>this work presents question answering system capable of answering complex temporal questions.
</nextsent>
<nextsent>this approach tries to imitate human behavior when responding this type of questions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1168">
<title id=" P01-1022.xml">practical issues in compiling typed unification grammars for speech recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>research systems can achieve impressive performance using statistical language models trained on large amounts of domain-targeted data, but for many domains sufficient data is not available.
</prevsent>
<prevsent>data may be unavailable because the domain has not been explored before, the relevant data may be confidential, or the system may be designed to do new functions for which there is no human-humananalog interaction.
</prevsent>
</prevsection>
<citsent citstr=" A97-1001 ">
the statistical approach is unworkable in such cases for both the commercial developers and for some research systems (moore et al  1997, <papid> A97-1001 </papid>rayner et al  2000, <papid> A00-1016 </papid>lemon et al  2001, gauthron and colineau 1999).</citsent>
<aftsection>
<nextsent>even incases for which there is no impediment to collecting data, the expense and time required to collect corpus can be prohibitive.
</nextsent>
<nextsent>the existence of the atis database (dahl et al  1994) <papid> H94-1010 </papid>is nodoubt factor in the popularity of the travel do main among the research community for exactly this reason.a major problem with grammar-based finite state or context-free language models is that they can be tedious to build and difficult to maintain, as they can become quite large very quickly as the scope of the grammar increases.</nextsent>
<nextsent>one wayto address this problem is to write the grammar in more expressive formalism and generate an approximation of this grammar in the format needed by the recognizer.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1169">
<title id=" P01-1022.xml">practical issues in compiling typed unification grammars for speech recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>research systems can achieve impressive performance using statistical language models trained on large amounts of domain-targeted data, but for many domains sufficient data is not available.
</prevsent>
<prevsent>data may be unavailable because the domain has not been explored before, the relevant data may be confidential, or the system may be designed to do new functions for which there is no human-humananalog interaction.
</prevsent>
</prevsection>
<citsent citstr=" A00-1016 ">
the statistical approach is unworkable in such cases for both the commercial developers and for some research systems (moore et al  1997, <papid> A97-1001 </papid>rayner et al  2000, <papid> A00-1016 </papid>lemon et al  2001, gauthron and colineau 1999).</citsent>
<aftsection>
<nextsent>even incases for which there is no impediment to collecting data, the expense and time required to collect corpus can be prohibitive.
</nextsent>
<nextsent>the existence of the atis database (dahl et al  1994) <papid> H94-1010 </papid>is nodoubt factor in the popularity of the travel do main among the research community for exactly this reason.a major problem with grammar-based finite state or context-free language models is that they can be tedious to build and difficult to maintain, as they can become quite large very quickly as the scope of the grammar increases.</nextsent>
<nextsent>one wayto address this problem is to write the grammar in more expressive formalism and generate an approximation of this grammar in the format needed by the recognizer.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1170">
<title id=" P01-1022.xml">practical issues in compiling typed unification grammars for speech recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the statistical approach is unworkable in such cases for both the commercial developers and for some research systems (moore et al  1997, <papid> A97-1001 </papid>rayner et al  2000, <papid> A00-1016 </papid>lemon et al  2001, gauthron and colineau 1999).</prevsent>
<prevsent>even incases for which there is no impediment to collecting data, the expense and time required to collect corpus can be prohibitive.</prevsent>
</prevsection>
<citsent citstr=" H94-1010 ">
the existence of the atis database (dahl et al  1994) <papid> H94-1010 </papid>is nodoubt factor in the popularity of the travel do main among the research community for exactly this reason.a major problem with grammar-based finite state or context-free language models is that they can be tedious to build and difficult to maintain, as they can become quite large very quickly as the scope of the grammar increases.</citsent>
<aftsection>
<nextsent>one wayto address this problem is to write the grammar in more expressive formalism and generate an approximation of this grammar in the format needed by the recognizer.
</nextsent>
<nextsent>this approach has been used in several systems, commandtalk(moore et al  1997), <papid> A97-1001 </papid>rialist psa simulator (rayner et al  2000), <papid> A00-1016 </papid>witas (lemon et al 2001), and sethivoice (gauthron and colineau 1999).</nextsent>
<nextsent>while theoretically straight-forward, this approach is more demanding in practice, aseach of the compilation stages contains the potential for combinatorial explosion that will exceed memory and time bounds.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1173">
<title id=" P01-1022.xml">practical issues in compiling typed unification grammars for speech recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>while theoretically straight-forward, this approach is more demanding in practice, aseach of the compilation stages contains the potential for combinatorial explosion that will exceed memory and time bounds.
</prevsent>
<prevsent>there is also no guarantee that the resulting language model will lead to accurate and efficient speech recognition.we will be interested in this paper in sound approximations (pereira and wright 1991) in which the language accepted by the approximation is superset of language accepted by the originalgrammar.
</prevsent>
</prevsection>
<citsent citstr=" P98-1101 ">
while we conceed that alternative techniques that are not sound (black 1989, (johnson 1998, <papid> P98-1101 </papid>rayner and carter 1996) <papid> P96-1030 </papid>may still be useful for many purposes, we prefer sound approximations because there is no chance that the correct hypothesis will be eliminated.</citsent>
<aftsection>
<nextsent>thus, further processing techniques (for instance, n-best search) will still have an opportunity to find the optimal solution.
</nextsent>
<nextsent>we will describe and evaluate two compilation approaches to approximating typed unification grammar with context-free grammar.
</nextsent>
<nextsent>we will also describe and evaluate additional techniques to reduce the size and structural ambiguity of the language model.
</nextsent>
<nextsent>typed unification grammars (tug), like hpsg (pollard and sag 1994) and gemini (dowding et al . 1993) <papid> P93-1008 </papid>are more expressive formalism in which to write formal grammars1.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1174">
<title id=" P01-1022.xml">practical issues in compiling typed unification grammars for speech recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>while theoretically straight-forward, this approach is more demanding in practice, aseach of the compilation stages contains the potential for combinatorial explosion that will exceed memory and time bounds.
</prevsent>
<prevsent>there is also no guarantee that the resulting language model will lead to accurate and efficient speech recognition.we will be interested in this paper in sound approximations (pereira and wright 1991) in which the language accepted by the approximation is superset of language accepted by the originalgrammar.
</prevsent>
</prevsection>
<citsent citstr=" P96-1030 ">
while we conceed that alternative techniques that are not sound (black 1989, (johnson 1998, <papid> P98-1101 </papid>rayner and carter 1996) <papid> P96-1030 </papid>may still be useful for many purposes, we prefer sound approximations because there is no chance that the correct hypothesis will be eliminated.</citsent>
<aftsection>
<nextsent>thus, further processing techniques (for instance, n-best search) will still have an opportunity to find the optimal solution.
</nextsent>
<nextsent>we will describe and evaluate two compilation approaches to approximating typed unification grammar with context-free grammar.
</nextsent>
<nextsent>we will also describe and evaluate additional techniques to reduce the size and structural ambiguity of the language model.
</nextsent>
<nextsent>typed unification grammars (tug), like hpsg (pollard and sag 1994) and gemini (dowding et al . 1993) <papid> P93-1008 </papid>are more expressive formalism in which to write formal grammars1.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1175">
<title id=" P01-1022.xml">practical issues in compiling typed unification grammars for speech recognition </title>
<section> typed unification grammars.  </section>
<citcontext>
<prevsection>
<prevsent>we will describe and evaluate two compilation approaches to approximating typed unification grammar with context-free grammar.
</prevsent>
<prevsent>we will also describe and evaluate additional techniques to reduce the size and structural ambiguity of the language model.
</prevsent>
</prevsection>
<citsent citstr=" P93-1008 ">
typed unification grammars (tug), like hpsg (pollard and sag 1994) and gemini (dowding et al . 1993) <papid> P93-1008 </papid>are more expressive formalism in which to write formal grammars1.</citsent>
<aftsection>
<nextsent>as opposed to atomic nonterminal symbols in cfg, each nonterminal in tug is complex feature structure (shieber 1986) where features with values can be attached.
</nextsent>
<nextsent>for example, the rule: s[]   np:[num=n] vp:[num=n] can be considered shorthand for 2 context free rules (assuming just two values for number):   np singular vp singular   np plural vp plural 1this paper specifically concerns grammars written in the gemini formalism.
</nextsent>
<nextsent>however, the basic issues involved in compiling typed unification grammars to context-free grammars remain the same across formalisms.
</nextsent>
<nextsent>this expressiveness allows us to write grammars with small number of rules (from dozens to few hundred) that correspond to grammars with large numbers of cf rules.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1176">
<title id=" P01-1022.xml">practical issues in compiling typed unification grammars for speech recognition </title>
<section> typed unification grammars.  </section>
<citcontext>
<prevsection>
<prevsent>note that the approximation need not incorporate all of the features from the original grammar in order to provide asound approximation.
</prevsent>
<prevsent>in particular, in order to derive finite cf grammar, we will need to consider only those features that have finite number of possible values, or at least consider only finitely many of the possible values for infinitely valued features.
</prevsent>
</prevsection>
<citsent citstr=" P85-1018 ">
we can use the technique of restriction (shieber 1985) <papid> P85-1018 </papid>to remove these features from our feature structures.</citsent>
<aftsection>
<nextsent>removing these features may give us more permissive language model, but it will still be sound approximation.the experimental results reported in this paper are based on grammar underdevelopment at riacs for spoken dialogue interface to semi-autonomous robot, the personal satellite assistant (psa).
</nextsent>
<nextsent>we consider this grammar to be medium-sized, with 61 grammar rules and 424 lexical entries.
</nextsent>
<nextsent>while this may sound small, ifthe grammar were expanded by instantiating variables in all legal permutations, it would contain over
</nextsent>
<nextsent>  context-free rules.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1177">
<title id=" P01-1022.xml">practical issues in compiling typed unification grammars for speech recognition </title>
<section> left recur sion elimination.  </section>
<citcontext>
<prevsection>
<prevsent>we expect that these transformations may be effective for some grammars, but not others.
</prevsent>
<prevsent>we plan to continue to explore refinements to these techiques to prevent them from applying in cases where cycles or left recur sion may be introduced.
</prevsent>
</prevsection>
<citsent citstr=" A00-2033 ">
we have used two left-recursion elimination techniques, the traditional one based on paulls algorithm, as reported by hop croft and ullman (1979), and one described by moore (2000)<papid> A00-2033 </papid>5, based on technique described by johnson (1998).<papid> P98-1101 </papid></citsent>
<aftsection>
<nextsent>our experience concurs with moore that the left-corner transform he describes produces more compact left-recursion free grammar than that of paulls algorithm.
</nextsent>
<nextsent>for the k&k; approximation, we were unable to get any grammar to compile through to working language model using paulls algorithm (the models built withpaulls algorithm caused the recognizer to exceed memory bounds), and only succeeded with moores left-recursion elimination technique.
</nextsent>
<nextsent>we have presented descriptions of two algorithms for approximating typed unification grammars with context-free grammars, and evaluated their performance during speech recognition.
</nextsent>
<nextsent>initial results show that high levels of ambiguity coo relate with poor recognition performance, and that size of the resuling language model does not appear to directly coo relate with recognition performance.we have developed new techniques for further reducing the size and amount of ambiguity in these context-free grammars, but have so far met with mixed results.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1179">
<title id=" P04-1058.xml">alternative approaches for generating bodies of grammar rules </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the second approach outperforms the first one along both dimensions.
</prevsent>
<prevsent>n -grams have had big impact on the state of the art in natural language parsing.
</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
they are central to many parsing models (charniak, 1997; collins,1997, <papid> P97-1003 </papid>2000; eisner, 1996), <papid> C96-1058 </papid>and despite their simplicity n-gram models have been very successful.</citsent>
<aftsection>
<nextsent>modeling with n-grams is an induction task (gold, 1967).
</nextsent>
<nextsent>given sample set of strings, the task is toguess the grammar that produced that sample.
</nextsent>
<nextsent>usually, the grammar is not be chosen from an arbitrary set of possible grammars, but from given class.
</nextsent>
<nextsent>hence, grammar induction consists of two parts: choosing the class of languages amongst which to search and designing the procedure for performing the search.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1180">
<title id=" P04-1058.xml">alternative approaches for generating bodies of grammar rules </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the second approach outperforms the first one along both dimensions.
</prevsent>
<prevsent>n -grams have had big impact on the state of the art in natural language parsing.
</prevsent>
</prevsection>
<citsent citstr=" C96-1058 ">
they are central to many parsing models (charniak, 1997; collins,1997, <papid> P97-1003 </papid>2000; eisner, 1996), <papid> C96-1058 </papid>and despite their simplicity n-gram models have been very successful.</citsent>
<aftsection>
<nextsent>modeling with n-grams is an induction task (gold, 1967).
</nextsent>
<nextsent>given sample set of strings, the task is toguess the grammar that produced that sample.
</nextsent>
<nextsent>usually, the grammar is not be chosen from an arbitrary set of possible grammars, but from given class.
</nextsent>
<nextsent>hence, grammar induction consists of two parts: choosing the class of languages amongst which to search and designing the procedure for performing the search.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1181">
<title id=" P04-1058.xml">alternative approaches for generating bodies of grammar rules </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the context of natural language parsing we present an empirical comparison between algorithms for inducing regular languages using grams on the one hand, and more general algorithms for learning the general class of regular language onthe other hand.
</prevsent>
<prevsent>we proceed as follows.
</prevsent>
</prevsection>
<citsent citstr=" P96-1025 ">
we generate our training data from the wall street journal section of the penn tree bank (ptb), by transforming it to projective dependency structures, following (collins, 1996), <papid> P96-1025 </papid>and extracting rules from the result.</citsent>
<aftsection>
<nextsent>these rules are used as training material for the rule induction algorithms we consider.
</nextsent>
<nextsent>the automata produced this way are then used to build grammars which, in turn, are used for parsing.
</nextsent>
<nextsent>we are interested in two different aspects of the use of probabilistic regular languages for natural language parsing: the quality of the induced automata and the performance of the resulting parsers.for evaluation purposes, we use two different met rics: perplexity for the first aspect and percentage of correct attachments for the second.
</nextsent>
<nextsent>the main results of the paper are that, measured in terms of perplexity, the automata induced by algorithms other than n-grams describe the rule bodies better than automata induced using n-gram-based algorithms, and that, moreover, the gain in automata quality is reflected by an improvement in parsing performance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1183">
<title id=" P04-1058.xml">alternative approaches for generating bodies of grammar rules </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the main results of the paper are that, measured in terms of perplexity, the automata induced by algorithms other than n-grams describe the rule bodies better than automata induced using n-gram-based algorithms, and that, moreover, the gain in automata quality is reflected by an improvement in parsing performance.
</prevsent>
<prevsent>we also find that the parsing performance of both methods (n-grams vs. general automata) can be substantially improved by splitting the training material into pos categories.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
as side product,we find empirical evidence to suggest that the effectiveness of rule lexicalization techniques (collins,1997; <papid> P97-1003 </papid>simaan, 2000) and parent annotation techniques (klein and manning, 2003) <papid> P03-1054 </papid>is due to the fact that both lead to reduction in perplexity in the automata induced from training corpora.section 2 surveys our experiments, and later sections provide details of the various aspects.</citsent>
<aftsection>
<nextsent>section 3 offers details on our grammatical framework, pcw-grammars, on transforming automata to pcw-grammars, and on parsing with pcw grammars.
</nextsent>
<nextsent>section 4 explains the starting point ofthis process: learning automata, and section 5 reports on parsing experiments.
</nextsent>
<nextsent>we discuss related work in section 6 and conclude in section 7.
</nextsent>
<nextsent>we want to build grammars using different algorithms for inducing their rules.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1186">
<title id=" P04-1058.xml">alternative approaches for generating bodies of grammar rules </title>
<section> grammatical framework.  </section>
<citcontext>
<prevsection>
<prevsent>where we use only two automata to fit every pos), we need to describe two automata-to-grammar transformations.lets start with the case where we build two automata per pos.
</prevsent>
<prevsent>let be pos in the ptb; let awl and awr be the two automata associated to it.
</prevsent>
</prevsection>
<citsent citstr=" P99-1070 ">
let gwland gwr be the pcfgs equivalent to awl and awr, respectively, following (abney et al , 1999), <papid> P99-1070 </papid>and let swl and swr be the starting symbols of gwl and gwr, respectively.</citsent>
<aftsection>
<nextsent>we build our final grammar with starting symbol s, by defining its meta-rules as the disjoint union of all rules in gwl and gwr (for all pos w), its set of pseudo-rules as the union of the sets {w s1 swlwswr and s1 swlwswr}, where is unique new variable symbol associated to w. when we use two automata for all parts of speech, the grammar is defined as follows.
</nextsent>
<nextsent>let al  and ar be the two automata learned.
</nextsent>
<nextsent>let gland gr be the pcfgs equivalent to aland ar, and let sl and sr be the starting symbols of gland gr,respectively.
</nextsent>
<nextsent>fix pos in the ptb.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1200">
<title id=" P04-1058.xml">alternative approaches for generating bodies of grammar rules </title>
<section> related work and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>n -grams are used to model sequences of arguments, and these hardly ever have length   3, making higher degrees useless.
</prevsent>
<prevsent>to make fair comparison for the many-automata grammar swe did not tune the mdi-based automata individually, but we picked unique alpha.mdi presents way to compact rule information on the ptb; of course, other approaches exists.
</prevsent>
</prevsection>
<citsent citstr=" P98-1115 ">
in particular, krotov et al  (1998) <papid> P98-1115 </papid>try to induce acw-grammar from the ptb with the underlying assumption that some derivations that were supposed to be hidden were left visible.</citsent>
<aftsection>
<nextsent>the attempt to use algorithms other than n-grams-based for inducing of regular languages in the context of grammar induction is not new; for example, kruijff (2003) uses profile hidden models in an attempt to quantify free order variations across languages; we are not aware of evaluations of his grammars as parsing devices.
</nextsent>
<nextsent>our experiments support two kinds of conclusions.
</nextsent>
<nextsent>first, modeling rules with algorithms other than n-grams not only produces smaller grammars butalso better performing ones.
</nextsent>
<nextsent>second, the procedure used for optimizing alpha reveals that some pos behave almost deterministically for selecting their arguments, while others do not.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1201">
<title id=" P04-1019.xml">learning to resolve bridging references </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>anaphoric expressions that cannot be resolved purely on the basis of string matching and thus require the reader to bridge?
</prevsent>
<prevsent>the gap using common sense inferences are arguably the most interesting and, at the same time, the most challenging problem in anaphora resolution.
</prevsent>
</prevsection>
<citsent citstr=" J86-3001 ">
work such as (poesioet al , 1998; poesio et al , 2002; poesio, 2003) provided an experimental confirmation of the hypothesis first put forward by sidner (1979) that bridging descriptions (bd)1 are more similar to pronouns than to other types of definite descriptions, in that they are sensitive to the local rather than the global focus (grosz and sidner, 1986).<papid> J86-3001 </papid></citsent>
<aftsection>
<nextsent>this previ uous work also suggested that simply choosing the entity whose description is lexically closest to thatof the bridging description among those in the current focus space gives poor results; in fact, better results are obtained by always choosing as anchor of the bridging reference2 the first-mentioned entity of the previous sentence (poesio, 2003).
</nextsent>
<nextsent>but neither source of information in isolation resulted in an accuracy over 40%.
</nextsent>
<nextsent>in short, this earlier work suggested that combination of salience and lexical / 1we will use the term bridging descriptions to indicate bridging references realized by definite descriptions, equated here with noun phrases with determiner the, like the top.2following (poesio and vieira, 1998), <papid> J98-2001 </papid>we use the term anchor?</nextsent>
<nextsent>as as generalization of the term antecedent, to indicate the discourse entity which an anaphoric expression either realizes, or is related to by an associative relation; reserving antecedent?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1202">
<title id=" P04-1019.xml">learning to resolve bridging references </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this previ uous work also suggested that simply choosing the entity whose description is lexically closest to thatof the bridging description among those in the current focus space gives poor results; in fact, better results are obtained by always choosing as anchor of the bridging reference2 the first-mentioned entity of the previous sentence (poesio, 2003).
</prevsent>
<prevsent>but neither source of information in isolation resulted in an accuracy over 40%.
</prevsent>
</prevsection>
<citsent citstr=" J98-2001 ">
in short, this earlier work suggested that combination of salience and lexical / 1we will use the term bridging descriptions to indicate bridging references realized by definite descriptions, equated here with noun phrases with determiner the, like the top.2following (poesio and vieira, 1998), <papid> J98-2001 </papid>we use the term anchor?</citsent>
<aftsection>
<nextsent>as as generalization of the term antecedent, to indicate the discourse entity which an anaphoric expression either realizes, or is related to by an associative relation; reserving antecedent?
</nextsent>
<nextsent>for the cases of identity.
</nextsent>
<nextsent>commonsense information is needed to choose the most likely anchor; the problem remained of how to combine this information.in the work described in this paper, we used machine learning techniques to find the best combination of local focus features and lexical distance features, focusing on mereological bridging references:3 references referring to parts of an object already introduced (the cabinet), such as the panels or the top (underlined) in the following example from the gnome corpus (poesio et al , 2004)<papid> J04-3003 </papid>1) the combination of rare and expensive materials used on [this cabinet]i indicates that it was particularly expensive commission.</nextsent>
<nextsent>the four japanese lacquer panels date from the mid- to late 1600s and were created with technique known as kijimaki-e.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1203">
<title id=" P04-1019.xml">learning to resolve bridging references </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as as generalization of the term antecedent, to indicate the discourse entity which an anaphoric expression either realizes, or is related to by an associative relation; reserving antecedent?
</prevsent>
<prevsent>for the cases of identity.
</prevsent>
</prevsection>
<citsent citstr=" J04-3003 ">
commonsense information is needed to choose the most likely anchor; the problem remained of how to combine this information.in the work described in this paper, we used machine learning techniques to find the best combination of local focus features and lexical distance features, focusing on mereological bridging references:3 references referring to parts of an object already introduced (the cabinet), such as the panels or the top (underlined) in the following example from the gnome corpus (poesio et al , 2004)<papid> J04-3003 </papid>1) the combination of rare and expensive materials used on [this cabinet]i indicates that it was particularly expensive commission.</citsent>
<aftsection>
<nextsent>the four japanese lacquer panels date from the mid- to late 1600s and were created with technique known as kijimaki-e.
</nextsent>
<nextsent>for this type of lacquer, artisans sanded plain woodto heighten its strong grain and used it as the back ground of each panel.
</nextsent>
<nextsent>they then added the scenic elements of landscape, plants, and animals in raised lacquer.
</nextsent>
<nextsent>although this technique was common in japan, such large panels were rarely incorporated into french eighteenth-century furniture.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1205">
<title id=" P04-1019.xml">learning to resolve bridging references </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>yellow jasper, semiprecious stone, rather than the usual marble, forms the top.
</prevsent>
<prevsent>reference resolution 2.1 lexical information.
</prevsent>
</prevsection>
<citsent citstr=" J00-4003 ">
the use of different sources of lexical knowledge for resolving bridging references has been investigated in series of papers by poesio et al  all using as dataset the bridging descriptions (bds) contained in the corpus used by vieira and poesio 3we make use of the classification of bridging references proposed by vieira and poesio (2000).<papid> J00-4003 </papid></citsent>
<aftsection>
<nextsent>mereological?
</nextsent>
<nextsent>bridging references are one of the the wordnet?
</nextsent>
<nextsent>bridging classes, which cover cases where the information required to bridge the gap may be found in resource such as wordnet (fellbaum, 1998): synonymy, hyponymy, and meronymy.(2000).
</nextsent>
<nextsent>in these studies, the lexical distance between bd and its antecedent was used to choose the anchor for the bd among the antecedents in the previous five sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1206">
<title id=" P04-1019.xml">learning to resolve bridging references </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>bridging classes, which cover cases where the information required to bridge the gap may be found in resource such as wordnet (fellbaum, 1998): synonymy, hyponymy, and meronymy.(2000).
</prevsent>
<prevsent>in these studies, the lexical distance between bd and its antecedent was used to choose the anchor for the bd among the antecedents in the previous five sentences.
</prevsent>
</prevsection>
<citsent citstr=" W97-1301 ">
in (poesio et al , 1997; <papid> W97-1301 </papid>vieira and poesio, 2000) <papid> J00-4003 </papid>wordnet 1.6 was used as lexical resource, with poor or mediocre results.</citsent>
<aftsection>
<nextsent>these results were due in part to missing entries and / or relations; in part to the fact that because ofthe monotonic organization of information in wordnet, complex searches are required even to find apparently close associations (like that between wheel and car).
</nextsent>
<nextsent>similar results using wordnet 1.6 were reported at around the same time by other groups - e.g., (humphreys et al , 1997; harabagiu and moldovan, 1998) and have been confirmed by more recent studies studying both hyponymy (markert et al ., 2003) and more specifically mereological bds.poesio (2003) found that none of the 58 mereo logical references in the gnome corpus (discussedbelow) had direct mereological link to their anchor: for example, table is not listed as possible holonym of drawer, nor is house listed as possible holonym for furniture.
</nextsent>
<nextsent>garcia-almanza(2003) found that only 16 of these 58 mereologi cal references could be resolved by means of more complex searches in wordnet, including following the hypernymy hierarchy for both the anchor and the bridging reference, and spreading activation?
</nextsent>
<nextsent>search.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1209">
<title id=" P04-1019.xml">learning to resolve bridging references </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the results on mereological bds recall .67,precision=.73were drastically better than those obtained with wordnet or with simple vector ial representations.
</prevsent>
<prevsent>the results with the three types of lexical resources and the different types of bds in the vieira / poesio dataset are summarized in table 1.
</prevsent>
</prevsection>
<citsent citstr=" J03-3005 ">
finally, number of researchers recently argued for using the web as way of addressing data sparseness (keller and lapata, 2003).<papid> J03-3005 </papid></citsent>
<aftsection>
<nextsent>the web has proven useful resource for work in anaphora resolution as well.
</nextsent>
<nextsent>uryupina (2003) <papid> P03-2012 </papid>used the web to estimate definite ness probabilities?</nextsent>
<nextsent>used as afeature to identify discourse-new definites.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1210">
<title id=" P04-1019.xml">learning to resolve bridging references </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>finally, number of researchers recently argued for using the web as way of addressing data sparseness (keller and lapata, 2003).<papid> J03-3005 </papid></prevsent>
<prevsent>the web has proven useful resource for work in anaphora resolution as well.</prevsent>
</prevsection>
<citsent citstr=" P03-2012 ">
uryupina (2003) <papid> P03-2012 </papid>used the web to estimate definite ness probabilities?</citsent>
<aftsection>
<nextsent>used as afeature to identify discourse-new definites.
</nextsent>
<nextsent>markert et al  (2003) used the web and the construction method to extract information about hyponymy used to resolve other-anaphora (achieving an value of around 67%) as well as the bds in the vieira-poesio dataset (their results for these cases were not better than those obtained by (vieira and poesio, 2000)).<papid> J00-4003 </papid></nextsent>
<nextsent>markert et al  also found sharp difference between using the web as a corpus and using the bnc, the results in the latter case being significantly worse than when using wordnet.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1213">
<title id=" P04-1019.xml">learning to resolve bridging references </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one of the motivations behind grosz and sidners(1986) <papid> J86-3001 </papid>distinction between two aspects of the atten tional state - the local focus and the global focusis the difference between the interpretive preferences of pronouns and definite descriptions.</prevsent>
<prevsent>according to grosz and sidner, the interpretation for pronouns is preferentially found in the local focus, whereas that of definite descriptions is preferentially found in the global focus.</prevsent>
</prevsection>
<citsent citstr=" P99-1008 ">
4a similar approach was pursued in parallel by berland and charniak (1999).<papid> P99-1008 </papid></citsent>
<aftsection>
<nextsent>synonymy hyponymy meronymy total wn total bds bds in vieira / poesio corpus 12 14 12 38 204 using wordnet 4 (33.3%) 8(57.1%) 3(33.3%) 15 (39%) 34 (16.7%) using hal lexicon 4 (33.3%) 2(14.3%) 2(16.7%) 8 (22.2%) 46(22.7%) using construction lexicon 1 (8.3%) 0 8(66.7%) 9 (23.7%) 34(16.7%) table 1: bd resolution results using only lexical distance with wordnet, hal-style vector ial lexicon, and construction-based lexicon.
</nextsent>
<nextsent>however, already sidner (1979) hypothesized that bds are different from other definite descriptions, in that the local focus is preferred for their interpretation.
</nextsent>
<nextsent>as already mentioned, the error analysis of poesio et al  (1998) supported this finding: the study found that the strategy found to be optimal for anaphoric definite descriptions by vieira and poesio (2000), <papid> J00-4003 </papid>considering as equally likely all antecedents in the previous five-sentence window (as opposed to preferring closer antecedents), gave poor results for bridging references; entities introduced in the lasttwo sentences and main entities?</nextsent>
<nextsent>were clearly pre ferred.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1222">
<title id=" P04-1019.xml">learning to resolve bridging references </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the dataset thus constructed was used for both training and testing, by means of 10-fold cross validation.types of classifiers used multi-layer percep trons (mlps) have been claimed to work well with small datasets; we tested both our own implementation of an mlp with back-propagation in matlab 6.5, experimenting with different configurations, and an off-the-shelf mlp included in the weka machine learning library8, weka-nn.
</prevsent>
<prevsent>the best configuration for our own mlp proved to be one with sigle hidden layer and 10 hidden nodes.
</prevsent>
</prevsection>
<citsent citstr=" W03-1023 ">
wealso used the implementation of naive bayes classifier included in the weka mll, as modjeska et al  (2003) <papid> W03-1023 </papid>reported good results.</citsent>
<aftsection>
<nextsent>4 experimental results.
</nextsent>
<nextsent>in the first series of experiments only mereological bridging descriptions were considered (i.e., only bridging references realized by the-nps).
</nextsent>
<nextsent>in second series of experiments we considered all 153mereological brs, including ones realized with in definites.
</nextsent>
<nextsent>finally, we tested classifier trained on balanced data (1:1 and 1:3) to find the anchors of bds among all possible anchors.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1223">
<title id=" P04-1019.xml">learning to resolve bridging references </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>its also conforting to note that results with the harder test improve themore data are used, which suggests that better results could be obtained with larger corpus.
</prevsent>
<prevsent>5 related work.
</prevsent>
</prevsection>
<citsent citstr=" P02-1014 ">
in recent years there has been lot of work to develop anaphora resolution algorithms using both symbolic and statistical methods that could be quantitatively evaluated (humphreys et al , 1997; ng andcardie, 2002) <papid> P02-1014 </papid>but this work focused on identity rela tions; bridging references were explicitly excluded from the muc coreference task because of the problems with reliability discussed earlier.</citsent>
<aftsection>
<nextsent>thus, most work on bridging has been theoretical, like the work by asher and lascarides (1998).
</nextsent>
<nextsent>apart from the work by poesio et al , the main other studies attempting quantitative evaluations of bridging reference resolution are (markert et al , 1996; markert et al , 2003).
</nextsent>
<nextsent>markert et al  (1996)also argue for the need to use both centering information and conceptual knowledge, and attempt to characterize the best?
</nextsent>
<nextsent>paths on the basis of an analysis of part-of relations, but use hand-coded, domain-dependent knowledge base.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1224">
<title id=" P03-1059.xml">learning the count ability of english nouns from corpus data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper is concerned with the task of knowledge rich lexical acquisition from unannotated corpora, focusing on the case of count ability in english.knowledge-rich lexical acquisition takes unstructured text and extracts out linguistically-precise cat egorisations of word and expression types.
</prevsent>
<prevsent>by combining this with grammar, we can buildbroad-coverage deep-processing tools with minimum of human effort.
</prevsent>
</prevsection>
<citsent citstr=" P96-1004 ">
this research is closein spirit to the work of light (1996) <papid> P96-1004 </papid>on classifying the semantics of derivational affixes, and siegel and mckeown (2000) <papid> J00-4004 </papid>on learning verb as pect.in english, nouns heading noun phrases are typically either countable or uncountable (also called count and mass).</citsent>
<aftsection>
<nextsent>countable nouns can be modified by denumerators, proto typically numbers, and have morphologically marked plural form: onedog, two dogs.
</nextsent>
<nextsent>uncountable nouns cannot be modified by denumerators, but can be modified by unspecific quantifiers such as much, and do not show any number distinction (prototypically being singular): *one equipment, some equipment, *two equipments.
</nextsent>
<nextsent>many nouns can be used in countable or uncountable environments, with differences in interpretation.
</nextsent>
<nextsent>we call the lexical property that determines which uses noun can have the nouns count ability preference.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1225">
<title id=" P03-1059.xml">learning the count ability of english nouns from corpus data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper is concerned with the task of knowledge rich lexical acquisition from unannotated corpora, focusing on the case of count ability in english.knowledge-rich lexical acquisition takes unstructured text and extracts out linguistically-precise cat egorisations of word and expression types.
</prevsent>
<prevsent>by combining this with grammar, we can buildbroad-coverage deep-processing tools with minimum of human effort.
</prevsent>
</prevsection>
<citsent citstr=" J00-4004 ">
this research is closein spirit to the work of light (1996) <papid> P96-1004 </papid>on classifying the semantics of derivational affixes, and siegel and mckeown (2000) <papid> J00-4004 </papid>on learning verb as pect.in english, nouns heading noun phrases are typically either countable or uncountable (also called count and mass).</citsent>
<aftsection>
<nextsent>countable nouns can be modified by denumerators, proto typically numbers, and have morphologically marked plural form: onedog, two dogs.
</nextsent>
<nextsent>uncountable nouns cannot be modified by denumerators, but can be modified by unspecific quantifiers such as much, and do not show any number distinction (prototypically being singular): *one equipment, some equipment, *two equipments.
</nextsent>
<nextsent>many nouns can be used in countable or uncountable environments, with differences in interpretation.
</nextsent>
<nextsent>we call the lexical property that determines which uses noun can have the nouns count ability preference.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1226">
<title id=" P03-1059.xml">learning the count ability of english nouns from corpus data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in addition, knowledge of count ability obtained from examples of use is an important resource for dictionary construction.in this paper, we learn the count ability preferences of english nouns from unannotated corpora.
</prevsent>
<prevsent>we first annotate them automatically, and then train classifiers using set of gold standard data, taken from comlex (grishman et al, 1998) and the transfer dictionaries used by the machine translation system alt-j/e (ikehara et al, 1991).
</prevsent>
</prevsection>
<citsent citstr=" W03-1010 ">
the classifiers and their training are described in more detail in baldwin and bond (2003).<papid> W03-1010 </papid></citsent>
<aftsection>
<nextsent>these are then run over the corpus to extract nouns as members of four classes ? countable: dog; uncountable: furniture; bi partite: [pair of] scissors and plural only: clothes.
</nextsent>
<nextsent>we first discuss count ability in more detail (?
</nextsent>
<nextsent>2).then we present the lexical resources used in our experiment (?
</nextsent>
<nextsent>3).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1228">
<title id=" P03-1059.xml">learning the count ability of english nouns from corpus data </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>the study of countabil ity is complicated by the fact that most nouns can have their count ability changed: either converted by lexical rule or embedded in another noun phrase.
</prevsent>
<prevsent>an example of conversion is the so-called universal packager, rule which takes an uncountable noun with an interpretation as substance, and returns acount able noun interpreted as portion of the substance: would like two beers.
</prevsent>
</prevsection>
<citsent citstr=" C94-1002 ">
an example of embedding is the use of classifier, e.g. uncountable nouns can be embedded in countable noun phra sesas complements of classifiers: one piece of equip ment.bond et al (1994) <papid> C94-1002 </papid>suggested division of count ability into five major types, based on allan (1980)s noun count ability preferences (ncps).</citsent>
<aftsection>
<nextsent>nouns which rarely undergo conversion are marked as either fully countable, uncountable or plural only.
</nextsent>
<nextsent>fully countable nouns have both singular and plural forms, and can not be used with determiners such as much, little, little, less and overmuch.
</nextsent>
<nextsent>uncountable nouns, such as furniture, have no plural form, and can be used with much.
</nextsent>
<nextsent>plural only nouns never head singular noun phrase: goods, scissors.nouns that are readily converted are marked as either strongly countable (for countable nouns that can be converted to uncountable, such as cake) or weakly countable (for uncountable nouns that are readily convertible to countable, such as beer).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1234">
<title id=" P03-1059.xml">learning the count ability of english nouns from corpus data </title>
<section> learning count ability.  </section>
<citcontext>
<prevsection>
<prevsent>first, we use part-of-speech (pos) tagged data and pos-based templates to extract out the necessary information.
</prevsent>
<prevsent>second, we use chunk datato determine np and pp boundaries, and medium recall chunk adjacency templates to recover inter phrasal dependency.
</prevsent>
</prevsection>
<citsent citstr=" N01-1006 ">
third, we fully parse the dataand simply read off all necessary data from the dependency output.with the pos extraction method, we first penn tagged the bnc using an fntbl-based tagger (ngai and florian, 2001), <papid> N01-1006 </papid>training over the brown andwsj corpora with some spelling, number and hyphenation normalisation.</citsent>
<aftsection>
<nextsent>we then lemmatised this data using version of morph (minnen et al, 2001) customised to the penn pos tagset.
</nextsent>
<nextsent>finally, we implemented range of high-precision, low-recall pos-based templates to extract out the features from the processed data.
</nextsent>
<nextsent>for example, nps are in many cases recoverable with the following perl-style regular expression over penn pos tags: (pdt)* dt (rb|jj[rs]?|nns?)* nns?
</nextsent>
<nextsent>[n].for the chunker, we ran fntbl over the lemmatised tagged data, training over conll 2000style (tjong kim sang and buchholz, 2000) chunk converted versions of the full brown and wsj corpora.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1241">
<title id=" P02-1053.xml">thumbs up or thumbs down semantic orientation applied to unsupervised classification of reviews </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the algorithm takes written review as input and produces classification as output.
</prevsent>
<prevsent>the first step is to use part-of-speech tagger to identify phrases in the in put text that contain adjectives or adverbs (brill, 1994).
</prevsent>
</prevsection>
<citsent citstr=" P97-1023 ">
the second step is to estimate the semantic orientation of each extracted phrase (hatzivassiloglou &amp; mckeown, 1997).<papid> P97-1023 </papid></citsent>
<aftsection>
<nextsent>a phrase has positive semantic orientation when it has good associations (e.g., romantic ambience?)
</nextsent>
<nextsent>and negative semantic orientation when it has bad associations (e.g., horrific events?).
</nextsent>
<nextsent>the third step is to assign the given review to class, recommended or not recommended, based on the average semantic orientation of the phrases extracted from there view.
</nextsent>
<nextsent>if the average is positive, the prediction is that the review recommends the item it discusses.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1244">
<title id=" P02-1053.xml">thumbs up or thumbs down semantic orientation applied to unsupervised classification of reviews </title>
<section> classifying reviews.  </section>
<citcontext>
<prevsection>
<prevsent>finally, conclusions are presented in section 7.
</prevsent>
<prevsent>the first step of the algorithm is to extract phrases containing adjectives or adverbs.
</prevsent>
</prevsection>
<citsent citstr=" W01-1626 ">
past work has demonstrated that adjectives are good indicators of subjective, evaluative sentences (hatzivassiloglou 2 http://www.epinions.com &amp; wiebe, 2000; wiebe, 2000; wiebe et al, 2001).<papid> W01-1626 </papid></citsent>
<aftsection>
<nextsent>however, although an isolated adjective may indicate subjectivity, there may be insufficient context to determine semantic orientation.
</nextsent>
<nextsent>for example, the adjective unpredictable?
</nextsent>
<nextsent>may have negative orientation in an automotive review, in phrase such as unpredictable steering?, but it could have positive orientation in movie review, in phrase such as unpredictable plot?.
</nextsent>
<nextsent>therefore the algorithm extracts two consecutive words, where one member of the pair is an adjective or an adverb and the second provides context.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1246">
<title id=" P02-1053.xml">thumbs up or thumbs down semantic orientation applied to unsupervised classification of reviews </title>
<section> jj jj not nn nor nns.  </section>
<citcontext>
<prevsection>
<prevsent>rb, rbr, or.
</prevsent>
<prevsent>rbs vb, vbd, vbn, or vbg anything the second step is to estimate the semantic orientation of the extracted phrases, using the pmi-ir algorithm.
</prevsent>
</prevsection>
<citsent citstr=" P89-1010 ">
this algorithm uses mutual information as measure of the strength of semantic association between two words (church &amp; hanks, 1989).<papid> P89-1010 </papid></citsent>
<aftsection>
<nextsent>pmi-ir has been empirically evaluated using 80 synonym test questions from the test of english as foreign language (toefl), obtaining score of 74% (turney, 2001).
</nextsent>
<nextsent>for comparison, latent semantic analysis (lsa), another statistical measure of word association, attains score of 64% on the 3 http://www.cs.jhu.edu/~brill/rbt1_14.tar.z 4 see santorini (1995) for complete description of the tags.
</nextsent>
<nextsent>same 80 toefl questions (landauer &amp; dumais, 1997).
</nextsent>
<nextsent>the pointwise mutual information (pmi) between two words, word1 and word2, is defined as follows (church &amp; hanks, 1989): <papid> P89-1010 </papid>p(word1 &amp; word2) pmi(word1, word2) = log2 p(word1) p(word2) (1) here, p(word1 &amp; word2) is the probability that word1 and word2 co-occur.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1252">
<title id=" P02-1053.xml">thumbs up or thumbs down semantic orientation applied to unsupervised classification of reviews </title>
<section> jj jj not nn nor nns.  </section>
<citcontext>
<prevsection>
<prevsent>the company mindfuleye7 offers technology called lexant?
</prevsent>
<prevsent>that appears similar to tongs (2001) system.
</prevsent>
</prevsection>
<citsent citstr=" C00-1044 ">
other related work is concerned with determining subjectivity (hatzivassiloglou &amp; wiebe, 2000; <papid> C00-1044 </papid>wiebe, 2000; wiebe et al, 2001).<papid> W01-1626 </papid></citsent>
<aftsection>
<nextsent>the task is to distinguish sentences that present opinions and evaluations from sentences that objectively present factual information (wiebe, 2000).
</nextsent>
<nextsent>wiebe et al (2001) <papid> W01-1626 </papid>list variety of potential applications for automated subjectivity tagging, such as recognizing flames?</nextsent>
<nextsent>(spertus, 1997), classifying email, recognizing speaker role in radio broadcasts, and mining reviews.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1261">
<title id=" P01-1005.xml">scaling to very very large corpora for natural language disambiguation </title>
<section> confusion set disambiguation.  </section>
<citcontext>
<prevsection>
<prevsent>example confusion sets include: {principle , principal}, {then, than}, {to,two,too}, and {weather,whether}.
</prevsent>
<prevsent>numerous methods have been presented for conf usable disambiguation.
</prevsent>
</prevsection>
<citsent citstr=" A97-1025 ">
the more recent set of techniques includes multiplicative weight update algorithms (golding and roth, 1998), latent semantic analysis (jones and martin, 1997), <papid> A97-1025 </papid>transformation-based learning (mangu and brill, 1997), differential grammars (powers, 1997), <papid> W97-1011 </papid>decision lists (yarowsky, 1994), <papid> P94-1013 </papid>and variety of bayesian classifiers (gale et al , 1993, golding, 1995, <papid> W95-0104 </papid>golding and schabes, 1996).<papid> P96-1010 </papid></citsent>
<aftsection>
<nextsent>in all of these approaches, the problem is formulated as follows: given specific confusion set (e.g. {to,two,too}), all occurrences of confusion set members in the test set are replaced by marker; everywhere the system sees this marker, it must decide which member of the confusion set to choose.
</nextsent>
<nextsent>confusion set disambiguation is one of class of natural language problems involving disambiguation from relatively small set of alternatives based upon the string context in which the ambiguity site appears.
</nextsent>
<nextsent>other such problems include word sense disambiguation, part of speech tagging and some formulations of phrasal chunking.
</nextsent>
<nextsent>one advantageous aspect of confusion set disambiguation, which allows us to study the effects of large datasets on performance, is that labeled training data is essentially free, since the correct answer is surface apparent in any collection of reasonably well-edited text.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1262">
<title id=" P01-1005.xml">scaling to very very large corpora for natural language disambiguation </title>
<section> confusion set disambiguation.  </section>
<citcontext>
<prevsection>
<prevsent>example confusion sets include: {principle , principal}, {then, than}, {to,two,too}, and {weather,whether}.
</prevsent>
<prevsent>numerous methods have been presented for conf usable disambiguation.
</prevsent>
</prevsection>
<citsent citstr=" W97-1011 ">
the more recent set of techniques includes multiplicative weight update algorithms (golding and roth, 1998), latent semantic analysis (jones and martin, 1997), <papid> A97-1025 </papid>transformation-based learning (mangu and brill, 1997), differential grammars (powers, 1997), <papid> W97-1011 </papid>decision lists (yarowsky, 1994), <papid> P94-1013 </papid>and variety of bayesian classifiers (gale et al , 1993, golding, 1995, <papid> W95-0104 </papid>golding and schabes, 1996).<papid> P96-1010 </papid></citsent>
<aftsection>
<nextsent>in all of these approaches, the problem is formulated as follows: given specific confusion set (e.g. {to,two,too}), all occurrences of confusion set members in the test set are replaced by marker; everywhere the system sees this marker, it must decide which member of the confusion set to choose.
</nextsent>
<nextsent>confusion set disambiguation is one of class of natural language problems involving disambiguation from relatively small set of alternatives based upon the string context in which the ambiguity site appears.
</nextsent>
<nextsent>other such problems include word sense disambiguation, part of speech tagging and some formulations of phrasal chunking.
</nextsent>
<nextsent>one advantageous aspect of confusion set disambiguation, which allows us to study the effects of large datasets on performance, is that labeled training data is essentially free, since the correct answer is surface apparent in any collection of reasonably well-edited text.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1263">
<title id=" P01-1005.xml">scaling to very very large corpora for natural language disambiguation </title>
<section> confusion set disambiguation.  </section>
<citcontext>
<prevsection>
<prevsent>example confusion sets include: {principle , principal}, {then, than}, {to,two,too}, and {weather,whether}.
</prevsent>
<prevsent>numerous methods have been presented for conf usable disambiguation.
</prevsent>
</prevsection>
<citsent citstr=" P94-1013 ">
the more recent set of techniques includes multiplicative weight update algorithms (golding and roth, 1998), latent semantic analysis (jones and martin, 1997), <papid> A97-1025 </papid>transformation-based learning (mangu and brill, 1997), differential grammars (powers, 1997), <papid> W97-1011 </papid>decision lists (yarowsky, 1994), <papid> P94-1013 </papid>and variety of bayesian classifiers (gale et al , 1993, golding, 1995, <papid> W95-0104 </papid>golding and schabes, 1996).<papid> P96-1010 </papid></citsent>
<aftsection>
<nextsent>in all of these approaches, the problem is formulated as follows: given specific confusion set (e.g. {to,two,too}), all occurrences of confusion set members in the test set are replaced by marker; everywhere the system sees this marker, it must decide which member of the confusion set to choose.
</nextsent>
<nextsent>confusion set disambiguation is one of class of natural language problems involving disambiguation from relatively small set of alternatives based upon the string context in which the ambiguity site appears.
</nextsent>
<nextsent>other such problems include word sense disambiguation, part of speech tagging and some formulations of phrasal chunking.
</nextsent>
<nextsent>one advantageous aspect of confusion set disambiguation, which allows us to study the effects of large datasets on performance, is that labeled training data is essentially free, since the correct answer is surface apparent in any collection of reasonably well-edited text.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1264">
<title id=" P01-1005.xml">scaling to very very large corpora for natural language disambiguation </title>
<section> confusion set disambiguation.  </section>
<citcontext>
<prevsection>
<prevsent>example confusion sets include: {principle , principal}, {then, than}, {to,two,too}, and {weather,whether}.
</prevsent>
<prevsent>numerous methods have been presented for conf usable disambiguation.
</prevsent>
</prevsection>
<citsent citstr=" W95-0104 ">
the more recent set of techniques includes multiplicative weight update algorithms (golding and roth, 1998), latent semantic analysis (jones and martin, 1997), <papid> A97-1025 </papid>transformation-based learning (mangu and brill, 1997), differential grammars (powers, 1997), <papid> W97-1011 </papid>decision lists (yarowsky, 1994), <papid> P94-1013 </papid>and variety of bayesian classifiers (gale et al , 1993, golding, 1995, <papid> W95-0104 </papid>golding and schabes, 1996).<papid> P96-1010 </papid></citsent>
<aftsection>
<nextsent>in all of these approaches, the problem is formulated as follows: given specific confusion set (e.g. {to,two,too}), all occurrences of confusion set members in the test set are replaced by marker; everywhere the system sees this marker, it must decide which member of the confusion set to choose.
</nextsent>
<nextsent>confusion set disambiguation is one of class of natural language problems involving disambiguation from relatively small set of alternatives based upon the string context in which the ambiguity site appears.
</nextsent>
<nextsent>other such problems include word sense disambiguation, part of speech tagging and some formulations of phrasal chunking.
</nextsent>
<nextsent>one advantageous aspect of confusion set disambiguation, which allows us to study the effects of large datasets on performance, is that labeled training data is essentially free, since the correct answer is surface apparent in any collection of reasonably well-edited text.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1265">
<title id=" P01-1005.xml">scaling to very very large corpora for natural language disambiguation </title>
<section> confusion set disambiguation.  </section>
<citcontext>
<prevsection>
<prevsent>example confusion sets include: {principle , principal}, {then, than}, {to,two,too}, and {weather,whether}.
</prevsent>
<prevsent>numerous methods have been presented for conf usable disambiguation.
</prevsent>
</prevsection>
<citsent citstr=" P96-1010 ">
the more recent set of techniques includes multiplicative weight update algorithms (golding and roth, 1998), latent semantic analysis (jones and martin, 1997), <papid> A97-1025 </papid>transformation-based learning (mangu and brill, 1997), differential grammars (powers, 1997), <papid> W97-1011 </papid>decision lists (yarowsky, 1994), <papid> P94-1013 </papid>and variety of bayesian classifiers (gale et al , 1993, golding, 1995, <papid> W95-0104 </papid>golding and schabes, 1996).<papid> P96-1010 </papid></citsent>
<aftsection>
<nextsent>in all of these approaches, the problem is formulated as follows: given specific confusion set (e.g. {to,two,too}), all occurrences of confusion set members in the test set are replaced by marker; everywhere the system sees this marker, it must decide which member of the confusion set to choose.
</nextsent>
<nextsent>confusion set disambiguation is one of class of natural language problems involving disambiguation from relatively small set of alternatives based upon the string context in which the ambiguity site appears.
</nextsent>
<nextsent>other such problems include word sense disambiguation, part of speech tagging and some formulations of phrasal chunking.
</nextsent>
<nextsent>one advantageous aspect of confusion set disambiguation, which allows us to study the effects of large datasets on performance, is that labeled training data is essentially free, since the correct answer is surface apparent in any collection of reasonably well-edited text.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1266">
<title id=" P01-1005.xml">scaling to very very large corpora for natural language disambiguation </title>
<section> the efficacy of voting.  </section>
<citcontext>
<prevsection>
<prevsent>but for others, where space comes at premium, obtaining the gains that come with billion words of training data may not be viable without an effort made to compress information.
</prevsent>
<prevsent>in such cases, one could look at numerous methods for compressing data (e.g. dagan and engle son, 1995, weng, et al  1998).
</prevsent>
</prevsection>
<citsent citstr=" W99-0623 ">
voting has proven to be an effective technique for improving classifier accuracy for many applications, including part-of-speech tagging (van halteren, et al  1998), parsing (henderson and brill, 1999), <papid> W99-0623 </papid>and word sense disambiguation (pederson, 2000).</citsent>
<aftsection>
<nextsent>by training set of classifiers on single training corpus and then combining their outputs in classification, it is often possible to achieve target accuracy with less labeled training data than would be needed if only one classifier was being used.
</nextsent>
<nextsent>voting can be effective in reducing both the bias of particular training corpus and the bias of specific learner.
</nextsent>
<nextsent>when training corpus is very small, there is much more room for these biases to surface and therefore for voting to be effective.
</nextsent>
<nextsent>but does voting still offer performance gains when classifiers are trained on much larger corpora?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1267">
<title id=" P01-1005.xml">scaling to very very large corpora for natural language disambiguation </title>
<section> the efficacy of voting.  </section>
<citcontext>
<prevsection>
<prevsent>when training corpus is very small, there is much more room for these biases to surface and therefore for voting to be effective.
</prevsent>
<prevsent>but does voting still offer performance gains when classifiers are trained on much larger corpora?
</prevsent>
</prevsection>
<citsent citstr=" P98-1029 ">
the complementarity between two learners was defined by brill and wu (1998) <papid> P98-1029 </papid>in order to quantify the percentage of time when one system is wrong, that another system is correct, and therefore providing an upper bound on combination accuracy.</citsent>
<aftsection>
<nextsent>as training size increases significantly, we would expect complementarity between classifiers to decrease.
</nextsent>
<nextsent>this is due in part to the fact that larger training corpus will reduce the dataset variance and any bias arising from this.
</nextsent>
<nextsent>also, some of the differences between classifiers might be due to how they handle sparse training set.
</nextsent>
<nextsent>1 10 100 1000 10000 100000 1000000 1 10 100 1000 millions of words winnow memory-based figure 2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1268">
<title id=" P01-1005.xml">scaling to very very large corpora for natural language disambiguation </title>
<section> when annotated data is not free.  </section>
<citcontext>
<prevsection>
<prevsent>while the observation that learning curves are not asymptoting even with orders of magnitude more training data than is currently used is very exciting, this result may have somewhat limited ramifications.
</prevsent>
<prevsent>very few problems exist for which annotated data of this size is available for free.
</prevsent>
</prevsection>
<citsent citstr=" H01-1052 ">
surely we cannot reasonably expect that the manual annotation of one billion words along with corresponding parse trees will occur any time soon (but see (banko and brill 2001) <papid> H01-1052 </papid>for discussion that this might not be completely infeasible).</citsent>
<aftsection>
<nextsent>despite this pitfall, there are techniques one can use to try to obtain the benefits of considerably larger training corpora without incurring significant additional costs.
</nextsent>
<nextsent>in the sections that follow, we study two such solutions: active learning and unsupervised learning.
</nextsent>
<nextsent>5.1 active learning.
</nextsent>
<nextsent>active learning involves intelligently selecting portion of samples for annotation from pool of as-yet unannotated training samples.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1269">
<title id=" P03-1011.xml">loosely tree based alignment for machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we augment model of translation based on re-ordering nodes in syntactic trees in order to allow alignments not conforming to the original tree structure, while keeping computational complexity polynomial in the sentence length.
</prevsent>
<prevsent>this is done by adding new subtree cloning operation to either tree-to-string or tree-to-tree alignment algorithms.
</prevsent>
</prevsection>
<citsent citstr=" J90-2002 ">
systems for automatic translation between languages have been divided into transfer-based approaches, which relyon interpreting the source string into an abstract semantic representation from which text is generated in the target language, and statistical approaches, pioneered by brown et al  (1990), <papid> J90-2002 </papid>which estimate parameters for model of word-to-word correspondences and wordre-orderings directly from large corpora of parallel bilingual text.</citsent>
<aftsection>
<nextsent>only recently have hybrid approaches begun to emerge, which apply probabilistic models to structured representation ofthe source text.
</nextsent>
<nextsent>wu (1997) <papid> J97-3002 </papid>showed that restricting word-level alignments between sentence pairsto observe syntactic bracketing constraints significantly reduces the complexity of the alignment problem and allows polynomial-time solution.alshawi et al  (2000) <papid> J00-1004 </papid>also induce parallel tree structures from un bracketed parallel text, modeling the generation of each nodes children with finite-state transducer.</nextsent>
<nextsent>yamada and knight (2001) <papid> P01-1067 </papid>present an algorithm for estimating probabilistic parameters fora similar model which represents translation as sequence of re-ordering operations over children ofnodes in syntactic tree, using automatic parser out put for the initial tree structures.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1270">
<title id=" P03-1011.xml">loosely tree based alignment for machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>systems for automatic translation between languages have been divided into transfer-based approaches, which relyon interpreting the source string into an abstract semantic representation from which text is generated in the target language, and statistical approaches, pioneered by brown et al  (1990), <papid> J90-2002 </papid>which estimate parameters for model of word-to-word correspondences and wordre-orderings directly from large corpora of parallel bilingual text.</prevsent>
<prevsent>only recently have hybrid approaches begun to emerge, which apply probabilistic models to structured representation ofthe source text.</prevsent>
</prevsection>
<citsent citstr=" J97-3002 ">
wu (1997) <papid> J97-3002 </papid>showed that restricting word-level alignments between sentence pairsto observe syntactic bracketing constraints significantly reduces the complexity of the alignment problem and allows polynomial-time solution.alshawi et al  (2000) <papid> J00-1004 </papid>also induce parallel tree structures from un bracketed parallel text, modeling the generation of each nodes children with finite-state transducer.</citsent>
<aftsection>
<nextsent>yamada and knight (2001) <papid> P01-1067 </papid>present an algorithm for estimating probabilistic parameters fora similar model which represents translation as sequence of re-ordering operations over children ofnodes in syntactic tree, using automatic parser out put for the initial tree structures.</nextsent>
<nextsent>the use of explicit syntactic information for the target language in this model has led to excellent translation results (ya mada and knight, 2002), <papid> P02-1039 </papid>and raises the prospect of training statistical system using syntactic information for both sides of the parallel corpus.tree-to-tree alignment techniques such as probabilistic tree substitution grammars (hajic?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1271">
<title id=" P03-1011.xml">loosely tree based alignment for machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>systems for automatic translation between languages have been divided into transfer-based approaches, which relyon interpreting the source string into an abstract semantic representation from which text is generated in the target language, and statistical approaches, pioneered by brown et al  (1990), <papid> J90-2002 </papid>which estimate parameters for model of word-to-word correspondences and wordre-orderings directly from large corpora of parallel bilingual text.</prevsent>
<prevsent>only recently have hybrid approaches begun to emerge, which apply probabilistic models to structured representation ofthe source text.</prevsent>
</prevsection>
<citsent citstr=" J00-1004 ">
wu (1997) <papid> J97-3002 </papid>showed that restricting word-level alignments between sentence pairsto observe syntactic bracketing constraints significantly reduces the complexity of the alignment problem and allows polynomial-time solution.alshawi et al  (2000) <papid> J00-1004 </papid>also induce parallel tree structures from un bracketed parallel text, modeling the generation of each nodes children with finite-state transducer.</citsent>
<aftsection>
<nextsent>yamada and knight (2001) <papid> P01-1067 </papid>present an algorithm for estimating probabilistic parameters fora similar model which represents translation as sequence of re-ordering operations over children ofnodes in syntactic tree, using automatic parser out put for the initial tree structures.</nextsent>
<nextsent>the use of explicit syntactic information for the target language in this model has led to excellent translation results (ya mada and knight, 2002), <papid> P02-1039 </papid>and raises the prospect of training statistical system using syntactic information for both sides of the parallel corpus.tree-to-tree alignment techniques such as probabilistic tree substitution grammars (hajic?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1272">
<title id=" P03-1011.xml">loosely tree based alignment for machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>only recently have hybrid approaches begun to emerge, which apply probabilistic models to structured representation ofthe source text.
</prevsent>
<prevsent>wu (1997) <papid> J97-3002 </papid>showed that restricting word-level alignments between sentence pairsto observe syntactic bracketing constraints significantly reduces the complexity of the alignment problem and allows polynomial-time solution.alshawi et al  (2000) <papid> J00-1004 </papid>also induce parallel tree structures from un bracketed parallel text, modeling the generation of each nodes children with finite-state transducer.</prevsent>
</prevsection>
<citsent citstr=" P01-1067 ">
yamada and knight (2001) <papid> P01-1067 </papid>present an algorithm for estimating probabilistic parameters fora similar model which represents translation as sequence of re-ordering operations over children ofnodes in syntactic tree, using automatic parser out put for the initial tree structures.</citsent>
<aftsection>
<nextsent>the use of explicit syntactic information for the target language in this model has led to excellent translation results (ya mada and knight, 2002), <papid> P02-1039 </papid>and raises the prospect of training statistical system using syntactic information for both sides of the parallel corpus.tree-to-tree alignment techniques such as probabilistic tree substitution grammars (hajic?</nextsent>
<nextsent>et al , 2002) can be trained on parse trees from parallel treebanks.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1274">
<title id=" P03-1011.xml">loosely tree based alignment for machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>wu (1997) <papid> J97-3002 </papid>showed that restricting word-level alignments between sentence pairsto observe syntactic bracketing constraints significantly reduces the complexity of the alignment problem and allows polynomial-time solution.alshawi et al  (2000) <papid> J00-1004 </papid>also induce parallel tree structures from un bracketed parallel text, modeling the generation of each nodes children with finite-state transducer.</prevsent>
<prevsent>yamada and knight (2001) <papid> P01-1067 </papid>present an algorithm for estimating probabilistic parameters fora similar model which represents translation as sequence of re-ordering operations over children ofnodes in syntactic tree, using automatic parser out put for the initial tree structures.</prevsent>
</prevsection>
<citsent citstr=" P02-1039 ">
the use of explicit syntactic information for the target language in this model has led to excellent translation results (ya mada and knight, 2002), <papid> P02-1039 </papid>and raises the prospect of training statistical system using syntactic information for both sides of the parallel corpus.tree-to-tree alignment techniques such as probabilistic tree substitution grammars (hajic?</citsent>
<aftsection>
<nextsent>et al , 2002) can be trained on parse trees from parallel treebanks.
</nextsent>
<nextsent>however, real bitexts generally do not exhibit parse-tree isomorphism, whether because of systematic differences between how languages express concept syntactically (dorr, 1994), <papid> J94-4004 </papid>or simply because of relatively free translations in the training material.</nextsent>
<nextsent>in this paper, we introduce loosely?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1275">
<title id=" P03-1011.xml">loosely tree based alignment for machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the use of explicit syntactic information for the target language in this model has led to excellent translation results (ya mada and knight, 2002), <papid> P02-1039 </papid>and raises the prospect of training statistical system using syntactic information for both sides of the parallel corpus.tree-to-tree alignment techniques such as probabilistic tree substitution grammars (hajic?</prevsent>
<prevsent>et al , 2002) can be trained on parse trees from parallel treebanks.</prevsent>
</prevsection>
<citsent citstr=" J94-4004 ">
however, real bitexts generally do not exhibit parse-tree isomorphism, whether because of systematic differences between how languages express concept syntactically (dorr, 1994), <papid> J94-4004 </papid>or simply because of relatively free translations in the training material.</citsent>
<aftsection>
<nextsent>in this paper, we introduce loosely?
</nextsent>
<nextsent>tree-based alignment techniques to address this problem.
</nextsent>
<nextsent>we present analogous extensions for both tree-to-string and tree-to-tree models that allow alignments not obeying the constraints of the original syntactic tree(or tree pair), although such alignments are dispre ferred because they incur cost in probability.
</nextsent>
<nextsent>this is achieved by introducing clone operation, which copies an entire subtree of the source language syntactic structure, moving it anywhere in the target language sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1280">
<title id=" P03-1011.xml">loosely tree based alignment for machine translation </title>
<section> the tree-to-string model.  </section>
<citcontext>
<prevsection>
<prevsent>any number of times.
</prevsent>
<prevsent>this independence assumption is crucial to the computational tract ability of the algorithm, as the model can be estimated using the dynamic programming method above, keeping counts for the expected number of times each node has been cloned, at no increase in computational complexity.
</prevsent>
</prevsection>
<citsent citstr=" J85-4001 ">
without such an assumption, the parameter estimation becomes problem of parsing with crossing dependencies, which is exponential in the length of the input string (barton, 1985).<papid> J85-4001 </papid></citsent>
<aftsection>
<nextsent>the tree-to-tree alignment model has tree transformation operations similar to those of the tree-tostring model described above.
</nextsent>
<nextsent>however, the transformed tree must not only match the surface string of the target language, but also the tree structure assigned to the string by the treebank annotators.
</nextsent>
<nextsent>in order to provide enough flexibility to make this possible, additional tree transformation operations allow single node in the source tree to produce two nodes in the target tree, or two nodes in the source tree to be grouped together and produce single node in the target tree.
</nextsent>
<nextsent>the model can be thought of as asynchronous tree substitution grammar, with probabilities parameterized to generate the target tree conditioned on the structure of the source tree.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1281">
<title id=" P03-1011.xml">loosely tree based alignment for machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>for reasons of computation speed, trees with more than 5 children were excluded from the experiments described below.
</prevsent>
<prevsent>we evaluate our translation models both in terms agreement with human-annotated word-level alignments between the sentence pairs.
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
for scoring the viterbi alignments of each system against gold standard annotated alignments, we use the alignment error rate (aer) of och and ney (2000), <papid> P00-1056 </papid>which measures agreement at the level of pairs of words:1 aer = 1 ? 2ja \ gj jaj + jgj 1while och and ney (2000) <papid> P00-1056 </papid>differentiate between sure and possible hand-annotated alignments, our gold standard alignments come in only one variety.</citsent>
<aftsection>
<nextsent>alignment error rate ibm model 1 .37 ibm model 2 .35 ibm model 3 .43 tree-to-string .42 tree-to-string, clone .36 tree-to-string, clone pins = .5 .32 tree-to-tree .49 tree-to-tree, clone .36 table 2: alignment error rate on korean-english corpus where is the set of word pairs aligned by the automatic system, and the set al gned in the gold standard.
</nextsent>
<nextsent>we provide comparison of the tree-basedmodels with the sequence of successively more complex models of brown et al  (1993).<papid> J93-2003 </papid></nextsent>
<nextsent>results are shown in table 2.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1283">
<title id=" P03-1011.xml">loosely tree based alignment for machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>for scoring the viterbi alignments of each system against gold standard annotated alignments, we use the alignment error rate (aer) of och and ney (2000), <papid> P00-1056 </papid>which measures agreement at the level of pairs of words:1 aer = 1 ? 2ja \ gj jaj + jgj 1while och and ney (2000) <papid> P00-1056 </papid>differentiate between sure and possible hand-annotated alignments, our gold standard alignments come in only one variety.</prevsent>
<prevsent>alignment error rate ibm model 1 .37 ibm model 2 .35 ibm model 3 .43 tree-to-string .42 tree-to-string, clone .36 tree-to-string, clone pins = .5 .32 tree-to-tree .49 tree-to-tree, clone .36 table 2: alignment error rate on korean-english corpus where is the set of word pairs aligned by the automatic system, and the set al gned in the gold standard.</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
we provide comparison of the tree-basedmodels with the sequence of successively more complex models of brown et al  (1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>results are shown in table 2.
</nextsent>
<nextsent>the error rates shown in table 2 represent the minimum over training iterations; training was stopped for each model when error began to in crease.
</nextsent>
<nextsent>ibm models 1, 2, and 3 refer to brown et al  (1993).<papid> J93-2003 </papid></nextsent>
<nextsent>tree-to-string?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1289">
<title id=" P03-1011.xml">loosely tree based alignment for machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>system on one sentence from our test set.we found better agreement with the human alignments when fixing pins(left) in the tree-to-stringmodel to constant rather than letting it be determined through the em training.
</prevsent>
<prevsent>while the model learned by em tends to overestimate the total number of aligned word pairs, fixing higher probability for insertions results in fewer total aligned pairs and therefore better trade-off between precision andrecall.
</prevsent>
</prevsection>
<citsent citstr=" J94-2001 ">
as seen for other tasks (carroll and charniak, 1992; merialdo, 1994), <papid> J94-2001 </papid>the likelihood criterion used in em training may not be optimal when evaluating system against human labeling.</citsent>
<aftsection>
<nextsent>the approach of optimizing small number of metapa rameters has been applied to machine translation byoch and ney (2002).<papid> P02-1038 </papid></nextsent>
<nextsent>it is likely that the ibm models could similarly be optimized to minimize alignment error ? an open question is whether the optimization with respect to alignment error will correspond to optimization for translation accuracy.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1290">
<title id=" P03-1011.xml">loosely tree based alignment for machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>while the model learned by em tends to overestimate the total number of aligned word pairs, fixing higher probability for insertions results in fewer total aligned pairs and therefore better trade-off between precision andrecall.
</prevsent>
<prevsent>as seen for other tasks (carroll and charniak, 1992; merialdo, 1994), <papid> J94-2001 </papid>the likelihood criterion used in em training may not be optimal when evaluating system against human labeling.</prevsent>
</prevsection>
<citsent citstr=" P02-1038 ">
the approach of optimizing small number of metapa rameters has been applied to machine translation byoch and ney (2002).<papid> P02-1038 </papid></citsent>
<aftsection>
<nextsent>it is likely that the ibm models could similarly be optimized to minimize alignment error ? an open question is whether the optimization with respect to alignment error will correspond to optimization for translation accuracy.
</nextsent>
<nextsent>within the strict em framework, we found roughly equivalent performance between the ibm models and the two tree-based models when making use of the cloning operation.
</nextsent>
<nextsent>for both the tree-to string and tree-to-tree models, the cloning operation improved results, indicating that adding the flexibility to handle structural divergence is important when using syntax-based models.
</nextsent>
<nextsent>the improvement was particularly significant for the tree-to-tree model, because using syntactic trees on both sides of the translation pair, while desirable as an additional source of information, severely constrains possible alignments unless the cloning operation is allowed.the tree-to-tree model has better theoretical complexity than the tree-to-string model, being quadratic rather than quartic in sentence length, and we found this to be significant advantage in practice.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1292">
<title id=" P02-1014.xml">improving machine learning approaches to coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>specifically, pair of nps is classified as co-referring or not based on constraints that are learned from an annotated corpus.
</prevsent>
<prevsent>a separate clustering mechanism then coordinates the possibly contradictory pairwise classifications and constructs partition on the set of nps.
</prevsent>
</prevsection>
<citsent citstr=" J01-4004 ">
soon et al (2001), <papid> J01-4004 </papid>for example, apply an np coreference system basedon decision tree induction to two standard coreference resolution datasets (muc-6, 1995; muc 7, 1998), achieving performance comparable to thebest-performing knowledge-based coreference en gines.</citsent>
<aftsection>
<nextsent>perhaps surprisingly, this was accomplished in decidedly knowledge-lean manner ? the learning algorithm has access to just 12 surface-level features.
</nextsent>
<nextsent>this paper presents an np coreference system that investigates two types of extensions to the soon et al. corpus-based approach.
</nextsent>
<nextsent>first, we propose and evaluate three extra-linguistic modifications to the machine learning framework, which together provide substantial and statistically significant gains in coreference resolution precision.
</nextsent>
<nextsent>second, in an attempt to understand whether incorporating additional knowledge can improve the performance of corpus-based coreference resolution system, we expand the soon et al feature set from 12 feature sto an arguably deeper set of 53.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1293">
<title id=" P02-1014.xml">improving machine learning approaches to coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>second, in an attempt to understand whether incorporating additional knowledge can improve the performance of corpus-based coreference resolution system, we expand the soon et al feature set from 12 feature sto an arguably deeper set of 53.
</prevsent>
<prevsent>we propose additional lexical, semantic, and knowledge-based features; most notably, however, we propose 26 additional grammatical features that include variety of linguistic constraints and preferences.
</prevsent>
</prevsection>
<citsent citstr=" J94-4002 ">
although the use of similar knowledge sources has been explored in the context of both pronoun resolution (e.g. lap pin and leass (1994)) <papid> J94-4002 </papid>and np coreference resolution (e.g. grishman (1995), <papid> M95-1014 </papid>lin (1995)), <papid> M95-1010 </papid>most previous work treats linguistic constraints as broadly and unconditionally applicable hard constraints.</citsent>
<aftsection>
<nextsent>because sources of linguistic information in learning-basedsystem are represented as features, we can, in contrast, incorporate them selectively rather than as universal hard constraints.
</nextsent>
<nextsent>our results using an expanded feature set aremixed.
</nextsent>
<nextsent>first, we find that performance drops significantly when using the full feature set, even though the learning algorithms investigated have built-infeature selection mechanisms.
</nextsent>
<nextsent>we demonstrate em computational linguistics (acl), philadelphia, july 2002, pp.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1294">
<title id=" P02-1014.xml">improving machine learning approaches to coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>second, in an attempt to understand whether incorporating additional knowledge can improve the performance of corpus-based coreference resolution system, we expand the soon et al feature set from 12 feature sto an arguably deeper set of 53.
</prevsent>
<prevsent>we propose additional lexical, semantic, and knowledge-based features; most notably, however, we propose 26 additional grammatical features that include variety of linguistic constraints and preferences.
</prevsent>
</prevsection>
<citsent citstr=" M95-1014 ">
although the use of similar knowledge sources has been explored in the context of both pronoun resolution (e.g. lap pin and leass (1994)) <papid> J94-4002 </papid>and np coreference resolution (e.g. grishman (1995), <papid> M95-1014 </papid>lin (1995)), <papid> M95-1010 </papid>most previous work treats linguistic constraints as broadly and unconditionally applicable hard constraints.</citsent>
<aftsection>
<nextsent>because sources of linguistic information in learning-basedsystem are represented as features, we can, in contrast, incorporate them selectively rather than as universal hard constraints.
</nextsent>
<nextsent>our results using an expanded feature set aremixed.
</nextsent>
<nextsent>first, we find that performance drops significantly when using the full feature set, even though the learning algorithms investigated have built-infeature selection mechanisms.
</nextsent>
<nextsent>we demonstrate em computational linguistics (acl), philadelphia, july 2002, pp.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1295">
<title id=" P02-1014.xml">improving machine learning approaches to coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>second, in an attempt to understand whether incorporating additional knowledge can improve the performance of corpus-based coreference resolution system, we expand the soon et al feature set from 12 feature sto an arguably deeper set of 53.
</prevsent>
<prevsent>we propose additional lexical, semantic, and knowledge-based features; most notably, however, we propose 26 additional grammatical features that include variety of linguistic constraints and preferences.
</prevsent>
</prevsection>
<citsent citstr=" M95-1010 ">
although the use of similar knowledge sources has been explored in the context of both pronoun resolution (e.g. lap pin and leass (1994)) <papid> J94-4002 </papid>and np coreference resolution (e.g. grishman (1995), <papid> M95-1014 </papid>lin (1995)), <papid> M95-1010 </papid>most previous work treats linguistic constraints as broadly and unconditionally applicable hard constraints.</citsent>
<aftsection>
<nextsent>because sources of linguistic information in learning-basedsystem are represented as features, we can, in contrast, incorporate them selectively rather than as universal hard constraints.
</nextsent>
<nextsent>our results using an expanded feature set aremixed.
</nextsent>
<nextsent>first, we find that performance drops significantly when using the full feature set, even though the learning algorithms investigated have built-infeature selection mechanisms.
</nextsent>
<nextsent>we demonstrate em computational linguistics (acl), philadelphia, july 2002, pp.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1297">
<title id=" P02-1014.xml">improving machine learning approaches to coreference resolution </title>
<section> the baseline coreference system.  </section>
<citcontext>
<prevsection>
<prevsent>each training instance represents the two nps under consideration and consists of the 12 soon et al features, which are described in table 1.
</prevsent>
<prevsent>linguistically, the feature scan be divided into four groups: lexical, grammatical, semantic, and positional.2 the classification associated with training instance is one of coref erent or not co referent depending on whether the nps co-refer in the associated training text.
</prevsent>
</prevsection>
<citsent citstr=" N01-1008 ">
we follow the procedure employed in soon et al to cre 1results presented in harabagiu et al (2001) <papid> N01-1008 </papid>are higher than those reported here, but assume that all and only the noun phrases involved in coreference relationships are provided for analysis by the coreference resolution system.</citsent>
<aftsection>
<nextsent>we presume no preprocessing of the training and test documents.
</nextsent>
<nextsent>2in all of the work presented here, nps are identified, and features values computed entirely automatically.
</nextsent>
<nextsent>ate the training data: we relyon coreference chains from the muc answer keys to create (1) positive instance for each anaphoric noun phrase, np , and its closest preceding antecedent, np ; and (2) negative instance for np paired with each of the intervening nps, np , np  ,  , np  . this method of negative instance selection is further described in soon et al (2001); <papid> J01-4004 </papid>it is designed to operate in conjunction with their method for creating coreference chains, which is explained next.</nextsent>
<nextsent>applying the classifier to create coreference chains.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1299">
<title id=" P02-1014.xml">improving machine learning approaches to coreference resolution </title>
<section> the baseline coreference system.  </section>
<citcontext>
<prevsection>
<prevsent>the muc-6 corpus produces training set of 26455 instances (5.4% positive) from 4381 nps and test set of 28443 instances (5.2% positive) from 4565 nps.
</prevsent>
<prevsent>for themuc-7 corpus, we obtain training set of 35895 instances (4.4% positive) from 5270 nps and test set of 22699 instances (3.9% positive) from 3558 nps.
</prevsent>
</prevsection>
<citsent citstr=" M95-1005 ">
results are shown in table 2 (duplicated soon baseline) where performance is reported in termsof recall, precision, and f-measure using the model theoretic muc scoring program (vilain et al, 1995).<papid> M95-1005 </papid></citsent>
<aftsection>
<nextsent>3we convert the binary class value using the smoothed ratio    , where is the number of positive instances and is the total number of instances contained in the corresponding leaf node.
</nextsent>
<nextsent>feature type feature description lexical soon str if, after discarding determiners, the string denoting np matches that of np ; else i. grammatical pronoun 1* if np is pronoun; else n. pronoun 2* if np is pronoun; else n. definite 2 if np starts with the word the;?
</nextsent>
<nextsent>else n. demonstrative 2 if np starts with demonstrative such as this,?
</nextsent>
<nextsent>that,?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1300">
<title id=" P02-1014.xml">improving machine learning approaches to coreference resolution </title>
<section> modifications to the machine learning.  </section>
<citcontext>
<prevsection>
<prevsent>similar, but weaker, effects occur when applying each of the learning framework modifications to the baseline system in isolation.
</prevsent>
<prevsent>(see the indented learning framework results in table 2.)
</prevsent>
</prevsection>
<citsent citstr=" W97-1303 ">
our results provide direct evidence for the claim (mitkov, 1997) <papid> W97-1303 </papid>that the extra-linguistic strategies employed to combine the available linguistic knowledge sources play an important role in computational approaches to coreference resolution.</citsent>
<aftsection>
<nextsent>in particular, our results suggest that additional performance gains might be obtained by further investigating the interaction between training instance selection, feature selection, and the coreference clustering algorithm.
</nextsent>
<nextsent>this section describes the second major extension to the soon approach investigated here: we explore the effect of including 41 additional, potentially useful knowledge sources for the coreference resolution classifier (table 3).
</nextsent>
<nextsent>the features were not derived empirically from the corpus, but were based on common-sense knowledge and linguistic intuitions 6chi-square statistical significance tests are applied to changes in recall and precision throughout the paper.
</nextsent>
<nextsent>unless otherwise noted, reported differences are at the 0.05 level or higher.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1303">
<title id=" N12-1056.xml">space efficiencies in discourse modeling via conditional random sampling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we show the method of conditional random sampling, thus far an underutilized technique, to be space-efficient meansof representing the sufficient statistics in discourse that underly recent pmi-based work.this is demonstrated in the context of inducing shan kian script-like structures over news articles.
</prevsent>
<prevsent>it has become common to model the distributional affinity between some word or phrase pair, (wi, wj),as function of co-occurance within some context boundary.
</prevsent>
</prevsection>
<citsent citstr=" J90-1003 ">
church and hanks (1990) <papid> J90-1003 </papid>suggested pointwise mutual information: pmi(wi, wj) = log pr(wi,wj)pr(wi) pr(wj) , showing linguistically appealing results using contexts defined by fixed width n-gram windows, and syntactic dependencies derived from automatically parsed corpora.</citsent>
<aftsection>
<nextsent>later work such asby lin (1999) <papid> P99-1041 </papid>continued this tradition.</nextsent>
<nextsent>here we consider document, or discourse-level contexts, such as explored by rosenfeld (1994) or church (2000), <papid> C00-1027 </papid>andmore recently by those such as chambers and jurafsky (2008) <papid> P08-1090 </papid>or van durme and lall (2009b).in the spirit of recent work in randomized algorithms for large-scale hlt (such as by ravichandran et al (2005), <papid> P05-1077 </papid>talbot and osborne (2007), <papid> P07-1065 </papid>goyal et al.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1304">
<title id=" N12-1056.xml">space efficiencies in discourse modeling via conditional random sampling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it has become common to model the distributional affinity between some word or phrase pair, (wi, wj),as function of co-occurance within some context boundary.
</prevsent>
<prevsent>church and hanks (1990) <papid> J90-1003 </papid>suggested pointwise mutual information: pmi(wi, wj) = log pr(wi,wj)pr(wi) pr(wj) , showing linguistically appealing results using contexts defined by fixed width n-gram windows, and syntactic dependencies derived from automatically parsed corpora.</prevsent>
</prevsection>
<citsent citstr=" P99-1041 ">
later work such asby lin (1999) <papid> P99-1041 </papid>continued this tradition.</citsent>
<aftsection>
<nextsent>here we consider document, or discourse-level contexts, such as explored by rosenfeld (1994) or church (2000), <papid> C00-1027 </papid>andmore recently by those such as chambers and jurafsky (2008) <papid> P08-1090 </papid>or van durme and lall (2009b).in the spirit of recent work in randomized algorithms for large-scale hlt (such as by ravichandran et al (2005), <papid> P05-1077 </papid>talbot and osborne (2007), <papid> P07-1065 </papid>goyal et al.</nextsent>
<nextsent>(2010), talbot and brants (2008),<papid> P08-1058 </papid>van durme and lall (2009a), levenberg and osborne (2009), <papid> D09-1079 </papid>goyal et al (2010), <papid> W10-2808 </papid>petrovic et al (2010), van durme andlall (2010), or goyal and daume?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1305">
<title id=" N12-1056.xml">space efficiencies in discourse modeling via conditional random sampling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>church and hanks (1990) <papid> J90-1003 </papid>suggested pointwise mutual information: pmi(wi, wj) = log pr(wi,wj)pr(wi) pr(wj) , showing linguistically appealing results using contexts defined by fixed width n-gram windows, and syntactic dependencies derived from automatically parsed corpora.</prevsent>
<prevsent>later work such asby lin (1999) <papid> P99-1041 </papid>continued this tradition.</prevsent>
</prevsection>
<citsent citstr=" C00-1027 ">
here we consider document, or discourse-level contexts, such as explored by rosenfeld (1994) or church (2000), <papid> C00-1027 </papid>andmore recently by those such as chambers and jurafsky (2008) <papid> P08-1090 </papid>or van durme and lall (2009b).in the spirit of recent work in randomized algorithms for large-scale hlt (such as by ravichandran et al (2005), <papid> P05-1077 </papid>talbot and osborne (2007), <papid> P07-1065 </papid>goyal et al.</citsent>
<aftsection>
<nextsent>(2010), talbot and brants (2008),<papid> P08-1058 </papid>van durme and lall (2009a), levenberg and osborne (2009), <papid> D09-1079 </papid>goyal et al (2010), <papid> W10-2808 </papid>petrovic et al (2010), van durme andlall (2010), or goyal and daume?</nextsent>
<nextsent>(2011)), we propose the method of conditional random sampling (crs) by li and church (2007) <papid> J07-3003 </papid>as an efficient wayto store approximations of the statistics used to calculate pmi for applications in inducing rudimentary script-like structures.efficiently storing such structures is an important step in integrating document-level statistics into downstream tasks, such as characterizing complex scenarios (chambers and jurafsky, 2011), <papid> P11-1098 </papid>or story understanding (gordon et al, 2011).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1306">
<title id=" N12-1056.xml">space efficiencies in discourse modeling via conditional random sampling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>church and hanks (1990) <papid> J90-1003 </papid>suggested pointwise mutual information: pmi(wi, wj) = log pr(wi,wj)pr(wi) pr(wj) , showing linguistically appealing results using contexts defined by fixed width n-gram windows, and syntactic dependencies derived from automatically parsed corpora.</prevsent>
<prevsent>later work such asby lin (1999) <papid> P99-1041 </papid>continued this tradition.</prevsent>
</prevsection>
<citsent citstr=" P08-1090 ">
here we consider document, or discourse-level contexts, such as explored by rosenfeld (1994) or church (2000), <papid> C00-1027 </papid>andmore recently by those such as chambers and jurafsky (2008) <papid> P08-1090 </papid>or van durme and lall (2009b).in the spirit of recent work in randomized algorithms for large-scale hlt (such as by ravichandran et al (2005), <papid> P05-1077 </papid>talbot and osborne (2007), <papid> P07-1065 </papid>goyal et al.</citsent>
<aftsection>
<nextsent>(2010), talbot and brants (2008),<papid> P08-1058 </papid>van durme and lall (2009a), levenberg and osborne (2009), <papid> D09-1079 </papid>goyal et al (2010), <papid> W10-2808 </papid>petrovic et al (2010), van durme andlall (2010), or goyal and daume?</nextsent>
<nextsent>(2011)), we propose the method of conditional random sampling (crs) by li and church (2007) <papid> J07-3003 </papid>as an efficient wayto store approximations of the statistics used to calculate pmi for applications in inducing rudimentary script-like structures.efficiently storing such structures is an important step in integrating document-level statistics into downstream tasks, such as characterizing complex scenarios (chambers and jurafsky, 2011), <papid> P11-1098 </papid>or story understanding (gordon et al, 2011).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1307">
<title id=" N12-1056.xml">space efficiencies in discourse modeling via conditional random sampling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>church and hanks (1990) <papid> J90-1003 </papid>suggested pointwise mutual information: pmi(wi, wj) = log pr(wi,wj)pr(wi) pr(wj) , showing linguistically appealing results using contexts defined by fixed width n-gram windows, and syntactic dependencies derived from automatically parsed corpora.</prevsent>
<prevsent>later work such asby lin (1999) <papid> P99-1041 </papid>continued this tradition.</prevsent>
</prevsection>
<citsent citstr=" P05-1077 ">
here we consider document, or discourse-level contexts, such as explored by rosenfeld (1994) or church (2000), <papid> C00-1027 </papid>andmore recently by those such as chambers and jurafsky (2008) <papid> P08-1090 </papid>or van durme and lall (2009b).in the spirit of recent work in randomized algorithms for large-scale hlt (such as by ravichandran et al (2005), <papid> P05-1077 </papid>talbot and osborne (2007), <papid> P07-1065 </papid>goyal et al.</citsent>
<aftsection>
<nextsent>(2010), talbot and brants (2008),<papid> P08-1058 </papid>van durme and lall (2009a), levenberg and osborne (2009), <papid> D09-1079 </papid>goyal et al (2010), <papid> W10-2808 </papid>petrovic et al (2010), van durme andlall (2010), or goyal and daume?</nextsent>
<nextsent>(2011)), we propose the method of conditional random sampling (crs) by li and church (2007) <papid> J07-3003 </papid>as an efficient wayto store approximations of the statistics used to calculate pmi for applications in inducing rudimentary script-like structures.efficiently storing such structures is an important step in integrating document-level statistics into downstream tasks, such as characterizing complex scenarios (chambers and jurafsky, 2011), <papid> P11-1098 </papid>or story understanding (gordon et al, 2011).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1308">
<title id=" N12-1056.xml">space efficiencies in discourse modeling via conditional random sampling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>church and hanks (1990) <papid> J90-1003 </papid>suggested pointwise mutual information: pmi(wi, wj) = log pr(wi,wj)pr(wi) pr(wj) , showing linguistically appealing results using contexts defined by fixed width n-gram windows, and syntactic dependencies derived from automatically parsed corpora.</prevsent>
<prevsent>later work such asby lin (1999) <papid> P99-1041 </papid>continued this tradition.</prevsent>
</prevsection>
<citsent citstr=" P07-1065 ">
here we consider document, or discourse-level contexts, such as explored by rosenfeld (1994) or church (2000), <papid> C00-1027 </papid>andmore recently by those such as chambers and jurafsky (2008) <papid> P08-1090 </papid>or van durme and lall (2009b).in the spirit of recent work in randomized algorithms for large-scale hlt (such as by ravichandran et al (2005), <papid> P05-1077 </papid>talbot and osborne (2007), <papid> P07-1065 </papid>goyal et al.</citsent>
<aftsection>
<nextsent>(2010), talbot and brants (2008),<papid> P08-1058 </papid>van durme and lall (2009a), levenberg and osborne (2009), <papid> D09-1079 </papid>goyal et al (2010), <papid> W10-2808 </papid>petrovic et al (2010), van durme andlall (2010), or goyal and daume?</nextsent>
<nextsent>(2011)), we propose the method of conditional random sampling (crs) by li and church (2007) <papid> J07-3003 </papid>as an efficient wayto store approximations of the statistics used to calculate pmi for applications in inducing rudimentary script-like structures.efficiently storing such structures is an important step in integrating document-level statistics into downstream tasks, such as characterizing complex scenarios (chambers and jurafsky, 2011), <papid> P11-1098 </papid>or story understanding (gordon et al, 2011).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1309">
<title id=" N12-1056.xml">space efficiencies in discourse modeling via conditional random sampling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>later work such asby lin (1999) <papid> P99-1041 </papid>continued this tradition.</prevsent>
<prevsent>here we consider document, or discourse-level contexts, such as explored by rosenfeld (1994) or church (2000), <papid> C00-1027 </papid>andmore recently by those such as chambers and jurafsky (2008) <papid> P08-1090 </papid>or van durme and lall (2009b).in the spirit of recent work in randomized algorithms for large-scale hlt (such as by ravichandran et al (2005), <papid> P05-1077 </papid>talbot and osborne (2007), <papid> P07-1065 </papid>goyal et al.</prevsent>
</prevsection>
<citsent citstr=" P08-1058 ">
(2010), talbot and brants (2008),<papid> P08-1058 </papid>van durme and lall (2009a), levenberg and osborne (2009), <papid> D09-1079 </papid>goyal et al (2010), <papid> W10-2808 </papid>petrovic et al (2010), van durme andlall (2010), or goyal and daume?</citsent>
<aftsection>
<nextsent>(2011)), we propose the method of conditional random sampling (crs) by li and church (2007) <papid> J07-3003 </papid>as an efficient wayto store approximations of the statistics used to calculate pmi for applications in inducing rudimentary script-like structures.efficiently storing such structures is an important step in integrating document-level statistics into downstream tasks, such as characterizing complex scenarios (chambers and jurafsky, 2011), <papid> P11-1098 </papid>or story understanding (gordon et al, 2011).</nextsent>
<nextsent>conditional random sampling (crs) li and church (2007) <papid> J07-3003 </papid>proposed crs to approximate the contingency table between elements in query, to be used in distributional similarity measures such as cosine similarity, correlation, and pmi.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1310">
<title id=" N12-1056.xml">space efficiencies in discourse modeling via conditional random sampling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>later work such asby lin (1999) <papid> P99-1041 </papid>continued this tradition.</prevsent>
<prevsent>here we consider document, or discourse-level contexts, such as explored by rosenfeld (1994) or church (2000), <papid> C00-1027 </papid>andmore recently by those such as chambers and jurafsky (2008) <papid> P08-1090 </papid>or van durme and lall (2009b).in the spirit of recent work in randomized algorithms for large-scale hlt (such as by ravichandran et al (2005), <papid> P05-1077 </papid>talbot and osborne (2007), <papid> P07-1065 </papid>goyal et al.</prevsent>
</prevsection>
<citsent citstr=" D09-1079 ">
(2010), talbot and brants (2008),<papid> P08-1058 </papid>van durme and lall (2009a), levenberg and osborne (2009), <papid> D09-1079 </papid>goyal et al (2010), <papid> W10-2808 </papid>petrovic et al (2010), van durme andlall (2010), or goyal and daume?</citsent>
<aftsection>
<nextsent>(2011)), we propose the method of conditional random sampling (crs) by li and church (2007) <papid> J07-3003 </papid>as an efficient wayto store approximations of the statistics used to calculate pmi for applications in inducing rudimentary script-like structures.efficiently storing such structures is an important step in integrating document-level statistics into downstream tasks, such as characterizing complex scenarios (chambers and jurafsky, 2011), <papid> P11-1098 </papid>or story understanding (gordon et al, 2011).</nextsent>
<nextsent>conditional random sampling (crs) li and church (2007) <papid> J07-3003 </papid>proposed crs to approximate the contingency table between elements in query, to be used in distributional similarity measures such as cosine similarity, correlation, and pmi.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1311">
<title id=" N12-1056.xml">space efficiencies in discourse modeling via conditional random sampling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>later work such asby lin (1999) <papid> P99-1041 </papid>continued this tradition.</prevsent>
<prevsent>here we consider document, or discourse-level contexts, such as explored by rosenfeld (1994) or church (2000), <papid> C00-1027 </papid>andmore recently by those such as chambers and jurafsky (2008) <papid> P08-1090 </papid>or van durme and lall (2009b).in the spirit of recent work in randomized algorithms for large-scale hlt (such as by ravichandran et al (2005), <papid> P05-1077 </papid>talbot and osborne (2007), <papid> P07-1065 </papid>goyal et al.</prevsent>
</prevsection>
<citsent citstr=" W10-2808 ">
(2010), talbot and brants (2008),<papid> P08-1058 </papid>van durme and lall (2009a), levenberg and osborne (2009), <papid> D09-1079 </papid>goyal et al (2010), <papid> W10-2808 </papid>petrovic et al (2010), van durme andlall (2010), or goyal and daume?</citsent>
<aftsection>
<nextsent>(2011)), we propose the method of conditional random sampling (crs) by li and church (2007) <papid> J07-3003 </papid>as an efficient wayto store approximations of the statistics used to calculate pmi for applications in inducing rudimentary script-like structures.efficiently storing such structures is an important step in integrating document-level statistics into downstream tasks, such as characterizing complex scenarios (chambers and jurafsky, 2011), <papid> P11-1098 </papid>or story understanding (gordon et al, 2011).</nextsent>
<nextsent>conditional random sampling (crs) li and church (2007) <papid> J07-3003 </papid>proposed crs to approximate the contingency table between elements in query, to be used in distributional similarity measures such as cosine similarity, correlation, and pmi.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1312">
<title id=" N12-1056.xml">space efficiencies in discourse modeling via conditional random sampling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>here we consider document, or discourse-level contexts, such as explored by rosenfeld (1994) or church (2000), <papid> C00-1027 </papid>andmore recently by those such as chambers and jurafsky (2008) <papid> P08-1090 </papid>or van durme and lall (2009b).in the spirit of recent work in randomized algorithms for large-scale hlt (such as by ravichandran et al (2005), <papid> P05-1077 </papid>talbot and osborne (2007), <papid> P07-1065 </papid>goyal et al.</prevsent>
<prevsent>(2010), talbot and brants (2008),<papid> P08-1058 </papid>van durme and lall (2009a), levenberg and osborne (2009), <papid> D09-1079 </papid>goyal et al (2010), <papid> W10-2808 </papid>petrovic et al (2010), van durme andlall (2010), or goyal and daume?</prevsent>
</prevsection>
<citsent citstr=" J07-3003 ">
(2011)), we propose the method of conditional random sampling (crs) by li and church (2007) <papid> J07-3003 </papid>as an efficient wayto store approximations of the statistics used to calculate pmi for applications in inducing rudimentary script-like structures.efficiently storing such structures is an important step in integrating document-level statistics into downstream tasks, such as characterizing complex scenarios (chambers and jurafsky, 2011), <papid> P11-1098 </papid>or story understanding (gordon et al, 2011).</citsent>
<aftsection>
<nextsent>conditional random sampling (crs) li and church (2007) <papid> J07-3003 </papid>proposed crs to approximate the contingency table between elements in query, to be used in distributional similarity measures such as cosine similarity, correlation, and pmi.</nextsent>
<nextsent>central is the idea of the postings list, which is made up of the identifiers of each document that contains given word or phrase.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1315">
<title id=" N12-1056.xml">space efficiencies in discourse modeling via conditional random sampling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>here we consider document, or discourse-level contexts, such as explored by rosenfeld (1994) or church (2000), <papid> C00-1027 </papid>andmore recently by those such as chambers and jurafsky (2008) <papid> P08-1090 </papid>or van durme and lall (2009b).in the spirit of recent work in randomized algorithms for large-scale hlt (such as by ravichandran et al (2005), <papid> P05-1077 </papid>talbot and osborne (2007), <papid> P07-1065 </papid>goyal et al.</prevsent>
<prevsent>(2010), talbot and brants (2008),<papid> P08-1058 </papid>van durme and lall (2009a), levenberg and osborne (2009), <papid> D09-1079 </papid>goyal et al (2010), <papid> W10-2808 </papid>petrovic et al (2010), van durme andlall (2010), or goyal and daume?</prevsent>
</prevsection>
<citsent citstr=" P11-1098 ">
(2011)), we propose the method of conditional random sampling (crs) by li and church (2007) <papid> J07-3003 </papid>as an efficient wayto store approximations of the statistics used to calculate pmi for applications in inducing rudimentary script-like structures.efficiently storing such structures is an important step in integrating document-level statistics into downstream tasks, such as characterizing complex scenarios (chambers and jurafsky, 2011), <papid> P11-1098 </papid>or story understanding (gordon et al, 2011).</citsent>
<aftsection>
<nextsent>conditional random sampling (crs) li and church (2007) <papid> J07-3003 </papid>proposed crs to approximate the contingency table between elements in query, to be used in distributional similarity measures such as cosine similarity, correlation, and pmi.</nextsent>
<nextsent>central is the idea of the postings list, which is made up of the identifiers of each document that contains given word or phrase.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1322">
<title id=" N12-1056.xml">space efficiencies in discourse modeling via conditional random sampling </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>he recommended selecting small list of trigger pairs based on the highest average mutual information (often simply called mutual information), although intuitively pmi could also be used.
</prevsent>
<prevsent>computational constraints forced him to apply heavy pruning to the bigrams in his model.
</prevsent>
</prevsection>
<citsent citstr=" T75-2023 ">
scripts script, proposed by schank (1975), <papid> T75-2023 </papid>is aform of minsky-style frame that captures commonsense knowledge regarding typical events.</citsent>
<aftsection>
<nextsent>forex ample, if machine were to reason about eating at arestaurant, it should associate to this event: the ex1for example, assume some word wi that appears in documents d1, d4, d10 and d12.
</nextsent>
<nextsent>the identifiers are then randomly permuted via pi such that: d3 = d1, ? 2 = d4, ? 7 = d10 and d1 = d12.
</nextsent>
<nextsent>following permutation, the postings list for wi ismade up of identifiers that map to the same underlying documents as before, but now in different order.
</nextsent>
<nextsent>if we let = 3, then si = (1, 2, 3), corresponding to documents: (d12, d4, d1).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1325">
<title id=" N12-1056.xml">space efficiencies in discourse modeling via conditional random sampling </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>j=1 pmi(w,wj) by relying on the average pairwise pmi, they are making independence assumptions that are not always valid.
</prevsent>
<prevsent>in order to consider more nuanced joint effects between more than two terms, more efficient methods would need to be considered.
</prevsent>
</prevsection>
<citsent citstr=" W00-1427 ">
setup following chambers and jurafsky (2008), <papid> P08-1090 </papid>we extracted and lemmatized the verbs from thenew york times section of the gigaword corpus using the stanford pos tagger (toutanova et al, 2004) and the morpha lemmatizer (minnen et al, 2000).<papid> W00-1427 </papid></citsent>
<aftsection>
<nextsent>after filtering various pos tagger errors and setting minimum document frequency (df) of 50, we went from vocabulary of 94,803 words to 8,051.3 for various values of we built sketches over 1,655,193 documents, for each resulting word type.
</nextsent>
<nextsent>2given large collection of news articles, some on the topic of local crime, one might see story such as: ?... searched for micha eli ... hei was arrested ...
</nextsent>
<nextsent>mikei plead guilty ... convicted himi ...?, helping to support an induced chain: (search, arrest, plead, acquit, convict, sentence).3types containing punctuation other than hyphens and underscores were discarded as tagger-error.
</nextsent>
<nextsent>514 table 1: top-n by approximate pmi, for varying k. sub scripts denote rank under true pmi, when less than 50.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1328">
<title id=" N12-1056.xml">space efficiencies in discourse modeling via conditional random sampling </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>we have shown that the approximate pmi rank list produces results that are intuitive and consistent with the exact pmi even with significant memory savings.
</prevsent>
<prevsent>this enables us to approximate pmi for tuples longer than pairs without undue independence assumptions.
</prevsent>
</prevsection>
<citsent citstr=" D08-1039 ">
one future avenue is to explore the use of this structure in applications such as machine translation, as potentially enabling greater use of long distance dependencies than in prior work, such as by hasan et al (2008).<papid> D08-1039 </papid></citsent>
<aftsection>
<nextsent>we acknowledge support from the national science foundation pire grant no.
</nextsent>
<nextsent>oise-0530118.
</nextsent>
<nextsent>we acknowledge the army research laboratory for its support to the first author under scep (the student career experience program).
</nextsent>
<nextsent>any opinions, findings, conclusions, or recommendations expressed inthis material are those of the authors and do not necessarily reflect the views of the supporting agencies.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1329">
<title id=" P03-2005.xml">an adaptive approach to collecting multimodal input </title>
<section> the mmif module.  </section>
<citcontext>
<prevsection>
<prevsent>after inputs from two modalities have been received, the integration process is performed and there sult sent to the dm.
</prevsent>
<prevsent>a window of 3 seconds is used after receiving the first in put.
</prevsent>
</prevsection>
<citsent citstr=" W97-1401 ">
(oviatt et. al. 1997) <papid> W97-1401 </papid>3.</citsent>
<aftsection>
<nextsent>information evaluation - in this method in-.
</nextsent>
<nextsent>tegration is performed after receiving each input, and the result is evaluated to determine if the information can be transformed to command that the system can under stand.
</nextsent>
<nextsent>if transformation is possible, the work of mmif is deemed complete and the information is sent to the dm.
</nextsent>
<nextsent>in the case of an incomplete transformation, wind owing technique is used.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1340">
<title id=" N12-1092.xml">mind the gap learning to choose gaps for question generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>even in traditional educational settings, there is need for automated test generation, as teachers want multiple tests for topics to give to different students, and students want different tests with which to study and practice the material.
</prevsent>
<prevsent>one possible solution to providing quizzes for new source material is the automatic generation of questions.
</prevsent>
</prevsection>
<citsent citstr=" W10-4234 ">
this is task the nlp community has already embraced, and significant progress has been made in recent years with the introduction of shared task (rus et al, 2010).<papid> W10-4234 </papid></citsent>
<aftsection>
<nextsent>however, thus far the research community has focused on the problem of generating grammatical questions (as in heilman and smith (2010<papid> W10-0705 </papid>a)) or generating effective dis tractors for multiple-choice questions (agarwal and mannem, 2011).<papid> W11-1407 </papid></nextsent>
<nextsent>while both of these research threads are of critical importance, there is another key issue that must be addressed ? which questions should we be asking in the first place?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1341">
<title id=" N12-1092.xml">mind the gap learning to choose gaps for question generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one possible solution to providing quizzes for new source material is the automatic generation of questions.
</prevsent>
<prevsent>this is task the nlp community has already embraced, and significant progress has been made in recent years with the introduction of shared task (rus et al, 2010).<papid> W10-4234 </papid></prevsent>
</prevsection>
<citsent citstr=" W10-0705 ">
however, thus far the research community has focused on the problem of generating grammatical questions (as in heilman and smith (2010<papid> W10-0705 </papid>a)) or generating effective dis tractors for multiple-choice questions (agarwal and mannem, 2011).<papid> W11-1407 </papid></citsent>
<aftsection>
<nextsent>while both of these research threads are of critical importance, there is another key issue that must be addressed ? which questions should we be asking in the first place?
</nextsent>
<nextsent>we have highlighted this aspect of the problem in the past (see vanderwende (2008)) and begin to address it in this work, postulating that we can both collect human judgments on what makes good question and train machine learning model that can replicate these judgments.
</nextsent>
<nextsent>the resulting learned model can then be applied to new material for automated question generation.
</nextsent>
<nextsent>we see this effort as complementary to the earlier progress.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1347">
<title id=" N12-1092.xml">mind the gap learning to choose gaps for question generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one possible solution to providing quizzes for new source material is the automatic generation of questions.
</prevsent>
<prevsent>this is task the nlp community has already embraced, and significant progress has been made in recent years with the introduction of shared task (rus et al, 2010).<papid> W10-4234 </papid></prevsent>
</prevsection>
<citsent citstr=" W11-1407 ">
however, thus far the research community has focused on the problem of generating grammatical questions (as in heilman and smith (2010<papid> W10-0705 </papid>a)) or generating effective dis tractors for multiple-choice questions (agarwal and mannem, 2011).<papid> W11-1407 </papid></citsent>
<aftsection>
<nextsent>while both of these research threads are of critical importance, there is another key issue that must be addressed ? which questions should we be asking in the first place?
</nextsent>
<nextsent>we have highlighted this aspect of the problem in the past (see vanderwende (2008)) and begin to address it in this work, postulating that we can both collect human judgments on what makes good question and train machine learning model that can replicate these judgments.
</nextsent>
<nextsent>the resulting learned model can then be applied to new material for automated question generation.
</nextsent>
<nextsent>we see this effort as complementary to the earlier progress.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1348">
<title id=" N12-1092.xml">mind the gap learning to choose gaps for question generation </title>
<section> background and related work.  </section>
<citcontext>
<prevsection>
<prevsent>as the final model has only minimal dependence on wikipedia-specific features, we expect that it can be applied to an even wider variety of material (blogs, news articles, health sites, etc.).
</prevsent>
<prevsent>there already exists large body of work in automatic question generation (qg) for educational purposes dating back to the auto quest system (wolfe, 1976), which used an entirely syntactic approach to generate wh-questions from individual sentences.
</prevsent>
</prevsection>
<citsent citstr=" W03-0203 ">
in addition to auto quest, several others have created systems for wh-question generation using approaches including transformation rules (mitkov and ha, 2003), <papid> W03-0203 </papid>template based generation (chen et al, 2009; curto et al, 2011), <papid> W11-2705 </papid>and overgenerate-and-rank (heilman and smith, 2010<papid> W10-0705 </papid>a).</citsent>
<aftsection>
<nextsent>the work in this area has largely focused on the surface form of the questions, with an emphasis on grammaticality.
</nextsent>
<nextsent>alternatively, generation of gap-fill style questions (a.k.a. cloze questions) avoids these issues of grammaticality by blanking out words or spans in known good sentence.
</nextsent>
<nextsent>there is large body of existing work that has focused on generation of this type of question, most of which has focused on vocabulary and language learning.
</nextsent>
<nextsent>the recent work of agarwal and mannem (2011) <papid> W11-1407 </papid>is closer to our purposes; they generated fill-in-the-blank questions and dis tractor answers for reading comprehension tests using heuristic scoring measures and small evaluation set.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1349">
<title id=" N12-1092.xml">mind the gap learning to choose gaps for question generation </title>
<section> background and related work.  </section>
<citcontext>
<prevsection>
<prevsent>as the final model has only minimal dependence on wikipedia-specific features, we expect that it can be applied to an even wider variety of material (blogs, news articles, health sites, etc.).
</prevsent>
<prevsent>there already exists large body of work in automatic question generation (qg) for educational purposes dating back to the auto quest system (wolfe, 1976), which used an entirely syntactic approach to generate wh-questions from individual sentences.
</prevsent>
</prevsection>
<citsent citstr=" W11-2705 ">
in addition to auto quest, several others have created systems for wh-question generation using approaches including transformation rules (mitkov and ha, 2003), <papid> W03-0203 </papid>template based generation (chen et al, 2009; curto et al, 2011), <papid> W11-2705 </papid>and overgenerate-and-rank (heilman and smith, 2010<papid> W10-0705 </papid>a).</citsent>
<aftsection>
<nextsent>the work in this area has largely focused on the surface form of the questions, with an emphasis on grammaticality.
</nextsent>
<nextsent>alternatively, generation of gap-fill style questions (a.k.a. cloze questions) avoids these issues of grammaticality by blanking out words or spans in known good sentence.
</nextsent>
<nextsent>there is large body of existing work that has focused on generation of this type of question, most of which has focused on vocabulary and language learning.
</nextsent>
<nextsent>the recent work of agarwal and mannem (2011) <papid> W11-1407 </papid>is closer to our purposes; they generated fill-in-the-blank questions and dis tractor answers for reading comprehension tests using heuristic scoring measures and small evaluation set.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1354">
<title id=" N12-1092.xml">mind the gap learning to choose gaps for question generation </title>
<section> background and related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, evaluation in this task was manual and the number of instances in both the development and training set were small.
</prevsent>
<prevsent>as there exists no other dataset for question generation, we created new corpus using amazon mechanical turk by soliciting judgments from non-experts.
</prevsent>
</prevsection>
<citsent citstr=" D08-1027 ">
snow et al (2008) <papid> D08-1027 </papid>have validated amt as valid data source by comparing non expert with gold-standard expert judgments.</citsent>
<aftsection>
<nextsent>corpus creation using amt has numerous precedents now; see i.e. callison-burch and dredze (2010) and heilman and smith (2010<papid> W10-0705 </papid>b).</nextsent>
<nextsent>we have made our corpus (see section 4) available online to enable others to continue research on the gap-selection problem we address here.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1368">
<title id=" N12-1092.xml">mind the gap learning to choose gaps for question generation </title>
<section> corpus construction.  </section>
<citcontext>
<prevsection>
<prevsent>we then wished to eliminate judges who were gaming the system or otherwise performing poorly on the task.
</prevsent>
<prevsent>it is common to do such filtering when using crowd sourced data by using the majority or median vote as the final judgment or to calibrate judges using expert judgments (snow et al 2008).<papid> D08-1027 </papid></prevsent>
</prevsection>
<citsent citstr=" P99-1032 ">
other approaches to annotator quality control include using em-based algorithms for estimating annotator bias (wiebe et al 1999, <papid> P99-1032 </papid>ipeirotis et al 2010).</citsent>
<aftsection>
<nextsent>in our case, we computed the distance for each judge from the median judgment (from all judges) on each question, then took the mean of this distance over all questions they rated.
</nextsent>
<nextsent>we removed judges with mean distance two standard deviations above the mean distance, which eliminated the five judges who disagreed most with others.
</nextsent>
<nextsent>in addition to filtering judges, we wanted to further constrain the data to those questions on which the human annotators had reasonable agreement, as it would not make sense to attempt to train model to replicate judgments on which the annotators themselves could not agree.
</nextsent>
<nextsent>to do this, we computed the variance of the judgments for each question.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1369">
<title id=" N12-1092.xml">mind the gap learning to choose gaps for question generation </title>
<section> model features.  </section>
<citcontext>
<prevsection>
<prevsent>5.4 semantic role label features.
</prevsent>
<prevsent>beyond syntactic constraints, semantics can yield additional cues in identifying the important spans for questioning.
</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
shallow-semantic parses like those found in propbank (palmer et al, 2005) <papid> J05-1004 </papid>provide concise representation for linking predicates (verbs) to their arguments.</citsent>
<aftsection>
<nextsent>because these semantic role labels (srls) often correspond to the who, what, where, and when?
</nextsent>
<nextsent>of sentence, they naturally lend themselves for use as features for rating question quality.
</nextsent>
<nextsent>to compute srl features, we used the msr splats semantic role labeler to find the srls whose spans cover the questions answer, the srls whose spans are contained with in the answer, and the answers constituent parse depth within the closest covering srl node.
</nextsent>
<nextsent>to investigate whether judges keyed in on specific roles or modifiers when rating questions, we plotted the distribution of the answer-covering srls (figure 4).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1370">
<title id=" P04-1073.xml">question answering using constraint satisfaction qabydossierwithcontraints </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>logic and inferencing have been part of ques tion-answering since its earliest days.
</prevsent>
<prevsent>the first such systems employed natural-language interfaces to expert systems, e.g. shrdlu (winograd, 1972), or to databases e.g. lunar (woods, 1973) and lifer/ladder (hendrix et al 1977).
</prevsent>
</prevsection>
<citsent citstr=" J82-3002 ">
chat-80 (warren &amp; pereira, 1982) <papid> J82-3002 </papid>was dcg-based nl query system about world geography, entirely in prolog.</citsent>
<aftsection>
<nextsent>in these systems, the nl question is transformed into semantic form, which is then processed further; the overall architecture and system operation is very different from todays systems, however, primarily in that there is no text corpus to process.
</nextsent>
<nextsent>inferencing is used in at least two of the more visible systems of the present day.
</nextsent>
<nextsent>the lcc system (moldovan &amp; rus, 2001) <papid> P01-1052 </papid>uses logic prover to establish the connection between candidate answer passage and the question.</nextsent>
<nextsent>text terms are converted to logical forms, and the question is treated as goal which is proven?, with real-world knowledge being provided by extended wordnet.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1371">
<title id=" P04-1073.xml">question answering using constraint satisfaction qabydossierwithcontraints </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in these systems, the nl question is transformed into semantic form, which is then processed further; the overall architecture and system operation is very different from todays systems, however, primarily in that there is no text corpus to process.
</prevsent>
<prevsent>inferencing is used in at least two of the more visible systems of the present day.
</prevsent>
</prevsection>
<citsent citstr=" P01-1052 ">
the lcc system (moldovan &amp; rus, 2001) <papid> P01-1052 </papid>uses logic prover to establish the connection between candidate answer passage and the question.</citsent>
<aftsection>
<nextsent>text terms are converted to logical forms, and the question is treated as goal which is proven?, with real-world knowledge being provided by extended wordnet.
</nextsent>
<nextsent>the ibm system piquant (chu-carroll et al, 2003) uses cyc (le nat, 1995) in answer verification.
</nextsent>
<nextsent>cyc can in some cases confirm or reject candidate answers based on its own store of instance information; in other cases, primarily of numerical nature, cyc can confirm whether candidates are within reasonable range established for their subtype.
</nextsent>
<nextsent>at more abstract level, the use of constraints discussed in this paper can be viewed as simply an example of finding support (or lack of it) for candidate answers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1372">
<title id=" P03-2035.xml">deverbal compound noun analysis based on lexical conceptual structure </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the description should not remain just kind of categorization.
</prevsent>
<prevsent>rather, it should take into account the construction of the analysis model.
</prevsent>
</prevsection>
<citsent citstr=" P84-1109 ">
the previous work proposed semantic approaches based on semantic categories (levi, 1978; isabelle,1984; <papid> P84-1109 </papid>iida et al, 1984) had proposed detailed analysis of relations between constituents in compoundnouns.</citsent>
<aftsection>
<nextsent>some of approaches (fabre, 1996; <papid> C96-1062 </papid>johnston and busa, 1998) take the framework of generative lexicon (gl) (pustejovsky, 1995).</nextsent>
<nextsent>semantic approaches are especially well designed but they should still clarify the complete lexical factors needed for analysis model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1373">
<title id=" P03-2035.xml">deverbal compound noun analysis based on lexical conceptual structure </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>rather, it should take into account the construction of the analysis model.
</prevsent>
<prevsent>the previous work proposed semantic approaches based on semantic categories (levi, 1978; isabelle,1984; <papid> P84-1109 </papid>iida et al, 1984) had proposed detailed analysis of relations between constituents in compoundnouns.</prevsent>
</prevsection>
<citsent citstr=" C96-1062 ">
some of approaches (fabre, 1996; <papid> C96-1062 </papid>johnston and busa, 1998) take the framework of generative lexicon (gl) (pustejovsky, 1995).</citsent>
<aftsection>
<nextsent>semantic approaches are especially well designed but they should still clarify the complete lexical factors needed for analysis model.
</nextsent>
<nextsent>probabilistic approaches (lauer, 1995; lapata, 2002) <papid> J02-3004 </papid>have been proposed to disambiguate semantic relations between constituents in compounds.</nextsent>
<nextsent>their experimental results show high performance, butonly for shallow analysis of compounds using semantically tagged corpora.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1374">
<title id=" P03-2035.xml">deverbal compound noun analysis based on lexical conceptual structure </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>some of approaches (fabre, 1996; <papid> C96-1062 </papid>johnston and busa, 1998) take the framework of generative lexicon (gl) (pustejovsky, 1995).</prevsent>
<prevsent>semantic approaches are especially well designed but they should still clarify the complete lexical factors needed for analysis model.</prevsent>
</prevsection>
<citsent citstr=" J02-3004 ">
probabilistic approaches (lauer, 1995; lapata, 2002) <papid> J02-3004 </papid>have been proposed to disambiguate semantic relations between constituents in compounds.</citsent>
<aftsection>
<nextsent>their experimental results show high performance, butonly for shallow analysis of compounds using semantically tagged corpora.
</nextsent>
<nextsent>to be fully effective,they also need to incorporate factors that are effective in disambiguating semantic relations.
</nextsent>
<nextsent>it is therefore necessary to clarify what kinds of factors are related to the mechanisms that govern the relations in compounds.against this background, we have carried out research which aims at clarifying how lexical semantics contribute to, independently of languages, the relations in compound nouns.
</nextsent>
<nextsent>this paper proposes principled approach for the analysis of semantic relations between constituents in compound nouns based on the theoretical framework of lexical conceptual structure (lcs), and shows that the framework originally developed on the basis of japanese compound noun data works well for both japanese and english compound nouns.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1375">
<title id=" N12-1078.xml">expectations of word sense in parallel corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for instance, for the english word duty, the french translation droit was taken to signal its tax sense and devoir to signal its obligation sense.
</prevsent>
<prevsent>these french words were used as labels for different english senses.
</prevsent>
</prevsection>
<citsent citstr=" P11-2055 ">
similarly, in cross-lingual wsd setting,1 lefever et al (2011) <papid> P11-2055 </papid>treated each english-foreign alignment as so-called para sense, using it as proxy for human labeled training data.</citsent>
<aftsection>
<nextsent>under the synonymy assumption, diab and resnik (2002) <papid> P02-1033 </papid>did word sense tagging by grouping together all english words that are translated into the same french word and by further enforcing thatthe majority sense for these english words was projected as the sense for the french word.</nextsent>
<nextsent>bannard and callison-burch (2005) applied the idea that french phrases aligned to the same english phrase are paraphrases in system that induces paraphrases by pivoting through aligned foreign phrases.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1376">
<title id=" N12-1078.xml">expectations of word sense in parallel corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these french words were used as labels for different english senses.
</prevsent>
<prevsent>similarly, in cross-lingual wsd setting,1 lefever et al (2011) <papid> P11-2055 </papid>treated each english-foreign alignment as so-called para sense, using it as proxy for human labeled training data.</prevsent>
</prevsection>
<citsent citstr=" P02-1033 ">
under the synonymy assumption, diab and resnik (2002) <papid> P02-1033 </papid>did word sense tagging by grouping together all english words that are translated into the same french word and by further enforcing thatthe majority sense for these english words was projected as the sense for the french word.</citsent>
<aftsection>
<nextsent>bannard and callison-burch (2005) applied the idea that french phrases aligned to the same english phrase are paraphrases in system that induces paraphrases by pivoting through aligned foreign phrases.
</nextsent>
<nextsent>based on this, and other successful prior work, it seems neither of the assumptions must hold universally.
</nextsent>
<nextsent>therefore we investigate how often we might expect one or the other to dominate: we sample polysemous words from wide-domain{french,chinese}-english corpora, and use amazons mechanical turk (mturk) to annotate word sense on the english side.
</nextsent>
<nextsent>we calculate empirical probabilities based on counting over the competing polysemous and synonymous scenario labels.a key factor deciding the validity of our conclusion is the reliability of the annotations derived viamturk.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1377">
<title id=" N12-1078.xml">expectations of word sense in parallel corpora </title>
<section> turker reliability.  </section>
<citcontext>
<prevsection>
<prevsent>621 as reasonable process for acquiring large amounts of wsd labeled data, we go on to frame the experimental design, giving final results in sec.
</prevsent>
<prevsent>4.
</prevsent>
</prevsection>
<citsent citstr=" D08-1027 ">
while amazons mechanical turk (mturk) has been been considered in the past for constructing lexical semantic resources (e.g., (snow et al, 2008; <papid> D08-1027 </papid>akkaya et al, 2010; <papid> W10-0731 </papid>parent and eskenazi, 2010;<papid> W10-0703 </papid>rumshisky, 2011)), word sense annotation is sensitive to subjectivity and usually achieves low agreement rate even among experts.</citsent>
<aftsection>
<nextsent>thus we first askedturkers to re-annotate sample of existing gold standard data.
</nextsent>
<nextsent>with an eye towards costs saving, we also considered how many turkers would be needed per item to produce results of sufficient quality.
</nextsent>
<nextsent>turkers were presented sentences from the test portion of the word sense induction task of semeval-2007 (agirre and soroa, 2007), <papid> W07-2002 </papid>covering 2,559 instances of 35 nouns, expert-annotated with ontonotes (hovy et al, 2006) <papid> N06-2015 </papid>senses.</nextsent>
<nextsent>two versions of the task were designed: 1.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1378">
<title id=" N12-1078.xml">expectations of word sense in parallel corpora </title>
<section> turker reliability.  </section>
<citcontext>
<prevsection>
<prevsent>621 as reasonable process for acquiring large amounts of wsd labeled data, we go on to frame the experimental design, giving final results in sec.
</prevsent>
<prevsent>4.
</prevsent>
</prevsection>
<citsent citstr=" W10-0731 ">
while amazons mechanical turk (mturk) has been been considered in the past for constructing lexical semantic resources (e.g., (snow et al, 2008; <papid> D08-1027 </papid>akkaya et al, 2010; <papid> W10-0731 </papid>parent and eskenazi, 2010;<papid> W10-0703 </papid>rumshisky, 2011)), word sense annotation is sensitive to subjectivity and usually achieves low agreement rate even among experts.</citsent>
<aftsection>
<nextsent>thus we first askedturkers to re-annotate sample of existing gold standard data.
</nextsent>
<nextsent>with an eye towards costs saving, we also considered how many turkers would be needed per item to produce results of sufficient quality.
</nextsent>
<nextsent>turkers were presented sentences from the test portion of the word sense induction task of semeval-2007 (agirre and soroa, 2007), <papid> W07-2002 </papid>covering 2,559 instances of 35 nouns, expert-annotated with ontonotes (hovy et al, 2006) <papid> N06-2015 </papid>senses.</nextsent>
<nextsent>two versions of the task were designed: 1.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1379">
<title id=" N12-1078.xml">expectations of word sense in parallel corpora </title>
<section> turker reliability.  </section>
<citcontext>
<prevsection>
<prevsent>621 as reasonable process for acquiring large amounts of wsd labeled data, we go on to frame the experimental design, giving final results in sec.
</prevsent>
<prevsent>4.
</prevsent>
</prevsection>
<citsent citstr=" W10-0703 ">
while amazons mechanical turk (mturk) has been been considered in the past for constructing lexical semantic resources (e.g., (snow et al, 2008; <papid> D08-1027 </papid>akkaya et al, 2010; <papid> W10-0731 </papid>parent and eskenazi, 2010;<papid> W10-0703 </papid>rumshisky, 2011)), word sense annotation is sensitive to subjectivity and usually achieves low agreement rate even among experts.</citsent>
<aftsection>
<nextsent>thus we first askedturkers to re-annotate sample of existing gold standard data.
</nextsent>
<nextsent>with an eye towards costs saving, we also considered how many turkers would be needed per item to produce results of sufficient quality.
</nextsent>
<nextsent>turkers were presented sentences from the test portion of the word sense induction task of semeval-2007 (agirre and soroa, 2007), <papid> W07-2002 </papid>covering 2,559 instances of 35 nouns, expert-annotated with ontonotes (hovy et al, 2006) <papid> N06-2015 </papid>senses.</nextsent>
<nextsent>two versions of the task were designed: 1.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1380">
<title id=" N12-1078.xml">expectations of word sense in parallel corpora </title>
<section> turker reliability.  </section>
<citcontext>
<prevsection>
<prevsent>thus we first askedturkers to re-annotate sample of existing gold standard data.
</prevsent>
<prevsent>with an eye towards costs saving, we also considered how many turkers would be needed per item to produce results of sufficient quality.
</prevsent>
</prevsection>
<citsent citstr=" W07-2002 ">
turkers were presented sentences from the test portion of the word sense induction task of semeval-2007 (agirre and soroa, 2007), <papid> W07-2002 </papid>covering 2,559 instances of 35 nouns, expert-annotated with ontonotes (hovy et al, 2006) <papid> N06-2015 </papid>senses.</citsent>
<aftsection>
<nextsent>two versions of the task were designed: 1.
</nextsent>
<nextsent>compare: given the same word in different sentences, tell whether their meaning is the same, almost the same, unlikely the same or different, where the results were collapsed post-hoc into binary same/different categorization; 2.
</nextsent>
<nextsent>sense map: map the meaning of given word in sentential context to its proper ontonotes definition.
</nextsent>
<nextsent>for both tasks, 2, 599 examples were presented.we measure inter-coder agreement using krip pendorffs alpha (krippendorff, 2004; artstein and poesio, 2008), <papid> J08-4004 </papid>where ? ?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1381">
<title id=" N12-1078.xml">expectations of word sense in parallel corpora </title>
<section> turker reliability.  </section>
<citcontext>
<prevsection>
<prevsent>thus we first askedturkers to re-annotate sample of existing gold standard data.
</prevsent>
<prevsent>with an eye towards costs saving, we also considered how many turkers would be needed per item to produce results of sufficient quality.
</prevsent>
</prevsection>
<citsent citstr=" N06-2015 ">
turkers were presented sentences from the test portion of the word sense induction task of semeval-2007 (agirre and soroa, 2007), <papid> W07-2002 </papid>covering 2,559 instances of 35 nouns, expert-annotated with ontonotes (hovy et al, 2006) <papid> N06-2015 </papid>senses.</citsent>
<aftsection>
<nextsent>two versions of the task were designed: 1.
</nextsent>
<nextsent>compare: given the same word in different sentences, tell whether their meaning is the same, almost the same, unlikely the same or different, where the results were collapsed post-hoc into binary same/different categorization; 2.
</nextsent>
<nextsent>sense map: map the meaning of given word in sentential context to its proper ontonotes definition.
</nextsent>
<nextsent>for both tasks, 2, 599 examples were presented.we measure inter-coder agreement using krip pendorffs alpha (krippendorff, 2004; artstein and poesio, 2008), <papid> J08-4004 </papid>where ? ?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1382">
<title id=" N12-1078.xml">expectations of word sense in parallel corpora </title>
<section> turker reliability.  </section>
<citcontext>
<prevsection>
<prevsent>compare: given the same word in different sentences, tell whether their meaning is the same, almost the same, unlikely the same or different, where the results were collapsed post-hoc into binary same/different categorization; 2.
</prevsent>
<prevsent>sense map: map the meaning of given word in sentential context to its proper ontonotes definition.
</prevsent>
</prevsection>
<citsent citstr=" J08-4004 ">
for both tasks, 2, 599 examples were presented.we measure inter-coder agreement using krip pendorffs alpha (krippendorff, 2004; artstein and poesio, 2008), <papid> J08-4004 </papid>where ? ?</citsent>
<aftsection>
<nextsent>0.8 is considered to be reliable and 0.667 ? ?
</nextsent>
<nextsent>  0.8 allows for tentative conclusions.
</nextsent>
<nextsent>two points emerge from table 1: there were greater agreement rates for sense map than compare, and 3 turkers were sufficient.
</nextsent>
<nextsent>data selection we used two parallel corpora: the french-english 109 corpus (callison-burch et al, 2009) and the gale chinese-english corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1383">
<title id=" N12-1078.xml">expectations of word sense in parallel corpora </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>alpha measures how turkers agreed with themselves.
</prevsent>
<prevsent>identical meaning is estimated here to be roughly 59-67% (59.2% (french), 66.7% (chinese)).
</prevsent>
</prevsection>
<citsent citstr=" E09-1013 ">
this accords with results from wsd evaluations, where the first-sense heuristic is roughly 75-80% accurate (e.g., 80.9% in semeval07 (brody and lapata, 2009)).<papid> E09-1013 </papid></citsent>
<aftsection>
<nextsent>minor algebra translates this into an expected p3 value in range from 56%62.5%, up to 64%?
</nextsent>
<nextsent>68%, which captures our estimates.5 finally for our motivating scenario: values for p1are barely higher than 50%, suggesting that syn onymy more regularly holds, but not conclusively.
</nextsent>
<nextsent>we expect in narrower domains, where words have less number of senses, this is more noticeable.
</nextsent>
<nextsent>as suggested by fig.s 1 and 2, less polysemous words tend to have higher values.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1384">
<title id=" P01-1070.xml">using machine learning techniques to interpret whquestions </title>
<section> related research.  </section>
<citcontext>
<prevsection>
<prevsent>one approach to the qa task consists of applying their methods to retrieve documents relevant to users question, and then using the shallow nlp to extract features from both the users question and the most promising retrieved documents.
</prevsent>
<prevsent>these features are then used to identify an answer within each document which best matches the users question.
</prevsent>
</prevsection>
<citsent citstr=" A00-1041 ">
this approach was adopted in (kupiec, 1993; abney et al , 2000; <papid> A00-1041 </papid>cardie et al , 2000; <papid> A00-1025 </papid>moldovan et al , 2000).<papid> P00-1071 </papid>the nlp components of these systems employed hand-crafted rules to infer the type of answer expected.</citsent>
<aftsection>
<nextsent>these rules were built by considering the first word of question as well as larger patterns of words identified in the question.
</nextsent>
<nextsent>for example, the question how far is mars??
</nextsent>
<nextsent>might be characterized as requiring reply of type distance.
</nextsent>
<nextsent>our work differs from traditional qaresearch in its use of statistical models to predict variables that represent users informational goals.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1385">
<title id=" P01-1070.xml">using machine learning techniques to interpret whquestions </title>
<section> related research.  </section>
<citcontext>
<prevsection>
<prevsent>one approach to the qa task consists of applying their methods to retrieve documents relevant to users question, and then using the shallow nlp to extract features from both the users question and the most promising retrieved documents.
</prevsent>
<prevsent>these features are then used to identify an answer within each document which best matches the users question.
</prevsent>
</prevsection>
<citsent citstr=" A00-1025 ">
this approach was adopted in (kupiec, 1993; abney et al , 2000; <papid> A00-1041 </papid>cardie et al , 2000; <papid> A00-1025 </papid>moldovan et al , 2000).<papid> P00-1071 </papid>the nlp components of these systems employed hand-crafted rules to infer the type of answer expected.</citsent>
<aftsection>
<nextsent>these rules were built by considering the first word of question as well as larger patterns of words identified in the question.
</nextsent>
<nextsent>for example, the question how far is mars??
</nextsent>
<nextsent>might be characterized as requiring reply of type distance.
</nextsent>
<nextsent>our work differs from traditional qaresearch in its use of statistical models to predict variables that represent users informational goals.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1386">
<title id=" P01-1070.xml">using machine learning techniques to interpret whquestions </title>
<section> related research.  </section>
<citcontext>
<prevsection>
<prevsent>one approach to the qa task consists of applying their methods to retrieve documents relevant to users question, and then using the shallow nlp to extract features from both the users question and the most promising retrieved documents.
</prevsent>
<prevsent>these features are then used to identify an answer within each document which best matches the users question.
</prevsent>
</prevsection>
<citsent citstr=" P00-1071 ">
this approach was adopted in (kupiec, 1993; abney et al , 2000; <papid> A00-1041 </papid>cardie et al , 2000; <papid> A00-1025 </papid>moldovan et al , 2000).<papid> P00-1071 </papid>the nlp components of these systems employed hand-crafted rules to infer the type of answer expected.</citsent>
<aftsection>
<nextsent>these rules were built by considering the first word of question as well as larger patterns of words identified in the question.
</nextsent>
<nextsent>for example, the question how far is mars??
</nextsent>
<nextsent>might be characterized as requiring reply of type distance.
</nextsent>
<nextsent>our work differs from traditional qaresearch in its use of statistical models to predict variables that represent users informational goals.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1387">
<title id=" P04-1065.xml">fsa an efficient and flexible c toolkit for finite state automata using on demand computation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>future extensibilityof the toolkit is ensured as it will be publically available as open source software.
</prevsent>
<prevsent>finite-state automata (fsa) methods proved to elegantly solve many difficult problems in the field of natural language processing.
</prevsent>
</prevsection>
<citsent citstr=" W00-0508 ">
among the most recent ones are full and lazy compilation of the search network for speech recognition (mohri et al., 2000a), integrated speech translation (vidal,1997; bangalore and riccardi, 2000), <papid> W00-0508 </papid>speech summarization (hori et al, 2003), language modelling (allauzen et al, 2003) <papid> P03-1006 </papid>and parameter estimation through em (eisner, 2001) to mention only few.</citsent>
<aftsection>
<nextsent>from this list of different applications it is clear that there is high demand for generic tools to create and manipulate fsas.in the past, number of tool kits have been published, all with different design principles.
</nextsent>
<nextsent>here, we give short overview of tool kits that offer an almost complete set of algorithms: ? the fsm librarytm from at&t; (mohri etal., 2000b) is judged the most efficient implementation, offers various semi rings, on demand computation and many algorithms, butis available only in binary form with proprietary, noncommercial license.?
</nextsent>
<nextsent>fsa6.1 from (van noord, 2000) is implemented in prolog.
</nextsent>
<nextsent>it is licensed under the terms of the (gpl, 1991).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1388">
<title id=" P04-1065.xml">fsa an efficient and flexible c toolkit for finite state automata using on demand computation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>future extensibilityof the toolkit is ensured as it will be publically available as open source software.
</prevsent>
<prevsent>finite-state automata (fsa) methods proved to elegantly solve many difficult problems in the field of natural language processing.
</prevsent>
</prevsection>
<citsent citstr=" P03-1006 ">
among the most recent ones are full and lazy compilation of the search network for speech recognition (mohri et al., 2000a), integrated speech translation (vidal,1997; bangalore and riccardi, 2000), <papid> W00-0508 </papid>speech summarization (hori et al, 2003), language modelling (allauzen et al, 2003) <papid> P03-1006 </papid>and parameter estimation through em (eisner, 2001) to mention only few.</citsent>
<aftsection>
<nextsent>from this list of different applications it is clear that there is high demand for generic tools to create and manipulate fsas.in the past, number of tool kits have been published, all with different design principles.
</nextsent>
<nextsent>here, we give short overview of tool kits that offer an almost complete set of algorithms: ? the fsm librarytm from at&t; (mohri etal., 2000b) is judged the most efficient implementation, offers various semi rings, on demand computation and many algorithms, butis available only in binary form with proprietary, noncommercial license.?
</nextsent>
<nextsent>fsa6.1 from (van noord, 2000) is implemented in prolog.
</nextsent>
<nextsent>it is licensed under the terms of the (gpl, 1991).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1389">
<title id=" P04-1065.xml">fsa an efficient and flexible c toolkit for finite state automata using on demand computation </title>
<section> finite-state automata.  </section>
<citcontext>
<prevsection>
<prevsent>we conclude the paper with short summary in section 5and discuss some possible future extensions in section 6.
</prevsent>
<prevsent>2.1 weighted finite-state transducer.
</prevsent>
</prevsection>
<citsent citstr=" J97-2003 ">
the basic theory of weighted finite-state automata has been reviewed in numerous papers (mohri, 1997; <papid> J97-2003 </papid>allauzen et al, 2003).<papid> P03-1006 </papid></citsent>
<aftsection>
<nextsent>we will introduce the notation briefly.
</nextsent>
<nextsent>a semi ring (k,?,?, 0, 1) is structure with set and two binary operations ? and ? such that (k,?, 0) is commutative monoid, (k,?, 1) is monoid and ? distributes over ? and 0 ? = ? 0 = 0 for any ? k. we will also associate the term weights with the elements of semiring.
</nextsent>
<nextsent>semi rings that are frequently usedin speech recognition are the positive real semir ing (ir?{??,+?},log,+,+?, 0) with alog = log(ea + eb) and the tropical semi ring (ir?{??,+?},min,+,+?, 0) representing thewell-known sum and maximum weighted path criteria.
</nextsent>
<nextsent>a weighted finite-state transducer (q,?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1400">
<title id=" P04-1065.xml">fsa an efficient and flexible c toolkit for finite state automata using on demand computation </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>for technical reasons, ?-labels are represented by $ symbol.
</prevsent>
<prevsent>note, that due to the fixed segmentation given by the alignments, phrases in the target language are moved to the last source word of an alignment block.
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
so, given an appropriate alignment which can be obtained by means of the pubic ally available giza++ toolkit (och and ney, 2000), <papid> P00-1056 </papid>the approach is very easy in practice: 1.</citsent>
<aftsection>
<nextsent>transform the training corpus with given.
</nextsent>
<nextsent>alignment into the corresponding bilingual corpus 2.
</nextsent>
<nextsent>train language model on the bilingual corpus.
</nextsent>
<nextsent>3.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1402">
<title id=" P01-1066.xml">quantitative and qualitative evaluation of darpa communicator spoken dialogue systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a logfile standard was developed by mitre along with set of tools for processing the log files (aberdeen, 2000); the standard and tools were used by all sites to collect set of core metrics for making cross system comparisons.
</prevsent>
<prevsent>the core metrics were developed during workshop of the evaluation committee and included all metrics that anyone in the committee suggested, that could be implemented consistently across systems.
</prevsent>
</prevsection>
<citsent citstr=" H92-1006 ">
nists contribution was to recruit the human subjects and to implement the experimental design specified by the evaluation committee.the experiment was designed to make it possible to apply the paradise evaluation framework (walker et al, 2000), which integrates and unifies previous approaches to evaluation (price et al, 1992; <papid> H92-1006 </papid>hirschman, 2000).</citsent>
<aftsection>
<nextsent>the framework posits that user satisfaction is the overall objective to be maximized and that task success and various interaction costs can be used as predictors of user satisfaction.
</nextsent>
<nextsent>our results from applying paradise include that user satisfaction differed considerably across the nine systems.
</nextsent>
<nextsent>subsequent modeling of user satisfaction gave us some insight into why each system was more or less satisfactory; four variables accounted for 37% of the variance in user-satisfaction: task completion, task duration, recognition accuracy, and mean system turn duration.
</nextsent>
<nextsent>however, when doing our analysis we were struck by the extent to which different aspects of the systems?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1403">
<title id=" P01-1066.xml">quantitative and qualitative evaluation of darpa communicator spoken dialogue systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>dialogue behavior werent captured by the core metrics.
</prevsent>
<prevsent>for example, the core metrics logged the number and duration of system turns, but didnt distinguish between turns usedto request or present information, to give instructions, or to indicate errors.
</prevsent>
</prevsection>
<citsent citstr=" P95-1016 ">
recent research on dialogue has been based on the assumption that dialogue acts provide useful way of characterizing dialogue behaviors (reithinger and maier, 1995; <papid> P95-1016 </papid>isard and carletta, 1995; shriberg et al, 2000; di eugenio et al, 1998).<papid> P98-1052 </papid></citsent>
<aftsection>
<nextsent>several research efforts have explored the use of dialogue act tagging schemes for tasks such as improving recognition performance (reithinger and maier, 1995; <papid> P95-1016 </papid>shriberg et al, 2000), identifying important partsof dialogue (finke et al, 1998), and as constraint on nominal expression generation (jordan,2000).</nextsent>
<nextsent>thus we decided to explore the application of dialogue act tagging scheme to the task of evaluating and comparing dialogue systems.section 2 describes the corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1405">
<title id=" P01-1066.xml">quantitative and qualitative evaluation of darpa communicator spoken dialogue systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>dialogue behavior werent captured by the core metrics.
</prevsent>
<prevsent>for example, the core metrics logged the number and duration of system turns, but didnt distinguish between turns usedto request or present information, to give instructions, or to indicate errors.
</prevsent>
</prevsection>
<citsent citstr=" P98-1052 ">
recent research on dialogue has been based on the assumption that dialogue acts provide useful way of characterizing dialogue behaviors (reithinger and maier, 1995; <papid> P95-1016 </papid>isard and carletta, 1995; shriberg et al, 2000; di eugenio et al, 1998).<papid> P98-1052 </papid></citsent>
<aftsection>
<nextsent>several research efforts have explored the use of dialogue act tagging schemes for tasks such as improving recognition performance (reithinger and maier, 1995; <papid> P95-1016 </papid>shriberg et al, 2000), identifying important partsof dialogue (finke et al, 1998), and as constraint on nominal expression generation (jordan,2000).</nextsent>
<nextsent>thus we decided to explore the application of dialogue act tagging scheme to the task of evaluating and comparing dialogue systems.section 2 describes the corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1408">
<title id=" P01-1066.xml">quantitative and qualitative evaluation of darpa communicator spoken dialogue systems </title>
<section> dialogue act tagging for evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>figure 1 showsa communicator dialogue with each system utterance classified on these three dimensions.
</prevsent>
<prevsent>the tagset for each dimension are briefly described in the remainder of this section.
</prevsent>
</prevsection>
<citsent citstr=" H01-1015 ">
see (walker and passonneau, 2001) <papid> H01-1015 </papid>for more detail.</citsent>
<aftsection>
<nextsent>3.1 speech acts.
</nextsent>
<nextsent>in date, the speech-act dimension has ten categories.
</nextsent>
<nextsent>we use familiar speech-act labels, suchas offer, request-info, present-info, acknowledge, and introduce new ones designed to help us capture generalizations about communicative behavior in this domain, on this task, given the range of system and human behavior we see in the data.
</nextsent>
<nextsent>one new one, for example, is status-report.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1410">
<title id=" P01-1066.xml">quantitative and qualitative evaluation of darpa communicator spoken dialogue systems </title>
<section> dialogue act tagging for evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>each speech act can occur in any of three domains of discourse described below.
</prevsent>
<prevsent>the about-task domain is necessary for evaluating dialogue systems ability to collaborate with speaker on achieving the task goal of making reservations for specific trip.
</prevsent>
</prevsection>
<citsent citstr=" C92-1054 ">
it supports metrics such as the amount of time/effort the system takes to complete particular phase of making an airline reservation, and any ancillary ho tel/car reservations.the about-communication domain reflects the system goal of managing the verbal channel and providing evidence of what has been understood (walker, 1992; <papid> C92-1054 </papid>clark and schaefer, 1989).</citsent>
<aftsection>
<nextsent>utterances of this type are frequent inhuman-computer dialogue, where they are motivated by the need to avoid potentially costly errors arising from imperfect speech recognition.
</nextsent>
<nextsent>all implicit and explicit confirmations are about communication; see figure 1 for examples.
</nextsent>
<nextsent>the situation-frame domain pertains to the goal of managing the culturally relevant framing expectations (goffman, 1974).
</nextsent>
<nextsent>the utterances inthis domain are particularly relevant in human computer dialogues because the users?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1414">
<title id=" P03-1003.xml">a noisy channel approach to question answering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>from this perspective then, the fundamental problem of question answering is that of finding spaces where the distance between questions and sentences that contain correct answers is small and where the distance between questions and sentences that contain incorrect answers is large.
</prevsent>
<prevsent>in this paper, we propose new space and new metric for computing this distance.
</prevsent>
</prevsection>
<citsent citstr=" A88-1019 ">
being inspired by the success of noisy-channel-based approaches in applications as diverse as speech recognition (jelinek, 1997), part of speech tagging (church, 1988), <papid> A88-1019 </papid>machine translation (brown et al, 1993), <papid> J93-2003 </papid>information retrieval (berger and lafferty, 1999), and text summarization (knight and marcu, 2002), we develop noisy channel model for qa.</citsent>
<aftsection>
<nextsent>this model explains how given sentence sa that contains an answer sub-string to question can be rewritten into through sequence of stochastic operations.
</nextsent>
<nextsent>given corpus of question answer pairs (q, sa), we can train probabilistic model for estimating the conditional probability p(q | sa).
</nextsent>
<nextsent>once the parameters of this model are learned, given question and the set of sentences ? returned by an ir engine, one can find the sentence si ? ?
</nextsent>
<nextsent>and an answer in it ai,j by searching for the si,ai,j that maximizes the conditional probability p(q | si,ai,j).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1415">
<title id=" P03-1003.xml">a noisy channel approach to question answering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>from this perspective then, the fundamental problem of question answering is that of finding spaces where the distance between questions and sentences that contain correct answers is small and where the distance between questions and sentences that contain incorrect answers is large.
</prevsent>
<prevsent>in this paper, we propose new space and new metric for computing this distance.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
being inspired by the success of noisy-channel-based approaches in applications as diverse as speech recognition (jelinek, 1997), part of speech tagging (church, 1988), <papid> A88-1019 </papid>machine translation (brown et al, 1993), <papid> J93-2003 </papid>information retrieval (berger and lafferty, 1999), and text summarization (knight and marcu, 2002), we develop noisy channel model for qa.</citsent>
<aftsection>
<nextsent>this model explains how given sentence sa that contains an answer sub-string to question can be rewritten into through sequence of stochastic operations.
</nextsent>
<nextsent>given corpus of question answer pairs (q, sa), we can train probabilistic model for estimating the conditional probability p(q | sa).
</nextsent>
<nextsent>once the parameters of this model are learned, given question and the set of sentences ? returned by an ir engine, one can find the sentence si ? ?
</nextsent>
<nextsent>and an answer in it ai,j by searching for the si,ai,j that maximizes the conditional probability p(q | si,ai,j).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1421">
<title id=" P03-2030.xml">the framenet data and software </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a new, more portable version of the framenet software is also being made available to researchers else where, including the spanish framenet project.this demo and poster will briefly explain the principles of frame semantics and demonstrate the new unified tools for lexicon building and annotation and alsoframesql, search tool for finding patterns in annotated sentences.
</prevsent>
<prevsent>we will discuss the content and format of the data releases and how the software and data can be used by other nlp researchers.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
framenet1 (fontenelle, 2003; fillmore, 2002; baker et al, 1998) <papid> P98-1013 </papid>is lexicographic research project which aims to produce lexicon containing very detailed information about the relation be 1http://framenet.icsi.berkeley.edu/ framenet tween the semantics and the syntax of predicators,including verbs, nouns and adjectives, for substantial subset of english.</citsent>
<aftsection>
<nextsent>the basic unit of analysis is the semantic frame,defined as type of event or state and the participants and props?
</nextsent>
<nextsent>associated with it, which we call frame elements (fes).2 frames range from highly abstract to quite specific.
</nextsent>
<nextsent>an example of an abstract frame would be the replacement frame, with fessuch as old and new as in the sentence pat replaced [old the curtains] [new with wooden blinds].
</nextsent>
<nextsent>one sense of the verb replace is associated with the replacement frame, thus constituting one lexical unit (lu), the basic unit of the framenet lexicon.an example of more specific frame is apply heat, with fes such as cook, food, medium, and duration.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1422">
<title id=" P03-2030.xml">the framenet data and software </title>
<section> applications and related projects.  </section>
<citcontext>
<prevsection>
<prevsent>a full representation of the meaning of sentence can be built up by composing the semantics of the frames evoked by the major predicators.
</prevsent>
<prevsent>in addition to the original lexicographic goal, preliminary version of our frame descriptions and the set of more than 100,000 annotated sentences have been released to more than 80 research groups in more than 15 countries.
</prevsent>
</prevsection>
<citsent citstr=" N03-2022 ">
the fn data is being used for variety of purposes, some of which we had foreseen and others which we had not; these include uses as teaching materials for lexical semantics classes, as basis for developing multi-lingual lexica, as an interlingua for machine translation, andas training data for nlp systems that perform question answering, information retrieval (mohit and narayanan, 2003), <papid> N03-2022 </papid>and automatic semantic parsing (gildea and jurafsky, 2002).<papid> J02-3001 </papid></citsent>
<aftsection>
<nextsent>a number of scholars have expressed interest in building frame nets for other languages.
</nextsent>
<nextsent>of these, three have already begun work: in spain, team from several universities, led by prof. carlos subi rats of a barcelona, is building using their own extraction software and the framenet desktop tools to build spanish framenet (subirats and petruck, forthcoming 2003) http://www.gemini.es/sfn.
</nextsent>
<nextsent>in saarbrucken, germany, work is proceeding on hand annotating parsed corpus with framenet fe labels (erk et al, ).
</nextsent>
<nextsent>and in japan, researchers from keio university and university of tokyo are building japanese framenet in the domains of motion and communication, using large newspaper corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1423">
<title id=" P03-2030.xml">the framenet data and software </title>
<section> applications and related projects.  </section>
<citcontext>
<prevsection>
<prevsent>a full representation of the meaning of sentence can be built up by composing the semantics of the frames evoked by the major predicators.
</prevsent>
<prevsent>in addition to the original lexicographic goal, preliminary version of our frame descriptions and the set of more than 100,000 annotated sentences have been released to more than 80 research groups in more than 15 countries.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
the fn data is being used for variety of purposes, some of which we had foreseen and others which we had not; these include uses as teaching materials for lexical semantics classes, as basis for developing multi-lingual lexica, as an interlingua for machine translation, andas training data for nlp systems that perform question answering, information retrieval (mohit and narayanan, 2003), <papid> N03-2022 </papid>and automatic semantic parsing (gildea and jurafsky, 2002).<papid> J02-3001 </papid></citsent>
<aftsection>
<nextsent>a number of scholars have expressed interest in building frame nets for other languages.
</nextsent>
<nextsent>of these, three have already begun work: in spain, team from several universities, led by prof. carlos subi rats of a barcelona, is building using their own extraction software and the framenet desktop tools to build spanish framenet (subirats and petruck, forthcoming 2003) http://www.gemini.es/sfn.
</nextsent>
<nextsent>in saarbrucken, germany, work is proceeding on hand annotating parsed corpus with framenet fe labels (erk et al, ).
</nextsent>
<nextsent>and in japan, researchers from keio university and university of tokyo are building japanese framenet in the domains of motion and communication, using large newspaper corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1424">
<title id=" P03-2040.xml">total recall a bilingual concordance for computer assisted translation and language learning </title>
<section> aligning the corpus.  </section>
<citcontext>
<prevsection>
<prevsent>after parsing each article from files and put them into the database, we need to segment articles into sentences and align them into pairs of mutual translation.
</prevsent>
<prevsent>while the length-based approach (church and gale 1991) to sentence alignment produces surprisingly good results for the close language pair of french and english at success rates well over 96%, it does not fair as well for distant language pairs such as english and chinese.
</prevsent>
</prevsection>
<citsent citstr=" P94-1012 ">
work on sentence alignment of english and chinese texts (wu 1994), <papid> P94-1012 </papid>indicates that the lengths of english and chinese texts are not as highly correlated as in french-english task, leading to lower success rate (85-94%) for length-based aligners.</citsent>
<aftsection>
<nextsent>table 1 the result of chinese collocation candidates extracted.
</nextsent>
<nextsent>the shaded collocation pairs are selected based on competition of whole phrase log likelihood ratio and word-based translation probability.
</nextsent>
<nextsent>un-shaded items 7 and 8 are not selected because of conflict with previously chosen bilingual collocations, items 2 and 3.
</nextsent>
<nextsent>simard, foster, and isabelle (1992) pointed out cognates in two close languages such as english and french can be used to measure the likelihood of mutual translation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1425">
<title id=" P03-1034.xml">integrating discourse markers into a pipe lined natural language generation architecture </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>historically, work on nlg architecture has focused on integrating major disparate architectural modules such as discourse and sentence planners and surface realizers.
</prevsent>
<prevsent>more recently, as it was discovered that these components by themselves did not create highly readable prose, new types of architectural modules were introduced to deal with newly desired linguistic phenomena such as referring expressions, lexical choice, revision, and pronominalization.
</prevsent>
</prevsection>
<citsent citstr=" J97-2001 ">
adding each new module typically entailed that an nlg system designer would justify not only the reason for including the new module (i.e., what linguistic phenomena it produced that had been previously unattainable) but how it was integrated into their architecture and why its placement was reasonably optimal (cf., (elhadad et al, 1997), <papid> J97-2001 </papid>pp.</citsent>
<aftsection>
<nextsent>47).at the same time, (reiter, 1994) <papid> W94-0319 </papid>argued that implemented nlg systems were converging toward de facto pipe lined architecture (figure 1) with minimal-to-nonexistent feedback between modules.although several nlg architectures were proposed in opposition to such linear arrangement(kantrowitz and bates, 1992; cline, 1994), these research projects have not continued while pipe lined architectures are still actively being pursued.in addition, reiter concludes that although complete integration of architectural components is theoretically good idea, in practical engineering terms such system would be too inefficient to operate and too complex to actually implement.</nextsent>
<nextsent>significantly, reiter states that fully interconnecting every module would entail constructing n(n   1) interfaces between them.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1426">
<title id=" P03-1034.xml">integrating discourse markers into a pipe lined natural language generation architecture </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>more recently, as it was discovered that these components by themselves did not create highly readable prose, new types of architectural modules were introduced to deal with newly desired linguistic phenomena such as referring expressions, lexical choice, revision, and pronominalization.
</prevsent>
<prevsent>adding each new module typically entailed that an nlg system designer would justify not only the reason for including the new module (i.e., what linguistic phenomena it produced that had been previously unattainable) but how it was integrated into their architecture and why its placement was reasonably optimal (cf., (elhadad et al, 1997), <papid> J97-2001 </papid>pp.</prevsent>
</prevsection>
<citsent citstr=" W94-0319 ">
47).at the same time, (reiter, 1994) <papid> W94-0319 </papid>argued that implemented nlg systems were converging toward de facto pipe lined architecture (figure 1) with minimal-to-nonexistent feedback between modules.although several nlg architectures were proposed in opposition to such linear arrangement(kantrowitz and bates, 1992; cline, 1994), these research projects have not continued while pipe lined architectures are still actively being pursued.in addition, reiter concludes that although complete integration of architectural components is theoretically good idea, in practical engineering terms such system would be too inefficient to operate and too complex to actually implement.</citsent>
<aftsection>
<nextsent>significantly, reiter states that fully interconnecting every module would entail constructing n(n   1) interfaces between them.
</nextsent>
<nextsent>as the number of modules rises (i.e., as the number of large-scale features an nlg engineer wants to implement rises) the implementation cost rises exponentially.
</nextsent>
<nextsent>moreover, this cost does not include modifications that are not component specific, such as multilingualism.
</nextsent>
<nextsent>as text planners scale up to produce ever larger texts, the switch to multi-page prose will introduce new features, and con sequentially the number of architectural modules will increase.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1427">
<title id=" P03-1034.xml">integrating discourse markers into a pipe lined natural language generation architecture </title>
<section> discourse markers in nlg.  </section>
<citcontext>
<prevsection>
<prevsent>for example,using large scale corpus analysis and human subjects employing substitution test over the corpus sentences containing discourse markers, knott and mellish (1996) distilled taxonomy of individual lexical discourse markers and 8 binary-valued features that could be used to drive discourse marker selection algorithm.
</prevsent>
<prevsent>other work often focuses on particular semantic categories, such as temporal discourse markers.
</prevsent>
</prevsection>
<citsent citstr=" W98-0304 ">
for instance, grote (1998) <papid> W98-0304 </papid>attempted to create declarative lexicons that contain applicability condition sand other constraints to aid in the process of discourse marker selection.</citsent>
<aftsection>
<nextsent>other theoretical research consists, for example, of adapting existing grammatical formalisms such as tags (webber and joshi, 1998) <papid> W98-0315 </papid>for discourse-level phenomena.alternatively, there are several implemented systems that automatically insert discourse markers into multi-sentential text.</nextsent>
<nextsent>in an early instance, elhadad and mckeown (1990) <papid> C90-3018 </papid>followed quirks pre-existing non-computational account of discourse connectives to produce single argumentative discourse markers inside functional unification surface realizer (andthereby postponing lexicalization till the last possible moment).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1428">
<title id=" P03-1034.xml">integrating discourse markers into a pipe lined natural language generation architecture </title>
<section> discourse markers in nlg.  </section>
<citcontext>
<prevsection>
<prevsent>other work often focuses on particular semantic categories, such as temporal discourse markers.
</prevsent>
<prevsent>for instance, grote (1998) <papid> W98-0304 </papid>attempted to create declarative lexicons that contain applicability condition sand other constraints to aid in the process of discourse marker selection.</prevsent>
</prevsection>
<citsent citstr=" W98-0315 ">
other theoretical research consists, for example, of adapting existing grammatical formalisms such as tags (webber and joshi, 1998) <papid> W98-0315 </papid>for discourse-level phenomena.alternatively, there are several implemented systems that automatically insert discourse markers into multi-sentential text.</citsent>
<aftsection>
<nextsent>in an early instance, elhadad and mckeown (1990) <papid> C90-3018 </papid>followed quirks pre-existing non-computational account of discourse connectives to produce single argumentative discourse markers inside functional unification surface realizer (andthereby postponing lexicalization till the last possible moment).</nextsent>
<nextsent>more recent approaches have tended to move the decision time for marker lexicalization higher up the pipe lined architecture.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1429">
<title id=" P03-1034.xml">integrating discourse markers into a pipe lined natural language generation architecture </title>
<section> discourse markers in nlg.  </section>
<citcontext>
<prevsection>
<prevsent>for instance, grote (1998) <papid> W98-0304 </papid>attempted to create declarative lexicons that contain applicability condition sand other constraints to aid in the process of discourse marker selection.</prevsent>
<prevsent>other theoretical research consists, for example, of adapting existing grammatical formalisms such as tags (webber and joshi, 1998) <papid> W98-0315 </papid>for discourse-level phenomena.alternatively, there are several implemented systems that automatically insert discourse markers into multi-sentential text.</prevsent>
</prevsection>
<citsent citstr=" C90-3018 ">
in an early instance, elhadad and mckeown (1990) <papid> C90-3018 </papid>followed quirks pre-existing non-computational account of discourse connectives to produce single argumentative discourse markers inside functional unification surface realizer (andthereby postponing lexicalization till the last possible moment).</citsent>
<aftsection>
<nextsent>more recent approaches have tended to move the decision time for marker lexicalization higher up the pipe lined architecture.
</nextsent>
<nextsent>for example, the moose system (stede and umbach, 1998; <papid> P98-2202 </papid>grote and stede, 1999) lexicalized discourse markers at the sentence planning level by pushing them directly into the lexicon.</nextsent>
<nextsent>similarly, power et al (1999) produce multiple discourse markers for patient information leaflets using constraint-based method applied to rst trees during sentence planning.finally, in the circ-sim intelligent tutoring system (yang et al, 2000) that generates connected dialogues for students studying heart ailments, discourse marker lexicalization has been pushed all the way up to the discourse planning level.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1430">
<title id=" P03-1034.xml">integrating discourse markers into a pipe lined natural language generation architecture </title>
<section> discourse markers in nlg.  </section>
<citcontext>
<prevsection>
<prevsent>in an early instance, elhadad and mckeown (1990) <papid> C90-3018 </papid>followed quirks pre-existing non-computational account of discourse connectives to produce single argumentative discourse markers inside functional unification surface realizer (andthereby postponing lexicalization till the last possible moment).</prevsent>
<prevsent>more recent approaches have tended to move the decision time for marker lexicalization higher up the pipe lined architecture.</prevsent>
</prevsection>
<citsent citstr=" P98-2202 ">
for example, the moose system (stede and umbach, 1998; <papid> P98-2202 </papid>grote and stede, 1999) lexicalized discourse markers at the sentence planning level by pushing them directly into the lexicon.</citsent>
<aftsection>
<nextsent>similarly, power et al (1999) produce multiple discourse markers for patient information leaflets using constraint-based method applied to rst trees during sentence planning.finally, in the circ-sim intelligent tutoring system (yang et al, 2000) that generates connected dialogues for students studying heart ailments, discourse marker lexicalization has been pushed all the way up to the discourse planning level.
</nextsent>
<nextsent>in this case, circ-sim lexicalizes discourse markers inside of the discourse schema templates themselves.
</nextsent>
<nextsent>given that these different implemented discourse marker insertion algorithms lexicalize their marker sat three distinct places in pipe lined nlg architecture, it is not clear if lexicalization can occur at any point without restriction, or if it is in fact tied to the particular architectural modules that system designer chooses to include.
</nextsent>
<nextsent>the answer becomes clearer after noting that noneof the implemented discourse marker algorithms described above have been incorporated into comprehensive nlg architecture containing additional significant components such as revision (with the exception of mooses lexical choice component,which stede considers to be sub module of the sentence planner).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1431">
<title id=" P03-1034.xml">integrating discourse markers into a pipe lined natural language generation architecture </title>
<section> current implemented revision systems.  </section>
<citcontext>
<prevsection>
<prevsent>the revisor system (callaway and lester,1997) takes an entire sentence plan at once and ite rates through it in paragraph-sized chunks, employing clause- and phrase-level aggregation and reordering operations before passing revised sentence plan to the surface realizer.
</prevsent>
<prevsent>however, at no point does it add information that previously did not exist in the sentence plan.
</prevsent>
</prevsection>
<citsent citstr=" P98-1084 ">
the rtpi system (har vey and carberry, 1998) <papid> P98-1084 </papid>takes in sets of multiple,lexicalized sentential plans over number of medical diagnoses from different critiquing systems and produces single, unified sentence plan which is both coherent and cohesive.</citsent>
<aftsection>
<nextsent>like streak, shaws casper system (shaw,1998) <papid> W98-1415 </papid>produces single sentences from sets of sentences and doesnt attempt to deal with discourse markers.</nextsent>
<nextsent>casper also delays lexicalization when aggregating by looking at the lexicon twice during the revision process.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1432">
<title id=" P03-1034.xml">integrating discourse markers into a pipe lined natural language generation architecture </title>
<section> current implemented revision systems.  </section>
<citcontext>
<prevsection>
<prevsent>however, at no point does it add information that previously did not exist in the sentence plan.
</prevsent>
<prevsent>the rtpi system (har vey and carberry, 1998) <papid> P98-1084 </papid>takes in sets of multiple,lexicalized sentential plans over number of medical diagnoses from different critiquing systems and produces single, unified sentence plan which is both coherent and cohesive.</prevsent>
</prevsection>
<citsent citstr=" W98-1415 ">
like streak, shaws casper system (shaw,1998) <papid> W98-1415 </papid>produces single sentences from sets of sentences and doesnt attempt to deal with discourse markers.</citsent>
<aftsection>
<nextsent>casper also delays lexicalization when aggregating by looking at the lexicon twice during the revision process.
</nextsent>
<nextsent>this is due mainly to the efficiency costs of the unification procedure.
</nextsent>
<nextsent>however, caspers sentence planner essentially uses the first lexicon lookup to find set of lexicalizations?
</nextsent>
<nextsent>before eventually selecting particular one.an important similarity of these pipe lined revision systems is that they all manipulate lexicalized representations at the clause level.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1433">
<title id=" P03-2024.xml">a limited domain english to japanese medical speech translator built using regulus 2 </title>
<section> an architecture for limited-domain.  </section>
<citcontext>
<prevsection>
<prevsent>these answers to these questions can be sucessfully communicated by limited number of one or two word responses (e.g. yes/no, left/right, numbers) or even gestures (e.g. pointing to an area of the body).
</prevsent>
<prevsent>this is clearly adomain in which the constraints of the task are sufficient for limited domain, one way spoken translation system to be useful tool.
</prevsent>
</prevsection>
<citsent citstr=" C00-2097 ">
speech translation the basic philosophy behind the architecture of the system is to attempt an intelligent compromise between fixed-phrase translation on one hand (e.g.(integratedwavetechnologies, 2002)) and linguistically motivated grammar-based processing on the other (e.g. verb mobil (wahlster, 2000) and spoken language translator (rayner et al, 2000<papid> C00-2097 </papid>a)).</citsent>
<aftsection>
<nextsent>at run-time, the system behaves essentially like phrasal translator which allows some variation in the input language.
</nextsent>
<nextsent>this is close in spirit to the approach used in most normal phrase-books, which typically allow slots?
</nextsent>
<nextsent>in at least some phrases (how much does ? cost??; how do get to ? ??).
</nextsent>
<nextsent>however, in order to minimize the overhead associated with defining and maintaining large sets of phrasal patterns, these patterns are derived from single large linguistically motivated unification grammar; thusthe compile-time architecture is that of linguistically motivated system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1436">
<title id=" P03-2024.xml">a limited domain english to japanese medical speech translator built using regulus 2 </title>
<section> an architecture for limited-domain.  </section>
<citcontext>
<prevsection>
<prevsent>the speech processing modules (recognition and synthesis) are implemented on top of the standard nuance toolkit platform (nuance, 2003).
</prevsent>
<prevsent>recognition is constrained by cfg language model written in nuance grammar specification language (gsl), which also specifies the semantic representations produced.
</prevsent>
</prevsection>
<citsent citstr=" E03-2010 ">
this language model is compiled froma linguistically motivated unification grammar using the open source regulus 2 platform (rayneret al, 2003; <papid> E03-2010 </papid>regulus, 2003); the compilation process is driven by small corpus of examples.</citsent>
<aftsection>
<nextsent>the language processing modules (transfer and genera tion) are suite of simple routines written in sicstusprolog.
</nextsent>
<nextsent>the speech and language processing modules communicate with each other through minimal file-based protocol.
</nextsent>
<nextsent>the semantic representations on both the source and target sides are expressed as attribute-valuestructures.
</nextsent>
<nextsent>in accordance with the generally mini malis tic design philosophy of the project, semantic representations have been kept as simple as possible.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1443">
<title id=" P04-1030.xml">head driven parsing for word lattices </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>our work is different from roark (2001) in that we usea bottom-up parsing algorithm with dynamic programming based on the parsing model ii of collins (1999).
</prevsent>
<prevsent>bottom-up chart parsing, through various formsof extensions to the cky algorithm, has been applied to word lattices for speech recognition (hall and johnson, 2003; chappelier and rajman, 1998; chelba and jelinek, 2000).
</prevsent>
</prevsection>
<citsent citstr=" P01-1017 ">
full acoustic and n-best lattices filtered by trigram scores have been parsed.hall and johnson (2003) use best-first probabilistic context free grammar (pcfg) to parse the input lattice, pruning to set of local trees (candidate partial parse trees), which are then passed to version of the parser of charniak (2001) <papid> P01-1017 </papid>for more refined parsing.</citsent>
<aftsection>
<nextsent>unlike (roark, 2001; chelba, 2000), hall and johnson (2003) achieve improvement in werover the trigram model without interpol ating its lattice parser probabilities directly with trigram probabilities.
</nextsent>
<nextsent>parsing models based on headword dependency relationships have been reported, such as the structured language model of chelba and jelinek (2000).these models use much less conditioning information than the parsing models of collins (1999), and do not provide penn treebank format parse trees as output.
</nextsent>
<nextsent>in this section we outline the adaptation of the collins (1999) parsing model to word lattices.
</nextsent>
<nextsent>the intended action of the parser is illustrated in figure 1, which shows parse trees built directly upon word lattice.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1447">
<title id=" P04-1030.xml">head driven parsing for word lattices </title>
<section> word lattice parser.  </section>
<citcontext>
<prevsection>
<prevsent>the example shows two final parses, one of low probability (s   ) and one of high probability (s).maximum likelihood estimates of conditional probabilities ? the probability of some event of interest (e.g., left-modifier attachment) given context (e.g., parent non-terminal, distance, headword).
</prevsent>
<prevsent>one notable difference between the word lattice parser and the original implementation of collins(1999) is the handling of part-of-speech (pos) tagging of unknown words (words seen fewer than 5 times in training).
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
the conditioning context of the parsing model parameters includes pos tagging.collins (1999) falls back to the pos tagging of ratnaparkhi (1996) <papid> W96-0213 </papid>for words seen fewer than 5 times in the training corpus.</citsent>
<aftsection>
<nextsent>as the tagger of ratnaparkhi (1996) <papid> W96-0213 </papid>cannot tag word lattice, we cannot back off to this tagging.</nextsent>
<nextsent>we relyon the tag assigned by the parsing model in all cases.edges created by the bottom-up parsing are assigned score which is the product of the inside and outside probabilities of the collins (1999) model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1449">
<title id=" P04-1030.xml">head driven parsing for word lattices </title>
<section> word lattice parser.  </section>
<citcontext>
<prevsection>
<prevsent>the base beam starts at low beam size and increases iteratively by specified increment if no parse is found.
</prevsent>
<prevsent>this allows parsing to operate quickly (with minimal number of edges added to the chart).
</prevsent>
</prevsection>
<citsent citstr=" W97-0302 ">
however, if many iterations are required to obtain parse, the utility of starting with low beam and ite rating becomes questionable(goodman, 1997).<papid> W97-0302 </papid></citsent>
<aftsection>
<nextsent>the base beam is limited to control the increase in the chart size.
</nextsent>
<nextsent>the selection of the base beam, beam increment, and variable beam function is governed by the familiar speed/accuracytrade-off.1 the variable beam function found to allow fast convergence with minimal loss of accuracy is: b
</nextsent>
<nextsent>blog   2  2  (1) 1details of the optimization can be found in collins (2004).
</nextsent>
<nextsent>charniak et al (1998) <papid> W98-1115 </papid>introduce over parsing as technique to improve parse accuracy by continuing parsing after the first complete parse tree is found.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1450">
<title id=" P04-1030.xml">head driven parsing for word lattices </title>
<section> word lattice parser.  </section>
<citcontext>
<prevsection>
<prevsent>the selection of the base beam, beam increment, and variable beam function is governed by the familiar speed/accuracytrade-off.1 the variable beam function found to allow fast convergence with minimal loss of accuracy is: b
</prevsent>
<prevsent>blog   2  2  (1) 1details of the optimization can be found in collins (2004).
</prevsent>
</prevsection>
<citsent citstr=" W98-1115 ">
charniak et al (1998) <papid> W98-1115 </papid>introduce over parsing as technique to improve parse accuracy by continuing parsing after the first complete parse tree is found.</citsent>
<aftsection>
<nextsent>the technique is employed by hall and johnson (2003) to ensure that early stages of parsing do not strongly bias later stages.
</nextsent>
<nextsent>we adapt this idea to single stage process.
</nextsent>
<nextsent>due to the restrictions of beam search and thresholds, the first parse found by the model may not be the model optimal parse (i.e.,we cannot guarantee best-first search).
</nextsent>
<nextsent>we therefore employ form of over parsing ? once complete parse tree is found, we further extend the base beam by the beam increment and parse again.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1451">
<title id=" P04-1030.xml">head driven parsing for word lattices </title>
<section> expanding the measures of success.  </section>
<citcontext>
<prevsection>
<prevsent>perplexity is related to the entropy of the source model which the language model attempts to estimate.these measures, while informative, do not capture success of extraction of high-level information from speech.
</prevsent>
<prevsent>task-specific measures should be usedin tandem with extensional measures such as perplexity and wer.
</prevsent>
</prevsection>
<citsent citstr=" P02-1037 ">
roark (2002), <papid> P02-1037 </papid>when reviewing 2sclite (http://www.nist.gov/speech/ tools/) by nist is the most commonly used alignment tool.parsing for speech recognition, discusses modelling trade-off between producing parse trees and producing strings.</citsent>
<aftsection>
<nextsent>most models are evaluated either with measures of success for parsing or forword recognition, but rarely both.
</nextsent>
<nextsent>parsing models are difficult to implement as word-predictivelanguage models due to their complexity.
</nextsent>
<nextsent>generative random sampling is equally challenging, so the parsing correlate of perplexity is not easy tomeasure.
</nextsent>
<nextsent>traditional (i.e., n-gram) language models do not produce parse trees, so parsing metrics are not useful.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1452">
<title id=" P04-1030.xml">head driven parsing for word lattices </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>results show scores for parsing strings which are lower than the original implementation of collins (1999).
</prevsent>
<prevsent>the wer scores for this, the first application of the collins (1999) model to parsing word lattices, are comparable to other recent work in syntactic language modelling, and better than simple trigram model trained on the same data.
</prevsent>
</prevsection>
<citsent citstr=" H91-1060 ">
3parse trees are commonly scored with the parseval set of metrics (black et al, 1991).<papid> H91-1060 </papid></citsent>
<aftsection>
<nextsent>5.1 parsing strings.
</nextsent>
<nextsent>the lattice parser can parse strings by creating asingle-path lattice from the input (all word transitions are assigned an input score of 1.0).
</nextsent>
<nextsent>the lattice parser was trained on sections 02-21 of the wall street journal portion of the penn treebank (tay lor et al, 2003) development testing was carried out on section 23 in order to select model thresholds and variable beam functions.
</nextsent>
<nextsent>final testing was carried out on section 00, and the parseval measures (black et al, 1991) <papid> H91-1060 </papid>were used to evaluate the performance.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1460">
<title id=" P04-1030.xml">head driven parsing for word lattices </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>1  16   ?
</prevsent>
<prevsent>1) achieved additional improvement in wer over the lattice trigram alone.
</prevsent>
</prevsection>
<citsent citstr=" P02-1025 ">
the current best-performing models, in terms of wer, for the hub-1 corpus, are the models of roark (2001), charniak (2001) <papid> P01-1017 </papid>(applied to n-best lists by hall and johnson (2003)), and the slm of chelba and jelinek (2000) (applied to n-best lists by xu et al (2002)).<papid> P02-1025 </papid></citsent>
<aftsection>
<nextsent>however, n-best list parsing, as seen in our evaluation, requires repeated analysis of common sub sequences, less efficient process than directly parsing the word lattice.
</nextsent>
<nextsent>the reported results of (roark, 2001) and (chelba, 2000) are for parsing models interpolated with the lattice trigram probabilities.
</nextsent>
<nextsent>hall and john 7the wer of the hypothesis which best matches the true utterance, i.e., the lowest wer possible given the hypotheses set.
</nextsent>
<nextsent>training size lattice/list op wer number of edgess i (per word) 1m lattice 10.4 3.3 1.5 15.2 1788 1m list 10.4 3.2 1.4 15.0 10211 1m lattice 10.3 3.2 1.4 14.9 2855 1m list 10.2 3.2 1.4 14.8 16821 20m lattice 9.0 3.1 1.0 13.1 1735 20m list 9.0 3.1 1.0 13.1 9999 20m lattice 9.0 3.1 1.0 13.1 2801 20m list 9.0 3.3 0.9 13.3 16030 table 2: results for parsing hub-1 n-best word lattices and lists: op = over parsing, = substutitions (%), = deletions (%), = insertions (%), = total wer (%).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1472">
<title id=" P04-1030.xml">head driven parsing for word lattices </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the difference in wer between our parser and those of charniak (2001) <papid> P01-1017 </papid>and roark (2001) applied to word lists may be due in part to the lower parseval scores of our system.</prevsent>
<prevsent>xu et al (2002) <papid> P02-1025 </papid>report inverse correlation between labelled precision/recall and wer.</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
we achieve 73.2/76.5%lp/lr on section 23 of the penn treebank, compared to 82.9/82.4% lp/lr of roark (2001) and 90.1/90.1% lp/lr of charniak (2000).<papid> A00-2018 </papid></citsent>
<aftsection>
<nextsent>another contributing factor to the accuracy of charniak (2001) <papid> P01-1017 </papid>is the size of the training set ? 20m words larger than that used in this work.</nextsent>
<nextsent>the low wer of roark (2001), top-down probabilistic parsing model, was achieved by training the model on 1 million words of the penn treebank, then performing single pass of expectation maximization (em) on further 1.2 million words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1477">
<title id=" P00-1051.xml">specifying the parameters of centering theory a corpus based evaluation using text from application oriented domains </title>
<section> motivation.  </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" J95-2003 ">
centering theory (grosz et al, 1995; <papid> J95-2003 </papid>walker et al., 1998b) is best characterized as parametrictheory: its key definitions and claims involve notions such as utterance?, realization?, and ranking?</citsent>
<aftsection>
<nextsent>which are not completely specified; their precise definition is left as matter for empirical research, and may vary from language to language.
</nextsent>
<nextsent>a first goal of the work presented in this paper was to find which way of specifying these parameters, among the many proposed in the literature, would make the claims of centering theory most accurate as predictors of coherence and pronomi nal ization for english.
</nextsent>
<nextsent>we did this by annotatinga corpus of english texts with the sort of information required to implement some of the most popular variants of centering theory, and using this corpus to automatically check two central claims of the theory, the claim that all utterances have backward looking center (cb) (constraint 1), andthe claim that if any discourse entity is pronomi nalized, the cb is (rule 1).
</nextsent>
<nextsent>in doing this, we tried to make sure we would only use information that could be annotated reliably.our second goal was to evaluate the predictions of the theory in domains of interest for real applications natural language generation, in ourcase.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1483">
<title id=" P00-1051.xml">specifying the parameters of centering theory a corpus based evaluation using text from application oriented domains </title>
<section> fundamentals of centering.  </section>
<citcontext>
<prevsection>
<prevsent>in this paper we concentrate on constraint 1 and rule 1.
</prevsent>
<prevsent>one of the most unusual features of centering theory is that the notions of utterance, previous utterance, ranking, and realization used in the definitions above are left unspecified, to be appropriately defined on the basis of empirical evidence, and possibly in different way for each language.
</prevsent>
</prevsection>
<citsent citstr=" P87-1022 ">
as result, centering theory is best viewed as cluster of theories, each of which specifies the parameters in different ways: e.g., ranking has been claimed to depend on grammatical function(kameyama, 1985; brennan et al, 1987), <papid> P87-1022 </papid>on thematic roles (cote, 1998), and on the discourse status of the cfs (strube and hahn, 1999); <papid> J99-3001 </papid>there areat least two definitions of what counts as previous utterance?</citsent>
<aftsection>
<nextsent>(kameyama, 1998; suri and mccoy, 1994); <papid> J94-2006 </papid>and realization?</nextsent>
<nextsent>can be interpreted either in strict sense, i.e., by taking cf to be realized in an utterance only if an np in that utterance denotes that cf, or in looser sense, by also counting cf as realized?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1484">
<title id=" P00-1051.xml">specifying the parameters of centering theory a corpus based evaluation using text from application oriented domains </title>
<section> fundamentals of centering.  </section>
<citcontext>
<prevsection>
<prevsent>in this paper we concentrate on constraint 1 and rule 1.
</prevsent>
<prevsent>one of the most unusual features of centering theory is that the notions of utterance, previous utterance, ranking, and realization used in the definitions above are left unspecified, to be appropriately defined on the basis of empirical evidence, and possibly in different way for each language.
</prevsent>
</prevsection>
<citsent citstr=" J99-3001 ">
as result, centering theory is best viewed as cluster of theories, each of which specifies the parameters in different ways: e.g., ranking has been claimed to depend on grammatical function(kameyama, 1985; brennan et al, 1987), <papid> P87-1022 </papid>on thematic roles (cote, 1998), and on the discourse status of the cfs (strube and hahn, 1999); <papid> J99-3001 </papid>there areat least two definitions of what counts as previous utterance?</citsent>
<aftsection>
<nextsent>(kameyama, 1998; suri and mccoy, 1994); <papid> J94-2006 </papid>and realization?</nextsent>
<nextsent>can be interpreted either in strict sense, i.e., by taking cf to be realized in an utterance only if an np in that utterance denotes that cf, or in looser sense, by also counting cf as realized?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1485">
<title id=" P00-1051.xml">specifying the parameters of centering theory a corpus based evaluation using text from application oriented domains </title>
<section> fundamentals of centering.  </section>
<citcontext>
<prevsection>
<prevsent>one of the most unusual features of centering theory is that the notions of utterance, previous utterance, ranking, and realization used in the definitions above are left unspecified, to be appropriately defined on the basis of empirical evidence, and possibly in different way for each language.
</prevsent>
<prevsent>as result, centering theory is best viewed as cluster of theories, each of which specifies the parameters in different ways: e.g., ranking has been claimed to depend on grammatical function(kameyama, 1985; brennan et al, 1987), <papid> P87-1022 </papid>on thematic roles (cote, 1998), and on the discourse status of the cfs (strube and hahn, 1999); <papid> J99-3001 </papid>there areat least two definitions of what counts as previous utterance?</prevsent>
</prevsection>
<citsent citstr=" J94-2006 ">
(kameyama, 1998; suri and mccoy, 1994); <papid> J94-2006 </papid>and realization?</citsent>
<aftsection>
<nextsent>can be interpreted either in strict sense, i.e., by taking cf to be realized in an utterance only if an np in that utterance denotes that cf, or in looser sense, by also counting cf as realized?
</nextsent>
<nextsent>if it is referred to indirectly by means of bridging reference (clark, 1977), i.e., an anaphoric expression that refers to an object which wasnt mentioned before but is somehow related to an object that already has, as in the vase . . .
</nextsent>
<nextsent>the handle (see, e.g., the discussion in (grosz et al, 1995; <papid> J95-2003 </papid>walker et al, 1998b)).</nextsent>
<nextsent>the fact that so many basic notions of centering theory do not have completely specified definition makes empirical verification of the theory rather difficult.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1490">
<title id=" P00-1051.xml">specifying the parameters of centering theory a corpus based evaluation using text from application oriented domains </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>the fact that so many basic notions of centering theory do not have completely specified definition makes empirical verification of the theory rather difficult.
</prevsent>
<prevsent>because any attempt at directly annotating corpus for utterances?
</prevsent>
</prevsection>
<citsent citstr=" P89-1031 ">
and their cbs is bound to force the annotators to adopt some specification of the basic notions of the theory, previous studies have tended to study particular variant of the theory (di eugenio, 1998; kameyama, 1998; passonneau, 1993; strube and hahn, 1999; <papid> J99-3001 </papid>walker, 1989).<papid> P89-1031 </papid></citsent>
<aftsection>
<nextsent>a notable exception is (tetreault, 1999), <papid> P99-1079 </papid>which used an annotated corpus to compare the performance of two variants of centering theory.</nextsent>
<nextsent>the work discussed here, like tetreaults, is an attempt at using corpora to compare different versions of centering theory, but considering also parameters of centering theory not studied in this earlier work.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1491">
<title id=" P00-1051.xml">specifying the parameters of centering theory a corpus based evaluation using text from application oriented domains </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>because any attempt at directly annotating corpus for utterances?
</prevsent>
<prevsent>and their cbs is bound to force the annotators to adopt some specification of the basic notions of the theory, previous studies have tended to study particular variant of the theory (di eugenio, 1998; kameyama, 1998; passonneau, 1993; strube and hahn, 1999; <papid> J99-3001 </papid>walker, 1989).<papid> P89-1031 </papid></prevsent>
</prevsection>
<citsent citstr=" P99-1079 ">
a notable exception is (tetreault, 1999), <papid> P99-1079 </papid>which used an annotated corpus to compare the performance of two variants of centering theory.</citsent>
<aftsection>
<nextsent>the work discussed here, like tetreaults, is an attempt at using corpora to compare different versions of centering theory, but considering also parameters of centering theory not studied in this earlier work.
</nextsent>
<nextsent>in particular, we looked at different ways of defining the notion of utterance, we studied the definition of realization, and more generally the role of semantic information.
</nextsent>
<nextsent>we did this by annotating corpus with information that hasbeen claimed by one or the other version of centering theory to play role in the definitions of its basic notions - e.g., the grammatical function of an np, anaphoric relations (including information about bridging references) and how sentences break up into clauses and subclausal unit sand then tried to find out the best way of specifying these notions automatically, by trying out different configurations of parameters, and counting the number of violations of the constraints and rules that would result by adopting particular parameter configuration.
</nextsent>
<nextsent>the data the aim of our project, which is called gnome and whose home page is at http://www.hcrc.ed.ac.uk/ ~ gnome, is to develop np generation algorithms whose generality is to be verified by incorporating them in two distinct systems: the ilex system developed at the university of edinburgh, that generates web pages describing museum objects on the basis of the perceived status of its users knowledge and of the objects she previously looked at (oberlander et al, 1998); and the iconoclast system, developed at the university of brighton, that supports the creation of patient information leaflets (scott et al, 1998).<papid> W98-1427 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1492">
<title id=" P00-1051.xml">specifying the parameters of centering theory a corpus based evaluation using text from application oriented domains </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>in particular, we looked at different ways of defining the notion of utterance, we studied the definition of realization, and more generally the role of semantic information.
</prevsent>
<prevsent>we did this by annotating corpus with information that hasbeen claimed by one or the other version of centering theory to play role in the definitions of its basic notions - e.g., the grammatical function of an np, anaphoric relations (including information about bridging references) and how sentences break up into clauses and subclausal unit sand then tried to find out the best way of specifying these notions automatically, by trying out different configurations of parameters, and counting the number of violations of the constraints and rules that would result by adopting particular parameter configuration.
</prevsent>
</prevsection>
<citsent citstr=" W98-1427 ">
the data the aim of our project, which is called gnome and whose home page is at http://www.hcrc.ed.ac.uk/ ~ gnome, is to develop np generation algorithms whose generality is to be verified by incorporating them in two distinct systems: the ilex system developed at the university of edinburgh, that generates web pages describing museum objects on the basis of the perceived status of its users knowledge and of the objects she previously looked at (oberlander et al, 1998); and the iconoclast system, developed at the university of brighton, that supports the creation of patient information leaflets (scott et al, 1998).<papid> W98-1427 </papid></citsent>
<aftsection>
<nextsent>the corpus we collected includes texts from both the domains we are studying.
</nextsent>
<nextsent>the texts in the museum domain consist of descriptions of museum objects and brief texts about the artists that produced them; the texts in the pharmaceutical domain are leaflets providing the patients with the legally mandatory information about their medicine.
</nextsent>
<nextsent>the total size of the corpus is of about 6,000 nps.
</nextsent>
<nextsent>for this study we used about half of each subset, for total number of about 3,000 nps, of which 103 are third person pronouns (72 in the museum domain, 31 in the pharmaceutical domain) and 61 are third-person possessive pronouns (58 in the museum domain, 3 in the pharmaceutical domain).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1494">
<title id=" P00-1051.xml">specifying the parameters of centering theory a corpus based evaluation using text from application oriented domains </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>for this study we used about half of each subset, for total number of about 3,000 nps, of which 103 are third person pronouns (72 in the museum domain, 31 in the pharmaceutical domain) and 61 are third-person possessive pronouns (58 in the museum domain, 3 in the pharmaceutical domain).
</prevsent>
<prevsent>annotation previous empirical studies of centering theory typically involved single annotator annotating her corpus according to her own subjective judgment (passonneau, 1993; kameyama, 1998; strube and hahn, 1999).<papid> J99-3001 </papid></prevsent>
</prevsection>
<citsent citstr=" J96-2004 ">
one of our goals was to use for our study only information that could be annotated reliably (passonneau and litman, 1993; carletta, 1996), <papid> J96-2004 </papid>as we believe this will make our results easier to replicate.</citsent>
<aftsection>
<nextsent>the pricewe paid to achieve replicability is that we couldnt test all hypotheses proposed in the literature, especially about segmentation and about ranking.
</nextsent>
<nextsent>we discuss some of the problems in what follows.
</nextsent>
<nextsent>(the latest version of the annotation manual is available from the gnome projects home page.)
</nextsent>
<nextsent>we used eight annotators for the reliability study and the annotation.utterances kameyama (1998) noted that identifying utterances with sentences is problematic in the case of multiclausal sentences: e.g., grammatical function ranking becomes difficult to measure, as there may be more than one subject.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1499">
<title id=" P00-1051.xml">specifying the parameters of centering theory a corpus based evaluation using text from application oriented domains </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent> finite: for verbed units, whether the verb is finite or not.
</prevsent>
<prevsent> subject: for verbed units, whether they have full subject, an empty subject (expletive, as in there sentences), or no subject (e.g., for infiniti val clauses).
</prevsent>
</prevsection>
<citsent citstr=" W99-0309 ">
the agreement on identifying the boundaries of units, using the  statistic discussed in (carletta, 1996), <papid> J96-2004 </papid>was  = :9 (for two annotators and 500 units); the agreement on features(2 annotators and at least 200 units) was follows: attribute  value utype .76 verbed .9 finite .81 subject .86nps our instructions for identifying np mark ables derive from those proposed in the mate project scheme for annotating anaphoric relations (poesio et al, 1999).<papid> W99-0309 </papid></citsent>
<aftsection>
<nextsent>we annotated attributes of nps which could be used to define their ranking, including:  the np type, cat (pronoun, proper name, etc.)  few other basic?
</nextsent>
<nextsent>syntactic features, num, per, and gen, that could be used to identify contexts in which the antecedent of pronoun could be identified unambiguously;  the grammatical function, gf;  ani: whether the object denoted is animate or inanimate deix: whether the object is deictic reference or not the agreement values for these attributes are as follows: attribute  value ani .81 cat .9 deix .81 gen .89 gf .85 num .84 per .9one of the features of nps claimed to affect ranking (sidner, 1979; cote, 1998) that we havent so far been able to annotate because of failure to reach acceptable agreement is thematic roles ( = :35).
</nextsent>
<nextsent>anaphoric information finally, in order to compute whether cf from an utterance was realized directly or indirectly in the following utterance, we marked up anaphoric relations between nps, again using variant of the mate scheme.
</nextsent>
<nextsent>theories of focusing such as (sidner, 1979; strube and hahn, 1999), <papid> J99-3001 </papid>as well as our own early experiments with centering, suggested that indirect realization can play quite crucial role in maintaining the cb; however, previous work, particularly in the context of the muc initiative, suggested that while its fairly easy to achieve agreement on identity relations, marking up bridging references is quite hard; this was confirmed by, e.g., poesio and vieira (1998).<papid> J98-2001 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1501">
<title id=" P00-1051.xml">specifying the parameters of centering theory a corpus based evaluation using text from application oriented domains </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>syntactic features, num, per, and gen, that could be used to identify contexts in which the antecedent of pronoun could be identified unambiguously;  the grammatical function, gf;  ani: whether the object denoted is animate or inanimate deix: whether the object is deictic reference or not the agreement values for these attributes are as follows: attribute  value ani .81 cat .9 deix .81 gen .89 gf .85 num .84 per .9one of the features of nps claimed to affect ranking (sidner, 1979; cote, 1998) that we havent so far been able to annotate because of failure to reach acceptable agreement is thematic roles ( = :35).
</prevsent>
<prevsent>anaphoric information finally, in order to compute whether cf from an utterance was realized directly or indirectly in the following utterance, we marked up anaphoric relations between nps, again using variant of the mate scheme.
</prevsent>
</prevsection>
<citsent citstr=" J98-2001 ">
theories of focusing such as (sidner, 1979; strube and hahn, 1999), <papid> J99-3001 </papid>as well as our own early experiments with centering, suggested that indirect realization can play quite crucial role in maintaining the cb; however, previous work, particularly in the context of the muc initiative, suggested that while its fairly easy to achieve agreement on identity relations, marking up bridging references is quite hard; this was confirmed by, e.g., poesio and vieira (1998).<papid> J98-2001 </papid></citsent>
<aftsection>
<nextsent>as result we did annotate this type of relations, but to achieve reasonable agreement, and to contain somehow the annotators?
</nextsent>
<nextsent>work, we limited the types of relations annotators were supposed to mark up, and we specified priorities.
</nextsent>
<nextsent>thus, besides identity (ident) we only marked up three non-identity(bridging?
</nextsent>
<nextsent>(clark, 1977)) relations, and only relations between objects.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1503">
<title id=" P00-1051.xml">specifying the parameters of centering theory a corpus based evaluation using text from application oriented domains </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>the behavior of the script that computes this information depends on the following parameters: utterance: whether sentences, finite clauses, orverbed clauses should be treated as utterances.
</prevsent>
<prevsent>previous utterance: whether adjunct clauses should be treated kameyama-style or suri-style.
</prevsent>
</prevsection>
<citsent citstr=" C00-1031 ">
rank: whether cfs should be ranked according to grammatical function or discourse status in strube and hahns sense 2(cristea et al, 2000) <papid> C00-1031 </papid>showed that it is indeed possible to achieve good agreement on discourse segmentation, but that it requires intensive training and repeated iterations; we intend to take advantage of corpus already annotated in this way in future work.</citsent>
<aftsection>
<nextsent>realization: whether only direct realization should be counted, or also indirect realization via bridging references.
</nextsent>
<nextsent>the principle we used to evaluate the different configurations of the theory was that the best definition of the parameters was the one that would lead to the fewest violations of constraint 1 and rule 1.
</nextsent>
<nextsent>we discuss the results for each principle.
</nextsent>
<nextsent>constraint 1: all utterances of segment except for the 1st have precisely one cb our first set of figures concerns constraint 1:how many utterances have cb.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1505">
<title id=" P00-1051.xml">specifying the parameters of centering theory a corpus based evaluation using text from application oriented domains </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>4this separation among center of coherence?
</prevsent>
<prevsent>and acenter of salience?
</prevsent>
</prevsection>
<citsent citstr=" W99-0109 ">
is independently motivated by considerations about the division of labor between the text planner and the sentence planner in generation system; see, e.g., (kibble, 1999).<papid> W99-0109 </papid></citsent>
<aftsection>




</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1506">
<title id=" N12-3002.xml">a graphical user interface for feature based opinion mining </title>
<section> the system and its interface.  </section>
<citcontext>
<prevsection>
<prevsent>is the time when the opinion is expressed.
</prevsent>
<prevsent>we use the robust parser to extract, using syntactic relations already extracted by general dependency grammar, semantic relations instantiating this model.
</prevsent>
</prevsection>
<citsent citstr=" N06-1026 ">
other systems use syntactic dependencies to link source and target of the opinion, for example in kim and hovy (2006).<papid> N06-1026 </papid></citsent>
<aftsection>
<nextsent>our system belongs to this family, as we believe that syntactic processing of complex phenomena (negation, comparison and anaphora) is necessary step to perform feature-based opinion mining.
</nextsent>
<nextsent>another specificity of our system is two level architecture based on generic level, applicable to any domain, and on domain dependent level, adapted for each sub-domain of application.
</nextsent>
<nextsent>regarding evaluation, the relations of opinion extracted by the system have been used to train svm classifier in order to assess the systems ability to correctly classify users reviews as positive or negative.
</nextsent>
<nextsent>results are quite satisfying, as they show 93% of accuracy to classify reviews about printers and 89% of accuracy to classify reviews about movies (brun, 2011).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1507">
<title id=" P01-1009.xml">alternative phrases and natural language information retrieval </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>answers that do not conform are wrong.
</prevsent>
<prevsent>another feature of alternative markers are their presuppositions.
</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
through these pre suppositions, alternative markers can provide rich source of knowledge about the world, as hearst (1992) <papid> C92-2082 </papid>has already recognized.</citsent>
<aftsection>
<nextsent>for example, these queries imply that afghanistan is country, net scape is web browser, bushwackers are shoes, and bidfindis an auction search engine.
</nextsent>
<nextsent>anaphoric resolution can sometimes be critical for these inferences.
</nextsent>
<nextsent>in (1), for instance, other countries anaphoric ally depends on afghanistan in the previous query.while not as obviously important to natural language information retrieval, this property of alternative phrases can be used to improve future queries (see section 4.1).
</nextsent>
<nextsent>the purpose of this paper is, first, to briefly provide well-founded semantic analysis for alternative phrases that is amenable to computation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1511">
<title id=" P01-1009.xml">alternative phrases and natural language information retrieval </title>
<section> analysis.  </section>
<citcontext>
<prevsection>
<prevsent>(for an overview of presup position, see beaver (1997).)
</prevsent>
<prevsent>the semantics of lexical entries are separated into assertion and pre supposition as in stalnaker (1974) and karttunen and peters (1979).
</prevsent>
</prevsection>
<citsent citstr=" P99-1006 ">
the idea is also used in webber et al (1999) <papid> P99-1006 </papid>to capture anaphoric(non-structural) links between discourse connectives and material derivable from previous discourse, and in stone and doran (1997) <papid> P97-1026 </papid>and stone and webber (1998) <papid> W98-1419 </papid>for natural language generation.</citsent>
<aftsection>
<nextsent>lexical entries are written in the following form, where the semantic parameters scope both the assertion and presuppositions: word ` ? ??
</nextsent>
<nextsent>syn : syntactic category sem : ?...
</nextsent>
<nextsent>{ assert : proposition presup : proposition* 3.2 alternative sets.
</nextsent>
<nextsent>the concept of alternative sets plays an important role in the semantics of alternative phrases.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1512">
<title id=" P01-1009.xml">alternative phrases and natural language information retrieval </title>
<section> analysis.  </section>
<citcontext>
<prevsection>
<prevsent>(for an overview of presup position, see beaver (1997).)
</prevsent>
<prevsent>the semantics of lexical entries are separated into assertion and pre supposition as in stalnaker (1974) and karttunen and peters (1979).
</prevsent>
</prevsection>
<citsent citstr=" P97-1026 ">
the idea is also used in webber et al (1999) <papid> P99-1006 </papid>to capture anaphoric(non-structural) links between discourse connectives and material derivable from previous discourse, and in stone and doran (1997) <papid> P97-1026 </papid>and stone and webber (1998) <papid> W98-1419 </papid>for natural language generation.</citsent>
<aftsection>
<nextsent>lexical entries are written in the following form, where the semantic parameters scope both the assertion and presuppositions: word ` ? ??
</nextsent>
<nextsent>syn : syntactic category sem : ?...
</nextsent>
<nextsent>{ assert : proposition presup : proposition* 3.2 alternative sets.
</nextsent>
<nextsent>the concept of alternative sets plays an important role in the semantics of alternative phrases.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1513">
<title id=" P01-1009.xml">alternative phrases and natural language information retrieval </title>
<section> analysis.  </section>
<citcontext>
<prevsection>
<prevsent>(for an overview of presup position, see beaver (1997).)
</prevsent>
<prevsent>the semantics of lexical entries are separated into assertion and pre supposition as in stalnaker (1974) and karttunen and peters (1979).
</prevsent>
</prevsection>
<citsent citstr=" W98-1419 ">
the idea is also used in webber et al (1999) <papid> P99-1006 </papid>to capture anaphoric(non-structural) links between discourse connectives and material derivable from previous discourse, and in stone and doran (1997) <papid> P97-1026 </papid>and stone and webber (1998) <papid> W98-1419 </papid>for natural language generation.</citsent>
<aftsection>
<nextsent>lexical entries are written in the following form, where the semantic parameters scope both the assertion and presuppositions: word ` ? ??
</nextsent>
<nextsent>syn : syntactic category sem : ?...
</nextsent>
<nextsent>{ assert : proposition presup : proposition* 3.2 alternative sets.
</nextsent>
<nextsent>the concept of alternative sets plays an important role in the semantics of alternative phrases.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1514">
<title id=" P01-1012.xml">detecting problematic turns in human machine interactions rule induction versus memory based learning approaches </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>as we shall see, some interesting differences between the two approaches arise.
</prevsent>
<prevsent>recently there has been an increased interest in developing automatic methods to detect problematic dialogue situations using machine learning techniques.
</prevsent>
</prevsection>
<citsent citstr=" P99-1040 ">
for instance, litman et al  (1999) <papid> P99-1040 </papid>and walker et al  (2000<papid> A00-2028 </papid>a) use ripper (cohen 1996) to classify problematic and un problematic dialogues.</citsent>
<aftsection>
<nextsent>following up on this, walker et al (2000<papid> A00-2028 </papid>b) aim at detecting problems at the utterance level, based on data obtained with at&ts; how may help you (hmihy) system (gorin et al . 1997).</nextsent>
<nextsent>walker and co-workers apply ripper to 43 features which are automatically generated by three modules of the hmihy system, namely the speech recognizer (asr), the natural language understanding module (nlu) and the dialogue manager (dm).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1515">
<title id=" P01-1012.xml">detecting problematic turns in human machine interactions rule induction versus memory based learning approaches </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>as we shall see, some interesting differences between the two approaches arise.
</prevsent>
<prevsent>recently there has been an increased interest in developing automatic methods to detect problematic dialogue situations using machine learning techniques.
</prevsent>
</prevsection>
<citsent citstr=" A00-2028 ">
for instance, litman et al  (1999) <papid> P99-1040 </papid>and walker et al  (2000<papid> A00-2028 </papid>a) use ripper (cohen 1996) to classify problematic and un problematic dialogues.</citsent>
<aftsection>
<nextsent>following up on this, walker et al (2000<papid> A00-2028 </papid>b) aim at detecting problems at the utterance level, based on data obtained with at&ts; how may help you (hmihy) system (gorin et al . 1997).</nextsent>
<nextsent>walker and co-workers apply ripper to 43 features which are automatically generated by three modules of the hmihy system, namely the speech recognizer (asr), the natural language understanding module (nlu) and the dialogue manager (dm).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1525">
<title id=" P02-1025.xml">a study on richer syntactic dependencies for structured language modeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>using the slms headword parametrization for word prediction is about 40%.
</prevsent>
<prevsent>the key to achieving this reduction isa good guess of the final best parse forgiven sentence as it is being traversed left-to-right, which is much harder than finding the final best parse for the entire sentence, as it is sought by regular statistical parser.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
nevertheless, it is expected that techniques developed in the statistical parsing community thataim at recovering the best parse for an entire sentence, i.e. as judged by human annotator, should also be productive in enhancing the performance of language model that uses syntactic structure.the statistical parsing community has used various ways of enriching the dependency structure underlying the parametrization of the probabilistic model used for scoring given parse tree (charniak,2000) (<papid> A00-2018 </papid>collins, 1999).</citsent>
<aftsection>
<nextsent>recently, such models (charniak, 2001) <papid> P01-1017 </papid>roark, 2001) have been shown to out perform the slm in terms of both ppl and wer on the upenn treebank and wsj corpora, respectively.</nextsent>
<nextsent>in (chelba and xu, 2001), simple way of enriching the probabilistic dependencies in the constructor component of the slm also showed betterppl and wer performance; the simple modification to the training procedure brought the wer performance of the slm to the same level with the best as reported in (roark, 2001).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1526">
<title id=" P02-1025.xml">a study on richer syntactic dependencies for structured language modeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the key to achieving this reduction isa good guess of the final best parse forgiven sentence as it is being traversed left-to-right, which is much harder than finding the final best parse for the entire sentence, as it is sought by regular statistical parser.
</prevsent>
<prevsent>nevertheless, it is expected that techniques developed in the statistical parsing community thataim at recovering the best parse for an entire sentence, i.e. as judged by human annotator, should also be productive in enhancing the performance of language model that uses syntactic structure.the statistical parsing community has used various ways of enriching the dependency structure underlying the parametrization of the probabilistic model used for scoring given parse tree (charniak,2000) (<papid> A00-2018 </papid>collins, 1999).</prevsent>
</prevsection>
<citsent citstr=" P01-1017 ">
recently, such models (charniak, 2001) <papid> P01-1017 </papid>roark, 2001) have been shown to out perform the slm in terms of both ppl and wer on the upenn treebank and wsj corpora, respectively.</citsent>
<aftsection>
<nextsent>in (chelba and xu, 2001), simple way of enriching the probabilistic dependencies in the constructor component of the slm also showed betterppl and wer performance; the simple modification to the training procedure brought the wer performance of the slm to the same level with the best as reported in (roark, 2001).
</nextsent>
<nextsent>in this paper, we present three simple ways of enriching the syntactic dependency structure in the slm, extending the work in (chelba and xu, 2001).the results show that an improved parser (as measured by lp/lr) is indeed helpful in reducing the ppl and wer.
</nextsent>
<nextsent>another remarkable fact is that forthe first time language model exploiting elemen computational linguistics (acl), philadelphia, july 2002, pp.
</nextsent>
<nextsent>191-198.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1539">
<title id=" P02-1025.xml">a study on richer syntactic dependencies for structured language modeling </title>
<section> enriching syntactic dependencies.  </section>
<citcontext>
<prevsection>
<prevsent>however, as mentioned in (roark, 2001), oneway of conditioning the probabilities is by annotating the extra conditioning information onto the node labels in the parse tree.
</prevsent>
<prevsent>we can annotate the training corpus with richer information and with the sameslm training procedure we can estimate the probabilities under the richer syntactic tags.
</prevsent>
</prevsection>
<citsent citstr=" J98-4004 ">
since the treebank parses allow us to annotate parent information onto the constituents, as johnson did in (johnson, 1998), <papid> J98-4004 </papid>this richer predictive annotation can extend information slightly beyond the left context.</citsent>
<aftsection>
<nextsent>under the equivalence classification ineq.( 2, 3, 4), the conditional information available to the slm model components is made up of the two most-recent exposed heads consisting of two nt tags and two headwords.
</nextsent>
<nextsent>in an attempt to extend the syntactic dependencies beyond this level, we enrich the non-terminal tag of node in the binarized parse tree with the nt tag of the parent node, or the nt tag of the child node from which the headword is not being percolated (same as in (chelba and xu, 2001)), or we add the nt tag of the third most-recent exposed head to the history of the constructor component.
</nextsent>
<nextsent>the three ways are briefly described as: 1.
</nextsent>
<nextsent>opposite (op): we use the non-terminal tag of the child node from which the headword is not being percolated 2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1549">
<title id=" P02-1025.xml">a study on richer syntactic dependencies for structured language modeling </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>see (chelba and jelinek, 2000) for details about special rules.
</prevsent>
<prevsent>and the average size was about 23.
</prevsent>
</prevsection>
<citsent citstr=" W97-0301 ">
the slm was trained on 20m words of wsj text automatically parsed using the parser in (ratnaparkhi, 1997), <papid> W97-0301 </papid>bi narized and enriched with headwords and nt/postag information as explained in section 2.2 and section 3.</citsent>
<aftsection>
<nextsent>because slm training on the 20m words ofwsj text is very expensive, especially after enriching the nt/pos tags, we only evaluated the werperformance of the seven models with initial statistics from binarized and enriched parse trees.
</nextsent>
<nextsent>the results are shown in table 4.
</nextsent>
<nextsent>the table shows not only the results according to different interpolation weights  , but also the results corresponding to   , virtual interpolation weight.
</nextsent>
<nextsent>we split the test data into two parts,  and  . the best interpolation weight, estimated from part  , was used to deco depart  , and vice versa.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1559">
<title id=" P02-1025.xml">a study on richer syntactic dependencies for structured language modeling </title>
<section> conclusion and future work.  </section>
<citcontext>
<prevsection>
<prevsent>furthermore, our best result shows that an un interpolated grammar-based language model can outperform 3-gram model.
</prevsent>
<prevsent>the best model achieved an overall wer improvement of 10% relative to the 3-gram baseline.although conditioning on more contextual information helps, we should note that some of our models suffer from over-parameterization.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
one solution would be to apply the maximum entropy estimation technique (maxent (berger et al, 1996)) <papid> J96-1002 </papid>to all of the three components of the slm, or at least to the constructor.</citsent>
<aftsection>
<nextsent>that would also allow for fine-tuning of the particular syntactic dependencies used in the model rather than the template based method we have used.
</nextsent>
<nextsent>along these lines, the maxent model has already shown promising improvements by combining syntactic dependencies in theword-predictor of the slm (wu and khudanpur, 1999).
</nextsent>


</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1560">
<title id=" N12-1073.xml">context enhanced citation sentiment detection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>negative sentiment is politically particularly dangerous (ziman, 1968), andsome authors have documented the strategy of prefacing the intended criticism by slightly disingenuous praise (macroberts and mac roberts, 1984).
</prevsent>
<prevsent>this makes the problem of identifying such opinions particularly challenging.
</prevsent>
</prevsection>
<citsent citstr=" J09-3003 ">
this non-local expression of sentiment has been observed in other genres as well (wilson et al, 2009; <papid> J09-3003 </papid>polanyi and zaenen, 2006).</citsent>
<aftsection>
<nextsent>figure 1: example of anaphora in citations typical case is illustrated in figure 1.
</nextsent>
<nextsent>while the first sentence praises some aspects of the cited paper, the remaining sentences list its shortcomings.
</nextsent>
<nextsent>it is clear that criticism is the intended sentiment, but 597 if we define our gold standard only by looking at the citation sentence, we lose significant amount of sentiment hidden in the text.
</nextsent>
<nextsent>given that most citations are neutral (spiegel-rosing, 1977; teufel etal., 2006), <papid> W06-1613 </papid>this makes it ever more important to recover what explicit sentiment there is from the context of the citation.however, the dominant assumption in current citation identification methods (ritchie et al, 2008; radev et al, 2009) is that the sentiment present in the citation sentence represents the true sentiment of the author towards the cited paper.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1561">
<title id=" N12-1073.xml">context enhanced citation sentiment detection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>while the first sentence praises some aspects of the cited paper, the remaining sentences list its shortcomings.
</prevsent>
<prevsent>it is clear that criticism is the intended sentiment, but 597 if we define our gold standard only by looking at the citation sentence, we lose significant amount of sentiment hidden in the text.
</prevsent>
</prevsection>
<citsent citstr=" W06-1613 ">
given that most citations are neutral (spiegel-rosing, 1977; teufel etal., 2006), <papid> W06-1613 </papid>this makes it ever more important to recover what explicit sentiment there is from the context of the citation.however, the dominant assumption in current citation identification methods (ritchie et al, 2008; radev et al, 2009) is that the sentiment present in the citation sentence represents the true sentiment of the author towards the cited paper.</citsent>
<aftsection>
<nextsent>this is due to the difficulty of determining the relevant context,whereas it is substantially easier to identify the citation sentence.
</nextsent>
<nextsent>in our example above, however, such an approach would lead to the wrong prediction of praise or neutral sentiment.in this paper, we address the problem of context enhanced citation sentiment detection.
</nextsent>
<nextsent>we present new citation sentiment corpus where each citation has been annotated according to the dominant sentiment in the corresponding citation context.
</nextsent>
<nextsent>weclaim that this corpus is closer to the truth than annotation that considers only the citation sentence it self.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1562">
<title id=" N12-1073.xml">context enhanced citation sentiment detection </title>
<section> corpus construction.  </section>
<citcontext>
<prevsection>
<prevsent>using this gold standard, we explore the effect of assuming context windows of different but fixed length son the performance of state-of-the-art citation sentiment detection system where the sentiment of citation is considered in the entire context of the citation and more than one single sentiment can beassigned.
</prevsent>
<prevsent>previous approaches neither detect citation sentiment and context simultaneously nor use as large corpus as we do.
</prevsent>
</prevsection>
<citsent citstr=" P11-3015 ">
we chose the dataset used by athar (2011) <papid> P11-3015 </papid>comprising 310 papers taken from the acl anthology (bird et al, 2008).<papid> L08-1005 </papid></citsent>
<aftsection>
<nextsent>the citation summary data from the acl anthology network1 (radev et al, 2009) was used.
</nextsent>
<nextsent>this dataset is rather large (8736 citations) and since manual annotation of context for each citation is time consuming task, subset of 20 papers were selected corresponding to approximately 20% of the original dataset.
</nextsent>
<nextsent>1http://www.aclweb.org we selected four-class scheme for annotation.
</nextsent>
<nextsent>every sentence that is in window of 4 sentences of the citation and does not contain any direct or in direct mention of the citation was labelled as being excluded (x).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1563">
<title id=" N12-1073.xml">context enhanced citation sentiment detection </title>
<section> corpus construction.  </section>
<citcontext>
<prevsection>
<prevsent>using this gold standard, we explore the effect of assuming context windows of different but fixed length son the performance of state-of-the-art citation sentiment detection system where the sentiment of citation is considered in the entire context of the citation and more than one single sentiment can beassigned.
</prevsent>
<prevsent>previous approaches neither detect citation sentiment and context simultaneously nor use as large corpus as we do.
</prevsent>
</prevsection>
<citsent citstr=" L08-1005 ">
we chose the dataset used by athar (2011) <papid> P11-3015 </papid>comprising 310 papers taken from the acl anthology (bird et al, 2008).<papid> L08-1005 </papid></citsent>
<aftsection>
<nextsent>the citation summary data from the acl anthology network1 (radev et al, 2009) was used.
</nextsent>
<nextsent>this dataset is rather large (8736 citations) and since manual annotation of context for each citation is time consuming task, subset of 20 papers were selected corresponding to approximately 20% of the original dataset.
</nextsent>
<nextsent>1http://www.aclweb.org we selected four-class scheme for annotation.
</nextsent>
<nextsent>every sentence that is in window of 4 sentences of the citation and does not contain any direct or in direct mention of the citation was labelled as being excluded (x).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1564">
<title id=" N12-1073.xml">context enhanced citation sentiment detection </title>
<section> corpus construction.  </section>
<citcontext>
<prevsection>
<prevsent>1http://www.aclweb.org we selected four-class scheme for annotation.
</prevsent>
<prevsent>every sentence that is in window of 4 sentences of the citation and does not contain any direct or in direct mention of the citation was labelled as being excluded (x).
</prevsent>
</prevsection>
<citsent citstr=" P10-1057 ">
the window length was motivated by recent research (qazvinian and radev, 2010) <papid> P10-1057 </papid>which shows the best score for four-sentence boundary when detecting non-explicit citation.</citsent>
<aftsection>
<nextsent>the rest of the sentences were marked either positive (p), negative (n) or objective/neutral (o).a total of 1,741 citations were annotated.
</nextsent>
<nextsent>although this annotation was performed by the first author only, we know from previous work that similar styles of annotation can achieve acceptable inter annotator agreement (teufel et al, 2006).<papid> W06-1613 </papid></nextsent>
<nextsent>an example annotation for smadja (1993) is given in figure 2, where the first column shows the line number and the second one shows the class label.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1567">
<title id=" N12-1073.xml">context enhanced citation sentiment detection </title>
<section> experiments and results.  </section>
<citcontext>
<prevsection>
<prevsent>without context with context 87% 73% 5% 17% 8% 11% table 1: distribution of classes.
</prevsent>
<prevsent>we represent each citation as feature set in support vector machine (svm) (cortes and vapnik, 1995) framework and use n-grams of length 1 to 3as well as dependency triplets as features.
</prevsent>
</prevsection>
<citsent citstr=" W02-1011 ">
the dependency triplets are constructed by merging there lation, governor and dependent in single string, for instance, the relation nsubj(failed, method) is represented as nsubj failed method . this setup has been shown to produce good results earlier as well (pang et al, 2002; <papid> W02-1011 </papid>athar, 2011).<papid> P11-3015 </papid>the first set of experiments focuses on simultaneous detection of sentiment and context sentences.</citsent>
<aftsection>
<nextsent>for this purpose, we use the four-class annotated corpus described earlier.
</nextsent>
<nextsent>while the original annotations were performed for window of length 4, we also experiment with asymmetrical windows of lsentences preceding the citation and sentences succeeding it.
</nextsent>
<nextsent>the detailed results are given in table 2.
</nextsent>
<nextsent>l x n fmacro fmicro 0 0 - 1509 86 146 0.768 0.932 1 1 2823 1982 216 200 0.737 0.820 2 2 5984 2214 273 218 0.709 0.851 3 3 9170 2425 318 234 0.672 0.875 0 4 5963 2171 322 215 0.712 0.853 0 3 4380 2070 293 201 0.702 0.832 0 2 2817 1945 258 193 0.701 0.801 0 1 1280 1812 206 182 0.717 0.777table 2: results for joint context and sentiment detection.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1576">
<title id=" N12-1073.xml">context enhanced citation sentiment detection </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, this work doesnot handle citation context.
</prevsent>
<prevsent>piao et al (2007) proposed system to attach sentiment information tothe citation links between biomedical papers by using existing semantic lexical resources.
</prevsent>
</prevsection>
<citsent citstr=" P97-1023 ">
a common approach for sentiment detection is touse labelled lexicon to score sentences (hatzivas siloglou and mckeown, 1997; <papid> P97-1023 </papid>turney, 2002; <papid> P02-1053 </papid>yu and hatzivassiloglou, 2003).<papid> W03-1017 </papid></citsent>
<aftsection>
<nextsent>however, such approaches 599have been found to be highly topic dependent (en gstrom, 2004; gamon and aue, 2005; <papid> W05-0408 </papid>blitzer et al, 2007).<papid> P07-1056 </papid>teufel et al (2006) <papid> W06-1613 </papid>worked on 2,829 sentence citation corpus using 12-class classification scheme.</nextsent>
<nextsent>although they used context in their annotation, their focus was on determining the authors reason for citing given paper.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1577">
<title id=" N12-1073.xml">context enhanced citation sentiment detection </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, this work doesnot handle citation context.
</prevsent>
<prevsent>piao et al (2007) proposed system to attach sentiment information tothe citation links between biomedical papers by using existing semantic lexical resources.
</prevsent>
</prevsection>
<citsent citstr=" P02-1053 ">
a common approach for sentiment detection is touse labelled lexicon to score sentences (hatzivas siloglou and mckeown, 1997; <papid> P97-1023 </papid>turney, 2002; <papid> P02-1053 </papid>yu and hatzivassiloglou, 2003).<papid> W03-1017 </papid></citsent>
<aftsection>
<nextsent>however, such approaches 599have been found to be highly topic dependent (en gstrom, 2004; gamon and aue, 2005; <papid> W05-0408 </papid>blitzer et al, 2007).<papid> P07-1056 </papid>teufel et al (2006) <papid> W06-1613 </papid>worked on 2,829 sentence citation corpus using 12-class classification scheme.</nextsent>
<nextsent>although they used context in their annotation, their focus was on determining the authors reason for citing given paper.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1578">
<title id=" N12-1073.xml">context enhanced citation sentiment detection </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, this work doesnot handle citation context.
</prevsent>
<prevsent>piao et al (2007) proposed system to attach sentiment information tothe citation links between biomedical papers by using existing semantic lexical resources.
</prevsent>
</prevsection>
<citsent citstr=" W03-1017 ">
a common approach for sentiment detection is touse labelled lexicon to score sentences (hatzivas siloglou and mckeown, 1997; <papid> P97-1023 </papid>turney, 2002; <papid> P02-1053 </papid>yu and hatzivassiloglou, 2003).<papid> W03-1017 </papid></citsent>
<aftsection>
<nextsent>however, such approaches 599have been found to be highly topic dependent (en gstrom, 2004; gamon and aue, 2005; <papid> W05-0408 </papid>blitzer et al, 2007).<papid> P07-1056 </papid>teufel et al (2006) <papid> W06-1613 </papid>worked on 2,829 sentence citation corpus using 12-class classification scheme.</nextsent>
<nextsent>although they used context in their annotation, their focus was on determining the authors reason for citing given paper.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1579">
<title id=" N12-1073.xml">context enhanced citation sentiment detection </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>piao et al (2007) proposed system to attach sentiment information tothe citation links between biomedical papers by using existing semantic lexical resources.
</prevsent>
<prevsent>a common approach for sentiment detection is touse labelled lexicon to score sentences (hatzivas siloglou and mckeown, 1997; <papid> P97-1023 </papid>turney, 2002; <papid> P02-1053 </papid>yu and hatzivassiloglou, 2003).<papid> W03-1017 </papid></prevsent>
</prevsection>
<citsent citstr=" W05-0408 ">
however, such approaches 599have been found to be highly topic dependent (en gstrom, 2004; gamon and aue, 2005; <papid> W05-0408 </papid>blitzer et al, 2007).<papid> P07-1056 </papid>teufel et al (2006) <papid> W06-1613 </papid>worked on 2,829 sentence citation corpus using 12-class classification scheme.</citsent>
<aftsection>
<nextsent>although they used context in their annotation, their focus was on determining the authors reason for citing given paper.
</nextsent>
<nextsent>this task differs from citation sentiment, which is in sense lower level?
</nextsent>
<nextsent>of analysis.
</nextsent>
<nextsent>for implicit citation extraction, kaplan et al(2009) <papid> W09-3611 </papid>explore co-reference chains for citation extraction using combination of co-reference resolution techniques.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1580">
<title id=" N12-1073.xml">context enhanced citation sentiment detection </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>piao et al (2007) proposed system to attach sentiment information tothe citation links between biomedical papers by using existing semantic lexical resources.
</prevsent>
<prevsent>a common approach for sentiment detection is touse labelled lexicon to score sentences (hatzivas siloglou and mckeown, 1997; <papid> P97-1023 </papid>turney, 2002; <papid> P02-1053 </papid>yu and hatzivassiloglou, 2003).<papid> W03-1017 </papid></prevsent>
</prevsection>
<citsent citstr=" P07-1056 ">
however, such approaches 599have been found to be highly topic dependent (en gstrom, 2004; gamon and aue, 2005; <papid> W05-0408 </papid>blitzer et al, 2007).<papid> P07-1056 </papid>teufel et al (2006) <papid> W06-1613 </papid>worked on 2,829 sentence citation corpus using 12-class classification scheme.</citsent>
<aftsection>
<nextsent>although they used context in their annotation, their focus was on determining the authors reason for citing given paper.
</nextsent>
<nextsent>this task differs from citation sentiment, which is in sense lower level?
</nextsent>
<nextsent>of analysis.
</nextsent>
<nextsent>for implicit citation extraction, kaplan et al(2009) <papid> W09-3611 </papid>explore co-reference chains for citation extraction using combination of co-reference resolution techniques.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1582">
<title id=" N12-1073.xml">context enhanced citation sentiment detection </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>this task differs from citation sentiment, which is in sense lower level?
</prevsent>
<prevsent>of analysis.
</prevsent>
</prevsection>
<citsent citstr=" W09-3611 ">
for implicit citation extraction, kaplan et al(2009) <papid> W09-3611 </papid>explore co-reference chains for citation extraction using combination of co-reference resolution techniques.</citsent>
<aftsection>
<nextsent>however, their corpus consists of only 94 sentences of citations to 4 papers which is likely to be too small to be representative.
</nextsent>
<nextsent>the most relevant work is by qazvinian and radev (2010) <papid> P10-1057 </papid>who extract only the non-explicit citations forgiven paper.</nextsent>
<nextsent>they model each sentence as anode in graph and experiment with various window boundaries to create edges between neighbouring nodes.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1584">
<title id=" N12-1073.xml">context enhanced citation sentiment detection </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>we also report the results of the state-of-the-art citation sentiment detection systems on this corpus when using this context-enhanced gold standard definition.
</prevsent>
<prevsent>future work directions may include improving the detection algorithms by filtering the context sentences more intelligently.
</prevsent>
</prevsection>
<citsent citstr=" W11-1902 ">
for this purpose, existing work on coreference resolution (lee et al, 2011) <papid> W11-1902 </papid>may prove to be useful.</citsent>
<aftsection>
<nextsent>context features may also be used for first filtering citations which have been mentioned only in passing, and then applying context based sentiment classification to the remaining significant citations.
</nextsent>



</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1585">
<title id=" P02-1038.xml">discriminative training and maximum entropy models for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>decision rule, we can equivalently to eq.
</prevsent>
<prevsent>1 perform the following maximization: ei1 = argmax ei1 {pr(ei1) ? pr(fj1 |ei1)} (2)this approach is referred to as source-channel approach to statistical mt. sometimes, it is also referred to as the fundamental equation of statistical mt?
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
(brown et al, 1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>here, pr(ei1) is the language model of the target language, whereas pr(fj1 |ei1) is the translation model.
</nextsent>
<nextsent>typically, eq.
</nextsent>
<nextsent>2 is favored over the direct translation model of eq.
</nextsent>
<nextsent>1 with the argument that it yields modular approach.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1587">
<title id=" P02-1038.xml">discriminative training and maximum entropy models for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>often, we observe that comparable results are.
</prevsent>
<prevsent>obtained by using the following decision rule instead of eq.
</prevsent>
</prevsection>
<citsent citstr=" W99-0604 ">
5 (och et al, 1999): <papid> W99-0604 </papid>ei1 = argmax ei1 {p??(ei1) ? p??(ei1|fj1 )} (6) here, we replaced p??(fj1 |ei1) by p??(ei1|fj1 ).from theoretical framework of the source channel approach, this approach is hard to jus tify.</citsent>
<aftsection>
<nextsent>yet, if both decision rules yield the same translation quality, we can use that decision rule which is better suited for efficient search.
</nextsent>
<nextsent>1.2 direct maximum entropy translation.
</nextsent>
<nextsent>model as alternative to the source-channel approach, we directly model the posterior probability pr(ei1|fj1 ).
</nextsent>
<nextsent>an especially well-founded framework for doing this is maximum entropy (berger et al, 1996).<papid> J96-1002 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1588">
<title id=" P02-1038.xml">discriminative training and maximum entropy models for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>1.2 direct maximum entropy translation.
</prevsent>
<prevsent>model as alternative to the source-channel approach, we directly model the posterior probability pr(ei1|fj1 ).
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
an especially well-founded framework for doing this is maximum entropy (berger et al, 1996).<papid> J96-1002 </papid></citsent>
<aftsection>
<nextsent>inthis framework, we have set of feature functions hm(ei1, fj1 ),m = 1, . . .
</nextsent>
<nextsent>,m . for each feature function, there exists model parameter m,m = 1, . . .
</nextsent>
<nextsent>,m . the direct translation probability is given source language text ??
</nextsent>
<nextsent>preprocessing ??
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1599">
<title id=" P04-1037.xml">unsupervised sense disambiguation using bilingual probabilistic models </title>
<section> abstract </section>
<citcontext>
<prevsection>

<prevsent>we describe two probabilistic models for unsupervised word-sense disambiguation using parallel corpora.
</prevsent>
</prevsection>
<citsent citstr=" P02-1033 ">
the first model, which we call the sense model, builds on the work of diab and resnik(2002) <papid> P02-1033 </papid>that uses both parallel text and sense inventory for the target language, and recasts their approach in probabilistic framework.</citsent>
<aftsection>
<nextsent>the second model, which we call the concept model, is hierarchical model that uses concept latent variable to relate different language specific sense labels.
</nextsent>
<nextsent>we show that both models improve performance on theword sense disambiguation task over previous unsupervised approaches, with the concept model showing the largest improvement.
</nextsent>
<nextsent>furthermore, in learning the concept model, as by-product, we learn sense inventory for the parallel language.
</nextsent>
<nextsent>word sense disambiguation (wsd) has been central question in the computational linguistics community since its inception.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1600">
<title id=" P04-1037.xml">unsupervised sense disambiguation using bilingual probabilistic models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>furthermore, in learning the concept model, as by-product, we learn sense inventory for the parallel language.
</prevsent>
<prevsent>word sense disambiguation (wsd) has been central question in the computational linguistics community since its inception.
</prevsent>
</prevsection>
<citsent citstr=" J98-1001 ">
wsd is fundamental to natural language understanding and is useful intermediate step for many other language processing tasks (ide and veronis, 1998).<papid> J98-1001 </papid></citsent>
<aftsection>
<nextsent>many recent approaches make use of ideas from statistical machine learning; the availability of shared sense definitions (e.g. wordnet (fellbaum, 1998)) and recent international competitions (kilgarrif and rosenzweig, 2000) have enabled researchers to compare their results.
</nextsent>
<nextsent>supervised approaches which make use of small hand-labeled training set (bruceand wiebe, 1994; <papid> H94-1047 </papid>yarowsky, 1993) <papid> H93-1052 </papid>typically out perform unsupervised approaches (agirre et al, 2000; litkowski, 2000; lin, 2000; resnik, 1997; <papid> W97-0209 </papid>yarowsky, 1992; <papid> C92-2070 </papid>yarowsky, 1995), <papid> P95-1026 </papid>but tend to be tuned to specific corpus and are constrained by scarcity of labeled data.in an effort to overcome the difficulty of finding sense-labeled training data, researchers have begun investigating unsupervised approaches to word sense disambiguation.</nextsent>
<nextsent>for example, the use of parallel corpora for sense tagging can help with word sense disambiguation (brown et al, 1991; <papid> P91-1034 </papid>dagan, 1991; <papid> P91-1048 </papid>dagan and itai, 1994; <papid> J94-4003 </papid>ide, 2000; resnik and yarowsky, 1999).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1601">
<title id=" P04-1037.xml">unsupervised sense disambiguation using bilingual probabilistic models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>wsd is fundamental to natural language understanding and is useful intermediate step for many other language processing tasks (ide and veronis, 1998).<papid> J98-1001 </papid></prevsent>
<prevsent>many recent approaches make use of ideas from statistical machine learning; the availability of shared sense definitions (e.g. wordnet (fellbaum, 1998)) and recent international competitions (kilgarrif and rosenzweig, 2000) have enabled researchers to compare their results.</prevsent>
</prevsection>
<citsent citstr=" H94-1047 ">
supervised approaches which make use of small hand-labeled training set (bruceand wiebe, 1994; <papid> H94-1047 </papid>yarowsky, 1993) <papid> H93-1052 </papid>typically out perform unsupervised approaches (agirre et al, 2000; litkowski, 2000; lin, 2000; resnik, 1997; <papid> W97-0209 </papid>yarowsky, 1992; <papid> C92-2070 </papid>yarowsky, 1995), <papid> P95-1026 </papid>but tend to be tuned to specific corpus and are constrained by scarcity of labeled data.in an effort to overcome the difficulty of finding sense-labeled training data, researchers have begun investigating unsupervised approaches to word sense disambiguation.</citsent>
<aftsection>
<nextsent>for example, the use of parallel corpora for sense tagging can help with word sense disambiguation (brown et al, 1991; <papid> P91-1034 </papid>dagan, 1991; <papid> P91-1048 </papid>dagan and itai, 1994; <papid> J94-4003 </papid>ide, 2000; resnik and yarowsky, 1999).</nextsent>
<nextsent>as an illustration of sense disambiguation from translation data, when the english word bank is translated to spanish as orilla, it is clear that we are referring to the shore sense of bank, rather than the nancial institution sense.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1602">
<title id=" P04-1037.xml">unsupervised sense disambiguation using bilingual probabilistic models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>wsd is fundamental to natural language understanding and is useful intermediate step for many other language processing tasks (ide and veronis, 1998).<papid> J98-1001 </papid></prevsent>
<prevsent>many recent approaches make use of ideas from statistical machine learning; the availability of shared sense definitions (e.g. wordnet (fellbaum, 1998)) and recent international competitions (kilgarrif and rosenzweig, 2000) have enabled researchers to compare their results.</prevsent>
</prevsection>
<citsent citstr=" H93-1052 ">
supervised approaches which make use of small hand-labeled training set (bruceand wiebe, 1994; <papid> H94-1047 </papid>yarowsky, 1993) <papid> H93-1052 </papid>typically out perform unsupervised approaches (agirre et al, 2000; litkowski, 2000; lin, 2000; resnik, 1997; <papid> W97-0209 </papid>yarowsky, 1992; <papid> C92-2070 </papid>yarowsky, 1995), <papid> P95-1026 </papid>but tend to be tuned to specific corpus and are constrained by scarcity of labeled data.in an effort to overcome the difficulty of finding sense-labeled training data, researchers have begun investigating unsupervised approaches to word sense disambiguation.</citsent>
<aftsection>
<nextsent>for example, the use of parallel corpora for sense tagging can help with word sense disambiguation (brown et al, 1991; <papid> P91-1034 </papid>dagan, 1991; <papid> P91-1048 </papid>dagan and itai, 1994; <papid> J94-4003 </papid>ide, 2000; resnik and yarowsky, 1999).</nextsent>
<nextsent>as an illustration of sense disambiguation from translation data, when the english word bank is translated to spanish as orilla, it is clear that we are referring to the shore sense of bank, rather than the nancial institution sense.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1603">
<title id=" P04-1037.xml">unsupervised sense disambiguation using bilingual probabilistic models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>wsd is fundamental to natural language understanding and is useful intermediate step for many other language processing tasks (ide and veronis, 1998).<papid> J98-1001 </papid></prevsent>
<prevsent>many recent approaches make use of ideas from statistical machine learning; the availability of shared sense definitions (e.g. wordnet (fellbaum, 1998)) and recent international competitions (kilgarrif and rosenzweig, 2000) have enabled researchers to compare their results.</prevsent>
</prevsection>
<citsent citstr=" W97-0209 ">
supervised approaches which make use of small hand-labeled training set (bruceand wiebe, 1994; <papid> H94-1047 </papid>yarowsky, 1993) <papid> H93-1052 </papid>typically out perform unsupervised approaches (agirre et al, 2000; litkowski, 2000; lin, 2000; resnik, 1997; <papid> W97-0209 </papid>yarowsky, 1992; <papid> C92-2070 </papid>yarowsky, 1995), <papid> P95-1026 </papid>but tend to be tuned to specific corpus and are constrained by scarcity of labeled data.in an effort to overcome the difficulty of finding sense-labeled training data, researchers have begun investigating unsupervised approaches to word sense disambiguation.</citsent>
<aftsection>
<nextsent>for example, the use of parallel corpora for sense tagging can help with word sense disambiguation (brown et al, 1991; <papid> P91-1034 </papid>dagan, 1991; <papid> P91-1048 </papid>dagan and itai, 1994; <papid> J94-4003 </papid>ide, 2000; resnik and yarowsky, 1999).</nextsent>
<nextsent>as an illustration of sense disambiguation from translation data, when the english word bank is translated to spanish as orilla, it is clear that we are referring to the shore sense of bank, rather than the nancial institution sense.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1604">
<title id=" P04-1037.xml">unsupervised sense disambiguation using bilingual probabilistic models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>wsd is fundamental to natural language understanding and is useful intermediate step for many other language processing tasks (ide and veronis, 1998).<papid> J98-1001 </papid></prevsent>
<prevsent>many recent approaches make use of ideas from statistical machine learning; the availability of shared sense definitions (e.g. wordnet (fellbaum, 1998)) and recent international competitions (kilgarrif and rosenzweig, 2000) have enabled researchers to compare their results.</prevsent>
</prevsection>
<citsent citstr=" C92-2070 ">
supervised approaches which make use of small hand-labeled training set (bruceand wiebe, 1994; <papid> H94-1047 </papid>yarowsky, 1993) <papid> H93-1052 </papid>typically out perform unsupervised approaches (agirre et al, 2000; litkowski, 2000; lin, 2000; resnik, 1997; <papid> W97-0209 </papid>yarowsky, 1992; <papid> C92-2070 </papid>yarowsky, 1995), <papid> P95-1026 </papid>but tend to be tuned to specific corpus and are constrained by scarcity of labeled data.in an effort to overcome the difficulty of finding sense-labeled training data, researchers have begun investigating unsupervised approaches to word sense disambiguation.</citsent>
<aftsection>
<nextsent>for example, the use of parallel corpora for sense tagging can help with word sense disambiguation (brown et al, 1991; <papid> P91-1034 </papid>dagan, 1991; <papid> P91-1048 </papid>dagan and itai, 1994; <papid> J94-4003 </papid>ide, 2000; resnik and yarowsky, 1999).</nextsent>
<nextsent>as an illustration of sense disambiguation from translation data, when the english word bank is translated to spanish as orilla, it is clear that we are referring to the shore sense of bank, rather than the nancial institution sense.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1605">
<title id=" P04-1037.xml">unsupervised sense disambiguation using bilingual probabilistic models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>wsd is fundamental to natural language understanding and is useful intermediate step for many other language processing tasks (ide and veronis, 1998).<papid> J98-1001 </papid></prevsent>
<prevsent>many recent approaches make use of ideas from statistical machine learning; the availability of shared sense definitions (e.g. wordnet (fellbaum, 1998)) and recent international competitions (kilgarrif and rosenzweig, 2000) have enabled researchers to compare their results.</prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
supervised approaches which make use of small hand-labeled training set (bruceand wiebe, 1994; <papid> H94-1047 </papid>yarowsky, 1993) <papid> H93-1052 </papid>typically out perform unsupervised approaches (agirre et al, 2000; litkowski, 2000; lin, 2000; resnik, 1997; <papid> W97-0209 </papid>yarowsky, 1992; <papid> C92-2070 </papid>yarowsky, 1995), <papid> P95-1026 </papid>but tend to be tuned to specific corpus and are constrained by scarcity of labeled data.in an effort to overcome the difficulty of finding sense-labeled training data, researchers have begun investigating unsupervised approaches to word sense disambiguation.</citsent>
<aftsection>
<nextsent>for example, the use of parallel corpora for sense tagging can help with word sense disambiguation (brown et al, 1991; <papid> P91-1034 </papid>dagan, 1991; <papid> P91-1048 </papid>dagan and itai, 1994; <papid> J94-4003 </papid>ide, 2000; resnik and yarowsky, 1999).</nextsent>
<nextsent>as an illustration of sense disambiguation from translation data, when the english word bank is translated to spanish as orilla, it is clear that we are referring to the shore sense of bank, rather than the nancial institution sense.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1606">
<title id=" P04-1037.xml">unsupervised sense disambiguation using bilingual probabilistic models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>many recent approaches make use of ideas from statistical machine learning; the availability of shared sense definitions (e.g. wordnet (fellbaum, 1998)) and recent international competitions (kilgarrif and rosenzweig, 2000) have enabled researchers to compare their results.
</prevsent>
<prevsent>supervised approaches which make use of small hand-labeled training set (bruceand wiebe, 1994; <papid> H94-1047 </papid>yarowsky, 1993) <papid> H93-1052 </papid>typically out perform unsupervised approaches (agirre et al, 2000; litkowski, 2000; lin, 2000; resnik, 1997; <papid> W97-0209 </papid>yarowsky, 1992; <papid> C92-2070 </papid>yarowsky, 1995), <papid> P95-1026 </papid>but tend to be tuned to specific corpus and are constrained by scarcity of labeled data.in an effort to overcome the difficulty of finding sense-labeled training data, researchers have begun investigating unsupervised approaches to word sense disambiguation.</prevsent>
</prevsection>
<citsent citstr=" P91-1034 ">
for example, the use of parallel corpora for sense tagging can help with word sense disambiguation (brown et al, 1991; <papid> P91-1034 </papid>dagan, 1991; <papid> P91-1048 </papid>dagan and itai, 1994; <papid> J94-4003 </papid>ide, 2000; resnik and yarowsky, 1999).</citsent>
<aftsection>
<nextsent>as an illustration of sense disambiguation from translation data, when the english word bank is translated to spanish as orilla, it is clear that we are referring to the shore sense of bank, rather than the nancial institution sense.
</nextsent>
<nextsent>the main inspiration for our work is diab and resnik (2002), <papid> P02-1033 </papid>who use translations and linguistic knowledge for disambiguation and automatic sense tagging.</nextsent>
<nextsent>bengio and kermorvant (2003) present graphical model that is an attempt to formalize probabilistically the main ideas in diab and resnik (2002).<papid> P02-1033 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1607">
<title id=" P04-1037.xml">unsupervised sense disambiguation using bilingual probabilistic models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>many recent approaches make use of ideas from statistical machine learning; the availability of shared sense definitions (e.g. wordnet (fellbaum, 1998)) and recent international competitions (kilgarrif and rosenzweig, 2000) have enabled researchers to compare their results.
</prevsent>
<prevsent>supervised approaches which make use of small hand-labeled training set (bruceand wiebe, 1994; <papid> H94-1047 </papid>yarowsky, 1993) <papid> H93-1052 </papid>typically out perform unsupervised approaches (agirre et al, 2000; litkowski, 2000; lin, 2000; resnik, 1997; <papid> W97-0209 </papid>yarowsky, 1992; <papid> C92-2070 </papid>yarowsky, 1995), <papid> P95-1026 </papid>but tend to be tuned to specific corpus and are constrained by scarcity of labeled data.in an effort to overcome the difficulty of finding sense-labeled training data, researchers have begun investigating unsupervised approaches to word sense disambiguation.</prevsent>
</prevsection>
<citsent citstr=" P91-1048 ">
for example, the use of parallel corpora for sense tagging can help with word sense disambiguation (brown et al, 1991; <papid> P91-1034 </papid>dagan, 1991; <papid> P91-1048 </papid>dagan and itai, 1994; <papid> J94-4003 </papid>ide, 2000; resnik and yarowsky, 1999).</citsent>
<aftsection>
<nextsent>as an illustration of sense disambiguation from translation data, when the english word bank is translated to spanish as orilla, it is clear that we are referring to the shore sense of bank, rather than the nancial institution sense.
</nextsent>
<nextsent>the main inspiration for our work is diab and resnik (2002), <papid> P02-1033 </papid>who use translations and linguistic knowledge for disambiguation and automatic sense tagging.</nextsent>
<nextsent>bengio and kermorvant (2003) present graphical model that is an attempt to formalize probabilistically the main ideas in diab and resnik (2002).<papid> P02-1033 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1608">
<title id=" P04-1037.xml">unsupervised sense disambiguation using bilingual probabilistic models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>many recent approaches make use of ideas from statistical machine learning; the availability of shared sense definitions (e.g. wordnet (fellbaum, 1998)) and recent international competitions (kilgarrif and rosenzweig, 2000) have enabled researchers to compare their results.
</prevsent>
<prevsent>supervised approaches which make use of small hand-labeled training set (bruceand wiebe, 1994; <papid> H94-1047 </papid>yarowsky, 1993) <papid> H93-1052 </papid>typically out perform unsupervised approaches (agirre et al, 2000; litkowski, 2000; lin, 2000; resnik, 1997; <papid> W97-0209 </papid>yarowsky, 1992; <papid> C92-2070 </papid>yarowsky, 1995), <papid> P95-1026 </papid>but tend to be tuned to specific corpus and are constrained by scarcity of labeled data.in an effort to overcome the difficulty of finding sense-labeled training data, researchers have begun investigating unsupervised approaches to word sense disambiguation.</prevsent>
</prevsection>
<citsent citstr=" J94-4003 ">
for example, the use of parallel corpora for sense tagging can help with word sense disambiguation (brown et al, 1991; <papid> P91-1034 </papid>dagan, 1991; <papid> P91-1048 </papid>dagan and itai, 1994; <papid> J94-4003 </papid>ide, 2000; resnik and yarowsky, 1999).</citsent>
<aftsection>
<nextsent>as an illustration of sense disambiguation from translation data, when the english word bank is translated to spanish as orilla, it is clear that we are referring to the shore sense of bank, rather than the nancial institution sense.
</nextsent>
<nextsent>the main inspiration for our work is diab and resnik (2002), <papid> P02-1033 </papid>who use translations and linguistic knowledge for disambiguation and automatic sense tagging.</nextsent>
<nextsent>bengio and kermorvant (2003) present graphical model that is an attempt to formalize probabilistically the main ideas in diab and resnik (2002).<papid> P02-1033 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1631">
<title id=" N12-1074.xml">predicting responses to microblog posts </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>popescu and jain (2011) explored how businesses use twitter to connect with their customer base.
</prevsent>
<prevsent>popescu and pennacchiotti (2011) and qu et al (2011) investigated 602 how users react to events on social media.
</prevsent>
</prevsection>
<citsent citstr=" N10-1020 ">
there also has been extensive work on modeling conversational interactions on twitter (honeycutt and her ring, 2009; boyd et al, 2010; ritter et al, 2010; <papid> N10-1020 </papid>danescu-niculescu-mizil et al, 2011).</citsent>
<aftsection>
<nextsent>our work builds on these findings to predict response behavior on large scale.mining twitter social media has been used to detect events (sakaki et al, 2010; popescu and pennacchiotti, 2010; popescu et al, 2011), and even predict their outcomes (asur and hub erman, 2010; culotta, 2010).
</nextsent>
<nextsent>similarly to this line of work, we mine the social network for event prediction.
</nextsent>
<nextsent>in contrast, our focus is on predicting events within the network.
</nextsent>
<nextsent>response prediction there has been significant work addressing the task of response prediction in news articles (tsagkias et al, 2009; tsagkias et al, 2010) and blogs (yano et al, 2009; <papid> N09-1054 </papid>yano and smith, 2010; balasubramanyan et al, 2011).<papid> W11-0703 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1632">
<title id=" N12-1074.xml">predicting responses to microblog posts </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>similarly to this line of work, we mine the social network for event prediction.
</prevsent>
<prevsent>in contrast, our focus is on predicting events within the network.
</prevsent>
</prevsection>
<citsent citstr=" N09-1054 ">
response prediction there has been significant work addressing the task of response prediction in news articles (tsagkias et al, 2009; tsagkias et al, 2010) and blogs (yano et al, 2009; <papid> N09-1054 </papid>yano and smith, 2010; balasubramanyan et al, 2011).<papid> W11-0703 </papid></citsent>
<aftsection>
<nextsent>the task of predicting responses in social networks has been investigated previously: hong et al (2011) focused on predicting responses for highly popular items,rowe et al (2011) targeted the prediction of conversations and their length and suh et al (2010) predicted retweets.
</nextsent>
<nextsent>in contrast, our work targets tweets regardless of their popularity and attempts to predict both replies and retweets.
</nextsent>
<nextsent>furthermore, we present scalable method to use linguistic lexical features in discriminative models by leveraging global network statistics.
</nextsent>
<nextsent>a related task to ours is that of response generation, as explored by ritter et al (2011).<papid> D11-1054 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1633">
<title id=" N12-1074.xml">predicting responses to microblog posts </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>similarly to this line of work, we mine the social network for event prediction.
</prevsent>
<prevsent>in contrast, our focus is on predicting events within the network.
</prevsent>
</prevsection>
<citsent citstr=" W11-0703 ">
response prediction there has been significant work addressing the task of response prediction in news articles (tsagkias et al, 2009; tsagkias et al, 2010) and blogs (yano et al, 2009; <papid> N09-1054 </papid>yano and smith, 2010; balasubramanyan et al, 2011).<papid> W11-0703 </papid></citsent>
<aftsection>
<nextsent>the task of predicting responses in social networks has been investigated previously: hong et al (2011) focused on predicting responses for highly popular items,rowe et al (2011) targeted the prediction of conversations and their length and suh et al (2010) predicted retweets.
</nextsent>
<nextsent>in contrast, our work targets tweets regardless of their popularity and attempts to predict both replies and retweets.
</nextsent>
<nextsent>furthermore, we present scalable method to use linguistic lexical features in discriminative models by leveraging global network statistics.
</nextsent>
<nextsent>a related task to ours is that of response generation, as explored by ritter et al (2011).<papid> D11-1054 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1634">
<title id=" N12-1074.xml">predicting responses to microblog posts </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in contrast, our work targets tweets regardless of their popularity and attempts to predict both replies and retweets.
</prevsent>
<prevsent>furthermore, we present scalable method to use linguistic lexical features in discriminative models by leveraging global network statistics.
</prevsent>
</prevsection>
<citsent citstr=" D11-1054 ">
a related task to ours is that of response generation, as explored by ritter et al (2011).<papid> D11-1054 </papid></citsent>
<aftsection>
<nextsent>our work complements their approach by allowing to detect when the generation of response is appropriate.
</nextsent>
<nextsent>lastly, the task of predicting the spread ofhashtags in microblogging networks (tsur and rappoport, 2012) is also closely related to our work and both approaches supplement each other as measures of impact.
</nextsent>
<nextsent>ranking in news feeds different approaches were suggested for ranking items in social media (das sarma et al, 2010; lakkaraju et al, 2011).
</nextsent>
<nextsent>ourwork provides an important signal, which can be incorporated into any ranking approach.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1635">
<title id=" N12-1074.xml">predicting responses to microblog posts </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>to detect sentiment words we use proprietary microsoft lexicon of 7k positive and negative terms.
</prevsent>
<prevsent>4.1 learning algorithm.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
we experimented with two different learning al gorithms: multiple additive regression-trees (mart) (wu et al, 2008) and maximum entropy classifier (berger et al, 1996).<papid> J96-1002 </papid></citsent>
<aftsection>
<nextsent>both provide fast classification, natural requirement for large-scale real-time tasks.
</nextsent>
<nextsent>4.2 dataset.
</nextsent>
<nextsent>in our evaluation we focus on english tweets only.
</nextsent>
<nextsent>since we use local posting time in our features, we filtered users whose profile did not contain location information.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1636">
<title id=" P01-1045.xml">from chunks to function argument structure a similarity based approach </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>by comparison, little or no attention has been paid to the question of how such partial analyses can be combined into larger structures for complete utterances.
</prevsent>
<prevsent>such larger structures are not only desirable for deeper syntactic analysis; they also constitute necessary prerequisite for assigning function-argument structure.
</prevsent>
</prevsection>
<citsent citstr=" H94-1020 ">
automatic assignment of function-argumentstructure has long been recognized as desider atum beyond pure syntactic labeling (marcus etal., 1994)<papid> H94-1020 </papid>1.</citsent>
<aftsection>
<nextsent>the present paper offers similarity 1with the exception of dependency-grammar-based parsers (tapanainen and jarvinen, 1997; <papid> A97-1011 </papid>broker et al, 1994; <papid> C94-1061 </papid>lesmo and lombardo, 2000), where functional labels are treated as first-class citizens as relations between words, and recent work on semi-automatic method for treebank construction (brants et al, 1997), <papid> W97-0307 </papid>little has been reported on based algorithm for assigning functional labels such as subject, object, head, complement, etc. to complete syntactic structures on the basis ofpre-chunked input.</nextsent>
<nextsent>the evaluation of the algorithm has concentrated on measuring the quality of these functional labels.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1637">
<title id=" P01-1045.xml">from chunks to function argument structure a similarity based approach </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>such larger structures are not only desirable for deeper syntactic analysis; they also constitute necessary prerequisite for assigning function-argument structure.
</prevsent>
<prevsent>automatic assignment of function-argumentstructure has long been recognized as desider atum beyond pure syntactic labeling (marcus etal., 1994)<papid> H94-1020 </papid>1.</prevsent>
</prevsection>
<citsent citstr=" A97-1011 ">
the present paper offers similarity 1with the exception of dependency-grammar-based parsers (tapanainen and jarvinen, 1997; <papid> A97-1011 </papid>broker et al, 1994; <papid> C94-1061 </papid>lesmo and lombardo, 2000), where functional labels are treated as first-class citizens as relations between words, and recent work on semi-automatic method for treebank construction (brants et al, 1997), <papid> W97-0307 </papid>little has been reported on based algorithm for assigning functional labels such as subject, object, head, complement, etc. to complete syntactic structures on the basis ofpre-chunked input.</citsent>
<aftsection>
<nextsent>the evaluation of the algorithm has concentrated on measuring the quality of these functional labels.
</nextsent>
<nextsent>in order to ensure robust and efficient architecture, tusbl, similarity-based chunk parser, is organized in three-level architecture, with the output of each level serving as input for the next higher level.
</nextsent>
<nextsent>the first level is part-of-speech (pos) tagging of the input string with the help of the bigram tagger likely (feldweg, 1993).2the parts of speech serve as pre-terminal elements for the next step, i.e. the chunk analysis.chunk parsing is carried out by an adapted version of abneys (1996) cass parser, which is realized as cascade of finite-state transducers.the chunks, which extend if possible to the simplex clause level, are then remodeled into complete trees in the tree construction level.
</nextsent>
<nextsent>the tree construction level is similar to the dop approach (bod, 1998; bod, 2000) <papid> C00-1011 </papid>in that it uses complete tree structures instead of rules.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1638">
<title id=" P01-1045.xml">from chunks to function argument structure a similarity based approach </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>such larger structures are not only desirable for deeper syntactic analysis; they also constitute necessary prerequisite for assigning function-argument structure.
</prevsent>
<prevsent>automatic assignment of function-argumentstructure has long been recognized as desider atum beyond pure syntactic labeling (marcus etal., 1994)<papid> H94-1020 </papid>1.</prevsent>
</prevsection>
<citsent citstr=" C94-1061 ">
the present paper offers similarity 1with the exception of dependency-grammar-based parsers (tapanainen and jarvinen, 1997; <papid> A97-1011 </papid>broker et al, 1994; <papid> C94-1061 </papid>lesmo and lombardo, 2000), where functional labels are treated as first-class citizens as relations between words, and recent work on semi-automatic method for treebank construction (brants et al, 1997), <papid> W97-0307 </papid>little has been reported on based algorithm for assigning functional labels such as subject, object, head, complement, etc. to complete syntactic structures on the basis ofpre-chunked input.</citsent>
<aftsection>
<nextsent>the evaluation of the algorithm has concentrated on measuring the quality of these functional labels.
</nextsent>
<nextsent>in order to ensure robust and efficient architecture, tusbl, similarity-based chunk parser, is organized in three-level architecture, with the output of each level serving as input for the next higher level.
</nextsent>
<nextsent>the first level is part-of-speech (pos) tagging of the input string with the help of the bigram tagger likely (feldweg, 1993).2the parts of speech serve as pre-terminal elements for the next step, i.e. the chunk analysis.chunk parsing is carried out by an adapted version of abneys (1996) cass parser, which is realized as cascade of finite-state transducers.the chunks, which extend if possible to the simplex clause level, are then remodeled into complete trees in the tree construction level.
</nextsent>
<nextsent>the tree construction level is similar to the dop approach (bod, 1998; bod, 2000) <papid> C00-1011 </papid>in that it uses complete tree structures instead of rules.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1639">
<title id=" P01-1045.xml">from chunks to function argument structure a similarity based approach </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>such larger structures are not only desirable for deeper syntactic analysis; they also constitute necessary prerequisite for assigning function-argument structure.
</prevsent>
<prevsent>automatic assignment of function-argumentstructure has long been recognized as desider atum beyond pure syntactic labeling (marcus etal., 1994)<papid> H94-1020 </papid>1.</prevsent>
</prevsection>
<citsent citstr=" W97-0307 ">
the present paper offers similarity 1with the exception of dependency-grammar-based parsers (tapanainen and jarvinen, 1997; <papid> A97-1011 </papid>broker et al, 1994; <papid> C94-1061 </papid>lesmo and lombardo, 2000), where functional labels are treated as first-class citizens as relations between words, and recent work on semi-automatic method for treebank construction (brants et al, 1997), <papid> W97-0307 </papid>little has been reported on based algorithm for assigning functional labels such as subject, object, head, complement, etc. to complete syntactic structures on the basis ofpre-chunked input.</citsent>
<aftsection>
<nextsent>the evaluation of the algorithm has concentrated on measuring the quality of these functional labels.
</nextsent>
<nextsent>in order to ensure robust and efficient architecture, tusbl, similarity-based chunk parser, is organized in three-level architecture, with the output of each level serving as input for the next higher level.
</nextsent>
<nextsent>the first level is part-of-speech (pos) tagging of the input string with the help of the bigram tagger likely (feldweg, 1993).2the parts of speech serve as pre-terminal elements for the next step, i.e. the chunk analysis.chunk parsing is carried out by an adapted version of abneys (1996) cass parser, which is realized as cascade of finite-state transducers.the chunks, which extend if possible to the simplex clause level, are then remodeled into complete trees in the tree construction level.
</nextsent>
<nextsent>the tree construction level is similar to the dop approach (bod, 1998; bod, 2000) <papid> C00-1011 </papid>in that it uses complete tree structures instead of rules.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1640">
<title id=" P01-1045.xml">from chunks to function argument structure a similarity based approach </title>
<section> the tusbl architecture.  </section>
<citcontext>
<prevsection>
<prevsent>in order to ensure robust and efficient architecture, tusbl, similarity-based chunk parser, is organized in three-level architecture, with the output of each level serving as input for the next higher level.
</prevsent>
<prevsent>the first level is part-of-speech (pos) tagging of the input string with the help of the bigram tagger likely (feldweg, 1993).2the parts of speech serve as pre-terminal elements for the next step, i.e. the chunk analysis.chunk parsing is carried out by an adapted version of abneys (1996) cass parser, which is realized as cascade of finite-state transducers.the chunks, which extend if possible to the simplex clause level, are then remodeled into complete trees in the tree construction level.
</prevsent>
</prevsection>
<citsent citstr=" C00-1011 ">
the tree construction level is similar to the dop approach (bod, 1998; bod, 2000) <papid> C00-1011 </papid>in that it uses complete tree structures instead of rules.</citsent>
<aftsection>
<nextsent>contrary to bod, we only use the complete trees and do not allow tree cuts.
</nextsent>
<nextsent>thus the number of possible combinations of partial trees is strictly controlled.
</nextsent>
<nextsent>the resulting parser is highly efficient (3770 english sentences took 106.5 seconds to parse on an ultra sparc 10).
</nextsent>
<nextsent>the division of labor between the chunking and tree construction modules can best be illustrated by an example.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1641">
<title id=" P01-1045.xml">from chunks to function argument structure a similarity based approach </title>
<section> similarity-based tree construction.  </section>
<citcontext>
<prevsection>
<prevsent>3.learning (stanfill and waltz, 1986).5 memory based learning assumes that the classification of given input should be based on the similarity to previously seen instances of the same type that have been stored in memory.
</prevsent>
<prevsent>this paradigm is an instance of lazy learning in the sense that these previously encountered instances are stored as is? and are crucially not abstracted over, as is typically the case in rule-based systems or other learning approaches.
</prevsent>
</prevsection>
<citsent citstr=" W97-1016 ">
previous applications of 5memory-based learning has recently been applied to variety of nlp classification tasks, including part-of-speechtagging, noun phrase chunking, grapheme-phoneme conversion, word sense disambiguation, and pp attachment (see (daelemans et al, 1999; veenstra et al, 2000; zavrel et al, 1997) <papid> W97-1016 </papid>for details).</citsent>
<aftsection>
<nextsent>memory-based learning to nlp tasks consisted of classification problems in which the set of classes to be learnt was simple in the sense that the class items did not have any internal structure and the number of distinct items was small.
</nextsent>
<nextsent>since in the current application, the set of classes are parse trees, the classification task is much more complex.
</nextsent>
<nextsent>the classification is simple only in those cases where direct hit is found, i.e. where complete match of the input with stored instance exists.
</nextsent>
<nextsent>in all other cases, the most similar tree from the instance base needs to be modified to match the chunked input.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1642">
<title id=" P01-1042.xml">joint and conditional estimation of tagging and parsing models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in ?.
</prevsent>
<prevsent>the mcle, on the other hand, selects the model parameter ? in order to make the training data pair (yi, xi) more likely than other pairs (y?, xi) in ?, i.e., pairs with the same visible value xi as the training datum.in statistical computational linguistics, maximum conditional likelihood estimators have mostly been used with general exponential or maximum entropy?
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
models because standard maximum likelihood estimation is usually computationally intractable (berger et al, 1996; <papid> J96-1002 </papid>dellapietra et al, 1997; jelinek, 1997).</citsent>
<aftsection>
<nextsent>well known computational linguistic models such as (mle) (mcle) ? = yi, = xi ? = xi = yi, = xi figure 1: the mle makes the training data (yi, xi) as likely as possible (relative to ?), while the mcle makes (yi, xi) as likely as possible relative to other pairs (y?, xi).
</nextsent>
<nextsent>maximum-entropy markov models (mccallum et al, 2000) and stochastic unification-based grammars (johnson et al, 1999) <papid> P99-1069 </papid>are standardly estimated with conditional estimators, and it would be interesting to know whether conditional estimation affects the quality of the estimated model.</nextsent>
<nextsent>it should be noted that in practice, the mcle of model with large number of features with complex dependencies may yield far better performance than the mle of the much smaller model that could be estimated with the same computational effort.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1643">
<title id=" P01-1042.xml">joint and conditional estimation of tagging and parsing models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>models because standard maximum likelihood estimation is usually computationally intractable (berger et al, 1996; <papid> J96-1002 </papid>dellapietra et al, 1997; jelinek, 1997).</prevsent>
<prevsent>well known computational linguistic models such as (mle) (mcle) ? = yi, = xi ? = xi = yi, = xi figure 1: the mle makes the training data (yi, xi) as likely as possible (relative to ?), while the mcle makes (yi, xi) as likely as possible relative to other pairs (y?, xi).</prevsent>
</prevsection>
<citsent citstr=" P99-1069 ">
maximum-entropy markov models (mccallum et al, 2000) and stochastic unification-based grammars (johnson et al, 1999) <papid> P99-1069 </papid>are standardly estimated with conditional estimators, and it would be interesting to know whether conditional estimation affects the quality of the estimated model.</citsent>
<aftsection>
<nextsent>it should be noted that in practice, the mcle of model with large number of features with complex dependencies may yield far better performance than the mle of the much smaller model that could be estimated with the same computational effort.
</nextsent>
<nextsent>nevertheless, as this paper shows, conditional estimators can be used with other kinds of models besides maxent models, and in any event it is interesting to ask whether the mle differs from the mcle in actual applications, and if so, how.
</nextsent>
<nextsent>because the mle is consistent for the joint distribution p(y,x) (e.g., in tagging application, the distribution of word-tag sequences), it is also consistent for the conditional distribution p(y |x) (e.g., the distribution of tag sequences given word sequences) and the marginal distribution p(x) (e.g., the distribution of word strings).
</nextsent>
<nextsent>on the other hand, the mcle is consistent for the conditional distribution p(y |x) alone, and provides no information about either the joint or the marginal distributions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1644">
<title id=" P01-1042.xml">joint and conditional estimation of tagging and parsing models </title>
<section> shift-reduce parsing.  </section>
<citcontext>
<prevsection>
<prevsent>these parsers are direct simplifications of the structured language model (jelinek, 2000).
</prevsent>
<prevsent>because the parsers?
</prevsent>
</prevsection>
<citsent citstr=" J93-1002 ">
moves are determined solely by the top two category labels on the stack and possibly the look-ahead symbol, they are much simpler than stochastic lr parsers (briscoe and carroll, 1993; <papid> J93-1002 </papid>inui et al, 1997).</citsent>
<aftsection>
<nextsent>the distribution over trees generated by the joint model is probabilistic context-free language (abney et al, 1999).<papid> P99-1070 </papid></nextsent>
<nextsent>as with the pcfg models discussed earlier, these parsers are not lexicalized; lexical items are ignored, and the pos tags are used as the terminals.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1645">
<title id=" P01-1042.xml">joint and conditional estimation of tagging and parsing models </title>
<section> shift-reduce parsing.  </section>
<citcontext>
<prevsection>
<prevsent>because the parsers?
</prevsent>
<prevsent>moves are determined solely by the top two category labels on the stack and possibly the look-ahead symbol, they are much simpler than stochastic lr parsers (briscoe and carroll, 1993; <papid> J93-1002 </papid>inui et al, 1997).</prevsent>
</prevsection>
<citsent citstr=" P99-1070 ">
the distribution over trees generated by the joint model is probabilistic context-free language (abney et al, 1999).<papid> P99-1070 </papid></citsent>
<aftsection>
<nextsent>as with the pcfg models discussed earlier, these parsers are not lexicalized; lexical items are ignored, and the pos tags are used as the terminals.
</nextsent>
<nextsent>these two parsers only produce trees withunary or binary nodes, so we binarized the training data before training the parser, and debinarize the trees the parsers produce before evaluating them with respect to the test data (johnson, 1998).<papid> J98-4004 </papid></nextsent>
<nextsent>we binarized by inserting n?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1646">
<title id=" P01-1042.xml">joint and conditional estimation of tagging and parsing models </title>
<section> shift-reduce parsing.  </section>
<citcontext>
<prevsection>
<prevsent>the distribution over trees generated by the joint model is probabilistic context-free language (abney et al, 1999).<papid> P99-1070 </papid></prevsent>
<prevsent>as with the pcfg models discussed earlier, these parsers are not lexicalized; lexical items are ignored, and the pos tags are used as the terminals.</prevsent>
</prevsection>
<citsent citstr=" J98-4004 ">
these two parsers only produce trees withunary or binary nodes, so we binarized the training data before training the parser, and debinarize the trees the parsers produce before evaluating them with respect to the test data (johnson, 1998).<papid> J98-4004 </papid></citsent>
<aftsection>
<nextsent>we binarized by inserting n?
</nextsent>
<nextsent>2 additional nodes into each local tree with   2 children.
</nextsent>
<nextsent>we binarized by first joining the head to all of the constituents to its right, and then joining there sulting structure with constituents to the left.
</nextsent>
<nextsent>the label of new node is the label of the head followed by the suffix ?-1?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1648">
<title id=" P04-1050.xml">evaluating centering based metrics of coherence for text structuring using a reliably annotated corpus </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>a corpus based methodology is presented which distinguishes between centering-based metrics taking these alternatives into account, and represents therefore more appropriate way to evaluate centering from text structuring perspective.
</prevsent>
<prevsent>our research area is descriptive text generation (odonnell et al , 2001; isard et al , 2003), i.e.the generation of descriptions of objects, typically museum artefacts, depicted in picture.
</prevsent>
</prevsection>
<citsent citstr=" J04-3003 ">
text (1), from the gnome corpus (poesio et al , 2004), <papid> J04-3003 </papid>is an example of short human-authored text from this genre: (1) (a) 144 is torc.</citsent>
<aftsection>
<nextsent>(b) its present arrangement,twisted into three rings, may be modern al teration; (c) it should probably be single ring, worn around the neck.
</nextsent>
<nextsent>(d) the terminals are in the form of goats?
</nextsent>
<nextsent>heads.
</nextsent>
<nextsent>according to centering theory (grosz et al ,1995; <papid> J95-2003 </papid>walker et al , 1998a), an important factor for the felicity of (1) is its entity coherence: the way centers (discourse entities), such as the referent of the nps 144?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1650">
<title id=" P04-1050.xml">evaluating centering based metrics of coherence for text structuring using a reliably annotated corpus </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>(d) the terminals are in the form of goats?
</prevsent>
<prevsent>heads.
</prevsent>
</prevsection>
<citsent citstr=" J95-2003 ">
according to centering theory (grosz et al ,1995; <papid> J95-2003 </papid>walker et al , 1998a), an important factor for the felicity of (1) is its entity coherence: the way centers (discourse entities), such as the referent of the nps 144?</citsent>
<aftsection>
<nextsent>in clause (a) and its?
</nextsent>
<nextsent>in clause (b), are introduced and discussed in subsequent clauses.
</nextsent>
<nextsent>it is often claimed in current work on in natural language generation that the constraints on felicitous text proposed by the theory are useful to guide text structuring, in combination with other factors (see (karamanis, 2003) for an overview).
</nextsent>
<nextsent>however, how successful centerings constraints are ontheir own in generating felicitous text structure is an open question, already raised by the seminal papers of the theory (brennan et al ,1987; <papid> P87-1022 </papid>grosz et al , 1995).<papid> J95-2003 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1651">
<title id=" P04-1050.xml">evaluating centering based metrics of coherence for text structuring using a reliably annotated corpus </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>in clause (b), are introduced and discussed in subsequent clauses.
</prevsent>
<prevsent>it is often claimed in current work on in natural language generation that the constraints on felicitous text proposed by the theory are useful to guide text structuring, in combination with other factors (see (karamanis, 2003) for an overview).
</prevsent>
</prevsection>
<citsent citstr=" P87-1022 ">
however, how successful centerings constraints are ontheir own in generating felicitous text structure is an open question, already raised by the seminal papers of the theory (brennan et al ,1987; <papid> P87-1022 </papid>grosz et al , 1995).<papid> J95-2003 </papid></citsent>
<aftsection>
<nextsent>in this work, we explored this question by developing an approach to text structuring purely based on centering, in which the role of other factors is deliberately ignored.in accordance with recent work in the emerging field of text-to-text generation (barzilay etal., 2002; lapata, 2003), <papid> P03-1069 </papid>we assume that the in put to text structuring is set of clauses.</nextsent>
<nextsent>the output of text structuring is merely an ordering of these clauses, rather than the tree-likestructure of database facts often used in traditional deep generation (reiter and dale, 2000).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1653">
<title id=" P04-1050.xml">evaluating centering based metrics of coherence for text structuring using a reliably annotated corpus </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>it is often claimed in current work on in natural language generation that the constraints on felicitous text proposed by the theory are useful to guide text structuring, in combination with other factors (see (karamanis, 2003) for an overview).
</prevsent>
<prevsent>however, how successful centerings constraints are ontheir own in generating felicitous text structure is an open question, already raised by the seminal papers of the theory (brennan et al ,1987; <papid> P87-1022 </papid>grosz et al , 1995).<papid> J95-2003 </papid></prevsent>
</prevsection>
<citsent citstr=" P03-1069 ">
in this work, we explored this question by developing an approach to text structuring purely based on centering, in which the role of other factors is deliberately ignored.in accordance with recent work in the emerging field of text-to-text generation (barzilay etal., 2002; lapata, 2003), <papid> P03-1069 </papid>we assume that the in put to text structuring is set of clauses.</citsent>
<aftsection>
<nextsent>the output of text structuring is merely an ordering of these clauses, rather than the tree-likestructure of database facts often used in traditional deep generation (reiter and dale, 2000).
</nextsent>
<nextsent>our approach is further characterized by two key insights.
</nextsent>
<nextsent>the first distinguishing feature is that we assume search-based approach to text structuring (mellish et al , 1998; <papid> W98-1411 </papid>kibble and power, 2000; <papid> W00-1411 </papid>karamanis and manurung, 2002) in which many candidate orderings of clauses are evaluated according to scores assigned by given metric, and the best-scoring ordering among the candidate solutions is chosen.</nextsent>
<nextsent>the second novel aspect is that our approach isbased on the position that the most straightforward way of using centering for text structuring is by defining centering-based metric of coherence karamanis (2003).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1654">
<title id=" P04-1050.xml">evaluating centering based metrics of coherence for text structuring using a reliably annotated corpus </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>the output of text structuring is merely an ordering of these clauses, rather than the tree-likestructure of database facts often used in traditional deep generation (reiter and dale, 2000).
</prevsent>
<prevsent>our approach is further characterized by two key insights.
</prevsent>
</prevsection>
<citsent citstr=" W98-1411 ">
the first distinguishing feature is that we assume search-based approach to text structuring (mellish et al , 1998; <papid> W98-1411 </papid>kibble and power, 2000; <papid> W00-1411 </papid>karamanis and manurung, 2002) in which many candidate orderings of clauses are evaluated according to scores assigned by given metric, and the best-scoring ordering among the candidate solutions is chosen.</citsent>
<aftsection>
<nextsent>the second novel aspect is that our approach isbased on the position that the most straightforward way of using centering for text structuring is by defining centering-based metric of coherence karamanis (2003).
</nextsent>
<nextsent>together, these two assumptions lead to view of text planning in which the constraints of centering act not as filters, but as ranking factors, and the text planner may be forced to choose sub-optimal solution.
</nextsent>
<nextsent>however, karamanis (2003) pointed out that many metrics of coherence can be derived from the claims of centering, all of which could be used for the type of text structuring assumed in this paper.
</nextsent>
<nextsent>hence, general methodology for identifying which of these metrics represent the most promising candidates for text structuring is required, so that at least some of them canbe compared empirically.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1655">
<title id=" P04-1050.xml">evaluating centering based metrics of coherence for text structuring using a reliably annotated corpus </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>the output of text structuring is merely an ordering of these clauses, rather than the tree-likestructure of database facts often used in traditional deep generation (reiter and dale, 2000).
</prevsent>
<prevsent>our approach is further characterized by two key insights.
</prevsent>
</prevsection>
<citsent citstr=" W00-1411 ">
the first distinguishing feature is that we assume search-based approach to text structuring (mellish et al , 1998; <papid> W98-1411 </papid>kibble and power, 2000; <papid> W00-1411 </papid>karamanis and manurung, 2002) in which many candidate orderings of clauses are evaluated according to scores assigned by given metric, and the best-scoring ordering among the candidate solutions is chosen.</citsent>
<aftsection>
<nextsent>the second novel aspect is that our approach isbased on the position that the most straightforward way of using centering for text structuring is by defining centering-based metric of coherence karamanis (2003).
</nextsent>
<nextsent>together, these two assumptions lead to view of text planning in which the constraints of centering act not as filters, but as ranking factors, and the text planner may be forced to choose sub-optimal solution.
</nextsent>
<nextsent>however, karamanis (2003) pointed out that many metrics of coherence can be derived from the claims of centering, all of which could be used for the type of text structuring assumed in this paper.
</nextsent>
<nextsent>hence, general methodology for identifying which of these metrics represent the most promising candidates for text structuring is required, so that at least some of them canbe compared empirically.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1691">
<title id=" P04-1050.xml">evaluating centering based metrics of coherence for text structuring using a reliably annotated corpus </title>
<section> evaluating the coherence of a.  </section>
<citcontext>
<prevsection>
<prevsent>cfs with the same gf are ranked according to the linear order of the corresponding nps in the utterance.
</prevsent>
<prevsent>the second column of table 1 shows how the utterances in example (1) are automatically translated by the scripts developed by poesio et al  (2004) <papid> J04-3003 </papid>into a1for example, one could equate utterance?</prevsent>
</prevsection>
<citsent citstr=" J99-3001 ">
with sentence (strube and hahn, 1999; <papid> J99-3001 </papid>miltsakaki, 2002), <papid> J02-3003 </papid>use indirect realisation for the computation of the cf list (grosz et al , 1995), <papid> J95-2003 </papid>rank the cfs according to their information status (strube and hahn, 1999), <papid> J99-3001 </papid>etc. 2our definition includes titles which are not always finite units, but excludes finite relative clauses, the second element of coordinated vps and clause complements which are often taken as not having their own cf lists in the literature.</citsent>
<aftsection>
<nextsent>3or as post-copular subject in there-clause.
</nextsent>
<nextsent>cf list: cheapness {cp, other cfs} cb transition cbn=cpn1 (a) {de374, de375} n.a. n.a. n.a.
</nextsent>
<nextsent>(b) {de376, de374, de377} de374 retain + (c) {de374, de379} de374 continue ?
</nextsent>
<nextsent>(d) {de380, de381, de382} - nocb + table 1: cp, cfs other than cp, cb, nocb or standard (see table 2) transition and violations of cheapness (denoted with an asterisk) for each utterance (u) in example (1) coherence: coherence?: cbn=cbn1 cbn 6=cbn1 or nocb in cfn1 salience: cbn=cpn continue smooth-shift salience?: cbn 6=cpn retain rough-shift table 2: coherence, salience and the table of standard transitions sequence of cf lists, each decomposed into the cp and the cfs other than the cp, according to the chosen setting of the centering parameters.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1692">
<title id=" P04-1050.xml">evaluating centering based metrics of coherence for text structuring using a reliably annotated corpus </title>
<section> evaluating the coherence of a.  </section>
<citcontext>
<prevsection>
<prevsent>cfs with the same gf are ranked according to the linear order of the corresponding nps in the utterance.
</prevsent>
<prevsent>the second column of table 1 shows how the utterances in example (1) are automatically translated by the scripts developed by poesio et al  (2004) <papid> J04-3003 </papid>into a1for example, one could equate utterance?</prevsent>
</prevsection>
<citsent citstr=" J02-3003 ">
with sentence (strube and hahn, 1999; <papid> J99-3001 </papid>miltsakaki, 2002), <papid> J02-3003 </papid>use indirect realisation for the computation of the cf list (grosz et al , 1995), <papid> J95-2003 </papid>rank the cfs according to their information status (strube and hahn, 1999), <papid> J99-3001 </papid>etc. 2our definition includes titles which are not always finite units, but excludes finite relative clauses, the second element of coordinated vps and clause complements which are often taken as not having their own cf lists in the literature.</citsent>
<aftsection>
<nextsent>3or as post-copular subject in there-clause.
</nextsent>
<nextsent>cf list: cheapness {cp, other cfs} cb transition cbn=cpn1 (a) {de374, de375} n.a. n.a. n.a.
</nextsent>
<nextsent>(b) {de376, de374, de377} de374 retain + (c) {de374, de379} de374 continue ?
</nextsent>
<nextsent>(d) {de380, de381, de382} - nocb + table 1: cp, cfs other than cp, cb, nocb or standard (see table 2) transition and violations of cheapness (denoted with an asterisk) for each utterance (u) in example (1) coherence: coherence?: cbn=cbn1 cbn 6=cbn1 or nocb in cfn1 salience: cbn=cpn continue smooth-shift salience?: cbn 6=cpn retain rough-shift table 2: coherence, salience and the table of standard transitions sequence of cf lists, each decomposed into the cp and the cfs other than the cp, according to the chosen setting of the centering parameters.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1737">
<title id=" P04-1050.xml">evaluating centering based metrics of coherence for text structuring using a reliably annotated corpus </title>
<section> evaluating the coherence of a.  </section>
<citcontext>
<prevsection>
<prevsent>more generally, significant percentage of nocbs (at least 20%) and other dispreferredtransitions was found with all parameter configurations tested by poesio et al  (2004) <papid> J04-3003 </papid>and indeed by all previous corpus-based evaluations of centering such as passoneau (1998), di eugenio (1998), strube and hahn (1999) <papid> J99-3001 </papid>among others.</prevsent>
<prevsent>these results led poesio et al  (2004) <papid> J04-3003 </papid>to the conclusion that the entity coherence as formalized in centering should be supplemented with an account of other coherence inducing factors to explain what makes texts coherent.</prevsent>
</prevsection>
<citsent citstr=" J01-4007 ">
these studies, however, do not investigate the question that is most important from thetext structuring perspective adopted in this pa per: whether there would be alternative ways of structuring the text that would result in fewer violations of centerings constraints (kibble, 2001).<papid> J01-4007 </papid></citsent>
<aftsection>
<nextsent>consider the nocb utterance (d) in (1).simply observing that this transition is dispre ferred?
</nextsent>
<nextsent>ignores the fact that every other ordering of utterances (b) to (d) would result in moreno cbs than those found in (1).
</nextsent>
<nextsent>even text structuring algorithm functioning solely on the basis of the centering constraints might therefore still choose the particular order in (1).
</nextsent>
<nextsent>in other words, metric of text coherence purely based on centering principles trying to minimize the number of nocbsmay be sufficient to explain why this order of clauses was chosen, at least in this particular genre, without need to involve more complex explanations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1757">
<title id=" P04-1041.xml">long distance dependency resolution in automatically acquired wide coverage pcfg based lfg approximations </title>
<section> abstract </section>
<citcontext>
<prevsection>

<prevsent>this paper shows how finite approximations of long distance dependency (ldd) resolution can be obtained automatically for wide-coverage, robust, probabilistic lexical-functional grammar (lfg) resources acquired from treebanks.
</prevsent>
</prevsection>
<citsent citstr=" P02-1018 ">
we extract lfg subcategorisation frames and paths linking lddreentrancies from f-structures generated automatically for the penn-ii treebank trees and use them in an ldd resolution algorithm to parse new text.unlike (collins, 1999; johnson, 2002)<papid> P02-1018 </papid>in our approach resolution of ldds is done at f-structure (attribute-value structure representations of basicpredicate-argument or dependency structure) with out empty productions, traces and co indexation in cfg parse trees.</citsent>
<aftsection>
<nextsent>currently our best automatically induced grammars achieve 80.97% f-score for structures parsing section 23 of the wsj part of the penn-ii treebank and evaluating against the dcu1051 and 80.24% against the parc 700 dependency bank (king et al, 2003), performing at the same or slightly better level than state-of-the-art hand-crafted grammars (kaplan et al, 2004).<papid> N04-1013 </papid></nextsent>
<nextsent>the determination of syntactic structure is an important step in natural language processing as syntactic structure strongly determines semantic interpretation in the form of predicate-argument structure, dependency relations or logical form.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1761">
<title id=" P04-1041.xml">long distance dependency resolution in automatically acquired wide coverage pcfg based lfg approximations </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>this paper shows how finite approximations of long distance dependency (ldd) resolution can be obtained automatically for wide-coverage, robust, probabilistic lexical-functional grammar (lfg) resources acquired from treebanks.
</prevsent>
<prevsent>we extract lfg subcategorisation frames and paths linking lddreentrancies from f-structures generated automatically for the penn-ii treebank trees and use them in an ldd resolution algorithm to parse new text.unlike (collins, 1999; johnson, 2002)<papid> P02-1018 </papid>in our approach resolution of ldds is done at f-structure (attribute-value structure representations of basicpredicate-argument or dependency structure) with out empty productions, traces and co indexation in cfg parse trees.</prevsent>
</prevsection>
<citsent citstr=" N04-1013 ">
currently our best automatically induced grammars achieve 80.97% f-score for structures parsing section 23 of the wsj part of the penn-ii treebank and evaluating against the dcu1051 and 80.24% against the parc 700 dependency bank (king et al, 2003), performing at the same or slightly better level than state-of-the-art hand-crafted grammars (kaplan et al, 2004).<papid> N04-1013 </papid></citsent>
<aftsection>
<nextsent>the determination of syntactic structure is an important step in natural language processing as syntactic structure strongly determines semantic interpretation in the form of predicate-argument structure, dependency relations or logical form.
</nextsent>
<nextsent>for substantial number of linguistic phenomena such as topical isation, wh-movement in relative clause sand interrogative sentences, however, there is an important difference between the location of the (surface) realisation of linguistic material and the location where this material should be interpreted semantically.
</nextsent>
<nextsent>resolution of such long-distance dependencies (ldds) is therefore crucial in the determination of accurate predicate-argument struc1manually constructed f-structures for 105 randomly selected trees from section 23 of the wsj section of the penn-ii treebank ture, deep dependency relations and the construction of proper meaning representations such as logical forms (johnson, 2002)<papid> P02-1018 </papid></nextsent>
<nextsent>modern unification/constraint-based grammars such as lfg or hpsg capture deep linguistic information including ldds, predicate-argument structure, or logical form.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1766">
<title id=" P04-1041.xml">long distance dependency resolution in automatically acquired wide coverage pcfg based lfg approximations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>modern unification/constraint-based grammars such as lfg or hpsg capture deep linguistic information including ldds, predicate-argument structure, or logical form.
</prevsent>
<prevsent>manually scaling rich unification grammars to naturally occurring free text, however, is extremely time-consuming, expensive and requires considerable linguistic and computational expertise.
</prevsent>
</prevsection>
<citsent citstr=" P02-1035 ">
few hand-crafted, deep unification grammars have in fact achieved the coverage and robustness required to parse corpus of say the size and complexity of the penn treebank: (riezler et al., 2002) <papid> P02-1035 </papid>show how deep, carefully hand-craftedlfg is successfully scaled to parse the penn-ii treebank (marcus et al, 1994) <papid> H94-1020 </papid>with discriminative (log linear) parameter estimation techniques.the last 20 years have seen continuously increasing efforts in the construction of parse-annotated corpora.</citsent>
<aftsection>
<nextsent>substantial treebanks2 are now available for many languages (including english, japanese, chinese, german, french, czech, turkish), others are currently under construction (arabic, bulgarian) or near completion (spanish, catalan).
</nextsent>
<nextsent>treebank shave been enormously influential in the development of robust, state-of-the-art parsing technology:grammars (or grammatical information) automatically extracted from treebank resources provide the backbone of many state-of-the-art probabilistic parsing approaches (charniak, 1996; collins, 1999; charniak, 1999; hockenmaier, 2003; <papid> P03-1046 </papid>klein and manning, 2003).<papid> P03-1054 </papid></nextsent>
<nextsent>such approaches are attractive as they achieve robustness, coverage and performance while incurring very low grammar development cost.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1767">
<title id=" P04-1041.xml">long distance dependency resolution in automatically acquired wide coverage pcfg based lfg approximations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>modern unification/constraint-based grammars such as lfg or hpsg capture deep linguistic information including ldds, predicate-argument structure, or logical form.
</prevsent>
<prevsent>manually scaling rich unification grammars to naturally occurring free text, however, is extremely time-consuming, expensive and requires considerable linguistic and computational expertise.
</prevsent>
</prevsection>
<citsent citstr=" H94-1020 ">
few hand-crafted, deep unification grammars have in fact achieved the coverage and robustness required to parse corpus of say the size and complexity of the penn treebank: (riezler et al., 2002) <papid> P02-1035 </papid>show how deep, carefully hand-craftedlfg is successfully scaled to parse the penn-ii treebank (marcus et al, 1994) <papid> H94-1020 </papid>with discriminative (log linear) parameter estimation techniques.the last 20 years have seen continuously increasing efforts in the construction of parse-annotated corpora.</citsent>
<aftsection>
<nextsent>substantial treebanks2 are now available for many languages (including english, japanese, chinese, german, french, czech, turkish), others are currently under construction (arabic, bulgarian) or near completion (spanish, catalan).
</nextsent>
<nextsent>treebank shave been enormously influential in the development of robust, state-of-the-art parsing technology:grammars (or grammatical information) automatically extracted from treebank resources provide the backbone of many state-of-the-art probabilistic parsing approaches (charniak, 1996; collins, 1999; charniak, 1999; hockenmaier, 2003; <papid> P03-1046 </papid>klein and manning, 2003).<papid> P03-1054 </papid></nextsent>
<nextsent>such approaches are attractive as they achieve robustness, coverage and performance while incurring very low grammar development cost.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1768">
<title id=" P04-1041.xml">long distance dependency resolution in automatically acquired wide coverage pcfg based lfg approximations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>few hand-crafted, deep unification grammars have in fact achieved the coverage and robustness required to parse corpus of say the size and complexity of the penn treebank: (riezler et al., 2002) <papid> P02-1035 </papid>show how deep, carefully hand-craftedlfg is successfully scaled to parse the penn-ii treebank (marcus et al, 1994) <papid> H94-1020 </papid>with discriminative (log linear) parameter estimation techniques.the last 20 years have seen continuously increasing efforts in the construction of parse-annotated corpora.</prevsent>
<prevsent>substantial treebanks2 are now available for many languages (including english, japanese, chinese, german, french, czech, turkish), others are currently under construction (arabic, bulgarian) or near completion (spanish, catalan).</prevsent>
</prevsection>
<citsent citstr=" P03-1046 ">
treebank shave been enormously influential in the development of robust, state-of-the-art parsing technology:grammars (or grammatical information) automatically extracted from treebank resources provide the backbone of many state-of-the-art probabilistic parsing approaches (charniak, 1996; collins, 1999; charniak, 1999; hockenmaier, 2003; <papid> P03-1046 </papid>klein and manning, 2003).<papid> P03-1054 </papid></citsent>
<aftsection>
<nextsent>such approaches are attractive as they achieve robustness, coverage and performance while incurring very low grammar development cost.
</nextsent>
<nextsent>however, with few notable exceptions(e.g. collins?
</nextsent>
<nextsent>model 3, (johnson, 2002)<papid> P02-1018 </papid>(hocken maier, 2003) ), <papid> P03-1046 </papid>treebank-based probabilistic parsers return fairly simple surfacey?</nextsent>
<nextsent>cfg trees, with out deep syntactic or semantic information.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1769">
<title id=" P04-1041.xml">long distance dependency resolution in automatically acquired wide coverage pcfg based lfg approximations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>few hand-crafted, deep unification grammars have in fact achieved the coverage and robustness required to parse corpus of say the size and complexity of the penn treebank: (riezler et al., 2002) <papid> P02-1035 </papid>show how deep, carefully hand-craftedlfg is successfully scaled to parse the penn-ii treebank (marcus et al, 1994) <papid> H94-1020 </papid>with discriminative (log linear) parameter estimation techniques.the last 20 years have seen continuously increasing efforts in the construction of parse-annotated corpora.</prevsent>
<prevsent>substantial treebanks2 are now available for many languages (including english, japanese, chinese, german, french, czech, turkish), others are currently under construction (arabic, bulgarian) or near completion (spanish, catalan).</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
treebank shave been enormously influential in the development of robust, state-of-the-art parsing technology:grammars (or grammatical information) automatically extracted from treebank resources provide the backbone of many state-of-the-art probabilistic parsing approaches (charniak, 1996; collins, 1999; charniak, 1999; hockenmaier, 2003; <papid> P03-1046 </papid>klein and manning, 2003).<papid> P03-1054 </papid></citsent>
<aftsection>
<nextsent>such approaches are attractive as they achieve robustness, coverage and performance while incurring very low grammar development cost.
</nextsent>
<nextsent>however, with few notable exceptions(e.g. collins?
</nextsent>
<nextsent>model 3, (johnson, 2002)<papid> P02-1018 </papid>(hocken maier, 2003) ), <papid> P03-1046 </papid>treebank-based probabilistic parsers return fairly simple surfacey?</nextsent>
<nextsent>cfg trees, with out deep syntactic or semantic information.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1784">
<title id=" P04-1041.xml">long distance dependency resolution in automatically acquired wide coverage pcfg based lfg approximations </title>
<section> acquiring lexical and ldd resources.  </section>
<citcontext>
<prevsection>
<prevsent>f-structure annotations allow us to distinguish passive and activeframes.
</prevsent>
<prevsent>table 3 shows the most frequent semantic forms for accept.
</prevsent>
</prevsection>
<citsent citstr=" H94-1003 ">
passive frames are marked p. we carried out comprehensive evaluation of the automatically acquired verbal semantic forms against the comlex resource (macleod et al,1994) <papid> H94-1003 </papid>for the 2992 active verb lemmas that both resources have in common.</citsent>
<aftsection>
<nextsent>we report on the evaluation of gf-based frames for the full frames with complete prepositional and particle infomation.
</nextsent>
<nextsent>we use relative conditional probability thresholds (1% and 5%) to filter the selection of semantic forms (table 4).
</nextsent>
<nextsent>(odonovan et al, 2004) <papid> P04-1047 </papid>provide more detailed description of the extraction and evaluation of semantic forms.</nextsent>
<nextsent>without prep/part with prep/part lemmas 3586 3586 sem.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1785">
<title id=" P04-1041.xml">long distance dependency resolution in automatically acquired wide coverage pcfg based lfg approximations </title>
<section> acquiring lexical and ldd resources.  </section>
<citcontext>
<prevsection>
<prevsent>we report on the evaluation of gf-based frames for the full frames with complete prepositional and particle infomation.
</prevsent>
<prevsent>we use relative conditional probability thresholds (1% and 5%) to filter the selection of semantic forms (table 4).
</prevsent>
</prevsection>
<citsent citstr=" P04-1047 ">
(odonovan et al, 2004) <papid> P04-1047 </papid>provide more detailed description of the extraction and evaluation of semantic forms.</citsent>
<aftsection>
<nextsent>without prep/part with prep/part lemmas 3586 3586 sem.
</nextsent>
<nextsent>forms 10969 14348 frame types 38 577 active frame types 38 548 passive frame types 21 177 table 2: verb results semantic form occurrences prob.
</nextsent>
<nextsent>accept([obj,subj]) 122 0.813 accept([subj],p) 9 0.060 accept([comp,subj]) 5 0.033 accept([subj,obl:as],p) 3 0.020 accept([obj,subj,obl:as]) 3 0.020 accept([obj,subj,obl:from]) 3 0.020 accept([subj]) 2 0.013 accept([obj,subj,obl:at]) 1 0.007 accept([obj,subj,obl:for]) 1 0.007 accept([obj,subj,xcomp]) 1 0.007 table 3: semantic forms for the verb accept.
</nextsent>
<nextsent>threshold 1% threshold 5% r f-score r f-score exp. 73.7% 22.1% 34.0% 78.0% 18.3% 29.6% table 4: comlex comparison we further acquire finite approximations of fu equations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1813">
<title id=" P04-1041.xml">long distance dependency resolution in automatically acquired wide coverage pcfg based lfg approximations </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>our approach provides wide-coverage, robust, and ? with the addition of ldd resolution ? deepor full?, pcfg-based lfg approximations.
</prevsent>
<prevsent>crucially, we do not claim to provide fully adequate statistical models.
</prevsent>
</prevsection>
<citsent citstr=" J97-4005 ">
it is well known (abney, 1997) <papid> J97-4005 </papid>that pcfg-type approximations to unification grammars can yield inconsistent probability models due toloss of probability mass: the parser successfully returns the highest ranked parse tree but the constraint solver cannot resolve the f-equations (generated in the pipeline or hidden?</citsent>
<aftsection>
<nextsent>in the integrated model) and the probability mass associated with that tree is lost.
</nextsent>
<nextsent>this case, however, is surprisingly rare for our grammars: only 0.0018% (85 out of 48424) of the original penn-ii trees (without frags) fail to produce an f-structure due to inconsistent annotations(table 1), and for parsing section 23 with the integrated model (a-pcfg), only 9 sentences do not receive parse because no f-structure can be generated for the highest ranked tree (0.4%).
</nextsent>
<nextsent>parsing with the pipeline model, all sentences receive one complete f-structure.
</nextsent>
<nextsent>research on adequate probability models for unification grammars is important.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1824">
<title id=" P04-1086.xml">using conditional random fields to predict pitch accents in conversational speech </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>syntactic information such as part of speech has proven to be successful predictor of accentuation (hirschberg, 1993; pan and hirschberg, 2001).
</prevsent>
<prevsent>in general, function words are not accented, while content words are.
</prevsent>
</prevsection>
<citsent citstr=" W99-0619 ">
various measures of words informative ness, such as the information content (ic) of word (pan and mckeown, 1999) <papid> W99-0619 </papid>and its collocational strength in given context (pan and hirschberg, 2001) have also proven to be useful models of pitch accent.</citsent>
<aftsection>
<nextsent>how ever, in open topic conversational speech, accent isvery unpredictable.
</nextsent>
<nextsent>part of speech and the infor mativeness of word do not capture all aspects of accentuation, as we see in this example taken from switchboard, where function word gets accented (accented words are in uppercase): i, have strong objections to that.
</nextsent>
<nextsent>accent is also influenced by aspects of rhythm and timing.
</nextsent>
<nextsent>the length of words, in both number of phones and normalized duration, affect its likelihood of being accented.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1832">
<title id=" P04-1086.xml">using conditional random fields to predict pitch accents in conversational speech </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>also, they require questionable independence assumptions to achieve efficient inference and learning.
</prevsent>
<prevsent>therefore, variables used in hidden markov models of pitch accent prediction have been very limited, e.g. part of speech and frequency (pan and mckeown, 1999).<papid> W99-0619 </papid></prevsent>
</prevsection>
<citsent citstr=" W02-1001 ">
discriminative learning methods, such as maximum entropy markov models (mccallum et al, 2000), projection based markov models (punyakanok and roth, 2000), conditional random fields (lafferty et al, 2001), sequence ada boost (altun et al,2003a), sequence perceptron (collins, 2002), <papid> W02-1001 </papid>hidden markov support vector machines (altun etal., 2003b) and maximum-margin markov networks (taskar et al, 2004), overcome the limitations of hmms.</citsent>
<aftsection>
<nextsent>among these methods, crfs is the most common technique used in nlp and hasbeen successfully applied to part-of-speech tagging (lafferty et al, 2001), named-entity recognition (collins, 2002) <papid> W02-1001 </papid>and shallow parsing (sha and pereira, 2003; <papid> N03-1028 </papid>mccallum, 2003).</nextsent>
<nextsent>the goal of this study is to better identify which words in string of text will bear pitch accent.our contribution is two-fold: employing new predictors and utilizing discriminative model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1834">
<title id=" P04-1086.xml">using conditional random fields to predict pitch accents in conversational speech </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>therefore, variables used in hidden markov models of pitch accent prediction have been very limited, e.g. part of speech and frequency (pan and mckeown, 1999).<papid> W99-0619 </papid></prevsent>
<prevsent>discriminative learning methods, such as maximum entropy markov models (mccallum et al, 2000), projection based markov models (punyakanok and roth, 2000), conditional random fields (lafferty et al, 2001), sequence ada boost (altun et al,2003a), sequence perceptron (collins, 2002), <papid> W02-1001 </papid>hidden markov support vector machines (altun etal., 2003b) and maximum-margin markov networks (taskar et al, 2004), overcome the limitations of hmms.</prevsent>
</prevsection>
<citsent citstr=" N03-1028 ">
among these methods, crfs is the most common technique used in nlp and hasbeen successfully applied to part-of-speech tagging (lafferty et al, 2001), named-entity recognition (collins, 2002) <papid> W02-1001 </papid>and shallow parsing (sha and pereira, 2003; <papid> N03-1028 </papid>mccallum, 2003).</citsent>
<aftsection>
<nextsent>the goal of this study is to better identify which words in string of text will bear pitch accent.our contribution is two-fold: employing new predictors and utilizing discriminative model.
</nextsent>
<nextsent>we combine the advantages of probabilistic, syntactic, and phonological predictors with the advantages of modeling pitch accent in sequence labeling setting using crfs (lafferty et al, 2001).
</nextsent>
<nextsent>the rest of the paper is organized as follows: in section 2, we introduce crfs.
</nextsent>
<nextsent>then, we describe our corpus and the variables in section 3 and section 4.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1835">
<title id=" P04-1086.xml">using conditional random fields to predict pitch accents in conversational speech </title>
<section> conditional random fields.  </section>
<citcontext>
<prevsection>
<prevsent>,m}.
</prevsent>
<prevsent>crfs are known to overfit, especially with noisy data if not regularized.
</prevsent>
</prevsection>
<citsent citstr=" P99-1069 ">
to overcome this problem, we penalize the objective function by adding gaussian prior (a term proportional to the squared norm ||?||2) as suggested in (johnson et al, 1999).<papid> P99-1069 </papid></citsent>
<aftsection>
<nextsent>then the loss function is given as: l(?;d) = ? ? log p(yi|xi; ?) + 1 2c||?|| 2 = ? ? f (xi,yi; ?) + logz(xi,?)
</nextsent>
<nextsent>+ 12c||?|| 2 (3) where is constant.
</nextsent>
<nextsent>lafferty et al (2001), proposed modification of improved iterative scaling for parameter estimation in crfs.
</nextsent>
<nextsent>however, gradient-based methods have often found to be more efficient for minimizing equation 3 (minka, 2001; sha and pereira, 2003).<papid> N03-1028 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1843">
<title id=" P02-1055.xml">shallow parsing on the basis of words only a case study </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in many early parsers, the pos sequences formed the only input to the parser, i.e. the actual words were not used except in pos tagging.
</prevsent>
<prevsent>later, with feature-based grammars, information on pos had more central place in the lexical entry of word than the identity of the word itself, e.g. major and other head features in (pollard and sag, 1987).
</prevsent>
</prevsection>
<citsent citstr=" P96-1025 ">
in the early days of statistical parsers, pos were explicitly and often exclusively used as symbols to base probabilities on; these probabilities are generally more reliable than lexical probabilities, due to the inherent sparseness of words.in modern lexicalized parsers, pos tagging is often interleaved with parsing proper instead of being separate preprocessing module (collins, 1996;<papid> P96-1025 </papid>ratnaparkhi, 1997).<papid> W97-0301 </papid></citsent>
<aftsection>
<nextsent>charniak (2000) <papid> A00-2018 </papid>notes that having his generative parser generate the pos of constituents head before the head itself increases performance by 2 points.</nextsent>
<nextsent>he suggests that this is due tothe usefulness of pos for estimating back-off prob abilities.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1844">
<title id=" P02-1055.xml">shallow parsing on the basis of words only a case study </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in many early parsers, the pos sequences formed the only input to the parser, i.e. the actual words were not used except in pos tagging.
</prevsent>
<prevsent>later, with feature-based grammars, information on pos had more central place in the lexical entry of word than the identity of the word itself, e.g. major and other head features in (pollard and sag, 1987).
</prevsent>
</prevsection>
<citsent citstr=" W97-0301 ">
in the early days of statistical parsers, pos were explicitly and often exclusively used as symbols to base probabilities on; these probabilities are generally more reliable than lexical probabilities, due to the inherent sparseness of words.in modern lexicalized parsers, pos tagging is often interleaved with parsing proper instead of being separate preprocessing module (collins, 1996;<papid> P96-1025 </papid>ratnaparkhi, 1997).<papid> W97-0301 </papid></citsent>
<aftsection>
<nextsent>charniak (2000) <papid> A00-2018 </papid>notes that having his generative parser generate the pos of constituents head before the head itself increases performance by 2 points.</nextsent>
<nextsent>he suggests that this is due tothe usefulness of pos for estimating back-off prob abilities.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1845">
<title id=" P02-1055.xml">shallow parsing on the basis of words only a case study </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>later, with feature-based grammars, information on pos had more central place in the lexical entry of word than the identity of the word itself, e.g. major and other head features in (pollard and sag, 1987).
</prevsent>
<prevsent>in the early days of statistical parsers, pos were explicitly and often exclusively used as symbols to base probabilities on; these probabilities are generally more reliable than lexical probabilities, due to the inherent sparseness of words.in modern lexicalized parsers, pos tagging is often interleaved with parsing proper instead of being separate preprocessing module (collins, 1996;<papid> P96-1025 </papid>ratnaparkhi, 1997).<papid> W97-0301 </papid></prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
charniak (2000) <papid> A00-2018 </papid>notes that having his generative parser generate the pos of constituents head before the head itself increases performance by 2 points.</citsent>
<aftsection>
<nextsent>he suggests that this is due tothe usefulness of pos for estimating back-off probabilities.
</nextsent>
<nextsent>abneys (1991) chunking parser consists of two modules: chunker and an attacher.
</nextsent>
<nextsent>the chunker divides the sentence into labeled, non-overlappingsequences (chunks) of words, with each chunk containing head and (nearly) all of its premodifiers, exluding arguments and postmodifiers.
</nextsent>
<nextsent>his chunker works on the basis of pos information alone, whereas the second module, the attacher,also uses lexical information.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1848">
<title id=" P02-1055.xml">shallow parsing on the basis of words only a case study </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>to answer these two questions, we designed the following experiments.
</prevsent>
<prevsent>the task to be learned is shallow parsing task (described below).
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
in one experiment, it has to be performed on the basis ofthe gold-standard?, assumed-perfect pos taken directly from the training data, the penn treebank(marcus et al, 1993), <papid> J93-2004 </papid>so as to abstract from particular pos tagger and to provide an upper bound.in another experiment, parsing is done on the basis of the words alone.</citsent>
<aftsection>
<nextsent>in third, special encoding of low-frequency words is used.
</nextsent>
<nextsent>finally, words and pos are combined.
</nextsent>
<nextsent>in all experiments, we increase the amount of training data stepwise and record parse performance for each step.
</nextsent>
<nextsent>this yields four learning curves.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1849">
<title id=" P02-1055.xml">shallow parsing on the basis of words only a case study </title>
<section> task representation, data preparation,.  </section>
<citcontext>
<prevsection>
<prevsent>and experimental setup we chose shallow parsing task as our benchmarktask.
</prevsent>
<prevsent>if, to support an application such as information extraction, summarization, or question answering, we are only interested in parts of the parse tree, then shallow parser forms viable alternative to full parser.
</prevsent>
</prevsection>
<citsent citstr=" W01-0706 ">
li and roth (2001) <papid> W01-0706 </papid>show thatfor the chunking task it is specialized in, their shallow parser is more accurate and more robust than general-purpose, i.e. full, parser.</citsent>
<aftsection>
<nextsent>our shallow parsing task is combination of chunking (finding and labelling non-overlapping syntactically functional sequences) and what we will call function tagging.
</nextsent>
<nextsent>our chunks and functions are based on the annotations in the third release of the penn treebank (marcus et al, 1993).<papid> J93-2004 </papid></nextsent>
<nextsent>below is an example of tree and the corresponding chunk (sub scripts on brackets) and function (superscripts on headwords) annotation: ((s (advp-tmp once) (np-sbj-1 he) (vp was (vp held (np *-1) (pp-tmp for (np three months)) (pp without (s-nom (np-sbj *-1) (vp being (vp charged) ))))) .)) [  once      ] [  he    ] [   was held  ff ] [  for fi  ] [  three months  ] [  without  ] [   being charged fffl  ] .nodes in the tree are labeled with syntactic category and up to four function tags that specify grammatical relations (e.g. sbj for subject), subtypesof adverbials (e.g. tmp for temporal), discrepancies between syntactic form and syntactic function(e.g. nom for non-nominal constituents functioning nominally) and notions like topicalization.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1851">
<title id=" P02-1055.xml">shallow parsing on the basis of words only a case study </title>
<section> task representation, data preparation,.  </section>
<citcontext>
<prevsection>
<prevsent>the features describe the focus word and its local context.
</prevsent>
<prevsent>for the chunk part of the code, we adopt the inside?,outside?, and between?
</prevsent>
</prevsection>
<citsent citstr=" W95-0107 ">
(iob) encoding originating from (ramshaw and marcus, 1995).<papid> W95-0107 </papid></citsent>
<aftsection>
<nextsent>for the function part of the code, the value is either the function for the head of chunk, or the dummy value nofunc for all non-heads.
</nextsent>
<nextsent>for creating thepos-based task, all words are replaced by the gold standard pos tags associated with them in the penntreebank.
</nextsent>
<nextsent>for the combined task, both types of features are used simultaneously.
</nextsent>
<nextsent>when the learner is presented with new instances from heldout material, its task is thus to assign the combined function-chunk codes to either words or pos in context.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1852">
<title id=" P02-1055.xml">shallow parsing on the basis of words only a case study </title>
<section> task representation, data preparation,.  </section>
<citcontext>
<prevsection>
<prevsent>arguably, the choice of algorithm is not crucial in learning curve experiments.
</prevsent>
<prevsent>first, we aim at measuring relative differences arising from the selection of types of input.
</prevsent>
</prevsection>
<citsent citstr=" P01-1005 ">
second, there are indications that increasing the training set of language processing tasks produces much larger performance gains than varying among algorithms at fixed training set sizes; moreover, these differences also tend to get smaller with larger datasets (banko and brill, 2001).<papid> P01-1005 </papid></citsent>
<aftsection>
<nextsent>memory-based learning (stanfill and waltz, 1986; aha et al, 1991; daelemans et al, 1999<papid> W99-0707 </papid>b) is supervised inductive learning algorithm for learning classification tasks.</nextsent>
<nextsent>memory-based learning treats set of labeled (pre-classified) training instances as points in multi-dimensional feature space, and stores them as such in an instance base in memory (rather than performing some abstraction over them).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1853">
<title id=" P02-1055.xml">shallow parsing on the basis of words only a case study </title>
<section> task representation, data preparation,.  </section>
<citcontext>
<prevsection>
<prevsent>first, we aim at measuring relative differences arising from the selection of types of input.
</prevsent>
<prevsent>second, there are indications that increasing the training set of language processing tasks produces much larger performance gains than varying among algorithms at fixed training set sizes; moreover, these differences also tend to get smaller with larger datasets (banko and brill, 2001).<papid> P01-1005 </papid></prevsent>
</prevsection>
<citsent citstr=" W99-0707 ">
memory-based learning (stanfill and waltz, 1986; aha et al, 1991; daelemans et al, 1999<papid> W99-0707 </papid>b) is supervised inductive learning algorithm for learning classification tasks.</citsent>
<aftsection>
<nextsent>memory-based learning treats set of labeled (pre-classified) training instances as points in multi-dimensional feature space, and stores them as such in an instance base in memory (rather than performing some abstraction over them).
</nextsent>
<nextsent>classification in memory-based learning is performed by the  -nn algorithm (cover and hart, 1967) that searches for the  nearest neighbors according to the distance function between two in 1f  !$# &amp;%(  )+*-, precision , recall % , precision   recall left context focus right context function-chunk code once he was held i-advp advp-tmp once he was held for i-np np-sbj once he was held for three i-vp nofunc once he was held for three months i-vp vp/s he was held for three months without i-pp pp-tmp was held for three months without being i-np nofunc held for three months without being charged i-np np for three months without being charged . i-pp pp three months without being charged . i-vp nofunc months without being charged . i-vp vp/s-nom without being charged . nofunc table 1: encoding into instances, with words as input, of the example sentence once he was held for three months without being charged .?
</nextsent>
<nextsent>stances . and / , 0213.546/87:9 ; =a@cbed gf 13h ? 4ji ? 7 , where is the number of features, ? is weight for feature , and estimates the difference between the two instances?
</nextsent>
<nextsent>values at the th feature.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1854">
<title id=" P02-1055.xml">shallow parsing on the basis of words only a case study </title>
<section> learning curve experiments.  </section>
<citcontext>
<prevsection>
<prevsent>as the tags are the gold-standardtags taken directly from the penn treebank, this result provides an upper bound for the contribution ofpos tags to the shallow parsing task under investigation.
</prevsent>
<prevsent>automatic pos tagging is well-studied input features precision recall f-score gold-standard pos 73.8 0.2 73.9 0.2 73.9 0.2 mbt pos 72.2 0.2 72.4 0.2 72.3 0.2 words 75.4 0.1 75.4 0.1 75.4 0.1 words gold-standard pos 76.5 0.2 77.1 0.2 76.8 0.2 words mbt pos 75.8 0.2 76.1 0.1 75.9 0.1 attenuated words 77.3 0.1 77.2 0.2 77.3 0.2 attenuated words gold-standard pos 78.9 0.2 79.1 0.2 79.0 0.2 attenuated words mbt pos 77.6 0.2 77.7 0.2 77.6 0.2table 2: average precision, recall, and f-scores on the chunking-function-tagging task, with standard deviation, using the input features words, attenuated words, gold-standard pos, and mbt pos, and combinations, on the maximal training set size.
</prevsent>
</prevsection>
<citsent citstr=" A88-1019 ">
task (church, 1988; <papid> A88-1019 </papid>brill, 1993; ratnaparkhi, 1996; <papid> W96-0213 </papid>daelemans et al, 1996), <papid> W96-0102 </papid>and reported errors in the range of 26% are common.</citsent>
<aftsection>
<nextsent>to investigate the effect of using automatically assigned tags, we trained mbt, memory-based tagger (daelemans et al,1996), <papid> W96-0102 </papid>on the training portions of our 10-fold cross validation experiment for the maximal data and let it predict tags for the test material.</nextsent>
<nextsent>the memory-based tagger attained an accuracy of 96.7% ( 0.1; 97.0% on known words, and 80.9% on unknown words).we then used these mbt pos instead of the gold standard ones.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1855">
<title id=" P02-1055.xml">shallow parsing on the basis of words only a case study </title>
<section> learning curve experiments.  </section>
<citcontext>
<prevsection>
<prevsent>as the tags are the gold-standardtags taken directly from the penn treebank, this result provides an upper bound for the contribution ofpos tags to the shallow parsing task under investigation.
</prevsent>
<prevsent>automatic pos tagging is well-studied input features precision recall f-score gold-standard pos 73.8 0.2 73.9 0.2 73.9 0.2 mbt pos 72.2 0.2 72.4 0.2 72.3 0.2 words 75.4 0.1 75.4 0.1 75.4 0.1 words gold-standard pos 76.5 0.2 77.1 0.2 76.8 0.2 words mbt pos 75.8 0.2 76.1 0.1 75.9 0.1 attenuated words 77.3 0.1 77.2 0.2 77.3 0.2 attenuated words gold-standard pos 78.9 0.2 79.1 0.2 79.0 0.2 attenuated words mbt pos 77.6 0.2 77.7 0.2 77.6 0.2table 2: average precision, recall, and f-scores on the chunking-function-tagging task, with standard deviation, using the input features words, attenuated words, gold-standard pos, and mbt pos, and combinations, on the maximal training set size.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
task (church, 1988; <papid> A88-1019 </papid>brill, 1993; ratnaparkhi, 1996; <papid> W96-0213 </papid>daelemans et al, 1996), <papid> W96-0102 </papid>and reported errors in the range of 26% are common.</citsent>
<aftsection>
<nextsent>to investigate the effect of using automatically assigned tags, we trained mbt, memory-based tagger (daelemans et al,1996), <papid> W96-0102 </papid>on the training portions of our 10-fold cross validation experiment for the maximal data and let it predict tags for the test material.</nextsent>
<nextsent>the memory-based tagger attained an accuracy of 96.7% ( 0.1; 97.0% on known words, and 80.9% on unknown words).we then used these mbt pos instead of the gold standard ones.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1856">
<title id=" P02-1055.xml">shallow parsing on the basis of words only a case study </title>
<section> learning curve experiments.  </section>
<citcontext>
<prevsection>
<prevsent>as the tags are the gold-standardtags taken directly from the penn treebank, this result provides an upper bound for the contribution ofpos tags to the shallow parsing task under investigation.
</prevsent>
<prevsent>automatic pos tagging is well-studied input features precision recall f-score gold-standard pos 73.8 0.2 73.9 0.2 73.9 0.2 mbt pos 72.2 0.2 72.4 0.2 72.3 0.2 words 75.4 0.1 75.4 0.1 75.4 0.1 words gold-standard pos 76.5 0.2 77.1 0.2 76.8 0.2 words mbt pos 75.8 0.2 76.1 0.1 75.9 0.1 attenuated words 77.3 0.1 77.2 0.2 77.3 0.2 attenuated words gold-standard pos 78.9 0.2 79.1 0.2 79.0 0.2 attenuated words mbt pos 77.6 0.2 77.7 0.2 77.6 0.2table 2: average precision, recall, and f-scores on the chunking-function-tagging task, with standard deviation, using the input features words, attenuated words, gold-standard pos, and mbt pos, and combinations, on the maximal training set size.
</prevsent>
</prevsection>
<citsent citstr=" W96-0102 ">
task (church, 1988; <papid> A88-1019 </papid>brill, 1993; ratnaparkhi, 1996; <papid> W96-0213 </papid>daelemans et al, 1996), <papid> W96-0102 </papid>and reported errors in the range of 26% are common.</citsent>
<aftsection>
<nextsent>to investigate the effect of using automatically assigned tags, we trained mbt, memory-based tagger (daelemans et al,1996), <papid> W96-0102 </papid>on the training portions of our 10-fold cross validation experiment for the maximal data and let it predict tags for the test material.</nextsent>
<nextsent>the memory-based tagger attained an accuracy of 96.7% ( 0.1; 97.0% on known words, and 80.9% on unknown words).we then used these mbt pos instead of the gold standard ones.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1859">
<title id=" P02-1055.xml">shallow parsing on the basis of words only a case study </title>
<section> learning curve experiments.  </section>
<citcontext>
<prevsection>
<prevsent>this suggests that this encoding is not optimal.
</prevsent>
<prevsent>5 related research.
</prevsent>
</prevsection>
<citsent citstr=" W99-0621 ">
ramshaw and marcus (1995), <papid> W95-0107 </papid>munoz et al (1999), <papid> W99-0621 </papid>argamon et al (1998), <papid> P98-1010 </papid>daelemans et al (1999<papid> W99-0707 </papid>a) find np chunks, using wall street journal training material of about 9000 sentences.</citsent>
<aftsection>
<nextsent>f-scores range between 91.4 and 92.8.
</nextsent>
<nextsent>the first two articles mention that words and (automatically assigned) pos together perform better than pos alone.
</nextsent>
<nextsent>chunking is one part of the task studied here, so we also computed performance on chunks alone, ignoring function codes.
</nextsent>
<nextsent>indeed the learning curve of words combined with gold-standard pos crosses the pos-based curve before 10,000 sentences on the chunking subtask.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1860">
<title id=" P02-1055.xml">shallow parsing on the basis of words only a case study </title>
<section> learning curve experiments.  </section>
<citcontext>
<prevsection>
<prevsent>this suggests that this encoding is not optimal.
</prevsent>
<prevsent>5 related research.
</prevsent>
</prevsection>
<citsent citstr=" P98-1010 ">
ramshaw and marcus (1995), <papid> W95-0107 </papid>munoz et al (1999), <papid> W99-0621 </papid>argamon et al (1998), <papid> P98-1010 </papid>daelemans et al (1999<papid> W99-0707 </papid>a) find np chunks, using wall street journal training material of about 9000 sentences.</citsent>
<aftsection>
<nextsent>f-scores range between 91.4 and 92.8.
</nextsent>
<nextsent>the first two articles mention that words and (automatically assigned) pos together perform better than pos alone.
</nextsent>
<nextsent>chunking is one part of the task studied here, so we also computed performance on chunks alone, ignoring function codes.
</nextsent>
<nextsent>indeed the learning curve of words combined with gold-standard pos crosses the pos-based curve before 10,000 sentences on the chunking subtask.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1862">
<title id=" P02-1055.xml">shallow parsing on the basis of words only a case study </title>
<section> learning curve experiments.  </section>
<citcontext>
<prevsection>
<prevsent>with gold-standard pos and attenuated words we at tainan f-score of 94.2; with mbt pos tags and attenuated words, 92.8.
</prevsent>
<prevsent>in the conll competition, all three best systems used combinations of classifiers instead of one single classifier.
</prevsent>
</prevsection>
<citsent citstr=" W99-0706 ">
in addition, the effect of our mix of sentences from different corpora on top of wsj is not clear.ferro et al (1999) <papid> W99-0706 </papid>describe system for finding grammatical relations in automatically tagged and manually chunked text.</citsent>
<aftsection>
<nextsent>they report an score of 69.8 for training size of 3299 words of elementary school reading comprehension tests.
</nextsent>
<nextsent>buchholz et al (1999) <papid> W99-0629 </papid>achieve 71.2 f-score for grammatical relation assignment on automatically tagged and chunked text after training on about 40,000 wall street journal sentences.</nextsent>
<nextsent>in contrast to these studies, we do not chunk before finding grammatical relations; rather, chunking is performed simultaneously with headword function tagging.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1863">
<title id=" P02-1055.xml">shallow parsing on the basis of words only a case study </title>
<section> learning curve experiments.  </section>
<citcontext>
<prevsection>
<prevsent>in addition, the effect of our mix of sentences from different corpora on top of wsj is not clear.ferro et al (1999) <papid> W99-0706 </papid>describe system for finding grammatical relations in automatically tagged and manually chunked text.</prevsent>
<prevsent>they report an score of 69.8 for training size of 3299 words of elementary school reading comprehension tests.</prevsent>
</prevsection>
<citsent citstr=" W99-0629 ">
buchholz et al (1999) <papid> W99-0629 </papid>achieve 71.2 f-score for grammatical relation assignment on automatically tagged and chunked text after training on about 40,000 wall street journal sentences.</citsent>
<aftsection>
<nextsent>in contrast to these studies, we do not chunk before finding grammatical relations; rather, chunking is performed simultaneously with headword function tagging.
</nextsent>
<nextsent>measuring f-scores on the correct assignment of functions to headwords in our study, we attain 78.2 f-score using words, 80.1 using attenuated words, 80.9 using attenuated words combined with gold-standard pos, and 79.7 using attenuated words combined with mbt pos (which is slightly worse than with attenuated words only).
</nextsent>
<nextsent>our function tagging task is easier than finding grammatical relations as we tag headword of chunk as e.g. subject in isolation whereas grammatical relation assignment also includes deciding which verb this chunk isthe subject of.
</nextsent>
<nextsent>at-mokhtar and chanod (1997) describe sequence of finite-state transducers in which function tagging is separate step, after pos tagging and chunking.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1864">
<title id=" P03-1015.xml">combining deep and shallow approaches in parsing german </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in several areas of natural language processing, combination of different approaches has been found to give the best results.
</prevsent>
<prevsent>it is especially rewarding to combine deep and shallow systems, where the former guarantees interpret ability and high precision and the latter provides robustness and high recall.this paper investigates such combination consisting of an n-gram based shallow parser and cascaded finite-state parser1 with hand-crafted grammar and morphological checking.
</prevsent>
</prevsection>
<citsent citstr=" A97-1014 ">
the respective strengths and weaknesses of these approaches are brought to light in an in-depth evaluation on tree bank of german newspaper texts (skut et al, 1997) <papid> A97-1014 </papid>containing ca.</citsent>
<aftsection>
<nextsent>340,000 tokens in 19,546 sentences.
</nextsent>
<nextsent>the evaluation format chosen (dependency tuples) is used as the common denominator of the systems 1although not everyone would agree that finite-state parsers constitute deep?
</nextsent>
<nextsent>approach to parsing, they still areknowledge-based, require efforts of grammar-writing, complex linguistic lexicon, manage without training data, etc.in building hybrid parser with improved performance.
</nextsent>
<nextsent>an under specification scheme allows the finite-state parser partially ambiguous output.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1865">
<title id=" P03-1015.xml">combining deep and shallow approaches in parsing german </title>
<section> parser evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>this measure is, how ever, not very informative since most applications do not require one hundred percent correct parse trees.
</prevsent>
<prevsent>thus, an important question in parser evaluation is how to break down parsing results.
</prevsent>
</prevsection>
<citsent citstr=" H91-1060 ">
in the parseval evaluation scheme (black et al., 1991), <papid> H91-1060 </papid>partially correct parses are gauged by the number of nodes they produce and have in common with the gold standard (measured in precision and recall).</citsent>
<aftsection>
<nextsent>another figure (crossing brackets) only counts those incorrect nodes that change the partial order induced by the tree.
</nextsent>
<nextsent>a problematic aspect of the parseval approach is that the weight given to particular constructions is again grammar-specific,since some grammars may need more nodes to describe them than others.
</nextsent>
<nextsent>further, the approach doesnot pay sufficient heed to the fact that parsing decisions are often intricately twisted: one wrong decision may produce whole series of other wrong decisions.
</nextsent>
<nextsent>both these problems are circumvented when parsing results are evaluated on more abstract level, viz.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1867">
<title id=" P03-1015.xml">combining deep and shallow approaches in parsing german </title>
<section> a direct approach: learning </section>
<citcontext>
<prevsection>
<prevsent>to make the learning task easier, the number of classes should be reduced as much as possible.
</prevsent>
<prevsent>for one, the task could be simplified by focusing on un labelled dependency structure (measured in unlabelled?
</prevsent>
</prevsection>
<citsent citstr=" C96-1058 ">
precision and recall (eisner, 1996;<papid> C96-1058 </papid>lin, 1995)), which is, however, in general not sufficient for further semantic processing.</citsent>
<aftsection>
<nextsent>3.1 tree property.
</nextsent>
<nextsent>another possibility for reduction is to associate every word with at most one pair of head token and grammatical role, i.e. to only look at dependency trees rather than graphs.
</nextsent>
<nextsent>there is one case where the tree property cannot easily be maintained: coordination.
</nextsent>
<nextsent>conceptually, all the conjuncts are head constituents in coordination, since the conjunction could be missing, and selectional restrictions work on the individual conjuncts (2).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1868">
<title id=" P03-1015.xml">combining deep and shallow approaches in parsing german </title>
<section> cascaded finite-state parser.  </section>
<citcontext>
<prevsection>
<prevsent>dependencies make up 98.90% of all dependencies correctly found, with the nth-tag method still 82%, but only 79.63% with the finite-state parser (see section 4) and 78.91% in the treebank.
</prevsent>
<prevsent>4if the learner was given chance to correct its errors, i.e. if it could train on its training results in second round, there was statistically significant gain in f-value with recall rising and precision falling (e.g. f-value .7314, precision .7397, recall .7232 for nth-tag trigrams, and f-value .7763, precision .7826, recall .7700 for nth-tag 5-grams).
</prevsent>
</prevsection>
<citsent citstr=" E03-1087 ">
in addition to the learning approach, we used cascaded finite-state parser (schiehlen, 2003), <papid> E03-1087 </papid>to extract dependency structures from the text.</citsent>
<aftsection>
<nextsent>the layout of this parser is similar to abneys parser (abney, 1991): first, series of transducers extracts noun chunks on the basis of tokenized and pos-tagged text.
</nextsent>
<nextsent>since center-embedding is frequent in german noun phrases, the same transducer is used several times over.
</nextsent>
<nextsent>it also has access to inflectional information which is vital for checking agreement and determining case for subsequent phases (see (schiehlen, 2002) <papid> C02-1121 </papid>for more thorough description).</nextsent>
<nextsent>second, series of transducers extracts verb-final, verb-first, and verb-second clauses.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1869">
<title id=" P03-1015.xml">combining deep and shallow approaches in parsing german </title>
<section> cascaded finite-state parser.  </section>
<citcontext>
<prevsection>
<prevsent>the layout of this parser is similar to abneys parser (abney, 1991): first, series of transducers extracts noun chunks on the basis of tokenized and pos-tagged text.
</prevsent>
<prevsent>since center-embedding is frequent in german noun phrases, the same transducer is used several times over.
</prevsent>
</prevsection>
<citsent citstr=" C02-1121 ">
it also has access to inflectional information which is vital for checking agreement and determining case for subsequent phases (see (schiehlen, 2002) <papid> C02-1121 </papid>for more thorough description).</citsent>
<aftsection>
<nextsent>second, series of transducers extracts verb-final, verb-first, and verb-second clauses.
</nextsent>
<nextsent>in contrast to abney, these are full clauses, not just simplex clause chunks, sothat again recur sion can occur.
</nextsent>
<nextsent>third, the resulting parse tree is refined and decorated with grammatical roles, using non-deterministic interpreta tion?
</nextsent>
<nextsent>transducers (the same technique is used byabney (1991)).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1870">
<title id=" P03-1015.xml">combining deep and shallow approaches in parsing german </title>
<section> cascaded finite-state parser.  </section>
<citcontext>
<prevsection>
<prevsent>(karl added some thoughts on/to the work.)
</prevsent>
<prevsent>gedanken fgte [1a] oa/[1b] oa zu [1a0] fgte [1a] pp:zu/[1b] adj [1a1] gedanken pp:zu 1a1   1b 4.2 evaluation of the underspecified.
</prevsent>
</prevsection>
<citsent citstr=" P02-1035 ">
representation in evaluating underspecified representations, riezler et al (2002) <papid> P02-1035 </papid>distinguish upper and lower bound, standing for optimal performance in disambiguation and average performance, respectively.</citsent>
<aftsection>
<nextsent>in i-tags t-tags f-val prec rec f-val prec rec upper .8816 .9137 .8517 .8377 .8910 .7903 direct .8471 .8779 .8183 .8073 .8588 .7617 lower .8266 .8567 .7986 .7895 .8398 .7449 figure 3: results for cascaded parser figure 3, values are also given for the performance of the parser without under specification, i.e. always favoring maximal attachment and word order with out scrambling (direct).
</nextsent>
<nextsent>interestingly this method performs significantly better than average, an effect mainly due to the preference for high attachment.
</nextsent>
<nextsent>we considered several strategies to combine the results of the diverse parsing approaches: simple voting, weighted voting, bayesian learning, maximum entropy, and greedy optimization of f-value.simple voting.
</nextsent>
<nextsent>the result predicted by thema jority of base classifiers is chosen.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1871">
<title id=" P03-1015.xml">combining deep and shallow approaches in parsing german </title>
<section> combining the parsers.  </section>
<citcontext>
<prevsection>
<prevsent>maximum entropy.
</prevsent>
<prevsent>combining the results canalso be seen as classification task, with base predictions added to the original set of features.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
we used the maximum entropy approach5 (berger etal., 1996) <papid> J96-1002 </papid>as machine learner for this task.</citsent>
<aftsection>
<nextsent>underspecified features were assigned multiple values.
</nextsent>
<nextsent>greedy optimization of f-value.
</nextsent>
<nextsent>another method uses decision list of prediction classifier pairs to choose prediction by classifier.
</nextsent>
<nextsent>the list is obtained by greedy optimization: in each step, the prediction classifier pair whose addition results in the highest gain in f-value for the combined model on the training set is appended to the list.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1872">
<title id=" P03-1015.xml">combining deep and shallow approaches in parsing german </title>
<section> in-depth evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>the nth-tag 5-gram method was the best method to combine the finite-state parser with.
</prevsent>
<prevsent>even on t-tags, this combination achieved an f-score of .8520 (lower, upper: .8579, direct: .8329)without pos tag and an f-score of .8563 (lower, up per: .8642, direct: .8535) with pos tags.
</prevsent>
</prevsection>
<citsent citstr=" E03-1025 ">
figure 6 gives survey of the performance of the parsing approaches relative to grammatical role.these figures are more informative than overall score (preiss, 2003).<papid> E03-1025 </papid></citsent>
<aftsection>
<nextsent>the first column gives the name of the grammatical role, as explained below.the second column shows corpus frequency in percent.
</nextsent>
<nextsent>the third column gives the standard deviation of distance between dependent and head.
</nextsent>
<nextsent>the three last columns give the performance (recall) of c4.5 with distance representation and 5-grams, c4.5 with nth-tag representation and 5-grams, and the cascaded finite-state parser, respectively.
</nextsent>
<nextsent>for the finite-state parser, the number shows performance with optimal disambiguation (upper bound) and, if the grammatical role allows under specification, the number for average disambiguation (lower bound) in parentheses.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1873">
<title id=" P03-2003.xml">on the applicability of global index grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>1see for example, (joshi et al, 1991), (weir, 1988).2however other phenomena (e.g. scrambling, georgian case and chinese numbers) might be considered to be beyond certain mildly context-sensitive formalisms.
</prevsent>
<prevsent>tals/lils) is able to capture up to 4 counting dependencies (includes l4 = {anbncndn |n ? 1} but not l5 = {anbncndnen |n ? 1}).
</prevsent>
</prevsection>
<citsent citstr=" J94-2002 ">
they were proven to have recognition algorithms with time complexity o(n6 ) (satta, 1994).<papid> J94-2002 </papid></citsent>
<aftsection>
<nextsent>in general for level-k mcsl the recognition problem is ino(n3 2 k1 ) and the descriptive power regarding counting dependencies is 2k (weir, 1988).
</nextsent>
<nextsent>even the descriptive power of level-2 mcsls(tree adjoining grammars (tags), linear indexed grammars (ligs), combinatory categorial grammars (ccgs) might be considered insufficient for some nl problems, therefore there have been many proposals3 to extend or modify them.
</nextsent>
<nextsent>on our view the possibility of modeling coordination phenomena is probably the most crucial in this respect.in (castano, 2003) we introduced global index grammars (gigs) - and gils the corresponding languages - as an alternative grammar formalism that has restricted context sensitivepower.
</nextsent>
<nextsent>we showed that gigs have enough descriptive power to capture the three phenomena mentioned above (reduplication, multiple agreements, crossed agreements) in their generalized forms.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1874">
<title id=" P03-2003.xml">on the applicability of global index grammars </title>
<section> global index grammars.  </section>
<citcontext>
<prevsection>
<prevsent>(earley, 1970)) for cfls.
</prevsent>
<prevsent>it has to be modified to perform the computations of the stack of indices in gig.
</prevsent>
</prevsection>
<citsent citstr=" J87-1004 ">
in (castano, 2003) graph-structured stack (tomita, 1987) <papid> J87-1004 </papid>was usedto efficiently represent ambiguous index operations in gig stack.</citsent>
<aftsection>
<nextsent>earley items are modified adding three parameters ?, c, o: [?, c,o, ? ?
</nextsent>
<nextsent>a?, i, j] the first two represent pointer to an active node in the graph-structured stack ( ? ?
</nextsent>
<nextsent>i and ? n).
</nextsent>
<nextsent>the third parameter (o ? n) is used to record the ordering of the rules affecting the stack.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1875">
<title id=" P03-2003.xml">on the applicability of global index grammars </title>
<section> gigs and hpsgs.  </section>
<citcontext>
<prevsection>
<prevsent>this follows from the ability of gigs to capture dependencies through different paths in the derivation.
</prevsent>
<prevsent>there has been some work compiling hpsgs into tags (cf.
</prevsent>
</prevsection>
<citsent citstr=" P95-1013 ">
(kasper et al, 1995), (<papid> P95-1013 </papid>becker and lopez, 2000)).</citsent>
<aftsection>
<nextsent>one of the motivations was the potential to improve the processing efficiency of hpsg, performing hpsg derivations at compile time.
</nextsent>
<nextsent>such compilation process allowed to identify significant parts of hpsg grammars that were mildly context-sensitive.we will introduce informally some slight modifications to the operations on the stacks performed by gig.
</nextsent>
<nextsent>we will allow the productions of gig to be annotated with finite strings in ? i? instead of single symbols.
</nextsent>
<nextsent>this does not change the power of the formalism.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1876">
<title id=" P03-1043.xml">a bootstrapping approach to named entity classification using successive learners </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>such systems cannot effectively support user-defined named entities.
</prevsent>
<prevsent>that is the motivation for using unsupervised or weakly supervised machine learning that only requires raw corpus from given domain for this ne research.
</prevsent>
</prevsection>
<citsent citstr=" J01-1005 ">
(cucchiarelli &amp; velardi 2001) <papid> J01-1005 </papid>discussed boosting the performance of an existing ne tagger by unsupervised learning based on parsing structures.</citsent>
<aftsection>
<nextsent>(cucerzan &amp; yarowsky 1999), (<papid> W99-0612 </papid>collins &amp; singer 1999) <papid> W99-0613 </papid>and (kim 2002) presented various techniques using co-training schemes for ne extraction seeded by small list of proper names or handcrafted ne rules.</nextsent>
<nextsent>ne tagging has two tasks: (i) ne chunking; (ii) ne classification.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1877">
<title id=" P03-1043.xml">a bootstrapping approach to named entity classification using successive learners </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>that is the motivation for using unsupervised or weakly supervised machine learning that only requires raw corpus from given domain for this ne research.
</prevsent>
<prevsent>(cucchiarelli &amp; velardi 2001) <papid> J01-1005 </papid>discussed boosting the performance of an existing ne tagger by unsupervised learning based on parsing structures.</prevsent>
</prevsection>
<citsent citstr=" W99-0612 ">
(cucerzan &amp; yarowsky 1999), (<papid> W99-0612 </papid>collins &amp; singer 1999) <papid> W99-0613 </papid>and (kim 2002) presented various techniques using co-training schemes for ne extraction seeded by small list of proper names or handcrafted ne rules.</citsent>
<aftsection>
<nextsent>ne tagging has two tasks: (i) ne chunking; (ii) ne classification.
</nextsent>
<nextsent>parsing supported ne bootstrapping systems including ours only focus on ne classification, assuming ne chunks have been constructed by the parser.
</nextsent>
<nextsent>the key idea of co-training is the separation of features into several orthogonal views.
</nextsent>
<nextsent>in case of ne classification, usually one view uses the context evidence and the other relies on the lexicon evidence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1879">
<title id=" P03-1043.xml">a bootstrapping approach to named entity classification using successive learners </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>that is the motivation for using unsupervised or weakly supervised machine learning that only requires raw corpus from given domain for this ne research.
</prevsent>
<prevsent>(cucchiarelli &amp; velardi 2001) <papid> J01-1005 </papid>discussed boosting the performance of an existing ne tagger by unsupervised learning based on parsing structures.</prevsent>
</prevsection>
<citsent citstr=" W99-0613 ">
(cucerzan &amp; yarowsky 1999), (<papid> W99-0612 </papid>collins &amp; singer 1999) <papid> W99-0613 </papid>and (kim 2002) presented various techniques using co-training schemes for ne extraction seeded by small list of proper names or handcrafted ne rules.</citsent>
<aftsection>
<nextsent>ne tagging has two tasks: (i) ne chunking; (ii) ne classification.
</nextsent>
<nextsent>parsing supported ne bootstrapping systems including ours only focus on ne classification, assuming ne chunks have been constructed by the parser.
</nextsent>
<nextsent>the key idea of co-training is the separation of features into several orthogonal views.
</nextsent>
<nextsent>in case of ne classification, usually one view uses the context evidence and the other relies on the lexicon evidence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1885">
<title id=" P03-1043.xml">a bootstrapping approach to named entity classification using successive learners </title>
<section> parsing-based ne rule learning.  </section>
<citcontext>
<prevsection>
<prevsent>for example, at string sequence level, person names are often preceded by set of pre fixing title words mr./mrs./miss/dr. etc., but the corresponding common noun seeds man/woman etc. cannot appear in such patterns.
</prevsent>
<prevsent>however, at structural level, the concept-based seeds share the same or similar linguistic patterns (e.g. subject-verb-object patterns) with the corresponding types of proper names.
</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
the rationale behind using concept-based seeds in ne bootstrapping is similar to that for parsing based word clustering (lin 1998): <papid> P98-2127 </papid>conceptually similar words occur in structurally similar context.</citsent>
<aftsection>
<nextsent>in fact, the anaphoric function of pronouns and common nouns to represent antecedent nes indicates the substitutability of proper names by the corresponding common nouns or pronouns.
</nextsent>
<nextsent>for example, this man can be substituted for the proper name john smith in almost all structural patterns.
</nextsent>
<nextsent>following the same rationale, bootstrapping approach is applied to the semantic lexicon acquisition task [thelen &amp; riloff.
</nextsent>
<nextsent>2002].
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1886">
<title id=" P03-1043.xml">a bootstrapping approach to named entity classification using successive learners </title>
<section> automatic construction of annotated.  </section>
<citcontext>
<prevsection>
<prevsent>after applying the decision list to the above the ne candidates, 33,104 per names, 16,426 loc names, 11,908 org names and 6,280 pro names were extracted.
</prevsent>
<prevsent>it is common practice in the bootstrapping research to make use of heuristics that suggest conditions under which instances should share the same answer.
</prevsent>
</prevsection>
<citsent citstr=" H92-1045 ">
for example, the one sense per discourse principle is often used for word sense disambiguation (gale et al 1992).<papid> H92-1045 </papid></citsent>
<aftsection>
<nextsent>in this research, we used the heuristic one tag per domain for multiword ne in addition to the one sense per discourse principle.
</nextsent>
<nextsent>these heuristics were found to be very helpful in improving the performance of the bootstrapping algorithm for the purpose of both increasing positive instances (i.e. tag propagation) and decreasing the spurious instances (i.e. tag elimination).
</nextsent>
<nextsent>the following are two examples to show how the tag propagation and elimination scheme works.
</nextsent>
<nextsent>tyco toys occurs 67 times in the corpus, and 11 instances are recognized as org, only one instance is recognized as per.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1887">
<title id=" P03-1043.xml">a bootstrapping approach to named entity classification using successive learners </title>
<section> automatic construction of annotated.  </section>
<citcontext>
<prevsection>
<prevsent>three instances of postal service are recognized as org, and two instances are recognized as per.
</prevsent>
<prevsent>these tags are regarded as noise, hence are removed by the tag elimination scheme.
</prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
the tag propagation/elimination scheme is adopted from (yarowsky 1995).<papid> P95-1026 </papid></citsent>
<aftsection>
<nextsent>after this step, total of 386,614 proper names were recognized, including 134,722 per names, 186,488 loc names, 46,231 org names and 19,173 pro names.
</nextsent>
<nextsent>the overall precision was ~90%.
</nextsent>
<nextsent>the benchmark details will be shown in section 6.
</nextsent>
<nextsent>the extracted proper name instances then led to the construction of fairly large training corpus sufficient for training the second ne learner.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1889">
<title id=" N12-1079.xml">why not grab a free lunch mining large corpora for parallel sentences to improve translation modeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>augmenting existing bitextwith these data yielded significant improvements over state-of-the-art baseline (2.39 bleu points in the best case).
</prevsent>
<prevsent>it has been repeatedly shown that throwing more data at the problem?
</prevsent>
</prevsection>
<citsent citstr=" W08-0333 ">
is effective in increasing smt output quality, both for translation modeling (dyer et al, 2008) <papid> W08-0333 </papid>and for language modeling (brants etal., 2007).<papid> D07-1090 </papid></citsent>
<aftsection>
<nextsent>in this paper, we bring together two related research threads to gather parallel sentences for improved translation modeling: cross-lingual pairwise similarity to mine comparable documents and classification to identify sentence pairs that are mutual translations.
</nextsent>
<nextsent>unlike most previous work, which sidesteps thecomputationally-intensive task of pairwise comparisons to mine comparable documents and instead relies on heuristics, we tackle the challenge head on.
</nextsent>
<nextsent>this paper describes fully open-source, scalable mapreduce-based processing pipeline that is able to automatically extract large quantities of parallel sentences.
</nextsent>
<nextsent>experiments examine the impact data size has on state-of-the-art smt system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1890">
<title id=" N12-1079.xml">why not grab a free lunch mining large corpora for parallel sentences to improve translation modeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>augmenting existing bitextwith these data yielded significant improvements over state-of-the-art baseline (2.39 bleu points in the best case).
</prevsent>
<prevsent>it has been repeatedly shown that throwing more data at the problem?
</prevsent>
</prevsection>
<citsent citstr=" D07-1090 ">
is effective in increasing smt output quality, both for translation modeling (dyer et al, 2008) <papid> W08-0333 </papid>and for language modeling (brants etal., 2007).<papid> D07-1090 </papid></citsent>
<aftsection>
<nextsent>in this paper, we bring together two related research threads to gather parallel sentences for improved translation modeling: cross-lingual pairwise similarity to mine comparable documents and classification to identify sentence pairs that are mutual translations.
</nextsent>
<nextsent>unlike most previous work, which sidesteps thecomputationally-intensive task of pairwise comparisons to mine comparable documents and instead relies on heuristics, we tackle the challenge head on.
</nextsent>
<nextsent>this paper describes fully open-source, scalable mapreduce-based processing pipeline that is able to automatically extract large quantities of parallel sentences.
</nextsent>
<nextsent>experiments examine the impact data size has on state-of-the-art smt system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1891">
<title id=" N12-1079.xml">why not grab a free lunch mining large corpora for parallel sentences to improve translation modeling </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>identify comparable documents and generate candidate sentence pairs, and 2.
</prevsent>
<prevsent>filter candidate pairs to retain parallel sentences.the general solution to the first step involves computing pairwise similarities across multi-lingual corpora.
</prevsent>
</prevsection>
<citsent citstr=" J05-4003 ">
as this is computationally intensive, most 626 studies fall back to heuristics, e.g., comparing news articles close in time (munteanu and marcu, 2005), <papid> J05-4003 </papid>exploiting inter-wiki?</citsent>
<aftsection>
<nextsent>links in wikipedia (smith et al., 2010), <papid> N10-1063 </papid>or bootstrapping off an existing search engine (resnik and smith, 2003).<papid> J03-3002 </papid></nextsent>
<nextsent>in contrast, weadopt more exhaustive approach by directly tackling the cross-lingual pairwise similarity problem, using map reduce on modest cluster.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1892">
<title id=" N12-1079.xml">why not grab a free lunch mining large corpora for parallel sentences to improve translation modeling </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>filter candidate pairs to retain parallel sentences.the general solution to the first step involves computing pairwise similarities across multi-lingual corpora.
</prevsent>
<prevsent>as this is computationally intensive, most 626 studies fall back to heuristics, e.g., comparing news articles close in time (munteanu and marcu, 2005), <papid> J05-4003 </papid>exploiting inter-wiki?</prevsent>
</prevsection>
<citsent citstr=" N10-1063 ">
links in wikipedia (smith et al., 2010), <papid> N10-1063 </papid>or bootstrapping off an existing search engine (resnik and smith, 2003).<papid> J03-3002 </papid></citsent>
<aftsection>
<nextsent>in contrast, weadopt more exhaustive approach by directly tackling the cross-lingual pairwise similarity problem, using map reduce on modest cluster.
</nextsent>
<nextsent>we perform experiments on german and english wikipedia (two largest available), but our technique is general anddoes not depend on sparse, manually-created inter wiki links.
</nextsent>
<nextsent>thus, compared to those approaches, we achieve much higher recall.
</nextsent>
<nextsent>the second step (filtering candidate sentence pairs) is relatively straightforward, and we adopt the classification approach of munteanu and marcu (2005).<papid> J05-4003 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1893">
<title id=" N12-1079.xml">why not grab a free lunch mining large corpora for parallel sentences to improve translation modeling </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>filter candidate pairs to retain parallel sentences.the general solution to the first step involves computing pairwise similarities across multi-lingual corpora.
</prevsent>
<prevsent>as this is computationally intensive, most 626 studies fall back to heuristics, e.g., comparing news articles close in time (munteanu and marcu, 2005), <papid> J05-4003 </papid>exploiting inter-wiki?</prevsent>
</prevsection>
<citsent citstr=" J03-3002 ">
links in wikipedia (smith et al., 2010), <papid> N10-1063 </papid>or bootstrapping off an existing search engine (resnik and smith, 2003).<papid> J03-3002 </papid></citsent>
<aftsection>
<nextsent>in contrast, weadopt more exhaustive approach by directly tackling the cross-lingual pairwise similarity problem, using map reduce on modest cluster.
</nextsent>
<nextsent>we perform experiments on german and english wikipedia (two largest available), but our technique is general anddoes not depend on sparse, manually-created inter wiki links.
</nextsent>
<nextsent>thus, compared to those approaches, we achieve much higher recall.
</nextsent>
<nextsent>the second step (filtering candidate sentence pairs) is relatively straightforward, and we adopt the classification approach of munteanu and marcu (2005).<papid> J05-4003 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1895">
<title id=" N12-1079.xml">why not grab a free lunch mining large corpora for parallel sentences to improve translation modeling </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>therefore, we care about the relationship between classification accuracy and the speed of the classifier.
</prevsent>
<prevsent>our two-stage approach gives us both high effectiveness (accuracy) and efficiency (speed).
</prevsent>
</prevsection>
<citsent citstr=" C10-1124 ">
a recent study from google describes general solution to our problem that scales to web collections (uszkoreit et al, 2010).<papid> C10-1124 </papid></citsent>
<aftsection>
<nextsent>the authors translate all documents from one language into another, thus transforming the problem into identifying similarmono-lingual document pairs.
</nextsent>
<nextsent>nevertheless, our approach makes several additional contributions.
</nextsent>
<nextsent>first, we explore the effect of dataset size on results.
</nextsent>
<nextsent>our conclusions are more nuanced than simply more data is better?, since there is tradeoff between quality and quantity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1897">
<title id=" N12-1079.xml">why not grab a free lunch mining large corpora for parallel sentences to improve translation modeling </title>
<section> generating candidate sentences.  </section>
<citcontext>
<prevsection>
<prevsent>each of the remaining candidate sentences are then processed by two separate classifiers: less accurate, fast classifier and more accurate, slow classifier.
</prevsent>
<prevsent>this is described in the next section.
</prevsent>
</prevsection>
<citsent citstr=" N10-4001 ">
this algorithm is variant of what is commonly known as reduce-side join in map reduce (lin and dyer, 2010), <papid> N10-4001 </papid>where (de, df ) serves as the join key.</citsent>
<aftsection>
<nextsent>note that in this algorithm, sentence vectors are emitted multiple times, one for each (de, df ) pair that they participate in: this results in increased network traffic during the sort/shufflephase.
</nextsent>
<nextsent>we experimented with an alternative algorithm that processes all foreign documents similar to the same english document together, e.g., processing (de, [df1, df2, . . .]) together.
</nextsent>
<nextsent>this approach,counter-intuitively, was slower despite reduced network traffic, due to skew in the distribution of similar document pairs.
</nextsent>
<nextsent>in our experiments, half of the source collection was not linked to any target document, whereas 4% had more than 100 links.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1899">
<title id=" N12-1079.xml">why not grab a free lunch mining large corpora for parallel sentences to improve translation modeling </title>
<section> end-to-end mt experiments.  </section>
<citcontext>
<prevsection>
<prevsent>these candidates went through the map reduce shuffle-and-sort process in 0.75 hours, which were then classified in 4 hours.
</prevsent>
<prevsent>628 processing by the more complex classifier in s2 took an additional 0.52 hours.
</prevsent>
</prevsection>
<citsent citstr=" J07-2003 ">
in all experiments, our mt system learned synchronous context-free grammar (chiang, 2007), <papid> J07-2003 </papid>using giza++ for word alignments, mira for parameter tuning (crammer et al, 2006), cdec forde coding (dyer et al, 2010), <papid> P10-4002 </papid>5-gram srilm for language modeling, and single-reference bleu for evaluation.</citsent>
<aftsection>
<nextsent>the baseline system was trained on the german-english wmt10 training data, consisting of 3.1m sentence pairs.
</nextsent>
<nextsent>for development and testing, we used the newswire datasets provided for wmt10, including 2525 sentences for tuning and 2489 sentences for testing.our baseline system includes all standard features, including phrase translation probabilities inboth directions, word and arity penalties, and language model scores.
</nextsent>
<nextsent>it achieves bleu score of 21.37 on the test set, which would place it 5th out of 9 systems that reported comparable results in wmt10 (only three systems achieved bleu score over 22).
</nextsent>
<nextsent>many of these systems used techniques that exploited the specific aspects of the task, e.g., german-specific morphological analysis.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1900">
<title id=" N12-1079.xml">why not grab a free lunch mining large corpora for parallel sentences to improve translation modeling </title>
<section> end-to-end mt experiments.  </section>
<citcontext>
<prevsection>
<prevsent>these candidates went through the map reduce shuffle-and-sort process in 0.75 hours, which were then classified in 4 hours.
</prevsent>
<prevsent>628 processing by the more complex classifier in s2 took an additional 0.52 hours.
</prevsent>
</prevsection>
<citsent citstr=" P10-4002 ">
in all experiments, our mt system learned synchronous context-free grammar (chiang, 2007), <papid> J07-2003 </papid>using giza++ for word alignments, mira for parameter tuning (crammer et al, 2006), cdec forde coding (dyer et al, 2010), <papid> P10-4002 </papid>5-gram srilm for language modeling, and single-reference bleu for evaluation.</citsent>
<aftsection>
<nextsent>the baseline system was trained on the german-english wmt10 training data, consisting of 3.1m sentence pairs.
</nextsent>
<nextsent>for development and testing, we used the newswire datasets provided for wmt10, including 2525 sentences for tuning and 2489 sentences for testing.our baseline system includes all standard features, including phrase translation probabilities inboth directions, word and arity penalties, and language model scores.
</nextsent>
<nextsent>it achieves bleu score of 21.37 on the test set, which would place it 5th out of 9 systems that reported comparable results in wmt10 (only three systems achieved bleu score over 22).
</nextsent>
<nextsent>many of these systems used techniques that exploited the specific aspects of the task, e.g., german-specific morphological analysis.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1901">
<title id=" P04-1057.xml">error mining for wide coverage grammar engineering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we propose new combination of suffix arrays with perfect hash finite automata, which reduces typical memory requirements by factor of five, in combination with modest increase in processing efficiency.
</prevsent>
<prevsent>4.1 suffix arrays.
</prevsent>
</prevsection>
<citsent citstr=" J01-1001 ">
suffix arrays (manber and myers, 1990; yamamoto and church, 2001) <papid> J01-1001 </papid>are simple, but useful data structure for various text-processing tasks.</citsent>
<aftsection>
<nextsent>a corp usis sequence of characters.
</nextsent>
<nextsent>a suffix array is an array consisting of all suffixes of the corpus, sorted alphabetically.
</nextsent>
<nextsent>for example, if the corpus is the string abba, the suffix array is a,abba,ba,bba?.
</nextsent>
<nextsent>rather than writing out each suffix, we use inte gers to refer to the suffix starting at position in the corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1902">
<title id=" P03-1020.xml">true casing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>finally, we demonstrate the considerable benefits of true casing through task based evaluations on named entity tagging and automatic content extraction.
</prevsent>
<prevsent>1.1 related work.
</prevsent>
</prevsection>
<citsent citstr=" P94-1013 ">
true casing can be viewed in lexical ambiguity resolution framework (yarowsky, 1994) <papid> P94-1013 </papid>as discriminating among several versions of word, which happen to have different surface forms (casings).</citsent>
<aftsection>
<nextsent>word sense disambiguation is broad scope problem that has been tackled with fairly good results generally due to the fact that context is very good predictor when choosing the sense of word.
</nextsent>
<nextsent>(gale et al, 1994) mention good results on limited case restoration experiments on toy problems with 100 words.
</nextsent>
<nextsent>they also observe that real world problems generally exhibit around 90% case restoration accuracy.
</nextsent>
<nextsent>(mikheev, 1999) <papid> P99-1021 </papid>also approaches casing disambiguation but models only instances when capitalization is expected: first word in sentence, after period, and after quotes.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1904">
<title id=" P03-1020.xml">true casing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(gale et al, 1994) mention good results on limited case restoration experiments on toy problems with 100 words.
</prevsent>
<prevsent>they also observe that real world problems generally exhibit around 90% case restoration accuracy.
</prevsent>
</prevsection>
<citsent citstr=" P99-1021 ">
(mikheev, 1999) <papid> P99-1021 </papid>also approaches casing disambiguation but models only instances when capitalization is expected: first word in sentence, after period, and after quotes.</citsent>
<aftsection>
<nextsent>(chieu and ng, 2002) <papid> P02-1061 </papid>attempted to extract named entities from non-casedtext by using weaker classifier but without focusing on regular text or case restoration.</nextsent>
<nextsent>accents can be viewed as additional surface formsor alternate word casings.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1905">
<title id=" P03-1020.xml">true casing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they also observe that real world problems generally exhibit around 90% case restoration accuracy.
</prevsent>
<prevsent>(mikheev, 1999) <papid> P99-1021 </papid>also approaches casing disambiguation but models only instances when capitalization is expected: first word in sentence, after period, and after quotes.</prevsent>
</prevsection>
<citsent citstr=" P02-1061 ">
(chieu and ng, 2002) <papid> P02-1061 </papid>attempted to extract named entities from non-casedtext by using weaker classifier but without focusing on regular text or case restoration.</citsent>
<aftsection>
<nextsent>accents can be viewed as additional surface formsor alternate word casings.
</nextsent>
<nextsent>from this perspective, either accent identification can be extended to true casing or true casing can be extended to incorporate accent restoration.
</nextsent>
<nextsent>(yarowsky, 1994) <papid> P94-1013 </papid>reports good results with statistical methods for spanish and french accent restoration.</nextsent>
<nextsent>true casing is also specialized method for spelling correction by relaxing the notion of casing to spelling variations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1908">
<title id=" P03-1020.xml">true casing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(yarowsky, 1994) <papid> P94-1013 </papid>reports good results with statistical methods for spanish and french accent restoration.</prevsent>
<prevsent>true casing is also specialized method for spelling correction by relaxing the notion of casing to spelling variations.</prevsent>
</prevsection>
<citsent citstr=" A97-1025 ">
there is vast literature on spelling correction (jones and martin, 1997; <papid> A97-1025 </papid>golding and roth, 1996) using both linguistic and statistical approaches.</citsent>
<aftsection>
<nextsent>also, (brill and moore, 2000) <papid> P00-1037 </papid>apply noisy channel model, based on generic string to string edits, to spelling correction.</nextsent>
<nextsent>in this paper we take statistical approach to true casing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1909">
<title id=" P03-1020.xml">true casing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>true casing is also specialized method for spelling correction by relaxing the notion of casing to spelling variations.
</prevsent>
<prevsent>there is vast literature on spelling correction (jones and martin, 1997; <papid> A97-1025 </papid>golding and roth, 1996) using both linguistic and statistical approaches.</prevsent>
</prevsection>
<citsent citstr=" P00-1037 ">
also, (brill and moore, 2000) <papid> P00-1037 </papid>apply noisy channel model, based on generic string to string edits, to spelling correction.</citsent>
<aftsection>
<nextsent>in this paper we take statistical approach to true casing.
</nextsent>
<nextsent>first we present the baseline: simple,straight forward unigram model which performs reasonably well in most cases.
</nextsent>
<nextsent>then, we propose better, more flexible statistical truecaser based on language modeling.
</nextsent>
<nextsent>from true casing perspective we observe four general classes of words: all lowercase (lc), first letter upper case (uc), all letters upper case (ca), and mixed case word mc).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1910">
<title id=" P03-1020.xml">true casing </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>we have successfully leveraged true casing in improving named entity recognition and automatic content extraction.
</prevsent>
<prevsent>3.4.1 named entity tagging in order to evaluate the effect of true casing on extracting named entity labels, we tested an existing named entity system on test set that has significant case mismatch to the training of the system.
</prevsent>
</prevsection>
<citsent citstr=" A97-1029 ">
the base system is an hmm based tagger, similar to (bikel et al, 1997).<papid> A97-1029 </papid></citsent>
<aftsection>
<nextsent>the system has 31 semantic categories which are extensions on the muc categories.
</nextsent>
<nextsent>the tagger creates lattice of decisions corresponding to tokenized words in the input stream.
</nextsent>
<nextsent>when tagging word wi in sentence of words w0...wn , two possibilities.
</nextsent>
<nextsent>if tag begins: p(tn1 |wn1 )i = p(ti|ti1, wi1)p?(wi|ti, wi1) if tag continues: p(tn1 |wn1 )i = p(wi|ti, wi1) the ? indicates that the distribution is formed from words that are the first words of entities.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1914">
<title id=" P01-1034.xml">xml based data preparation for robust deep parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>ing that supports the computation of semantics.
</prevsent>
<prevsent>the computation of grammatical relations?
</prevsent>
</prevsection>
<citsent citstr=" W99-0629 ">
from shallow parsers or chunk ers is still at an early stage (buchholz et al , 1999, <papid> W99-0629 </papid>carroll et al , 1998)<papid> W98-1114 </papid>and there are few other robust semantic processors, and none in the medical domain.</citsent>
<aftsection>
<nextsent>wehave therefore chosen to re-use an existing handcrafted grammar which produces compositionally derived underspecified logical forms, namely the wide-coverage grammar, morphological analyse rand lexicon provided by the alvey natural language tools (anlt) system (carroll et al  1991, grover et al  1993).
</nextsent>
<nextsent>our immediate aim is to increase coverage up to reasonable level and thereafter to experiment with ranking the parses,e.g. using briscoe and carrolls (1993) <papid> J93-1002 </papid>probabilistic extension of the anlt software.</nextsent>
<nextsent>we use xml as the preprocessing mark-up technology, specifically the lt ttt and lt xml tools (grover et al , 2000; thompson et al , 1997).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1915">
<title id=" P01-1034.xml">xml based data preparation for robust deep parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>ing that supports the computation of semantics.
</prevsent>
<prevsent>the computation of grammatical relations?
</prevsent>
</prevsection>
<citsent citstr=" W98-1114 ">
from shallow parsers or chunk ers is still at an early stage (buchholz et al , 1999, <papid> W99-0629 </papid>carroll et al , 1998)<papid> W98-1114 </papid>and there are few other robust semantic processors, and none in the medical domain.</citsent>
<aftsection>
<nextsent>wehave therefore chosen to re-use an existing handcrafted grammar which produces compositionally derived underspecified logical forms, namely the wide-coverage grammar, morphological analyse rand lexicon provided by the alvey natural language tools (anlt) system (carroll et al  1991, grover et al  1993).
</nextsent>
<nextsent>our immediate aim is to increase coverage up to reasonable level and thereafter to experiment with ranking the parses,e.g. using briscoe and carrolls (1993) <papid> J93-1002 </papid>probabilistic extension of the anlt software.</nextsent>
<nextsent>we use xml as the preprocessing mark-up technology, specifically the lt ttt and lt xml tools (grover et al , 2000; thompson et al , 1997).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1916">
<title id=" P01-1034.xml">xml based data preparation for robust deep parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>from shallow parsers or chunk ers is still at an early stage (buchholz et al , 1999, <papid> W99-0629 </papid>carroll et al , 1998)<papid> W98-1114 </papid>and there are few other robust semantic processors, and none in the medical domain.</prevsent>
<prevsent>wehave therefore chosen to re-use an existing handcrafted grammar which produces compositionally derived underspecified logical forms, namely the wide-coverage grammar, morphological analyse rand lexicon provided by the alvey natural language tools (anlt) system (carroll et al  1991, grover et al  1993).</prevsent>
</prevsection>
<citsent citstr=" J93-1002 ">
our immediate aim is to increase coverage up to reasonable level and thereafter to experiment with ranking the parses,e.g. using briscoe and carrolls (1993) <papid> J93-1002 </papid>probabilistic extension of the anlt software.</citsent>
<aftsection>
<nextsent>we use xml as the preprocessing mark-up technology, specifically the lt ttt and lt xml tools (grover et al , 2000; thompson et al , 1997).
</nextsent>
<nextsent>in the initial stages of the project we converted the ohsumed corpus into xml annotated format with mark-up that encodes word tokens, pos tags,lemmatisation information etc. the research reported here builds on that mark-up in further stage of pre-processing prior to parsing.
</nextsent>
<nextsent>the xml paradigm has proved invaluable throughout.
</nextsent>
<nextsent>2.1 strategy.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1917">
<title id=" P01-1034.xml">xml based data preparation for robust deep parsing </title>
<section> improving the lexical component.  </section>
<citcontext>
<prevsection>
<prevsent>for example, monitoring is present in the anlt lexicon as verb but not as noun: we studied vbd the value nn of trans cutaneous jj carbon nn dioxide nn monitoring nn during transport nn look up of the word tag pair monitoring nnfails and the basic entry for the tag nn is used instead.
</prevsent>
<prevsent>without the tag, the verb entry for monitoring would be accessed and the parse would fail.in the following example the adjectives diminished and stabilized exist only as verb entries: with the jj tag the parse succeeds but without it, the verb entries are accessed and the parse fails.
</prevsent>
</prevsection>
<citsent citstr=" H94-1020 ">
there was radiographic jj evidence nn of diminished jj or stabilized jj pleural jj effusion nn2the lt ttt tagger uses the penn treebank tagset (mar cus et al , 1994): <papid> H94-1020 </papid>jj labels adjectives, nn labels nouns and vb labels verbs.note that cases such as these would be problematic for strategy where tagging was used only when lexical look-up failed, since here lexicallook-up doesnt fail, it just provides an incomplete set of entries.</citsent>
<aftsection>
<nextsent>it is of course possible to augment the grammar and/or lexicon with rules to infer noun entries from verb+ing entries and adjective entries from verb+ed entries.
</nextsent>
<nextsent>however, this will increase lexical ambiguity quite considerably and lead to higher numbers of spurious parses.
</nextsent>
<nextsent>2.2 implementation.
</nextsent>
<nextsent>we expect the technique outlined above to be applicable across range of parsing systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1919">
<title id=" P01-1034.xml">xml based data preparation for robust deep parsing </title>
<section> xml tools for pre-processing.  </section>
<citcontext>
<prevsection>
<prevsent>a sample part of the output of this basic pipeline is shown in figure 1.
</prevsent>
<prevsent>the initial conversion to xmland the identification of words is achieved using the core lt ttt program fsgmatch, general purpose transducer which processes an in put stream and rewrites it using rules provided in grammar file.
</prevsent>
</prevsection>
<citsent citstr=" J97-3003 ">
the identification of sentence boundaries, mark-up of sentence elements andpos tagging is done by the statistical program lt pos (mikheev, 1997).<papid> J97-3003 </papid></citsent>
<aftsection>
<nextsent>words are marked up as elements with further information encoded as values of attributes on the elements.
</nextsent>
<nextsent>in the example, the attributes value is pos tag and the lm attributes is lemma (only on nouns andverbs).
</nextsent>
<nextsent>the lemmatisation is performed by min nen et al (2000) <papid> W00-1427 </papid>morpha program which is not an xml processor.</nextsent>
<nextsent>in such cases we pass data out of the pipeline in the format required by the tool and merge its output back into the xml mark-up.typically we use mckelvies (1999) xmlperl program to convert out of and back into xml: for anlt this involves putting each sentence on one line, converting some elements into word tag pairs and stripping out all other xml mark-up to provide input to the parser in the form it requires.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1920">
<title id=" P01-1034.xml">xml based data preparation for robust deep parsing </title>
<section> xml tools for pre-processing.  </section>
<citcontext>
<prevsection>
<prevsent>words are marked up as elements with further information encoded as values of attributes on the elements.
</prevsent>
<prevsent>in the example, the attributes value is pos tag and the lm attributes is lemma (only on nouns andverbs).
</prevsent>
</prevsection>
<citsent citstr=" W00-1427 ">
the lemmatisation is performed by min nen et al (2000) <papid> W00-1427 </papid>morpha program which is not an xml processor.</citsent>
<aftsection>
<nextsent>in such cases we pass data out of the pipeline in the format required by the tool and merge its output back into the xml mark-up.typically we use mckelvies (1999) xmlperl program to convert out of and back into xml: for anlt this involves putting each sentence on one line, converting some elements into word tag pairs and stripping out all other xml mark-up to provide input to the parser in the form it requires.
</nextsent>
<nextsent>we are currently experimenting with bringing the labelled bracketing of the parse result back into the xml as stand-off?
</nextsent>
<nextsent>mark up.
</nextsent>
<nextsent>3.1 pre-processing for parsing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1921">
<title id=" P01-1034.xml">xml based data preparation for robust deep parsing </title>
<section> evaluation and future research.  </section>
<citcontext>
<prevsection>
<prevsent>moreover, we have not yet incorporated any domain specific lexical knowledge from, e.g., umls but we would expect this to contribute to improved performance.
</prevsent>
<prevsent>furthermore, our current level of success has been achieved without significant changes to the original grammar and, once we start to tailor the grammar to the domain, we will gain further significant increases in performance.
</prevsent>
</prevsection>
<citsent citstr=" P99-1052 ">
as final stage, we may find it useful to follow kasper et al  (1999) <papid> P99-1052 </papid>and have fallback?</citsent>
<aftsection>
<nextsent>strategy for failed parses where the best partial analyses are assembled in robust processing phase.
</nextsent>



</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1922">
<title id=" P04-3005.xml">customizing parallel corpora at the document level </title>
<section> clir method.  </section>
<citcontext>
<prevsection>
<prevsent>here, blind feedback is the process of retrieving documents and adding the terms of the top-ranking documents to the query for expansion.
</prevsent>
<prevsent>we used simplified rocchio positive feedback as implemented by lemur (olgivie and callan, 2001).
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
for the results in this paper, we have used pointwise mutual information (pmi) instead of ibm model 1 (brown et al, 1993), <papid> J93-2003 </papid>since (rogati and yang, 2004) found it to be as effective on springer, but faster to compute.</citsent>
<aftsection>
<nextsent>5.1 empirical settings.
</nextsent>
<nextsent>for the retrieval part of our system, we adapted lemur (ogilvie and callan, 2001) to allow the use of weighted queries.
</nextsent>
<nextsent>several parameters were tuned, none of them on the test set.
</nextsent>
<nextsent>in our corpus based approach, the main parameters are those used in query expansion based on pseudo relevance, i.e., the maximum number of documents and the maximum number of words to be used, and the relative weight of the expanded portion with respect to the initial query.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1923">
<title id=" P00-1001.xml">invited talk processes that shape conversation and their implications for computational linguistics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in humans, speech production and speech processing are done incrementally, using contextual information from the earliest moments of processing (see, e.g., tanenhaus et al. 1995).
</prevsent>
<prevsent>this sort of processing requires quite different architecture and different mechanisms for ambiguity resolution than one that begins processing only at the end of complete and well-formed utterance.
</prevsent>
</prevsection>
<citsent citstr=" P83-1019 ">
few approaches to parsing have tried to handle dis fluent utterances (notable exceptions are core &amp; schubert, 1999; hindle, 1983; <papid> P83-1019 </papid>nakatani &amp; hirschberg, 1994; shriberg, bear, &amp; dowding, 1992).</citsent>
<aftsection>
<nextsent>the few psycho linguistic experiments that have examined human processing of dis fluent speech also throw into question the assumption that dis fluent speech is harder to process than fluent speech.
</nextsent>
<nextsent>lickley and bard (1996) found evidence that listeners may be relatively deaf to the words in reparandum (the part that would need to be excised in order for the utterance to be fluent), and shriberg and lickley (1993) found that fillers such as um or uh may be produced with distinctive intonation that helps listeners distinguish them from the rest of the utterance.
</nextsent>
<nextsent>fox tree (1995) found that while previous restarts in an utterance may slow listeners monitoring for particular word, repetitions dont seem to hurt, and some fillers, such as uh, seem to actually speed monitoring for subsequent word.
</nextsent>
<nextsent>what information exists in disfluencies, and how might speakers use it?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1924">
<title id=" P03-1030.xml">optimizing story link detection is not equivalent to optimizing new event detection </title>
<section> differences between lnk and ned.  </section>
<citcontext>
<prevsection>
<prevsent>6.2 similarity measures.
</prevsent>
<prevsent>the systems developed for tdt primarily use co sine similarity as the similarity measure.
</prevsent>
</prevsection>
<citsent citstr=" N03-2005 ">
we have developed systems based on cosine similarity (chen et al, 2003).<papid> N03-2005 </papid></citsent>
<aftsection>
<nextsent>in work on text segmentation, (brants et al, 2002) observed that the system performance was much better when the hell inger measure was used instead.
</nextsent>
<nextsent>in this work, we decided to use the clarity metric, precision enhancing device (croft et al., 2001).
</nextsent>
<nextsent>for both our lnk and ned systems, we compared the performance of the systems using each of the similarity measures separately.
</nextsent>
<nextsent>table 1 shows that for lnk, the system based on clarity similarity performed better the system based on hell inger similarity; in contrast, for ned, the system based on 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 similarity cd ned hell inger vs. clarity hell inger on topic hell inger off topic clarity on topic clarity off topic figure 2: cdf for clarity and hell inger similarity on the ned task for on-topic and off-topic pairs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1925">
<title id=" P03-1030.xml">optimizing story link detection is not equivalent to optimizing new event detection </title>
<section> differences between lnk and ned.  </section>
<citcontext>
<prevsection>
<prevsent>another situation where asr is different from transcribed text is abbreviations, e.g. asr system will recognize cnn?
</prevsent>
<prevsent>as three separate tokens c?, n?, and n?.in order to account for these differences, we identified the set of tokens that are problematic for asr.
</prevsent>
</prevsection>
<citsent citstr=" J93-1003 ">
our approach was to identify parallel corpus of manually and automatically transcribed documents, the tdt2 corpus, and then use statistical approach (dunning, 1993) <papid> J93-1003 </papid>to identify tokens with significantly table 5: impact of recall and precision enhancing devices.</citsent>
<aftsection>
<nextsent>device impact lnk ned asr stop precision +3.1% -5.5 % pos recall -38.8 % 8.3 % clarity precision +19 % -30 %different distributions in the two corpora.
</nextsent>
<nextsent>we compiled the problematic asr terms into an asr stoplist?.
</nextsent>
<nextsent>this list was primarily composed of spelled out numbers, numerals and few other terms.
</nextsent>
<nextsent>table 4 shows the topic-weighted minimum detection costs for lnk and ned on the tdt 2002 dry rundata.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1927">
<title id=" N12-1081.xml">comparing hmms and bayesian networks for surface realisation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>and constructs semantic form.
</prevsent>
<prevsent>utterance planning organises the message into sub messages and surface realisation maps the semantics onto words.
</prevsent>
</prevsection>
<citsent citstr=" D10-1049 ">
recently, number of studies have pointed out that many decisions made at these distinct stages require interrelated, rather than isolated, optimisations (angeli et al, 2010; <papid> D10-1049 </papid>lemon, 2011; cuayahuitl and dethlefs, 2011a; dethlefs and cuayahuitl, 2011a).</citsent>
<aftsection>
<nextsent>the key feature of joint architecture is that decisions of all three nlg stages share information and can be made in an interrelated fashion.
</nextsent>
<nextsent>we present joint nlg framework based on hierarchical rl and focus, in particular, on the surface realisation component of joint nlg systems.
</nextsent>
<nextsent>we compare the user satisfaction and naturalness of surface realisation using hidden markov models (hmms) and bayesian networks (bns) which both have been suggested as generation spaces spaces of surface form variants for semantic concept?
</nextsent>
<nextsent>within joint nlg systems (dethlefs and cuayahuitl,2011a; dethlefs and cuayahuitl, 2011b) and in isolation (georgila et al, 2002; mairesse et al, 2010).<papid> P10-1157 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1928">
<title id=" N12-1081.xml">comparing hmms and bayesian networks for surface realisation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we present joint nlg framework based on hierarchical rl and focus, in particular, on the surface realisation component of joint nlg systems.
</prevsent>
<prevsent>we compare the user satisfaction and naturalness of surface realisation using hidden markov models (hmms) and bayesian networks (bns) which both have been suggested as generation spaces spaces of surface form variants for semantic concept?
</prevsent>
</prevsection>
<citsent citstr=" P10-1157 ">
within joint nlg systems (dethlefs and cuayahuitl,2011a; dethlefs and cuayahuitl, 2011b) and in isolation (georgila et al, 2002; mairesse et al, 2010).<papid> P10-1157 </papid></citsent>
<aftsection>
<nextsent>we address the generation of navigation instructions, where e.g. the semantic form (path(target = end of corridor) ?
</nextsent>
<nextsent>(landmark = lif ? dir = left)) can be expressed as go to the end of the corridor?, head to the end of the corridor past thelift on your left?
</nextsent>
<nextsent>and many more.
</nextsent>
<nextsent>the best realisation depends on the space (types and properties of spatial objects), the user (position, orientation, prior knowledge) and decisions of content selection and utterance planning.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1929">
<title id=" N12-1081.xml">comparing hmms and bayesian networks for surface realisation </title>
<section> experimental setting.  </section>
<citcontext>
<prevsection>
<prevsent>the learn 1this is key to the joint treatment of content selection and surface realisation: if an utterance is not informative in terms of content, it will receive bad rewards, even with good surface realisation choices (and vice versa).
</prevsent>
<prevsent>ing agent is trained using the reward function reward = user satisfaction ? (w0 . . .
</prevsent>
</prevsection>
<citsent citstr=" P97-1035 ">
wn) ? cas.2 user satisfaction is function of task success and the number of user turns based on the paradise framework3 (walker et al, 1997) <papid> P97-1035 </papid>and cas refers to the proportion of repetition and variation in surface forms.</citsent>
<aftsection>
<nextsent>our focus in this short paper is on (w0 . . .
</nextsent>
<nextsent>wn) which rewards the agent for having generated surface form sequence w0 . . .
</nextsent>
<nextsent>wn.
</nextsent>
<nextsent>in hmms, this corresponds tothe forward probability obtained from the forward algorithm of observing the sequence in the data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1930">
<title id=" P00-1014.xml">an unsupervised approach to prepositional phrase attachment using contextually similar words </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>1 previous work.
</prevsent>
<prevsent>altmann and steedman (1988) showed that current discourse context is often required for disambiguating attachments.
</prevsent>
</prevsection>
<citsent citstr=" C94-2195 ">
recent work shows that it is generally sufficient to utilize lexical information (brill and resnik, 1994; <papid> C94-2195 </papid>collins and brooks, 1995; <papid> W95-0103 </papid>hindle and rooth, 1993; <papid> J93-1005 </papid>ratnaparkhi et al, 1994)<papid> H94-1048 </papid></citsent>
<aftsection>
<nextsent>one of the earliest corpus-based approaches to prepositional phrase attachment used lexical preference by computing co-occurrence frequencies (lexical associations) of verbs and nouns with prepositions (hindle and rooth, 1993).<papid> J93-1005 </papid></nextsent>
<nextsent>training data was obtained by extracting all phrases of the form (v, n1, p, n2) from large parsed corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1931">
<title id=" P00-1014.xml">an unsupervised approach to prepositional phrase attachment using contextually similar words </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>1 previous work.
</prevsent>
<prevsent>altmann and steedman (1988) showed that current discourse context is often required for disambiguating attachments.
</prevsent>
</prevsection>
<citsent citstr=" W95-0103 ">
recent work shows that it is generally sufficient to utilize lexical information (brill and resnik, 1994; <papid> C94-2195 </papid>collins and brooks, 1995; <papid> W95-0103 </papid>hindle and rooth, 1993; <papid> J93-1005 </papid>ratnaparkhi et al, 1994)<papid> H94-1048 </papid></citsent>
<aftsection>
<nextsent>one of the earliest corpus-based approaches to prepositional phrase attachment used lexical preference by computing co-occurrence frequencies (lexical associations) of verbs and nouns with prepositions (hindle and rooth, 1993).<papid> J93-1005 </papid></nextsent>
<nextsent>training data was obtained by extracting all phrases of the form (v, n1, p, n2) from large parsed corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1932">
<title id=" P00-1014.xml">an unsupervised approach to prepositional phrase attachment using contextually similar words </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>1 previous work.
</prevsent>
<prevsent>altmann and steedman (1988) showed that current discourse context is often required for disambiguating attachments.
</prevsent>
</prevsection>
<citsent citstr=" J93-1005 ">
recent work shows that it is generally sufficient to utilize lexical information (brill and resnik, 1994; <papid> C94-2195 </papid>collins and brooks, 1995; <papid> W95-0103 </papid>hindle and rooth, 1993; <papid> J93-1005 </papid>ratnaparkhi et al, 1994)<papid> H94-1048 </papid></citsent>
<aftsection>
<nextsent>one of the earliest corpus-based approaches to prepositional phrase attachment used lexical preference by computing co-occurrence frequencies (lexical associations) of verbs and nouns with prepositions (hindle and rooth, 1993).<papid> J93-1005 </papid></nextsent>
<nextsent>training data was obtained by extracting all phrases of the form (v, n1, p, n2) from large parsed corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1933">
<title id=" P00-1014.xml">an unsupervised approach to prepositional phrase attachment using contextually similar words </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>1 previous work.
</prevsent>
<prevsent>altmann and steedman (1988) showed that current discourse context is often required for disambiguating attachments.
</prevsent>
</prevsection>
<citsent citstr=" H94-1048 ">
recent work shows that it is generally sufficient to utilize lexical information (brill and resnik, 1994; <papid> C94-2195 </papid>collins and brooks, 1995; <papid> W95-0103 </papid>hindle and rooth, 1993; <papid> J93-1005 </papid>ratnaparkhi et al, 1994)<papid> H94-1048 </papid></citsent>
<aftsection>
<nextsent>one of the earliest corpus-based approaches to prepositional phrase attachment used lexical preference by computing co-occurrence frequencies (lexical associations) of verbs and nouns with prepositions (hindle and rooth, 1993).<papid> J93-1005 </papid></nextsent>
<nextsent>training data was obtained by extracting all phrases of the form (v, n1, p, n2) from large parsed corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1940">
<title id=" P00-1014.xml">an unsupervised approach to prepositional phrase attachment using contextually similar words </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>later, collins and brooks (1995) <papid> W95-0103 </papid>achieved 84.5% accuracy by employing backed-off model to smooth for unseen events.</prevsent>
<prevsent>they discovered that is the most informative lexical item for attachment disambiguation and keeping low frequency events increases performance.</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
a non-statistical supervised approach by brill and resnik (1994) <papid> C94-2195 </papid>yielded 81.8% accuracy using transformation-based approach (brill, 1995) <papid> J95-4004 </papid>and incorporating word-class information.</citsent>
<aftsection>
<nextsent>they report that the top 20 transformations learned involved specific prepositions supporting collins and brooks?
</nextsent>
<nextsent>claim that the preposition is the most important lexical item for resolving the attachment ambiguity.
</nextsent>
<nextsent>the state of the art is supervised algorithm that employs semantically tagged corpus (stetina and nagao, 1997).<papid> W97-0109 </papid></nextsent>
<nextsent>each word in labelled corpus is sense-tagged using an unsupervised word-sense disambiguation algorithm with wordnet (miller, 1990).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1941">
<title id=" P00-1014.xml">an unsupervised approach to prepositional phrase attachment using contextually similar words </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they report that the top 20 transformations learned involved specific prepositions supporting collins and brooks?
</prevsent>
<prevsent>claim that the preposition is the most important lexical item for resolving the attachment ambiguity.
</prevsent>
</prevsection>
<citsent citstr=" W97-0109 ">
the state of the art is supervised algorithm that employs semantically tagged corpus (stetina and nagao, 1997).<papid> W97-0109 </papid></citsent>
<aftsection>
<nextsent>each word in labelled corpus is sense-tagged using an unsupervised word-sense disambiguation algorithm with wordnet (miller, 1990).
</nextsent>
<nextsent>testing examples are classified using decision tree induced from the training examples.
</nextsent>
<nextsent>they report 88.1% attachment accuracy approaching the human accuracy of 88.2% (ratnaparkhi et al, 1994)<papid> H94-1048 </papid></nextsent>
<nextsent>the current unsupervised state of the art achieves 81.9% attachment accuracy (ratnaparkhi, 1998).<papid> P98-2177 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1945">
<title id=" P00-1014.xml">an unsupervised approach to prepositional phrase attachment using contextually similar words </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>testing examples are classified using decision tree induced from the training examples.
</prevsent>
<prevsent>they report 88.1% attachment accuracy approaching the human accuracy of 88.2% (ratnaparkhi et al, 1994)<papid> H94-1048 </papid></prevsent>
</prevsection>
<citsent citstr=" P98-2177 ">
the current unsupervised state of the art achieves 81.9% attachment accuracy (ratnaparkhi, 1998).<papid> P98-2177 </papid></citsent>
<aftsection>
<nextsent>using an extraction heuristic, unambiguous prepositional phrase attachments of the form (v, p, n2) and (n1, p,n2) are extracted from large corpus.
</nextsent>
<nextsent>cooccurrence frequencies are then used to disambiguate examples with ambiguous attachments.
</nextsent>
<nextsent>the input to our algorithm includes collocation database and corpus-based thesaurus, both available on the internet2.
</nextsent>
<nextsent>below, we briefly describe these resources.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1947">
<title id=" P00-1014.xml">an unsupervised approach to prepositional phrase attachment using contextually similar words </title>
<section> resources.  </section>
<citcontext>
<prevsection>
<prevsent>below, we briefly describe these resources.
</prevsent>
<prevsent>2.1 collocation database.
</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
given word in dependency relationship (such as subject or object), the collocation database is used to retrieve the words that occurred in that relationship with w, in large corpus, along with their frequencies (lin, 1998<papid> P98-2127 </papid>a).</citsent>
<aftsection>
<nextsent>figure 1 shows excerpts of the entries in 2available at www.cs.ualberta.ca/~lindek/demos.htm.
</nextsent>
<nextsent>eat: object: almond 1, apple 25, bean 5, beam 1, binge 1, bread 13, cake 17, cheese 8, dish 14, disorder 20, egg 31, grape 12, grub 2, hay 3, junk 1, meat 70, poultry 3, rabbit 4, soup 5, sandwich 18, pasta 7, vegetable 35, ... subject: adult 3, animal 8, beetle 1, cat 3, child 41, decrease 1, dog 24, family 29, guest 7, kid 22, patient 7, refugee 2, rider 1, russian 1, shark 2, something 19, we 239, wolf 5, ... salad: adj-modifier:assorted 1, crisp 4, fresh 13, good 3, grilled 5, leftover 3, mixed 4, olive 3, prepared 3, side 4, small 6, special 5, vegetable 3, ... object-of: add 3, consume 1, dress 1, grow 1, harvest 2, have 20, like 5, love 1, mix 1, pick 1, place 3, prepare 4, return 3, rinse 1, season 1, serve 8, sprinkle 1, taste 1, test 1, toss 8, try 3, ...
</nextsent>
<nextsent>figure 1.
</nextsent>
<nextsent>excepts of entries in the collocation database for eat and salad.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1952">
<title id=" P00-1014.xml">an unsupervised approach to prepositional phrase attachment using contextually similar words </title>
<section> training data extraction.  </section>
<citcontext>
<prevsection>
<prevsent>using the collocation database, lin (1998<papid> P98-2127 </papid>b) usedan unsupervised method to construct corpus based thesaurus consisting of 11839 nouns, 3639 verbs and 5658 adjectives/adverbs.</prevsent>
<prevsent>given word w, the thesaurus returns set of similar words of along with their similarity to w. r example, the 20 most similar words of eat and salad are shown in table 1.</prevsent>
</prevsection>
<citsent citstr=" C94-1079 ">
we parsed 125-million word newspaper corpus with minipar3, descend ent of principar (lin, 1994).<papid> C94-1079 </papid></citsent>
<aftsection>
<nextsent>minipar outputs dependency trees (lin, 1999) <papid> P99-1041 </papid>from the input sentences.</nextsent>
<nextsent>for example, the following sentence is decomposed into dependency tree: occasionally, the parser generates incorrect dependency trees.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1953">
<title id=" P00-1014.xml">an unsupervised approach to prepositional phrase attachment using contextually similar words </title>
<section> training data extraction.  </section>
<citcontext>
<prevsection>
<prevsent>given word w, the thesaurus returns set of similar words of along with their similarity to w. r example, the 20 most similar words of eat and salad are shown in table 1.
</prevsent>
<prevsent>we parsed 125-million word newspaper corpus with minipar3, descend ent of principar (lin, 1994).<papid> C94-1079 </papid></prevsent>
</prevsection>
<citsent citstr=" P99-1041 ">
minipar outputs dependency trees (lin, 1999) <papid> P99-1041 </papid>from the input sentences.</citsent>
<aftsection>
<nextsent>for example, the following sentence is decomposed into dependency tree: occasionally, the parser generates incorrect dependency trees.
</nextsent>
<nextsent>for example, in the above sentence, the prepositional phrase headed by with should attach to saw(as opposed to g).
</nextsent>
<nextsent>two separate sets of training data were then extracted from this corpus.
</nextsent>
<nextsent>below, we briefly describe how we obtained these datasets.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1972">
<title id=" P01-1030.xml">fast decoding and optimal decoding for machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a statistical mt system that translates (say) french sentences into english, is divided into three parts: (1) language model (lm) that assigns probability p(e) to any english string, (2) translation model (tm) that assigns probability p(f  e) to any pair of english and french strings,and (3) decoder.
</prevsent>
<prevsent>the decoder takes previously unseen sentence  and tries to find the  that maximizes p(e  f), or equivalently maximizes p(e)  p(f  e).
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
brown et al (1993) <papid> J93-2003 </papid>introduced series oftms based on word-for-word substitution and reordering, but did not include decoding algorithm.</citsent>
<aftsection>
<nextsent>if the source and target languages are constrained to have the same word order (by choice or through suitable pre-processing), then the linear viterbi algorithm can be applied (tillmann et al., 1997).<papid> P97-1037 </papid></nextsent>
<nextsent>if re-ordering is limited to rotations around nodes in binary tree, then optimal decoding can be carried out by high-polynomial algorithm (wu, 1996).<papid> P96-1021 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1973">
<title id=" P01-1030.xml">fast decoding and optimal decoding for machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the decoder takes previously unseen sentence  and tries to find the  that maximizes p(e  f), or equivalently maximizes p(e)  p(f  e).
</prevsent>
<prevsent>brown et al (1993) <papid> J93-2003 </papid>introduced series oftms based on word-for-word substitution and reordering, but did not include decoding algorithm.</prevsent>
</prevsection>
<citsent citstr=" P97-1037 ">
if the source and target languages are constrained to have the same word order (by choice or through suitable pre-processing), then the linear viterbi algorithm can be applied (tillmann et al., 1997).<papid> P97-1037 </papid></citsent>
<aftsection>
<nextsent>if re-ordering is limited to rotations around nodes in binary tree, then optimal decoding can be carried out by high-polynomial algorithm (wu, 1996).<papid> P96-1021 </papid></nextsent>
<nextsent>for arbitrary word-reordering, the decoding problem is np-complete (knight, 1999).<papid> J99-4005 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1974">
<title id=" P01-1030.xml">fast decoding and optimal decoding for machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>brown et al (1993) <papid> J93-2003 </papid>introduced series oftms based on word-for-word substitution and reordering, but did not include decoding algorithm.</prevsent>
<prevsent>if the source and target languages are constrained to have the same word order (by choice or through suitable pre-processing), then the linear viterbi algorithm can be applied (tillmann et al., 1997).<papid> P97-1037 </papid></prevsent>
</prevsection>
<citsent citstr=" P96-1021 ">
if re-ordering is limited to rotations around nodes in binary tree, then optimal decoding can be carried out by high-polynomial algorithm (wu, 1996).<papid> P96-1021 </papid></citsent>
<aftsection>
<nextsent>for arbitrary word-reordering, the decoding problem is np-complete (knight, 1999).<papid> J99-4005 </papid></nextsent>
<nextsent>a sensible strategy (brown et al, 1995; wang and waibel, 1997) <papid> P97-1047 </papid>is to examine large subset of likely deco dings and choose just from that.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1975">
<title id=" P01-1030.xml">fast decoding and optimal decoding for machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>if the source and target languages are constrained to have the same word order (by choice or through suitable pre-processing), then the linear viterbi algorithm can be applied (tillmann et al., 1997).<papid> P97-1037 </papid></prevsent>
<prevsent>if re-ordering is limited to rotations around nodes in binary tree, then optimal decoding can be carried out by high-polynomial algorithm (wu, 1996).<papid> P96-1021 </papid></prevsent>
</prevsection>
<citsent citstr=" J99-4005 ">
for arbitrary word-reordering, the decoding problem is np-complete (knight, 1999).<papid> J99-4005 </papid></citsent>
<aftsection>
<nextsent>a sensible strategy (brown et al, 1995; wang and waibel, 1997) <papid> P97-1047 </papid>is to examine large subset of likely deco dings and choose just from that.</nextsent>
<nextsent>of course, it is possible to miss good translation this way.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1976">
<title id=" P01-1030.xml">fast decoding and optimal decoding for machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>if re-ordering is limited to rotations around nodes in binary tree, then optimal decoding can be carried out by high-polynomial algorithm (wu, 1996).<papid> P96-1021 </papid></prevsent>
<prevsent>for arbitrary word-reordering, the decoding problem is np-complete (knight, 1999).<papid> J99-4005 </papid></prevsent>
</prevsection>
<citsent citstr=" P97-1047 ">
a sensible strategy (brown et al, 1995; wang and waibel, 1997) <papid> P97-1047 </papid>is to examine large subset of likely deco dings and choose just from that.</citsent>
<aftsection>
<nextsent>of course, it is possible to miss good translation this way.
</nextsent>
<nextsent>if the decoder returns  but there exists some for which p(e  f) p(e   f), this is calleda search error.
</nextsent>
<nextsent>as wang and waibel (1997) <papid> P97-1047 </papid>remark, it is hard to know whether search error has occurred the only way to show that decoding is sub-optimal is to actually produce higher scoring one.thus, while decoding is clear-cut optimization task in which every problem instance has right answer, it is hard to come up with good answers quickly.</nextsent>
<nextsent>this paper reports on measurements of speed, search errors, and translation quality in the context of traditional stack decoder (jelinek, 1969; brown et al, 1995) and two new decoders.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1980">
<title id=" P04-2010.xml">a machine learning approach to german pronoun resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the system achieved an f-measure of 86.5 for full coreference resolution (no values were given for pronouns).
</prevsent>
<prevsent>although number this high must be attributed tothe specific textual domain, resolve also outperformed the authors?
</prevsent>
</prevsection>
<citsent citstr=" P00-1023 ">
rule-based algorithm by 7.6 percentage points, which encouraged further reseach in this direction.unlike the other systems presented in this section, (morton, 2000) <papid> P00-1023 </papid>does not use decision tree algorithm but opts instead for maximum entropy model.</citsent>
<aftsection>
<nextsent>the model is trained on subset of the wall street journal, comprising 21 million tokens.
</nextsent>
<nextsent>the reported f-measure for pronoun resolution is 81.5.
</nextsent>
<nextsent>however, (morton, 2000) <papid> P00-1023 </papid>only attempts to resolve singular pronouns, and there is no mention of what percentage of total pronouns are covered by this restriction.</nextsent>
<nextsent>(soon et al, 2001) <papid> J01-4004 </papid>use the c4.5 algorithm witha set of 12 domain-independent features, ten syntactic and two semantic.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1984">
<title id=" P04-2010.xml">a machine learning approach to german pronoun resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the reported f-measure for pronoun resolution is 81.5.
</prevsent>
<prevsent>however, (morton, 2000) <papid> P00-1023 </papid>only attempts to resolve singular pronouns, and there is no mention of what percentage of total pronouns are covered by this restriction.</prevsent>
</prevsection>
<citsent citstr=" J01-4004 ">
(soon et al, 2001) <papid> J01-4004 </papid>use the c4.5 algorithm witha set of 12 domain-independent features, ten syntactic and two semantic.</citsent>
<aftsection>
<nextsent>their system was trained on both the muc-6 and the muc-7 datasets, for which it achieved f-scores of 62.6 and 60.4, respectively.
</nextsent>
<nextsent>although these results are far worse than the ones reported in (mccarthy and lehnert, 1995), they are comparable to the best-performing rule-based systems in the respective competitions.
</nextsent>
<nextsent>as (mccarthy and lehnert, 1995), (soon et al, 2001) <papid> J01-4004 </papid>do not report separate results for pronouns.</nextsent>
<nextsent>(ng and cardie, 2002) <papid> P02-1014 </papid>expanded on the workof (soon et al, 2001) <papid> J01-4004 </papid>by adding 41 lexical, semantic and grammatical features.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1990">
<title id=" P04-2010.xml">a machine learning approach to german pronoun resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>although these results are far worse than the ones reported in (mccarthy and lehnert, 1995), they are comparable to the best-performing rule-based systems in the respective competitions.
</prevsent>
<prevsent>as (mccarthy and lehnert, 1995), (soon et al, 2001) <papid> J01-4004 </papid>do not report separate results for pronouns.</prevsent>
</prevsection>
<citsent citstr=" P02-1014 ">
(ng and cardie, 2002) <papid> P02-1014 </papid>expanded on the workof (soon et al, 2001) <papid> J01-4004 </papid>by adding 41 lexical, semantic and grammatical features.</citsent>
<aftsection>
<nextsent>however, since using this many features proved to be detrimental to performance, all features that induced low precision rules were discarded, leaving only 19.
</nextsent>
<nextsent>the final system outperformed that of (soon et al, 2001), <papid> J01-4004 </papid>with f-scores of 69.1 and 63.4 for muc-6and muc-7, respectively.</nextsent>
<nextsent>for pronouns, there ported results are 74.6 and 57.8, respectively.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1995">
<title id=" P04-2010.xml">a machine learning approach to german pronoun resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the final system outperformed that of (soon et al, 2001), <papid> J01-4004 </papid>with f-scores of 69.1 and 63.4 for muc-6and muc-7, respectively.</prevsent>
<prevsent>for pronouns, there ported results are 74.6 and 57.8, respectively.</prevsent>
</prevsection>
<citsent citstr=" W02-1040 ">
the experiment presented in (strube et al,2002) <papid> W02-1040 </papid>is one of the few dealing with the application of machine learning to german coreference resolution covering definite noun phrases, proper names and personal, possessive and demonstrative pronouns.</citsent>
<aftsection>
<nextsent>the research is based on the heidelberg text corpus (see section 4), which makes it ideal for comparison with our system.
</nextsent>
<nextsent>(strube et al, 2002)<papid> W02-1040 </papid>used 15 features modeled after those used by state-of-the-art resolution systems for english.</nextsent>
<nextsent>the results for personal and possessive pronouns are 82.79 and 84.94, respectively.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q1999">
<title id=" P04-2010.xml">a machine learning approach to german pronoun resolution </title>
<section> boosting.  </section>
<citcontext>
<prevsection>
<prevsent>after each iteration, the weight is redistributed, so that misclassified examples get higher weights.
</prevsent>
<prevsent>the base learner is thus forced to concentrate on difficult examples.
</prevsent>
</prevsection>
<citsent citstr=" W99-0606 ">
although boosting has not yet been applied to coreference resolution, it has outperformedstateof-the-art systems for nlp tasks such as partofspeech tagging and prepositional phrase attachment (abney et al, 1999), <papid> W99-0606 </papid>word sense disambiguation (escudero et al, 2000), and named entity recognition (carreras et al, 2002).<papid> W02-2004 </papid></citsent>
<aftsection>
<nextsent>the implementation used for this project is boostexter (schapire and singer, 2000), toolkit freely available for research purposes.
</nextsent>
<nextsent>in addition to labels, boostexter assigns confidence weights that reflect the reliability of the decisions.
</nextsent>
<nextsent>our system resolves pronouns in three stages: preprocessing, classification, and postprocessing.figure 1 gives an overview of the system architecture, while this section provides details of each component.
</nextsent>
<nextsent>4.1 training and test data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2000">
<title id=" P04-2010.xml">a machine learning approach to german pronoun resolution </title>
<section> boosting.  </section>
<citcontext>
<prevsection>
<prevsent>after each iteration, the weight is redistributed, so that misclassified examples get higher weights.
</prevsent>
<prevsent>the base learner is thus forced to concentrate on difficult examples.
</prevsent>
</prevsection>
<citsent citstr=" W02-2004 ">
although boosting has not yet been applied to coreference resolution, it has outperformedstateof-the-art systems for nlp tasks such as partofspeech tagging and prepositional phrase attachment (abney et al, 1999), <papid> W99-0606 </papid>word sense disambiguation (escudero et al, 2000), and named entity recognition (carreras et al, 2002).<papid> W02-2004 </papid></citsent>
<aftsection>
<nextsent>the implementation used for this project is boostexter (schapire and singer, 2000), toolkit freely available for research purposes.
</nextsent>
<nextsent>in addition to labels, boostexter assigns confidence weights that reflect the reliability of the decisions.
</nextsent>
<nextsent>our system resolves pronouns in three stages: preprocessing, classification, and postprocessing.figure 1 gives an overview of the system architecture, while this section provides details of each component.
</nextsent>
<nextsent>4.1 training and test data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2004">
<title id=" P04-2010.xml">a machine learning approach to german pronoun resolution </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>this is different from manually annotated markables, which can be complex noun phrases.
</prevsent>
<prevsent>despite good overall performance, the chunker fails on multi-word proper names in which case it marks each word as an individual chunk.1 since many pronouns refer to named entities, the chun ker needs to be supplemented by named entityrecogniser.
</prevsent>
</prevsection>
<citsent citstr=" W03-0424 ">
although, to our knowledge, there currently does not exist an off-the-shelf named entity recogniser for german, we were able to obtain the system submitted by (curran and clark, 2003) <papid> W03-0424 </papid>to the 2003 conll competition.</citsent>
<aftsection>
<nextsent>in order to run the recogniser, the data needs to be token ised, tagged and lemmatised, all of which is done by the tree tagger (schmid, 1995).
</nextsent>
<nextsent>4.5 mark able creation.
</nextsent>
<nextsent>after the markables are identified, they are automatically annotated with the attributes described in section 4.4.
</nextsent>
<nextsent>the np form can be reliably determined by examining the output of the noun chun ker and the named entity recogniser.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2012">
<title id=" P04-1055.xml">classifying semantic relations in bioscience texts </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in the related work for statistical models there has been, to the best of our knowledge, no attempt to distinguish between different relations that can occur between the same semantic entities.
</prevsent>
<prevsent>in agichtein and gravano (2000) the goal is to extract pairs such as (microsoft, redmond), where redmond is the location of the organization microsoft.
</prevsent>
</prevsection>
<citsent citstr=" W02-1010 ">
their technique generates and evaluates lexical patterns that are indicative of the relation.only the relation location of is tackled and the entities are assumed given.in zelenko et al (2002), <papid> W02-1010 </papid>the task is to extract the relationships person-affiliation and organization-location.</citsent>
<aftsection>
<nextsent>the classification (donewith support vector machine and voted perceptron algorithms) is between positive and negative sentences, where the positive sentences contain the two entities.
</nextsent>
<nextsent>in the bioscience nlp literature there are also efforts to extract entities and relations.
</nextsent>
<nextsent>in ray and craven (2001), hidden markov models are applied to medline text to extract the entities proteins and locations in the relationship subcellular-location and the entities geneand disorder in the relationship disorder association.
</nextsent>
<nextsent>the authors acknowledge that the task of extracting relations is different from thetask of extracting entities.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2013">
<title id=" P04-1055.xml">classifying semantic relations in bioscience texts </title>
<section> data and features.  </section>
<citcontext>
<prevsection>
<prevsent>when there are multiple mesh terms for one word, we simply choose the first one.
</prevsent>
<prevsent>these semantic features are shown to be very useful for our tasks (see section 4.3).
</prevsent>
</prevsection>
<citsent citstr=" P02-1032 ">
rosario et al (2002) <papid> P02-1032 </papid>demonstrate the usefulness of mesh for the classification of the semantic relationships between nouns in noun compounds.</citsent>
<aftsection>
<nextsent>the results reported in this paper were obtained with the following features: the word itself, its part of speech from the brill tagger (brill, 1995), <papid> J95-4004 </papid>the phrase constituent the word belongs to, obtained by flattening the output of parser (collins, 1996),<papid> P96-1025 </papid>and the words mesh id (if available).</nextsent>
<nextsent>in addition, we identified the sub-hierarchies of mesh that tend to correspond to treatments and diseases,and convert these into tri-valued attribute indicating one of: disease, treatment or neither.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2014">
<title id=" P04-1055.xml">classifying semantic relations in bioscience texts </title>
<section> data and features.  </section>
<citcontext>
<prevsection>
<prevsent>these semantic features are shown to be very useful for our tasks (see section 4.3).
</prevsent>
<prevsent>rosario et al (2002) <papid> P02-1032 </papid>demonstrate the usefulness of mesh for the classification of the semantic relationships between nouns in noun compounds.</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
the results reported in this paper were obtained with the following features: the word itself, its part of speech from the brill tagger (brill, 1995), <papid> J95-4004 </papid>the phrase constituent the word belongs to, obtained by flattening the output of parser (collins, 1996),<papid> P96-1025 </papid>and the words mesh id (if available).</citsent>
<aftsection>
<nextsent>in addition, we identified the sub-hierarchies of mesh that tend to correspond to treatments and diseases,and convert these into tri-valued attribute indicating one of: disease, treatment or neither.
</nextsent>
<nextsent>finally, we included orthographic features such as is the word number?, only part of the word is number?, first letter is capitalized?, all letters are capitalized?.
</nextsent>
<nextsent>in section 4.3 we analyze the impact of these features.
</nextsent>
<nextsent>this section describes the models and their performance on both entity extraction and relation classification.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2015">
<title id=" P04-1055.xml">classifying semantic relations in bioscience texts </title>
<section> data and features.  </section>
<citcontext>
<prevsection>
<prevsent>these semantic features are shown to be very useful for our tasks (see section 4.3).
</prevsent>
<prevsent>rosario et al (2002) <papid> P02-1032 </papid>demonstrate the usefulness of mesh for the classification of the semantic relationships between nouns in noun compounds.</prevsent>
</prevsection>
<citsent citstr=" P96-1025 ">
the results reported in this paper were obtained with the following features: the word itself, its part of speech from the brill tagger (brill, 1995), <papid> J95-4004 </papid>the phrase constituent the word belongs to, obtained by flattening the output of parser (collins, 1996),<papid> P96-1025 </papid>and the words mesh id (if available).</citsent>
<aftsection>
<nextsent>in addition, we identified the sub-hierarchies of mesh that tend to correspond to treatments and diseases,and convert these into tri-valued attribute indicating one of: disease, treatment or neither.
</nextsent>
<nextsent>finally, we included orthographic features such as is the word number?, only part of the word is number?, first letter is capitalized?, all letters are capitalized?.
</nextsent>
<nextsent>in section 4.3 we analyze the impact of these features.
</nextsent>
<nextsent>this section describes the models and their performance on both entity extraction and relation classification.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2016">
<title id=" P04-1082.xml">using linguistic principles to recover empty categories </title>
<section> abstract </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" J93-2004 ">
this paper describes an algorithm for detecting empty nodes in the penn treebank (marcus et al, 1993), <papid> J93-2004 </papid>finding their antecedents, and assigning them function tags, without access to lexical information such as valency.</citsent>
<aftsection>
<nextsent>unlike previous approaches to this task, the current method is not corpus-based, but rather makes use of the principles of early government-binding theory (chomsky, 1981), the syntactic theory that underlies the annotation.
</nextsent>
<nextsent>using the evaluation metric proposed by johnson (2002), <papid> P02-1018 </papid>this approach outperforms previously published approaches on both detection of empty categories and antecedent identification, given either annotated input stripped of empty categories or the output of parser.</nextsent>
<nextsent>some problems with this evaluation metric are noted and an alternative is proposed along with the results.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2018">
<title id=" P04-1082.xml">using linguistic principles to recover empty categories </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>this paper describes an algorithm for detecting empty nodes in the penn treebank (marcus et al, 1993), <papid> J93-2004 </papid>finding their antecedents, and assigning them function tags, without access to lexical information such as valency.</prevsent>
<prevsent>unlike previous approaches to this task, the current method is not corpus-based, but rather makes use of the principles of early government-binding theory (chomsky, 1981), the syntactic theory that underlies the annotation.</prevsent>
</prevsection>
<citsent citstr=" P02-1018 ">
using the evaluation metric proposed by johnson (2002), <papid> P02-1018 </papid>this approach outperforms previously published approaches on both detection of empty categories and antecedent identification, given either annotated input stripped of empty categories or the output of parser.</citsent>
<aftsection>
<nextsent>some problems with this evaluation metric are noted and an alternative is proposed along with the results.
</nextsent>
<nextsent>the paper considers the reasons principle based approach to this problem should outperform corpus-based approaches, and speculates on the possibility of hybrid approach.
</nextsent>
<nextsent>many recent approaches to parsing (e.g. charniak, 2000) <papid> A00-2018 </papid>have focused on labeled bracketing of the input string, ignoring aspects of structure that are not reflected in the string, such as phonetic ally null elements and long-distance dependencies, many of which provide important semantic information such as predicate-argument structure.</nextsent>
<nextsent>in the penn treebank (marcus et al, 1993), <papid> J93-2004 </papid>null elements, or empty categories, are used to indicate non-local dependencies, discontinuous constituents, and certain missing elements.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2021">
<title id=" P04-1082.xml">using linguistic principles to recover empty categories </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>some problems with this evaluation metric are noted and an alternative is proposed along with the results.
</prevsent>
<prevsent>the paper considers the reasons principle based approach to this problem should outperform corpus-based approaches, and speculates on the possibility of hybrid approach.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
many recent approaches to parsing (e.g. charniak, 2000) <papid> A00-2018 </papid>have focused on labeled bracketing of the input string, ignoring aspects of structure that are not reflected in the string, such as phonetic ally null elements and long-distance dependencies, many of which provide important semantic information such as predicate-argument structure.</citsent>
<aftsection>
<nextsent>in the penn treebank (marcus et al, 1993), <papid> J93-2004 </papid>null elements, or empty categories, are used to indicate non-local dependencies, discontinuous constituents, and certain missing elements.</nextsent>
<nextsent>empty categories are co indexed with their antecedents in the same sentence.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2027">
<title id=" P04-1082.xml">using linguistic principles to recover empty categories </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper describes an algorithm for inserting empty categories in such impoverished trees, co indexing them with their antecedents, and assigning them function tags.
</prevsent>
<prevsent>this is the first approach to include function tag assignment as part of the more general task of empty category recovery.
</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
previous approaches to the problem (collins, 1997; <papid> P97-1003 </papid>johnson, 2002; <papid> P02-1018 </papid>dienes and dubey, 2003<papid> W03-1005 </papid>a,b; higgins, 2003) <papid> E03-1049 </papid>have all been learning-based; the primary difference between the present algorithm and earlier ones is that it is not learned, but explicitly incorporates principles of government binding theory (chomsky, 1981), since that theory underlies the annotation.</citsent>
<aftsection>
<nextsent>the absence of rule based approaches up until now is not motivated by the failure of such approaches in this domain; on the contrary, no one seems to have tried rule based approach to this problem.
</nextsent>
<nextsent>instead it appears that there is an understandable predisposition against rule-based approaches, given the fact that data-driven, especially machine-learning, approaches have worked so much better in many other domains.1 empty categories however seem different, in that, for the most part, their location and existence is determined, not by observable data, but by explicitly constructed linguistic principles, which 1both collins (1997: <papid> P97-1003 </papid>19) and higgins (2003: <papid> E03-1049 </papid>100) are explicit about this predisposition.</nextsent>
<nextsent>were consciously used in the annotation; i.e., unlike overt words and phrases, which correspond to actual strings in the data, empty categories are in the data only because linguists doing the annotation put them there.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2029">
<title id=" P04-1082.xml">using linguistic principles to recover empty categories </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper describes an algorithm for inserting empty categories in such impoverished trees, co indexing them with their antecedents, and assigning them function tags.
</prevsent>
<prevsent>this is the first approach to include function tag assignment as part of the more general task of empty category recovery.
</prevsent>
</prevsection>
<citsent citstr=" W03-1005 ">
previous approaches to the problem (collins, 1997; <papid> P97-1003 </papid>johnson, 2002; <papid> P02-1018 </papid>dienes and dubey, 2003<papid> W03-1005 </papid>a,b; higgins, 2003) <papid> E03-1049 </papid>have all been learning-based; the primary difference between the present algorithm and earlier ones is that it is not learned, but explicitly incorporates principles of government binding theory (chomsky, 1981), since that theory underlies the annotation.</citsent>
<aftsection>
<nextsent>the absence of rule based approaches up until now is not motivated by the failure of such approaches in this domain; on the contrary, no one seems to have tried rule based approach to this problem.
</nextsent>
<nextsent>instead it appears that there is an understandable predisposition against rule-based approaches, given the fact that data-driven, especially machine-learning, approaches have worked so much better in many other domains.1 empty categories however seem different, in that, for the most part, their location and existence is determined, not by observable data, but by explicitly constructed linguistic principles, which 1both collins (1997: <papid> P97-1003 </papid>19) and higgins (2003: <papid> E03-1049 </papid>100) are explicit about this predisposition.</nextsent>
<nextsent>were consciously used in the annotation; i.e., unlike overt words and phrases, which correspond to actual strings in the data, empty categories are in the data only because linguists doing the annotation put them there.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2031">
<title id=" P04-1082.xml">using linguistic principles to recover empty categories </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper describes an algorithm for inserting empty categories in such impoverished trees, co indexing them with their antecedents, and assigning them function tags.
</prevsent>
<prevsent>this is the first approach to include function tag assignment as part of the more general task of empty category recovery.
</prevsent>
</prevsection>
<citsent citstr=" E03-1049 ">
previous approaches to the problem (collins, 1997; <papid> P97-1003 </papid>johnson, 2002; <papid> P02-1018 </papid>dienes and dubey, 2003<papid> W03-1005 </papid>a,b; higgins, 2003) <papid> E03-1049 </papid>have all been learning-based; the primary difference between the present algorithm and earlier ones is that it is not learned, but explicitly incorporates principles of government binding theory (chomsky, 1981), since that theory underlies the annotation.</citsent>
<aftsection>
<nextsent>the absence of rule based approaches up until now is not motivated by the failure of such approaches in this domain; on the contrary, no one seems to have tried rule based approach to this problem.
</nextsent>
<nextsent>instead it appears that there is an understandable predisposition against rule-based approaches, given the fact that data-driven, especially machine-learning, approaches have worked so much better in many other domains.1 empty categories however seem different, in that, for the most part, their location and existence is determined, not by observable data, but by explicitly constructed linguistic principles, which 1both collins (1997: <papid> P97-1003 </papid>19) and higgins (2003: <papid> E03-1049 </papid>100) are explicit about this predisposition.</nextsent>
<nextsent>were consciously used in the annotation; i.e., unlike overt words and phrases, which correspond to actual strings in the data, empty categories are in the data only because linguists doing the annotation put them there.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2070">
<title id=" P04-1082.xml">using linguistic principles to recover empty categories </title>
<section> the recovery algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>the output of imperatives; see below.
</prevsent>
<prevsent>charniaks parser (charniak, 2000), <papid> A00-2018 </papid>however, does not include function tags, so in order for the algorithm to work properly on parser output (see section 5), additional functions were written to approximate the required tags.</prevsent>
</prevsection>
<citsent citstr=" A00-2031 ">
presumably, the accuracy of the algorithm on parser output would be enhanced by accurate prior assignment of the tags to all relevant nodes, as in blaheta and charniak (2000) (<papid> A00-2031 </papid>see also section 5).</citsent>
<aftsection>
<nextsent>each empty category insertion rule, in addition to inserting an empty node in the tree, also may assign function tag to the empty node.
</nextsent>
<nextsent>this is illustrated in figure 2, where the final line inserts np* with the function tag sbj in the case where it is the subject of an infinitive clause.
</nextsent>
<nextsent>the rule that inserts wh-trace (called in line 12 in figure 1) takes whxp needing trace as input, and walks the tree until an appropriate insertion site is found (see appendix for fuller description).
</nextsent>
<nextsent>since this rule requires whxp as input, and that whxp may itself be an empty category (inserted by an earlier rule), it is handled in separate pass through the tree.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2144">
<title id=" P01-1004.xml">lowcost high performance translation retrieval dumber is better </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>translation memories (tms) are list of translation records (source language strings paired with unique target language translation), which the tm system accesses in suggesting alist of target language (l2) translation candidates forgiven source language (l1) input (tru jillo, 1999; planas, 1998).
</prevsent>
<prevsent>translation retrieval (tr) is description of this process of selecting from the tm set of translation records (trecs)of maximum l1 similarity to given input.
</prevsent>
</prevsection>
<citsent citstr=" C90-3044 ">
typically in example-based machine translation, either single trec is retrieved from the tm based on match with the overall l1 input, or the inputis partitioned into coherent segments, and individual translations retrieved for each (sato and nagao, 1990; <papid> C90-3044 </papid>nirenburg et al, 1993); this is the first step toward generating customised translation for the input.</citsent>
<aftsection>
<nextsent>with stand-alone tm systems, on the other hand, the system selects an arbitrary number of translation candidates falling within certain empirical corridor of similarity with the overall input string, and simply outputs these for manual manipulation by the user in fashioning the final translation.
</nextsent>
<nextsent>a key assumption surrounding the bulk of past tr research has been that the greater the match stringency/linguistic awareness of the retrieval mechanism, the greater the final retrieval accuracy will become.
</nextsent>
<nextsent>naturally, any appreciation in retrieval complexity comes at price in terms of computational overhead.
</nextsent>
<nextsent>we thus follow the leadof baldwin and tanaka (2000) <papid> C00-1006 </papid>in asking the question: what is the empirical effect on retrieval performance of different match approaches?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2145">
<title id=" P01-1004.xml">lowcost high performance translation retrieval dumber is better </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a key assumption surrounding the bulk of past tr research has been that the greater the match stringency/linguistic awareness of the retrieval mechanism, the greater the final retrieval accuracy will become.
</prevsent>
<prevsent>naturally, any appreciation in retrieval complexity comes at price in terms of computational overhead.
</prevsent>
</prevsection>
<citsent citstr=" C00-1006 ">
we thus follow the leadof baldwin and tanaka (2000) <papid> C00-1006 </papid>in asking the question: what is the empirical effect on retrieval performance of different match approaches?</citsent>
<aftsection>
<nextsent>here,retrieval performance is defined as the combination of retrieval speed and accuracy, with the ideal method offering fast response times at high accuracy.
</nextsent>
<nextsent>in this paper, we choose to focus on retrieval performance within japanese english tr context.
</nextsent>
<nextsent>one key area of interest with japanese is the effect that segmentation has on retrieval performance.
</nextsent>
<nextsent>as japanese is non-segmentinglanguage (does not explicitly delimit words orthographically), we can take the brute-force approach in treating each string as sequence of characters (character-based indexing), or alternatively call upon segmentation technology in partitioning each string into words (word-based indexing).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2148">
<title id=" P01-1004.xml">lowcost high performance translation retrieval dumber is better </title>
<section> basic parameters.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 segmentation.
</prevsent>
<prevsent>despite non-segmenting languages such as japanese not making use of segment delimiters, it is possible to artificially partition off given string into constituent morphemes through the process of segmentation.
</prevsent>
</prevsection>
<citsent citstr=" C92-4203 ">
we will collectively term the resultant segments as words for the remainder of this paper.looking to past research on string comparison methods for tm systems, almost all systems involving japanese as the source language relyon segmentation (nakamura, 1989;sumita and tsutsumi, 1991; kitamura and yamamoto, 1996; tanaka, 1997), with sato (1992)<papid> C92-4203 </papid>and sato and kawase (1994) providing rare instances of character-based systems.</citsent>
<aftsection>
<nextsent>thisis despite fujii and croft (1993) providing evidence from japanese information retrieval that character-based indexing performs comparably to word-based indexing.
</nextsent>
<nextsent>in analogous research,baldwin and tanaka (2000) <papid> C00-1006 </papid>compared character and word-based indexing within japanese english tr context and found character-based indexing to hold slight empirical advantage.</nextsent>
<nextsent>the most obvious advantage of character-based indexing over word-based indexing is that there is no pre-processing overhead.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2165">
<title id=" P04-1069.xml">probabilistic parsing strategies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>parameters.
</prevsent>
<prevsent>depending on the choice of the parsing strategy,the constructed pda may allow different probability distributions than the underlying cfg, since the set of free parameters may differ between the cfg and the pda, both quantitatively and qualitatively.
</prevsent>
</prevsection>
<citsent citstr=" P99-1054 ">
for example, (sornlertlamvanich et al, 1999) and(roark and johnson, 1999) <papid> P99-1054 </papid>have shown that probability distribution that can be obtained by training the probabilities of cfg on the basis of corpus can be less accurate than the probability distribution obtained by training the probabilities of pda constructed by particular parsing strategy, on the basis of the same corpus.</citsent>
<aftsection>
<nextsent>also the results from (chitrao and grishman, 1990), (<papid> H90-1053 </papid>charniak and carroll, 1994) and (manning and carpenter, 2000) could be seen in this light.the question arises of whether parsing strategies can be extended probabilistically, i.e., whether given construction of pdas from cfgs can beaugmented?</nextsent>
<nextsent>with function defining the probabilities for the target pda, given the probabilities associated with the input cfg, in such way that the obtained probabilistic distributions on the cfg derivations and the corresponding pda computations are equivalent.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2166">
<title id=" P04-1069.xml">probabilistic parsing strategies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>depending on the choice of the parsing strategy,the constructed pda may allow different probability distributions than the underlying cfg, since the set of free parameters may differ between the cfg and the pda, both quantitatively and qualitatively.
</prevsent>
<prevsent>for example, (sornlertlamvanich et al, 1999) and(roark and johnson, 1999) <papid> P99-1054 </papid>have shown that probability distribution that can be obtained by training the probabilities of cfg on the basis of corpus can be less accurate than the probability distribution obtained by training the probabilities of pda constructed by particular parsing strategy, on the basis of the same corpus.</prevsent>
</prevsection>
<citsent citstr=" H90-1053 ">
also the results from (chitrao and grishman, 1990), (<papid> H90-1053 </papid>charniak and carroll, 1994) and (manning and carpenter, 2000) could be seen in this light.the question arises of whether parsing strategies can be extended probabilistically, i.e., whether given construction of pdas from cfgs can beaugmented?</citsent>
<aftsection>
<nextsent>with function defining the probabilities for the target pda, given the probabilities associated with the input cfg, in such way that the obtained probabilistic distributions on the cfg derivations and the corresponding pda computations are equivalent.
</nextsent>
<nextsent>some first results on this issue have been presented by (tendeau, 1995), who shows that the already mentioned left-corner parsing strategy can be extended probabilistically, and later by (abney et al., 1999) <papid> P99-1070 </papid>who show that the pure top-down parsing strategy and specific type of shift-reduce parsing strategy can be probabilistically extended.</nextsent>
<nextsent>one might think that any practical?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2167">
<title id=" P04-1069.xml">probabilistic parsing strategies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>also the results from (chitrao and grishman, 1990), (<papid> H90-1053 </papid>charniak and carroll, 1994) and (manning and carpenter, 2000) could be seen in this light.the question arises of whether parsing strategies can be extended probabilistically, i.e., whether given construction of pdas from cfgs can beaugmented?</prevsent>
<prevsent>with function defining the probabilities for the target pda, given the probabilities associated with the input cfg, in such way that the obtained probabilistic distributions on the cfg derivations and the corresponding pda computations are equivalent.</prevsent>
</prevsection>
<citsent citstr=" P99-1070 ">
some first results on this issue have been presented by (tendeau, 1995), who shows that the already mentioned left-corner parsing strategy can be extended probabilistically, and later by (abney et al., 1999) <papid> P99-1070 </papid>who show that the pure top-down parsing strategy and specific type of shift-reduce parsing strategy can be probabilistically extended.</citsent>
<aftsection>
<nextsent>one might think that any practical?
</nextsent>
<nextsent>parsing strategy can be probabilistically extended, but this turns out not to be the case.
</nextsent>
<nextsent>we briefly discus shere counter-example, in order to motivate the approach we have taken in this paper.
</nextsent>
<nextsent>probabilistic lr parsing has been investigated in the literature (wright and wrigley, 1991; briscoe and carroll, 1993; <papid> J93-1002 </papid>inui et al, 2000) under the assumption thatit would allow more fine-grained probability distributions than the underlying pcfgs.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2168">
<title id=" P04-1069.xml">probabilistic parsing strategies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>parsing strategy can be probabilistically extended, but this turns out not to be the case.
</prevsent>
<prevsent>we briefly discus shere counter-example, in order to motivate the approach we have taken in this paper.
</prevsent>
</prevsection>
<citsent citstr=" J93-1002 ">
probabilistic lr parsing has been investigated in the literature (wright and wrigley, 1991; briscoe and carroll, 1993; <papid> J93-1002 </papid>inui et al, 2000) under the assumption thatit would allow more fine-grained probability distributions than the underlying pcfgs.</citsent>
<aftsection>
<nextsent>however, this is not the case in general.
</nextsent>
<nextsent>consider pcfg with rule/probability pairs: ? ab , 1 ? bc , 23 a?
</nextsent>
<nextsent>ac , 13 ? bd , 1 3 a?
</nextsent>
<nextsent>ad , 23 ? xc, 1 ? xd , 1 there are two key transitions in the associated lr automaton, which represent shift actions over and (we denote lr states by their sets of kernel items and encode these states into stack symbols): : {c ? ? c,d ? ? d} c7?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2170">
<title id=" P04-1069.xml">probabilistic parsing strategies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>therefore the lr strategy does not allow probabilistic extension.one may seemingly solve this problem by dropping the constraint of properness, letting each transition that outputs rule have the same probability as that rule in the pcfg, and letting other transition shave probability 1.
</prevsent>
<prevsent>however, the properness condition for pdas has been heavily exploited in parsing applications, in doing incremental left-to-right probability computation for beam search (roark and johnson, 1999; <papid> P99-1054 </papid>manning and carpenter, 2000),and more generally in integration with other linear probabilistic models.</prevsent>
</prevsection>
<citsent citstr=" J98-2005 ">
furthermore, commonly used training algorithms for pcfgs/ppdas always produce proper probability assignments, and many desired mathematical properties of these methods are based on such an assumption (chi and geman,1998; <papid> J98-2005 </papid>sanchez and bened??, 1997).</citsent>
<aftsection>
<nextsent>we may therefore discard non-proper probability assignments in the current study.however, such probability assignments are out side the reach of the usual training algorithms forpdas, which always produce proper pdas.
</nextsent>
<nextsent>therefore, we may discard such assignments in the current study, which investigates aspects of the potential of training algorithms for cfgs and pdas.what has been lacking in the literature is theoretical framework to relate the parameter space of cfg to that of pda constructed from the cfg by particular parsing strategy, in terms of the set of allowable probability distributions over derivations.
</nextsent>
<nextsent>note that the number of free parameters alone is not satisfactory characterization of the parameter space.
</nextsent>
<nextsent>in fact, if the nature?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2173">
<title id=" P04-1069.xml">probabilistic parsing strategies </title>
<section> strong predictive ness.  </section>
<citcontext>
<prevsection>
<prevsent>hence, probability functionpa with the properties we required above cannot exist, and therefore cannot be extended to become probabilistic parsing strategy.
</prevsent>
<prevsent>in this section we present our main result, which is asufficient condition allowing the probabilistic extension of parsing strategy.
</prevsent>
</prevsection>
<citsent citstr=" J99-1004 ">
we start with technical result that was proven in (abney et al, 1999; <papid> P99-1070 </papid>chi, 1999; <papid> J99-1004 </papid>nederhof and satta, 2003).</citsent>
<aftsection>
<nextsent>lemma 4 given non-proper pcfg (g, pg), = (?,n, s,r), there is probability function pg such that pcfg (g, pg) is proper and, for every complete derivation d, pg(d) = 1c ? pg(d), where =?
</nextsent>
<nextsent>sdw,w???
</nextsent>
<nextsent>pg(d ?).
</nextsent>
<nextsent>note that if pcfg (g, pg) in the above lemma is consistent, then = 1 and (g, pg) and (g, pg) define the same distribution on derivations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2174">
<title id=" P04-1069.xml">probabilistic parsing strategies </title>
<section> strong predictive ness.  </section>
<citcontext>
<prevsection>
<prevsent>note that if pcfg (g, pg) in the above lemma is consistent, then = 1 and (g, pg) and (g, pg) define the same distribution on derivations.
</prevsent>
<prevsent>the normalization procedure underlying lemma 4 makes use of quantities ? adw,w???
</prevsent>
</prevsection>
<citsent citstr=" J95-2002 ">
pg(d) for each ? . these quantities can be computed to any degree of precision, as discussed for instance in (booth and thompson, 1973) and (stolcke, 1995).<papid> J95-2002 </papid></citsent>
<aftsection>
<nextsent>thus normalization of pcfg can be effectively computed.
</nextsent>
<nextsent>for fixed pdt, we define the binary relation ; on stack symbols by: ; ? if and only if (y,w, ?) `?
</nextsent>
<nextsent>(y ?, ?, v) for some ? ???
</nextsent>
<nextsent>and ? ???
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2175">
<title id=" P04-1069.xml">probabilistic parsing strategies </title>
<section> strong predictive ness.  </section>
<citcontext>
<prevsection>
<prevsent>a given (p)cfg is mapped to an equivalent (p)pdt by (probabilistic) parsing strategy.
</prevsent>
<prevsent>by ignoring the output components of swap transitions we obtain (p)pda, which can be mapped to an equivalent (p)cfg as shown above.
</prevsent>
</prevsection>
<citsent citstr=" P89-1017 ">
this observation gives rise to an extension with probabilities of the work on covers by (nijholt, 1980; leermakers, 1989).<papid> P89-1017 </papid></citsent>
<aftsection>
<nextsent>many well-known parsing strategies with the cpp also have the spp.
</nextsent>
<nextsent>this is for instance the case for top-down parsing and left-corner parsing.
</nextsent>
<nextsent>as discussed in the introduction, it has already been shown that for any pcfg g, there are equivalent ppdts implementing these strategies, as reported in (abney et al, 1999) <papid> P99-1070 </papid>and (tendeau, 1995), respectively.</nextsent>
<nextsent>those results more simply follow now from our general characterization.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2177">
<title id=" P04-1069.xml">probabilistic parsing strategies </title>
<section> applications.  </section>
<citcontext>
<prevsection>
<prevsent>as discussed in the introduction, it has already been shown that for any pcfg g, there are equivalent ppdts implementing these strategies, as reported in (abney et al, 1999) <papid> P99-1070 </papid>and (tendeau, 1995), respectively.</prevsent>
<prevsent>those results more simply follow now from our general characterization.</prevsent>
</prevsection>
<citsent citstr=" P94-1017 ">
furthermore, plr parsing (soisalon-soininen and ukko nen, 1979; nederhof, 1994) <papid> P94-1017 </papid>can be expressed in our framework as parsing strategy with the cpp and the spp, and thus we obtain as new result that this strategy allows probabilistic extension.</citsent>
<aftsection>
<nextsent>the above strategies are in contrast to the lr parsing strategy, which has the cpp but lacks thespp, and therefore falls outside our sufficient condition.
</nextsent>
<nextsent>as we have already seen in the introduction, itturns out that lr parsing cannot be extended to be come probabilistic parsing strategy.
</nextsent>
<nextsent>related to lr parsing is elr parsing (purdom and brown, 1981; nederhof, 1994), <papid> P94-1017 </papid>which also lacks the spp.</nextsent>
<nextsent>by an argument similar to the one provided for lr, we can show that also elr parsing cannot be extended to become probabilistic parsing strategy.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2179">
<title id=" N12-3005.xml">an interactive human oid robot exhibiting flexible sub dialogues </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>hierarchical dialogue control (hdc) consists of behaviours or discourse segments at different levels of granularity executed from higher to lower level.
</prevsent>
<prevsent>for example, dialogue agent can invoke asub-dialogue agent, which can also invoke subsub-dialogue agent, and so on.
</prevsent>
</prevsection>
<citsent citstr=" J86-3001 ">
task-oriented dialogues have shown evidence of following hierarchical structures (grosz and sidner, 1986; <papid> J86-3001 </papid>litman and allen, 1987; clark, 1996).</citsent>
<aftsection>
<nextsent>practically speaking, hdc offers the following benefits.
</nextsent>
<nextsent>first, modularity helps to specify sub-dialogues thatmay be easier to specify than the entire full dialogues.
</nextsent>
<nextsent>second, sub-dialogues may include only relevant dialogue knowledge (e.g. subsets of dialogue acts), thus reducing significantly their com ?*funding by the eu-fp7 project aliz-e (ict-248116) is gratefully acknowledged.
</nextsent>
<nextsent>(a) strict hierachical dialogue control dialogue sub-dialogue1 sub-dialogue2 (b) flexible hierachical dialogue control dialogue sub-dialogue1 sub-dialogue2 figure 1: hierarchies of dialogue agents with strict (top down) and flexible control (partial top down).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2180">
<title id=" N12-3008.xml">a robust shallow temporal reasoning system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we present system that addresses three fundamental tasks in temporal reasoning:?
</prevsent>
<prevsent>extraction: capturing the extent of time expressions in given text.
</prevsent>
</prevsection>
<citsent citstr=" S10-1010 ">
this task is based on task in the tempeval-2 challenge (verhagen et al , 2010).<papid> S10-1010 </papid></citsent>
<aftsection>
<nextsent>consider the following sentence: seventy-five million copies of the rifle have been built since it entered production in february 1947.
</nextsent>
<nextsent>in this sentence, february 1947 is basic temporal expression that should be extracted by the extraction module.
</nextsent>
<nextsent>more importantly, we further extend thetask to support also the extraction of complex temporal expressions that are not addressed by existingsystems.
</nextsent>
<nextsent>in the example above, it is important to recognize and capture the phrase since it entered production in february 1947 as another temporal expression that expresses the time period of the manufacturing event (triggered by built.)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2184">
<title id=" N12-3008.xml">a robust shallow temporal reasoning system </title>
<section> the system.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 temporal expression extraction.
</prevsent>
<prevsent>we built the temporal expression extraction module on top of the heideltime system (strotgen and gertz,2010) to take advantage of state-of-the-art temporal extraction system in capturing basic expressions.
</prevsent>
</prevsection>
<citsent citstr=" P98-2186 ">
we use the illinois pos tagger1 (roth and zelenko, 1998) <papid> P98-2186 </papid>to provide part-of-speech tags for the input text before passing it to heideltime.</citsent>
<aftsection>
<nextsent>below is an example of the heideltime output of the example in the previous section: seventy-five million copies of the rifle have been built since it entered production in  timex3 tid=t2?
</nextsent>
<nextsent>type=date?
</nextsent>
<nextsent>value=1947-02? february 1947 /timex3 in this example, heideltime captures basic temporal expression: february 1947.
</nextsent>
<nextsent>however, heideltime cannot capture the complex temporal expression since it entered production in february 1947, which expresses period of time from february1947 until the document creation time.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2185">
<title id=" N12-3008.xml">a robust shallow temporal reasoning system </title>
<section> the system.  </section>
<citcontext>
<prevsection>
<prevsent>furthermore, we take advantage of the predicted temporal value ofeach temporal expression from the heideltime out put.
</prevsent>
<prevsent>for instance, in the heideltime output example above, we extract 1947-02 as the normalized dateof february 1947 and then convert it to the interval [1947-02-01 00:00:00, 1947-02-28 23:59:59].
</prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
if heideltime cannot identify an exact date, month or year, we then resort to our own temporal normalizer, 2we use nlparser (charniak and johnson, 2005) <papid> P05-1022 </papid>30which consists of set of conversion rules, regarding to the document creation time of the input text.an interval endpoint can get infinity value if its temporal boundary cannot be specified.</citsent>
<aftsection>
<nextsent>2.3 comparison.
</nextsent>
<nextsent>to compare two time intervals (i.e. normalized temporal expressions), we define six temporal rela tions: before, before-and-overlap, contains, equals, inside, after and after-and-overlap.
</nextsent>
<nextsent>the temporal relation between two normalized intervals is determined by set of comparison rules that take the four interval endpoints into consideration.
</nextsent>
<nextsent>for example, = [sa, ea] contains = [sb, eb] if and only if (sa   sb)?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2187">
<title id=" N12-2012.xml">automatic humor classification on twitter </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the latter is also very limited in its syntax.
</prevsent>
<prevsent>only in later studies was the recognition of humor examined.
</prevsent>
</prevsection>
<citsent citstr=" H05-1067 ">
mihalcea and strapparava (2005) <papid> H05-1067 </papid>used content and stylistic features to automatically recognize humor.</citsent>
<aftsection>
<nextsent>this was done, however, on more homogenous set of data, one-liners, that, unlike tweets, are formal, grammatically correct and of ten exhibit stylistic features, such as alliteration and antonyms, which seldom appear in tweets.
</nextsent>
<nextsent>davidov et al (2010) recognized sarcastic sentences in twitter.
</nextsent>
<nextsent>they used semi-supervised algorithm to acquire features that could then be used by the classifier to decide which data item was sarcastic.
</nextsent>
<nextsent>in addition to these lexical patterns, the classifier also used punctuation-based features (i.e. number of !).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2188">
<title id=" P01-1048.xml">predicting user reactions to system error </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in such interactions, however, there is also evidence showing prosodic information may be used as resource for error recovery.
</prevsent>
<prevsent>in previous work,we identified new procedures to detect recognition errors.
</prevsent>
</prevsection>
<citsent citstr=" A00-2029 ">
in particular, we found that prosodic features, in combination with other information already available to the recognizer, can distinguish user turns that are mis recognized by the system far better than traditional methods used in asr rejection (litman et al, 2000; <papid> A00-2029 </papid>hirschberg et al., 2000).</citsent>
<aftsection>
<nextsent>we also found that user corrections of system mis recognitions exhibit certain typical prosodic features, which can be used to identify such turns (swerts et al, 2000; hirschberg et al,2001).<papid> N01-1027 </papid></nextsent>
<nextsent>these findings are consistent with previous research showing that corrections tend to be hyper articulated ? higher, louder, longer . . .</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2189">
<title id=" P01-1048.xml">predicting user reactions to system error </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in previous work,we identified new procedures to detect recognition errors.
</prevsent>
<prevsent>in particular, we found that prosodic features, in combination with other information already available to the recognizer, can distinguish user turns that are mis recognized by the system far better than traditional methods used in asr rejection (litman et al, 2000; <papid> A00-2029 </papid>hirschberg et al., 2000).</prevsent>
</prevsection>
<citsent citstr=" N01-1027 ">
we also found that user corrections of system mis recognitions exhibit certain typical prosodic features, which can be used to identify such turns (swerts et al, 2000; hirschberg et al,2001).<papid> N01-1027 </papid></citsent>
<aftsection>
<nextsent>these findings are consistent with previous research showing that corrections tend to be hyper articulated ? higher, louder, longer . . .
</nextsent>
<nextsent>than other turns (wade et al, 1992; oviatt et al, 1996; levow, 1998; <papid> P98-1122 </papid>bell and gustafson, 1999).</nextsent>
<nextsent>in the current study, we focus on another turn category that is potentially useful in error hand ling.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2190">
<title id=" P01-1048.xml">predicting user reactions to system error </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also found that user corrections of system mis recognitions exhibit certain typical prosodic features, which can be used to identify such turns (swerts et al, 2000; hirschberg et al,2001).<papid> N01-1027 </papid></prevsent>
<prevsent>these findings are consistent with previous research showing that corrections tend to be hyper articulated ? higher, louder, longer . . .</prevsent>
</prevsection>
<citsent citstr=" P98-1122 ">
than other turns (wade et al, 1992; oviatt et al, 1996; levow, 1998; <papid> P98-1122 </papid>bell and gustafson, 1999).</citsent>
<aftsection>
<nextsent>in the current study, we focus on another turn category that is potentially useful in error handling.
</nextsent>
<nextsent>in particular, we examine what we term aware sites ? turns where user, while interacting with machine, first becomes aware that the system has mis recognized previous user turn.
</nextsent>
<nextsent>note that such aware sites may or may not also be corrections (another type of post-misrecognition turn), since user may not immediately provide correcting information.
</nextsent>
<nextsent>we will refer to turns that are both aware sites and corrections as corr awares, to turns that are only corrections as corrs, to turns that are only aware sites as awares, and to turns that are neither aware sites nor corrections as norm.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2193">
<title id=" P04-1045.xml">predicting student emotions in computer human tutoring dialogues </title>
<section> computer-human dialogue data.  </section>
<citcontext>
<prevsection>
<prevsent>our best models for predicting three different types of emotion classifications achieve accuracies of 66-73%, representing relative improvements of 19-36% over majority class baseline errors.
</prevsent>
<prevsent>our computer-human results also show interesting differences compared with comparable analyses of human-human data.our results provide an empirical basis for enhancing our spoken dialogue tutoring system to automatically predict and adapt to student model that includes emotional states.
</prevsent>
</prevsection>
<citsent citstr=" N04-3002 ">
our data consists of student dialogues with it spoke (intelligent tutoring spoken dialoguesystem) (litman and silliman, 2004), <papid> N04-3002 </papid>spoken dialogue tutor built on top of the why2-atlas conceptual physics text-based tutoring system (vanlehn et al ., 2002).</citsent>
<aftsection>
<nextsent>in itspoke, student first types anessay answering qualitative physics problem.
</nextsent>
<nextsent>itspoke then analyzes the essay and engages the student in spoken dialogue to correct misconceptions and to elicit complete explanations.
</nextsent>
<nextsent>first, the why2-atlas back-end parses the student essay into propositional representations, in order tofind useful dialogue topics.
</nextsent>
<nextsent>it uses 3 different approaches (symbolic, statistical and hybrid) competitively to create representation for each sentence, then resolves temporal and nominal anaphora and constructs proofs using abductive reasoning (jor dan et al , 2004).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2194">
<title id=" N12-2006.xml">choosing an evaluation metric for parser design </title>
<section> prior work.  </section>
<citcontext>
<prevsection>
<prevsent>comparisons of parser metrics have been undertaken in the past.
</prevsent>
<prevsent>carroll et al(1998) describe 29broad range of parser evaluation metrics, and comment on their advantages and disadvantages, but donot offer quantitative comparison.
</prevsent>
</prevsection>
<citsent citstr=" P07-1032 ">
a number of papers such as clark and curran (2007) <papid> P07-1032 </papid>have explored the difficulty of parser comparison across different underlying formalisms.</citsent>
<aftsection>
<nextsent>crouch et al(2002) compare two variant dependency-based metrics in some detail on single lfg-based parsing model, concluding that despite some differences in the metrics?
</nextsent>
<nextsent>strategies, they offer similar views on the performance of their parser.the literature specifically seeking to quantitatively compare broad range of metrics across alarge array of parsers is small.
</nextsent>
<nextsent>emms (2008) describes the tree-distance metric and compares the rankings induced by several variants of that metric and parseval on collection of six statistical parsers, finding broad compatibility, but observing frequent disagreement about the relative ranks of two parsers whose scores were only marginally different.
</nextsent>
<nextsent>in our setup, the overall score metric assigns to parser is the average of the scores awarded forthe parsers analyses of each sentence in the treebank (termed macro-averaging, in contrast to micro averaging which is also common).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2195">
<title id=" N12-2006.xml">choosing an evaluation metric for parser design </title>
<section> metrics.  </section>
<citcontext>
<prevsection>
<prevsent>labels are rule names.
</prevsent>
<prevsent>unlabeled parseval (up) - identical to lp, except ignoring the labels on the brackets.?
</prevsent>
</prevsection>
<citsent citstr=" W06-2920 ">
labeled syntactic dependencies (lsd) (buch holz and marsi, 2006) - <papid> W06-2920 </papid>the f1 for comparing the sets of directed bilexical syntactic dependencies extracted from the returned and gold trees, labeled by the rule name that joins the dependent to the dependee.?</citsent>
<aftsection>
<nextsent>unlabeled syntactic dependencies (usd) identical to lsd, except ignoring the labels.
</nextsent>
<nextsent>labeled elementary dependencies (led) - thef1 for comparing the sets of elementary dependency triples (oepen and lnning, 2006) extracted from the returned and gold mrs. these annotations are similar in spirit to those used in the parc 700 dependency bank (king et al,2003) and other semantic dependency evaluation schemes.?
</nextsent>
<nextsent>unlabeled elementary dependencies (ued) identical to led, except ignoring all labeling information other than the input positions involved.
</nextsent>
<nextsent>leaf ancestor (la) (sampson and babarczy,2003) - the average of the edit distances between the paths through the returned and gold trees from root to each leaf.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2196">
<title id=" P00-1028.xml">a constraint based approach to english prosodic constituents </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the general aim is to define prosodic structures recursively, in parallel with the definition of syntactic structures.
</prevsent>
<prevsent>we address number of prima facie problems arising from the discrepancy between syntactic and prosodic structure
</prevsent>
</prevsection>
<citsent citstr=" W94-0202 ">
this paper develops declarative treatment of prosodic constituents within the framework of constraint based phonology, as developed for example in (bird, 1995; mastroianni and carpenter, 1994).<papid> W94-0202 </papid></citsent>
<aftsection>
<nextsent>on such an approach, phonological representations are encoded with typed feature terms.
</nextsent>
<nextsent>in addition to the representational power of complex feature values, the inheritance hierarchy of types provides flexible mechanism for classifying linguistic structures, and for expressing generalizations by means of type inference.to date, little work within constraint-based phono logy has addressed prosodic structure above the level of the foot.
</nextsent>
<nextsent>in my treatment, will adopt the following assumptions: 1.
</nextsent>
<nextsent>phonology is induced in parallel with syntactic.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2197">
<title id=" P00-1028.xml">a constraint based approach to english prosodic constituents </title>
<section> syntactic and prosodic structure.  </section>
<citcontext>
<prevsection>
<prevsent>i will also not adopt the strict layer hypothesis (selkirk, 1984) which holds that elements of given prosodic category (such as into national phrase) must be exhaustively analysed into sequence of elements of the next lower category (such as phonological phrase).
</prevsent>
<prevsent>however, it is important to note that every ip will be prosodic constituent, in my sense.
</prevsent>
</prevsection>
<citsent citstr=" J90-3003 ">
moreover, my lower-level prosodic constituents could be identified with the ?-phrases of (selkirk, 1981; gee and grosjean, 1983; nespor and vogel, 1986; bachenko and fitzpatrick, 1990), <papid> J90-3003 </papid>which are grouped together to make ips.</citsent>
<aftsection>
<nextsent>2.2 representing prosodic structure.
</nextsent>
<nextsent>i shall follow standard assumptions in hpsg by separating the phonology attribute out from syntax semantics (synsem): (4) feat-struc !   phon pros synsem synsem # the type of value of phon is pros (i.e., prosody).
</nextsent>
<nextsent>in this paper, am going to take word forms as phonologically simple.
</nextsent>
<nextsent>this means that the prosodic type of word forms will be maximal in the hierarchy.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2198">
<title id=" P00-1028.xml">a constraint based approach to english prosodic constituents </title>
<section> concluding remarks.  </section>
<citcontext>
<prevsection>
<prevsent>(26) extmtr( 1 [lnr], dom 2  3 dte 4 # ) = 2 6 4 full-mtr dom extmtr( 1 ), mtr dom extmtr(2 )  3 dte 4 3 7 5 this will also allow an un accented subject pronoun to left-associate with the lexical head of vp, as in [[he provoked] [the objections of everyone]] (gee and grosjean, 1983).
</prevsent>
<prevsent>i believe that the preceding analysis demonstrates that despite the well-known mismatches between syntactic and prosodic structure, it is possible to induce the required prosodic structures in tandem with syntax.
</prevsent>
</prevsection>
<citsent citstr=" E93-1039 ">
moreover, the analysis retains rather conventional notions of syntactic constituency, eschewing the nonstandard syntactic constituents advocated by prevost and steedman (1993), <papid> E93-1039 </papid>steedman (1990),  <papid> P90-1002 </papid>steedman (1991).</citsent>
<aftsection>
<nextsent>although have only mentioned two syntactic rules in hpsg, the radically underspecified nature of these rules, coupled with rich lexical entries, means that the approach have sketched has more generality than might appear at first.
</nextsent>
<nextsent>with the addition of rule for pre nominal adjectives, prosodically interpreted like the head-specifier rule, we can derive range of analyses as summarised in (27).
</nextsent>
<nextsent>here, use square brackets to demarcate trees of type full-mtr and parentheses for trees of type lnr-mtr.
</nextsent>
<nextsent>(27) a. [this possession](of the samurai) b. [this treasured possession](of the samurai) c.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2199">
<title id=" P00-1028.xml">a constraint based approach to english prosodic constituents </title>
<section> concluding remarks.  </section>
<citcontext>
<prevsection>
<prevsent>(26) extmtr( 1 [lnr], dom 2  3 dte 4 # ) = 2 6 4 full-mtr dom extmtr( 1 ), mtr dom extmtr(2 )  3 dte 4 3 7 5 this will also allow an un accented subject pronoun to left-associate with the lexical head of vp, as in [[he provoked] [the objections of everyone]] (gee and grosjean, 1983).
</prevsent>
<prevsent>i believe that the preceding analysis demonstrates that despite the well-known mismatches between syntactic and prosodic structure, it is possible to induce the required prosodic structures in tandem with syntax.
</prevsent>
</prevsection>
<citsent citstr=" P90-1002 ">
moreover, the analysis retains rather conventional notions of syntactic constituency, eschewing the nonstandard syntactic constituents advocated by prevost and steedman (1993), <papid> E93-1039 </papid>steedman (1990),  <papid> P90-1002 </papid>steedman (1991).</citsent>
<aftsection>
<nextsent>although have only mentioned two syntactic rules in hpsg, the radically underspecified nature of these rules, coupled with rich lexical entries, means that the approach have sketched has more generality than might appear at first.
</nextsent>
<nextsent>with the addition of rule for pre nominal adjectives, prosodically interpreted like the head-specifier rule, we can derive range of analyses as summarised in (27).
</nextsent>
<nextsent>here, use square brackets to demarcate trees of type full-mtr and parentheses for trees of type lnr-mtr.
</nextsent>
<nextsent>(27) a. [this possession](of the samurai) b. [this treasured possession](of the samurai) c.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2200">
<title id=" P03-2031.xml">automatic acquisition of named entity tagged corpus from world wide web </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our experiments demonstrates that the suggested method can acquire enough ne tagged corpus equally useful to the manually tagged one without any human intervention.
</prevsent>
<prevsent>current trend in named entity recognition (ner) is to apply machine learning approach, which is more attractive because it is trainable and adaptable, and subsequently the porting of machine learning system to another domain is much easier than that of arule-based one.
</prevsent>
</prevsection>
<citsent citstr=" P02-1060 ">
various supervised learning methods for named entity (ne) tasks were successfully applied and have shown reasonably satisfiable per formance.((zhou and su, 2002)(<papid> P02-1060 </papid>borthwick et al, 1998)(<papid> W98-1118 </papid>sassano and utsuro, 2000)) <papid> C00-2102 </papid>however, most of these systems heavily relyon tagged corpus for training.</citsent>
<aftsection>
<nextsent>for machine learning approach, large corpus is required to circumvent the data sparseness problem, but the dilemma is that the costs required to annotate large training corpus are non-trivial.in this paper, we suggest method that automatically constructs an ne tagged corpus from the web to be used for learning of ner systems.
</nextsent>
<nextsent>we use anne list and an web search engine to collect web documents which contain the ne instances.
</nextsent>
<nextsent>the documents are refined through the sentence separation and text refinement procedures and ne instances are finally annotated with the appropriate ne categories.
</nextsent>
<nextsent>this automatically tagged corpus may have lower quality than the manually tagged ones but its sizecan be almost infinitely increased without any human efforts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2201">
<title id=" P03-2031.xml">automatic acquisition of named entity tagged corpus from world wide web </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our experiments demonstrates that the suggested method can acquire enough ne tagged corpus equally useful to the manually tagged one without any human intervention.
</prevsent>
<prevsent>current trend in named entity recognition (ner) is to apply machine learning approach, which is more attractive because it is trainable and adaptable, and subsequently the porting of machine learning system to another domain is much easier than that of arule-based one.
</prevsent>
</prevsection>
<citsent citstr=" W98-1118 ">
various supervised learning methods for named entity (ne) tasks were successfully applied and have shown reasonably satisfiable per formance.((zhou and su, 2002)(<papid> P02-1060 </papid>borthwick et al, 1998)(<papid> W98-1118 </papid>sassano and utsuro, 2000)) <papid> C00-2102 </papid>however, most of these systems heavily relyon tagged corpus for training.</citsent>
<aftsection>
<nextsent>for machine learning approach, large corpus is required to circumvent the data sparseness problem, but the dilemma is that the costs required to annotate large training corpus are non-trivial.in this paper, we suggest method that automatically constructs an ne tagged corpus from the web to be used for learning of ner systems.
</nextsent>
<nextsent>we use anne list and an web search engine to collect web documents which contain the ne instances.
</nextsent>
<nextsent>the documents are refined through the sentence separation and text refinement procedures and ne instances are finally annotated with the appropriate ne categories.
</nextsent>
<nextsent>this automatically tagged corpus may have lower quality than the manually tagged ones but its sizecan be almost infinitely increased without any human efforts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2202">
<title id=" P03-2031.xml">automatic acquisition of named entity tagged corpus from world wide web </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our experiments demonstrates that the suggested method can acquire enough ne tagged corpus equally useful to the manually tagged one without any human intervention.
</prevsent>
<prevsent>current trend in named entity recognition (ner) is to apply machine learning approach, which is more attractive because it is trainable and adaptable, and subsequently the porting of machine learning system to another domain is much easier than that of arule-based one.
</prevsent>
</prevsection>
<citsent citstr=" C00-2102 ">
various supervised learning methods for named entity (ne) tasks were successfully applied and have shown reasonably satisfiable per formance.((zhou and su, 2002)(<papid> P02-1060 </papid>borthwick et al, 1998)(<papid> W98-1118 </papid>sassano and utsuro, 2000)) <papid> C00-2102 </papid>however, most of these systems heavily relyon tagged corpus for training.</citsent>
<aftsection>
<nextsent>for machine learning approach, large corpus is required to circumvent the data sparseness problem, but the dilemma is that the costs required to annotate large training corpus are non-trivial.in this paper, we suggest method that automatically constructs an ne tagged corpus from the web to be used for learning of ner systems.
</nextsent>
<nextsent>we use anne list and an web search engine to collect web documents which contain the ne instances.
</nextsent>
<nextsent>the documents are refined through the sentence separation and text refinement procedures and ne instances are finally annotated with the appropriate ne categories.
</nextsent>
<nextsent>this automatically tagged corpus may have lower quality than the manually tagged ones but its sizecan be almost infinitely increased without any human efforts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2203">
<title id=" P03-2031.xml">automatic acquisition of named entity tagged corpus from world wide web </title>
<section> automatic acquisition of an ne tagged.  </section>
<citcontext>
<prevsection>
<prevsent>sentence refinement is accomplished by three different processes: separation of functional words, segmentation of compound nouns, and verification of the usefulness of the extracted sentences.
</prevsent>
<prevsent>an ne is often concatenated with more than one josa, korean functional word, to compose korean word.
</prevsent>
</prevsection>
<citsent citstr=" J02-1004 ">
therefore we need to separate the functional words from an ne instance to detect the boundary of the ne instance and this is achieved by part-of-speech tagger, postag, which can detect unknown words (lee et al, 2002).<papid> J02-1004 </papid></citsent>
<aftsection>
<nextsent>the separation of functional words gives us another benefit that we can resolve the ambiguities between an ne and common noun plus functional words 1we used empas (http://www.empas.com) person location organization training automatic 29,042 37,480 2,271manual 1,014 724 1,338 test manual 102 72 193table 1: corpus description (number of nes) (au tomatic: automatically annotated corpus, manual: manually annotated corpus and filter out erroneous matches.
</nextsent>
<nextsent>for example, e??(kyunggi-do)?
</nextsent>
<nextsent>can be interpreted as either e??(kyunggi province)?
</nextsent>
<nextsent>or e?+?(a game also)?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2204">
<title id=" P03-1022.xml">a machine learning approach to pronoun resolution in spoken dialogue </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we present setof features designed for pronoun resolution in spoken dialogue and determine the most promising features.
</prevsent>
<prevsent>we evaluate the system on twenty switchboard dialogues and show that it compares well to byrons (2002) manually tuned system.
</prevsent>
</prevsection>
<citsent citstr=" J01-4004 ">
corpus-based methods and machine learning techniques have been applied to anaphora resolution in written text with considerable success (soon et al, 2001; <papid> J01-4004 </papid>ng &amp; cardie, 2002, <papid> P02-1014 </papid>among others).</citsent>
<aftsection>
<nextsent>it hasbeen demonstrated that systems based on these approaches achieve performance that is comparable to hand-crafted systems.
</nextsent>
<nextsent>since they can easily be applied to new domains it seems also feasible toport given corpus-based anaphora resolution system from written text to spoken dialogue.
</nextsent>
<nextsent>this paper describes the extensions and adaptations needed for applying our anaphora resolution system (mulleret al, 2002; strube et al, 2002) <papid> W02-1040 </papid>to pronoun resolution in spoken dialogue.</nextsent>
<nextsent>there are important differences between written text and spoken dialogue which have to be accountedfor.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2205">
<title id=" P03-1022.xml">a machine learning approach to pronoun resolution in spoken dialogue </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we present setof features designed for pronoun resolution in spoken dialogue and determine the most promising features.
</prevsent>
<prevsent>we evaluate the system on twenty switchboard dialogues and show that it compares well to byrons (2002) manually tuned system.
</prevsent>
</prevsection>
<citsent citstr=" P02-1014 ">
corpus-based methods and machine learning techniques have been applied to anaphora resolution in written text with considerable success (soon et al, 2001; <papid> J01-4004 </papid>ng &amp; cardie, 2002, <papid> P02-1014 </papid>among others).</citsent>
<aftsection>
<nextsent>it hasbeen demonstrated that systems based on these approaches achieve performance that is comparable to hand-crafted systems.
</nextsent>
<nextsent>since they can easily be applied to new domains it seems also feasible toport given corpus-based anaphora resolution system from written text to spoken dialogue.
</nextsent>
<nextsent>this paper describes the extensions and adaptations needed for applying our anaphora resolution system (mulleret al, 2002; strube et al, 2002) <papid> W02-1040 </papid>to pronoun resolution in spoken dialogue.</nextsent>
<nextsent>there are important differences between written text and spoken dialogue which have to be accountedfor.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2206">
<title id=" P03-1022.xml">a machine learning approach to pronoun resolution in spoken dialogue </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it hasbeen demonstrated that systems based on these approaches achieve performance that is comparable to hand-crafted systems.
</prevsent>
<prevsent>since they can easily be applied to new domains it seems also feasible toport given corpus-based anaphora resolution system from written text to spoken dialogue.
</prevsent>
</prevsection>
<citsent citstr=" W02-1040 ">
this paper describes the extensions and adaptations needed for applying our anaphora resolution system (mulleret al, 2002; strube et al, 2002) <papid> W02-1040 </papid>to pronoun resolution in spoken dialogue.</citsent>
<aftsection>
<nextsent>there are important differences between written text and spoken dialogue which have to be accountedfor.
</nextsent>
<nextsent>the most obvious difference is that in spoken dialogue there is an abundance of (personal and demonstrative) pronouns with non-np-antecedents or no antecedents at all.
</nextsent>
<nextsent>corpus studies have shown that significant amount of pronouns in spoken dialogue have non-np-antecedents: byron &amp; allen (1998) report that about 50% of the pronouns in thetrains93 corpus have non-np-antecedents.
</nextsent>
<nextsent>eckert &amp; strube (2000) note that only about 45% of the pronouns in set of switchboard dialogues have np-antecedents.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2207">
<title id=" P03-1022.xml">a machine learning approach to pronoun resolution in spoken dialogue </title>
<section> np- vs. non-np-antecedents.  </section>
<citcontext>
<prevsection>
<prevsent>a3: [his]  mother comes in and says, why did you let [him]  [play in the dirt] , a:4 guess [[he]  enjoying himself]  . b5: [that]  right.
</prevsent>
<prevsent>b6: [it] healthy, . . .a major problem for pronoun resolution in spoken dialogue is the large number of personal and demonstrative pronouns which are either not referential at all (e.g. expletive pronouns) or for which particular antecedent cannot easily be determined by humans (called vague anaphors by eckert &amp; strube (2000)).in the following example, the that  ? in utterance (a3) refers back to utterance (a1).
</prevsent>
</prevsection>
<citsent citstr=" P02-1011 ">
as for the first two pronouns in (b4), following eckert &strube; (2000) and byron (2002) <papid> P02-1011 </papid>we assume that referring expressions in disfluencies, abandoned utterances etc. are excluded from the resolution.</citsent>
<aftsection>
<nextsent>the third pronoun in (b4) is an expletive.
</nextsent>
<nextsent>the pronoun in (a5) is different in that it is indeed referential: it refers back tothat  ? from (a3).
</nextsent>
<nextsent>a1: . . .
</nextsent>
<nextsent>[there is lot of theft, lot of assault dealing with, uh, people trying to get money for drugs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2213">
<title id=" P03-1022.xml">a machine learning approach to pronoun resolution in spoken dialogue </title>
<section> features.  </section>
<citcontext>
<prevsection>
<prevsent>the features mdist 3mf3p and mdist 3n (21), and mdist 3n (22) are refinements of the mdistfeature.
</prevsent>
<prevsent>they measure the distance in markables between antecedent and anaphor, but in doing so they take the agreement value of the anaphor into account.
</prevsent>
</prevsection>
<citsent citstr=" A97-1052 ">
for anaphors with an agreement value of 3mfor 3p, mdist 3mf3p is measured as = 1 + the num3it seemed preferable to compile our own list instead of using existing ones like briscoe &amp; carroll (1997).<papid> A97-1052 </papid></citsent>
<aftsection>
<nextsent>ber of np-markables between anaphor and potential antecedent.
</nextsent>
<nextsent>anaphors with an agreement value of 3n, (i.e. it or that), on the other hand, potentially have non-np-antecedents, so mdist 3n is measure das + the number of anaphoric ally accessible4 and vp-markables between anaphor and potential antecedent.
</nextsent>
<nextsent>the feature ante tfifd (23) is supposed to capture the relative importance of an expression for dialogue.
</nextsent>
<nextsent>the underlying assumption is that the higher the importance of non-np expression, the higher the probability of its being referred back to.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2214">
<title id=" P03-1022.xml">a machine learning approach to pronoun resolution in spoken dialogue </title>
<section> experiments and results.  </section>
<citcontext>
<prevsection>
<prevsent>all results reported were obtained by performing 20-fold cross validation.in the prediction phase, the trained classifier is exposed to unlabeled instances of test data.
</prevsent>
<prevsent>the classifiers task is to label each instance.
</prevsent>
</prevsection>
<citsent citstr=" M95-1005 ">
when an instance is labeled as co referring, the ids of the anaphor and antecedent are kept in response list for the evaluation according to vilain et al (1995).<papid> M95-1005 </papid>for determining the relevant feature set we followed an iterative procedure similar to the wrapper approach for feature selection (kohavi &amp; john,1997).</citsent>
<aftsection>
<nextsent>we start with model based on set of predefined baseline features.
</nextsent>
<nextsent>then we train models combining the baseline with all additional features separately.
</nextsent>
<nextsent>we choose the best performing feature (f measure according to vilain et al (1995)), <papid> M95-1005 </papid>adding it to the model.</nextsent>
<nextsent>we then train classifiers combining the enhanced model with each of the remaining features separately.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2228">
<title id=" P03-1022.xml">a machine learning approach to pronoun resolution in spoken dialogue </title>
<section> comparison to related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, there are few papers dealing with neuter pronouns with np-antecedents.
</prevsent>
<prevsent>e.g., dagan &amp; itai (1991) presented corpus-based approach to the resolution of the pronoun it, but they use written text corpus and do not mention non-np-antecedents at all.
</prevsent>
</prevsection>
<citsent citstr=" W99-0207 ">
paul et al(1999) <papid> W99-0207 </papid>presented corpus-based anaphora resolution algorithm for spoken dialogue.</citsent>
<aftsection>
<nextsent>for their experiments, however, they restricted anaphoric relations to those with np-antecedents.
</nextsent>
<nextsent>byron (2002) <papid> P02-1011 </papid>presented symbolic approach which resolves pronouns with np- and non-npantecedents in spoken dialogue in the trains domain.</nextsent>
<nextsent>byron extends pronoun resolution algorithm (tetrault, 2001) with semantic filtering,thus enabling it to resolve anaphors with non-np antecedents as well.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2240">
<title id=" P04-1028.xml">mining meta linguistic activity in corpora to create lexical resources using information extraction techniques the mop system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>availability of large-scale corpora has made it possible to mine specific knowledge from free or semi-structured text, resulting in what many consider by now reasonably mature nlp technology.
</prevsent>
<prevsent>extensive research in information extraction (ie) techniques, especially with the series of message understanding conferences of the nineties, has focused on tasks such as creating and updating databases of corporate join ventures or terrorist and guerrilla attacks, while the acquilex project used similar methods for creating lexical databases using the highly structured environment of machine-readable dictionary entries and other resources.
</prevsent>
</prevsection>
<citsent citstr=" M95-1011 ">
gathering knowledge from unstructured text often requires manually crafting knowledge engineering rules both complex and deeply dependent of the domain at hand, although some successful experiences using learning algorithms have been reported (fisher et al, 1995; <papid> M95-1011 </papid>chieu et al., 2003).<papid> P03-1028 </papid></citsent>
<aftsection>
<nextsent>although mining specific semantic relations and subcategorization information from free-text has been successfully carried out in the past (hearst, 1999; manning, 1993), <papid> P93-1032 </papid>automatically extracting lexical resources (including terminological definitions) from text in special domains has been field less explored, but recent experiences (klavans et al, 2001; rodrguez, 2001; cartier, 1998) show that compiling the extensive resources that modern scientific and technical disciplines need in order to manage the explosive growth of their knowledge, is both feasible and practical.</nextsent>
<nextsent>a good example of this nlp-based processing need is the medline abstract database maintained by the national library of medicine1 (nlm), which incorporates around 40,000 health sciences papers each month.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2241">
<title id=" P04-1028.xml">mining meta linguistic activity in corpora to create lexical resources using information extraction techniques the mop system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>availability of large-scale corpora has made it possible to mine specific knowledge from free or semi-structured text, resulting in what many consider by now reasonably mature nlp technology.
</prevsent>
<prevsent>extensive research in information extraction (ie) techniques, especially with the series of message understanding conferences of the nineties, has focused on tasks such as creating and updating databases of corporate join ventures or terrorist and guerrilla attacks, while the acquilex project used similar methods for creating lexical databases using the highly structured environment of machine-readable dictionary entries and other resources.
</prevsent>
</prevsection>
<citsent citstr=" P03-1028 ">
gathering knowledge from unstructured text often requires manually crafting knowledge engineering rules both complex and deeply dependent of the domain at hand, although some successful experiences using learning algorithms have been reported (fisher et al, 1995; <papid> M95-1011 </papid>chieu et al., 2003).<papid> P03-1028 </papid></citsent>
<aftsection>
<nextsent>although mining specific semantic relations and subcategorization information from free-text has been successfully carried out in the past (hearst, 1999; manning, 1993), <papid> P93-1032 </papid>automatically extracting lexical resources (including terminological definitions) from text in special domains has been field less explored, but recent experiences (klavans et al, 2001; rodrguez, 2001; cartier, 1998) show that compiling the extensive resources that modern scientific and technical disciplines need in order to manage the explosive growth of their knowledge, is both feasible and practical.</nextsent>
<nextsent>a good example of this nlp-based processing need is the medline abstract database maintained by the national library of medicine1 (nlm), which incorporates around 40,000 health sciences papers each month.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2242">
<title id=" P04-1028.xml">mining meta linguistic activity in corpora to create lexical resources using information extraction techniques the mop system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>extensive research in information extraction (ie) techniques, especially with the series of message understanding conferences of the nineties, has focused on tasks such as creating and updating databases of corporate join ventures or terrorist and guerrilla attacks, while the acquilex project used similar methods for creating lexical databases using the highly structured environment of machine-readable dictionary entries and other resources.
</prevsent>
<prevsent>gathering knowledge from unstructured text often requires manually crafting knowledge engineering rules both complex and deeply dependent of the domain at hand, although some successful experiences using learning algorithms have been reported (fisher et al, 1995; <papid> M95-1011 </papid>chieu et al., 2003).<papid> P03-1028 </papid></prevsent>
</prevsection>
<citsent citstr=" P93-1032 ">
although mining specific semantic relations and subcategorization information from free-text has been successfully carried out in the past (hearst, 1999; manning, 1993), <papid> P93-1032 </papid>automatically extracting lexical resources (including terminological definitions) from text in special domains has been field less explored, but recent experiences (klavans et al, 2001; rodrguez, 2001; cartier, 1998) show that compiling the extensive resources that modern scientific and technical disciplines need in order to manage the explosive growth of their knowledge, is both feasible and practical.</citsent>
<aftsection>
<nextsent>a good example of this nlp-based processing need is the medline abstract database maintained by the national library of medicine1 (nlm), which incorporates around 40,000 health sciences papers each month.
</nextsent>
<nextsent>researchers depend on these electronic resources to keep abreast of their rapidly changing field.
</nextsent>
<nextsent>in order to maintain and update vital indexing references such as the unified medical language system (umls) resources, the mesh and specialist vocabularies, the nlm staff needs to review 400,000 highly-technical papers each year.
</nextsent>
<nextsent>clearly, neology detection, terminological information update and other tasks can benefit from applications that automatically search text for information, e.g., when new term is introduced or an existing one is modified due to data or theory-driven concerns, or, in general, when new information about sublanguage usage is being put forward.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2243">
<title id=" P04-1028.xml">mining meta linguistic activity in corpora to create lexical resources using information extraction techniques the mop system </title>
<section> locating meta linguistic information in.  </section>
<citcontext>
<prevsection>
<prevsent>the different number of positions considered to the left and right of the markers in our training corpus, as well as the nature of the features selected (there are many more word-types than pos tags) ensured that our 3-part vector introduced wide range of features against our 2 possible yes-no labels for processing by our algorithms.
</prevsent>
<prevsent>although our test runs using only collocations showed initially that structural regulari 6 with ? factor of 1.0, and within the sociology.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
document set 7 see ratnaparkhi (1997) and berger et al (1996) <papid> J96-1002 </papid>for formal description of these algorithms ties would perform well, both with our restricted lemma cluster and with our wider set of verbs and markers, our intuitions about improvement with more features (more positions to the right of left of the markers) or more controlled and grammatically restricted environment (a finite set of surrounding pos tags), turned out to be overly optimistic.</citsent>
<aftsection>
<nextsent>nevertheless, stochastic approaches that used short range features did perform very well, in line with the hand-coded approach.
</nextsent>
<nextsent>the results of the different algorithms, restricted to the lexeme call, are presented in table 1, while figures 1 and 2 present best results in the learning experiments for the complete set of patterns used in the collocation approach, over two of our evaluation corpora.
</nextsent>
<nextsent>type positions tags/ words features accuracy precision recall gismax 1 1254 0.97 0.96 0.98 iismax 1 136 0.95 0.96 0.94 iismax 1 1252 0.92 0.97 0.9 gismax 1 138 0.91 0.9 0.96 gismax 2 796 0.88 0.93 0.92 iismax 2 794 0.86 0.95 0.89 iismax 3 4290 0.87 0.85 0.98 gismax 3 4292 0.87 0.85 0.98 iismax 2 3186 0.86 0.87 0.95 gismax 2 3188 0.86 0.87 0.95 nb 1 136 0.88 0.97 0.84 nb 2 794 0.87 0.96 0.84 nb 3 4290 0.73 0.86 0.77 table 1.
</nextsent>
<nextsent>best metrics for call?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2244">
<title id=" P04-1068.xml">creating multilingual translation lexicons with regional variations using web corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the experimental results have shown the feasibility of the proposed approach inefficiently generating translation equivalents of various terms not covered by general translation dictionaries.
</prevsent>
<prevsent>it also revealed that the created translation lexicons can reflect different cultural aspects across regions such as taiwan, hongkong and mainland china.
</prevsent>
</prevsection>
<citsent citstr=" J90-2002 ">
compilation of translation lexicons is crucial process for machine translation (mt) (brown et al, 1990) <papid> J90-2002 </papid>and cross-language information retrieval (clir) systems (nie et al, 1999).</citsent>
<aftsection>
<nextsent>a lot of effort has been spent on constructing translation lexicons from do main-specific corpora in an automatic way (melamed, 2000; <papid> J00-2004 </papid>smadja et al, 1996; <papid> J96-1001 </papid>kupiec, 1993).<papid> P93-1003 </papid></nextsent>
<nextsent>however, such methods encounter two fundamental problems: translation of regional variations and the lack of up-to-date and high-lexical-coverage corpus source, which are worthy of further investigation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2245">
<title id=" P04-1068.xml">creating multilingual translation lexicons with regional variations using web corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it also revealed that the created translation lexicons can reflect different cultural aspects across regions such as taiwan, hongkong and mainland china.
</prevsent>
<prevsent>compilation of translation lexicons is crucial process for machine translation (mt) (brown et al, 1990) <papid> J90-2002 </papid>and cross-language information retrieval (clir) systems (nie et al, 1999).</prevsent>
</prevsection>
<citsent citstr=" J00-2004 ">
a lot of effort has been spent on constructing translation lexicons from do main-specific corpora in an automatic way (melamed, 2000; <papid> J00-2004 </papid>smadja et al, 1996; <papid> J96-1001 </papid>kupiec, 1993).<papid> P93-1003 </papid></citsent>
<aftsection>
<nextsent>however, such methods encounter two fundamental problems: translation of regional variations and the lack of up-to-date and high-lexical-coverage corpus source, which are worthy of further investigation.
</nextsent>
<nextsent>the first problem is resulted from the fact that the translations of term may have variations in different dialectal regions.
</nextsent>
<nextsent>translation lexicons constructed with conventional methods may not adapt to regional usages.
</nextsent>
<nextsent>for example, chinese-english lexicon constructed using hongkong corpus can not be directly adapted to the use in mainland china and taiwan.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2246">
<title id=" P04-1068.xml">creating multilingual translation lexicons with regional variations using web corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it also revealed that the created translation lexicons can reflect different cultural aspects across regions such as taiwan, hongkong and mainland china.
</prevsent>
<prevsent>compilation of translation lexicons is crucial process for machine translation (mt) (brown et al, 1990) <papid> J90-2002 </papid>and cross-language information retrieval (clir) systems (nie et al, 1999).</prevsent>
</prevsection>
<citsent citstr=" J96-1001 ">
a lot of effort has been spent on constructing translation lexicons from do main-specific corpora in an automatic way (melamed, 2000; <papid> J00-2004 </papid>smadja et al, 1996; <papid> J96-1001 </papid>kupiec, 1993).<papid> P93-1003 </papid></citsent>
<aftsection>
<nextsent>however, such methods encounter two fundamental problems: translation of regional variations and the lack of up-to-date and high-lexical-coverage corpus source, which are worthy of further investigation.
</nextsent>
<nextsent>the first problem is resulted from the fact that the translations of term may have variations in different dialectal regions.
</nextsent>
<nextsent>translation lexicons constructed with conventional methods may not adapt to regional usages.
</nextsent>
<nextsent>for example, chinese-english lexicon constructed using hongkong corpus can not be directly adapted to the use in mainland china and taiwan.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2247">
<title id=" P04-1068.xml">creating multilingual translation lexicons with regional variations using web corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it also revealed that the created translation lexicons can reflect different cultural aspects across regions such as taiwan, hongkong and mainland china.
</prevsent>
<prevsent>compilation of translation lexicons is crucial process for machine translation (mt) (brown et al, 1990) <papid> J90-2002 </papid>and cross-language information retrieval (clir) systems (nie et al, 1999).</prevsent>
</prevsection>
<citsent citstr=" P93-1003 ">
a lot of effort has been spent on constructing translation lexicons from do main-specific corpora in an automatic way (melamed, 2000; <papid> J00-2004 </papid>smadja et al, 1996; <papid> J96-1001 </papid>kupiec, 1993).<papid> P93-1003 </papid></citsent>
<aftsection>
<nextsent>however, such methods encounter two fundamental problems: translation of regional variations and the lack of up-to-date and high-lexical-coverage corpus source, which are worthy of further investigation.
</nextsent>
<nextsent>the first problem is resulted from the fact that the translations of term may have variations in different dialectal regions.
</nextsent>
<nextsent>translation lexicons constructed with conventional methods may not adapt to regional usages.
</nextsent>
<nextsent>for example, chinese-english lexicon constructed using hongkong corpus can not be directly adapted to the use in mainland china and taiwan.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2248">
<title id=" P04-1068.xml">creating multilingual translation lexicons with regional variations using web corpora </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in this section, we review some research in generating translation equivalents for automatic construction of translational lexicons.
</prevsent>
<prevsent>transitive translation: several transitive translation techniques have been developed to deal with the unreliable direct translation problem.
</prevsent>
</prevsection>
<citsent citstr=" C00-1015 ">
borin (2000) <papid> C00-1015 </papid>used various sources to improve the alignment of word translation and proposed the pivot alignment, which combined direct translation and indirect translation via third language.</citsent>
<aftsection>
<nextsent>gollins et al (2001) proposed feasible method that translated terms in parallel across multiple intermediate languages to eliminate errors.
</nextsent>
<nextsent>in addition, simard (2000) exploited the transitive properties of translations to improve the quality of multilingual text alignment.
</nextsent>
<nextsent>corpus-based translation: to automatically construct translation lexicons, conventional research in mt has generally used statistical techniques to extract translations from domain-specific sentence aligned parallel bilingual corpora.
</nextsent>
<nextsent>kupiec (1993) <papid> P93-1003 </papid>attempted to find noun phrase correspondences in parallel corpora using part-of-speech tagging and noun phrase recognition methods.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2252">
<title id=" P04-1068.xml">creating multilingual translation lexicons with regional variations using web corpora </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>some attention has been devoted to automatic extraction of term translations from comparable or even unrelated texts.
</prevsent>
<prevsent>such methods encounter more difficulties due to the lack of parallel correlations aligned between documents or sentence pairs.
</prevsent>
</prevsection>
<citsent citstr=" P99-1067 ">
rapp (1999) <papid> P99-1067 </papid>utilized non-parallel corpora based on the assumption that the contexts of term should be similar to the contexts of its translation in any language pairs.</citsent>
<aftsection>
<nextsent>fung et al (1998) also proposed similar approach that used vector-space model and took bilingual lexicon (called seed words) as feature set to estimate the similarity between word and its translation candidates.
</nextsent>
<nextsent>web-based translation: collecting parallel texts of different language versions from the web has recently received much attention (kilgarriff et al, 2003).
</nextsent>
<nextsent>nie et al (1999) tried to automatically discover parallel web documents.
</nextsent>
<nextsent>they assumed web pages parents might contain the links to different versions of it and web pages with the same content might have similar structures and lengths.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2253">
<title id=" P04-1068.xml">creating multilingual translation lexicons with regional variations using web corpora </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>nie et al (1999) tried to automatically discover parallel web documents.
</prevsent>
<prevsent>they assumed web pages parents might contain the links to different versions of it and web pages with the same content might have similar structures and lengths.
</prevsent>
</prevsection>
<citsent citstr=" P99-1068 ">
resnik (1999) <papid> P99-1068 </papid>addressed the issue of language identification for finding web pages in the languages of interest.</citsent>
<aftsection>
<nextsent>yang et al (2003) presented an alignment method to identify one-to-one chinese and english title pairs based on dynamic programming.
</nextsent>
<nextsent>these methods of ten require powerful crawlers to gather sufficient web data, as well as more network bandwidth and storage.
</nextsent>
<nextsent>on the other hand, cao et al (2002) used the web to examine if the arbitrary combination of translations of noun phrase was statistically important.
</nextsent>
<nextsent>to construct translation lexicons with regional variations, we propose transitive translation model strans(s,t) to estimate the degree of possibility of the translation of term in one (source) language ls into term in another (target) language lt. given the term in ls, we first extract set of terms c={tj}, where tj in lt acts as translation candidate of s, from corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2260">
<title id=" P01-1067.xml">a syntax based statistical translation model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the model produces word alignments that are better than those produced by ibm model 5.
</prevsent>
<prevsent>a statistical translation model (tm) is mathematical model in which the process of human language translation is statistically modeled.model parameters are automatically estimated using corpus of translation pairs.
</prevsent>
</prevsection>
<citsent citstr=" J00-2004 ">
tms have been used for statistical machine translation (berger etal., 1996), word alignment of translation corpus (melamed, 2000), <papid> J00-2004 </papid>multilingual document retrieval (franz et al, 1999), automatic dictionary construction (resnik and melamed, 1997), <papid> A97-1050 </papid>and data preparation for word sense disambiguation programs (brown et al, 1991).<papid> P91-1034 </papid></citsent>
<aftsection>
<nextsent>developing better tm is fundamental issue for those applica tions.researchers at ibm first described such statistical tm in (brown et al, 1988).<papid> C88-1016 </papid></nextsent>
<nextsent>their models are based on string-to-string noisy channel model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2261">
<title id=" P01-1067.xml">a syntax based statistical translation model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the model produces word alignments that are better than those produced by ibm model 5.
</prevsent>
<prevsent>a statistical translation model (tm) is mathematical model in which the process of human language translation is statistically modeled.model parameters are automatically estimated using corpus of translation pairs.
</prevsent>
</prevsection>
<citsent citstr=" A97-1050 ">
tms have been used for statistical machine translation (berger etal., 1996), word alignment of translation corpus (melamed, 2000), <papid> J00-2004 </papid>multilingual document retrieval (franz et al, 1999), automatic dictionary construction (resnik and melamed, 1997), <papid> A97-1050 </papid>and data preparation for word sense disambiguation programs (brown et al, 1991).<papid> P91-1034 </papid></citsent>
<aftsection>
<nextsent>developing better tm is fundamental issue for those applica tions.researchers at ibm first described such statistical tm in (brown et al, 1988).<papid> C88-1016 </papid></nextsent>
<nextsent>their models are based on string-to-string noisy channel model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2262">
<title id=" P01-1067.xml">a syntax based statistical translation model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the model produces word alignments that are better than those produced by ibm model 5.
</prevsent>
<prevsent>a statistical translation model (tm) is mathematical model in which the process of human language translation is statistically modeled.model parameters are automatically estimated using corpus of translation pairs.
</prevsent>
</prevsection>
<citsent citstr=" P91-1034 ">
tms have been used for statistical machine translation (berger etal., 1996), word alignment of translation corpus (melamed, 2000), <papid> J00-2004 </papid>multilingual document retrieval (franz et al, 1999), automatic dictionary construction (resnik and melamed, 1997), <papid> A97-1050 </papid>and data preparation for word sense disambiguation programs (brown et al, 1991).<papid> P91-1034 </papid></citsent>
<aftsection>
<nextsent>developing better tm is fundamental issue for those applica tions.researchers at ibm first described such statistical tm in (brown et al, 1988).<papid> C88-1016 </papid></nextsent>
<nextsent>their models are based on string-to-string noisy channel model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2263">
<title id=" P01-1067.xml">a syntax based statistical translation model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a statistical translation model (tm) is mathematical model in which the process of human language translation is statistically modeled.model parameters are automatically estimated using corpus of translation pairs.
</prevsent>
<prevsent>tms have been used for statistical machine translation (berger etal., 1996), word alignment of translation corpus (melamed, 2000), <papid> J00-2004 </papid>multilingual document retrieval (franz et al, 1999), automatic dictionary construction (resnik and melamed, 1997), <papid> A97-1050 </papid>and data preparation for word sense disambiguation programs (brown et al, 1991).<papid> P91-1034 </papid></prevsent>
</prevsection>
<citsent citstr=" C88-1016 ">
developing better tm is fundamental issue for those applica tions.researchers at ibm first described such statistical tm in (brown et al, 1988).<papid> C88-1016 </papid></citsent>
<aftsection>
<nextsent>their models are based on string-to-string noisy channel model.
</nextsent>
<nextsent>the channel converts sequence of words in one language (such as english) into another (such as french).
</nextsent>
<nextsent>the channel operations are movements, duplications, and translations, applied to each word independently.
</nextsent>
<nextsent>the movement is conditioned only on word classes and positions in the string, and the duplication and translation are conditioned only on the word identity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2264">
<title id=" P01-1067.xml">a syntax based statistical translation model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the channel operations are movements, duplications, and translations, applied to each word independently.
</prevsent>
<prevsent>the movement is conditioned only on word classes and positions in the string, and the duplication and translation are conditioned only on the word identity.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
mathematical details are fully described in (brown et al., 1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>one criticism of the ibm-style tm is that it does not model structural or syntactic aspects of the language.
</nextsent>
<nextsent>the tm was only demonstrated for structurally similar language pair (english and french).
</nextsent>
<nextsent>it has been suspected that language pair with very different word order such as english and japanese would not be modeled well by these tms.to incorporate structural aspects of the language, our channel model accepts parse tree as an input, i.e., the input sentence is preprocessed by syntactic parser.
</nextsent>
<nextsent>the channel performs operations on each node of the parse tree.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2265">
<title id=" P01-1067.xml">a syntax based statistical translation model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>therefore, parsing is only needed on the channel input side.
</prevsent>
<prevsent>the reorder operation is intended to model translation between languages with different word orders, such as svo-languages (english or chi nese) and sov-languages (japanese or turkish).the word-insertion operation is intended to capture linguistic differences in specifying syntacticcases.
</prevsent>
</prevsection>
<citsent citstr=" W99-0604 ">
e.g., english and french use structural position to specify case, while japanese and korean use case-marker particles.wang (1998) enhanced the ibm models by introducing phrases, and och et al (1999) <papid> W99-0604 </papid>used templates to capture phrasal sequences in sentence.</citsent>
<aftsection>
<nextsent>both also tried to incorporate structural aspects of the language, however, neither handles 1.
</nextsent>
<nextsent>channel input.
</nextsent>
<nextsent>3.
</nextsent>
<nextsent>inserted.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2266">
<title id=" P01-1067.xml">a syntax based statistical translation model </title>
<section> reordered.  </section>
<citcontext>
<prevsection>
<prevsent>translated.
</prevsent>
<prevsent>         ff  fi  fl ff fl ffi   ff !fi  vb prp vb1 vb2 vb to to nn vb vb2 to       vb1  ff  fi  fl ff fl ffi vb   prp   ff ! nn fi  to vb   # $ % &amp; #   ( ) * vb2 to vb  ff  fi  fl ff fl ffi       vb1   prp   ff ! nn fi  to vb   # $ % &amp; #   ( ) * vb2 to vb prp nn to vb1 + # , ( % $ &amp; # + * + - + *  # ) *+ . % figure 1: channel operations: reorder, insert, and translate nested structures.
</prevsent>
</prevsection>
<citsent citstr=" J97-3002 ">
wu (1997) <papid> J97-3002 </papid>and alshawi et al (2000) <papid> J00-1004 </papid>showed statistical models based on syntactic structure.the way we handle syntactic parse trees is inspired by their work, although their approach is not to model the translation process, but to formalize model that generates two languages at the same time.</citsent>
<aftsection>
<nextsent>our channel operations are also similar to the mechanism in twisted pair grammar (jones and havrilla, 1998) used in their knowledge-based system.
</nextsent>
<nextsent>following (brown et al, 1993) <papid> J93-2003 </papid>and the other literature in tm, this paper only focuses the details of tm.</nextsent>
<nextsent>applications of our tm, such as machine translation or dictionary construction, willbe described in separate paper.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2267">
<title id=" P01-1067.xml">a syntax based statistical translation model </title>
<section> reordered.  </section>
<citcontext>
<prevsection>
<prevsent>translated.
</prevsent>
<prevsent>         ff  fi  fl ff fl ffi   ff !fi  vb prp vb1 vb2 vb to to nn vb vb2 to       vb1  ff  fi  fl ff fl ffi vb   prp   ff ! nn fi  to vb   # $ % &amp; #   ( ) * vb2 to vb  ff  fi  fl ff fl ffi       vb1   prp   ff ! nn fi  to vb   # $ % &amp; #   ( ) * vb2 to vb prp nn to vb1 + # , ( % $ &amp; # + * + - + *  # ) *+ . % figure 1: channel operations: reorder, insert, and translate nested structures.
</prevsent>
</prevsection>
<citsent citstr=" J00-1004 ">
wu (1997) <papid> J97-3002 </papid>and alshawi et al (2000) <papid> J00-1004 </papid>showed statistical models based on syntactic structure.the way we handle syntactic parse trees is inspired by their work, although their approach is not to model the translation process, but to formalize model that generates two languages at the same time.</citsent>
<aftsection>
<nextsent>our channel operations are also similar to the mechanism in twisted pair grammar (jones and havrilla, 1998) used in their knowledge-based system.
</nextsent>
<nextsent>following (brown et al, 1993) <papid> J93-2003 </papid>and the other literature in tm, this paper only focuses the details of tm.</nextsent>
<nextsent>applications of our tm, such as machine translation or dictionary construction, willbe described in separate paper.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2271">
<title id=" P01-1067.xml">a syntax based statistical translation model </title>
<section> for each.  </section>
<citcontext>
<prevsection>
<prevsent>however, many rare words were used, which made the task difficult.
</prevsent>
<prevsent>the vocabulary size was 3463 tokens for english, and 3983 tokens for japanese, with 2029 tokens for english and 2507 tokens for japanese occurring only once in the corpus.
</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
brills part-of-speech (pos) tagger (brill, 1995) <papid> J95-4004 </papid>and collins?</citsent>
<aftsection>
<nextsent>parser (collins, 1999) were used to obtain parse trees for the english side of the corpus.
</nextsent>
<nextsent>the output of collins?
</nextsent>
<nextsent>parser was 3note that the algorithm performs full em counting,whereas the ibm models only permit counting over subset of possible alignments.
</nextsent>
<nextsent>modified in the following way.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2272">
<title id=" P01-1067.xml">a syntax based statistical translation model </title>
<section> for each.  </section>
<citcontext>
<prevsection>
<prevsent>an english svo structure is translated into sov in japanese, or into vso in arabic.these differences are easily modeled by the flattened subtree (nn1 vb nn2), rather than (nn1 (vb nn2)).
</prevsent>
<prevsent>we ran 20 iterations of the em algorithm as described in section 2.2.
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
ibm model 5 was sequentially boot strapped with model 1, an hmm model, and model 3 (och and ney, 2000).<papid> P00-1056 </papid></citsent>
<aftsection>
<nextsent>each preceding model and the final model 5 were trained with five iterations (total 20 iterations).
</nextsent>
<nextsent>3.2 evaluation.
</nextsent>
<nextsent>the training procedure resulted in the tables of estimated model parameters.
</nextsent>
<nextsent>table 1 in section 2.1 shows part of those parameters obtained by the training above.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2274">
<title id=" P02-1058.xml">from single to multi document summarization </title>
<section> neats.  </section>
<citcontext>
<prevsection>
<prevsent>computational linguistics (acl), philadelphia, july 2002, pp.
</prevsent>
<prevsent>457-464.
</prevsent>
</prevsection>
<citsent citstr=" J93-1003 ">
proceedings of the 40th annual meeting of the association for in key step for locating important sentences, neats computes the likelihood ratio (dunning, 1993) <papid> J93-1003 </papid>to identify key concepts in unigrams, bigrams, and trigrams1, using the on- topic document collection as the relevant set and the off-topic document collection as the irrelevant set.</citsent>
<aftsection>
<nextsent>figure 1 shows the top 5 concepts with their relevancy scores (-2l) for the topic slovenia secession from yugoslavia?
</nextsent>
<nextsent>in the duc-2001 test collection.
</nextsent>
<nextsent>this is similar to the idea of topic signature introduced in (lin and hovy 2000).<papid> C00-1072 </papid></nextsent>
<nextsent>with the individual key concepts available, we proceed to cluster these concepts in order to identify major sub topics within the main topic.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2275">
<title id=" P02-1058.xml">from single to multi document summarization </title>
<section> neats.  </section>
<citcontext>
<prevsection>
<prevsent>figure 1 shows the top 5 concepts with their relevancy scores (-2l) for the topic slovenia secession from yugoslavia?
</prevsent>
<prevsent>in the duc-2001 test collection.
</prevsent>
</prevsection>
<citsent citstr=" C00-1072 ">
this is similar to the idea of topic signature introduced in (lin and hovy 2000).<papid> C00-1072 </papid></citsent>
<aftsection>
<nextsent>with the individual key concepts available, we proceed to cluster these concepts in order to identify major sub topics within the main topic.
</nextsent>
<nextsent>clusters are formed through strict lexical connection.
</nextsent>
<nextsent>for example, milan and kucan are grouped as milan kucan?
</nextsent>
<nextsent>since milan kucan?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2276">
<title id=" P02-1058.xml">from single to multi document summarization </title>
<section> conclusions.  </section>
<citcontext>
<prevsection>
<prevsent>working with sub-sentence units should help.
</prevsent>
<prevsent>to improve neatss capability in content selection, we have started to parse sentences containing key unigram, bigram, and trigram concepts to identify their relations within their concept clusters.
</prevsent>
</prevsection>
<citsent citstr=" J98-3005 ">
to enhance cohesion and coherence, we are looking into incorporating discourse processing techniques (marcu 1999) or radev and mckeowns (1998) <papid> J98-3005 </papid>summary operators.</citsent>
<aftsection>
<nextsent>we are analyzing the duc evaluation scores in the hope of suggesting improved and more stable metrics.
</nextsent>



</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2277">
<title id=" P02-1049.xml">whats the problem automatically identifying problematic dialogues in darpa communicator dialogue systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as spoken dialogue system is developed, it is first tested as prototype, then fielded in limited setting, possibly running with human supervision (gorin et al, 1997), and finally deployed.
</prevsent>
<prevsent>at each stage from research prototype to deployed commercial application, the system is constantly undergoing further development.
</prevsent>
</prevsection>
<citsent citstr=" P01-1066 ">
when system is proto typed in house or first tested in the field, human subjects are often paid to use the system and give detailed feedback on task completion and user satisfaction (baggia et al, 1998; walker et al, 2001).<papid> P01-1066 </papid></citsent>
<aftsection>
<nextsent>even when system is deployed, it often keeps evolving, either because customers want to do different things with it, or because new tasks arise out of developments in the underlying application.
</nextsent>
<nextsent>however, real customers of deployed system may not be willing to give detailed feedback.
</nextsent>
<nextsent>thus, the widespread use of these systems has created data management and analysis problem.
</nextsent>
<nextsent>system designers need to constantly track system performance, identify problems, and fix them.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2282">
<title id=" P02-1049.xml">whats the problem automatically identifying problematic dialogues in darpa communicator dialogue systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>proceedings of the 40th annual meeting of the association for therefore, there is great need for methods for both automatically evaluating system performance, and for extracting subsets of dialogues that provide good training data for system improvement.
</prevsent>
<prevsent>this is difficult problem because by the time system is deployed, typically over 90% of the dialogue interactions result in completed tasks and satisfied users.dialogues such as these do not provide very useful training data for further system development be cause there is little to be learned when the dialogue goes well.
</prevsent>
</prevsection>
<citsent citstr=" P99-1040 ">
previous research on spoken dialogue evaluation proposed the application of automatic classifiers for identifying and predicting of problematic dialogues (litman et al, 1999; <papid> P99-1040 </papid>walker et al, 2002) for the purpose of automatically adapting the dialogue man ager.</citsent>
<aftsection>
<nextsent>here we apply similar methods to the dialogue corpus data-mining problem described above.
</nextsent>
<nextsent>we report results on automatically training problematic dialogue identifier (pdi) to classify problematic human-computer dialogues using the october 2001 darpa communicator corpus..
</nextsent>
<nextsent>section 2 describes our approach and the dialogue corpus.
</nextsent>
<nextsent>section 3 describes how we use the date dialogue act tagging scheme to define input features for the pdi.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2298">
<title id=" P02-1049.xml">whats the problem automatically identifying problematic dialogues in darpa communicator dialogue systems </title>
<section> extracting date features.  </section>
<citcontext>
<prevsection>
<prevsent>for the extension, we collected fresh set of vocabulary lists from the sites and augmented the pattern database with additional 800 labelled utterance patterns.
</prevsent>
<prevsent>we also implemented contextual rule-based post processor that takes any remaining un labelled utterances and attempts to label them by looking at their surrounding date labels.
</prevsent>
</prevsection>
<citsent citstr=" W02-0221 ">
more details about the extended tagger can be found in (prasad and walker, 2002).<papid> W02-0221 </papid></citsent>
<aftsection>
<nextsent>on the 2001 corpus, we were able to label 98.4
</nextsent>
<nextsent>of the data.
</nextsent>
<nextsent>a hand evaluation of 10 randomly selected dialogues from each system shows that we achieved classification accuracy of 96
</nextsent>
<nextsent>at the utterance level.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2299">
<title id=" P02-1049.xml">whats the problem automatically identifying problematic dialogues in darpa communicator dialogue systems </title>
<section> discussion and future developments.  </section>
<citcontext>
<prevsection>
<prevsent>this paper presented problematic dialogue identifier which system developers can use for evaluation and to extract problematic dialogues from large dataset for system development.
</prevsent>
<prevsent>we describe pdisfor predicting both task completion and user satisfaction in the darpa communicator october 2001 corpus.there has been little previous work on recognizing problematic dialogues.
</prevsent>
</prevsection>
<citsent citstr=" H01-1028 ">
however, number of studies have been done on predicting specific error sin dialogue, using variety of automatic and hand labelled features, such as asr confidence and semantic labels (aberdeen et al, 2001; <papid> H01-1028 </papid>hirschberg etal., 2000; levow, 1998; <papid> P98-1122 </papid>litman et al, 1999).<papid> P99-1040 </papid></citsent>
<aftsection>
<nextsent>previous work on predicting problematic dialogues before the end of the dialogue (walker et al, 2002)achieved accuracies of 87% using hand-labelled features (baseline 67%).
</nextsent>
<nextsent>our automatic task completion pdi achieves an accuracy of 85%.
</nextsent>
<nextsent>previous work also predicted user satisfaction by applying multi-variate linear regression features with and without date features and showed that date improved the model fit from     to  (walker et al, 2001).<papid> P01-1066 </papid></nextsent>
<nextsent>our best model has an   . one potential explanation for this difference is that the date features are most useful in combination with non-automatic features such as word accuracy which the previous study used.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2300">
<title id=" P02-1049.xml">whats the problem automatically identifying problematic dialogues in darpa communicator dialogue systems </title>
<section> discussion and future developments.  </section>
<citcontext>
<prevsection>
<prevsent>this paper presented problematic dialogue identifier which system developers can use for evaluation and to extract problematic dialogues from large dataset for system development.
</prevsent>
<prevsent>we describe pdisfor predicting both task completion and user satisfaction in the darpa communicator october 2001 corpus.there has been little previous work on recognizing problematic dialogues.
</prevsent>
</prevsection>
<citsent citstr=" P98-1122 ">
however, number of studies have been done on predicting specific error sin dialogue, using variety of automatic and hand labelled features, such as asr confidence and semantic labels (aberdeen et al, 2001; <papid> H01-1028 </papid>hirschberg etal., 2000; levow, 1998; <papid> P98-1122 </papid>litman et al, 1999).<papid> P99-1040 </papid></citsent>
<aftsection>
<nextsent>previous work on predicting problematic dialogues before the end of the dialogue (walker et al, 2002)achieved accuracies of 87% using hand-labelled features (baseline 67%).
</nextsent>
<nextsent>our automatic task completion pdi achieves an accuracy of 85%.
</nextsent>
<nextsent>previous work also predicted user satisfaction by applying multi-variate linear regression features with and without date features and showed that date improved the model fit from     to  (walker et al, 2001).<papid> P01-1066 </papid></nextsent>
<nextsent>our best model has an   . one potential explanation for this difference is that the date features are most useful in combination with non-automatic features such as word accuracy which the previous study used.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2307">
<title id=" P03-1018.xml">orthogonal negation in vector spaces for modelling word meanings and document retrieval </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as well as removing unwanted terms, this form of vector negation reduces the occurrence of synonyms and neighbours of the negated terms by as much as 76% compared with standard boolean methods.
</prevsent>
<prevsent>by altering the query vector itself, vector negation removes not only unwanted strings but unwanted meanings.
</prevsent>
</prevsection>
<citsent citstr=" N03-1036 ">
vector spaces enjoy widespread use in information retrieval (salton and mcgill, 1983; baeza-yates and this research was supported in part by the research collaboration between the ntt communication science laboratories, nippon telegraph and telephone corporation and csli, stanford university, and by ec/nsf grant ist-1999-11438 for the much more project.ribiero-neto, 1999), and from this original application vector models have been applied to semantic tasks such as word-sense acquisition (landauerand dumais, 1997; widdows, 2003) <papid> N03-1036 </papid>and disambiguation (schutze, 1998).</citsent>
<aftsection>
<nextsent>one benefit of these models is that the similarity between pairs of terms or between queries and documents is continuous function, automatically ranking results rather than giving just yes/no judgment.
</nextsent>
<nextsent>in addition, vector models can be freely built from un labelled text and so are both entirely unsupervised, and an accurate reflection of the way words are used in practice.
</nextsent>
<nextsent>in vector models, terms are usually combined to form more complicated query statements by (weighted) vector addition.
</nextsent>
<nextsent>because vector addition is commutative, terms are combined in bag of words?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2310">
<title id=" P03-1026.xml">a tabulation based parsing method that reduces copying </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it is thus of some theoretical interest in that it proves that at least constant bound is attainable within prologsetting.
</prevsent>
<prevsent>it does so by invoking new kind of grammar transformation, called efd-closure, which ensures that grammar need not match an empty category to the left most daughter of any rule.
</prevsent>
</prevsection>
<citsent citstr=" C94-2199 ">
this transformation is similar to many of the myriad of earlier transformations proposed for exploring the decidability of recognition under various parsing control strategies, but the property it establishes ismore conservative than brute-force epsilon elimination for unification-based grammars (dymetman, 1994).<papid> C94-2199 </papid></citsent>
<aftsection>
<nextsent>it also still treats empty categories distinctly from non-empty ones, unlike the linking tables proposed for treating left most daughters in left-corner parsing (pereira and shieber, 1987).
</nextsent>
<nextsent>its motivation, the practical consideration of copying overhead, is also rather different, of course.
</nextsent>
<nextsent>the algorithm will be presented as an improved version of ales parser, although other standard bottom-up parsers can be similarly adapted.
</nextsent>
<nextsent>apology!
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2311">
<title id=" P03-1026.xml">a tabulation based parsing method that reduces copying </title>
<section> theoretical benefits.  </section>
<citcontext>
<prevsection>
<prevsent>it is in fact only greedy approximation ? the optimization problem is exponential in the number of feature paths used for the check.penn (1999) cites an improvement of 15-40% simply by re-ordering the sister features of only two types in the signature of the ale hpsg grammar during normal unification.true indexing re-orders required operations with out repeating them.
</prevsent>
<prevsent>penn and popescu (1997) build an automaton-based index for surface realization with large lexica, and suggest an extension to statistically trained decision trees.
</prevsent>
</prevsection>
<citsent citstr=" C02-2024 ">
ninomiya et al (2002) <papid> C02-2024 </papid>take more computationally brute-force approach to index very large databases of feature structures forsome kind of information retrieval application.</citsent>
<aftsection>
<nextsent>neither of these is suitable for indexing chart edges during parsing, because the edges are discarded after every sentence, before the expense of building the index can be satisfactorily amortized.
</nextsent>
<nextsent>there is fair amount of relevant work in the database and programming language communities, but many of the results are negative (graf, 1996) ? very little time can be spent on constructing the index.
</nextsent>
<nextsent>a moments thought reveals that the very notion of an active edge, tabulating the well-formed prefixes of rule right-hand-sides, presumes that copying is not significant enough issue to merit the overhead of more specialized indexing.
</nextsent>
<nextsent>while the present paper proceeds from carpenters algorithm, in which no active edges are used, it will become clear from our evaluation that active edges or their equivalent within more sophisticated indexing strategy are an issue that should be re-investigatednow that the cost of copying can prov ably be reduced in prolog.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2312">
<title id=" P03-1026.xml">a tabulation based parsing method that reduces copying </title>
<section> termination properties.  </section>
<citcontext>
<prevsection>
<prevsent>we say that an extended context-free grammar, by which classical cfgs as well as unification-basedphrase-structure grammars are implied, is   -offline parse able (   -op) iff the empty string is not infinitely ambiguous in the grammar.
</prevsent>
<prevsent>every   -op grammar can be converted to weakly equivalent grammar which has the efd-closure property.
</prevsent>
</prevsection>
<citsent citstr=" C92-1057 ">
the proof of this statement, which establishes the correctness of the algorithm, is omitted for brevity.efd-closure bears some resemblance in its intentions to greibach normal form, but: (1) it is far more conservative in the number of extra rules itmust create; (2) it is linked directly to the deriv able empty categories of the grammar, whereas gnf conversion proceeds from an already   -eliminated grammar (efd-closure of any   -free grammar, in fact, is the grammar itself); (3) gnf is rather more difficult to define in the case of unification-based grammars than with classical cfgs, and in the one generalization we are aware of (dymetman, 1992), <papid> C92-1057 </papid>efd-closure is actually not guaranteed by it; anddymetmans generalization only works for classically offline-parseable grammars.</citsent>
<aftsection>
<nextsent>in the case of non-   -op grammars, standard bottom-up parser without efd-closure would not terminate at run-time either.
</nextsent>
<nextsent>our new algorithm isthus neither better nor worse than textbook bottom up parser with respect to termination.
</nextsent>
<nextsent>a remaining topic for consideration is the adaptation of this method to strategies with better termination properties than the pure bottom-up strategy.
</nextsent>
<nextsent>the details of how to integrate an indexing strategy for unification-based grammars into the efd-based parsing algorithm are too numerous to present here, but few empirical observations can be made.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2313">
<title id=" P04-1014.xml">parsing the wsj using ccg and loglinear models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also develop new efficient parsing algorithm for ccg which maximises expected recall of dependencies.
</prevsent>
<prevsent>we compare models which use all ccg derivations, including nonstandard derivations, with normal-form models.the performances of the two models are comparable and the results are competitive with existing wide-coverage ccg parsers.
</prevsent>
</prevsection>
<citsent citstr=" P02-1042 ">
a number of statistical parsing models have recently been developed for combinatory categorial grammar (ccg; steedman, 2000) and used in parsers applied to the wsj penn treebank (clark et al, 2002; <papid> P02-1042 </papid>hockenmaier and steedman, 2002; <papid> P02-1043 </papid>hockenmaier, 2003<papid> P03-1046 </papid>b).</citsent>
<aftsection>
<nextsent>in clark and curran (2003) <papid> W03-1013 </papid>we argued for the use of log-linear parsing models for ccg.however, estimating log-linear model for wide coverage ccg grammar is very computationally ex pensive.</nextsent>
<nextsent>following miyao and tsujii (2002), we showed how the estimation can be performed efficiently by applying the inside-outside algorithm to packed chart.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2314">
<title id=" P04-1014.xml">parsing the wsj using ccg and loglinear models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also develop new efficient parsing algorithm for ccg which maximises expected recall of dependencies.
</prevsent>
<prevsent>we compare models which use all ccg derivations, including nonstandard derivations, with normal-form models.the performances of the two models are comparable and the results are competitive with existing wide-coverage ccg parsers.
</prevsent>
</prevsection>
<citsent citstr=" P02-1043 ">
a number of statistical parsing models have recently been developed for combinatory categorial grammar (ccg; steedman, 2000) and used in parsers applied to the wsj penn treebank (clark et al, 2002; <papid> P02-1042 </papid>hockenmaier and steedman, 2002; <papid> P02-1043 </papid>hockenmaier, 2003<papid> P03-1046 </papid>b).</citsent>
<aftsection>
<nextsent>in clark and curran (2003) <papid> W03-1013 </papid>we argued for the use of log-linear parsing models for ccg.however, estimating log-linear model for wide coverage ccg grammar is very computationally ex pensive.</nextsent>
<nextsent>following miyao and tsujii (2002), we showed how the estimation can be performed efficiently by applying the inside-outside algorithm to packed chart.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2315">
<title id=" P04-1014.xml">parsing the wsj using ccg and loglinear models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also develop new efficient parsing algorithm for ccg which maximises expected recall of dependencies.
</prevsent>
<prevsent>we compare models which use all ccg derivations, including nonstandard derivations, with normal-form models.the performances of the two models are comparable and the results are competitive with existing wide-coverage ccg parsers.
</prevsent>
</prevsection>
<citsent citstr=" P03-1046 ">
a number of statistical parsing models have recently been developed for combinatory categorial grammar (ccg; steedman, 2000) and used in parsers applied to the wsj penn treebank (clark et al, 2002; <papid> P02-1042 </papid>hockenmaier and steedman, 2002; <papid> P02-1043 </papid>hockenmaier, 2003<papid> P03-1046 </papid>b).</citsent>
<aftsection>
<nextsent>in clark and curran (2003) <papid> W03-1013 </papid>we argued for the use of log-linear parsing models for ccg.however, estimating log-linear model for wide coverage ccg grammar is very computationally ex pensive.</nextsent>
<nextsent>following miyao and tsujii (2002), we showed how the estimation can be performed efficiently by applying the inside-outside algorithm to packed chart.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2317">
<title id=" P04-1014.xml">parsing the wsj using ccg and loglinear models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we compare models which use all ccg derivations, including nonstandard derivations, with normal-form models.the performances of the two models are comparable and the results are competitive with existing wide-coverage ccg parsers.
</prevsent>
<prevsent>a number of statistical parsing models have recently been developed for combinatory categorial grammar (ccg; steedman, 2000) and used in parsers applied to the wsj penn treebank (clark et al, 2002; <papid> P02-1042 </papid>hockenmaier and steedman, 2002; <papid> P02-1043 </papid>hockenmaier, 2003<papid> P03-1046 </papid>b).</prevsent>
</prevsection>
<citsent citstr=" W03-1013 ">
in clark and curran (2003) <papid> W03-1013 </papid>we argued for the use of log-linear parsing models for ccg.however, estimating log-linear model for wide coverage ccg grammar is very computationally ex pensive.</citsent>
<aftsection>
<nextsent>following miyao and tsujii (2002), we showed how the estimation can be performed efficiently by applying the inside-outside algorithm to packed chart.
</nextsent>
<nextsent>we also showed how the complete wsj penn treebank can be used for training by developing parallel version of generalised iterative scaling (gis) to perform the estimation.
</nextsent>
<nextsent>this paper significantly extends our earlier work in number of ways.
</nextsent>
<nextsent>first, we evaluate number of log-linear models, obtaining results which are competitive with the state-of-the-art for ccg parsing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2329">
<title id=" P04-1014.xml">parsing the wsj using ccg and loglinear models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also compare log-linear models which useall ccg derivations, including non-standard derivations, with normal-form models.
</prevsent>
<prevsent>second, we find that gis is unsuitable for estimating model of thesize being considered, and develop parallel version of the l-bfgs algorithm (nocedal and wright,1999).
</prevsent>
</prevsection>
<citsent citstr=" P96-1024 ">
and finally, we show that the parsing algorithm described in clark and curran (2003) <papid> W03-1013 </papid>is extremely slow in some cases, and suggest an efficient alternative based on goodman (1996).<papid> P96-1024 </papid>the development of parsing and estimation algorithms for models which use all derivations extends existing ccg parsing techniques, and allows us totest whether there is useful information in the additional derivations.</citsent>
<aftsection>
<nextsent>however, we find that the performance of the normal-form model is at least as goodas the all-derivations model, in our experiments to date.
</nextsent>
<nextsent>the normal-form approach allows the use of additional constraints on rule applications, leading to smaller model, reducing the computational resources required for estimation, and resulting in an extremely efficient parser.
</nextsent>
<nextsent>this paper assumes basic understanding of ccg; see steedman (2000) for an introduction, and clark et al (2002) <papid> P02-1042 </papid>and hockenmaier (2003<papid> P03-1046 </papid>a) for an introduction to statistical parsing with ccg.</nextsent>
<nextsent>ccg is unusual among grammar formalisms in that, for each derived structure for sentence, there can be many derivations leading to that structure.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2345">
<title id=" P04-1014.xml">parsing the wsj using ccg and loglinear models </title>
<section> parsing models for ccg.  </section>
<citcontext>
<prevsection>
<prevsent>the presence of such ambiguity, sometimes referred toas spurious ambiguity, enables ccg to produce elegant analyses of coordination and extraction phenomena (steedman, 2000).
</prevsent>
<prevsent>however, the introduction of extra derivations increases the complexity of the modelling and parsing problem.clark et al (2002) <papid> P02-1042 </papid>handle the additional derivations by modelling the derived structure, in their case dependency structures.</prevsent>
</prevsection>
<citsent citstr=" P96-1025 ">
they use conditional model, based on collins (1996), <papid> P96-1025 </papid>which, as the authors acknowledge, has number of theoretical de ficiencies; thus the results of clark et al provide useful baseline for the new models presented here.</citsent>
<aftsection>
<nextsent>hockenmaier (2003<papid> P03-1046 </papid>a) uses model which favours only one of the derivations leading to aderived structure, namely the normal-form derivation (eisner, 1996).<papid> P96-1011 </papid></nextsent>
<nextsent>in this paper we compare the normal-form approach with dependency model.for the dependency model, we define the probability of dependency structure as follows: p(pi|s ) = ? d??(pi) p(d, pi|s ) (1) where pi is dependency structure, is sentence and ?(pi) is the set of derivations which lead to pi.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2349">
<title id=" P04-1014.xml">parsing the wsj using ccg and loglinear models </title>
<section> parsing models for ccg.  </section>
<citcontext>
<prevsection>
<prevsent>however, the introduction of extra derivations increases the complexity of the modelling and parsing problem.clark et al (2002) <papid> P02-1042 </papid>handle the additional derivations by modelling the derived structure, in their case dependency structures.</prevsent>
<prevsent>they use conditional model, based on collins (1996), <papid> P96-1025 </papid>which, as the authors acknowledge, has number of theoretical de ficiencies; thus the results of clark et al provide useful baseline for the new models presented here.</prevsent>
</prevsection>
<citsent citstr=" P96-1011 ">
hockenmaier (2003<papid> P03-1046 </papid>a) uses model which favours only one of the derivations leading to aderived structure, namely the normal-form derivation (eisner, 1996).<papid> P96-1011 </papid></citsent>
<aftsection>
<nextsent>in this paper we compare the normal-form approach with dependency model.for the dependency model, we define the probability of dependency structure as follows: p(pi|s ) = ? d??(pi) p(d, pi|s ) (1) where pi is dependency structure, is sentence and ?(pi) is the set of derivations which lead to pi.
</nextsent>
<nextsent>this extends the approach of clark et al (2002) <papid> P02-1042 </papid>who modelled the dependency structures directly, not using any information from the derivations.</nextsent>
<nextsent>in contrast to the dependency model, the normal-formmodel simply defines distribution over normal form derivations.the dependency structures considered in this paper are described in detail in clark et al (2002) <papid> P02-1042 </papid>and clark and curran (2003).<papid> W03-1013 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2365">
<title id=" P04-1014.xml">parsing the wsj using ccg and loglinear models </title>
<section> log-linear parsing models.  </section>
<citcontext>
<prevsection>
<prevsent>a dependency structure is multi set of these dependencies.
</prevsent>
<prevsent>log-linear models (also known as maximum entropy models) are popular in nlp because of theease with which discriminating features can be included in the model.
</prevsent>
</prevsection>
<citsent citstr=" P02-1035 ">
log-linear models have been applied to the parsing problem across range of grammar formalisms, e.g. riezler et al (2002) <papid> P02-1035 </papid>and toutanova et al (2002).</citsent>
<aftsection>
<nextsent>one motivation for using log-linear model is that long-range dependencies which ccg was designed to handle can easily be encoded as features.
</nextsent>
<nextsent>a conditional log-linear model of parse ? ?
</nextsent>
<nextsent>?, given sentence , is defined as follows: p(?|s ) = 1 zs e?.
</nextsent>
<nextsent>f (?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2371">
<title id=" P04-1014.xml">parsing the wsj using ccg and loglinear models </title>
<section> log-linear parsing models.  </section>
<citcontext>
<prevsection>
<prevsent>f (?)
</prevsent>
<prevsent>i 2ithe first two terms in (5) are expectations of feature fi: the first expectation is over all derivations leading to each gold standard dependency structure; the second is over all derivations for each sentence in the training data.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
setting the gradient to zero yields the usual maximum entropy constraints (berger et al, 1996), <papid> J96-1002 </papid>except that in this case the empirical values are themselves expectations (overall derivations leading to each gold standard dependency structure).</citsent>
<aftsection>
<nextsent>the estimation process attempts to make the expectations equal, by putting as much mass as possible on the derivations leading to the gold standard structures.1 the gaussian prior term penalises any model whose weights get too large in absolute value.
</nextsent>
<nextsent>calculation of the feature expectations requires summing over all derivations for sentence, and summing over all derivations leading to gold standard dependency structure.
</nextsent>
<nextsent>in both cases there canbe exponentially many derivations, and so enumerating all derivations is not possible (at least for wide-coverage automatically extracted grammars).
</nextsent>
<nextsent>clark and curran (2003) <papid> W03-1013 </papid>show how the sum overthe complete derivation space can be performed efficiently using packed chart and variant of the inside-outside algorithm.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2389">
<title id=" P04-1014.xml">parsing the wsj using ccg and loglinear models </title>
<section> estimation in practice.  </section>
<citcontext>
<prevsection>
<prevsent>not all rule instantiations in ccg bank are instances of combinatory rules, and not all can be produced by the parser, and so gold standard structures were created for 85.5% of the sentences in sections 2-21 (33,777 sentences).
</prevsent>
<prevsent>the same parser is used to produce the packedcharts.
</prevsent>
</prevsection>
<citsent citstr=" C04-1041 ">
the parser uses maximum entropy su per tagger (clark and curran, 2004) <papid> C04-1041 </papid>to assign lexical categories to the words in sentence, and applies the cky chart parsing algorithm described in steedman (2000).</citsent>
<aftsection>
<nextsent>for parsing the training data, we ensure that the correct category is member of the set assigned to each word.
</nextsent>
<nextsent>the average number of categories assigned to each word is determined by parameter in the supertagger.
</nextsent>
<nextsent>for the first set of experiments, we used setting which assigns 1.7 categories on average per word.the feature set for the dependency model consists of the following types of features: dependency features (with and without distance measures), rule instantiation features (with and without lexical head), lexical category features, and root categoryfeatures.
</nextsent>
<nextsent>dependency features are the 5-tuples defined in section 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2400">
<title id=" P04-1014.xml">parsing the wsj using ccg and loglinear models </title>
<section> estimation in practice.  </section>
<citcontext>
<prevsection>
<prevsent>the normal-form model requires only 5 machines for estimation, with an average memory usage of 730 mb for each machine..
</prevsent>
<prevsent>initially we tried the parallel version of gis described in clark and curran (2003) <papid> W03-1013 </papid>to perform the estimation, running over the beowulf cluster.</prevsent>
</prevsection>
<citsent citstr=" N03-1028 ">
however, we found that gis converged extremely slowly; this is in line with other recent results in the literature applying gis to globally optimised models such as conditional random fields, e.g. sha and pereira (2003).<papid> N03-1028 </papid></citsent>
<aftsection>
<nextsent>as an alternative to gis, we have implemented parallel version of our l-bfgs code using the message passing interface (mpi) standard.
</nextsent>
<nextsent>l-bfgs over forests can be parallel ised, using the method described in clark and curran (2003) <papid> W03-1013 </papid>to calculate the feature expectations.</nextsent>
<nextsent>the l-bfgs algorithm, run to convergence on the cluster, takes 479 iterations and 2 hours for the normal-form model, and 1,550 iterations and roughly 17 hours for the dependency model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2420">
<title id=" P04-1014.xml">parsing the wsj using ccg and loglinear models </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>table 2 gives the results for the normal-form model for various feature sets.
</prevsent>
<prevsent>the results show that each additional feature type increases perfor lp lr up ur cat clark et al 2002 <papid> P02-1042 </papid>81.9 81.8 90.1 89.9 90.3 hockenmaier 2003 <papid> P03-1046 </papid>84.3 84.6 91.8 92.2 92.2 log-linear 86.6 86.3 92.5 92.1 93.6 hockenmaier(pos) 83.1 83.5 91.1 91.5 91.5 log-linear (pos) 84.8 84.5 91.4 91.0 92.5 table 3: results on the test set mance.</prevsent>
</prevsection>
<citsent citstr=" W01-0521 ">
hockenmaier also found the dependencies to be very beneficial ? in contrast to recent results from the lexicalised pcfg parsing literature (gildea, 2001) ? <papid> W01-0521 </papid>but did not gain from the use of distance measures.</citsent>
<aftsection>
<nextsent>one of the advantages of log-linearmodel is that it is easy to include additional information, such as distance, as features.the final result in table 2 is obtained by using larger derivation space for training, created using more categories per word from the super tag ger, 2.9, and hence using charts containing more derivations.
</nextsent>
<nextsent>(15 machines were used to estimate thismodel.)
</nextsent>
<nextsent>more investigation is needed to find the optimal chart size for estimation, but the results show gain inaccuracy.
</nextsent>
<nextsent>table 3 gives the results of the best performing normal-form model on the test set.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2430">
<title id=" P04-1014.xml">parsing the wsj using ccg and loglinear models </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>our test set against hockenmaiers gives an f-score of over 97%, showing the test sets to be very similar.
</prevsent>
<prevsent>the results show that our parser is performing significantly better than that of clark et al, demonstrating the benefit of derivation features and the use of sound statistical model.the results given so far have all used gold standard pos tags from ccgbank.
</prevsent>
</prevsection>
<citsent citstr=" E03-1071 ">
table 3 also gives the results if automatically assigned pos tags are used in the training and testing phases, using the c&cpos; tagger (curran and clark, 2003).<papid> E03-1071 </papid></citsent>
<aftsection>
<nextsent>the performance reduction is expected given that the super tag ger relies heavily on pos tags as features.more investigation is needed to properly compare our parser and hockenmaiers, since there are number of differences in addition to the models used: hockenmaier effectively reads lexicalised pcfg off ccgbank, and is able to use all of the available training data; hockenmaier does not use super tagger, but does use beam search.
</nextsent>
<nextsent>parsing the 2,401 sentences in section 23 takes 1.6 minutes using the normal-form model, and 10.5minutes using the dependency model.
</nextsent>
<nextsent>the difference is due largely to the normal-form constraints used by the normal-form parser.
</nextsent>
<nextsent>clark and curran(2004) <papid> C04-1041 </papid>shows that the normal-form constraints significantly increase parsing speed and, in combination with adaptive super tagging, result in highly efficient wide-coverage parser.as final oracle experiment we parsed the sentences in section 00 using the correct lexical categories from ccgbank.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2438">
<title id=" P02-1061.xml">teaching a weaker classifier named entity recognition on upper case text </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>machine learning methods such as bbns identifinder (bikel, schwartz, and weischedel, 1999) and borthwicks mene (borth wick, 1999) have shown that machine learning ners can achieve comparable performance with systems using hand-coded rules.
</prevsent>
<prevsent>bikel, schwartz, and weischedel (1999) have also shown how mixed case text can be automatically converted to upper case snor or ocr format to train ners to workon such formats.
</prevsent>
</prevsection>
<citsent citstr=" W99-0613 ">
there is also some work on unsupervised learning for mixed case named entity recognition (collins and singer, 1999; <papid> W99-0613 </papid>cucerzan and yarowsky, 1999).<papid> W99-0612 </papid></citsent>
<aftsection>
<nextsent>collins and singer (1999)<papid> W99-0613 </papid>investigated named entity classification using ad aboost, coboost, and the em algorithm.</nextsent>
<nextsent>however,features were extracted using parser, and performance was evaluated differently (the classes were person, organization, location, and noise).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2439">
<title id=" P02-1061.xml">teaching a weaker classifier named entity recognition on upper case text </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>machine learning methods such as bbns identifinder (bikel, schwartz, and weischedel, 1999) and borthwicks mene (borth wick, 1999) have shown that machine learning ners can achieve comparable performance with systems using hand-coded rules.
</prevsent>
<prevsent>bikel, schwartz, and weischedel (1999) have also shown how mixed case text can be automatically converted to upper case snor or ocr format to train ners to workon such formats.
</prevsent>
</prevsection>
<citsent citstr=" W99-0612 ">
there is also some work on unsupervised learning for mixed case named entity recognition (collins and singer, 1999; <papid> W99-0613 </papid>cucerzan and yarowsky, 1999).<papid> W99-0612 </papid></citsent>
<aftsection>
<nextsent>collins and singer (1999)<papid> W99-0613 </papid>investigated named entity classification using ad aboost, coboost, and the em algorithm.</nextsent>
<nextsent>however,features were extracted using parser, and performance was evaluated differently (the classes were person, organization, location, and noise).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2443">
<title id=" P02-1061.xml">teaching a weaker classifier named entity recognition on upper case text </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>we suspect that it will be hard for purely unsupervised methods to perform as well as supervised ones.
</prevsent>
<prevsent>seeger (2001) gave comprehensive summary of recent work in learning with labeled and unlabeled data.
</prevsent>
</prevsection>
<citsent citstr=" W01-0501 ">
there is much recent research on co-training, such as (blum and mitchell, 1998; collins and singer, 1999; <papid> W99-0613 </papid>pierce and cardie, 2001).<papid> W01-0501 </papid></citsent>
<aftsection>
<nextsent>most co training methods involve using two classifiers built on different sets of features.
</nextsent>
<nextsent>instead of using distinct sets of features, goldman and zhou (2000) used different classification algorithms to do co-training.
</nextsent>
<nextsent>blum and mitchell (1998) showed that in order for pac-like guarantees to hold for co-training, features should be divided into two disjoint sets satis fying: (1) each set is sufficient for classifier to learn concept correctly; and (2) the two sets are conditionally independent of each other.
</nextsent>
<nextsent>each set of features can be used to build classifier, resulting in two independent classifiers, and b. classifications by on unlabeled data can then be used to further train classifier b, and vice versa.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2444">
<title id=" P04-1075.xml">multicriteriabased active learning for named entity recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the machine learning approaches of natural language processing (nlp), models are generally trained on large annotated corpus.
</prevsent>
<prevsent>however, annotating such corpus is expensive and time consuming, which makes it difficult to adapt an existing model to new domain.
</prevsent>
</prevsection>
<citsent citstr=" P02-1016 ">
in order to overcome this difficulty, active learning (sample selec tion) has been studied in more and more nlp applications such as pos tagging (engelson and dagan 1999), information extraction (thompson et al. 1999), text classification (lewis and catlett 1994; mccallum and nigam 1998; schohn and cohn 2000; tong and koller 2000; brinker 2003), statistical parsing (thompson et al 1999; tang et al. 2002; <papid> P02-1016 </papid>steedman et al 2003), <papid> N03-1031 </papid>noun phrase chunking (ngai and yarowsky 2000), <papid> P00-1016 </papid>etc. active learning is based on the assumption that small number of annotated examples and large number of unannotated examples are available.</citsent>
<aftsection>
<nextsent>this assumption is valid in most nlp tasks.
</nextsent>
<nextsent>different from supervised learning in which the entire corpus are labeled manually, active learning is to select the most useful example for labeling and add the labeled example to training set to retrain model.
</nextsent>
<nextsent>this procedure is repeated until the model achieves certain level of performance.
</nextsent>
<nextsent>practically, batch of examples are selected at time, called batched based sample selection (lewis and catlett 1994) since it is time consuming to retrain the model if only one new example is added to the training set.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2445">
<title id=" P04-1075.xml">multicriteriabased active learning for named entity recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the machine learning approaches of natural language processing (nlp), models are generally trained on large annotated corpus.
</prevsent>
<prevsent>however, annotating such corpus is expensive and time consuming, which makes it difficult to adapt an existing model to new domain.
</prevsent>
</prevsection>
<citsent citstr=" N03-1031 ">
in order to overcome this difficulty, active learning (sample selec tion) has been studied in more and more nlp applications such as pos tagging (engelson and dagan 1999), information extraction (thompson et al. 1999), text classification (lewis and catlett 1994; mccallum and nigam 1998; schohn and cohn 2000; tong and koller 2000; brinker 2003), statistical parsing (thompson et al 1999; tang et al. 2002; <papid> P02-1016 </papid>steedman et al 2003), <papid> N03-1031 </papid>noun phrase chunking (ngai and yarowsky 2000), <papid> P00-1016 </papid>etc. active learning is based on the assumption that small number of annotated examples and large number of unannotated examples are available.</citsent>
<aftsection>
<nextsent>this assumption is valid in most nlp tasks.
</nextsent>
<nextsent>different from supervised learning in which the entire corpus are labeled manually, active learning is to select the most useful example for labeling and add the labeled example to training set to retrain model.
</nextsent>
<nextsent>this procedure is repeated until the model achieves certain level of performance.
</nextsent>
<nextsent>practically, batch of examples are selected at time, called batched based sample selection (lewis and catlett 1994) since it is time consuming to retrain the model if only one new example is added to the training set.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2446">
<title id=" P04-1075.xml">multicriteriabased active learning for named entity recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the machine learning approaches of natural language processing (nlp), models are generally trained on large annotated corpus.
</prevsent>
<prevsent>however, annotating such corpus is expensive and time consuming, which makes it difficult to adapt an existing model to new domain.
</prevsent>
</prevsection>
<citsent citstr=" P00-1016 ">
in order to overcome this difficulty, active learning (sample selec tion) has been studied in more and more nlp applications such as pos tagging (engelson and dagan 1999), information extraction (thompson et al. 1999), text classification (lewis and catlett 1994; mccallum and nigam 1998; schohn and cohn 2000; tong and koller 2000; brinker 2003), statistical parsing (thompson et al 1999; tang et al. 2002; <papid> P02-1016 </papid>steedman et al 2003), <papid> N03-1031 </papid>noun phrase chunking (ngai and yarowsky 2000), <papid> P00-1016 </papid>etc. active learning is based on the assumption that small number of annotated examples and large number of unannotated examples are available.</citsent>
<aftsection>
<nextsent>this assumption is valid in most nlp tasks.
</nextsent>
<nextsent>different from supervised learning in which the entire corpus are labeled manually, active learning is to select the most useful example for labeling and add the labeled example to training set to retrain model.
</nextsent>
<nextsent>this procedure is repeated until the model achieves certain level of performance.
</nextsent>
<nextsent>practically, batch of examples are selected at time, called batched based sample selection (lewis and catlett 1994) since it is time consuming to retrain the model if only one new example is added to the training set.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2449">
<title id=" P04-1075.xml">multicriteriabased active learning for named entity recognition </title>
<section> multi-criteria for ner active learning.  </section>
<citcontext>
<prevsection>
<prevsent>to our knowledge, it is the first work on considering the three criteria all together for active learning.
</prevsent>
<prevsent>furthermore, such measures and strategies can be easily adapted to other active learning tasks as well.
</prevsent>
</prevsection>
<citsent citstr=" W02-0301 ">
support vector machines (svm) is powerful machine learning method, which has been applied successfully inner tasks, such as (kazama et al 2002; <papid> W02-0301 </papid>lee et al 2003).<papid> W03-1305 </papid></citsent>
<aftsection>
<nextsent>in this paper, we apply active learning methods to simple and effective svm model to recognize one class of names at time, such as protein names, person names, etc. inner, svm is to classify word into positive class 1?
</nextsent>
<nextsent>indicating that the word is part of an entity, or negative class ?-1?
</nextsent>
<nextsent>indicating that the word is not part of an entity.
</nextsent>
<nextsent>each word in svm is represented as high-dimensional feature vector including surface word information, orthographic features, pos feature and semantic trigger features (shen et al 2003).<papid> W03-1307 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2450">
<title id=" P04-1075.xml">multicriteriabased active learning for named entity recognition </title>
<section> multi-criteria for ner active learning.  </section>
<citcontext>
<prevsection>
<prevsent>to our knowledge, it is the first work on considering the three criteria all together for active learning.
</prevsent>
<prevsent>furthermore, such measures and strategies can be easily adapted to other active learning tasks as well.
</prevsent>
</prevsection>
<citsent citstr=" W03-1305 ">
support vector machines (svm) is powerful machine learning method, which has been applied successfully inner tasks, such as (kazama et al 2002; <papid> W02-0301 </papid>lee et al 2003).<papid> W03-1305 </papid></citsent>
<aftsection>
<nextsent>in this paper, we apply active learning methods to simple and effective svm model to recognize one class of names at time, such as protein names, person names, etc. inner, svm is to classify word into positive class 1?
</nextsent>
<nextsent>indicating that the word is part of an entity, or negative class ?-1?
</nextsent>
<nextsent>indicating that the word is not part of an entity.
</nextsent>
<nextsent>each word in svm is represented as high-dimensional feature vector including surface word information, orthographic features, pos feature and semantic trigger features (shen et al 2003).<papid> W03-1307 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2451">
<title id=" P04-1075.xml">multicriteriabased active learning for named entity recognition </title>
<section> multi-criteria for ner active learning.  </section>
<citcontext>
<prevsection>
<prevsent>indicating that the word is part of an entity, or negative class ?-1?
</prevsent>
<prevsent>indicating that the word is not part of an entity.
</prevsent>
</prevsection>
<citsent citstr=" W03-1307 ">
each word in svm is represented as high-dimensional feature vector including surface word information, orthographic features, pos feature and semantic trigger features (shen et al 2003).<papid> W03-1307 </papid></citsent>
<aftsection>
<nextsent>the semantic trigger features consist of some special head nouns for an entity class which is supplied by users.
</nextsent>
<nextsent>furthermore, window (size = 7), which represents the local context of the target word w, is also used to classify w. however, for active learning inner, it is not reasonable to select single word without context for human to label.
</nextsent>
<nextsent>even if we require human to label single word, he has to make an addition effort to refer to the context of the word.
</nextsent>
<nextsent>in our active learning process, we select word sequence which consists of machine-annotated named entity and its context rather than single word.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2464">
<title id=" P04-3004.xml">sub sentential translation memory for computer assisted writing and translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for instance, the english-french concordance system, trans search provides familiar interface for the users (macklovitch et al  2000).
</prevsent>
<prevsent>the user type in the expression in question, list of citations will come up and it is easy to scroll down until one finds translation that is useful much like using search engine.
</prevsent>
</prevsection>
<citsent citstr=" J90-2002 ">
trans search exploits sentence alignment techniques (brown et al 1990; <papid> J90-2002 </papid>gale and church 1990) to facilitate bilingual search at the granularity level of sentences.</citsent>
<aftsection>
<nextsent>in this paper, we describe bilingual concordancer which facilitate search and visualization with fine granularity.
</nextsent>
<nextsent>total recall exploits sub sentential and word alignment to provide new kind of bilingual concordancer.
</nextsent>
<nextsent>through the interactive interface and clustering of short sub sentential bi-lingual citations, it helps translators and non-native speakers find ways to translate or express them-selves in foreign language.
</nextsent>
<nextsent>central to total recall is bilingual corpus and set of programs that provide the bilingual analyses to yield translation memory database out of the bilingual corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2465">
<title id=" P04-3004.xml">sub sentential translation memory for computer assisted writing and translation </title>
<section> aligning the corpus.  </section>
<citcontext>
<prevsection>
<prevsent>2.2 word and collocation alignment.
</prevsent>
<prevsent>after sentences and their translation counterparts are identified, we proceeded to carry out finer grained alignment on the word level.
</prevsent>
</prevsection>
<citsent citstr=" J00-2004 ">
we employed the competitive linking algorithm (melamed 2000) <papid> J00-2004 </papid>produce high precision word alignment.</citsent>
<aftsection>
<nextsent>we also extract english collocations and their translation equivalent based on the result of word alignment.
</nextsent>
<nextsent>these alignment results were subsequently used to cluster citations and highlight translation equivalents of the query.
</nextsent>
<nextsent>total recall allows user to look for instances of specific words or expressions and its translation counterpart.
</nextsent>
<nextsent>for this purpose, the system opens up two text boxes for the user to enter queries in any or both of the two languages involved.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2466">
<title id=" P02-1017.xml">a generative constituent context model for improved grammar induction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we compare distributionally induced and actual part-of-speech tags as input data,and examine extensions to the basic model.
</prevsent>
<prevsent>we discuss errors made by the system, compare the system to previous models, and discuss upper bounds, lower bounds, and stability for this task.
</prevsent>
</prevsection>
<citsent citstr=" P92-1017 ">
the task of inducing hierarchical syntactic structure from observed yields alone has received great deal of attention (carroll and charniak, 1992; pereira and schabes, 1992; <papid> P92-1017 </papid>brill, 1993; <papid> P93-1035 </papid>stolcke and omohun dro, 1994).</citsent>
<aftsection>
<nextsent>researchers have explored this problem for variety of reasons: to argue empirically against the poverty of the stimulus (clark, 2001), <papid> W01-0713 </papid>to use induction systems as first stage in constructing large treebanks (van zaanen, 2000), or to build better language models (baker, 1979; chen, 1995).<papid> P95-1031 </papid></nextsent>
<nextsent>in previous work, we presented conditional model over trees which gave the best published results for unsupervised parsing of the atis corpus (klein and manning, 2001<papid> W01-0714 </papid>b).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2467">
<title id=" P02-1017.xml">a generative constituent context model for improved grammar induction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we compare distributionally induced and actual part-of-speech tags as input data,and examine extensions to the basic model.
</prevsent>
<prevsent>we discuss errors made by the system, compare the system to previous models, and discuss upper bounds, lower bounds, and stability for this task.
</prevsent>
</prevsection>
<citsent citstr=" P93-1035 ">
the task of inducing hierarchical syntactic structure from observed yields alone has received great deal of attention (carroll and charniak, 1992; pereira and schabes, 1992; <papid> P92-1017 </papid>brill, 1993; <papid> P93-1035 </papid>stolcke and omohun dro, 1994).</citsent>
<aftsection>
<nextsent>researchers have explored this problem for variety of reasons: to argue empirically against the poverty of the stimulus (clark, 2001), <papid> W01-0713 </papid>to use induction systems as first stage in constructing large treebanks (van zaanen, 2000), or to build better language models (baker, 1979; chen, 1995).<papid> P95-1031 </papid></nextsent>
<nextsent>in previous work, we presented conditional model over trees which gave the best published results for unsupervised parsing of the atis corpus (klein and manning, 2001<papid> W01-0714 </papid>b).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2468">
<title id=" P02-1017.xml">a generative constituent context model for improved grammar induction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we discuss errors made by the system, compare the system to previous models, and discuss upper bounds, lower bounds, and stability for this task.
</prevsent>
<prevsent>the task of inducing hierarchical syntactic structure from observed yields alone has received great deal of attention (carroll and charniak, 1992; pereira and schabes, 1992; <papid> P92-1017 </papid>brill, 1993; <papid> P93-1035 </papid>stolcke and omohun dro, 1994).</prevsent>
</prevsection>
<citsent citstr=" W01-0713 ">
researchers have explored this problem for variety of reasons: to argue empirically against the poverty of the stimulus (clark, 2001), <papid> W01-0713 </papid>to use induction systems as first stage in constructing large treebanks (van zaanen, 2000), or to build better language models (baker, 1979; chen, 1995).<papid> P95-1031 </papid></citsent>
<aftsection>
<nextsent>in previous work, we presented conditional model over trees which gave the best published results for unsupervised parsing of the atis corpus (klein and manning, 2001<papid> W01-0714 </papid>b).</nextsent>
<nextsent>however, it suffered from several drawbacks, primarily stemming from the conditional model used for induction.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2470">
<title id=" P02-1017.xml">a generative constituent context model for improved grammar induction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we discuss errors made by the system, compare the system to previous models, and discuss upper bounds, lower bounds, and stability for this task.
</prevsent>
<prevsent>the task of inducing hierarchical syntactic structure from observed yields alone has received great deal of attention (carroll and charniak, 1992; pereira and schabes, 1992; <papid> P92-1017 </papid>brill, 1993; <papid> P93-1035 </papid>stolcke and omohun dro, 1994).</prevsent>
</prevsection>
<citsent citstr=" P95-1031 ">
researchers have explored this problem for variety of reasons: to argue empirically against the poverty of the stimulus (clark, 2001), <papid> W01-0713 </papid>to use induction systems as first stage in constructing large treebanks (van zaanen, 2000), or to build better language models (baker, 1979; chen, 1995).<papid> P95-1031 </papid></citsent>
<aftsection>
<nextsent>in previous work, we presented conditional model over trees which gave the best published results for unsupervised parsing of the atis corpus (klein and manning, 2001<papid> W01-0714 </papid>b).</nextsent>
<nextsent>however, it suffered from several drawbacks, primarily stemming from the conditional model used for induction.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2471">
<title id=" P02-1017.xml">a generative constituent context model for improved grammar induction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the task of inducing hierarchical syntactic structure from observed yields alone has received great deal of attention (carroll and charniak, 1992; pereira and schabes, 1992; <papid> P92-1017 </papid>brill, 1993; <papid> P93-1035 </papid>stolcke and omohun dro, 1994).</prevsent>
<prevsent>researchers have explored this problem for variety of reasons: to argue empirically against the poverty of the stimulus (clark, 2001), <papid> W01-0713 </papid>to use induction systems as first stage in constructing large treebanks (van zaanen, 2000), or to build better language models (baker, 1979; chen, 1995).<papid> P95-1031 </papid></prevsent>
</prevsection>
<citsent citstr=" W01-0714 ">
in previous work, we presented conditional model over trees which gave the best published results for unsupervised parsing of the atis corpus (klein and manning, 2001<papid> W01-0714 </papid>b).</citsent>
<aftsection>
<nextsent>however, it suffered from several drawbacks, primarily stemming from the conditional model used for induction.
</nextsent>
<nextsent>here, we improve on that model in several ways.
</nextsent>
<nextsent>first, we construct generative model which utilizes the samefeatures.
</nextsent>
<nextsent>then, we extend the model to allow multiple constituent types and multiple prior distributions over trees.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2482">
<title id=" P02-1017.xml">a generative constituent context model for improved grammar induction </title>
<section> rb vb to vb.  </section>
<citcontext>
<prevsection>
<prevsent>these vectors were length-normalized, and then rank-reduced by an svd, keeping the 50 largest singular vectors.
</prevsent>
<prevsent>the resulting vectors were clustered into 200 word classes by weighted k-means algorithm, and then grammar induction operated over these classes.
</prevsent>
</prevsection>
<citsent citstr=" W00-0717 ">
we do not believe that the quality of our tags matches that of the better methods of schutze (1995), much less the recent results of clark (2000).<papid> W00-0717 </papid></citsent>
<aftsection>
<nextsent>nevertheless, using these tags as input still gave induced structure substantially above right-branching.
</nextsent>
<nextsent>figure 8 shows 0 10 20 30 40 50 60 70 80 0 4 8 12 16 20 24 28 32 36 40 iterations
</nextsent>
<nextsent>      0.00m 0.05m 0.10m 0.15m 0.20m 0.25m 0.30m 0.35m
</nextsent>
<nextsent>    f1 log-likelihood figure 10: f1 is non-decreasing until convergence.the performance with induced tags compared to correct tags.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2486">
<title id=" P03-1006.xml">generalized algorithms for constructing statistical language models </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>most offline representations of these models are based instead on an approximation to limit their size.
</prevsent>
<prevsent>we describe new technique for creating an exact representation of  -gram language models by wfas whose size is practical for offline use even in tasks with vocabulary size of about 500,000 words and for  .class-based models.
</prevsent>
</prevsection>
<citsent citstr=" J92-4003 ">
in many applications, it is natural and convenient to construct class-based language models, that is models based on classes of words (brown et al, 1992).<papid> J92-4003 </papid></citsent>
<aftsection>
<nextsent>such models are also often more robust since they may include words that belong to class but that were not found in the corpus.
</nextsent>
<nextsent>classical class-based models are based on simple classes such as list of words.
</nextsent>
<nextsent>but new clustering algorithms allow one to create more general and more complex classes that may be regular languages.
</nextsent>
<nextsent>very large and complex classes can also be defined using regular expressions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2487">
<title id=" P03-1006.xml">generalized algorithms for constructing statistical language models </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>but new clustering algorithms allow one to create more general and more complex classes that may be regular languages.
</prevsent>
<prevsent>very large and complex classes can also be defined using regular expressions.
</prevsent>
</prevsection>
<citsent citstr=" J94-3001 ">
we present simple and more general approach to class-based language models based on general weighted context-dependent rules (kaplan and kay, 1994; <papid> J94-3001 </papid>mohri and sproat, 1996).<papid> P96-1031 </papid></citsent>
<aftsection>
<nextsent>our approach allows us to deal efficiently with more complex classes such as weighted regular languages.we have fully implemented the algorithms just mentioned and incorporated them in general software library for language modeling, the grm library, that includes many other text and grammar processing function alities (allauzen et al, 2003).
</nextsent>
<nextsent>in the following, we will present in detail these algorithms and briefly describe the corresponding grm utilities.
</nextsent>
<nextsent>definition 1 system      is semi ring (kuich and salomaa, 1986) if:    is commuta tive monoid with identity element  ;    ff is monoid with identity element  ;  distributes over  ; and  is an annihilator for  : for all fiffifl  fi!   #fi$  . thus, semi ring is ring that may lack negation.
</nextsent>
<nextsent>two semi rings often used in speech processing are: the log semi ring %&amp;  (*),+.-0/1  2 3 45 6 -0 1 (mohri, 2002) which is isomorphic to the familiar real or probability semi ring (879 6 5:;   = via  @1a morphism with, for all fib cfld(e)f+.-0/ : fi; 2 3g4 chid @1aj lknmpoq risfipq6,ktmpoq uictu and the convention that: ktmpoq ui -#   and id @1a 1vw- , and the tropical semi ring xyy z([7\) +.-0/1 g]!^@_` 6 - g1 which can be derived from the log semi ring using the viterbi approximation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2489">
<title id=" P03-1006.xml">generalized algorithms for constructing statistical language models </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>but new clustering algorithms allow one to create more general and more complex classes that may be regular languages.
</prevsent>
<prevsent>very large and complex classes can also be defined using regular expressions.
</prevsent>
</prevsection>
<citsent citstr=" P96-1031 ">
we present simple and more general approach to class-based language models based on general weighted context-dependent rules (kaplan and kay, 1994; <papid> J94-3001 </papid>mohri and sproat, 1996).<papid> P96-1031 </papid></citsent>
<aftsection>
<nextsent>our approach allows us to deal efficiently with more complex classes such as weighted regular languages.we have fully implemented the algorithms just mentioned and incorporated them in general software library for language modeling, the grm library, that includes many other text and grammar processing function alities (allauzen et al, 2003).
</nextsent>
<nextsent>in the following, we will present in detail these algorithms and briefly describe the corresponding grm utilities.
</nextsent>
<nextsent>definition 1 system      is semi ring (kuich and salomaa, 1986) if:    is commuta tive monoid with identity element  ;    ff is monoid with identity element  ;  distributes over  ; and  is an annihilator for  : for all fiffifl  fi!   #fi$  . thus, semi ring is ring that may lack negation.
</nextsent>
<nextsent>two semi rings often used in speech processing are: the log semi ring %&amp;  (*),+.-0/1  2 3 45 6 -0 1 (mohri, 2002) which is isomorphic to the familiar real or probability semi ring (879 6 5:;   = via  @1a morphism with, for all fib cfld(e)f+.-0/ : fi; 2 3g4 chid @1aj lknmpoq risfipq6,ktmpoq uictu and the convention that: ktmpoq ui -#   and id @1a 1vw- , and the tropical semi ring xyy z([7\) +.-0/1 g]!^@_` 6 - g1 which can be derived from the log semi ring using the viterbi approximation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2492">
<title id=" P03-1006.xml">generalized algorithms for constructing statistical language models </title>
<section> counting.  </section>
<citcontext>
<prevsection>
<prevsent>zw:??n ed\:f+vn/.g? is rational.
</prevsent>
<prevsent>thus, by the theorem of schutzenberger (schutzenberger, 1961), there exists weighted transducer defined over the alphabet dand the probability semi ring realizing that transduction.
</prevsent>
</prevsection>
<citsent citstr=" J97-2003 ">
figure 1 shows the transducer in the particular case of d*?+fib c/ . 1there exist general weighted determinization and weight pushing algorithms that can be used to create deterministic and pushed automaton equivalent to an input word or phone lattice (mohri, 1997).<papid> J97-2003 </papid></citsent>
<aftsection>
<nextsent>proposition 1 let ? be weighted automaton over the probability semi ring, then: ? ?
</nextsent>
<nextsent>?*?[a ??
</nextsent>
<nextsent>l??? ? lb proof.
</nextsent>
<nextsent>by definition of , for any ? fld9?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2505">
<title id=" P03-1048.xml">evaluation challenges in largescale document summarization </title>
<section> data, annotation, and experimental.  </section>
<citcontext>
<prevsection>
<prevsent>in order to produce human extracts, our judges also labeled sentences with relevance judgements?, which indicate the relevance of sentence to the topic of the document.
</prevsent>
<prevsent>the relevance judgements for sentences range from 0 (irrelevant) to 10 (essential).
</prevsent>
</prevsection>
<citsent citstr=" W00-0403 ">
as in (radev et al, 2000), <papid> W00-0403 </papid>in order to create an extract of certain length, we simply extract the top scoring sentences that add up to that length.</citsent>
<aftsection>
<nextsent>for each target summary length, we produce an extract using summarizer or baseline.
</nextsent>
<nextsent>then we compare the output of the summarizer or baseline with the extract produced from the human relevancejudgements.
</nextsent>
<nextsent>both the summarizers and the evaluation measures are described in greater detail in the next two sections.
</nextsent>
<nextsent>2.1 summarizers and baselines.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2508">
<title id=" P03-1048.xml">evaluation challenges in largescale document summarization </title>
<section> data, annotation, and experimental.  </section>
<citcontext>
<prevsection>
<prevsent>websumm uses graph-connectivity model and operates under the assumption that nodes which are connected to many other nodes are likely to carry salient information.
</prevsent>
<prevsent>summ (summarist (hovy and lin, 1999)):an extractive summarizer based on topic signatures.
</prevsent>
</prevsection>
<citsent citstr=" J93-1004 ">
algn (alignment-based): we ran sentence alignment algorithm (gale and church, 1993) <papid> J93-1004 </papid>for each pair of english and chinese stories.</citsent>
<aftsection>
<nextsent>we used it to automatically generate chinesemanual?
</nextsent>
<nextsent>extracts from the english manual extracts we received from ldc.
</nextsent>
<nextsent>lead (lead-based): n% sentences are chosen from the beginning of the text.
</nextsent>
<nextsent>rand (random): n% sentences are chosen at random.the six summarizers were run at ten different target lengths to produce more than 100 million summaries (figure 2).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2511">
<title id=" P03-1048.xml">evaluation challenges in largescale document summarization </title>
<section> summary evaluation techniques.  </section>
<citcontext>
<prevsection>
<prevsent>for the purpose of this paper, weonly focus on small portion of the possible experiments that our corpus can facilitate.
</prevsent>
<prevsent>we used three general types of evaluation measures: co-selection, content-based similarity, and relevancecorrelation.
</prevsent>
</prevsection>
<citsent citstr=" J96-2004 ">
co-selection measures include precision and recall of co-selected sentences, relative utility (radev et al, 2000), <papid> W00-0403 </papid>and kappa (siegel andcastellan, 1988; carletta, 1996).<papid> J96-2004 </papid></citsent>
<aftsection>
<nextsent>co-selection methods have some restrictions: they only work forex tractive summarizers.
</nextsent>
<nextsent>two manual summaries of the same input do not in general share many identical sentences.
</nextsent>
<nextsent>we address this weakness of co-selection lengths #dj 05w 05s 10w 10s 20w 20s 30w 30s 40w 40s fd e-fd - - - - - - - - - - 40 e-ld x x x x x - 440 e-ra x x x x x - 440 e-mo x x x x x - 540 e-m2 - - - - - - - - - - 20 e-m3 - - - - - - - - - - 8 e-s2 - - - - - - - - - - 8 e-ws - - x - - - 160 e-wq - - - - - - - - - - 10 e-lc - - - - - - - - - - 40 e-cy - - - - - - 120 e-al x x x x x - 200 e-ar x x x x x - 200 e-am x x x x x - 200 c-fd - - - - - - - - - - 40 c-ld x x x x x - 240 c-ra x x x x x - 240 c-mo x x x x x - 320 c-m2 - - - - - - - - - - 20 c-cy - - - - - - 120 c-al x x x x x - 180 c-ar x x x x x - 200 c-am - x x x x - 120 x-fd - - - - - - - - - - 40 x-ld x x x x x - 240 x-ra x x x x x - 240 x-mo x x x x x - 320 x-m2 - - - - - - - - - - 20 x-cy - - - - - - 120 x-al x x x x x - 140 x-ar x x x x x - 160 x-am - x x x - - 120 figure 2: all runs performed (x = 20 clusters, = 10 clusters).
</nextsent>
<nextsent>language: = english, = chinese, = cross-lingual; summarizer: ld=lead, ra=rand, ws=webs, wq=webs-query based, etc.; = sentence-based, = word-based; #dj = number of docjudges?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2516">
<title id=" P00-1012.xml">the order of pre nominal adjectives in natural language generation </title>
<section> word bigram model.  </section>
<citcontext>
<prevsection>
<prevsent>the problem of generating ordered sequences of adjectives is an instance of the more general problem of selecting among number of possible outputs from natural language generation system.
</prevsent>
<prevsent>one approach to this more general problem, taken by the nitrogen?
</prevsent>
</prevsection>
<citsent citstr=" W98-1426 ">
generator (langkilde and knight, 1998<papid> W98-1426 </papid>a; langkilde and knight, 1998<papid> W98-1426 </papid>b), takes advantage of standard statistical techniques by generating lattice of all possible strings given semantic representation as input and selecting the most likely output using bigram language model.</citsent>
<aftsection>
<nextsent>langkilde and knight report that this strategy yields good results for problems like generatingverb/object collocations and for selecting the correct morphological form of word.
</nextsent>
<nextsent>it also should be straightforwardly applicable to the more specific problem we are addressing here.
</nextsent>
<nextsent>to determine the correct order for sequence of pre nominal adjectives, we can simply generate all possible orderings and choose the one with the highest probability.
</nextsent>
<nextsent>this has the advantage of reducing the problem of adjective ordering to the problem of estimating n-gram probabilities, some thing which is relatively well understood.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2524">
<title id=" P00-1012.xml">the order of pre nominal adjectives in natural language generation </title>
<section> the experiments.  </section>
<citcontext>
<prevsection>
<prevsent>this lack of context makes this problem different from other problems, such as part-of-speech tagging and grapheme-to-phoneme conversion, for which statistical and machine learning solutions have been proposed.
</prevsent>
<prevsent>3.2 direct evidence.
</prevsent>
</prevsection>
<citsent citstr=" P99-1018 ">
the simplest strategy for ordering adjectives is what shaw and hatzivassiloglou (1999) <papid> P99-1018 </papid>call the direct evidence method.</citsent>
<aftsection>
<nextsent>to order the pair {a,b}, count how many times the ordered sequences a,b? and b,a? appear in the training data and output the pair in the order which occurred more often.this method has the advantage of being conceptually very simple, easy to implement, and highly accurate for pairs of adjectives which actually appear in the training data.
</nextsent>
<nextsent>applying this method to the adjectives sequences taken from the bnc yields better than 98% accuracy for pairs that occurred in the training data.
</nextsent>
<nextsent>however, since as we have seen, the majority of pairs occur only once, the overall accuracy of this method is59.72%, only slightly better than random guessing.
</nextsent>
<nextsent>fortunately, another strength of this method is that it is easy to identify those pairs for which it is likely to give the right result.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2533">
<title id=" P00-1012.xml">the order of pre nominal adjectives in natural language generation </title>
<section> future directions.  </section>
<citcontext>
<prevsection>
<prevsent>furthermore, any realistic dialog system would make use of some limited vocabulary direct evidence 78.28% adjective bigrams 88.02% mbl (morphological) 89.34% (*) positional probabilities 89.73% (*) mbl (combined) 91.85% table 1: summary of results.
</prevsent>
<prevsent>with the exception of the starred values, all differences are statistically significant (p  0.005)for which semantic information would be available.
</prevsent>
</prevsection>
<citsent citstr=" P93-1024 ">
more generally, distributional clustering techniques (schutze, 1992; pereira et al, 1993) <papid> P93-1024 </papid>could be applied to extract semantic classes fromthe corpus itself.</citsent>
<aftsection>
<nextsent>since the constraints on adjective ordering in english depend largely on semantic classes, the addition of semantic information to the model ought to improve the results.
</nextsent>
<nextsent>the second area where the methods described here could be improved is in the way that multiple information sources are integrated.
</nextsent>
<nextsent>the technique method described in section 3.7 is fairly crude method for combining frequency information with symbolic data.
</nextsent>
<nextsent>it would be worthwhile to investigate applying some of the more sophisticated ensemble learning techniques which have been proposed in the literature (dietterich, 1997).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2534">
<title id=" P00-1012.xml">the order of pre nominal adjectives in natural language generation </title>
<section> future directions.  </section>
<citcontext>
<prevsection>
<prevsent>the technique method described in section 3.7 is fairly crude method for combining frequency information with symbolic data.
</prevsent>
<prevsent>it would be worthwhile to investigate applying some of the more sophisticated ensemble learning techniques which have been proposed in the literature (dietterich, 1997).
</prevsent>
</prevsection>
<citsent citstr=" W99-0606 ">
in particular, boosting (schapire, 1999; abney et al., 1999) <papid> W99-0606 </papid>offers the possibility of achieving high accuracy from collection of classifiers which individually perform quite poorly.</citsent>
<aftsection>
<nextsent>in this paper, we have presented the results of applying number of statistical and machine learning techniques to the problem of predicting the order of pre nominal adjectives in english.
</nextsent>
<nextsent>the scores for each of the methods are summarized intable 1.
</nextsent>
<nextsent>the best methods yield around 90% accuracy, better than the best previously published methods when applied to the broad domain dataof the british national corpus.
</nextsent>
<nextsent>note that mcnemars test (dietterich, 1998) confirms the significance of all of the differences reflected here(with  0.005) with the exception of the difference between purely morphological mbl and the method based on positional probabilities.from this investigation, we can draw some additional conclusions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2535">
<title id=" P03-2011.xml">semantic classification of chinese unknown words </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>this paper describes classifier that assigns semantic thesaurus categories to unknown chinese words (words not already in the cilin thesaurus and the chinese electronic dictionary, but in the sinica corpus).
</prevsent>
<prevsent>the focus of the paper differs in two ways from previous research in this particular area.
</prevsent>
</prevsection>
<citsent citstr=" W00-1203 ">
prior research in chinese unknown words mostly focused on proper nouns (lee 1993, lee, lee and chen 1994, huang, hong and chen 1994, chen and chen 2000).<papid> W00-1203 </papid></citsent>
<aftsection>
<nextsent>this paper does not address proper nouns, focusing rather on common nouns, adjectives, and verbs.
</nextsent>
<nextsent>my analysis of the sinica corpus shows that contrary to expectation, most of unknown words in chinese are common nouns, adjectives, and verbs rather than proper nouns.
</nextsent>
<nextsent>other previous research has focused on features related to unknown word contexts (caraballo 1999; <papid> P99-1016 </papid>roark and charniak 1998).<papid> P98-2182 </papid></nextsent>
<nextsent>while context is clearly an important feature, this paper focuses on non-contextual features, which may play key role for unknown words that occur only once and hence have limited context.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2536">
<title id=" P03-2011.xml">semantic classification of chinese unknown words </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>this paper does not address proper nouns, focusing rather on common nouns, adjectives, and verbs.
</prevsent>
<prevsent>my analysis of the sinica corpus shows that contrary to expectation, most of unknown words in chinese are common nouns, adjectives, and verbs rather than proper nouns.
</prevsent>
</prevsection>
<citsent citstr=" P99-1016 ">
other previous research has focused on features related to unknown word contexts (caraballo 1999; <papid> P99-1016 </papid>roark and charniak 1998).<papid> P98-2182 </papid></citsent>
<aftsection>
<nextsent>while context is clearly an important feature, this paper focuses on non-contextual features, which may play key role for unknown words that occur only once and hence have limited context.
</nextsent>
<nextsent>the feature focus on, following ciaramita (2002), <papid> W02-0903 </papid>is morphological similarity to words whose semantic category is known.</nextsent>
<nextsent>my nearest neighbor approach to lexical acquisition computes the distance between an unknown word and examples from the cilin thesaurus based upon its morphological structure.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2537">
<title id=" P03-2011.xml">semantic classification of chinese unknown words </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>this paper does not address proper nouns, focusing rather on common nouns, adjectives, and verbs.
</prevsent>
<prevsent>my analysis of the sinica corpus shows that contrary to expectation, most of unknown words in chinese are common nouns, adjectives, and verbs rather than proper nouns.
</prevsent>
</prevsection>
<citsent citstr=" P98-2182 ">
other previous research has focused on features related to unknown word contexts (caraballo 1999; <papid> P99-1016 </papid>roark and charniak 1998).<papid> P98-2182 </papid></citsent>
<aftsection>
<nextsent>while context is clearly an important feature, this paper focuses on non-contextual features, which may play key role for unknown words that occur only once and hence have limited context.
</nextsent>
<nextsent>the feature focus on, following ciaramita (2002), <papid> W02-0903 </papid>is morphological similarity to words whose semantic category is known.</nextsent>
<nextsent>my nearest neighbor approach to lexical acquisition computes the distance between an unknown word and examples from the cilin thesaurus based upon its morphological structure.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2538">
<title id=" P03-2011.xml">semantic classification of chinese unknown words </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>other previous research has focused on features related to unknown word contexts (caraballo 1999; <papid> P99-1016 </papid>roark and charniak 1998).<papid> P98-2182 </papid></prevsent>
<prevsent>while context is clearly an important feature, this paper focuses on non-contextual features, which may play key role for unknown words that occur only once and hence have limited context.</prevsent>
</prevsection>
<citsent citstr=" W02-0903 ">
the feature focus on, following ciaramita (2002), <papid> W02-0903 </papid>is morphological similarity to words whose semantic category is known.</citsent>
<aftsection>
<nextsent>my nearest neighbor approach to lexical acquisition computes the distance between an unknown word and examples from the cilin thesaurus based upon its morphological structure.
</nextsent>
<nextsent>the classifier improves on baseline semantic categorization performance for adjectives and verbs, but not for nouns.
</nextsent>
<nextsent>the biggest problem for assigning semantic categories to words lies in the incompleteness of dictionaries.
</nextsent>
<nextsent>it is impractical to construct dictionary that will contain all words that may occur in some previously unseen corpora.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2546">
<title id=" P03-2011.xml">semantic classification of chinese unknown words </title>
<section> semantic classification.  </section>
<citcontext>
<prevsection>
<prevsent>the baseline method is to assign the semantic category of the morphological head to each word.
</prevsent>
<prevsent>4.2 an example-base semantic classification.
</prevsent>
</prevsection>
<citsent citstr=" W02-1811 ">
the algorithm for the nearest neighbor classifier is as follows: 1) an unknown word is parsed by morphological analyzer (tseng and chen 2002).<papid> W02-1811 </papid></citsent>
<aftsection>
<nextsent>the analyzer a) segments word into sequence of morphemes, b) tags the syntactic categories of morphemes, and c) predicts morpho-syntactic relationships between morphemes, such as modifier-head, verb-object and resultative verbs as shown as in table 3.
</nextsent>
<nextsent>for example, if ???
</nextsent>
<nextsent>/wudaojia dance-expert dancer?
</nextsent>
<nextsent>is an unknown word, the morphological segmentation is ??/wudao dance dance?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2547">
<title id=" P01-1065.xml">a generic approach to parallel chart parsing with an application to lingo </title>
<section> design and implementation.  </section>
<citcontext>
<prevsection>
<prevsent>this is especially problematic forthe feature structures.
</prevsent>
<prevsent>many unification algorithms need write access to scratch fields in the graph structures.
</prevsent>
</prevsection>
<citsent citstr=" P91-1041 ">
such algorithms are therefore not thread-safe.2 for this reason weuse the thread-safe unification algorithm presented by van lohuizen (2000), which is comparable in performance to tomabechis algorithm (tomabechi, 1991).<papid> P91-1041 </papid></citsent>
<aftsection>
<nextsent>note that each thread also has its own agenda.
</nextsent>
<nextsent>some parsing systems require strict control over the order of evaluation of tasks.
</nextsent>
<nextsent>the distributed agendas that we use in our approach may make it hard to implement such strict control.
</nextsent>
<nextsent>one solution to the problem would be to use centralized agenda.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2548">
<title id=" P03-1013.xml">probabilistic parsing for german using sister head dependencies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this model outperforms the baseline, achieving labeled precision and recall of up to 74%.
</prevsent>
<prevsent>this indicates that sister-head dependencies are more appropriate for treebanks with very flat structures such as negra.
</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
treebank-based probabilistic parsing has been the subject of intensive research over the past few years, resulting in parsing models that achieve both broad coverage and high parsing accuracy (e.g., collins1997; <papid> P97-1003 </papid>charniak 2000).<papid> A00-2018 </papid></citsent>
<aftsection>
<nextsent>however, most of the existing models have been developed for english and trained on the penn treebank (marcus et al, 1993), <papid> J93-2004 </papid>which raises the question whether these models generalize to other languages, and to annotation schemes that differ from the penn treebank markup.</nextsent>
<nextsent>the present paper addresses this question by proposing probabilistic parsing model trained on negra (skut et al, 1997), <papid> A97-1014 </papid>syntactically annotated corpus for german.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2549">
<title id=" P03-1013.xml">probabilistic parsing for german using sister head dependencies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this model outperforms the baseline, achieving labeled precision and recall of up to 74%.
</prevsent>
<prevsent>this indicates that sister-head dependencies are more appropriate for treebanks with very flat structures such as negra.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
treebank-based probabilistic parsing has been the subject of intensive research over the past few years, resulting in parsing models that achieve both broad coverage and high parsing accuracy (e.g., collins1997; <papid> P97-1003 </papid>charniak 2000).<papid> A00-2018 </papid></citsent>
<aftsection>
<nextsent>however, most of the existing models have been developed for english and trained on the penn treebank (marcus et al, 1993), <papid> J93-2004 </papid>which raises the question whether these models generalize to other languages, and to annotation schemes that differ from the penn treebank markup.</nextsent>
<nextsent>the present paper addresses this question by proposing probabilistic parsing model trained on negra (skut et al, 1997), <papid> A97-1014 </papid>syntactically annotated corpus for german.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2550">
<title id=" P03-1013.xml">probabilistic parsing for german using sister head dependencies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this indicates that sister-head dependencies are more appropriate for treebanks with very flat structures such as negra.
</prevsent>
<prevsent>treebank-based probabilistic parsing has been the subject of intensive research over the past few years, resulting in parsing models that achieve both broad coverage and high parsing accuracy (e.g., collins1997; <papid> P97-1003 </papid>charniak 2000).<papid> A00-2018 </papid></prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
however, most of the existing models have been developed for english and trained on the penn treebank (marcus et al, 1993), <papid> J93-2004 </papid>which raises the question whether these models generalize to other languages, and to annotation schemes that differ from the penn treebank markup.</citsent>
<aftsection>
<nextsent>the present paper addresses this question by proposing probabilistic parsing model trained on negra (skut et al, 1997), <papid> A97-1014 </papid>syntactically annotated corpus for german.</nextsent>
<nextsent>german has number of syntactic properties that set it apart from english, andthe negra annotation scheme differs in important respects from the penn treebank markup.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2551">
<title id=" P03-1013.xml">probabilistic parsing for german using sister head dependencies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>treebank-based probabilistic parsing has been the subject of intensive research over the past few years, resulting in parsing models that achieve both broad coverage and high parsing accuracy (e.g., collins1997; <papid> P97-1003 </papid>charniak 2000).<papid> A00-2018 </papid></prevsent>
<prevsent>however, most of the existing models have been developed for english and trained on the penn treebank (marcus et al, 1993), <papid> J93-2004 </papid>which raises the question whether these models generalize to other languages, and to annotation schemes that differ from the penn treebank markup.</prevsent>
</prevsection>
<citsent citstr=" A97-1014 ">
the present paper addresses this question by proposing probabilistic parsing model trained on negra (skut et al, 1997), <papid> A97-1014 </papid>syntactically annotated corpus for german.</citsent>
<aftsection>
<nextsent>german has number of syntactic properties that set it apart from english, andthe negra annotation scheme differs in important respects from the penn treebank markup.
</nextsent>
<nextsent>while negra has been used to build probabilistic chunk ers (becker and frank, 2002; <papid> C02-1093 </papid>skut and brants, 1998), <papid> W98-1117 </papid>the research reported in this paper is the first attempt to develop probabilistic full parsing model forger man trained on treebank (to our knowledge).</nextsent>
<nextsent>lexicalization can increase parsing performance dramatically for english (carroll and rooth, 1998;charniak, 1997, 2000; collins, 1997), <papid> P97-1003 </papid>and the lexicalized model proposed by collins (1997) <papid> P97-1003 </papid>has been successfully applied to czech (collins et al, 1999) <papid> P99-1065 </papid>and chinese (bikel and chiang, 2000).<papid> W00-1201 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2552">
<title id=" P03-1013.xml">probabilistic parsing for german using sister head dependencies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the present paper addresses this question by proposing probabilistic parsing model trained on negra (skut et al, 1997), <papid> A97-1014 </papid>syntactically annotated corpus for german.</prevsent>
<prevsent>german has number of syntactic properties that set it apart from english, andthe negra annotation scheme differs in important respects from the penn treebank markup.</prevsent>
</prevsection>
<citsent citstr=" C02-1093 ">
while negra has been used to build probabilistic chunk ers (becker and frank, 2002; <papid> C02-1093 </papid>skut and brants, 1998), <papid> W98-1117 </papid>the research reported in this paper is the first attempt to develop probabilistic full parsing model forger man trained on treebank (to our knowledge).</citsent>
<aftsection>
<nextsent>lexicalization can increase parsing performance dramatically for english (carroll and rooth, 1998;charniak, 1997, 2000; collins, 1997), <papid> P97-1003 </papid>and the lexicalized model proposed by collins (1997) <papid> P97-1003 </papid>has been successfully applied to czech (collins et al, 1999) <papid> P99-1065 </papid>and chinese (bikel and chiang, 2000).<papid> W00-1201 </papid></nextsent>
<nextsent>however, the resulting performance is significantly lower than the performance of the same model for english (see table 1).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2553">
<title id=" P03-1013.xml">probabilistic parsing for german using sister head dependencies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the present paper addresses this question by proposing probabilistic parsing model trained on negra (skut et al, 1997), <papid> A97-1014 </papid>syntactically annotated corpus for german.</prevsent>
<prevsent>german has number of syntactic properties that set it apart from english, andthe negra annotation scheme differs in important respects from the penn treebank markup.</prevsent>
</prevsection>
<citsent citstr=" W98-1117 ">
while negra has been used to build probabilistic chunk ers (becker and frank, 2002; <papid> C02-1093 </papid>skut and brants, 1998), <papid> W98-1117 </papid>the research reported in this paper is the first attempt to develop probabilistic full parsing model forger man trained on treebank (to our knowledge).</citsent>
<aftsection>
<nextsent>lexicalization can increase parsing performance dramatically for english (carroll and rooth, 1998;charniak, 1997, 2000; collins, 1997), <papid> P97-1003 </papid>and the lexicalized model proposed by collins (1997) <papid> P97-1003 </papid>has been successfully applied to czech (collins et al, 1999) <papid> P99-1065 </papid>and chinese (bikel and chiang, 2000).<papid> W00-1201 </papid></nextsent>
<nextsent>however, the resulting performance is significantly lower than the performance of the same model for english (see table 1).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2563">
<title id=" P03-1013.xml">probabilistic parsing for german using sister head dependencies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>german has number of syntactic properties that set it apart from english, andthe negra annotation scheme differs in important respects from the penn treebank markup.
</prevsent>
<prevsent>while negra has been used to build probabilistic chunk ers (becker and frank, 2002; <papid> C02-1093 </papid>skut and brants, 1998), <papid> W98-1117 </papid>the research reported in this paper is the first attempt to develop probabilistic full parsing model forger man trained on treebank (to our knowledge).</prevsent>
</prevsection>
<citsent citstr=" P99-1065 ">
lexicalization can increase parsing performance dramatically for english (carroll and rooth, 1998;charniak, 1997, 2000; collins, 1997), <papid> P97-1003 </papid>and the lexicalized model proposed by collins (1997) <papid> P97-1003 </papid>has been successfully applied to czech (collins et al, 1999) <papid> P99-1065 </papid>and chinese (bikel and chiang, 2000).<papid> W00-1201 </papid></citsent>
<aftsection>
<nextsent>however, the resulting performance is significantly lower than the performance of the same model for english (see table 1).
</nextsent>
<nextsent>neither collins et al (1999) <papid> P99-1065 </papid>nor bikel and chiang (2000) <papid> W00-1201 </papid>compare the lexicalized model to anunlexicalized baseline model, leaving open the possibility that lexicalization is useful for english, but not for other languages.this paper is structured as follows.</nextsent>
<nextsent>section 2 reviews the syntactic properties of german, focusing on its semi-flexible wordorder.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2565">
<title id=" P03-1013.xml">probabilistic parsing for german using sister head dependencies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>german has number of syntactic properties that set it apart from english, andthe negra annotation scheme differs in important respects from the penn treebank markup.
</prevsent>
<prevsent>while negra has been used to build probabilistic chunk ers (becker and frank, 2002; <papid> C02-1093 </papid>skut and brants, 1998), <papid> W98-1117 </papid>the research reported in this paper is the first attempt to develop probabilistic full parsing model forger man trained on treebank (to our knowledge).</prevsent>
</prevsection>
<citsent citstr=" W00-1201 ">
lexicalization can increase parsing performance dramatically for english (carroll and rooth, 1998;charniak, 1997, 2000; collins, 1997), <papid> P97-1003 </papid>and the lexicalized model proposed by collins (1997) <papid> P97-1003 </papid>has been successfully applied to czech (collins et al, 1999) <papid> P99-1065 </papid>and chinese (bikel and chiang, 2000).<papid> W00-1201 </papid></citsent>
<aftsection>
<nextsent>however, the resulting performance is significantly lower than the performance of the same model for english (see table 1).
</nextsent>
<nextsent>neither collins et al (1999) <papid> P99-1065 </papid>nor bikel and chiang (2000) <papid> W00-1201 </papid>compare the lexicalized model to anunlexicalized baseline model, leaving open the possibility that lexicalization is useful for english, but not for other languages.this paper is structured as follows.</nextsent>
<nextsent>section 2 reviews the syntactic properties of german, focusing on its semi-flexible wordorder.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2610">
<title id=" P03-1013.xml">probabilistic parsing for german using sister head dependencies </title>
<section> experiment 1.  </section>
<citcontext>
<prevsection>
<prevsent>in order to make the models comparable, we used uniform approach to unknown words.
</prevsent>
<prevsent>all models were runon pos-tagged input; this input was created by tagging the test set with separate pos tagger, for both known and unknown words.
</prevsent>
</prevsection>
<citsent citstr=" A00-1031 ">
we used tnt (brants, 2000), <papid> A00-1031 </papid>trained on the negra training set.</citsent>
<aftsection>
<nextsent>the tagging accuracy was 97.12% on the development set.in order to obtain an upper bound for the performance of the parsing models, we also ran the parsers on the test set with the correct tags (as specified in negra), again for both known and unknown words.
</nextsent>
<nextsent>we will refer to this mode as perfect tagging?.all models were evaluated using standard parseval measures.
</nextsent>
<nextsent>we report labeled recall (lr) labeled precision (lp), average crossing brackets (cbs), zero crossing brackets (0cb), and two or less crossing brackets (2cb).
</nextsent>
<nextsent>we also give the cover age (cov), i.e., the percentage of sentences that the parser was able to parse.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2637">
<title id=" P03-1013.xml">probabilistic parsing for german using sister head dependencies </title>
<section> comparison with previous work.  </section>
<citcontext>
<prevsection>
<prevsent>becker and frank (2002) <papid> C02-1093 </papid>train an un lexicalized pcfg on negra to perform different chunking task, viz., the identification oftopological fields (sentence-based chunks).</prevsent>
<prevsent>theyre port an lr and lp of 93%.</prevsent>
</prevsection>
<citsent citstr=" W01-0521 ">
the head-lexicalized model of carroll and rooth (1998) has been applied to german by beil et al 3it is unclear what effect bi-lexical statistics have on thesister-head model; while gildea (2001) <papid> W01-0521 </papid>shows bi-lexical statistics are sparse for some grammars, hockenmaier and steedman (2002) <papid> P02-1043 </papid>found they play greater role in binarized grammars.</citsent>
<aftsection>
<nextsent>(1999), (2002).
</nextsent>
<nextsent>however, this approach differs in the number of ways from the results reported here: (a) ahand-written grammar (instead of treebank grammar) is used; (b) training is carried out on unannotated data; (c) the grammar and the training set cover only subordinate and relative clauses, not unrestricted text.
</nextsent>
<nextsent>beil et al (2002) report an evaluation using an np chunking task, achieving 92% lr andlp.
</nextsent>
<nextsent>they also report the results of task-based evaluation (extraction of sucategorization frames).there is some research on treebank-based parsing of languages other than english.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2638">
<title id=" P03-1013.xml">probabilistic parsing for german using sister head dependencies </title>
<section> comparison with previous work.  </section>
<citcontext>
<prevsection>
<prevsent>becker and frank (2002) <papid> C02-1093 </papid>train an un lexicalized pcfg on negra to perform different chunking task, viz., the identification oftopological fields (sentence-based chunks).</prevsent>
<prevsent>theyre port an lr and lp of 93%.</prevsent>
</prevsection>
<citsent citstr=" P02-1043 ">
the head-lexicalized model of carroll and rooth (1998) has been applied to german by beil et al 3it is unclear what effect bi-lexical statistics have on thesister-head model; while gildea (2001) <papid> W01-0521 </papid>shows bi-lexical statistics are sparse for some grammars, hockenmaier and steedman (2002) <papid> P02-1043 </papid>found they play greater role in binarized grammars.</citsent>
<aftsection>
<nextsent>(1999), (2002).
</nextsent>
<nextsent>however, this approach differs in the number of ways from the results reported here: (a) ahand-written grammar (instead of treebank grammar) is used; (b) training is carried out on unannotated data; (c) the grammar and the training set cover only subordinate and relative clauses, not unrestricted text.
</nextsent>
<nextsent>beil et al (2002) report an evaluation using an np chunking task, achieving 92% lr andlp.
</nextsent>
<nextsent>they also report the results of task-based evaluation (extraction of sucategorization frames).there is some research on treebank-based parsing of languages other than english.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2659">
<title id=" P03-1061.xml">morphological analysis of a large spontaneous speech corpus in japanese </title>
<section> problems and their solutions.  </section>
<citcontext>
<prevsection>
<prevsent>this section describes major problems in tagging large spontaneous speech corpus with high precision in semiautomatic way, and our solutions to those problems.one of the most important problems in morphological analysis is that posed by unknown words, which are words found in neither dictionary nor training corpus.
</prevsent>
<prevsent>two statistical approaches have been applied to this problem.
</prevsent>
</prevsection>
<citsent citstr=" C96-2202 ">
one is to find unknown words from corpora and put them into dictionary (e.g., (mori and nagao, 1996)), <papid> C96-2202 </papid>and the other is to estimate model that can identify unknown words correctly (e.g., (kashioka et al, 1997;nagata, 1999)).<papid> P99-1036 </papid></citsent>
<aftsection>
<nextsent>uchimoto et al used both approaches.
</nextsent>
<nextsent>they proposed morphological analysis method based on maximum entropy (me) model (uchimoto et al, 2001).<papid> W01-0512 </papid></nextsent>
<nextsent>their method uses model that estimates how likely string is to be morpheme as its probability, and thus it has potential to overcome the unknown word problem.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2660">
<title id=" P03-1061.xml">morphological analysis of a large spontaneous speech corpus in japanese </title>
<section> problems and their solutions.  </section>
<citcontext>
<prevsection>
<prevsent>this section describes major problems in tagging large spontaneous speech corpus with high precision in semiautomatic way, and our solutions to those problems.one of the most important problems in morphological analysis is that posed by unknown words, which are words found in neither dictionary nor training corpus.
</prevsent>
<prevsent>two statistical approaches have been applied to this problem.
</prevsent>
</prevsection>
<citsent citstr=" P99-1036 ">
one is to find unknown words from corpora and put them into dictionary (e.g., (mori and nagao, 1996)), <papid> C96-2202 </papid>and the other is to estimate model that can identify unknown words correctly (e.g., (kashioka et al, 1997;nagata, 1999)).<papid> P99-1036 </papid></citsent>
<aftsection>
<nextsent>uchimoto et al used both approaches.
</nextsent>
<nextsent>they proposed morphological analysis method based on maximum entropy (me) model (uchimoto et al, 2001).<papid> W01-0512 </papid></nextsent>
<nextsent>their method uses model that estimates how likely string is to be morpheme as its probability, and thus it has potential to overcome the unknown word problem.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2661">
<title id=" P03-1061.xml">morphological analysis of a large spontaneous speech corpus in japanese </title>
<section> problems and their solutions.  </section>
<citcontext>
<prevsection>
<prevsent>one is to find unknown words from corpora and put them into dictionary (e.g., (mori and nagao, 1996)), <papid> C96-2202 </papid>and the other is to estimate model that can identify unknown words correctly (e.g., (kashioka et al, 1997;nagata, 1999)).<papid> P99-1036 </papid></prevsent>
<prevsent>uchimoto et al used both ap proaches.</prevsent>
</prevsection>
<citsent citstr=" W01-0512 ">
they proposed morphological analysis method based on maximum entropy (me) model (uchimoto et al, 2001).<papid> W01-0512 </papid></citsent>
<aftsection>
<nextsent>their method uses model that estimates how likely string is to be morpheme as its probability, and thus it has potential to overcome the unknown word problem.
</nextsent>
<nextsent>therefore, we use their method for morphological analysis of the csj.
</nextsent>
<nextsent>however, uchimoto et al reported that the accuracy of automatic word segmentation and pos tagging was 94 points in f-measure (uchimoto etal., 2002).<papid> C02-2019 </papid></nextsent>
<nextsent>that is much lower than the accuracy obtained by manual tagging.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2662">
<title id=" P03-1061.xml">morphological analysis of a large spontaneous speech corpus in japanese </title>
<section> problems and their solutions.  </section>
<citcontext>
<prevsection>
<prevsent>their method uses model that estimates how likely string is to be morpheme as its probability, and thus it has potential to overcome the unknown word problem.
</prevsent>
<prevsent>therefore, we use their method for morphological analysis of the csj.
</prevsent>
</prevsection>
<citsent citstr=" C02-2019 ">
however, uchimoto et al reported that the accuracy of automatic word segmentation and pos tagging was 94 points in f-measure (uchimoto etal., 2002).<papid> C02-2019 </papid></citsent>
<aftsection>
<nextsent>that is much lower than the accuracy obtained by manual tagging.
</nextsent>
<nextsent>several problems led to this inaccuracy.
</nextsent>
<nextsent>in the following, we describe these problems and our solutions to them.
</nextsent>
<nextsent>fillers and disfluenciesfillers and disfluencies are characteristic expressions often used in spoken language, butthey are randomly inserted into text, so detecting their segmentation is difficult.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2665">
<title id=" P03-1061.xml">morphological analysis of a large spontaneous speech corpus in japanese </title>
<section> models and algorithms.  </section>
<citcontext>
<prevsection>
<prevsent>a tag designated as 1 is thus assigned one of number, n, of grammatical attributes assigned to morphemes, and the problem becomes to assign an attribute (from 0 to n) to every string in given sentence.
</prevsent>
<prevsent>we define model that estimates the likelihood that given string is morpheme and has grammatical attribute i(1 ? ? n) as morpheme model.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
we implemented this model within an me modeling framework (jaynes, 1957; jaynes, 1979; berger et al, 1996).<papid> J96-1002 </papid></citsent>
<aftsection>
<nextsent>the model is represented by eq.
</nextsent>
<nextsent>(1): ?
</nextsent>
<nextsent>(a|b) = exp ( ? i,j ? i,j i,j (a, b) ) ?
</nextsent>
<nextsent>(b) (1) short word long word word pronunciation pos others word pronunciation pos others ??
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2670">
<title id=" P03-2002.xml">an ontology based semantic tagger for ie system </title>
<section> overall system.  </section>
<citcontext>
<prevsection>
<prevsent>the semantic tagger, is detailed in section 4.
</prevsent>
<prevsent>3.1 extraction of candidates.
</prevsent>
</prevsection>
<citsent citstr=" A92-1021 ">
candidates considered in the semantic tagging process are noun phrases np, proposition phrases pp, verb phrases vp, adjectives adj and adverbs adv.to gather these candidates we used the brill transformational tagger (brill, 1992) <papid> A92-1021 </papid>for the part-ofspeech step and the cass partial parser for the parsing step (abney, 1994).</citsent>
<aftsection>
<nextsent>however, because of the disfluencies (repairs, substitutions and omissions)encountered in the conversations, many errors occurred when parsing large constructions.
</nextsent>
<nextsent>so, we reduced the set of grammatical rules used by cass tocover only minimal chunks and discard large constructions such as vp ? vx np?
</nextsent>
<nextsent>adv* or noun 1url http://www.wordsmyth.net/.
</nextsent>
<nextsent>transcribed conversation  stage . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2671">
<title id=" N12-1084.xml">learning from bullying traces in social media </title>
<section> nlp task a: text categorization.  </section>
<citcontext>
<prevsection>
<prevsent>the same annotators who labeled thetrec corpus labeled 1762 tweets sampled uniformly from the enriched dataset on august 6, 2011.
</prevsent>
<prevsent>among them, 684 (39%) were labeled as bullying traces.
</prevsent>
</prevsection>
<citsent citstr=" D11-1136 ">
following (settles, 2011), <papid> D11-1136 </papid>these 1762 tweets werecase-folded but without any stemming or stop word removal.</citsent>
<aftsection>
<nextsent>any user mentions preceded by ?@?
</nextsent>
<nextsent>were replaced by the anonymized user name ?@username?.
</nextsent>
<nextsent>any urls starting with http?
</nextsent>
<nextsent>were replaced by the token httplink?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2672">
<title id=" N12-1084.xml">learning from bullying traces in social media </title>
<section> nlp task a: text categorization.  </section>
<citcontext>
<prevsection>
<prevsent>or ?:d?, were also included as tokens.
</prevsent>
<prevsent>after these preprocessing procedures, we created three different sets of feature representations: unigrams (1g), unigrams+bigrams (1g2g), and pos colored unigrams+bigrams (1g2gpos).
</prevsent>
</prevsection>
<citsent citstr=" N03-1033 ">
pos tagging was done with the stanford corenlp package (toutanova et al , 2003).<papid> N03-1033 </papid></citsent>
<aftsection>
<nextsent>pos-coloring was done by expanding each token into token:pos.
</nextsent>
<nextsent>we chose four commonly used text classifiers, namely, naive bayes, svm with linear kernel (svm(linear)), svm with rbf kernel (svm(rbf)) and logistic regression (equivalent to maxent).
</nextsent>
<nextsent>we used the weka (hall et al , 2009) implementation for the first three (calling libsvm (chang and lin, 2011) with wekas interfaces for svms), and the l1general package (schmidt, fung, and rosales, 2007) for the fourth.we held out 262 tweets for test, and systematically varied training set size among the remaining tweets, from 100 to 1500 with the step-size 100.
</nextsent>
<nextsent>we tuned all parameters jointly by 5-fold.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2673">
<title id=" N12-1084.xml">learning from bullying traces in social media </title>
<section> nlp task b: role labeling.  </section>
<citcontext>
<prevsection>
<prevsent>4.2 person-mentions roles.
</prevsent>
<prevsent>this sub-task labels each person-mention with bullying role.
</prevsent>
</prevsection>
<citsent citstr=" W09-1119 ">
it uses named entity recognition(ner) (finkel, grenager, and manning, 2005; ratinov and roth, 2009; <papid> W09-1119 </papid>ritter et al , 2011) <papid> D11-1141 </papid>as subroutine to identify named person entities, though we are also interested in unnamed persons such as my teacher?</citsent>
<aftsection>
<nextsent>and pronouns.
</nextsent>
<nextsent>it is related to semantic role 660labeling (srl) (gildea and jurafsky, 2002; <papid> J02-3001 </papid>punyakanok, roth, and yih, 2008) but differs critically in that our roles are not tied to specific verb predi cates.</nextsent>
<nextsent>methods.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2674">
<title id=" N12-1084.xml">learning from bullying traces in social media </title>
<section> nlp task b: role labeling.  </section>
<citcontext>
<prevsection>
<prevsent>4.2 person-mentions roles.
</prevsent>
<prevsent>this sub-task labels each person-mention with bullying role.
</prevsent>
</prevsection>
<citsent citstr=" D11-1141 ">
it uses named entity recognition(ner) (finkel, grenager, and manning, 2005; ratinov and roth, 2009; <papid> W09-1119 </papid>ritter et al , 2011) <papid> D11-1141 </papid>as subroutine to identify named person entities, though we are also interested in unnamed persons such as my teacher?</citsent>
<aftsection>
<nextsent>and pronouns.
</nextsent>
<nextsent>it is related to semantic role 660labeling (srl) (gildea and jurafsky, 2002; <papid> J02-3001 </papid>punyakanok, roth, and yih, 2008) but differs critically in that our roles are not tied to specific verb predi cates.</nextsent>
<nextsent>methods.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2675">
<title id=" N12-1084.xml">learning from bullying traces in social media </title>
<section> nlp task b: role labeling.  </section>
<citcontext>
<prevsection>
<prevsent>it uses named entity recognition(ner) (finkel, grenager, and manning, 2005; ratinov and roth, 2009; <papid> W09-1119 </papid>ritter et al , 2011) <papid> D11-1141 </papid>as subroutine to identify named person entities, though we are also interested in unnamed persons such as my teacher?</prevsent>
<prevsent>and pronouns.</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
it is related to semantic role 660labeling (srl) (gildea and jurafsky, 2002; <papid> J02-3001 </papid>punyakanok, roth, and yih, 2008) but differs critically in that our roles are not tied to specific verb predi cates.</citsent>
<aftsection>
<nextsent>methods.
</nextsent>
<nextsent>our annotators labeled each token in the 684 bullying traces with the tags a, b, r, v, and for not-a-person.
</nextsent>
<nextsent>there are11,751 tokens in total.
</nextsent>
<nextsent>similar to the sequential tagging formulation (ma`rquez et al , 2005; liu et al , 2010), <papid> C10-1079 </papid>we trained linear crf to label each token in the tweet with the crf++ package (http://crfpp.sourceforge.net/).as standard in linear crfs, we used pairwise label features f(yi1, yi) and input features f(yi,w),where s are binary indicator functions on the values of their arguments and is the text.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2676">
<title id=" N12-1084.xml">learning from bullying traces in social media </title>
<section> nlp task b: role labeling.  </section>
<citcontext>
<prevsection>
<prevsent>our annotators labeled each token in the 684 bullying traces with the tags a, b, r, v, and for not-a-person.
</prevsent>
<prevsent>there are11,751 tokens in total.
</prevsent>
</prevsection>
<citsent citstr=" C10-1079 ">
similar to the sequential tagging formulation (ma`rquez et al , 2005; liu et al , 2010), <papid> C10-1079 </papid>we trained linear crf to label each token in the tweet with the crf++ package (http://crfpp.sourceforge.net/).as standard in linear crfs, we used pairwise label features f(yi1, yi) and input features f(yi,w),where s are binary indicator functions on the values of their arguments and is the text.</citsent>
<aftsection>
<nextsent>in the following, we introduce our input features using the example tweet ?@username ill tell vinny you bullied me.?
</nextsent>
<nextsent>with the current token wi =vinny?: (i) the token, lemma, and pos tag of the five tokens around position i. for example,fbully,wi1=tell(yi,w) will be 1 if the current token has label yi = bully??
</nextsent>
<nextsent>and wi1 = tell??.
</nextsent>
<nextsent>similarly, fvictim,posi+2=v bd(yi,w) will be 1 if yi = victim??
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2677">
<title id=" N12-1084.xml">learning from bullying traces in social media </title>
<section> nlp task c: sentiment analysis.  </section>
<citcontext>
<prevsection>
<prevsent>therefore, there is considerable interest among social scientists to understand teasing in bullying traces.methods.
</prevsent>
<prevsent>one first task is to identify teasing bullying traces.
</prevsent>
</prevsection>
<citsent citstr=" P04-1035 ">
we formulated it as binary classification problem, similar to classic positive/negative sentiment classification (pang and lee, 2004).<papid> P04-1035 </papid></citsent>
<aftsection>
<nextsent>our annotators labeled each of the 684 bullying traces in task as teasing (99) or not (585).
</nextsent>
<nextsent>we used thesame feature representations, classifiers and parameter tuning as in section 3 and 10-fold cross validation procedure.
</nextsent>
<nextsent>results.
</nextsent>
<nextsent>the best cross validation accuracy of 89% is obtained by svm(linear) + 1g2g.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2678">
<title id=" N12-1084.xml">learning from bullying traces in social media </title>
<section> nlp task c: sentiment analysis.  </section>
<citcontext>
<prevsection>
<prevsent>discussions.
</prevsent>
<prevsent>specialized word normalization for social media text may significantly improve performance.
</prevsent>
</prevsection>
<citsent citstr=" D11-1052 ">
for example, word lengthening can be identified and used as cues for teasing (brody and diakopoulos, 2011).<papid> D11-1052 </papid></citsent>
<aftsection>
<nextsent>teasing is diverse in its form and content.
</nextsent>
<nextsent>our training set is perhaps too small.
</nextsent>
<nextsent>borrowing training data from other corpora, such as one-liner jokes (mihalcea and strapparava, 2005), <papid> H05-1067 </papid>may be helpful.</nextsent>
<nextsent>methods.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2679">
<title id=" N12-1084.xml">learning from bullying traces in social media </title>
<section> nlp task c: sentiment analysis.  </section>
<citcontext>
<prevsection>
<prevsent>teasing is diverse in its form and content.
</prevsent>
<prevsent>our training set is perhaps too small.
</prevsent>
</prevsection>
<citsent citstr=" H05-1067 ">
borrowing training data from other corpora, such as one-liner jokes (mihalcea and strapparava, 2005), <papid> H05-1067 </papid>may be helpful.</citsent>
<aftsection>
<nextsent>methods.
</nextsent>
<nextsent>given the large volume of bullying traces, methods for automatically analyzing what people are talking about are needed.
</nextsent>
<nextsent>latent topic models allow us to extract the main topics in bullying trace sto facilitate understanding.
</nextsent>
<nextsent>we used latent dirich let al ocation (lda) (blei, ng, and jordan, 2003) as our exploratory tool.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2682">
<title id=" P04-3007.xml">exploiting aggregate properties of bilingual dictionaries for distinguishing senses of english words and inducing english sense clusters </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>figure 4 also presents flat clusters automatically derived from the tree, as well as listing of some foreign words associated with particular clusters.
</prevsent>
<prevsent>figure 3: induced sense hierarchy for the word vital?
</prevsent>
</prevsection>
<citsent citstr=" J98-1003 ">
there is distinguished history of research extracting lexical semantic relationships from bilingual dictionaries (copestakeet al, 1995; chen and chang, 1998).<papid> J98-1003 </papid></citsent>
<aftsection>
<nextsent>there is also longstanding goal of mapping translations and senses in multiple languages in linked ontology structure (resnik and yarowsky, 1997; risk, 1989; vossen, 1998).
</nextsent>
<nextsent>the recent work of ploux and ji (2003) <papid> J03-2001 </papid>has some similarities to the techniques presented herein that it considers topological properties of the graph of syn onymy relationships between words.</nextsent>
<nextsent>the current paper can be distinguished on number of dimensions, including our much greater range of participating languages, and the fundamentalalgorithmic linkage between multilingual translation distributions and monolingual synonymy clusters.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2683">
<title id=" P04-3007.xml">exploiting aggregate properties of bilingual dictionaries for distinguishing senses of english words and inducing english sense clusters </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>there is distinguished history of research extracting lexical semantic relationships from bilingual dictionaries (copestakeet al, 1995; chen and chang, 1998).<papid> J98-1003 </papid></prevsent>
<prevsent>there is also longstanding goal of mapping translations and senses in multiple languages in linked ontology structure (resnik and yarowsky, 1997; risk, 1989; vossen, 1998).</prevsent>
</prevsection>
<citsent citstr=" J03-2001 ">
the recent work of ploux and ji (2003) <papid> J03-2001 </papid>has some similarities to the techniques presented herein that it considers topological properties of the graph of syn onymy relationships between words.</citsent>
<aftsection>
<nextsent>the current paper can be distinguished on number of dimensions, including our much greater range of participating languages, and the fundamentalalgorithmic linkage between multilingual translation distributions and monolingual synonymy clusters.
</nextsent>
<nextsent>4in both vital?
</nextsent>
<nextsent>and strike?
</nextsent>
<nextsent>examples, the rendered hierarchical clusterings were pruned (automatically) in order to fit in this paper.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2684">
<title id=" P04-1066.xml">improving ibm word alignment model 1 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we investigate number of simple methods for improving the word-alignment accuracy of ibm model 1.
</prevsent>
<prevsent>we demonstrate reduction in alignment error rate of approximately 30% resulting from (1) giving extra weight to the probability of alignment to the null word, (2) smoothing probability estimates for rare words, and (3) using simple heuristic estimation method to initialize, or replace, em training of model parameters.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
ibm model 1 (brown et al, 1993<papid> J93-2003 </papid>a) is word alignment model that is widely used in working with parallel bilingual corpora.</citsent>
<aftsection>
<nextsent>it was originally developed to provide reasonable initial parameter estimates for more complex word-alignment models, but it has subsequently found host of additional uses.
</nextsent>
<nextsent>among the applications of model 1 are segmenting long sentences into subsentental units for improved word alignment (nevado et al,2003), extracting parallel sentences from comparable corpora (munteanu et al, 2004), <papid> N04-1034 </papid>bilingual sentence alignment (moore, 2002), aligning syntactic tree fragments (ding et al, 2003), and estimating phrase translation probabilities (venugopal et al, 2003).<papid> P03-1041 </papid></nextsent>
<nextsent>furthermore, at the 2003 johns hopkins summer workshop on statistical machine translation, large number of features were tested to discover which ones could improve state-of-the-arttranslation system, and the only feature that produced truly significant improvement?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2688">
<title id=" P04-1066.xml">improving ibm word alignment model 1 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>ibm model 1 (brown et al, 1993<papid> J93-2003 </papid>a) is word alignment model that is widely used in working with parallel bilingual corpora.</prevsent>
<prevsent>it was originally developed to provide reasonable initial parameter estimates for more complex word-alignment models, but it has subsequently found host of additional uses.</prevsent>
</prevsection>
<citsent citstr=" N04-1034 ">
among the applications of model 1 are segmenting long sentences into subsentental units for improved word alignment (nevado et al,2003), extracting parallel sentences from comparable corpora (munteanu et al, 2004), <papid> N04-1034 </papid>bilingual sentence alignment (moore, 2002), aligning syntactic tree fragments (ding et al, 2003), and estimating phrase translation probabilities (venugopal et al, 2003).<papid> P03-1041 </papid></citsent>
<aftsection>
<nextsent>furthermore, at the 2003 johns hopkins summer workshop on statistical machine translation, large number of features were tested to discover which ones could improve state-of-the-arttranslation system, and the only feature that produced truly significant improvement?
</nextsent>
<nextsent>was the model 1 score (och et al, 2004).<papid> N04-1021 </papid></nextsent>
<nextsent>despite the fact that ibm model 1 is so widely used, essentially no attention seems to have been paid to whether it is possible to improve on the standard expectation-maximization (em) procedure for estimating its parameters.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2689">
<title id=" P04-1066.xml">improving ibm word alignment model 1 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>ibm model 1 (brown et al, 1993<papid> J93-2003 </papid>a) is word alignment model that is widely used in working with parallel bilingual corpora.</prevsent>
<prevsent>it was originally developed to provide reasonable initial parameter estimates for more complex word-alignment models, but it has subsequently found host of additional uses.</prevsent>
</prevsection>
<citsent citstr=" P03-1041 ">
among the applications of model 1 are segmenting long sentences into subsentental units for improved word alignment (nevado et al,2003), extracting parallel sentences from comparable corpora (munteanu et al, 2004), <papid> N04-1034 </papid>bilingual sentence alignment (moore, 2002), aligning syntactic tree fragments (ding et al, 2003), and estimating phrase translation probabilities (venugopal et al, 2003).<papid> P03-1041 </papid></citsent>
<aftsection>
<nextsent>furthermore, at the 2003 johns hopkins summer workshop on statistical machine translation, large number of features were tested to discover which ones could improve state-of-the-arttranslation system, and the only feature that produced truly significant improvement?
</nextsent>
<nextsent>was the model 1 score (och et al, 2004).<papid> N04-1021 </papid></nextsent>
<nextsent>despite the fact that ibm model 1 is so widely used, essentially no attention seems to have been paid to whether it is possible to improve on the standard expectation-maximization (em) procedure for estimating its parameters.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2690">
<title id=" P04-1066.xml">improving ibm word alignment model 1 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>among the applications of model 1 are segmenting long sentences into subsentental units for improved word alignment (nevado et al,2003), extracting parallel sentences from comparable corpora (munteanu et al, 2004), <papid> N04-1034 </papid>bilingual sentence alignment (moore, 2002), aligning syntactic tree fragments (ding et al, 2003), and estimating phrase translation probabilities (venugopal et al, 2003).<papid> P03-1041 </papid></prevsent>
<prevsent>furthermore, at the 2003 johns hopkins summer workshop on statistical machine translation, large number of features were tested to discover which ones could improve state-of-the-arttranslation system, and the only feature that produced truly significant improvement?</prevsent>
</prevsection>
<citsent citstr=" N04-1021 ">
was the model 1 score (och et al, 2004).<papid> N04-1021 </papid></citsent>
<aftsection>
<nextsent>despite the fact that ibm model 1 is so widely used, essentially no attention seems to have been paid to whether it is possible to improve on the standard expectation-maximization (em) procedure for estimating its parameters.
</nextsent>
<nextsent>this may be due in part to the fact that brown et al (1993<papid> J93-2003 </papid>a) proved that the log-likelihood objective function for model 1 is strictly concave function of the model parameters, so that it has unique local maximum.</nextsent>
<nextsent>this, in turn,means that em training will converge to that maximum from any starting point in which none of the initial parameter values is zero.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2699">
<title id=" P04-1066.xml">improving ibm word alignment model 1 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>if one equates optimum parameter estimation with finding the global maximum for the likelihood of the training data,then this result would seem to show no improvement is possible.however, in virtually every application of statistical techniques in natural-language processing, maximizing the likelihood of the training data causes over fitting, resulting in lower task performance than some other estimates for the model parameters.
</prevsent>
<prevsent>this is implicitly recognized in the widespread adoption of early stopping in estimating the parameters of model 1.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
brown et al (1993<papid> J93-2003 </papid>a) stopped after only one iteration of em in using model 1 to initializetheir model 2, and och and ney (2003) <papid> J03-1002 </papid>stop after five iterations in using model 1 to initialize the hmm word-alignment model.</citsent>
<aftsection>
<nextsent>both of these are far short of convergence to the maximum likelihood estimates for the model parameters.
</nextsent>
<nextsent>we have identified at least two ways in which the standard em training method for model 1leads to sub optimal performance in terms of word alignment accuracy.
</nextsent>
<nextsent>in this paper we show that by addressing these issues, substantial improvements in word-alignment accuracy can be achieved.
</nextsent>
<nextsent>model 1 is probabilistic generative model within framework that assumes source sentence of length translates as target sentence , according to the following stochastic process: ? length for sentence is generated.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2706">
<title id=" P04-1066.xml">improving ibm word alignment model 1 </title>
<section> smoothing translation counts.  </section>
<citcontext>
<prevsection>
<prevsent>we arbitrarily chose |v | to be 100,000, which is some what more than the total number of distinct words in our target language training data.
</prevsent>
<prevsent>the value of is empirically optimized on annotated development test data.this sort of add-n?
</prevsent>
</prevsection>
<citsent citstr=" P96-1041 ">
smoothing has poor reputation in statistical nlp, because it has repeatedly been shown to perform badly compared to other methods of smoothing higher-order n-gram models for statistical language modeling (e.g., chen and goodman, 1996).<papid> P96-1041 </papid></citsent>
<aftsection>
<nextsent>in those studies, however, add-n smoothing was used to smooth bigram or trigrammodels.
</nextsent>
<nextsent>add-n smoothing is way of smoothing with uniform distribution, so it is not surprising that it performs poorly in language modeling when it is compared to smoothing with higher order models; e.g, smoothing trigrams with bigrams or smoothing bigrams with unigrams.
</nextsent>
<nextsent>in situations where smoothing with uniform distribution is appropriate, it is not clear that add-n is bad way to do it.
</nextsent>
<nextsent>furthermore, we would argue that the word translation probabilities of model 1 are case where there is no clearly better alternative to uniform distribution as the smoothing distribution.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2707">
<title id=" P04-1066.xml">improving ibm word alignment model 1 </title>
<section> initializing model 1 with heuristic.  </section>
<citcontext>
<prevsection>
<prevsent>the unspoken justification for this is that em training of model 1 will always converge to the same set of parameter values from any set of initial values, so the intial values should not matter.
</prevsent>
<prevsent>but this is only the case if we want to obtain the parameter values at convergence, and we have strong reasons to believe that these values do not produce the most accurate sentence alignments.
</prevsent>
</prevsection>
<citsent citstr=" J93-1003 ">
even though em will head towards those values from any initial position in the parameter space, there may be some starting points we can systematically find that will take us closer to the optimal parameter values for alignment accuracy along the way.to test whether better set of initial parameter estimates can improve model 1 alignment accuracy, we use heuristic model based on the log likelihood-ratio (llr) statistic recommended by dunning (1993).<papid> J93-1003 </papid></citsent>
<aftsection>
<nextsent>we chose this statistic because ithas previously been found to be effective for automatically constructing translation lexicons (e.g., melamed, 2000; <papid> J00-2004 </papid>moore, 2001).<papid> W01-1411 </papid></nextsent>
<nextsent>in our application, the statistic can be defined by the following formula: ? t??{t,t} ? s??{s,s} c(t?, s?)</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2708">
<title id=" P04-1066.xml">improving ibm word alignment model 1 </title>
<section> initializing model 1 with heuristic.  </section>
<citcontext>
<prevsection>
<prevsent>but this is only the case if we want to obtain the parameter values at convergence, and we have strong reasons to believe that these values do not produce the most accurate sentence alignments.
</prevsent>
<prevsent>even though em will head towards those values from any initial position in the parameter space, there may be some starting points we can systematically find that will take us closer to the optimal parameter values for alignment accuracy along the way.to test whether better set of initial parameter estimates can improve model 1 alignment accuracy, we use heuristic model based on the log likelihood-ratio (llr) statistic recommended by dunning (1993).<papid> J93-1003 </papid></prevsent>
</prevsection>
<citsent citstr=" J00-2004 ">
we chose this statistic because ithas previously been found to be effective for automatically constructing translation lexicons (e.g., melamed, 2000; <papid> J00-2004 </papid>moore, 2001).<papid> W01-1411 </papid></citsent>
<aftsection>
<nextsent>in our application, the statistic can be defined by the following formula: ? t??{t,t} ? s??{s,s} c(t?, s?)
</nextsent>
<nextsent>log p(t?|s?) p(t?)
</nextsent>
<nextsent>(4)in this formula and mean that the corresponding words occur in the respective target and source sentences of an aligned sentence pair, and mean that the corresponding words do not occur in the respective sentences, t?
</nextsent>
<nextsent>and s?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2709">
<title id=" P04-1066.xml">improving ibm word alignment model 1 </title>
<section> initializing model 1 with heuristic.  </section>
<citcontext>
<prevsection>
<prevsent>but this is only the case if we want to obtain the parameter values at convergence, and we have strong reasons to believe that these values do not produce the most accurate sentence alignments.
</prevsent>
<prevsent>even though em will head towards those values from any initial position in the parameter space, there may be some starting points we can systematically find that will take us closer to the optimal parameter values for alignment accuracy along the way.to test whether better set of initial parameter estimates can improve model 1 alignment accuracy, we use heuristic model based on the log likelihood-ratio (llr) statistic recommended by dunning (1993).<papid> J93-1003 </papid></prevsent>
</prevsection>
<citsent citstr=" W01-1411 ">
we chose this statistic because ithas previously been found to be effective for automatically constructing translation lexicons (e.g., melamed, 2000; <papid> J00-2004 </papid>moore, 2001).<papid> W01-1411 </papid></citsent>
<aftsection>
<nextsent>in our application, the statistic can be defined by the following formula: ? t??{t,t} ? s??{s,s} c(t?, s?)
</nextsent>
<nextsent>log p(t?|s?) p(t?)
</nextsent>
<nextsent>(4)in this formula and mean that the corresponding words occur in the respective target and source sentences of an aligned sentence pair, and mean that the corresponding words do not occur in the respective sentences, t?
</nextsent>
<nextsent>and s?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2710">
<title id=" P04-1066.xml">improving ibm word alignment model 1 </title>
<section> initializing model 1 with heuristic.  </section>
<citcontext>
<prevsection>
<prevsent>to maintain this property, for each source word we compute the sum of the 1this is not the form in which the llr statistic is usually presented, but it can easily be shown by basic algebra to be equivalent to ??
</prevsent>
<prevsent>in dunnings paper.
</prevsent>
</prevsection>
<citsent citstr=" W04-3243 ">
see moore (2004) <papid> W04-3243 </papid>for details.llr scores over all target words, but we then divide every llr score by the single largest of these sums.</citsent>
<aftsection>
<nextsent>thus the source word with the highest llrscore sum receives conditional probability distribution over target words summing to 1, but the corresponding distribution for every other source word sums to less than 1, reserving some probability mass for target words not seen with that word, with more probability mass being reserved the rarer the word.
</nextsent>
<nextsent>there is no guarantee, of course, that this is the optimal way of discounting the probabilities assigned to less frequent words.
</nextsent>
<nextsent>to allow wider range of possibilities, we add one more parameter to the model by raising each llr score to an empirically optimized exponent before summing the resulting scores and scaling them from 0 to 1 as described above.
</nextsent>
<nextsent>choosing an exponent less than 1.0decreases the degree to which low scores are discounted, and choosing an exponent greater than 1.0 increases degree of discounting.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2711">
<title id=" P04-1066.xml">improving ibm word alignment model 1 </title>
<section> training and evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>hence we initialize the distribution for the null word to be the unigram distribution of target words, so that frequent function words will receive higher probability of aligning to the null word than rare words, which tend to be content words that do have translation.
</prevsent>
<prevsent>finally, we also effectively add extra null words to every sentence in this heuristic model, by multiplying the null word probabilities by constant, as described in section 5.
</prevsent>
</prevsection>
<citsent citstr=" W03-0301 ">
we trained and evaluated our various modification sto model 1 on data from the bilingual word alignment workshop held at hlt-naacl 2003 (mihal cea and pedersen, 2003).<papid> W03-0301 </papid></citsent>
<aftsection>
<nextsent>we used subset of the canadian hansa rds bilingual corpus supplied for the workshop, comprising 500,000 english-frenchsentences pairs, including 37 sentence pairs designated as trial?
</nextsent>
<nextsent>data, and 447 sentence pairs designated as test data.
</nextsent>
<nextsent>the trial and test data had been manually aligned at the word level, noting particular pairs of words either as sure?
</nextsent>
<nextsent>or possible?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2720">
<title id=" P01-1035.xml">serial combination of rules and statistics a case study in czech tagging </title>
<section> tagging of inflective languages.  </section>
<citcontext>
<prevsection>
<prevsent>the average tagset contains about 1,000 - 2,000 distinct tags; the size of the set of possible and plausible tags can reach several thousands.
</prevsent>
<prevsent>apart from agglutinative languages such as turkish, finnish and hungarian (see e.g.
</prevsent>
</prevsection>
<citsent citstr=" P98-1063 ">
(hakkani-tur et al, 2000)), and basque (ezeiza et al, 1998), <papid> P98-1063 </papid>which pose quite different and inthe end less severe problems, there have been attempts at solving this problem for some of the highly inflectional european languages, such as (daelemans et al, 1996), (<papid> W96-0102 </papid>erjavec et al, 1999) (slovenian), (hajic?</citsent>
<aftsection>
<nextsent>and hladka?, 1997), (hajic?
</nextsent>
<nextsent>and hladka?, 1998) (czech) and (hajic?, 2000) (five central and eastern european languages), but so far no system has reached - in the absolute terms - performance comparable to english tagging (such as (ratnaparkhi, 1996)), <papid> W96-0213 </papid>which stands around or above 97%.</nextsent>
<nextsent>for example, (hajic?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2721">
<title id=" P01-1035.xml">serial combination of rules and statistics a case study in czech tagging </title>
<section> tagging of inflective languages.  </section>
<citcontext>
<prevsection>
<prevsent>the average tagset contains about 1,000 - 2,000 distinct tags; the size of the set of possible and plausible tags can reach several thousands.
</prevsent>
<prevsent>apart from agglutinative languages such as turkish, finnish and hungarian (see e.g.
</prevsent>
</prevsection>
<citsent citstr=" W96-0102 ">
(hakkani-tur et al, 2000)), and basque (ezeiza et al, 1998), <papid> P98-1063 </papid>which pose quite different and inthe end less severe problems, there have been attempts at solving this problem for some of the highly inflectional european languages, such as (daelemans et al, 1996), (<papid> W96-0102 </papid>erjavec et al, 1999) (slovenian), (hajic?</citsent>
<aftsection>
<nextsent>and hladka?, 1997), (hajic?
</nextsent>
<nextsent>and hladka?, 1998) (czech) and (hajic?, 2000) (five central and eastern european languages), but so far no system has reached - in the absolute terms - performance comparable to english tagging (such as (ratnaparkhi, 1996)), <papid> W96-0213 </papid>which stands around or above 97%.</nextsent>
<nextsent>for example, (hajic?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2722">
<title id=" P01-1035.xml">serial combination of rules and statistics a case study in czech tagging </title>
<section> tagging of inflective languages.  </section>
<citcontext>
<prevsection>
<prevsent>(hakkani-tur et al, 2000)), and basque (ezeiza et al, 1998), <papid> P98-1063 </papid>which pose quite different and inthe end less severe problems, there have been attempts at solving this problem for some of the highly inflectional european languages, such as (daelemans et al, 1996), (<papid> W96-0102 </papid>erjavec et al, 1999) (slovenian), (hajic?</prevsent>
<prevsent>and hladka?, 1997), (hajic?</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
and hladka?, 1998) (czech) and (hajic?, 2000) (five central and eastern european languages), but so far no system has reached - in the absolute terms - performance comparable to english tagging (such as (ratnaparkhi, 1996)), <papid> W96-0213 </papid>which stands around or above 97%.</citsent>
<aftsection>
<nextsent>for example, (hajic?
</nextsent>
<nextsent>and hladka?, 1998) report results on czech slightly above 93% only.
</nextsent>
<nextsent>one has to realize that even though such performance might be adequate for some tasks (such as word sense disambiguation), for many other (such as parsing or translation) the implied sentence error rate at 50% or more is simply too much to deal with.
</nextsent>
<nextsent>1.1 statistical tagging.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2723">
<title id=" P01-1035.xml">serial combination of rules and statistics a case study in czech tagging </title>
<section> tagging of inflective languages.  </section>
<citcontext>
<prevsection>
<prevsent>1.2 manual rule-based systems.
</prevsent>
<prevsent>the idea of tagging by means of hand-written disambiguation rules has been put forward and implemented for the first time in the form of constraint-based grammars (karlsson et al, 1995).
</prevsent>
</prevsection>
<citsent citstr=" P97-1032 ">
from languages we are acquainted with, the method has been applied on larger scale only to english (karlsson et al, 1995), (samuelsson and voutilainen, 1997), <papid> P97-1032 </papid>and french (chanod and tapanainen, 1995).<papid> E95-1021 </papid></citsent>
<aftsection>
<nextsent>also (bick, 1996) and (bick, 2000) use manually written rules for brazilian portuguese, and there are several publications by oflazer for turkish.authors of such systems claim that handwritten systems can perform better than systems based on machine learning (samuelsson and voutilainen, 1997); <papid> P97-1032 </papid>however, except for the work cited, comparison is difficult to impossible due tothe fact that they do not use the standard evaluation techniques (and not even the same data).</nextsent>
<nextsent>butthe substantial disadvantage is that the development of manual rule-based systems is demanding and requires good deal of very subtle linguistic expertise and skills if full disambiguation also of difficult?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2724">
<title id=" P01-1035.xml">serial combination of rules and statistics a case study in czech tagging </title>
<section> tagging of inflective languages.  </section>
<citcontext>
<prevsection>
<prevsent>1.2 manual rule-based systems.
</prevsent>
<prevsent>the idea of tagging by means of hand-written disambiguation rules has been put forward and implemented for the first time in the form of constraint-based grammars (karlsson et al, 1995).
</prevsent>
</prevsection>
<citsent citstr=" E95-1021 ">
from languages we are acquainted with, the method has been applied on larger scale only to english (karlsson et al, 1995), (samuelsson and voutilainen, 1997), <papid> P97-1032 </papid>and french (chanod and tapanainen, 1995).<papid> E95-1021 </papid></citsent>
<aftsection>
<nextsent>also (bick, 1996) and (bick, 2000) use manually written rules for brazilian portuguese, and there are several publications by oflazer for turkish.authors of such systems claim that handwritten systems can perform better than systems based on machine learning (samuelsson and voutilainen, 1997); <papid> P97-1032 </papid>however, except for the work cited, comparison is difficult to impossible due tothe fact that they do not use the standard evaluation techniques (and not even the same data).</nextsent>
<nextsent>butthe substantial disadvantage is that the development of manual rule-based systems is demanding and requires good deal of very subtle linguistic expertise and skills if full disambiguation also of difficult?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2726">
<title id=" P01-1035.xml">serial combination of rules and statistics a case study in czech tagging </title>
<section> tagging of inflective languages.  </section>
<citcontext>
<prevsection>
<prevsent>1.3 system combination.
</prevsent>
<prevsent>combination of (manual) rule-writing and statistical learning has been studied before.
</prevsent>
</prevsection>
<citsent citstr=" P00-1016 ">
e.g., (ngai and yarowsky, 2000) <papid> P00-1016 </papid>and (ngai, 2001) prov idea thorough description of many experiments involving rule-based systems and statistical learners for np bracketing.</citsent>
<aftsection>
<nextsent>for tagging, combination of purely statistical classifiers has been described(hladka?, 2000), with about 3% relative improvement (error reduction from 18.6% to 18%, trained on small data) over the best original system.
</nextsent>
<nextsent>we regard such systems as working in parallel, since all the original classifiers run independently of each other.in the present study, we have chosen different strategy (similar to the one described for other types of languages in (tapanainen and voutilainen, 1994), (ezeiza et al, 1998) <papid> P98-1063 </papid>and (hakkanitur et al, 2000)).</nextsent>
<nextsent>at the same time, the rule based component is known to perform well in eliminating the incorrect alternatives2, rather than picking the correct one under all circumstances.moreover, the rule-based system used can examine the whole sentential context, again difficult thing for statistical system3.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2728">
<title id=" P01-1035.xml">serial combination of rules and statistics a case study in czech tagging </title>
<section> the statistical component.  </section>
<citcontext>
<prevsection>
<prevsent>we use the usual equal-weight formula for f-measure:   fiffffifl  !#%$&amp; ()ff#fl#*+ + ),ff#fl-.!ffi%$&amp; /0()ff#flffi*+ +21 where3 465, 75#8 9: ; =?  $a@ff-&b;!dce f.gihjfl#$k,ff#fl flfm* nbo ; ; =?  $p@ff &b;!qnff-&amp;6ff ,*fmff#r6o ; ands 4 utffitv ; =?  $a@ff-&b;!dce.f gihjfl#$k,ff#fl fqfw*anxo ; ; =?  $p@ff &b;!v.&yr;*fw*6o ;
</prevsent>
<prevsent>3.1 the hmm tagger.
</prevsent>
</prevsection>
<citsent citstr=" P99-1023 ">
we have used an hmm tagger in the usual source channel setting, fine-tuned to perfection using  3-gram tag language model z\[ffi]a^_ ] ^ffi`  1 ] ^ffi`ba7c , tag-to-word lexical (translation) model using bigram histories instead of just same word conditioning z\[ffide^_ ]a^ 1 ]a^ffi`ba7c 5 , 5first used in (thede and harper, 1999), <papid> P99-1023 </papid>as far as we know.</citsent>
<aftsection>
<nextsent> bucketed linear interpolation smoothing for both models.
</nextsent>
<nextsent>thus the hmm tagger outputs sequence of tags according to the usual equation hgei jek:gml)nvo [qpr_ c [ c 1 where [ ctsvu ^xwqy7z{z | zl}-~ipax??[ffi] ^_ ]a^fi`  1 ]a^ffi`bac 1 and [qpr_ cesu ^mwqy7z{z | zl}q~?p x?)[ffid?^_ ]a^ 1 ]a^ffi`ba7c?
</nextsent>
<nextsent>the tagger has been trained in the usual way, using part of the training data as heldout data for smoothing of the two models employed.
</nextsent>
<nextsent>there is no threshold being applied for low counts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2729">
<title id=" P03-2036.xml">comparison between cfg filtering techniques for ltag and hpsg </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we demonstrate that an approximation of hpsg produces more effective cfg filter than that of ltag.
</prevsent>
<prevsent>we also investigate the reason for that difference.
</prevsent>
</prevsection>
<citsent citstr=" C88-2121 ">
various parsing techniques have been developed for lexicalized grammars such as lexicalized tree adjoining grammar (ltag) (schabes et al,1988), <papid> C88-2121 </papid>and head-driven phrase structure grammar (hpsg) (pollard and sag, 1994).</citsent>
<aftsection>
<nextsent>along with the independent development of parsing techniques for individual grammar formalisms, some of them have been adapted to other formalisms (schabes et al., 1988; <papid> C88-2121 </papid>van noord, 1994; yoshida et al, 1999;torisawa et al, 2000).</nextsent>
<nextsent>however, these realizations sometimes exhibit quite different performance in each grammar formalism (yoshida et al, 1999;yoshinaga et al, 2001).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2731">
<title id=" P03-2036.xml">comparison between cfg filtering techniques for ltag and hpsg </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, these realizations sometimes exhibit quite different performance in each grammar formalism (yoshida et al, 1999;yoshinaga et al, 2001).
</prevsent>
<prevsent>if we could identify an algorithmic difference that causes performance difference, it would reveal advantages and disadvantages of the different realizations.
</prevsent>
</prevsection>
<citsent citstr=" P90-1036 ">
this should also allow us to integrate the advantages of the realizations intoone generic parsing technique, which yields the further advancement of the whole parsing community.in this paper, we compare cfg filtering techniques for ltag (harbusch, 1990; <papid> P90-1036 </papid>poller and becker, 1998) and hpsg (torisawa et al, 2000; kiefer and krieger, 2000), following an approach to parsing comparison among different grammar formalisms (yoshinaga et al, 2001).</citsent>
<aftsection>
<nextsent>the key ideaof the approach is to use strongly equivalent grammars, which generate equivalent parse results for the same input, obtained by grammar conversion as demonstrated by yoshinaga and miyao (2001).
</nextsent>
<nextsent>the parsers with cfg filtering predict possible parse trees by cfg approximated from given grammar.
</nextsent>
<nextsent>comparison of those parsers are interesting because effective cfg filters allow us to bring the empirical time complexity of the parsers close to that of cfg parsing.
</nextsent>
<nextsent>investigating the difference between the ways of context-free (cf) approximation of ltag and hpsg will thereby enlighten way of further optimization for both techniques.we performed comparison between the existing cfg filtering techniques for ltag (poller and becker, 1998) and hpsg (torisawa et al, 2000), using strongly equivalent grammars obtained by converting ltags extracted from the penn tree bank (marcus et al, 1993) <papid> J93-2004 </papid>into hpsg-style.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2734">
<title id=" P03-2036.xml">comparison between cfg filtering techniques for ltag and hpsg </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the parsers with cfg filtering predict possible parse trees by cfg approximated from given grammar.
</prevsent>
<prevsent>comparison of those parsers are interesting because effective cfg filters allow us to bring the empirical time complexity of the parsers close to that of cfg parsing.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
investigating the difference between the ways of context-free (cf) approximation of ltag and hpsg will thereby enlighten way of further optimization for both techniques.we performed comparison between the existing cfg filtering techniques for ltag (poller and becker, 1998) and hpsg (torisawa et al, 2000), using strongly equivalent grammars obtained by converting ltags extracted from the penn tree bank (marcus et al, 1993) <papid> J93-2004 </papid>into hpsg-style.</citsent>
<aftsection>
<nextsent>we compared the parsers with respect to the size of the approximated cfg and its effectiveness as filter.
</nextsent>
<nextsent>in this section, we introduce grammar conversion (yoshinaga and miyao, 2001) and cfg filtering (harbusch, 1990; <papid> P90-1036 </papid>poller and becker, 1998; torisawa et al, 2000; kiefer and krieger, 2000).</nextsent>
<nextsent>2.1 grammar conversion.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2742">
<title id=" P03-2036.xml">comparison between cfg filtering techniques for ltag and hpsg </title>
<section> comparison with cfg filtering.  </section>
<citcontext>
<prevsection>
<prevsent>with the strongly equivalent grammars for section 2 of wsj parser g2 g2-4 g2-6 g2-8 g2-10 g2-21 pb 1.4 9.1 17.4 24.0 34.2 124.3 tnt 0.044 0.097 0.144 0.182 0.224 0.542
</prevsent>
<prevsent>in this section, we compare pair of cfg filtering techniques for ltag (poller and becker, 1998)and hpsg (torisawa et al, 2000) described in section 2.2.1 and 2.2.2.
</prevsent>
</prevsection>
<citsent citstr=" E03-1047 ">
we hereafter refer to pb and tnt for the c++ implementations of the former and valiant1 of the latter, respectively.2we first acquired ltags by method proposed in miyao et al (2003) <papid> E03-1047 </papid>from sections 2-21 ofthe wall street journal (wsj) in the penn tree bank (marcus et al, 1993) <papid> J93-2004 </papid>and its subsets.3 we then converted them into strongly equivalent hpsg-style grammars using the grammar conversion described in section 2.1.</citsent>
<aftsection>
<nextsent>table 1 shows the size of cfg approximated from the strongly equivalent grammars.
</nextsent>
<nextsent>gx, cfgpb, and cfgtnt henceforth refer to the ltag extracted from section of wsj and cfgs approximated from gx by pb and tnt, respectively.
</nextsent>
<nextsent>the size of cfgtnt is much larger than that of cfgpb.
</nextsent>
<nextsent>by investigating parsing performance using these cfgs, we show that the larger size of cfgtnt resulted in better parsing performance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2746">
<title id=" P04-1061.xml">corpus based induction of syntactic structure models of dependency and constituency </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the product model outperforms both components on their respective evaluation metrics, giving the best published figures for unsupervised dependency parsing and unsupervised constituency parsing.
</prevsent>
<prevsent>we also demonstrate that the combined model works and is robust cross-linguistically, being able to exploit either attachment or distributional regularities that are salient in the data.
</prevsent>
</prevsection>
<citsent citstr=" P92-1017 ">
the task of statistically inducing hierarchical syntactic structure over unannotated sentences of natural language has received great deal of attention (carroll and charniak, 1992; pereira and schabes, 1992; <papid> P92-1017 </papid>brill, 1993; <papid> P93-1035 </papid>stolcke and omohundro, 1994).</citsent>
<aftsection>
<nextsent>researchers have explored this problem for variety of reasons: to argue empirically against the poverty of the stimulus (clark, 2001), <papid> W01-0713 </papid>to use induction systems as first stage in constructing large treebanks (van zaanen, 2000), to build better language models (baker, 1979; chen, 1995), <papid> P95-1031 </papid>and to examine cognitive issues in language learning (solan et al, 2003).</nextsent>
<nextsent>an important distinction should be drawn between work primarily interested in theweak generative capacity of models, where modeling hierarchical structure is only useful insofar as it leads to improved models over observed structures (baker, 1979; chen, 1995), <papid> P95-1031 </papid>and work interested in the strong generative capacity of models, where the unobserved structure itself is evaluated (van zaa nen, 2000; clark, 2001; <papid> W01-0713 </papid>klein and manning, 2002).<papid> P02-1017 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2747">
<title id=" P04-1061.xml">corpus based induction of syntactic structure models of dependency and constituency </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the product model outperforms both components on their respective evaluation metrics, giving the best published figures for unsupervised dependency parsing and unsupervised constituency parsing.
</prevsent>
<prevsent>we also demonstrate that the combined model works and is robust cross-linguistically, being able to exploit either attachment or distributional regularities that are salient in the data.
</prevsent>
</prevsection>
<citsent citstr=" P93-1035 ">
the task of statistically inducing hierarchical syntactic structure over unannotated sentences of natural language has received great deal of attention (carroll and charniak, 1992; pereira and schabes, 1992; <papid> P92-1017 </papid>brill, 1993; <papid> P93-1035 </papid>stolcke and omohundro, 1994).</citsent>
<aftsection>
<nextsent>researchers have explored this problem for variety of reasons: to argue empirically against the poverty of the stimulus (clark, 2001), <papid> W01-0713 </papid>to use induction systems as first stage in constructing large treebanks (van zaanen, 2000), to build better language models (baker, 1979; chen, 1995), <papid> P95-1031 </papid>and to examine cognitive issues in language learning (solan et al, 2003).</nextsent>
<nextsent>an important distinction should be drawn between work primarily interested in theweak generative capacity of models, where modeling hierarchical structure is only useful insofar as it leads to improved models over observed structures (baker, 1979; chen, 1995), <papid> P95-1031 </papid>and work interested in the strong generative capacity of models, where the unobserved structure itself is evaluated (van zaa nen, 2000; clark, 2001; <papid> W01-0713 </papid>klein and manning, 2002).<papid> P02-1017 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2748">
<title id=" P04-1061.xml">corpus based induction of syntactic structure models of dependency and constituency </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also demonstrate that the combined model works and is robust cross-linguistically, being able to exploit either attachment or distributional regularities that are salient in the data.
</prevsent>
<prevsent>the task of statistically inducing hierarchical syntactic structure over unannotated sentences of natural language has received great deal of attention (carroll and charniak, 1992; pereira and schabes, 1992; <papid> P92-1017 </papid>brill, 1993; <papid> P93-1035 </papid>stolcke and omohundro, 1994).</prevsent>
</prevsection>
<citsent citstr=" W01-0713 ">
researchers have explored this problem for variety of reasons: to argue empirically against the poverty of the stimulus (clark, 2001), <papid> W01-0713 </papid>to use induction systems as first stage in constructing large treebanks (van zaanen, 2000), to build better language models (baker, 1979; chen, 1995), <papid> P95-1031 </papid>and to examine cognitive issues in language learning (solan et al, 2003).</citsent>
<aftsection>
<nextsent>an important distinction should be drawn between work primarily interested in theweak generative capacity of models, where modeling hierarchical structure is only useful insofar as it leads to improved models over observed structures (baker, 1979; chen, 1995), <papid> P95-1031 </papid>and work interested in the strong generative capacity of models, where the unobserved structure itself is evaluated (van zaa nen, 2000; clark, 2001; <papid> W01-0713 </papid>klein and manning, 2002).<papid> P02-1017 </papid></nextsent>
<nextsent>this paper falls into the latter category; we will be inducing models of linguistic constituency and dependency with the goal of recovering linguistically plausible structures.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2749">
<title id=" P04-1061.xml">corpus based induction of syntactic structure models of dependency and constituency </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also demonstrate that the combined model works and is robust cross-linguistically, being able to exploit either attachment or distributional regularities that are salient in the data.
</prevsent>
<prevsent>the task of statistically inducing hierarchical syntactic structure over unannotated sentences of natural language has received great deal of attention (carroll and charniak, 1992; pereira and schabes, 1992; <papid> P92-1017 </papid>brill, 1993; <papid> P93-1035 </papid>stolcke and omohundro, 1994).</prevsent>
</prevsection>
<citsent citstr=" P95-1031 ">
researchers have explored this problem for variety of reasons: to argue empirically against the poverty of the stimulus (clark, 2001), <papid> W01-0713 </papid>to use induction systems as first stage in constructing large treebanks (van zaanen, 2000), to build better language models (baker, 1979; chen, 1995), <papid> P95-1031 </papid>and to examine cognitive issues in language learning (solan et al, 2003).</citsent>
<aftsection>
<nextsent>an important distinction should be drawn between work primarily interested in theweak generative capacity of models, where modeling hierarchical structure is only useful insofar as it leads to improved models over observed structures (baker, 1979; chen, 1995), <papid> P95-1031 </papid>and work interested in the strong generative capacity of models, where the unobserved structure itself is evaluated (van zaa nen, 2000; clark, 2001; <papid> W01-0713 </papid>klein and manning, 2002).<papid> P02-1017 </papid></nextsent>
<nextsent>this paper falls into the latter category; we will be inducing models of linguistic constituency and dependency with the goal of recovering linguistically plausible structures.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2755">
<title id=" P04-1061.xml">corpus based induction of syntactic structure models of dependency and constituency </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the task of statistically inducing hierarchical syntactic structure over unannotated sentences of natural language has received great deal of attention (carroll and charniak, 1992; pereira and schabes, 1992; <papid> P92-1017 </papid>brill, 1993; <papid> P93-1035 </papid>stolcke and omohundro, 1994).</prevsent>
<prevsent>researchers have explored this problem for variety of reasons: to argue empirically against the poverty of the stimulus (clark, 2001), <papid> W01-0713 </papid>to use induction systems as first stage in constructing large treebanks (van zaanen, 2000), to build better language models (baker, 1979; chen, 1995), <papid> P95-1031 </papid>and to examine cognitive issues in language learning (solan et al, 2003).</prevsent>
</prevsection>
<citsent citstr=" P02-1017 ">
an important distinction should be drawn between work primarily interested in theweak generative capacity of models, where modeling hierarchical structure is only useful insofar as it leads to improved models over observed structures (baker, 1979; chen, 1995), <papid> P95-1031 </papid>and work interested in the strong generative capacity of models, where the unobserved structure itself is evaluated (van zaa nen, 2000; clark, 2001; <papid> W01-0713 </papid>klein and manning, 2002).<papid> P02-1017 </papid></citsent>
<aftsection>
<nextsent>this paper falls into the latter category; we will be inducing models of linguistic constituency and dependency with the goal of recovering linguistically plausible structures.
</nextsent>
<nextsent>we make no claims as to the cognitive plausibility of the induction mechanism swe present here; however, the ability of these systems to recover substantial linguistic patterns from surface yields alone does speak to the strength of support for these patterns in the data, and hence undermines arguments based on the poverty of the stimulus?
</nextsent>
<nextsent>(chomsky, 1965).
</nextsent>
<nextsent>most recent progress in unsupervised parsing has come from tree or phrase-structure grammar based models (clark, 2001; <papid> W01-0713 </papid>klein and manning, 2002),<papid> P02-1017 </papid>but there are compelling reasons to reconsider unsupervised dependency parsing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2759">
<title id=" P04-1061.xml">corpus based induction of syntactic structure models of dependency and constituency </title>
<section> an improved dependency model.  </section>
<citcontext>
<prevsection>
<prevsent>we now turn to an improved dependency model that addresses this problem.
</prevsent>
<prevsent>the dependency models discussed above are distinct from dependency models used inside high performance supervised probabilistic parsers in several ways.
</prevsent>
</prevsection>
<citsent citstr=" C96-1058 ">
first, in supervised models, head outward process is modeled (eisner, 1996; <papid> C96-1058 </papid>collins, 1999).</citsent>
<aftsection>
<nextsent>in such processes, heads generate sequence of arguments outward to the left or right, conditioning on not only the identity of the head and direction of the attachment, but also on some notion of distance or valence.
</nextsent>
<nextsent>moreover, in head-outward model, it is natural to model stop steps, where the final argument on each side of head is always the special symbol stop.
</nextsent>
<nextsent>models like paskin (2002)avoid modeling stop by generating the graph skeleton first, uniformly at random, then populating the words of conditioned on g. previous work(collins, 1999) has stressed the importance of including termination probabilities, which allows the graph structure to be generated jointly with the terminal words, precisely because it does allow the modeling of required dependents.
</nextsent>
<nextsent>we propose simple head-outward dependency model over word classes which includes model of valence, which we call dmv (for dependency model with valence).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2762">
<title id=" P04-1061.xml">corpus based induction of syntactic structure models of dependency and constituency </title>
<section> distributional constituency induction.  </section>
<citcontext>
<prevsection>
<prevsent>data clustering methods.
</prevsent>
<prevsent>in the most common case, the items are words, and one uses distributions over adjacent words to induce word classes.
</prevsent>
</prevsection>
<citsent citstr=" W00-0717 ">
previous work has shown that even this quite simple representation allows the induction of quite high quality word classes, largely corresponding to traditional parts of speech (finch, 1993; schutze, 1995; clark, 2000).<papid> W00-0717 </papid></citsent>
<aftsection>
<nextsent>a typical pattern would be that stocks and treasuries both frequently occur before the words fell and rose, and might therefore be put into the same class.
</nextsent>
<nextsent>clark (2001) <papid> W01-0713 </papid>and klein and manning (2002) <papid> P02-1017 </papid>show that this approach can be successfully usedfor discovering syntactic constituents as well.</nextsent>
<nextsent>how ever, as one might expect, it is easier to cluster word sequences (or word class sequences) than totell how to put them together into trees.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2782">
<title id=" P02-1059.xml">supervised ranking in open domain text summarization </title>
<section> test data and procedure.  </section>
<citcontext>
<prevsection>
<prevsent>a summary with compression rate ? is obtained by selecting top ? percent of the list.
</prevsent>
<prevsent>when coupled with find diversity, on the other hand, each probdt is set to work on each cluster discovered by the diversity component, producing multiple lists of sentences, each corresponding to one of the clusters identified.a summary is formed by collecting top ranking sentences from each list.evaluation was done by 10-fold cross validation.
</prevsent>
</prevsection>
<citsent citstr=" C96-2166 ">
for the purpose of comparison, we also ran the diversity based model as given in nomoto and matsumoto (2001c) and tfidf based ranking model (zechner, 1996) (<papid> C96-2166 </papid>call it model), which simply ranks sentences according to the tfidf score and selects those which rank highest.</citsent>
<aftsection>
<nextsent>recall that the diversity based model (dbs) (nomoto and matsumoto, 2001c) consists in find-diversity and the ranking model by zechner (1996), <papid> C96-2166 </papid>which they call reduce-redundancy.</nextsent>
<nextsent>tables 4-8 show performance of each probdt andits combination with the diversity (clustering) com ponent.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2784">
<title id=" P00-1029.xml">inducing probabilistic syllable classes using multivariate clustering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in rst step, we collect syllables by going through large text corpus, looking up the words and their syllabications in pronunciation dictionary and counting the occurrence frequencies of the syllable types.
</prevsent>
<prevsent>probabilistic syllable classes are then computed by applying maximum likelihood estimation from incomplete data via the em algorithm.
</prevsent>
</prevsection>
<citsent citstr=" P99-1014 ">
two-dimensional em-based clustering has been applied to tasks in syntax (rooth et al, 1999), <papid> P99-1014 </papid>but so far this approach has not been used to derive models of higher dimensionality and, to the best of our knowledge, this is the rst time that it is being applied to speech.</citsent>
<aftsection>
<nextsent>accordingly, we have trained 3- and 5-dimensional models for english and german syllable structure.the obtained models of syllable structure were evaluated in three ways.
</nextsent>
<nextsent>firstly, the 3-dimensional models were subjected to pseudo-disambiguation task, the result ofwhich shows that the onset is the most variable part of the syllable.
</nextsent>
<nextsent>secondly, the resulting syllable classes were qualitatively evaluated from phonological and phonotacticpoint of view.
</nextsent>
<nextsent>thirdly, 5-dimensional syllable model for german was tested in g2p conversion task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2790">
<title id=" P00-1029.xml">inducing probabilistic syllable classes using multivariate clustering </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>these comparative results emphasize the value of phonotactic knowledge and information on syllable structure and morphological structure for g2p conversion.
</prevsent>
<prevsent>in comparison across languages, word accuracy rate of 75.3% for our 5-dimensional german syllable model is slightly higher than the best data-driven method for english with 72% (damper et al, 1999).
</prevsent>
</prevsection>
<citsent citstr=" A00-2040 ">
recently, bouma (2000) <papid> A00-2040 </papid>has reported word accuracy of 92.6% for dutch, using `lazy  training strategy on data aligned with the correct phoneme string, and hand-crafted system that relied on large set of rule templates and many-to-one mapping of characters to graphemes preceding the actual g2p conversion.we are condent that judicious combination of phonological information of the type employed in our feasibility study with standard techniques such as g2p alignment of training data will produce pronunciation system with word accuracy that matches the one reported by bouma (2000).<papid> A00-2040 </papid></citsent>
<aftsection>
<nextsent>we believe, however, that for an optimally performing system as is desired for tts, an even more complex design will have to be adopted.in many languages, including english, german and dutch, access to morphological and phonological information is required to reliably predict the pronunciation of words; this view is further evidenced by the performance of the bell labs system, which relies on precisely this type of information.
</nextsent>
<nextsent>we agree with sproat (1998, p. 77) that it is unrealistic to expect optimal results from system that has no access to this type of information or is trained on data that are insucient for the task.
</nextsent>


</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2792">
<title id=" P03-1033.xml">flexible guidance generation using user model in spoken dialogue systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>according tothe spread of cellular phones, spoken dialogue systems via telephone enable us to obtain information from various places without any other special appa ratuses.however, the speech interface involves two inevitable problems: one is speech recognition errors, and the other is that much information can not be conveyed at once in speech communications.
</prevsent>
<prevsent>therefore, the dialogue strategies, which determine when to make guidance and what the system should tell to the user, are the essential factors.
</prevsent>
</prevsection>
<citsent citstr=" C00-1068 ">
to cope with speech recognition errors, several confirmation strategies have been proposed: confirmation management methods based on confidence measures of speech recognition results (komatani and kawahara, 2000; <papid> C00-1068 </papid>hazen et al, 2000) and implicit confirmation that includes previous recognition results into systems prompts (sturm et al, 1999).</citsent>
<aftsection>
<nextsent>in termsof determining what to say to the user, several studies have been done not only to output answers corresponding to users questions but also to generate cooperative responses (sadek, 1999).
</nextsent>
<nextsent>furthermore,methods have also been proposed to change the dialogue initiative based on various cues (litman and pan, 2000; chu-carroll, 2000; lamel et al, 1999).nevertheless, whether particular response is cooperative or not depends on individual users characteristics.
</nextsent>
<nextsent>for example, when user says nothing, the appropriate response should be different whetherhe/she is not accustomed to using the spoken dialogue systems or he/she does not know much about the target domain.
</nextsent>
<nextsent>unless we detect the cause of the silence, the system may fall into the same situation repeatedly.in order to adapt the systems behavior to individual users, it is necessary to model the users patterns(kass and finin, 1988).<papid> J88-3002 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2793">
<title id=" P03-1033.xml">flexible guidance generation using user model in spoken dialogue systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>furthermore,methods have also been proposed to change the dialogue initiative based on various cues (litman and pan, 2000; chu-carroll, 2000; lamel et al, 1999).nevertheless, whether particular response is cooperative or not depends on individual users characteristics.
</prevsent>
<prevsent>for example, when user says nothing, the appropriate response should be different whetherhe/she is not accustomed to using the spoken dialogue systems or he/she does not know much about the target domain.
</prevsent>
</prevsection>
<citsent citstr=" J88-3002 ">
unless we detect the cause of the silence, the system may fall into the same situation repeatedly.in order to adapt the systems behavior to individual users, it is necessary to model the users patterns(kass and finin, 1988).<papid> J88-3002 </papid></citsent>
<aftsection>
<nextsent>most of conventional studies on user models have focused on the knowledge of users.
</nextsent>
<nextsent>others tried to infer and utilize users goals to generate responses adapted to the user (van beek, 1987; paris, 1988).
</nextsent>
<nextsent>elzer et al (2000) proposed method to generate adaptive suggestions according to users?
</nextsent>
<nextsent>preferences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2794">
<title id=" P04-1011.xml">trainable sentence planning for complex information presentations in spoken dialog systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>furthermore, full nlg may be too slow for use in dialog systems.
</prevsent>
<prevsent>a third, more recent, approach is trainablegeneration: techniques for automatically training nlg modules, or hybrid techniques that adapt nlg modules to particular domains or user groups, e.g.
</prevsent>
</prevsection>
<citsent citstr=" A00-2023 ">
(langkilde, 2000; <papid> A00-2023 </papid>mellish, 1998; walker, rambow and rogati, 2002).</citsent>
<aftsection>
<nextsent>open questions about the trainable approach include (1) whether the output quality is high enough, and (2) whether the techniques work well across domains.
</nextsent>
<nextsent>for example, the training method used in spot (sentence planner trainable), as described in (walker, rambow and ro gati, 2002), was only shown to work in the travel domain, for the information gathering phase ofthe dialog, and with simple content plans involving no rhetorical relations.
</nextsent>
<nextsent>this paper describes trainable sentence planning for information presentation in the match (multimodal access to city help) dialog system (johnston et al, 2002).<papid> P02-1048 </papid></nextsent>
<nextsent>we provide evidence that the trainable approach is feasible by showing (1) that the training technique used for spot can be extended to new domain (restaurant information); (2) that this technique, previously used for information gathering utterances, can be used for information presentations, namely recommendations and comparisons; and (3) that the quality of the output is comparable to that of template-based generator previously developed and experimentally evaluated with match users (walker et al, 2002; stent et al, 2002).section 2 describes sparky (sentence planning with rhetorical knowledge), an extension of spot that uses rhetorical relations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2795">
<title id=" P04-1011.xml">trainable sentence planning for complex information presentations in spoken dialog systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>open questions about the trainable approach include (1) whether the output quality is high enough, and (2) whether the techniques work well across domains.
</prevsent>
<prevsent>for example, the training method used in spot (sentence planner trainable), as described in (walker, rambow and ro gati, 2002), was only shown to work in the travel domain, for the information gathering phase ofthe dialog, and with simple content plans involving no rhetorical relations.
</prevsent>
</prevsection>
<citsent citstr=" P02-1048 ">
this paper describes trainable sentence planning for information presentation in the match (multimodal access to city help) dialog system (johnston et al, 2002).<papid> P02-1048 </papid></citsent>
<aftsection>
<nextsent>we provide evidence that the trainable approach is feasible by showing (1) that the training technique used for spot can be extended to new domain (restaurant information); (2) that this technique, previously used for information gathering utterances, can be used for information presentations, namely recommendations and comparisons; and (3) that the quality of the output is comparable to that of template-based generator previously developed and experimentally evaluated with match users (walker et al, 2002; stent et al, 2002).section 2 describes sparky (sentence planning with rhetorical knowledge), an extension of spot that uses rhetorical relations.
</nextsent>
<nextsent>sparky consists of randomized sentence plan generator (spg) and trainable sentence plan ranker (spr); these are described in sections 3 strategy:recommend items: chanpen thairelations:justify(nuc:1;sat:2); justify(nuc:1;sat:3); jus tify(nuc:1;sat:4) content: 1.
</nextsent>
<nextsent>assert(best(chanpen thai)) 2.
</nextsent>
<nextsent>assert(has-att(chanpen thai, decor(decent))) 3.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2796">
<title id=" P04-1011.xml">trainable sentence planning for complex information presentations in spoken dialog systems </title>
<section> sparky architecture.  </section>
<citcontext>
<prevsection>
<prevsent>for example, the two tp-trees in figure 6 are generated for the content plan in figure 2.
</prevsent>
<prevsent>sentence plans such as alternative 25 in figure 4 are avoided; it is clearly worse than alternatives 12, 13 and 20 since it neither combines information based on restaurant entity (e.g babbo) nor on an attribute (e.g. decor).
</prevsent>
</prevsection>
<citsent citstr=" A97-1039 ">
the top ranked sentence plan output by the spr is input to the realpro surface realizer which produces surface linguistic utterance(lavoie and rambow, 1997).<papid> A97-1039 </papid></citsent>
<aftsection>
<nextsent>a prosody assignment module uses the prior levels of linguistic representation to determine the appropriate prosody for the utterance, and passes marked up string to the text-to-speech module.
</nextsent>
<nextsent>as in spot, the basis of the spg is set ofclause-combining operations that operate on tptrees and incrementally transform the elementary predicate-argument lexico-structural representations (called dsynts (melcuk, 1988)) associated with the speech-acts on the leaves of the tree.
</nextsent>
<nextsent>the operations are applied in abottom-up left-to-right fashion and the resulting representation may contain one or more sentences.
</nextsent>
<nextsent>the application of the operations yields two parallel structures: (1) sentence plan tree (sp-tree), binary tree with leaves labeled by the assertions from the input tp-tree, and interior nodes labeled with clause-combining op erations; and (2) one or more dsynts trees (d-trees) which reflect the parallel operations on the predicate-argument representations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2797">
<title id=" P04-1011.xml">trainable sentence planning for complex information presentations in spoken dialog systems </title>
<section> sentence plan generation.  </section>
<citcontext>
<prevsection>
<prevsent>we added another relation to be used during the content-structuring phase, called infer, which holds for combinations of speech acts for which there is no rhetorical relation expressed in the content plan, as in (marcu, 1997).
</prevsent>
<prevsent>by explicitly representing the discourse structure of the information presentation, we can generate information presentations with considerably more internal complexity than those generated in (walker, rambow and rogati, 2002) and eliminate those that violate certain coherence principles, as described in section 2.
</prevsent>
</prevsection>
<citsent citstr=" A92-1006 ">
the clause-combining operations are general operations similar to aggregation operations used in other research (rambow and korelsky, 1992; <papid> A92-1006 </papid>danlos, 2000).</citsent>
<aftsection>
<nextsent>the operations and the1although the probability distribution here is handcrafted based on assumed preferences for operations such as merge, relative-clause and with-reduction, itmight also be possible to learn this probability distribution from the data by training in two phases.
</nextsent>
<nextsent>nucleus: 3 assert-com-decor contrast nucleus: 2 assert-com-decor nucleus: 6 assert-com-cuisine nucleus: 7 assert-com-cuisine contrast nucleus: 4 assert-com-service nucleus: 5 assert-com-service contrast elaboration nucleus: 1 assert-com-list_exceptional infer nucleus: 3 assert-com-decor nucleus: 5 assert-com-service nucleus: 7 assert-com-cuisine infer infer nucleus: 2 assert-com-decor nucleus: 6 assert-com-cuisine nucleus: 4 assert-com-service elaboration nucleus: 1 assert-com-list_exceptional contrast figure 6: two tp-trees for alternative 13 in figure 4.
</nextsent>
<nextsent>constraints on their use are described below.
</nextsent>
<nextsent>merge applies to two clauses with identical matrix verbs and all but one identical arguments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2798">
<title id=" P04-1011.xml">trainable sentence planning for complex information presentations in spoken dialog systems </title>
<section> sentence plan generation.  </section>
<citcontext>
<prevsection>
<prevsent>the d-tree for alt 13 in figure 8 shows that the spg treats the period operation as part of the lexico-structural representation for the d-tree.
</prevsent>
<prevsent>after sentence planning, the d-tree is split into multiple d-trees at period nodes; these are sent to the realpro surface realizer.separately, the spg also handles referring expression generation by converting proper names to pronouns when they appear in the previous utterance.
</prevsent>
</prevsection>
<citsent citstr=" P87-1022 ">
the rules are applied locally, across adjacent sequences of utterances (brennan etal., 1987).<papid> P87-1022 </papid></citsent>
<aftsection>
<nextsent>referring expressions are manipulated in the d-trees, either intrasententially during the creation of the sp-tree, or intersententially, if the full sp-tree contains any period operations.
</nextsent>
<nextsent>the third and fourth sentences for alt 13 in figure 4 show the conversion of named restaurant (carmines) to pronoun.
</nextsent>
<nextsent>rankerthe spr takes as input set of sp-trees generated by the spg and ranks them.
</nextsent>
<nextsent>the sprsrules for ranking sp-trees are learned from labeled set of sentence-plan training examples using the rank boost algorithm (schapire, 1999).examples and feedback: to apply rank boost, set of human-rated sp-trees are encoded in terms of set of features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2799">
<title id=" P04-1011.xml">trainable sentence planning for complex information presentations in spoken dialog systems </title>
<section> conclusions.  </section>
<citcontext>
<prevsection>
<prevsent>s represents the increment ordecrement associated with satisfying the condition.
</prevsent>
<prevsent>domain and used for information presentation as well as information gathering.
</prevsent>
</prevsection>
<citsent citstr=" P01-1056 ">
previous workon spot also compared trainable sentence planning to template-based generator that had previously been developed for the same application (rambow et al, 2001).<papid> P01-1056 </papid></citsent>
<aftsection>
<nextsent>the evaluation results for sparky (1) support the results for spot, by showing that trainable sentence generation can produce output comparable totemplate-based generation, even for complex information presentations such as extended comparisons; (2) show that trainable sentence generation is sensitive to variations in domain application, presentation type, and even human preferences about the arrangement of particular types of information.
</nextsent>
<nextsent>we thank at&t; for supporting this research, and the anonymous reviewers for their helpful comments on this paper.
</nextsent>


</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2800">
<title id=" P03-1023.xml">coreference resolution using competition learning approach </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>whether candidate is coreferential to an anaphor is often determined by the competition among all the candidates.
</prevsent>
<prevsent>so far, various algorithms have been proposed to determine the preference relationship between two candidates.
</prevsent>
</prevsection>
<citsent citstr=" P98-2143 ">
mitkovs knowledge-poor pronoun resolution method (mitkov, 1998), <papid> P98-2143 </papid>for example, uses the scores from set of antecedent indicators to rank the candidates.</citsent>
<aftsection>
<nextsent>and centering algorithms (brennan et al , 1987; <papid> P87-1022 </papid>strube, 1998; <papid> P98-2204 </papid>tetreault, 2001), <papid> J01-4003 </papid>sort the antecedent candidates based on the ranking of the forward-looking or backward looking centers.</nextsent>
<nextsent>in recent years, supervised machine learning approaches have been widely used in coreference resolution (aone and bennett, 1995; mccarthy, 1996; soon et al , 2001; <papid> J01-4004 </papid>ng and cardie, 2002<papid> P02-1014 </papid>a), and have achieved significant success.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2801">
<title id=" P03-1023.xml">coreference resolution using competition learning approach </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>so far, various algorithms have been proposed to determine the preference relationship between two candidates.
</prevsent>
<prevsent>mitkovs knowledge-poor pronoun resolution method (mitkov, 1998), <papid> P98-2143 </papid>for example, uses the scores from set of antecedent indicators to rank the candidates.</prevsent>
</prevsection>
<citsent citstr=" P87-1022 ">
and centering algorithms (brennan et al , 1987; <papid> P87-1022 </papid>strube, 1998; <papid> P98-2204 </papid>tetreault, 2001), <papid> J01-4003 </papid>sort the antecedent candidates based on the ranking of the forward-looking or backward looking centers.</citsent>
<aftsection>
<nextsent>in recent years, supervised machine learning approaches have been widely used in coreference resolution (aone and bennett, 1995; mccarthy, 1996; soon et al , 2001; <papid> J01-4004 </papid>ng and cardie, 2002<papid> P02-1014 </papid>a), and have achieved significant success.</nextsent>
<nextsent>normally, these approaches adopt single-candidate model in which the classifier judges whether an antecedent candidate is coreferential to an anaphor with confidence value.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2802">
<title id=" P03-1023.xml">coreference resolution using competition learning approach </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>so far, various algorithms have been proposed to determine the preference relationship between two candidates.
</prevsent>
<prevsent>mitkovs knowledge-poor pronoun resolution method (mitkov, 1998), <papid> P98-2143 </papid>for example, uses the scores from set of antecedent indicators to rank the candidates.</prevsent>
</prevsection>
<citsent citstr=" P98-2204 ">
and centering algorithms (brennan et al , 1987; <papid> P87-1022 </papid>strube, 1998; <papid> P98-2204 </papid>tetreault, 2001), <papid> J01-4003 </papid>sort the antecedent candidates based on the ranking of the forward-looking or backward looking centers.</citsent>
<aftsection>
<nextsent>in recent years, supervised machine learning approaches have been widely used in coreference resolution (aone and bennett, 1995; mccarthy, 1996; soon et al , 2001; <papid> J01-4004 </papid>ng and cardie, 2002<papid> P02-1014 </papid>a), and have achieved significant success.</nextsent>
<nextsent>normally, these approaches adopt single-candidate model in which the classifier judges whether an antecedent candidate is coreferential to an anaphor with confidence value.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2803">
<title id=" P03-1023.xml">coreference resolution using competition learning approach </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>so far, various algorithms have been proposed to determine the preference relationship between two candidates.
</prevsent>
<prevsent>mitkovs knowledge-poor pronoun resolution method (mitkov, 1998), <papid> P98-2143 </papid>for example, uses the scores from set of antecedent indicators to rank the candidates.</prevsent>
</prevsection>
<citsent citstr=" J01-4003 ">
and centering algorithms (brennan et al , 1987; <papid> P87-1022 </papid>strube, 1998; <papid> P98-2204 </papid>tetreault, 2001), <papid> J01-4003 </papid>sort the antecedent candidates based on the ranking of the forward-looking or backward looking centers.</citsent>
<aftsection>
<nextsent>in recent years, supervised machine learning approaches have been widely used in coreference resolution (aone and bennett, 1995; mccarthy, 1996; soon et al , 2001; <papid> J01-4004 </papid>ng and cardie, 2002<papid> P02-1014 </papid>a), and have achieved significant success.</nextsent>
<nextsent>normally, these approaches adopt single-candidate model in which the classifier judges whether an antecedent candidate is coreferential to an anaphor with confidence value.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2804">
<title id=" P03-1023.xml">coreference resolution using competition learning approach </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>mitkovs knowledge-poor pronoun resolution method (mitkov, 1998), <papid> P98-2143 </papid>for example, uses the scores from set of antecedent indicators to rank the candidates.</prevsent>
<prevsent>and centering algorithms (brennan et al , 1987; <papid> P87-1022 </papid>strube, 1998; <papid> P98-2204 </papid>tetreault, 2001), <papid> J01-4003 </papid>sort the antecedent candidates based on the ranking of the forward-looking or backward looking centers.</prevsent>
</prevsection>
<citsent citstr=" J01-4004 ">
in recent years, supervised machine learning approaches have been widely used in coreference resolution (aone and bennett, 1995; mccarthy, 1996; soon et al , 2001; <papid> J01-4004 </papid>ng and cardie, 2002<papid> P02-1014 </papid>a), and have achieved significant success.</citsent>
<aftsection>
<nextsent>normally, these approaches adopt single-candidate model in which the classifier judges whether an antecedent candidate is coreferential to an anaphor with confidence value.
</nextsent>
<nextsent>the confidence values are generally used as the competition criterion for the antecedent candidates.
</nextsent>
<nextsent>for example, the best-first?
</nextsent>
<nextsent>selection algorithms (aone and bennett, 1995; ng and cardie, 2002<papid> P02-1014 </papid>a) link the anaphor to the candidate with the maximal confidence value (above 0.5).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2805">
<title id=" P03-1023.xml">coreference resolution using competition learning approach </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>mitkovs knowledge-poor pronoun resolution method (mitkov, 1998), <papid> P98-2143 </papid>for example, uses the scores from set of antecedent indicators to rank the candidates.</prevsent>
<prevsent>and centering algorithms (brennan et al , 1987; <papid> P87-1022 </papid>strube, 1998; <papid> P98-2204 </papid>tetreault, 2001), <papid> J01-4003 </papid>sort the antecedent candidates based on the ranking of the forward-looking or backward looking centers.</prevsent>
</prevsection>
<citsent citstr=" P02-1014 ">
in recent years, supervised machine learning approaches have been widely used in coreference resolution (aone and bennett, 1995; mccarthy, 1996; soon et al , 2001; <papid> J01-4004 </papid>ng and cardie, 2002<papid> P02-1014 </papid>a), and have achieved significant success.</citsent>
<aftsection>
<nextsent>normally, these approaches adopt single-candidate model in which the classifier judges whether an antecedent candidate is coreferential to an anaphor with confidence value.
</nextsent>
<nextsent>the confidence values are generally used as the competition criterion for the antecedent candidates.
</nextsent>
<nextsent>for example, the best-first?
</nextsent>
<nextsent>selection algorithms (aone and bennett, 1995; ng and cardie, 2002<papid> P02-1014 </papid>a) link the anaphor to the candidate with the maximal confidence value (above 0.5).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2836">
<title id=" P03-1023.xml">coreference resolution using competition learning approach </title>
<section> the competition learning approach.  </section>
<citcontext>
<prevsection>
<prevsent>if the set is empty, we left this np unresolved; otherwise we apply the antecedent identification algorithm to choose the antecedent and then link the np to it.
</prevsent>
<prevsent>4.1 preprocessing.
</prevsent>
</prevsection>
<citsent citstr=" W00-1309 ">
to determine the boundary of the noun phrases, pipeline of nature language processing components are applied to an input raw text: tokenization and sentence segmentation named entity recognition part-of-speech tagging noun phrase chunking among them, named entity recognition, part-of speech tagging and text chunking apply the same hidden markov model (hmm) based engine with error-driven learning capability (zhou and su, 2000 &amp; <papid> W00-1309 </papid>2002).</citsent>
<aftsection>
<nextsent>the named entity recognition component recognizes various types of muc-style named entities, i.e., organization, location, person, date, time, money and percentage.
</nextsent>
<nextsent>4.2 features selection.
</nextsent>
<nextsent>for our study, in this paper we only select those features that can be obtained with low annotation cost and high reliability.
</nextsent>
<nextsent>all features are listed in table 1 together with their respective possible values.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2866">
<title id=" P03-1023.xml">coreference resolution using competition learning approach </title>
<section> evaluation and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>table 4 summarizes the overall performance of different approaches to coreference resolution.
</prevsent>
<prevsent>different from table 2 and 3, here we focus on whether coreferential chain could be correctly identified.
</prevsent>
</prevsection>
<citsent citstr=" M95-1005 ">
for this purpose, we obtain the recall, the precision and the f-measure using the standard muc scoring program (vilain et al  1995) <papid> M95-1005 </papid>for the coreference resolution task.</citsent>
<aftsection>
<nextsent>here the recall means the correct resolved chains over the whole coreferential chains in the dataset, and precision means the correct resolved chains over the whole resolved chains.
</nextsent>
<nextsent>in line with the previous experiments, we see reasonable improvement in the performance of the coreference resolution: compared with the baseline approach based on the single-candidate model, the f-measure of approach increases from 69.4 to 71.3 for muc-6, and from 58.7 to 60.2 for muc-7.
</nextsent>
<nextsent>a similar twin-candidate model was adopted in the anaphoric resolution system by connolly et al  (1997).
</nextsent>
<nextsent>the differences between our approach and theirs are: (1) in connolly et al approach, all the preceding nps of an anaphor are taken as the antecedent candidates, whereas in our approach we use candidate filters to eliminate invalid or irrelevant candidates.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2867">
<title id=" P03-1023.xml">coreference resolution using competition learning approach </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>currently, we employ the single-candidate classifier to filter the candidate set during resolution.
</prevsent>
<prevsent>while the filter guarantees the qualification of the candidates, it removes too many positive candidates, and thus the recall suffers.
</prevsent>
</prevsection>
<citsent citstr=" P99-1048 ">
in our future work, we intend to adopt looser filter together with an anaphoricity determination module (bean and riloff, 1999; <papid> P99-1048 </papid>ng and cardie, 2002<papid> P02-1014 </papid>b).</citsent>
<aftsection>
<nextsent>only if an encountered np is determined as an anaphor, we will select an antecedent from the candidate set generated by the looser filter.
</nextsent>
<nextsent>furthermore, we would like to incorporate more syntactic features into our feature set, such as grammatical role or syntactic parallelism.
</nextsent>
<nextsent>these features may be helpful to improve the performance of pronoun resolution.
</nextsent>

</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2878">
<title id=" P02-1039.xml">a decoder for syntax based statistical mt </title>
<section> abstract </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" P01-1067 ">
this paper describes decoding algorithm for syntax-based translation model (ya mada and knight, 2001).<papid> P01-1067 </papid></citsent>
<aftsection>
<nextsent>the model has been extended to incorporate phrasaltranslations as presented here.
</nextsent>
<nextsent>in contrast to conventional word-to-word statistical model, decoder for the syntax based model builds up an english parse tree given sentence in foreign language.
</nextsent>
<nextsent>as the model size becomes huge ina practical setting, and the decoder considers multiple syntactic structures for each word alignment, several pruning techniques are necessary.
</nextsent>
<nextsent>we tested our decoder in chinese-to-english translation system, and obtained better results thanibm model 4.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2879">
<title id=" P02-1039.xml">a decoder for syntax based statistical mt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a different decoder is needed for different choices of lm and tm.
</prevsent>
<prevsent>since  and   are not simple probability tables but are parameterized models,a decoder must conduct search over the space defined by the models.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
for the ibm models defined by pioneering paper (brown et al, 1993), <papid> J93-2003 </papid>decoding algorithm based on left-to-right search was described in (berger et al, 1996).</citsent>
<aftsection>
<nextsent>recently (ya mada and knight, 2001) <papid> P01-1067 </papid>introduced syntax-basedtm which utilized syntactic structure in the channel input, and showed that it could outperform the ibm model in alignment quality.</nextsent>
<nextsent>in contrast to the ibm models, which are word-to-word models, the syntax-based model works on syntactic parse tree, so the decoder builds up an english parse tree given sentence  in foreign language.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2881">
<title id=" P02-1039.xml">a decoder for syntax based statistical mt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in contrast to the ibm models, which are word-to-word models, the syntax-based model works on syntactic parse tree, so the decoder builds up an english parse tree given sentence  in foreign language.
</prevsent>
<prevsent>this paper describes an algorithm for such decoder, and reports experimental results.
</prevsent>
</prevsection>
<citsent citstr=" J97-3002 ">
other statistical machine translation systems suchas (wu, 1997) <papid> J97-3002 </papid>and (alshawi et al, 2000) <papid> J00-1004 </papid>also produce tree  given sentence  . their models are based on mechanisms that generate two languages at the same time, so an english tree  is obtained as sub product of parsing  . however, their use of the lm is not mathematically motivated, since their models do not decompose into     and  unlike the noisy channel model.</citsent>
<aftsection>
<nextsent>section 2 briefly reviews the syntax-based tm,and section 3 describes phrasal translation as an extension.
</nextsent>
<nextsent>section 4 presents the basic idea forde coding.
</nextsent>
<nextsent>as in other statistical machine translation systems, the decoder has to cope with huge search computational linguistics (acl), philadelphia, july 2002, pp.
</nextsent>
<nextsent>303-310.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2882">
<title id=" P02-1039.xml">a decoder for syntax based statistical mt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in contrast to the ibm models, which are word-to-word models, the syntax-based model works on syntactic parse tree, so the decoder builds up an english parse tree given sentence  in foreign language.
</prevsent>
<prevsent>this paper describes an algorithm for such decoder, and reports experimental results.
</prevsent>
</prevsection>
<citsent citstr=" J00-1004 ">
other statistical machine translation systems suchas (wu, 1997) <papid> J97-3002 </papid>and (alshawi et al, 2000) <papid> J00-1004 </papid>also produce tree  given sentence  . their models are based on mechanisms that generate two languages at the same time, so an english tree  is obtained as sub product of parsing  . however, their use of the lm is not mathematically motivated, since their models do not decompose into     and  unlike the noisy channel model.</citsent>
<aftsection>
<nextsent>section 2 briefly reviews the syntax-based tm,and section 3 describes phrasal translation as an extension.
</nextsent>
<nextsent>section 4 presents the basic idea forde coding.
</nextsent>
<nextsent>as in other statistical machine translation systems, the decoder has to cope with huge search computational linguistics (acl), philadelphia, july 2002, pp.
</nextsent>
<nextsent>303-310.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2886">
<title id=" P02-1039.xml">a decoder for syntax based statistical mt </title>
<section> translated.  </section>
<citcontext>
<prevsection>
<prevsent>theoretically we need an lm which gives the prior probability of an english parse tree.
</prevsent>
<prevsent>however, we can approximate it with an n-gram lm, which is well studied and widely implemented.
</prevsent>
</prevsection>
<citsent citstr=" A00-2023 ">
we will discuss this point later in section 7.if we use trigram model for the lm, convenient implementation is to first build decoded tree forest and then to pick out the best tree using trigram-based forest-ranking algorithm as described in (langkilde, 2000).<papid> A00-2023 </papid></citsent>
<aftsection>
<nextsent>the ranker uses two left most and rightmost leaf words to efficiently calculate the trigram probability of subtree, and finds the most plausible tree according to the trigram and the rule probabilities.
</nextsent>
<nextsent>this algorithm finds the optimal tree in terms of the model probability ? but it is not practical when the vocabulary size and the rule size grow.
</nextsent>
<nextsent>the next section describes how to make it practical.
</nextsent>
<nextsent>we use our decoder for chinese-english translation in general news domain.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2887">
<title id=" P02-1039.xml">a decoder for syntax based statistical mt </title>
<section> pruning.  </section>
<citcontext>
<prevsection>
<prevsent>these are statistics which are not modeled in the tm.
</prevsent>
<prevsent>the frequency count is essentially joint probability ap ozor , while the tm uses conditional probability aps or . utilizing statistics outside of model is an important idea for statistical machine translation in general.
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
for example, decoder in (och and ney, 2000) <papid> P00-1056 </papid>uses alignment template statistics found in the viterbi alignments.</citsent>
<aftsection>
<nextsent>this section describes results from our experiment using the decoder as described in the previous section.
</nextsent>
<nextsent>we used chinese-english translation corpus for the experiment.
</nextsent>
<nextsent>after discarding long sentences (more than 20 words in english), the english side of the corpus consisted of about 3m words, and it was parsed with collins?
</nextsent>
<nextsent>parser (collins, 1999).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2888">
<title id=" P02-1039.xml">a decoder for syntax based statistical mt </title>
<section> experimental results: chinese/english.  </section>
<citcontext>
<prevsection>
<prevsent>the second and the third (syn and syn-nozf) are our decoders.both used the same decoding algorithm and pruning as described in the previous sections, except that syn-nozf allowed no zero-fertility insertions.
</prevsent>
<prevsent>the average decoding speed was about 100 seconds6 per sentence for both syn and syn-nozf.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
as an overall decoding performance measure, we used the bleu metric (papineni et al, 2002).<papid> P02-1040 </papid></citsent>
<aftsection>
<nextsent>this measure is geometric average of n-gram accuracy, adjusted by length penalty factor lp.7 the n-gram accuracy (in percentage) is shown in table 1 as p1/p2/p3/p4 for unigram/bigram/trigram/4-gram.
</nextsent>
<nextsent>overall, our decoder performed better than the ibm system, as indicated by the higher bleu score.
</nextsent>
<nextsent>we obtained better n-gram accuracy, but the lower lp score penalized the overall score.
</nextsent>
<nextsent>interestingly, the system with no explicit zero-fertility word insertion(syn-nozf) performed better than the one with zero fertility insertion (syn).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2889">
<title id=" P02-1039.xml">a decoder for syntax based statistical mt </title>
<section> decoded trees.  </section>
<citcontext>
<prevsection>
<prevsent>however, thebleu metric may not be affected by the syntactic aspect of translation quality, and as we saw in figure 4, we can improve the syntactic quality by introducing the pcfg using some corpus selection techniques.
</prevsent>
<prevsent>also, the pruning methods described in section 5 use syntactic statistics from the training corpus.
</prevsent>
</prevsection>
<citsent citstr=" P01-1017 ">
therefore, we are now investigating more sophisticated lms such as (charniak, 2001) <papid> P01-1017 </papid>which8viterbi-ratio is the ratio of the probability of the most plausible alignment with the sum of the probabilities of all the align ments.</citsent>
<aftsection>
<nextsent>low viterbi-ratio is good indicator of misalignment or parse error.
</nextsent>
<nextsent>he major contents prp npb nns npbadjp vps briefed nnsvbd npb the reporters declaring npb vbg npa jjdt npb prn npb prn prn npb np major contents such statement briefed reporters from others dt nnnns vbd npb jj npb nns npb npa pp vp npa he contents prp nnsmd jj briefed the reporters vbd dt vp npa nns should declare major npb npb npb xvb vpa vp figure 4: effect of pcfg and re-training: no cfg probability (pcfg) was used (left).
</nextsent>
<nextsent>pcfg was used for the search (middle).
</nextsent>
<nextsent>the r-table was re-trained and pcfg was used (right).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2890">
<title id=" N12-3009.xml">attitude miner mining attitude from online discussions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this analysis is done on words to identify their polarities, then on sentences to identify attitudinal sentences and the sign of attitude, then on the post level to identify the sign of an interaction, and finally on the entire thread level to identify the overall polarity of the relation.once the polarity of the pairwise relations that develop between interacting discus sants is identified, this information is then used to construct signed network representation of the discussion thread.
</prevsent>
<prevsent>the system also implements two signed network partitioning techniques that can be used to detect how the discus sants split into subgroups regarding the discussion topic.
</prevsent>
</prevsection>
<citsent citstr=" P10-1041 ">
the functionality of the system is based onour previous research on word polarity identification (hassan and radev, 2010) <papid> P10-1041 </papid>and attitude identification (hassan et al, 2010).<papid> D10-1121 </papid></citsent>
<aftsection>
<nextsent>the system is publicly available for download and has web interface to try online1.
</nextsent>
<nextsent>this work is related to previous work in the areas of sentiment analysis and online discussion mining.many previous systems studied the problem of identifying the polarity of individual words (hatzivas siloglou and mckeown, 1997; <papid> P97-1023 </papid>turney and littman,2003).</nextsent>
<nextsent>opinion finder (wilson et al, 2005<papid> H05-2018 </papid>a) is system for mining opinions from text.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2891">
<title id=" N12-3009.xml">attitude miner mining attitude from online discussions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this analysis is done on words to identify their polarities, then on sentences to identify attitudinal sentences and the sign of attitude, then on the post level to identify the sign of an interaction, and finally on the entire thread level to identify the overall polarity of the relation.once the polarity of the pairwise relations that develop between interacting discus sants is identified, this information is then used to construct signed network representation of the discussion thread.
</prevsent>
<prevsent>the system also implements two signed network partitioning techniques that can be used to detect how the discus sants split into subgroups regarding the discussion topic.
</prevsent>
</prevsection>
<citsent citstr=" D10-1121 ">
the functionality of the system is based onour previous research on word polarity identification (hassan and radev, 2010) <papid> P10-1041 </papid>and attitude identification (hassan et al, 2010).<papid> D10-1121 </papid></citsent>
<aftsection>
<nextsent>the system is publicly available for download and has web interface to try online1.
</nextsent>
<nextsent>this work is related to previous work in the areas of sentiment analysis and online discussion mining.many previous systems studied the problem of identifying the polarity of individual words (hatzivas siloglou and mckeown, 1997; <papid> P97-1023 </papid>turney and littman,2003).</nextsent>
<nextsent>opinion finder (wilson et al, 2005<papid> H05-2018 </papid>a) is system for mining opinions from text.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2892">
<title id=" N12-3009.xml">attitude miner mining attitude from online discussions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the functionality of the system is based onour previous research on word polarity identification (hassan and radev, 2010) <papid> P10-1041 </papid>and attitude identification (hassan et al, 2010).<papid> D10-1121 </papid></prevsent>
<prevsent>the system is publicly available for download and has web interface to try online1.</prevsent>
</prevsection>
<citsent citstr=" P97-1023 ">
this work is related to previous work in the areas of sentiment analysis and online discussion mining.many previous systems studied the problem of identifying the polarity of individual words (hatzivas siloglou and mckeown, 1997; <papid> P97-1023 </papid>turney and littman,2003).</citsent>
<aftsection>
<nextsent>opinion finder (wilson et al, 2005<papid> H05-2018 </papid>a) is system for mining opinions from text.</nextsent>
<nextsent>another research line focused on analyzing online discussions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2893">
<title id=" N12-3009.xml">attitude miner mining attitude from online discussions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the system is publicly available for download and has web interface to try online1.
</prevsent>
<prevsent>this work is related to previous work in the areas of sentiment analysis and online discussion mining.many previous systems studied the problem of identifying the polarity of individual words (hatzivas siloglou and mckeown, 1997; <papid> P97-1023 </papid>turney and littman,2003).</prevsent>
</prevsection>
<citsent citstr=" H05-2018 ">
opinion finder (wilson et al, 2005<papid> H05-2018 </papid>a) is system for mining opinions from text.</citsent>
<aftsection>
<nextsent>another research line focused on analyzing online discussions.
</nextsent>
<nextsent>for example, lin et al (2009) proposed sparse coding based model that simultaneously models the semantics and the structure of threaded discussions andshen et al (2006) proposed method for exploiting the temporal information in discussion streams to identify the reply structure of the dialog.
</nextsent>
<nextsent>many systems addressed the problem of extracting social networks from data (elson et al, 2010; <papid> P10-1015 </papid>mccallum et al, 2007), but none of them considered both positive and negative relations.</nextsent>
<nextsent>in the rest of the paper, we describe the system architecture, implementation, usage, and its perfor 1http://clair.eecs.umich.edu/attitudeminer/ 33 discussion thread ?.??.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2897">
<title id=" N12-3009.xml">attitude miner mining attitude from online discussions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>another research line focused on analyzing online discussions.
</prevsent>
<prevsent>for example, lin et al (2009) proposed sparse coding based model that simultaneously models the semantics and the structure of threaded discussions andshen et al (2006) proposed method for exploiting the temporal information in discussion streams to identify the reply structure of the dialog.
</prevsent>
</prevsection>
<citsent citstr=" P10-1015 ">
many systems addressed the problem of extracting social networks from data (elson et al, 2010; <papid> P10-1015 </papid>mccallum et al, 2007), but none of them considered both positive and negative relations.</citsent>
<aftsection>
<nextsent>in the rest of the paper, we describe the system architecture, implementation, usage, and its perfor 1http://clair.eecs.umich.edu/attitudeminer/ 33 discussion thread ?.??.
</nextsent>
<nextsent>text polarity identification ? identify polarized words ? identify the contextual polarity of each word attitude identification ? identify attitudinal sentences ? predict the sign on attitude post sign identification ? aggregate the signs of attitudinal sentences to assign sign to the post.
</nextsent>
<nextsent>relation sign ? aggregate the signs of all the posts exchanged by interacting participants to assign sign for their relation.
</nextsent>
<nextsent>signed network subgroups thread parsing ? identify posts ? identify discus sants ? identify the reply structure ? tokenize text ? split posts into sentences + _ figure 1: overview of the system processing pipeline mance evaluation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2910">
<title id=" P01-1011.xml">underspecified beta reduction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they delay the enumeration of the readings and represent them all at once in single,compact description.
</prevsent>
<prevsent>an under specification formalism that is particularly well suited for describing higher-order formulas is the constraint language for lambda structures, clls (egg et al, 2001; erk et al, 2001).
</prevsent>
</prevsection>
<citsent citstr=" C00-1067 ">
clls descriptions can be derived compositionally and have been used to deal with rich class of linguistic phenomena (koller et al, 2000; koller and niehren, 2000).<papid> C00-1067 </papid>they are based on dominance constraints (mar cus et al, 1983; <papid> P83-1020 </papid>rambow et al, 1995) <papid> P95-1021 </papid>and extend them with parallelism (erk and niehren, 2000) and binding constraints.</citsent>
<aftsection>
<nextsent>however, lifting   -reduction to an operation on underspecified descriptions is not trivial, and to our knowledge it is not known how this can bedone.
</nextsent>
<nextsent>such an operation ? which we will call underspecified   -reduction ? would essentially   reduce all described formulas at once by deriving description of the reduced formulas.
</nextsent>
<nextsent>in this paper, we show how underspecified   -reductions can be performed in the framework of clls.
</nextsent>
<nextsent>our approach extends the work presented in (bodirsky et al, 2001), which defines   -reduction constraints and shows how to obtain complete solution procedure by reducing them to parallelism constraints in clls.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2911">
<title id=" P01-1011.xml">underspecified beta reduction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they delay the enumeration of the readings and represent them all at once in single,compact description.
</prevsent>
<prevsent>an under specification formalism that is particularly well suited for describing higher-order formulas is the constraint language for lambda structures, clls (egg et al, 2001; erk et al, 2001).
</prevsent>
</prevsection>
<citsent citstr=" P83-1020 ">
clls descriptions can be derived compositionally and have been used to deal with rich class of linguistic phenomena (koller et al, 2000; koller and niehren, 2000).<papid> C00-1067 </papid>they are based on dominance constraints (mar cus et al, 1983; <papid> P83-1020 </papid>rambow et al, 1995) <papid> P95-1021 </papid>and extend them with parallelism (erk and niehren, 2000) and binding constraints.</citsent>
<aftsection>
<nextsent>however, lifting   -reduction to an operation on underspecified descriptions is not trivial, and to our knowledge it is not known how this can bedone.
</nextsent>
<nextsent>such an operation ? which we will call underspecified   -reduction ? would essentially   reduce all described formulas at once by deriving description of the reduced formulas.
</nextsent>
<nextsent>in this paper, we show how underspecified   -reductions can be performed in the framework of clls.
</nextsent>
<nextsent>our approach extends the work presented in (bodirsky et al, 2001), which defines   -reduction constraints and shows how to obtain complete solution procedure by reducing them to parallelism constraints in clls.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2912">
<title id=" P01-1011.xml">underspecified beta reduction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they delay the enumeration of the readings and represent them all at once in single,compact description.
</prevsent>
<prevsent>an under specification formalism that is particularly well suited for describing higher-order formulas is the constraint language for lambda structures, clls (egg et al, 2001; erk et al, 2001).
</prevsent>
</prevsection>
<citsent citstr=" P95-1021 ">
clls descriptions can be derived compositionally and have been used to deal with rich class of linguistic phenomena (koller et al, 2000; koller and niehren, 2000).<papid> C00-1067 </papid>they are based on dominance constraints (mar cus et al, 1983; <papid> P83-1020 </papid>rambow et al, 1995) <papid> P95-1021 </papid>and extend them with parallelism (erk and niehren, 2000) and binding constraints.</citsent>
<aftsection>
<nextsent>however, lifting   -reduction to an operation on underspecified descriptions is not trivial, and to our knowledge it is not known how this can bedone.
</nextsent>
<nextsent>such an operation ? which we will call underspecified   -reduction ? would essentially   reduce all described formulas at once by deriving description of the reduced formulas.
</nextsent>
<nextsent>in this paper, we show how underspecified   -reductions can be performed in the framework of clls.
</nextsent>
<nextsent>our approach extends the work presented in (bodirsky et al, 2001), which defines   -reduction constraints and shows how to obtain complete solution procedure by reducing them to parallelism constraints in clls.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2913">
<title id=" P04-1042.xml">deep dependencies from context free statistical parsers correcting the surface dependency approximation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>or precise?
</prevsent>
<prevsent>approaches to syntax, such as gb, ccg, hpsg, lfg, or tag,have argued that sophisticated grammatical formalisms are essential to resolving various hidden relationships such as the source phrase of moved whphrases in questions and relativizations, or the controller of clauses without an overt subject.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
knowledge of these hidden relationships is in turn essential to semantic interpretation of the kind practiced in the semantic parsing (gildea and jurafsky,2002) <papid> J02-3001 </papid>and qa (pasca and harabagiu, 2001) litera tures.</citsent>
<aftsection>
<nextsent>however, work in statistical parsing has for the most part put these needs aside, being content to recover surface context-free (cf) phrase structure trees.
</nextsent>
<nextsent>this perhaps reflects the fact that context-free phrase structure grammar (cfg) is in some sense at the the heart of the majority of both formal and computational syntactic research.
</nextsent>
<nextsent>although, upon introducing it, chomsky (1956) rejected cfg as an adequate framework for natural language description, the majority of work in the last half century has used context-free structural descriptions andre lated methodologies in one form or another as an important component of syntactic analysis.
</nextsent>
<nextsent>cfgsseem adequate to weakly generate almost all common natural language structures, and also facilitate transparent predicate-argument and/or semantic interpretation for the more basic ones (gazdar et al,1985).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2914">
<title id=" P04-1042.xml">deep dependencies from context free statistical parsers correcting the surface dependency approximation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>previous work on non local dependency has focused entirely on english, despite the disparity in type and frequency of various non-local dependency constructions for varying languages (kruijff, 2002).
</prevsent>
<prevsent>collins (1999)s model 3 investigated gpsg-styletrace threading for resolving non local relative pronoun dependencies.
</prevsent>
</prevsection>
<citsent citstr=" P02-1018 ">
johnson (2002)<papid> P02-1018 </papid>was the first post-processing approach to non-local dependency recovery, using simple pattern-matching algorithm on context-free trees.</citsent>
<aftsection>
<nextsent>dienes and dubey (2003<papid> W03-1005 </papid>a,b)and dienes (2003) approached the problem by pre identifying empty categories using an hmm on un parsed strings and threaded the identified empties into the category structure of context-free parser, finding that this method compared favorably with both collins?</nextsent>
<nextsent>and johnsons. traditional lfg parsing, in both non-stochastic (kaplan and maxwell, 1993) and stochastic (riezler et al, 2002; <papid> P02-1035 </papid>kaplan et al, 2004) <papid> N04-1013 </papid>incarnations, also divides the labor of local and non local dependency identification into two phases, starting with context-free parses and continuing by augmentation with functional infor mation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2917">
<title id=" P04-1042.xml">deep dependencies from context free statistical parsers correcting the surface dependency approximation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>collins (1999)s model 3 investigated gpsg-styletrace threading for resolving non local relative pronoun dependencies.
</prevsent>
<prevsent>johnson (2002)<papid> P02-1018 </papid>was the first post-processing approach to non-local dependency recovery, using simple pattern-matching algorithm on context-free trees.</prevsent>
</prevsection>
<citsent citstr=" W03-1005 ">
dienes and dubey (2003<papid> W03-1005 </papid>a,b)and dienes (2003) approached the problem by pre identifying empty categories using an hmm on un parsed strings and threaded the identified empties into the category structure of context-free parser, finding that this method compared favorably with both collins?</citsent>
<aftsection>
<nextsent>and johnsons. traditional lfg parsing, in both non-stochastic (kaplan and maxwell, 1993) and stochastic (riezler et al, 2002; <papid> P02-1035 </papid>kaplan et al, 2004) <papid> N04-1013 </papid>incarnations, also divides the labor of local and non local dependency identification into two phases, starting with context-free parses and continuing by augmentation with functional infor mation.</nextsent>
<nextsent>the datasets used for this study consist of the wall street journal section of the penn treebank of english (wsj) and the context-free version of the negra (version 2) corpus of german (skut et al, 1997<papid> A97-1014 </papid>b).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2925">
<title id=" P04-1042.xml">deep dependencies from context free statistical parsers correcting the surface dependency approximation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>johnson (2002)<papid> P02-1018 </papid>was the first post-processing approach to non-local dependency recovery, using simple pattern-matching algorithm on context-free trees.</prevsent>
<prevsent>dienes and dubey (2003<papid> W03-1005 </papid>a,b)and dienes (2003) approached the problem by pre identifying empty categories using an hmm on un parsed strings and threaded the identified empties into the category structure of context-free parser, finding that this method compared favorably with both collins?</prevsent>
</prevsection>
<citsent citstr=" P02-1035 ">
and johnsons. traditional lfg parsing, in both non-stochastic (kaplan and maxwell, 1993) and stochastic (riezler et al, 2002; <papid> P02-1035 </papid>kaplan et al, 2004) <papid> N04-1013 </papid>incarnations, also divides the labor of local and non local dependency identification into two phases, starting with context-free parses and continuing by augmentation with functional infor mation.</citsent>
<aftsection>
<nextsent>the datasets used for this study consist of the wall street journal section of the penn treebank of english (wsj) and the context-free version of the negra (version 2) corpus of german (skut et al, 1997<papid> A97-1014 </papid>b).</nextsent>
<nextsent>full-size experiments on wsj described in section 4 used the standard sections 2-21 for training, 24 for development, and trees whose yield isunder 100 words from section 23 for testing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2926">
<title id=" P04-1042.xml">deep dependencies from context free statistical parsers correcting the surface dependency approximation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>johnson (2002)<papid> P02-1018 </papid>was the first post-processing approach to non-local dependency recovery, using simple pattern-matching algorithm on context-free trees.</prevsent>
<prevsent>dienes and dubey (2003<papid> W03-1005 </papid>a,b)and dienes (2003) approached the problem by pre identifying empty categories using an hmm on un parsed strings and threaded the identified empties into the category structure of context-free parser, finding that this method compared favorably with both collins?</prevsent>
</prevsection>
<citsent citstr=" N04-1013 ">
and johnsons. traditional lfg parsing, in both non-stochastic (kaplan and maxwell, 1993) and stochastic (riezler et al, 2002; <papid> P02-1035 </papid>kaplan et al, 2004) <papid> N04-1013 </papid>incarnations, also divides the labor of local and non local dependency identification into two phases, starting with context-free parses and continuing by augmentation with functional infor mation.</citsent>
<aftsection>
<nextsent>the datasets used for this study consist of the wall street journal section of the penn treebank of english (wsj) and the context-free version of the negra (version 2) corpus of german (skut et al, 1997<papid> A97-1014 </papid>b).</nextsent>
<nextsent>full-size experiments on wsj described in section 4 used the standard sections 2-21 for training, 24 for development, and trees whose yield isunder 100 words from section 23 for testing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2927">
<title id=" P04-1042.xml">deep dependencies from context free statistical parsers correcting the surface dependency approximation </title>
<section> datasets.  </section>
<citcontext>
<prevsection>
<prevsent>dienes and dubey (2003<papid> W03-1005 </papid>a,b)and dienes (2003) approached the problem by pre identifying empty categories using an hmm on un parsed strings and threaded the identified empties into the category structure of context-free parser, finding that this method compared favorably with both collins?</prevsent>
<prevsent>and johnsons. traditional lfg parsing, in both non-stochastic (kaplan and maxwell, 1993) and stochastic (riezler et al, 2002; <papid> P02-1035 </papid>kaplan et al, 2004) <papid> N04-1013 </papid>incarnations, also divides the labor of local and non local dependency identification into two phases, starting with context-free parses and continuing by augmentation with functional infor mation.</prevsent>
</prevsection>
<citsent citstr=" A97-1014 ">
the datasets used for this study consist of the wall street journal section of the penn treebank of english (wsj) and the context-free version of the negra (version 2) corpus of german (skut et al, 1997<papid> A97-1014 </papid>b).</citsent>
<aftsection>
<nextsent>full-size experiments on wsj described in section 4 used the standard sections 2-21 for training, 24 for development, and trees whose yield isunder 100 words from section 23 for testing.
</nextsent>
<nextsent>experiments described in section 4.3 used the same development and test sets but files 200-959 of wsj as smaller training set; for negra we followed dubey and keller (2003) <papid> P03-1013 </papid>in using the first 18,602sentences for training, the last 1,000 for development, and the previous 1,000 for testing.</nextsent>
<nextsent>consistent with prior work and with common practice in statistical parsing, we stripped categories of all functional tags prior to training and testing (though in several cases this seems to have been limiting move; see section 5).nonlocal dependency annotation in penn treebanks can be divided into three major types: unin dexed empty elements, dislocations, and control.the first type consists primarily of null complementizers, as exemplified in figure 1 by the null relative pronoun 0 (c.f. aspects that it sees), and do not participate in (though they may mediate) nonlocaldependency.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2928">
<title id=" P04-1042.xml">deep dependencies from context free statistical parsers correcting the surface dependency approximation </title>
<section> datasets.  </section>
<citcontext>
<prevsection>
<prevsent>the datasets used for this study consist of the wall street journal section of the penn treebank of english (wsj) and the context-free version of the negra (version 2) corpus of german (skut et al, 1997<papid> A97-1014 </papid>b).</prevsent>
<prevsent>full-size experiments on wsj described in section 4 used the standard sections 2-21 for training, 24 for development, and trees whose yield isunder 100 words from section 23 for testing.</prevsent>
</prevsection>
<citsent citstr=" P03-1013 ">
experiments described in section 4.3 used the same development and test sets but files 200-959 of wsj as smaller training set; for negra we followed dubey and keller (2003) <papid> P03-1013 </papid>in using the first 18,602sentences for training, the last 1,000 for development, and the previous 1,000 for testing.</citsent>
<aftsection>
<nextsent>consistent with prior work and with common practice in statistical parsing, we stripped categories of all functional tags prior to training and testing (though in several cases this seems to have been limiting move; see section 5).nonlocal dependency annotation in penn treebanks can be divided into three major types: unin dexed empty elements, dislocations, and control.the first type consists primarily of null complementizers, as exemplified in figure 1 by the null relative pronoun 0 (c.f. aspects that it sees), and do not participate in (though they may mediate) nonlocaldependency.
</nextsent>
<nextsent>the second type consists of dislocated element co indexed with an origin site of semantic interpretation, as in the association in figure 1 of whnp-1 with the direct object position of sees (a relativization), and the association of 2 with the adjp quick (a right dislocation).
</nextsent>
<nextsent>this type encompasses the classic cases of non local dependency: topical ization, relativization, wh- movement, and right dislocation, as well as expletives and other instances of non-canonical argument positioning.
</nextsent>
<nextsent>the third type involves control loci in syntactic argument positions, sometimes co indexed with overt controllers, as in the association of the npfarmers with the empty subject position of the 2 node.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2975">
<title id=" P04-1042.xml">deep dependencies from context free statistical parsers correcting the surface dependency approximation </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>it is not entirely clear how to interpret the intended semantics of these examples, so we ignore them in evaluation.13the interpretation of comparative results must be modulated by the fact that more total time was spent on feature engineering for wsj than for negra, and the first author, who engineered the negra feature set, is not native speaker of german.comparison we tested wsj using the smaller training set described in section 2, comparable in size to negras. since the positioning of traces within negra nodes is trivial, we evaluate remapping and combination performances requiring only proper selection of the originating mother node; thus we carry the algorithm out on both treebanks through step (2b).
</prevsent>
<prevsent>this is adequate for purposes of our typed dependency evaluation in section 4.2, since typed dependencies do not depend on positional information.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
state-of-the-art statistical parsing is far better on wsj (charniak, 2000) <papid> A00-2018 </papid>than on negra (dubey and keller, 2003), <papid> P03-1013 </papid>so for comparison of parser-composed dependency performance we used vanilla pcfg models for both wsj and negra trained on comparably-sized datasets; in addition to making similar types of independence assumptions, these models performed relatively comparably on labeled bracketing measures for our development sets (73.2% performance for wsj versus 70.9% for negra).table 5 compares the testset performance of algorithms on the two treebanks on the typed dependency measure introduced in section 4.2.14</citsent>
<aftsection>
<nextsent>the wsj results shown in tables 2 and 3 suggest that discriminative models incorporating both non local and local lexical and syntactic information can achieve good results on the task of non-local dependency identification.
</nextsent>
<nextsent>on the parseval metric, our algorithm performed particularly well on null complementizer and control locus insertion, and on node relocation.
</nextsent>
<nextsent>in particular, johnson noted that the proper insertion of control loci was difficult issue involving lexical as well as structural sensitivity.
</nextsent>
<nextsent>we found the loglinear paradigm good one in which to model this feature combination; when run in isolation on gold-standard development trees,our model reached 96.4% f1 on control locus insertion, reducing error over the johnson models 89.3% 14many head-dependent relations in negra are explicitly marked, but for those that are not we used collins (1999)style head-finding algorithm independently developed forger man pcfg parsing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2978">
<title id=" P04-1042.xml">deep dependencies from context free statistical parsers correcting the surface dependency approximation </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>but temporal nps, indistinguishable by gross category,also appear under such nodes, creating major confound.
</prevsent>
<prevsent>we used customized features to compensate to some extent, but temporal annotation already exists in wsj and could be used.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
we note that klein and manning (2003) <papid> P03-1054 </papid>independently found retention of temporal np marking useful for pcfg parsing.as can be seen in table 3, the absolute improvement in dependency recovery is smaller for both our and johnsons postprocessing algorithms when applied to parsed input trees than when applied togold-standard input trees.</citsent>
<aftsection>
<nextsent>it seems that this degradation is not primarily due to noise in parse tree outputs reducing recall of non local dependency iden tification: precision/recall splits were largely the same between gold and parsed data, and manual inspection revealed that incorrect non local dependency choices often arose from syntactically reasonable yet incorrect input from the parser.
</nextsent>
<nextsent>for example, the gold-standard parse right-wing whites . . .
</nextsent>
<nextsent>will [vp step up [np their threats [s [vp * to take matters into their own hands ]]]] has an un indexed control locus because treebank annotation specifies that infiniti val vps inside nps are not assigned controllers.
</nextsent>
<nextsent>charniaks parser, however, attaches the in finitival vp into the higher step up . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2987">
<title id=" N12-1066.xml">behavioral factors in interactive training of text classifiers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>positive or terrible??
</prevsent>
<prevsent>negative, which might be useful word-label rules for sentiment analysis task.contemporary work has also focused on making such learning algorithms active, by enabling them to pose queries?
</prevsent>
</prevsection>
<citsent citstr=" D09-1009 ">
in the form of feature-based rules to be labeled by annotators in addition to ? and sometimes lieu of ? data instances such as documents (attenberg et al, 2010; druck et al, 2009).<papid> D09-1009 </papid></citsent>
<aftsection>
<nextsent>these concepts were recently implemented in practical system for interactive training of text classifiers called dualist1.
</nextsent>
<nextsent>settles (2011) <papid> D11-1136 </papid>reports that, in user experiments with real annotators, humans were able to train near state of the art classifiers with only few minutes of effort.</nextsent>
<nextsent>however,there were only five subjects, who were all computer science researchers.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2988">
<title id=" N12-1066.xml">behavioral factors in interactive training of text classifiers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the form of feature-based rules to be labeled by annotators in addition to ? and sometimes lieu of ? data instances such as documents (attenberg et al, 2010; druck et al, 2009).<papid> D09-1009 </papid></prevsent>
<prevsent>these concepts were recently implemented in practical system for interactive training of text classifiers called dualist1.</prevsent>
</prevsection>
<citsent citstr=" D11-1136 ">
settles (2011) <papid> D11-1136 </papid>reports that, in user experiments with real annotators, humans were able to train near state of the art classifiers with only few minutes of effort.</citsent>
<aftsection>
<nextsent>however,there were only five subjects, who were all computer science researchers.
</nextsent>
<nextsent>it is possible that these positive results can be attributed to the subjects?
</nextsent>
<nextsent>implicit familiarity with machine learning and natural language processing algorithms.this short paper sheds more light on previous experiments by replicating them with many more human subjects, and of different type: non-expertsrecruited through the amazon mechanical turk service2.
</nextsent>
<nextsent>we also analyze the impact of annotator behavior on the resulting classifiers, and suggest relationships to recent work in curriculum learning.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2993">
<title id=" P04-2005.xml">automatic acquisition of english topic signatures based on a second language </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the web provides further ways of overcoming the bottleneck.
</prevsent>
<prevsent>mihalcea et al (1999) present eda method enabling automatic acquisition of sense tagged corpora, based on wordnet and an internet search engine.
</prevsent>
</prevsection>
<citsent citstr=" W02-0817 ">
chklovski and mihalcea (2002) <papid> W02-0817 </papid>presented another interesting proposal which turns to web users to produce sense-tagged corpora.another type of method, which exploits differences between languages, has shown great promise.</citsent>
<aftsection>
<nextsent>for example, some work has been done based on the assumption that mappings of words and meanings are different in different languages.gale et al (1992) proposed method which automatically produces sense-tagged data using parallel bilingual corpora.
</nextsent>
<nextsent>diab and resnik (2002)<papid> P02-1033 </papid>presented an unsupervised method for wsd using the same type of resource.</nextsent>
<nextsent>one problem with relying on bilingual corpora for data collection isthat bilingual corpora are rare, and aligned bilingual corpora are even rarer.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2994">
<title id=" P04-2005.xml">automatic acquisition of english topic signatures based on a second language </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>chklovski and mihalcea (2002) <papid> W02-0817 </papid>presented another interesting proposal which turns to web users to produce sense-tagged corpora.another type of method, which exploits differences between languages, has shown great promise.</prevsent>
<prevsent>for example, some work has been done based on the assumption that mappings of words and meanings are different in different languages.gale et al (1992) proposed method which automatically produces sense-tagged data using parallel bilingual corpora.</prevsent>
</prevsection>
<citsent citstr=" P02-1033 ">
diab and resnik (2002)<papid> P02-1033 </papid>presented an unsupervised method for wsd using the same type of resource.</citsent>
<aftsection>
<nextsent>one problem with relying on bilingual corpora for data collection isthat bilingual corpora are rare, and aligned bilingual corpora are even rarer.
</nextsent>
<nextsent>mining the web for bilingual text (resnik, 1999) <papid> P99-1068 </papid>is not likely to provide sufficient quantities of high quality data.</nextsent>
<nextsent>an other problem is that if two languages are closely related, data for some words cannot be collected because different senses of polysemous words in one language often translate to the same word in the other.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2995">
<title id=" P04-2005.xml">automatic acquisition of english topic signatures based on a second language </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>diab and resnik (2002)<papid> P02-1033 </papid>presented an unsupervised method for wsd using the same type of resource.</prevsent>
<prevsent>one problem with relying on bilingual corpora for data collection isthat bilingual corpora are rare, and aligned bilingual corpora are even rarer.</prevsent>
</prevsection>
<citsent citstr=" P99-1068 ">
mining the web for bilingual text (resnik, 1999) <papid> P99-1068 </papid>is not likely to provide sufficient quantities of high quality data.</citsent>
<aftsection>
<nextsent>an other problem is that if two languages are closely related, data for some words cannot be collected because different senses of polysemous words in one language often translate to the same word in the other.
</nextsent>
<nextsent>in this paper, we present novel approach for automatically acquiring topic signatures (see table 1 for an example of topic signatures), which also adopts the cross-lingual paradigm.
</nextsent>
<nextsent>to solve the problem of different senses not being distinguishable mentioned in the previous paragraph, we chose language very distant to english ? chinese, since the more distant two languages are, the more likely that senses are lexicalised differently (resnik and yarowsky, 1999).
</nextsent>
<nextsent>because our approach only uses chinese monolingual text, we also avoid the problem of shortage of aligned bilingual corpora.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2996">
<title id=" P04-2005.xml">automatic acquisition of english topic signatures based on a second language </title>
<section> shallow process these chinese corpora. text segmen-.  </section>
<citcontext>
<prevsection>
<prevsent>since they were created by word to word translation, syntactic analysis of them is not possible.
</prevsent>
<prevsent>even the distances between the target ambiguous word and its context words are not reliable because of differences in word order between chinese and english.table 1 lists two sets of topic signatures, each containing the 20 most frequent nouns, ranked by occurrence count, that surround instances of the financial sense of interest.
</prevsent>
</prevsection>
<citsent citstr=" P94-1020 ">
one set was extracted from hand-tagged corpus (bruce and wiebe, 1994) <papid> P94-1020 </papid>and the other by our algorithm.</citsent>
<aftsection>
<nextsent>3 application on wsd.
</nextsent>
<nextsent>to evaluate the usefulness of the topic signatures acquired, we applied them in wsd task.
</nextsent>
<nextsent>we adopted an algorithm similar to schutzes (1998) context-group discrimination, which determines word sense according to the semantic similarity of contexts, computed using second-order cooccurrence vector model.
</nextsent>
<nextsent>in this section, we firstly introduce our adaptation of this algorithm, and then describe the disambiguation experiments on 6 words for which gold standard is available.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2997">
<title id=" P01-1038.xml">generation of vp ellipsis a corpus based approach </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we identify factors which govern the decision to elide vps.
</prevsent>
<prevsent>we examine corpus of positive and negative examples; i.e., examples in which vps were or were not elided.
</prevsent>
</prevsection>
<citsent citstr=" P93-1009 ">
we find that,indeed, the distance between ellipsis site and antecedent is correlated with the decision to elide, as are the syntactic relation between antecedent 2the classic study is (sag, 1976); for more recent work, see, eg, (dalrymple et al, 1991; kehler, 1993; <papid> P93-1009 </papid>fiengo and may, 1994; hardt, 1999).</citsent>
<aftsection>
<nextsent>and ellipsis site, and the presence or absence ofadjuncts.
</nextsent>
<nextsent>building on these results, we use machine learning techniques to examine where in the generation architecture trainable algorithm for vp ellipsis should be located.
</nextsent>
<nextsent>we show that the best performance (error rate of 7.5%) is achieved when the trainable module is located after there alizer and has access to surface-oriented features.
</nextsent>
<nextsent>in what follows, we first describe our corpus of negative and positive examples.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2998">
<title id=" P01-1038.xml">generation of vp ellipsis a corpus based approach </title>
<section> the corpus.  </section>
<citcontext>
<prevsection>
<prevsent>first, candidate examples were identified automatically if there were two occurrences of the same verb, separated byfewer than 10 intervening verbs.
</prevsent>
<prevsent>then, the collected examples were manually examined to determine whether the two verb phrases had identical meanings or not.3 if not, the examples were eliminated.
</prevsent>
</prevsection>
<citsent citstr=" J97-4002 ">
this yielded 111 negative examples.the positive examples were taken from the corpus collected in previous work (hardt, 1997).<papid> J97-4002 </papid></citsent>
<aftsection>
<nextsent>this is corpus of several hundred examples ofvpe from the treebank, based on their syntactic analysis.
</nextsent>
<nextsent>vpe is not annotated uniformly in the ptb.
</nextsent>
<nextsent>we found several different bracketing patterns and searched for these patterns, but one cannot be certain that no other bracketing patterns were used in the ptb.
</nextsent>
<nextsent>this yielded 15 positive examples in sections 5 and 6.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q2999">
<title id=" P01-1038.xml">generation of vp ellipsis a corpus based approach </title>
<section> factors examined.  </section>
<citcontext>
<prevsection>
<prevsent>this information can be annotated reliably (
</prevsent>
<prevsent>    and
</prevsent>
</prevsection>
<citsent citstr=" J96-2004 ">
).44following (carletta, 1996), <papid> J96-2004 </papid>we use the  statistic to estimate reliability of annotation.</citsent>
<aftsection>
<nextsent>we assume that values  ffshow reliability, and values fifl ffi  !#$!%fifl ff show sufficient reliability for drawing conclusions, given that the other variable we are comparing these variables to (vpe) is coded 100% correctly.
</nextsent>
<nextsent>the following syntactic features were coded:  voice (vox): grammatical voice (ac tive/passive) of antecedent and candidate.
</nextsent>
<nextsent>this information can be annotated reliably (
</nextsent>
<nextsent>&amp;    ).  syntactic structure (syn): this feature describes the syntactic relation between the head verbs of the two vps, i.e., conjunction(which includes conjunction?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3000">
<title id=" P01-1038.xml">generation of vp ellipsis a corpus based approach </title>
<section> algorithms for vpe.  </section>
<citcontext>
<prevsection>
<prevsent>however, before we can use ripper, we must discuss the issue of how our new trainable vpe module fits into the architecture of generation.
</prevsent>
<prevsent>5.1 vpe in the generation architecture.
</prevsent>
</prevsection>
<citsent citstr=" A92-1006 ">
tasks in the generation process have been divided into three stages (rambow and korelsky,1992): <papid> A92-1006 </papid>the text planner has access only to information about communicative goals, the discourse context, and semantics, and generates non-linguistic representation of text structure and content.</citsent>
<aftsection>
<nextsent>the sentence planner chooses abstract linguistic resources (meaning-bearing lexemes, syntactic constructions) and determines sentence boundaries.
</nextsent>
<nextsent>it passes an abstract lexico-syntactic specification5 to the realizer, which inflects,adds function words, and linearizes, thus producing the surface string.
</nextsent>
<nextsent>the question arises where in this architecture the decision about vpe should be made.
</nextsent>
<nextsent>we will investigate this question in this section by distinguishing three places for making the vpe decision: in or just after the text planner; in or just after the sentence planner; and in or just after the realizer (i..e, at the end of the whole generation process if there are no modules after realization, such as prosody).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3001">
<title id=" P01-1038.xml">generation of vp ellipsis a corpus based approach </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>if this is the case, further work will allow us to define algorithms so that the decision on vpe can be made after sentence planning.
</prevsent>
<prevsent>however, it is also possible that decisions about vpe (and related pronominal constraints) cannot be made before the text is linear ized, presumably because of the processing limitations of the hearer/reader(and of the speaker/writer).
</prevsent>
</prevsection>
<citsent citstr=" J96-2005 ">
walker (1996) <papid> J96-2005 </papid>has argued in favor of the importance of limited attention in processing discourse phenomena, and the surface-oriented features can be argued to model such cognitive constraints.</citsent>
<aftsection>




</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3002">
<title id=" P03-1019.xml">a comparative study on reordering constraints in statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>ei . . .
</prevsent>
<prevsent>ei . among all possible target language sentences, wewill choose the sentence with the highest pro babil ity: ei1 = argmax ei1 {pr(ei1|fj1 )} (1) = argmax ei1 {pr(ei1) ? pr(fj1 |ei1)} (2) the decomposition into two knowledge sources in eq.
</prevsent>
</prevsection>
<citsent citstr=" J90-2002 ">
2 is the so-called source-channel approach to statistical machine translation (brown et al,1990).<papid> J90-2002 </papid></citsent>
<aftsection>
<nextsent>it allows an independent modeling of target language model pr(ei1) and translation model pr(fj1 |ei1).
</nextsent>
<nextsent>the target language model describes the well-formedness of the target language sentence.the translation model links the source language sentence to the target language sentence.
</nextsent>
<nextsent>it can be further decomposed into alignment and lexicon model.
</nextsent>
<nextsent>the argmax operation denotes the search problem,i.e. the generation of the output sentence in the target language.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3003">
<title id=" P03-1019.xml">a comparative study on reordering constraints in statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we will focus on the alignment problem, i.e. the mapping between source sentence positions and target sentence positions.
</prevsent>
<prevsent>as the word order in source and target language may differ, the search algorithm has to allow certain word-reorderings.
</prevsent>
</prevsection>
<citsent citstr=" J99-4005 ">
if arbitrary word-reorderings are allowed, the search problem is np-hard (knight, 1999).<papid> J99-4005 </papid></citsent>
<aftsection>
<nextsent>therefore, we have to restrict the possible reorderings in some way to make the search problem feasible.
</nextsent>
<nextsent>here, we will discuss two such constraints in detail.
</nextsent>
<nextsent>the first constraints are based on inversion transduction grammars (itg) (wu, 1995; wu, 1997).<papid> J97-3002 </papid></nextsent>
<nextsent>in the following, we will call these the itg constraints.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3004">
<title id=" P03-1019.xml">a comparative study on reordering constraints in statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>therefore, we have to restrict the possible reorderings in some way to make the search problem feasible.
</prevsent>
<prevsent>here, we will discuss two such constraints in detail.
</prevsent>
</prevsection>
<citsent citstr=" J97-3002 ">
the first constraints are based on inversion transduction grammars (itg) (wu, 1995; wu, 1997).<papid> J97-3002 </papid></citsent>
<aftsection>
<nextsent>in the following, we will call these the itg constraints.
</nextsent>
<nextsent>the second constraints are the ibm constraints (berger et al, 1996).
</nextsent>
<nextsent>in the next section, we will describe these constraints from theoretical point of view.
</nextsent>
<nextsent>then, we will describe the resulting search algorithm and its extension for word graph generation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3018">
<title id=" P03-1019.xml">a comparative study on reordering constraints in statistical machine translation </title>
<section> search.  </section>
<citcontext>
<prevsection>
<prevsent>let qjl,jr denote the maximum probability of all translation hypotheses for jrjl . then, we prune hypothesis iff: qjl,jr,eb,et   qjl,jrapplying these pruning techniques the computational costs can be reduced significantly with almost no loss in translation quality.
</prevsent>
<prevsent>3.3 generation of word graphs.
</prevsent>
</prevsection>
<citsent citstr=" W02-1021 ">
the generation of word graphs for bottom-top search with the ibm constraints is described in (ueffing et al, 2002).<papid> W02-1021 </papid></citsent>
<aftsection>
<nextsent>these methods cannot be applied to the cyk-style search for the itg constraints.
</nextsent>
<nextsent>here, the idea for the generation of word graphs is the following: assuming we already have word graphs for the source sequences fkjl and jr k+1, then we can construct word graph for the sequence jrjl by concatenating the partial word graphs either in monotone or inverted order.
</nextsent>
<nextsent>now, we describe this idea in more formal way.
</nextsent>
<nextsent>a word graph is directed acyclic graph (dag) with one start and one end node.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3025">
<title id=" P03-1019.xml">a comparative study on reordering constraints in statistical machine translation </title>
<section> corpus statistics.  </section>
<citcontext>
<prevsection>
<prevsent>table 2 shows the corpus statistics of this corpus.
</prevsent>
<prevsent>the training corpus (train) was used to train the ibm model parameters.
</prevsent>
</prevsection>
<citsent citstr=" P02-1038 ">
the remaining free parameters, i.e. pm and the model scaling factors (och and ney, 2002), <papid> P02-1038 </papid>were adjusted on the development corpus (dev).</citsent>
<aftsection>
<nextsent>the resulting system was evaluated on the test corpus (test).
</nextsent>
<nextsent>table 2: statistics of training and test corpus for the verb mobil task (pp=perplexity, sl=sentence length).
</nextsent>
<nextsent>german english train sentences 58 073 words 519 523 549 921 vocabulary 7 939 4 672 singletons 3 453 1 698 average sl 8.9 9.5 dev sentences 276 words 3 159 3 438 trigram pp - 28.1 average sl 11.5 12.5 test sentences 251 words 2 628 2 871 trigram pp - 30.5 average sl 10.5 11.4 table 3: statistics of training and test corpus for the canadian hansa rds task (pp=perplexity, sl=sentence length).
</nextsent>
<nextsent>french english train sentences 1.5m words 24m 22m vocabulary 100 269 78 332 singletons 40 199 31 319 average sl 16.6 15.1 test sentences 5432 words 97 646 88 773 trigram pp ? 179.8 average sl 18.0 16.3 4.2 canadian hansards.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3026">
<title id=" P03-1019.xml">a comparative study on reordering constraints in statistical machine translation </title>
<section> evaluation in training.  </section>
<citcontext>
<prevsection>
<prevsent>table 3 shows the training and test corpus statistics.
</prevsent>
<prevsent>in this section, we will investigate for each of the constraints the coverage of the training corpus alignment.
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
for this purpose, we compute the viterbi alignment of ibm model 5 with giza++ (och and ney, 2000).<papid> P00-1056 </papid></citsent>
<aftsection>
<nextsent>this alignment is produced without any restrictions on word-reorderings.
</nextsent>
<nextsent>then, we check for every sentence if the alignment satisfies each of the constraints.
</nextsent>
<nextsent>the ratio of the number of satisfied alignments and the total number of sentences is referred to as coverage.
</nextsent>
<nextsent>tab.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3027">
<title id=" P03-1019.xml">a comparative study on reordering constraints in statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the itg constraints were introduced in (wu, 1995).the applications were, for instance, the segmentation of chinese character sequences into chinese words?
</prevsent>
<prevsent>and the bracketing of the source sentence into sub-sentential chunks.
</prevsent>
</prevsection>
<citsent citstr=" P96-1021 ">
in (wu, 1996) <papid> P96-1021 </papid>the baseline itg constraints were used for statistical machine translation.</citsent>
<aftsection>
<nextsent>the resulting algorithm is similar to the one presented insect.
</nextsent>
<nextsent>3.1, but here, we use monotone translation hypotheses of the full ibm model 4 as initialization, whereas in (wu, 1996) <papid> P96-1021 </papid>single-word based lexicon model is used.</nextsent>
<nextsent>in (vilar,1998) model similar to wus method was consid ered.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3031">
<title id=" P03-1005.xml">hierarchical directed acyclic graph kernel methods for structured natural language data </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>treat the same input objects, their kernel calculation methods differ as do the return values.
</prevsent>
<prevsent>we used the words and semantic information of goi-taikei?
</prevsent>
</prevsection>
<citsent citstr=" W02-2016 ">
(ikehara et al, 1997), which is similar to wordnet in english, as the attributes of the node.the chunks and their relations in the texts were analyzed by cabocha (kudo and matsumoto, 2002), <papid> W02-2016 </papid>and named entities were analyzed by the method of (isozaki and kazawa, 2002).<papid> C02-1054 </papid></citsent>
<aftsection>
<nextsent>we tested each ? -combination case with changing parameter ? from 0.1 through 0.9 in the step of 0.1.only the best performance achieved under parameter ? is shown in each case.
</nextsent>
<nextsent>table 3: results of the performance as similarity measure for question classification ? 1 2 3 4 5 6 hdag - .580 .583 .580 .579 .573 dag - .577 .578 .573 .573 .563 dsk?
</nextsent>
<nextsent>- .547 .469 .441 .436 .436 ssk?
</nextsent>
<nextsent>- .568 .572 .570 .562 .548 boa .556 boa?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3032">
<title id=" P03-1005.xml">hierarchical directed acyclic graph kernel methods for structured natural language data </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>treat the same input objects, their kernel calculation methods differ as do the return values.
</prevsent>
<prevsent>we used the words and semantic information of goi-taikei?
</prevsent>
</prevsection>
<citsent citstr=" C02-1054 ">
(ikehara et al, 1997), which is similar to wordnet in english, as the attributes of the node.the chunks and their relations in the texts were analyzed by cabocha (kudo and matsumoto, 2002), <papid> W02-2016 </papid>and named entities were analyzed by the method of (isozaki and kazawa, 2002).<papid> C02-1054 </papid></citsent>
<aftsection>
<nextsent>we tested each ? -combination case with changing parameter ? from 0.1 through 0.9 in the step of 0.1.only the best performance achieved under parameter ? is shown in each case.
</nextsent>
<nextsent>table 3: results of the performance as similarity measure for question classification ? 1 2 3 4 5 6 hdag - .580 .583 .580 .579 .573 dag - .577 .578 .573 .573 .563 dsk?
</nextsent>
<nextsent>- .547 .469 .441 .436 .436 ssk?
</nextsent>
<nextsent>- .568 .572 .570 .562 .548 boa .556 boa?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3033">
<title id=" N12-1087.xml">unified expectation maximization </title>
<section> abstract </section>
<citcontext>
<prevsection>

<prevsent>we present general framework containing graded spectrum of expectation maximization (em) algorithms called unified expectation maximization (uem.)
</prevsent>
</prevsection>
<citsent citstr=" P07-1036 ">
uem is parameterized by single parameter and covers existing algorithms like standard em and hard em, constrained versions of em such as constraint driven learning (chang et al, 2007) <papid> P07-1036 </papid>and posterior regularization (ganchev et al, 2010), along with range of new em algorithms.</citsent>
<aftsection>
<nextsent>for the constrained inference step in uem we present an efficient dual projected gradient as cent algorithm which generalizes several dual decomposition and lagrange relaxation algorithms popularized recently in the nlp literature (ganchev et al, 2008; <papid> P08-1112 </papid>koo et al, 2010; <papid> D10-1125 </papid>rush and collins, 2011).<papid> P11-1008 </papid></nextsent>
<nextsent>uem is as efficient and easy to implement as standard em.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3036">
<title id=" N12-1087.xml">unified expectation maximization </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>we present general framework containing graded spectrum of expectation maximization (em) algorithms called unified expectation maximization (uem.)
</prevsent>
<prevsent>uem is parameterized by single parameter and covers existing algorithms like standard em and hard em, constrained versions of em such as constraint driven learning (chang et al, 2007) <papid> P07-1036 </papid>and posterior regularization (ganchev et al, 2010), along with range of new em algorithms.</prevsent>
</prevsection>
<citsent citstr=" P08-1112 ">
for the constrained inference step in uem we present an efficient dual projected gradient as cent algorithm which generalizes several dual decomposition and lagrange relaxation algorithms popularized recently in the nlp literature (ganchev et al, 2008; <papid> P08-1112 </papid>koo et al, 2010; <papid> D10-1125 </papid>rush and collins, 2011).<papid> P11-1008 </papid></citsent>
<aftsection>
<nextsent>uem is as efficient and easy to implement as standard em.
</nextsent>
<nextsent>furthermore, experiments on pos tagging, information extraction, and word-alignment show that often the best performing algorithm in the uem family is new algorithm that wasnt available earlier, exhibiting the benefits of the uem framework.
</nextsent>
<nextsent>expectation maximization (em) (dempster et al,1977) is in arguably the most widely used algorithm for unsupervised and semi-supervised learning.
</nextsent>
<nextsent>many successful applications of unsupervised and semi-supervised learning in nlp use em including text classification (mccallum et al, 1998; nigam et al, 2000), machine translation (brown et al., 1993), <papid> J93-2003 </papid>and parsing (klein and manning, 2004).<papid> P04-1061 </papid>recently, em algorithms which incorporate constraints on structured output spaces have been proposed (chang et al, 2007; <papid> P07-1036 </papid>ganchev et al, 2010).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3037">
<title id=" N12-1087.xml">unified expectation maximization </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>we present general framework containing graded spectrum of expectation maximization (em) algorithms called unified expectation maximization (uem.)
</prevsent>
<prevsent>uem is parameterized by single parameter and covers existing algorithms like standard em and hard em, constrained versions of em such as constraint driven learning (chang et al, 2007) <papid> P07-1036 </papid>and posterior regularization (ganchev et al, 2010), along with range of new em algorithms.</prevsent>
</prevsection>
<citsent citstr=" D10-1125 ">
for the constrained inference step in uem we present an efficient dual projected gradient as cent algorithm which generalizes several dual decomposition and lagrange relaxation algorithms popularized recently in the nlp literature (ganchev et al, 2008; <papid> P08-1112 </papid>koo et al, 2010; <papid> D10-1125 </papid>rush and collins, 2011).<papid> P11-1008 </papid></citsent>
<aftsection>
<nextsent>uem is as efficient and easy to implement as standard em.
</nextsent>
<nextsent>furthermore, experiments on pos tagging, information extraction, and word-alignment show that often the best performing algorithm in the uem family is new algorithm that wasnt available earlier, exhibiting the benefits of the uem framework.
</nextsent>
<nextsent>expectation maximization (em) (dempster et al,1977) is in arguably the most widely used algorithm for unsupervised and semi-supervised learning.
</nextsent>
<nextsent>many successful applications of unsupervised and semi-supervised learning in nlp use em including text classification (mccallum et al, 1998; nigam et al, 2000), machine translation (brown et al., 1993), <papid> J93-2003 </papid>and parsing (klein and manning, 2004).<papid> P04-1061 </papid>recently, em algorithms which incorporate constraints on structured output spaces have been proposed (chang et al, 2007; <papid> P07-1036 </papid>ganchev et al, 2010).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3038">
<title id=" N12-1087.xml">unified expectation maximization </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>we present general framework containing graded spectrum of expectation maximization (em) algorithms called unified expectation maximization (uem.)
</prevsent>
<prevsent>uem is parameterized by single parameter and covers existing algorithms like standard em and hard em, constrained versions of em such as constraint driven learning (chang et al, 2007) <papid> P07-1036 </papid>and posterior regularization (ganchev et al, 2010), along with range of new em algorithms.</prevsent>
</prevsection>
<citsent citstr=" P11-1008 ">
for the constrained inference step in uem we present an efficient dual projected gradient as cent algorithm which generalizes several dual decomposition and lagrange relaxation algorithms popularized recently in the nlp literature (ganchev et al, 2008; <papid> P08-1112 </papid>koo et al, 2010; <papid> D10-1125 </papid>rush and collins, 2011).<papid> P11-1008 </papid></citsent>
<aftsection>
<nextsent>uem is as efficient and easy to implement as standard em.
</nextsent>
<nextsent>furthermore, experiments on pos tagging, information extraction, and word-alignment show that often the best performing algorithm in the uem family is new algorithm that wasnt available earlier, exhibiting the benefits of the uem framework.
</nextsent>
<nextsent>expectation maximization (em) (dempster et al,1977) is in arguably the most widely used algorithm for unsupervised and semi-supervised learning.
</nextsent>
<nextsent>many successful applications of unsupervised and semi-supervised learning in nlp use em including text classification (mccallum et al, 1998; nigam et al, 2000), machine translation (brown et al., 1993), <papid> J93-2003 </papid>and parsing (klein and manning, 2004).<papid> P04-1061 </papid>recently, em algorithms which incorporate constraints on structured output spaces have been proposed (chang et al, 2007; <papid> P07-1036 </papid>ganchev et al, 2010).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3041">
<title id=" N12-1087.xml">unified expectation maximization </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>furthermore, experiments on pos tagging, information extraction, and word-alignment show that often the best performing algorithm in the uem family is new algorithm that wasnt available earlier, exhibiting the benefits of the uem framework.
</prevsent>
<prevsent>expectation maximization (em) (dempster et al,1977) is in arguably the most widely used algorithm for unsupervised and semi-supervised learning.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
many successful applications of unsupervised and semi-supervised learning in nlp use em including text classification (mccallum et al, 1998; nigam et al, 2000), machine translation (brown et al., 1993), <papid> J93-2003 </papid>and parsing (klein and manning, 2004).<papid> P04-1061 </papid>recently, em algorithms which incorporate constraints on structured output spaces have been proposed (chang et al, 2007; <papid> P07-1036 </papid>ganchev et al, 2010).</citsent>
<aftsection>
<nextsent>several variations of em (e.g. hard em) exist inthe literature and choosing suitable variation is of ten very task-specific.
</nextsent>
<nextsent>some works have shown thatfor certain tasks, hard em is more suitable than regular em (spitkovsky et al, 2010).<papid> W10-2902 </papid></nextsent>
<nextsent>the same issue continues in the presence of constraints where posterior regularization (pr) (ganchev et al, 2010) corresponds to em while constraint-driven learning (codl)1 (chang et al, 2007) <papid> P07-1036 </papid>corresponds to hard em.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3042">
<title id=" N12-1087.xml">unified expectation maximization </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>furthermore, experiments on pos tagging, information extraction, and word-alignment show that often the best performing algorithm in the uem family is new algorithm that wasnt available earlier, exhibiting the benefits of the uem framework.
</prevsent>
<prevsent>expectation maximization (em) (dempster et al,1977) is in arguably the most widely used algorithm for unsupervised and semi-supervised learning.
</prevsent>
</prevsection>
<citsent citstr=" P04-1061 ">
many successful applications of unsupervised and semi-supervised learning in nlp use em including text classification (mccallum et al, 1998; nigam et al, 2000), machine translation (brown et al., 1993), <papid> J93-2003 </papid>and parsing (klein and manning, 2004).<papid> P04-1061 </papid>recently, em algorithms which incorporate constraints on structured output spaces have been proposed (chang et al, 2007; <papid> P07-1036 </papid>ganchev et al, 2010).</citsent>
<aftsection>
<nextsent>several variations of em (e.g. hard em) exist inthe literature and choosing suitable variation is of ten very task-specific.
</nextsent>
<nextsent>some works have shown thatfor certain tasks, hard em is more suitable than regular em (spitkovsky et al, 2010).<papid> W10-2902 </papid></nextsent>
<nextsent>the same issue continues in the presence of constraints where posterior regularization (pr) (ganchev et al, 2010) corresponds to em while constraint-driven learning (codl)1 (chang et al, 2007) <papid> P07-1036 </papid>corresponds to hard em.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3045">
<title id=" N12-1087.xml">unified expectation maximization </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>many successful applications of unsupervised and semi-supervised learning in nlp use em including text classification (mccallum et al, 1998; nigam et al, 2000), machine translation (brown et al., 1993), <papid> J93-2003 </papid>and parsing (klein and manning, 2004).<papid> P04-1061 </papid>recently, em algorithms which incorporate constraints on structured output spaces have been proposed (chang et al, 2007; <papid> P07-1036 </papid>ganchev et al, 2010).</prevsent>
<prevsent>several variations of em (e.g. hard em) exist inthe literature and choosing suitable variation is of ten very task-specific.</prevsent>
</prevsection>
<citsent citstr=" W10-2902 ">
some works have shown thatfor certain tasks, hard em is more suitable than regular em (spitkovsky et al, 2010).<papid> W10-2902 </papid></citsent>
<aftsection>
<nextsent>the same issue continues in the presence of constraints where posterior regularization (pr) (ganchev et al, 2010) corresponds to em while constraint-driven learning (codl)1 (chang et al, 2007) <papid> P07-1036 </papid>corresponds to hard em.</nextsent>
<nextsent>the problem of choosing between em and hard em (or between pr and codl) remains elusive,along with the possibility of simple and better alternatives, to practitioners.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3056">
<title id=" N12-1087.xml">unified expectation maximization </title>
<section> preliminaries.  </section>
<citcontext>
<prevsection>
<prevsent>2.2 constraints in em.
</prevsent>
<prevsent>it has become common practice in the nlp community to use constraints on output variables to guide inference.
</prevsent>
</prevsection>
<citsent citstr=" W04-2401 ">
few of many examples include type constraints between relations and entities (roth and yih, 2004), <papid> W04-2401 </papid>sentential and modifier constraints during sentence compression (clarke and lapata,2006), <papid> P06-2019 </papid>and agreement constraints between word alignment directions (ganchev et al, 2008) <papid> P08-1112 </papid>or various parsing models (koo et al, 2010).<papid> D10-1125 </papid></citsent>
<aftsection>
<nextsent>in the con 689text of em, constraints can be imposed on the posterior probabilities, q, to guide the learning procedure (chang et al, 2007; <papid> P07-1036 </papid>ganchev et al, 2010).</nextsent>
<nextsent>in this paper, we focus on linear constraints overh (potentially non-linear over x.)</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3057">
<title id=" N12-1087.xml">unified expectation maximization </title>
<section> preliminaries.  </section>
<citcontext>
<prevsection>
<prevsent>2.2 constraints in em.
</prevsent>
<prevsent>it has become common practice in the nlp community to use constraints on output variables to guide inference.
</prevsent>
</prevsection>
<citsent citstr=" P06-2019 ">
few of many examples include type constraints between relations and entities (roth and yih, 2004), <papid> W04-2401 </papid>sentential and modifier constraints during sentence compression (clarke and lapata,2006), <papid> P06-2019 </papid>and agreement constraints between word alignment directions (ganchev et al, 2008) <papid> P08-1112 </papid>or various parsing models (koo et al, 2010).<papid> D10-1125 </papid></citsent>
<aftsection>
<nextsent>in the con 689text of em, constraints can be imposed on the posterior probabilities, q, to guide the learning procedure (chang et al, 2007; <papid> P07-1036 </papid>ganchev et al, 2010).</nextsent>
<nextsent>in this paper, we focus on linear constraints overh (potentially non-linear over x.)</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3068">
<title id=" N12-1087.xml">unified expectation maximization </title>
<section> unified expectation maximization.  </section>
<citcontext>
<prevsection>
<prevsent>we refer to the uem algorithm with parameter ? as uem?
</prevsent>
<prevsent>3.1 relationship between uem and other em.
</prevsent>
</prevsection>
<citsent citstr=" P04-1062 ">
algorithms the relation between unconstrained versions of em has been mentioned before (ueda and nakano, 1998; smith and eisner, 2004).<papid> P04-1062 </papid></citsent>
<aftsection>
<nextsent>we show that the relationship takes novel aspects in the presence of constraints.
</nextsent>
<nextsent>in order to better understand differentuem variations, we write the uem e-step (6) explicitly as an optimization problem: 3the term metric?
</nextsent>
<nextsent>is used very loosely.
</nextsent>
<nextsent>kl(?, ?; ?) does not satisfy the mathematical properties of metric.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3073">
<title id=" N12-1087.xml">unified expectation maximization </title>
<section> unified expectation maximization.  </section>
<citcontext>
<prevsection>
<prevsent>second, for ? = 0, the e-step solves max ? hh(x) q(h) logp?(h|x) (10) s.t. eq[uh] ? b, q(h) ? 0, ? h(x), ? hh(x) q(h) = 1 , which is an lp-relaxation of hard em (eq.
</prevsent>
<prevsent>(4) and (9)).
</prevsent>
</prevsection>
<citsent citstr=" P09-1039 ">
lp relaxations often provide decent proxy to ilp (roth and yih, 2004; <papid> W04-2401 </papid>martins et al, 2009).<papid> P09-1039 </papid></citsent>
<aftsection>
<nextsent>third, ? ?
</nextsent>
<nextsent>[0, 1] covers standard em/pr.
</nextsent>
<nextsent>3.2.1 discussion: role of ? the modified kl divergence can be related to standard kl divergence as kl(q, p?(h|x); ?) = 691kl(q, p?(y|x)) + (1?
</nextsent>
<nextsent>?)h(q) ? uem (6) minimizes the former during the e-step, while standard em (3) minimizes the latter.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3077">
<title id=" N12-1087.xml">unified expectation maximization </title>
<section> solving constrained e-step with.  </section>
<citcontext>
<prevsection>
<prevsent>existing code for constrained em (pr or codl) can be easily extended to run uem.
</prevsent>
<prevsent>we solve the e-step (8) using lagrangian dual-based algorithm which performs projectedsubgradient-ascent on dual variables.
</prevsent>
</prevsection>
<citsent citstr=" D10-1001 ">
our algorithm covers lagrange relaxation and dual decomposition techniques (bertsekas, 1999) which were recently popularized in nlp (rush and collins, 2011; <papid> P11-1008 </papid>rush et al, 2010; <papid> D10-1001 </papid>koo et al, 2010).<papid> D10-1125 </papid></citsent>
<aftsection>
<nextsent>not only do we extend the algorithmic framework to continuum of algorithms, we also allow, unlike the aforementioned works, general inequality constraints over the output variables.
</nextsent>
<nextsent>furthermore, we establish new and interesting connections between existing constrained inference techniques.
</nextsent>
<nextsent>4.1 projected sub gradient ascent with.
</nextsent>
<nextsent>lagrangian dualwe provide below high-level view of our algorithm, omitting the technical derivations due to lack of space.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3093">
<title id=" N12-1087.xml">unified expectation maximization </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>that hardem is better choice than em with good initialization point whereas the opposite is true with an uninformed?
</prevsent>
<prevsent>initialization.unsupervised pos tagging we conduct experiments on unsupervised pos learning experiment with the tagging dictionary assumption.
</prevsent>
</prevsection>
<citsent citstr=" P09-1057 ">
we use standard subset of penn treebank containing 24,115tokens (ravi and knight, 2009) <papid> P09-1057 </papid>with the tagging dictionary derived from the entire penn treebank.</citsent>
<aftsection>
<nextsent>we run uem with first order (bigram) hmm model5.
</nextsent>
<nextsent>we consider initialization points of varying quality and observe the performance for ? ?
</nextsent>
<nextsent>[0, 1].
</nextsent>
<nextsent>different initialization points are constructed as follows.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3098">
<title id=" N12-1087.xml">unified expectation maximization </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>furthermore, the results not only indicate that measure of hardness?
</prevsent>
<prevsent>of em i.e. the best value 694of ?, is closely related to the quality of the initialization point but also elicit more fine-grained relationship between initialization and uem.
</prevsent>
</prevsection>
<citsent citstr=" J94-2001 ">
this experiment agrees with (merialdo, 1994),<papid> J94-2001 </papid>which shows that em performs poorly in the semi supervised setting.</citsent>
<aftsection>
<nextsent>in (spitkovsky et al, 2010), <papid> W10-2902 </papid>the authors show that hard em (viterbi em) works better than standard em.</nextsent>
<nextsent>we extend these results by showing that this issue can be overcome with the uem framework by picking appropriate ? based on the amount of available labeled data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3101">
<title id=" N12-1087.xml">unified expectation maximization </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we add relation type none indicating no relation exists between given pair of entities.
</prevsent>
<prevsent>we train two loglinear models for entity type and relation type prediction, respectively via discriminative uem.
</prevsent>
</prevsection>
<citsent citstr=" W09-1110 ">
we work in discriminative setting in order to use several informative features which we borrow from (roth and small, 2009).<papid> W09-1110 </papid></citsent>
<aftsection>
<nextsent>using these features, we obtain 56% average f1 for relations and88% average f1 for entities in fully supervised setting with an 80-20 split which is competitive with the reported results on this data (roth and yih, 2004; <papid> W04-2401 </papid>roth and small, 2009).<papid> W09-1110 </papid></nextsent>
<nextsent>for our ssl experiments, we use 20% of data for testing, small amount, ?%,as labeled training data (we vary ?), and the remaining as unlabeled training data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3108">
<title id=" N12-1087.xml">unified expectation maximization </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>however, notably, for entities, for ? = 10%, uem outperforms codl and pr and for 20%, the supervised baseline outperforms pr statistically significantly.
</prevsent>
<prevsent>word alignment statistical word alignment is awell known structured output application of unsupervised learning and is key step towards machine translation from source language to target language . we experiment with two language pairs: english-french and english-spanish.
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
weuse hansa rds corpus for french-english translation (och and ney, 2000) <papid> P00-1056 </papid>and europarl corpus (koehn, 2002) for spanish-english translation with epps (lambert et al, 2005) annotation.we use an hmm-based model for word alignment (vogel et al, 1996) <papid> C96-2141 </papid>and add agreement constraints (liang et al, 2008; ganchev et al, 2008) <papid> P08-1112 </papid>to constrain alignment probabilities in one direction(p1 : from to ) to agree with the alignment probabilities in the other direction (p2 : from to s.)</citsent>
<aftsection>
<nextsent>we use small development set of size 50 to tune the model.
</nextsent>
<nextsent>note that the amount of labeled data we use is much smaller than the supervised approaches reported in (taskar et al, 2005; <papid> H05-1010 </papid>moore et al, 2006) <papid> P06-1065 </papid>and unsupervised approaches mentioned in (liang et al., 2008; ganchev et al, 2008) <papid> P08-1112 </papid>and hence our results are not directly comparable.</nextsent>
<nextsent>for the e-step, we use alg.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3109">
<title id=" N12-1087.xml">unified expectation maximization </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>however, notably, for entities, for ? = 10%, uem outperforms codl and pr and for 20%, the supervised baseline outperforms pr statistically significantly.
</prevsent>
<prevsent>word alignment statistical word alignment is awell known structured output application of unsupervised learning and is key step towards machine translation from source language to target language . we experiment with two language pairs: english-french and english-spanish.
</prevsent>
</prevsection>
<citsent citstr=" C96-2141 ">
weuse hansa rds corpus for french-english translation (och and ney, 2000) <papid> P00-1056 </papid>and europarl corpus (koehn, 2002) for spanish-english translation with epps (lambert et al, 2005) annotation.we use an hmm-based model for word alignment (vogel et al, 1996) <papid> C96-2141 </papid>and add agreement constraints (liang et al, 2008; ganchev et al, 2008) <papid> P08-1112 </papid>to constrain alignment probabilities in one direction(p1 : from to ) to agree with the alignment probabilities in the other direction (p2 : from to s.)</citsent>
<aftsection>
<nextsent>we use small development set of size 50 to tune the model.
</nextsent>
<nextsent>note that the amount of labeled data we use is much smaller than the supervised approaches reported in (taskar et al, 2005; <papid> H05-1010 </papid>moore et al, 2006) <papid> P06-1065 </papid>and unsupervised approaches mentioned in (liang et al., 2008; ganchev et al, 2008) <papid> P08-1112 </papid>and hence our results are not directly comparable.</nextsent>
<nextsent>for the e-step, we use alg.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3114">
<title id=" N12-1087.xml">unified expectation maximization </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>weuse hansa rds corpus for french-english translation (och and ney, 2000) <papid> P00-1056 </papid>and europarl corpus (koehn, 2002) for spanish-english translation with epps (lambert et al, 2005) annotation.we use an hmm-based model for word alignment (vogel et al, 1996) <papid> C96-2141 </papid>and add agreement constraints (liang et al, 2008; ganchev et al, 2008) <papid> P08-1112 </papid>to constrain alignment probabilities in one direction(p1 : from to ) to agree with the alignment probabilities in the other direction (p2 : from to s.)</prevsent>
<prevsent>we use small development set of size 50 to tune the model.</prevsent>
</prevsection>
<citsent citstr=" H05-1010 ">
note that the amount of labeled data we use is much smaller than the supervised approaches reported in (taskar et al, 2005; <papid> H05-1010 </papid>moore et al, 2006) <papid> P06-1065 </papid>and unsupervised approaches mentioned in (liang et al., 2008; ganchev et al, 2008) <papid> P08-1112 </papid>and hence our results are not directly comparable.</citsent>
<aftsection>
<nextsent>for the e-step, we use alg.
</nextsent>
<nextsent>3 with r=5 and pick ? from {0.0, 0.1, . . .
</nextsent>
<nextsent>, 1.0}, tuning it over the development set.during testing, instead of running hmm models for each direction separately, we obtain posterior probabilities by performing agreement constraints based inference as in alg.
</nextsent>
<nextsent>3.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3115">
<title id=" N12-1087.xml">unified expectation maximization </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>weuse hansa rds corpus for french-english translation (och and ney, 2000) <papid> P00-1056 </papid>and europarl corpus (koehn, 2002) for spanish-english translation with epps (lambert et al, 2005) annotation.we use an hmm-based model for word alignment (vogel et al, 1996) <papid> C96-2141 </papid>and add agreement constraints (liang et al, 2008; ganchev et al, 2008) <papid> P08-1112 </papid>to constrain alignment probabilities in one direction(p1 : from to ) to agree with the alignment probabilities in the other direction (p2 : from to s.)</prevsent>
<prevsent>we use small development set of size 50 to tune the model.</prevsent>
</prevsection>
<citsent citstr=" P06-1065 ">
note that the amount of labeled data we use is much smaller than the supervised approaches reported in (taskar et al, 2005; <papid> H05-1010 </papid>moore et al, 2006) <papid> P06-1065 </papid>and unsupervised approaches mentioned in (liang et al., 2008; ganchev et al, 2008) <papid> P08-1112 </papid>and hence our results are not directly comparable.</citsent>
<aftsection>
<nextsent>for the e-step, we use alg.
</nextsent>
<nextsent>3 with r=5 and pick ? from {0.0, 0.1, . . .
</nextsent>
<nextsent>, 1.0}, tuning it over the development set.during testing, instead of running hmm models for each direction separately, we obtain posterior probabilities by performing agreement constraints based inference as in alg.
</nextsent>
<nextsent>3.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3124">
<title id=" N12-1087.xml">unified expectation maximization </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>threshold, tuned over the development set.
</prevsent>
<prevsent>results we compare uem with em, pr, and codl on the basis of alignment error rate (aer) for different sizes of unlabeled data (see tab.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
2.) see (och and ney, 2003) <papid> J03-1002 </papid>for the definition of aer.</citsent>
<aftsection>
<nextsent>uem consistently outperforms em, pr, and codl with wide margin.
</nextsent>
<nextsent>we proposed continuum of em algorithms parameterized by single parameter.
</nextsent>
<nextsent>our framework naturally incorporates constraints on output variables and generalizes existing constrained and unconstrained em algorithms like standard and hard em, pr, and codl.
</nextsent>
<nextsent>we provided an efficient lagrange relaxation algorithm for inference with constraints in the e-step and empirically showed how important it is to choose the right em version.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3125">
<title id=" P00-1010.xml">robust temporal processing of news </title>
<section> time tagging performance.  </section>
<citcontext>
<prevsection>
<prevsent>(the muc task required recognizing wider variety of timexs, including event-dependent ones.
</prevsent>
<prevsent>however, at least 30% of the dates and times in the muc test were fixed-format ones occurring in document headers, trailers, and copyright notices.
</prevsent>
</prevsection>
<citsent citstr=" J88-2003 ">
) finally, there is large body of work, e.g., (moens and steedman 1988), (<papid> J88-2003 </papid>passoneau 1988), (webber 1988), (<papid> J88-2006 </papid>hwang 1992), (song and cohen 1991), that has focused on computational analysis of tense and aspect.</citsent>
<aftsection>
<nextsent>while the work on event chronologies is based on some of the notions developed in that body of work, we hope to further exploit insights from previous work.
</nextsent>
<nextsent>conclusion we have developed temporal annotation specification, and an algorithm for resolving class of time expressions found in news.
</nextsent>
<nextsent>the algorithm, which is relatively knowledge-poor, uses mix of hand-crafted and machine-learnt rules and obtains reasonable results.
</nextsent>
<nextsent>in the future, we expect to improve the integration of various modules, including tracking the temporal focus in the timeresolver, and interaction between the event order and the event-aligner.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3126">
<title id=" P00-1010.xml">robust temporal processing of news </title>
<section> time tagging performance.  </section>
<citcontext>
<prevsection>
<prevsent>(the muc task required recognizing wider variety of timexs, including event-dependent ones.
</prevsent>
<prevsent>however, at least 30% of the dates and times in the muc test were fixed-format ones occurring in document headers, trailers, and copyright notices.
</prevsent>
</prevsection>
<citsent citstr=" J88-2006 ">
) finally, there is large body of work, e.g., (moens and steedman 1988), (<papid> J88-2003 </papid>passoneau 1988), (webber 1988), (<papid> J88-2006 </papid>hwang 1992), (song and cohen 1991), that has focused on computational analysis of tense and aspect.</citsent>
<aftsection>
<nextsent>while the work on event chronologies is based on some of the notions developed in that body of work, we hope to further exploit insights from previous work.
</nextsent>
<nextsent>conclusion we have developed temporal annotation specification, and an algorithm for resolving class of time expressions found in news.
</nextsent>
<nextsent>the algorithm, which is relatively knowledge-poor, uses mix of hand-crafted and machine-learnt rules and obtains reasonable results.
</nextsent>
<nextsent>in the future, we expect to improve the integration of various modules, including tracking the temporal focus in the timeresolver, and interaction between the event order and the event-aligner.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3127">
<title id=" P02-1007.xml">ot syntax  decidability of generation based optimization </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>in optimality-theoretic syntax, optimization with unrestricted expressive power onthe side of the ot constraints is unde cidable.
</prevsent>
<prevsent>this paper provides proof for the decidability of optimization based on constraints expressed with reference to local subtrees (which is in the spirit of ot theory).
</prevsent>
</prevsection>
<citsent citstr=" C00-1062 ">
the proof builds on kaplan and wedekinds (2000) <papid> C00-1062 </papid>construction showing that lfg generation produces context free languages.</citsent>
<aftsection>
<nextsent>optimality-theoretic (ot) grammar systems are an interesting alternative to classical formal grammars, as they construe the task of learning from data ina meaning-based way: form is defined as grammatical if it is optimal (most harmonic) within set of generation alternatives for an underlying logical form.
</nextsent>
<nextsent>the harmony of candidate analysis depend son language-specific ranking (
</nextsent>
<nextsent>) of viola ble constraints, thus the learning task amounts to adjusting the ranking over given set of constraints.
</nextsent>
<nextsent>(1) candidate  is more harmonic than  iff it incurs fewer violations of the highest-ranking constraint   in which  and  differ.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3128">
<title id=" P02-1007.xml">ot syntax  decidability of generation based optimization </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>) of viola ble constraints, thus the learning task amounts to adjusting the ranking over given set of constraints.
</prevsent>
<prevsent>(1) candidate  is more harmonic than  iff it incurs fewer violations of the highest-ranking constraint   in which  and  differ.
</prevsent>
</prevsection>
<citsent citstr=" P99-1069 ">
the comparison-based setup of ot learning is closely related to discriminative learning approaches in probabilistic parsing (johnson et al, 1999; <papid> P99-1069 </papid>riezler et al, 2000; <papid> P00-1061 </papid>riezler et al, 2002),<papid> P02-1035 </papid>1 however the comparison of generation alternatives ? rather than parsing alternatives ? adds the possibility of systematically learning the basic language-specific grammatical principles (which in probabilistic parsing are typically fixed priori, using either treebank derived or manually written grammar for the given  this work was supported by postdoctoral fellowship of the german academic exchange service (daad).</citsent>
<aftsection>
<nextsent>1this is for instance pointed out by (johnson, 1998).
</nextsent>
<nextsent>language).
</nextsent>
<nextsent>the base grammar?
</nextsent>
<nextsent>assumed as given can be highly unrestricted in the ot setup.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3129">
<title id=" P02-1007.xml">ot syntax  decidability of generation based optimization </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>) of viola ble constraints, thus the learning task amounts to adjusting the ranking over given set of constraints.
</prevsent>
<prevsent>(1) candidate  is more harmonic than  iff it incurs fewer violations of the highest-ranking constraint   in which  and  differ.
</prevsent>
</prevsection>
<citsent citstr=" P00-1061 ">
the comparison-based setup of ot learning is closely related to discriminative learning approaches in probabilistic parsing (johnson et al, 1999; <papid> P99-1069 </papid>riezler et al, 2000; <papid> P00-1061 </papid>riezler et al, 2002),<papid> P02-1035 </papid>1 however the comparison of generation alternatives ? rather than parsing alternatives ? adds the possibility of systematically learning the basic language-specific grammatical principles (which in probabilistic parsing are typically fixed priori, using either treebank derived or manually written grammar for the given  this work was supported by postdoctoral fellowship of the german academic exchange service (daad).</citsent>
<aftsection>
<nextsent>1this is for instance pointed out by (johnson, 1998).
</nextsent>
<nextsent>language).
</nextsent>
<nextsent>the base grammar?
</nextsent>
<nextsent>assumed as given can be highly unrestricted in the ot setup.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3130">
<title id=" P02-1007.xml">ot syntax  decidability of generation based optimization </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>) of viola ble constraints, thus the learning task amounts to adjusting the ranking over given set of constraints.
</prevsent>
<prevsent>(1) candidate  is more harmonic than  iff it incurs fewer violations of the highest-ranking constraint   in which  and  differ.
</prevsent>
</prevsection>
<citsent citstr=" P02-1035 ">
the comparison-based setup of ot learning is closely related to discriminative learning approaches in probabilistic parsing (johnson et al, 1999; <papid> P99-1069 </papid>riezler et al, 2000; <papid> P00-1061 </papid>riezler et al, 2002),<papid> P02-1035 </papid>1 however the comparison of generation alternatives ? rather than parsing alternatives ? adds the possibility of systematically learning the basic language-specific grammatical principles (which in probabilistic parsing are typically fixed priori, using either treebank derived or manually written grammar for the given  this work was supported by postdoctoral fellowship of the german academic exchange service (daad).</citsent>
<aftsection>
<nextsent>1this is for instance pointed out by (johnson, 1998).
</nextsent>
<nextsent>language).
</nextsent>
<nextsent>the base grammar?
</nextsent>
<nextsent>assumed as given can be highly unrestricted in the ot setup.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3131">
<title id=" P02-1007.xml">ot syntax  decidability of generation based optimization </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>using linguistically motivated set of constraints, learning proceeds with bias for unmarked linguistic structures (cf.
</prevsent>
<prevsent>e.g., (bresnan et al, 2001)).
</prevsent>
</prevsection>
<citsent citstr=" P00-1046 ">
for computational ot syntax, an inter leaving of candidate generation and constraint checking has been proposed (kuhn, 2000).<papid> P00-1046 </papid></citsent>
<aftsection>
<nextsent>but the decidabilityof the optimization task in ot syntax, i.e., the identification of the optimal candidate(s) in potentially infinite candidate set, has not been proven yet.2
</nextsent>
<nextsent>assume that the candidate set is characterized bya context-free grammar (cfg)  , plus one additional candidate yes?.
</nextsent>
<nextsent>there are two constraints (
</nextsent>
<nextsent> ):   is violated if the candidate is neither yes?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3133">
<title id=" P02-1007.xml">ot syntax  decidability of generation based optimization </title>
<section> ot-lfg.  </section>
<citcontext>
<prevsection>
<prevsent>is in the language defined by this system iff there are no structures in  that are also in   . but the emptiness problem.
</prevsent>
<prevsent>for the intersection of two context-free languages is known to be undecidable, so the optimization task for unrestricted ot is undecidable too.3 however, it is not in the spirit of ot to have extremely powerful individual constraints; the explanatory power should rather arise from interaction of simple constraints.
</prevsent>
</prevsection>
<citsent citstr=" J98-2006 ">
following (bresnan, 2000; kuhn, 2000; <papid> P00-1046 </papid>kuhn, 2001), we define restricted ot system basedon lexical-functional grammar (lfg) represen tations: c(ategory) structure/f(unctional) structure 2most computational ot work so far focuses on candidatesand constraints expressible as regular languages/rational relations, based on (frank and satta, 1998) (<papid> J98-2006 </papid>e.g., (eisner, 1997; <papid> P97-1040 </papid>karttunen, 1998; <papid> W98-1301 </papid>gerdemann and van noord, 2000)).</citsent>
<aftsection>
<nextsent>3cf.
</nextsent>
<nextsent>also (johnson, 1998) for the sketch of an undecidability argument and (kuhn, 2001, 4.2, 6.3) for further constructions.
</nextsent>
<nextsent>computational linguistics (acl), philadelphia, july 2002, pp.
</nextsent>
<nextsent>48-55.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3134">
<title id=" P02-1007.xml">ot syntax  decidability of generation based optimization </title>
<section> ot-lfg.  </section>
<citcontext>
<prevsection>
<prevsent>is in the language defined by this system iff there are no structures in  that are also in   . but the emptiness problem.
</prevsent>
<prevsent>for the intersection of two context-free languages is known to be undecidable, so the optimization task for unrestricted ot is undecidable too.3 however, it is not in the spirit of ot to have extremely powerful individual constraints; the explanatory power should rather arise from interaction of simple constraints.
</prevsent>
</prevsection>
<citsent citstr=" P97-1040 ">
following (bresnan, 2000; kuhn, 2000; <papid> P00-1046 </papid>kuhn, 2001), we define restricted ot system basedon lexical-functional grammar (lfg) represen tations: c(ategory) structure/f(unctional) structure 2most computational ot work so far focuses on candidatesand constraints expressible as regular languages/rational relations, based on (frank and satta, 1998) (<papid> J98-2006 </papid>e.g., (eisner, 1997; <papid> P97-1040 </papid>karttunen, 1998; <papid> W98-1301 </papid>gerdemann and van noord, 2000)).</citsent>
<aftsection>
<nextsent>3cf.
</nextsent>
<nextsent>also (johnson, 1998) for the sketch of an undecidability argument and (kuhn, 2001, 4.2, 6.3) for further constructions.
</nextsent>
<nextsent>computational linguistics (acl), philadelphia, july 2002, pp.
</nextsent>
<nextsent>48-55.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3135">
<title id=" P02-1007.xml">ot syntax  decidability of generation based optimization </title>
<section> ot-lfg.  </section>
<citcontext>
<prevsection>
<prevsent>is in the language defined by this system iff there are no structures in  that are also in   . but the emptiness problem.
</prevsent>
<prevsent>for the intersection of two context-free languages is known to be undecidable, so the optimization task for unrestricted ot is undecidable too.3 however, it is not in the spirit of ot to have extremely powerful individual constraints; the explanatory power should rather arise from interaction of simple constraints.
</prevsent>
</prevsection>
<citsent citstr=" W98-1301 ">
following (bresnan, 2000; kuhn, 2000; <papid> P00-1046 </papid>kuhn, 2001), we define restricted ot system basedon lexical-functional grammar (lfg) represen tations: c(ategory) structure/f(unctional) structure 2most computational ot work so far focuses on candidatesand constraints expressible as regular languages/rational relations, based on (frank and satta, 1998) (<papid> J98-2006 </papid>e.g., (eisner, 1997; <papid> P97-1040 </papid>karttunen, 1998; <papid> W98-1301 </papid>gerdemann and van noord, 2000)).</citsent>
<aftsection>
<nextsent>3cf.
</nextsent>
<nextsent>also (johnson, 1998) for the sketch of an undecidability argument and (kuhn, 2001, 4.2, 6.3) for further constructions.
</nextsent>
<nextsent>computational linguistics (acl), philadelphia, july 2002, pp.
</nextsent>
<nextsent>48-55.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3138">
<title id=" P02-1026.xml">entropy rate constancy in text </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>this is in fact an estimate ofcross entropy between our model and true distribution.
</prevsent>
<prevsent>thus we are overestimating the entropy, but if we assume that the overestimation error ismore or less uniform, we should still see our estimate increase as the sentence number increases.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
penn treebank corpus (marcus et al, 1993)<papid> J93-2004 </papid>sections 0-20 were used for training, sections 2124 for testing.</citsent>
<aftsection>
<nextsent>each article was treated as separate text, results for each sentence number were grouped together, and the mean value reported on figure 1 (dashed line).
</nextsent>
<nextsent>since most articles are short, there are fewer sentences available for larger sentence numbers, thus results for large sentence numbers are less reliable.
</nextsent>
<nextsent>the trend is fairly obvious, especially for small sentence numbers: sentences (with no context used) get harder as sentence number increases, i.e. the probability of the sentence given the model decreases.
</nextsent>
<nextsent>4.2 parser model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3139">
<title id=" P04-1081.xml">a kernel pca method for superior word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also contrast against another type of kernel method, the support vector machine (svm) model, and show that our kpca-based model outperforms the svm-based model.
</prevsent>
<prevsent>it is hoped that these highly encouraging first results on kpca for natural language processing tasks will inspire further development of these directions.
</prevsent>
</prevsection>
<citsent citstr=" W96-0208 ">
achieving higher precision in supervised word sense disambiguation (wsd) tasks without resorting to ad hoc voting or similar ensemble techniques has become somewhat daunting in recent years, given the challenging benchmarks set by nave bayes models (e.g., mooney (1996), <papid> W96-0208 </papid>chodorow etal.</citsent>
<aftsection>
<nextsent>(1999), pedersen (2001), yarowsky and florian (2002)) as well as maximum entropy models(e.g., dang and palmer (2002), <papid> W02-0813 </papid>klein and manning (2002)).<papid> W02-1002 </papid></nextsent>
<nextsent>a good foundation for comparative studies has been established by the senseval data and evaluations; of particular relevance here are the lexical sample tasks from senseval-1 (kilgarriff and rosenzweig, 1999) and senseval-2 (kilgarriff, 2001).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3140">
<title id=" P04-1081.xml">a kernel pca method for superior word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it is hoped that these highly encouraging first results on kpca for natural language processing tasks will inspire further development of these directions.
</prevsent>
<prevsent>achieving higher precision in supervised word sense disambiguation (wsd) tasks without resorting to ad hoc voting or similar ensemble techniques has become somewhat daunting in recent years, given the challenging benchmarks set by nave bayes models (e.g., mooney (1996), <papid> W96-0208 </papid>chodorow etal.</prevsent>
</prevsection>
<citsent citstr=" W02-0813 ">
(1999), pedersen (2001), yarowsky and florian (2002)) as well as maximum entropy models(e.g., dang and palmer (2002), <papid> W02-0813 </papid>klein and manning (2002)).<papid> W02-1002 </papid></citsent>
<aftsection>
<nextsent>a good foundation for comparative studies has been established by the senseval data and evaluations; of particular relevance here are the lexical sample tasks from senseval-1 (kilgarriff and rosenzweig, 1999) and senseval-2 (kilgarriff, 2001).
</nextsent>
<nextsent>we therefore chose this problem to introduce an efficient and accurate new word sense disambiguation approach that exploits nonlinear kernel pca technique to make predictions implicitly based on generalizations over feature combinations.
</nextsent>
<nextsent>the1the author would like to thank the hongkong research grants council (rgc) for supporting this research in part through grants rgc6083/99e, rgc6256/00e, and dag03/04.eg09.technique is applicable whenever vector representations of disambiguation task can be generated;thus many properties of our technique can be expected to be highly attractive from the standpoint of natural language processing in general.in the following sections, we first analyze the potential of nonlinear principal components with respect to the task of disambiguating word senses.
</nextsent>
<nextsent>based on this, we describe full model for wsd built on kpca.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3141">
<title id=" P04-1081.xml">a kernel pca method for superior word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it is hoped that these highly encouraging first results on kpca for natural language processing tasks will inspire further development of these directions.
</prevsent>
<prevsent>achieving higher precision in supervised word sense disambiguation (wsd) tasks without resorting to ad hoc voting or similar ensemble techniques has become somewhat daunting in recent years, given the challenging benchmarks set by nave bayes models (e.g., mooney (1996), <papid> W96-0208 </papid>chodorow etal.</prevsent>
</prevsection>
<citsent citstr=" W02-1002 ">
(1999), pedersen (2001), yarowsky and florian (2002)) as well as maximum entropy models(e.g., dang and palmer (2002), <papid> W02-0813 </papid>klein and manning (2002)).<papid> W02-1002 </papid></citsent>
<aftsection>
<nextsent>a good foundation for comparative studies has been established by the senseval data and evaluations; of particular relevance here are the lexical sample tasks from senseval-1 (kilgarriff and rosenzweig, 1999) and senseval-2 (kilgarriff, 2001).
</nextsent>
<nextsent>we therefore chose this problem to introduce an efficient and accurate new word sense disambiguation approach that exploits nonlinear kernel pca technique to make predictions implicitly based on generalizations over feature combinations.
</nextsent>
<nextsent>the1the author would like to thank the hongkong research grants council (rgc) for supporting this research in part through grants rgc6083/99e, rgc6256/00e, and dag03/04.eg09.technique is applicable whenever vector representations of disambiguation task can be generated;thus many properties of our technique can be expected to be highly attractive from the standpoint of natural language processing in general.in the following sections, we first analyze the potential of nonlinear principal components with respect to the task of disambiguating word senses.
</nextsent>
<nextsent>based on this, we describe full model for wsd built on kpca.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3142">
<title id=" P04-1081.xml">a kernel pca method for superior word sense disambiguation </title>
<section> nonlinear principal components and.  </section>
<citcontext>
<prevsection>
<prevsent>wsdthe kernel principal component analysis technique, or kpca, is nonlinear kernel method for extraction of nonlinear principal components from vector sets in which, conceptually, the dimensional input vectors are non linearly mapped from their original space rn to high-dimensional feature space where linear pca is performed, yielding transform by which the input vectors can be mapped non linearly to new set of vectors (scholkopf et al, 1998).
</prevsent>
<prevsent>a major advantage of kpca is that, unlike other common analysis techniques, as with other kernel methods it inherently takes combinations of predictive features into account when optimizing dimensionality reduction.
</prevsent>
</prevsection>
<citsent citstr=" P03-1004 ">
for natural language problems in general, of course, it is widely recognized that significant accuracy gains can often be achieved by generalizing over relevant feature combinations(e.g., kudo and matsumoto (2003)).<papid> P03-1004 </papid></citsent>
<aftsection>
<nextsent>another advantage of kpca for the wsd task is that the dimensionality of the input data is generally very table 1: two of the senseval-2 sense classes for the target word art?, from wordnet 1.7 (fellbaum 1998).
</nextsent>
<nextsent>class sense 1 the creation of beautiful or significant things 2 superior skill large, condition where kernel methods excel.
</nextsent>
<nextsent>nonlinear principal components (diamantarasand kung, 1996) may be defined as follows.
</nextsent>
<nextsent>suppose we are given training set of pairs (xt, ct)where the observed vectors xt ? rn in an dimensional input space represent the context ofthe target word being disambiguated, and the correct class ct represents the sense of the word, for = 1, ..,m . suppose ? is nonlinear mapping from the input space rn to the feature space .without loss of generality we assume the vectors are centered vectors in the feature space, i.e., t=1 ?(xt) = 0; un centered vectors can easily be converted to centered vectors (scholkopf et al,1998).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3146">
<title id=" P04-1081.xml">a kernel pca method for superior word sense disambiguation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>svm-based model 65.2% +/-1.00% kpca-based model 65.8% +/-0.79% many variations of the experiments.
</prevsent>
<prevsent>4.2 kpca versus svm models.
</prevsent>
</prevsection>
<citsent citstr=" W01-0507 ">
support vector machines (e.g., vapnik (1995),joachims (1998)) are different kind of kernel method that, unlike kpca methods, have already gained high popularity for nlp applications (e.g., takamura and matsumoto (2001), <papid> W01-0507 </papid>isozaki and kazawa (2002), <papid> C02-1054 </papid>mayfield et al (2003)) <papid> W03-0429 </papid>including the word sense disambiguation task (e.g., cabezas et al (2001)).</citsent>
<aftsection>
<nextsent>given that svm and kpca are both kernel methods, we are frequently asked whether svm-based wsd could achieve similar results.
</nextsent>
<nextsent>to explore this question, we trained and tunedan svm model, providing the same rich set of features and also varying the feature representations to optimize for svm biases.
</nextsent>
<nextsent>as shown in table 6, the highest-achieving svm model is also able to obtain higher accuracies than the nave bayes and maximum entropy models.
</nextsent>
<nextsent>however, in all our experiments the kpca-based model consistently outperforms the svm model (though the margin falls within the statistical significance interval as computed by bootstrap re sampling for this single experiment).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3147">
<title id=" P04-1081.xml">a kernel pca method for superior word sense disambiguation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>svm-based model 65.2% +/-1.00% kpca-based model 65.8% +/-0.79% many variations of the experiments.
</prevsent>
<prevsent>4.2 kpca versus svm models.
</prevsent>
</prevsection>
<citsent citstr=" C02-1054 ">
support vector machines (e.g., vapnik (1995),joachims (1998)) are different kind of kernel method that, unlike kpca methods, have already gained high popularity for nlp applications (e.g., takamura and matsumoto (2001), <papid> W01-0507 </papid>isozaki and kazawa (2002), <papid> C02-1054 </papid>mayfield et al (2003)) <papid> W03-0429 </papid>including the word sense disambiguation task (e.g., cabezas et al (2001)).</citsent>
<aftsection>
<nextsent>given that svm and kpca are both kernel methods, we are frequently asked whether svm-based wsd could achieve similar results.
</nextsent>
<nextsent>to explore this question, we trained and tunedan svm model, providing the same rich set of features and also varying the feature representations to optimize for svm biases.
</nextsent>
<nextsent>as shown in table 6, the highest-achieving svm model is also able to obtain higher accuracies than the nave bayes and maximum entropy models.
</nextsent>
<nextsent>however, in all our experiments the kpca-based model consistently outperforms the svm model (though the margin falls within the statistical significance interval as computed by bootstrap re sampling for this single experiment).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3148">
<title id=" P04-1081.xml">a kernel pca method for superior word sense disambiguation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>svm-based model 65.2% +/-1.00% kpca-based model 65.8% +/-0.79% many variations of the experiments.
</prevsent>
<prevsent>4.2 kpca versus svm models.
</prevsent>
</prevsection>
<citsent citstr=" W03-0429 ">
support vector machines (e.g., vapnik (1995),joachims (1998)) are different kind of kernel method that, unlike kpca methods, have already gained high popularity for nlp applications (e.g., takamura and matsumoto (2001), <papid> W01-0507 </papid>isozaki and kazawa (2002), <papid> C02-1054 </papid>mayfield et al (2003)) <papid> W03-0429 </papid>including the word sense disambiguation task (e.g., cabezas et al (2001)).</citsent>
<aftsection>
<nextsent>given that svm and kpca are both kernel methods, we are frequently asked whether svm-based wsd could achieve similar results.
</nextsent>
<nextsent>to explore this question, we trained and tunedan svm model, providing the same rich set of features and also varying the feature representations to optimize for svm biases.
</nextsent>
<nextsent>as shown in table 6, the highest-achieving svm model is also able to obtain higher accuracies than the nave bayes and maximum entropy models.
</nextsent>
<nextsent>however, in all our experiments the kpca-based model consistently outperforms the svm model (though the margin falls within the statistical significance interval as computed by bootstrap re sampling for this single experiment).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3149">
<title id=" P04-1077.xml">automatic evaluation of machine translation quality using longest common sub sequence and skip bigram statistics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the empirical results show that both methods correlate with human judgments very well in both adequacy and fluency.
</prevsent>
<prevsent>using objective functions to automatically evaluate machine translation quality is not new.
</prevsent>
</prevsection>
<citsent citstr=" C92-2067 ">
su et al (1992) <papid> C92-2067 </papid>proposed method based on measuring edit distance (levenshtein 1966) between candidate and reference translations.</citsent>
<aftsection>
<nextsent>akiba et al (2001) extended the idea to accommodate multiple references.
</nextsent>
<nextsent>nieen et al (2000) calculated the length normalized edit distance, called word error rate (wer), between candidate and multiple reference translations.
</nextsent>
<nextsent>leusch et al (2003) proposed related measure called position-independent word error rate (per) that did not consider word position, i.e. using bag-of-words instead.
</nextsent>
<nextsent>instead of error measures, we can also use accuracy measures that compute similarity between candidate and reference translations in proportion to the number of common words between them as suggested by melamed (1995).<papid> W95-0115 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3150">
<title id=" P04-1077.xml">automatic evaluation of machine translation quality using longest common sub sequence and skip bigram statistics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>nieen et al (2000) calculated the length normalized edit distance, called word error rate (wer), between candidate and multiple reference translations.
</prevsent>
<prevsent>leusch et al (2003) proposed related measure called position-independent word error rate (per) that did not consider word position, i.e. using bag-of-words instead.
</prevsent>
</prevsection>
<citsent citstr=" W95-0115 ">
instead of error measures, we can also use accuracy measures that compute similarity between candidate and reference translations in proportion to the number of common words between them as suggested by melamed (1995).<papid> W95-0115 </papid></citsent>
<aftsection>
<nextsent>an n-gram co-occurrence measure, bleu, proposed by papineni et al (2001) that calculates co-occurrence statistics based on n-gram overlaps have shown great potential.
</nextsent>
<nextsent>a variant of bleu developed by nist (2002) has been used in two recent large-scale machine translation evaluations.
</nextsent>
<nextsent>recently, turian et al (2003) indicated that standard accuracy measures such as recall, precision, and the f-measure can also be used in evaluation of machine translation.
</nextsent>
<nextsent>however, results based on their method, general text matcher (gtm), showed that unigram f-measure correlated best with human judgments while assigning more weight to higher n-gram (n   1) matches achieved similar performance as bleu.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3152">
<title id=" P04-1077.xml">automatic evaluation of machine translation quality using longest common sub sequence and skip bigram statistics </title>
<section> longest common sub sequence.  </section>
<citcontext>
<prevsection>
<prevsent>melamed (1995) <papid> W95-0115 </papid>used the ratio (lcsr) between the length of the lcs of two words and the length of the longer word of the two words to measure the cognateness between them.</prevsent>
<prevsent>he used as an approximate string matching algorithm.</prevsent>
</prevsection>
<citsent citstr=" C02-1073 ">
saggion et al (2002) <papid> C02-1073 </papid>used normalized pairwise lcs (np-lcs) to compare similarity between two texts in automatic summarization evaluation.</citsent>
<aftsection>
<nextsent>np-lcs can be shown as special case of equation (6) with ? = 1.
</nextsent>
<nextsent>however, they did not provide the correlation analysis of np-lcs with 1 this is real machine translation output..
</nextsent>
<nextsent>2 the kill?
</nextsent>
<nextsent>in s2 or s3 does not match with killed?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3153">
<title id=" P04-1077.xml">automatic evaluation of machine translation quality using longest common sub sequence and skip bigram statistics </title>
<section> longest common sub sequence.  </section>
<citcontext>
<prevsection>
<prevsent>notice that rouge-l is 1 when = since lcs(x,y) = or n; while rouge-l is zero when lcs(x,y) = 0, i.e. there is nothing in common between and y. measure or its equivalents has been shown to have met several theoretical criteria in measuring accuracy involving more than one factor (van rijsber gen 1979).
</prevsent>
<prevsent>the composite factors are lcs-based recall and precision in this case.
</prevsent>
</prevsection>
<citsent citstr=" N03-2021 ">
melamed et al (2003) <papid> N03-2021 </papid>used unigram f-measure to estimate machine translation quality and showed that unigram f-measure was as good as bleu.</citsent>
<aftsection>
<nextsent>one advantage of using lcs is that it does not require consecutive matches but in-sequence matches that reflect sentence level word order as grams.
</nextsent>
<nextsent>the other advantage is that it automatically includes longest in-sequence common n-grams, therefore no predefined n-gram length is necessary.
</nextsent>
<nextsent>rouge-l as defined in equation 6 has the property that its value is less than or equal to the minimum of unigram f-measure of and y. unigram recall reflects the proportion of words in (reference translation) that are also present in (candi date translation); while unigram precision is the proportion of words in that are also in x. uni gram recall and precision count all co-occurring words regardless their orders; while rouge-l counts only in-sequence co-occurrences.
</nextsent>
<nextsent>by only awarding credit to in-sequence unigram matches, rouge-l also captures sentence level structure in natural way.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3154">
<title id=" P04-1077.xml">automatic evaluation of machine translation quality using longest common sub sequence and skip bigram statistics </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>in the next step, we plan to extend them to accommodate synonyms and paraphrases.
</prevsent>
<prevsent>for example, we can use an existing thesaurus such as wordnet (miller 1990) or creating customized one by applying automated synonym set discovery methods (pantel and lin 2002) to identify potential synonyms.
</prevsent>
</prevsection>
<citsent citstr=" N03-1003 ">
paraphrases can also be automatically acquired using statistical methods as shown by barzilay and lee (2003).<papid> N03-1003 </papid></citsent>
<aftsection>
<nextsent>once we have acquired synonym and paraphrase data, we then need to design soft matching function that assigns partial credits to these approximate matches.
</nextsent>
<nextsent>in this scenario, statistically generated data has the advantage of being able to provide scores reflecting the strength of similarity between synonyms and paraphrased.
</nextsent>
<nextsent>rouge-l, rouge-w, and rouge-s have also been applied in automatic evaluation of summarization and achieved very promising results (lin 2004).<papid> W04-1013 </papid></nextsent>
<nextsent>in lin and och (2004), <papid> C04-1072 </papid>we proposed framework that automatically evaluated automatic mt evaluation metrics using only manual translations without further human involvement.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3155">
<title id=" P04-1077.xml">automatic evaluation of machine translation quality using longest common sub sequence and skip bigram statistics </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>once we have acquired synonym and paraphrase data, we then need to design soft matching function that assigns partial credits to these approximate matches.
</prevsent>
<prevsent>in this scenario, statistically generated data has the advantage of being able to provide scores reflecting the strength of similarity between synonyms and paraphrased.
</prevsent>
</prevsection>
<citsent citstr=" W04-1013 ">
rouge-l, rouge-w, and rouge-s have also been applied in automatic evaluation of summarization and achieved very promising results (lin 2004).<papid> W04-1013 </papid></citsent>
<aftsection>
<nextsent>in lin and och (2004), <papid> C04-1072 </papid>we proposed framework that automatically evaluated automatic mt evaluation metrics using only manual translations without further human involvement.</nextsent>
<nextsent>according to the results reported in that paper, rouge-l, rouge-w, and rouge-s also outperformed bleu and nist.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3156">
<title id=" P04-1077.xml">automatic evaluation of machine translation quality using longest common sub sequence and skip bigram statistics </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>in this scenario, statistically generated data has the advantage of being able to provide scores reflecting the strength of similarity between synonyms and paraphrased.
</prevsent>
<prevsent>rouge-l, rouge-w, and rouge-s have also been applied in automatic evaluation of summarization and achieved very promising results (lin 2004).<papid> W04-1013 </papid></prevsent>
</prevsection>
<citsent citstr=" C04-1072 ">
in lin and och (2004), <papid> C04-1072 </papid>we proposed framework that automatically evaluated automatic mt evaluation metrics using only manual translations without further human involvement.</citsent>
<aftsection>
<nextsent>according to the results reported in that paper, rouge-l, rouge-w, and rouge-s also outperformed bleu and nist.
</nextsent>



</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3157">
<title id=" P01-1014.xml">towards automatic classification of discourse elements in essays </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>using relatively small corpus of manually annotated data, we use bayesian classification to identify thesis statements.
</prevsent>
<prevsent>this method yields results that are much closer to human performance than the results produced by two baseline systems.
</prevsent>
</prevsection>
<citsent citstr=" P98-1032 ">
automated essay scoring technology can achieve agreement with single human judge that is comparable to agreement between two single human judges (burstein, et al 1998; <papid> P98-1032 </papid>foltz, et al 1998; larkey, 1998; and page and peterson, 1995).</citsent>
<aftsection>
<nextsent>unfortunately, providing students with just score (grade) is insufficient for instruction.
</nextsent>
<nextsent>to help students improve their writing skills, writing evaluation systems need to provide feedback that is specific to each individuals writing and that is applicable to essay revision.
</nextsent>
<nextsent>the factors that contribute to improvement of student writing include refined sentence structure, variety of appropriate word usage, and organizational structure.
</nextsent>
<nextsent>the improvement of organizational structure is believed to be critical in the essay revision process toward overall improvement of essay quality.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3158">
<title id=" P01-1014.xml">towards automatic classification of discourse elements in essays </title>
<section> what are thesis statements?.  </section>
<citcontext>
<prevsection>
<prevsent>in addition, table 1b indicates that there is very little overlap between thesis and generic summary sentences: just 6% of the summary sentences were labeled by human judges as thesis statement sentences.
</prevsent>
<prevsent>this strongly suggests that there are critical differences between thesis statements and summary sentences, at least in first-draft essay writing.
</prevsent>
</prevsection>
<citsent citstr=" J86-3001 ">
it is possible that thesis statements reflect an intentional facet (grosz and sidner, 1986) <papid> J86-3001 </papid>of language, while summary sentences reflect semantic one (martin, 1992).</citsent>
<aftsection>
<nextsent>more detailed experiments need to be carried out though before proper conclusions can be derived.
</nextsent>
<nextsent>table 1a: agreement between human judges on thesis and summary sentence identification.
</nextsent>
<nextsent>metric thesis statements summary sentences kappa 0.733 0.603 (1 vs. 2) 0.73 0.44 (1 vs. 2) 0.69 0.60 (1 vs. 2) 0.71 0.51 table 1b: percent overlap between human labeled thesis statements and summary sentences.
</nextsent>
<nextsent>thesis statements vs. summary sentences percent overlap 0.06 the results in table 1a provide an estimate for an upper bound of thesis statement identification algorithm.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3159">
<title id=" P01-1014.xml">towards automatic classification of discourse elements in essays </title>
<section> generality of the thesis statement.  </section>
<citcontext>
<prevsection>
<prevsent>the larger implication is that we begin to see that there are underlying discourse elements in essays that can be identified, independent of the topic of the test question.
</prevsent>
<prevsent>for essay evaluation applications this is critical since new test questions are continuously being introduced into on-line essay evaluation applications.
</prevsent>
</prevsection>
<citsent citstr=" W99-0311 ">
our results compare favorably with results reported by teufel and moens (1999) <papid> W99-0311 </papid>who also use bayes classification techniques to identify rhetorical arguments such as aim and background in scientific texts, although the texts we are working with are extremely noisy.</citsent>
<aftsection>
<nextsent>because ept essays are often produced for high-stake exams, under severe time constraints, they are often ungrammatical, repetitive, and poorly organized at the discourse level.
</nextsent>
<nextsent>current investigations indicate that this technique can be used to reliably identify other essay-specific discourse elements, such as, concluding statements, main points of arguments, and supporting ideas.
</nextsent>
<nextsent>in addition, we are exploring how we can use estimated probabilities as confidence measures of the decisions made by the system.
</nextsent>
<nextsent>if the confidence level associated with the identification of thesis statement is low, the system would instruct the student that no explicit thesis statement has been found in the essay.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3160">
<title id=" P00-1015.xml">a unified statistical model for the identification of english basenp </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the following example are basenps, where nns, in vbg etc are part-of-speech tags [as defined in m. marcus 1993].
</prevsent>
<prevsent>[measures/nns] of/in [manufacturing/vbg activity/nn] fell/vbd more/rbr than/in [the/dt overall/jj measures/nns] ./.
</prevsent>
</prevsection>
<citsent citstr=" A88-1019 ">
figure 1: an example sentence with basenp brackets number of researchers have dealt with the problem of basenp identification (church 1988; <papid> A88-1019 </papid>bourigault 1992; voutilainen 1993; justeson &amp; katz 1995).</citsent>
<aftsection>
<nextsent>recently some researchers have made experiments with the same test corpus extracted from the 20th section of the penn treebank wall street journal (penn treebank).ramshaw &amp; markus (1998) applied transform based error-driven algorithm (brill 1995) to learn set of transformation rules, and using those rules to locally updates the bracket positions.
</nextsent>
<nextsent>argamon, dagan &amp; krymolowski (1998) introduced memory-based sequences learning method, the training examples are stored and generalization is performed at application time by comparing sub sequence of the new text to positive and negative evidence.
</nextsent>
<nextsent>cardie &amp; pierce (1998 <papid> P98-1034 </papid>1999) devised error driven pruning approach trained on penn treebank.</nextsent>
<nextsent>it extracts basenp rules from the training corpus and prune some bad basenp by incremental training, and then apply the pruned rules to identify basenp through maximum length matching (or dynamic program algorithm).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3161">
<title id=" P00-1015.xml">a unified statistical model for the identification of english basenp </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recently some researchers have made experiments with the same test corpus extracted from the 20th section of the penn treebank wall street journal (penn treebank).ramshaw &amp; markus (1998) applied transform based error-driven algorithm (brill 1995) to learn set of transformation rules, and using those rules to locally updates the bracket positions.
</prevsent>
<prevsent>argamon, dagan &amp; krymolowski (1998) introduced memory-based sequences learning method, the training examples are stored and generalization is performed at application time by comparing sub sequence of the new text to positive and negative evidence.
</prevsent>
</prevsection>
<citsent citstr=" P98-1034 ">
cardie &amp; pierce (1998 <papid> P98-1034 </papid>1999) devised error driven pruning approach trained on penn treebank.</citsent>
<aftsection>
<nextsent>it extracts basenp rules from the training corpus and prune some bad basenp by incremental training, and then apply the pruned rules to identify basenp through maximum length matching (or dynamic program algorithm).
</nextsent>
<nextsent>most of the prior work treats pos tagging and basenp identification as two separate procedures.
</nextsent>
<nextsent>however, uncertainty is involved in both steps.
</nextsent>
<nextsent>using the result of the first step as if they are certain will lead to more errors in the second step.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3162">
<title id=" P00-1009.xml">an improved parser for data oriented lexical functional analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they operate by decomposing the given representations into (arbitrarily large) fragments and re composing those pieces to analyze new utterances.
</prevsent>
<prevsent>a probability model is used to choose from the collection of different fragments of different sizes those that make up the most appropriate analysis of an utterance.
</prevsent>
</prevsection>
<citsent citstr=" C00-1011 ">
dop models have been shown to achieve state-of-the-art parsing performance on benchmarks such as the wall street journal corpus (see bod 2000<papid> C00-1011 </papid>a).</citsent>
<aftsection>
<nextsent>the original dop model in bod (1993) was based on utterance analyses represented as surface trees, and is equivalent to stochastic tree-substitution grammar.
</nextsent>
<nextsent>but the model has also been applied to several other grammatical frameworks, e.g. tree-insertion grammar (hoogweg 2000), tree-adjoining grammar (neumann 1998), lexical-functional grammar (bod &amp; kaplan 1998; <papid> P98-1022 </papid>cormons 1999), head-driven phrase structure grammar (neumann &amp; flickinger 1999), and montague grammar (bonnema et al 1997; <papid> P97-1021 </papid>bod 1999).</nextsent>
<nextsent>most probability models for dop use the relative frequency estimator to estimate fragment probabilities, although bod (2000<papid> C00-1011 </papid>b) trains fragment probabilities by maximum likelihood reestimation procedure belonging to the class of expectation-maximization algorithms.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3172">
<title id=" P00-1009.xml">an improved parser for data oriented lexical functional analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>dop models have been shown to achieve state-of-the-art parsing performance on benchmarks such as the wall street journal corpus (see bod 2000<papid> C00-1011 </papid>a).</prevsent>
<prevsent>the original dop model in bod (1993) was based on utterance analyses represented as surface trees, and is equivalent to stochastic tree-substitution grammar.</prevsent>
</prevsection>
<citsent citstr=" P98-1022 ">
but the model has also been applied to several other grammatical frameworks, e.g. tree-insertion grammar (hoogweg 2000), tree-adjoining grammar (neumann 1998), lexical-functional grammar (bod &amp; kaplan 1998; <papid> P98-1022 </papid>cormons 1999), head-driven phrase structure grammar (neumann &amp; flickinger 1999), and montague grammar (bonnema et al 1997; <papid> P97-1021 </papid>bod 1999).</citsent>
<aftsection>
<nextsent>most probability models for dop use the relative frequency estimator to estimate fragment probabilities, although bod (2000<papid> C00-1011 </papid>b) trains fragment probabilities by maximum likelihood reestimation procedure belonging to the class of expectation-maximization algorithms.</nextsent>
<nextsent>the dop model has also been tested as model for human sentence processing (bod 2000<papid> C00-1011 </papid>d).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3173">
<title id=" P00-1009.xml">an improved parser for data oriented lexical functional analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>dop models have been shown to achieve state-of-the-art parsing performance on benchmarks such as the wall street journal corpus (see bod 2000<papid> C00-1011 </papid>a).</prevsent>
<prevsent>the original dop model in bod (1993) was based on utterance analyses represented as surface trees, and is equivalent to stochastic tree-substitution grammar.</prevsent>
</prevsection>
<citsent citstr=" P97-1021 ">
but the model has also been applied to several other grammatical frameworks, e.g. tree-insertion grammar (hoogweg 2000), tree-adjoining grammar (neumann 1998), lexical-functional grammar (bod &amp; kaplan 1998; <papid> P98-1022 </papid>cormons 1999), head-driven phrase structure grammar (neumann &amp; flickinger 1999), and montague grammar (bonnema et al 1997; <papid> P97-1021 </papid>bod 1999).</citsent>
<aftsection>
<nextsent>most probability models for dop use the relative frequency estimator to estimate fragment probabilities, although bod (2000<papid> C00-1011 </papid>b) trains fragment probabilities by maximum likelihood reestimation procedure belonging to the class of expectation-maximization algorithms.</nextsent>
<nextsent>the dop model has also been tested as model for human sentence processing (bod 2000<papid> C00-1011 </papid>d).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3192">
<title id=" P00-1009.xml">an improved parser for data oriented lexical functional analysis </title>
<section> summary of lfg-dop.  </section>
<citcontext>
<prevsection>
<prevsent>due to memory limitations, we restricted the maximum depth of the indexed subtrees to 4.
</prevsent>
<prevsent>because of the small size of the corpora we averaged our results on 10 different training/test set splits.
</prevsent>
</prevsection>
<citsent citstr=" H91-1060 ">
besides an exact match accuracy metric, we also used more fine-grained score based on the well-known parseval metrics that evaluate phrase-structure trees (black et al 1991).<papid> H91-1060 </papid></citsent>
<aftsection>
<nextsent>the parseval metrics compare proposed parse with the corresponding correct treebank parse as follows: precision = # correct constituents in # constituents in # correct constituents in # constituents in recall = constituent in is correct if there exists constituent in of the same label that spans the same words and that ?-corresponds to the same f-structure unit (see bod 2000<papid> C00-1011 </papid>c for some illustrations of these metrics for lfg-dop).</nextsent>
<nextsent>5.1 comparing the two fragment estimators.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3229">
<title id=" P00-1030.xml">modeling local context for pitch accent prediction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in general, syntactic features are the most widely used features inpitch accent predication.
</prevsent>
<prevsent>for example, partof-speech is traditionally the most useful single pitch accent predictor (hirschberg, 1993).function words, such as prepositions and articles, are less likely to be accented, while content words, such as nouns and adjectives,are more likely to be accented.
</prevsent>
</prevsection>
<citsent citstr=" P98-2155 ">
other linguistic features, such as inferred given/newstatus (hirschberg, 1993; brown, 1983), con trastiveness (bolinger, 1961), and discourse structure (nakatani, 1998), <papid> P98-2155 </papid>have also been examined to explain accent assignment in large speech corpora.</citsent>
<aftsection>
<nextsent>in previous study (pan and mckeown, 1998; <papid> P98-2165 </papid>pan and mckeown, 1999), <papid> W99-0619 </papid>we investigated how features such as deep syntactic/semantic structure and word informative ness correlate with accent placement.</nextsent>
<nextsent>in this paper, we focus on how local context in uencesaccent patterns.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3230">
<title id=" P00-1030.xml">modeling local context for pitch accent prediction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, partof-speech is traditionally the most useful single pitch accent predictor (hirschberg, 1993).function words, such as prepositions and articles, are less likely to be accented, while content words, such as nouns and adjectives,are more likely to be accented.
</prevsent>
<prevsent>other linguistic features, such as inferred given/newstatus (hirschberg, 1993; brown, 1983), con trastiveness (bolinger, 1961), and discourse structure (nakatani, 1998), <papid> P98-2155 </papid>have also been examined to explain accent assignment in large speech corpora.</prevsent>
</prevsection>
<citsent citstr=" P98-2165 ">
in previous study (pan and mckeown, 1998; <papid> P98-2165 </papid>pan and mckeown, 1999), <papid> W99-0619 </papid>we investigated how features such as deep syntactic/semantic structure and word informative ness correlate with accent placement.</citsent>
<aftsection>
<nextsent>in this paper, we focus on how local context in uencesaccent patterns.
</nextsent>
<nextsent>more speci cally, we investigate how word collocation in uences whether nouns are accented or not.
</nextsent>
<nextsent>determining which nouns are accented and which are not is challenging, since part-of speech information cannot help here.
</nextsent>
<nextsent>so, other accent predictors must be found.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3231">
<title id=" P00-1030.xml">modeling local context for pitch accent prediction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, partof-speech is traditionally the most useful single pitch accent predictor (hirschberg, 1993).function words, such as prepositions and articles, are less likely to be accented, while content words, such as nouns and adjectives,are more likely to be accented.
</prevsent>
<prevsent>other linguistic features, such as inferred given/newstatus (hirschberg, 1993; brown, 1983), con trastiveness (bolinger, 1961), and discourse structure (nakatani, 1998), <papid> P98-2155 </papid>have also been examined to explain accent assignment in large speech corpora.</prevsent>
</prevsection>
<citsent citstr=" W99-0619 ">
in previous study (pan and mckeown, 1998; <papid> P98-2165 </papid>pan and mckeown, 1999), <papid> W99-0619 </papid>we investigated how features such as deep syntactic/semantic structure and word informative ness correlate with accent placement.</citsent>
<aftsection>
<nextsent>in this paper, we focus on how local context in uencesaccent patterns.
</nextsent>
<nextsent>more speci cally, we investigate how word collocation in uences whether nouns are accented or not.
</nextsent>
<nextsent>determining which nouns are accented and which are not is challenging, since part-of speech information cannot help here.
</nextsent>
<nextsent>so, other accent predictors must be found.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3234">
<title id=" P02-1041.xml">coupling ccg and hybrid logic dependency semantics </title>
<section> indexed semantic representations.  </section>
<citcontext>
<prevsection>
<prevsent>(4) [e][party(x);past(e); to(e;x);come(e;ed)] inl thus flattens logical forms to some extent, using the indexes to spread given entity or event through multiple predications.
</prevsent>
<prevsent>the use of indexes is crucial for ucgs account of modifiers, and as we will see later, we exploit such referents to achieve similar ends when coupling hlds and ccg.
</prevsent>
</prevsection>
<citsent citstr=" P01-1019 ">
minimal recur sion semantics (mrs) (copestakeet al, 1999; copestake et al, 2001) <papid> P01-1019 </papid>is framework for computational semantics that is designed to simplify the work of algorithms which produce or use semantic representations.</citsent>
<aftsection>
<nextsent>mrs provides the means to represent interpretations with flat, underspecified semantics using terms of the predicate calculus and generalized quantifiers.
</nextsent>
<nextsent>flattening is achieved by using an indexation scheme involving labels that tag particular groups of elementary predications (eps) and handles (here, h1;h2; :::) that reference those eps.
</nextsent>
<nextsent>under specification is achieved by using unresolved handles as the arguments for scope-bearing elements and declaring constraints (with the =q operator) on how those handles can be resolved.
</nextsent>
<nextsent>different scopes can be reconstructed by equating unresolved handles with the labels of the other eps obeying the =q constraints.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3235">
<title id=" P02-1041.xml">coupling ccg and hybrid logic dependency semantics </title>
<section> hybrid logic dependency semantics.  </section>
<citcontext>
<prevsection>
<prevsent>the pronoun is resolvable only if state where male holds is xsaccessible in the discourse model.
</prevsent>
<prevsent>different accessibility relations can be modeled, e.g. to distinguish local context (for resolving reflexive anaphors like himself ) from global context (kruijff, 2001).
</prevsent>
</prevsection>
<citsent citstr=" J88-2003 ">
finally, the rich temporal ontology underlying models of tense and aspect such as moens and steedman (1988) <papid> J88-2003 </papid>can be captured using the sorting strategy.</citsent>
<aftsection>
<nextsent>earlier work like blackburn and lascarides (1992) already explored such ideas.
</nextsent>
<nextsent>hlds employs hybrid logic to integrate moens and steed mans notion of the event nucleus directly into meaning representations.
</nextsent>
<nextsent>the event nucleus is tripartite structure reflecting the underlying semantics of type ofevent.
</nextsent>
<nextsent>the event is related to preparation (an activity bringing the event about) and consequent (a state ensuing to the event), which we encode as the modal relations prep and cons, respectively.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3236">
<title id=" P02-1041.xml">coupling ccg and hybrid logic dependency semantics </title>
<section> ccg coupled to hlds.  </section>
<citcontext>
<prevsection>
<prevsent>though dgl demonstrates procedure for building hlds terms from linguistic expressions, there are several problems we can overcome by switching to ccg.
</prevsent>
<prevsent>first, parsing with ccg grammars for substantial fragments is generally more efficient than with ctl grammars with similar coverage.
</prevsent>
</prevsection>
<citsent citstr=" P02-1042 ">
also, wide-coverage statistical parser which produces syntactic dependency structures for english is available for ccg (clark et al, 2002).<papid> P02-1042 </papid></citsent>
<aftsection>
<nextsent>second, syntactic features (modeled by unary modalities) in ctl have no intuitive semantic reflection, whereas ccg can relate syntactic and semantic features perspicuously using unification.
</nextsent>
<nextsent>finally, ccg has detailed syntactic account of the realization of information structure in english.to link syntax and semantics in derivations, every logical form in dgl expresses nominal identifying its head in the format @i p. this handles dependents in linguistically motivated way through linking theory: given the form of dependent, its(possible) role is established, after which its meaning states that it seeks head that can take such role.
</nextsent>
<nextsent>however, to subsequently bind that dependent into the verbs argument slot requires logical axioms about the nature of various dependents.
</nextsent>
<nextsent>this not only requires extra reduction steps to arrive at the desired logical form, but could also lead to problems depending on the underlying theory of roles.we present an alternative approach to binding dependents, which overcomes these problems without abandoning the linguistic motivation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3237">
<title id=" P02-1041.xml">coupling ccg and hybrid logic dependency semantics </title>
<section> conclusions and future work.  </section>
<citcontext>
<prevsection>
<prevsent>this is particularly important since the system does not otherwise support typed feature structures with inheritance.hybrid logics provide perspicuous logical language for representing structures in temporal logic, description logic, avms, and indeed any relational structure.
</prevsent>
<prevsent>terms of hlds can thus be marshalled into terms of these other representations with the potential of taking advantage of tools developed for them or providing input to modules expecting them.
</prevsent>
</prevsection>
<citsent citstr=" P02-1043 ">
in future work, we intend to combine techniques for building wide-coverage statistical parsers for ccg (hockenmaier and steedman, 2002; <papid> P02-1043 </papid>clark et al., 2002) <papid> P02-1042 </papid>with corpora that have explicitly marked semantic dependency relations (such as the prague dependency treebank and negra) to produce hlds terms as the parse output.</citsent>
<aftsection>
<nextsent>acknowledgements we would like to thank patrick blackburn, johan bos, nissim francez, alex lascarides, mark steedman, bonnie webber and the acl reviewers for helpful comments on earlier versions of this paper.
</nextsent>
<nextsent>all errors are, of course, our own.
</nextsent>
<nextsent>jason bald ridges work is supported in part by overseas research student award ors/98014014.
</nextsent>
<nextsent>geert-jan kruijffs work is supported by thedfg sonderforschungsbereich 378 resource-sensitive cognitive processes, project negra em6.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3239">
<title id=" P02-1036.xml">dynamic programming for parsing and estimation of stochastic unification based grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this research was supported by nsf awards dms 0074276 and itr iis 0085940.
</prevsent>
<prevsent>stochastic unification-based grammars (subgs) use log-linear models (also known as exponential ormaxent models and markov random fields) to define probability distributions over the parses of unification grammar.
</prevsent>
</prevsection>
<citsent citstr=" J97-4005 ">
these grammars can incorporate virtually all kinds of linguistically important constraints (including non-local and non-context-free constraints), and are equipped with statistically sound framework for estimation and learning.abney (1997) <papid> J97-4005 </papid>pointed out that the non-context free dependencies of unification grammar require stochastic models more general than probabilistic context-free grammars (pcfgs) and markov branching processes, and proposed the use of loglinear models for defining probability distributions over the parses of unification grammar.</citsent>
<aftsection>
<nextsent>unfortunately, the maximum likelihood estimator abney proposed for subgs seems computationally intractable since it requires statistics that depend on the set of all parses of all strings generated by thegrammar.
</nextsent>
<nextsent>this set is infinite (so exhaustive enumeration is impossible) and presumably has very complex structure (so sampling estimates might take an extremely long time to converge).
</nextsent>
<nextsent>johnson et al (1999) <papid> P99-1069 </papid>observed that parsing and related tasks only require conditional distributions over parses given strings, and that such conditional distributions are considerably easier to estimate than joint distributions of strings and their parses.</nextsent>
<nextsent>the conditional maximum likelihood estimator proposed by johnson et al requires statistics that depend onthe set of all parses of the strings in the training cor computational linguistics (acl), philadelphia, july 2002, pp.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3240">
<title id=" P02-1036.xml">dynamic programming for parsing and estimation of stochastic unification based grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>unfortunately, the maximum likelihood estimator abney proposed for subgs seems computationally intractable since it requires statistics that depend on the set of all parses of all strings generated by thegrammar.
</prevsent>
<prevsent>this set is infinite (so exhaustive enumeration is impossible) and presumably has very complex structure (so sampling estimates might take an extremely long time to converge).
</prevsent>
</prevsection>
<citsent citstr=" P99-1069 ">
johnson et al (1999) <papid> P99-1069 </papid>observed that parsing and related tasks only require conditional distributions over parses given strings, and that such conditional distributions are considerably easier to estimate than joint distributions of strings and their parses.</citsent>
<aftsection>
<nextsent>the conditional maximum likelihood estimator proposed by johnson et al requires statistics that depend onthe set of all parses of the strings in the training cor computational linguistics (acl), philadelphia, july 2002, pp.
</nextsent>
<nextsent>279-286.
</nextsent>
<nextsent>proceedings of the 40th annual meeting of the association for pus.
</nextsent>
<nextsent>for most linguistically realistic grammars this set is finite, and for moderate sized grammars and training corpora this estimation procedure is quite feasible.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3248">
<title id=" P03-1060.xml">a syllable based word recognition model for korean noun extraction </title>
<section> syllable based word recognition model.  </section>
<citcontext>
<prevsection>
<prevsent>several attempts have been made to use characteristics of korean syllables.
</prevsent>
<prevsent>kang (1995) used syllable information to reduce the over-generated results in analyzing conjugated forms of verbs.
</prevsent>
</prevsection>
<citsent citstr=" W02-1208 ">
syllable statistics have been also used for automatic word spacing (shim, 1996; kang and woo, 2001; lee et al, 2002).<papid> W02-1208 </papid>the syllable based word recognition model is represented as function</citsent>
<aftsection>
<nextsent>like the following equations.
</nextsent>
<nextsent>it is to find the most probable syllable-tag sequence
</nextsent>
<nextsent>, forgiven sentence  consisting of sequence of  syllables
</nextsent>
<nextsent>       .1korean morphemes can be classified into two types: uninflected morphemes having fixed word forms (such as noun, un conjugated adjective, post position, adverb, interject ion, etc.) and inflected morphemes having conjugated word forms (such as morpheme with declined or conjugated endings, predicative post position, etc.) 2
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3249">
<title id=" P03-1060.xml">a syllable based word recognition model for korean noun extraction </title>
<section> syllable based word recognition model.  </section>
<citcontext>
<prevsection>
<prevsent>this method has been used in some tasks such as text chunking and named entity recognition to represent boundary of an element (e.g. individual phrase or named entity).
</prevsent>
<prevsent>there are several possible representation schemes to do this.
</prevsent>
</prevsection>
<citsent citstr=" W95-0107 ">
the simplest one is the bio representation scheme (ramshaw and marcus, 1995), <papid> W95-0107 </papid>where b? denotes the first item of an element and an i? any non-initial item, and syllable with tag o? is not part of any element.</citsent>
<aftsection>
<nextsent>because every syllable corresponds to one syllable tag, o? is not used in our task.
</nextsent>
<nextsent>the representation schemes used in this paper are described in detail in section 4.
</nextsent>
<nextsent>the probabilities in equation 3 are estimated bythe maximum likelihood estimator (mle) using relative frequencies in the training data.
</nextsent>
<nextsent>4 the most probable sequence of syllable tags in sentence (a sequence of syllables) can be efficiently computed by using the viterbi algorithm.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3250">
<title id=" P04-1060.xml">experiments in parallel text based grammar induction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we discuss an implemented system and present experimental results with an evaluation against the penn tree bank.
</prevsent>
<prevsent>there have been number of recent studies exploiting parallel corpora in bootstrapping of monolingual analysis tools.
</prevsent>
</prevsection>
<citsent citstr=" N01-1026 ">
in the information projection approach (e.g., (yarowsky and ngai, 2001)), <papid> N01-1026 </papid>statistical word alignment is applied to parallel corpus of english and some other language   for which notagger/morphological analyzer/chunker etc.</citsent>
<aftsection>
<nextsent>(hence forth simply: analysis tool) exists.
</nextsent>
<nextsent>a high-quality analysis tool is applied to the english text, and the statistical word alignment is used to project (noisy) target annotation to the   version of the text.robust learning techniques are then applied to bootstrap an analysis tool for   , using the annotations projected with high confidence as the initial training data.
</nextsent>
<nextsent>(confidence of both the english analysis tool and the statistical word alignment is taken into account.)
</nextsent>
<nextsent>the results that have been achieved by this method are very encouraging.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3251">
<title id=" P04-1060.xml">experiments in parallel text based grammar induction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the experiments we report in this paper focus on specific part of the prob lem: we replace standard treebank training with an expectation-maximization (em) algorithm forpcfgs, augmented by weighting factors for there liability of training data, following the approach of(nigam et al, 2000), who apply it for em training of text classifier.
</prevsent>
<prevsent>the factors are only sensitive to the constituent/distituent (c/d) status of each span of the string in  (cp.
</prevsent>
</prevsection>
<citsent citstr=" P02-1017 ">
(klein and manning, 2002)).<papid> P02-1017 </papid></citsent>
<aftsection>
<nextsent>the c/d status is derived from an aligned parallel corpus in way discussed in section 2.
</nextsent>
<nextsent>we use the europarl corpus (koehn, 2002), and the statistical word alignment was performed with the giza++ toolkit (al-onaizan et al, 1999; och and ney, 2003).<papid> J03-1002 </papid>1for the current experiments we assume no preexisting parser for any of the languages, contrary to the information projection scenario.</nextsent>
<nextsent>while better absolute results could be expected using one or more parsers for the languages involved, we think that it is important to isolate the usefulness of exploiting just cross linguistic word order divergences in order to obtain partial prior knowledge about the constituent structure of language, which is then exploited in an em learning approach (section 3).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3252">
<title id=" P04-1060.xml">experiments in parallel text based grammar induction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(klein and manning, 2002)).<papid> P02-1017 </papid></prevsent>
<prevsent>the c/d status is derived from an aligned parallel corpus in way discussed in section 2.</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
we use the europarl corpus (koehn, 2002), and the statistical word alignment was performed with the giza++ toolkit (al-onaizan et al, 1999; och and ney, 2003).<papid> J03-1002 </papid>1for the current experiments we assume no preexisting parser for any of the languages, contrary to the information projection scenario.</citsent>
<aftsection>
<nextsent>while better absolute results could be expected using one or more parsers for the languages involved, we think that it is important to isolate the usefulness of exploiting just cross linguistic word order divergences in order to obtain partial prior knowledge about the constituent structure of language, which is then exploited in an em learning approach (section 3).
</nextsent>
<nextsent>not using parser for some languages also makes it possible to compare various language pairs at the same level, and specifically, we can experiment with grammar induction for english exploiting various 1the software is available at http://www.isi.edu/och/giza++.html at   that
</nextsent>
<nextsent>moment  the  voting  will  commence  .  le   vote
</nextsent>
<nextsent>aura  lieu  ?  ce  moment  -la  .  figure 1: alignment example other languages.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3253">
<title id=" P04-1060.xml">experiments in parallel text based grammar induction </title>
<section> cross-language order divergences.  </section>
<citcontext>
<prevsection>
<prevsent>let us define maximal  -block as an  -block  $ 35353  * , such that adding  $#=   at the beginning or  *    at the end is either (i) impossible (because it would lead to non-block, or  $?=   or  *    do not exist as we are at the beginning or end of the string), or (ii) it would introduce new crossing alignment2the block notion we are defining in this section is indirectly related to the concept of phrase?
</prevsent>
<prevsent>in recent work in statistical machine translation.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
(koehn et al, 2003) <papid> N03-1017 </papid>show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only.</citsent>
<aftsection>
<nextsent>in our context, we are interested in inducing syntactic constituents based on alignment information; given the observations from statistical mt, it does not come as surprise that there is no direct link from blocks to constituents.
</nextsent>
<nextsent>our work can be seen as an attempt to zero in on the distinction between the concepts; we find that it is most useful to keep track of the boundaries between blocks.(wu, 1997) <papid> J97-3002 </papid>also includes brief discussion of crossing constraints that can be derived from phrase structure cor respon dences.</nextsent>
<nextsent>to the block.3string     in (1) is not maximal  -block, because       is an  -block; but       is maximal since   is the final word of the sentence and </nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3254">
<title id=" P04-1060.xml">experiments in parallel text based grammar induction </title>
<section> cross-language order divergences.  </section>
<citcontext>
<prevsection>
<prevsent>(koehn et al, 2003) <papid> N03-1017 </papid>show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only.</prevsent>
<prevsent>in our context, we are interested in inducing syntactic constituents based on alignment information; given the observations from statistical mt, it does not come as surprise that there is no direct link from blocks to constituents.</prevsent>
</prevsection>
<citsent citstr=" J97-3002 ">
our work can be seen as an attempt to zero in on the distinction between the concepts; we find that it is most useful to keep track of the boundaries between blocks.(wu, 1997) <papid> J97-3002 </papid>also includes brief discussion of crossing constraints that can be derived from phrase structure cor respon dences.</citsent>
<aftsection>
<nextsent>to the block.3string     in (1) is not maximal  -block, because       is an  -block; but       is maximal since   is the final word of the sentence and
</nextsent>
<nextsent>      is non-block.
</nextsent>
<nextsent>we can now make the initial observation precise that (1) and (2) have the same block structure, but the constituent structures are different (and this isnot due to an incorrect alignment).
</nextsent>
<nextsent>is maximal block in both cases, but while it is constituent in (1), it isnt in (2).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3258">
<title id=" P04-2012.xml">a framework for unsupervised natural language morphology induction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>striving to bypass the time consuming, labor intensive task of constructing morphological analyzer by hand, unsupervised morphology induction techniques seek to automatically discover the morphological structure of natural language through the analysis of corpora.
</prevsent>
<prevsent>this paper presents framework for automatic natural language morphology induction inspired by the traditional and linguistic concept of inflection classes.
</prevsent>
</prevsection>
<citsent citstr=" W04-0107 ">
monson et al (2004) <papid> W04-0107 </papid>uses the framework discussed in this paper and presents results using an intuitive baseline search strategy.</citsent>
<aftsection>
<nextsent>this paper presents discussion of the candidate inflection class framework as generalization of corpus tries used in early work (harris, 1955; harris, 1967; hafer and weiss, 1974) and discusses an as yet unimplemented statistically motivated search strategy.
</nextsent>
<nextsent>this paper employs english to illustrate its main conjectures and spanish newswire corpus of 40,011 tokens and 6,975 types for concrete examples.
</nextsent>
<nextsent>it is possible to organize much of the recent work on unsupervised morphology induction by considering the bias each approach has toward discovering morphologically related words that are also ortho graphically similar.
</nextsent>
<nextsent>yarowsky et al (2001), <papid> H01-1035 </papid>who acquire morphological analyzer for language by projecting the morphological analysis of second language onto the first through clever application of statistical machine translation style word alignment probabilities, place no constraints on the orthographic shape of related word forms.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3261">
<title id=" P04-2012.xml">a framework for unsupervised natural language morphology induction </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>this paper employs english to illustrate its main conjectures and spanish newswire corpus of 40,011 tokens and 6,975 types for concrete examples.
</prevsent>
<prevsent>it is possible to organize much of the recent work on unsupervised morphology induction by considering the bias each approach has toward discovering morphologically related words that are also ortho graphically similar.
</prevsent>
</prevsection>
<citsent citstr=" H01-1035 ">
yarowsky et al (2001), <papid> H01-1035 </papid>who acquire morphological analyzer for language by projecting the morphological analysis of second language onto the first through clever application of statistical machine translation style word alignment probabilities, place no constraints on the orthographic shape of related word forms.</citsent>
<aftsection>
<nextsent>next along the spectrum of orthographic similarity bias is the work of schone and jurafsky (2000), <papid> W00-0712 </papid>schone and jurafsky (2001), <papid> N01-1024 </papid>who first acquire list of potential morphological variants using an orthographic similarity technique due to gaussier (1999) <papid> W99-0904 </papid>in which pairs of words with the same initial string are identified.</nextsent>
<nextsent>they then apply latent semantic analysis (lsa) to score the potential morphological variants with semantic distance.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3262">
<title id=" P04-2012.xml">a framework for unsupervised natural language morphology induction </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>it is possible to organize much of the recent work on unsupervised morphology induction by considering the bias each approach has toward discovering morphologically related words that are also ortho graphically similar.
</prevsent>
<prevsent>yarowsky et al (2001), <papid> H01-1035 </papid>who acquire morphological analyzer for language by projecting the morphological analysis of second language onto the first through clever application of statistical machine translation style word alignment probabilities, place no constraints on the orthographic shape of related word forms.</prevsent>
</prevsection>
<citsent citstr=" W00-0712 ">
next along the spectrum of orthographic similarity bias is the work of schone and jurafsky (2000), <papid> W00-0712 </papid>schone and jurafsky (2001), <papid> N01-1024 </papid>who first acquire list of potential morphological variants using an orthographic similarity technique due to gaussier (1999) <papid> W99-0904 </papid>in which pairs of words with the same initial string are identified.</citsent>
<aftsection>
<nextsent>they then apply latent semantic analysis (lsa) to score the potential morphological variants with semantic distance.
</nextsent>
<nextsent>word forms with small semantic distance are proposed as morphological variants of one anther.
</nextsent>
<nextsent>goldsmith (2001), <papid> J01-2001 </papid>by searching over space of morphology models limited to substitution of suffixes, ties morphology yet closer to orthography.</nextsent>
<nextsent>segmenting word forms in corpus, goldsmith creates an inventory of stems and suffixes.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3263">
<title id=" P04-2012.xml">a framework for unsupervised natural language morphology induction </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>it is possible to organize much of the recent work on unsupervised morphology induction by considering the bias each approach has toward discovering morphologically related words that are also ortho graphically similar.
</prevsent>
<prevsent>yarowsky et al (2001), <papid> H01-1035 </papid>who acquire morphological analyzer for language by projecting the morphological analysis of second language onto the first through clever application of statistical machine translation style word alignment probabilities, place no constraints on the orthographic shape of related word forms.</prevsent>
</prevsection>
<citsent citstr=" N01-1024 ">
next along the spectrum of orthographic similarity bias is the work of schone and jurafsky (2000), <papid> W00-0712 </papid>schone and jurafsky (2001), <papid> N01-1024 </papid>who first acquire list of potential morphological variants using an orthographic similarity technique due to gaussier (1999) <papid> W99-0904 </papid>in which pairs of words with the same initial string are identified.</citsent>
<aftsection>
<nextsent>they then apply latent semantic analysis (lsa) to score the potential morphological variants with semantic distance.
</nextsent>
<nextsent>word forms with small semantic distance are proposed as morphological variants of one anther.
</nextsent>
<nextsent>goldsmith (2001), <papid> J01-2001 </papid>by searching over space of morphology models limited to substitution of suffixes, ties morphology yet closer to orthography.</nextsent>
<nextsent>segmenting word forms in corpus, goldsmith creates an inventory of stems and suffixes.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3264">
<title id=" P04-2012.xml">a framework for unsupervised natural language morphology induction </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>it is possible to organize much of the recent work on unsupervised morphology induction by considering the bias each approach has toward discovering morphologically related words that are also ortho graphically similar.
</prevsent>
<prevsent>yarowsky et al (2001), <papid> H01-1035 </papid>who acquire morphological analyzer for language by projecting the morphological analysis of second language onto the first through clever application of statistical machine translation style word alignment probabilities, place no constraints on the orthographic shape of related word forms.</prevsent>
</prevsection>
<citsent citstr=" W99-0904 ">
next along the spectrum of orthographic similarity bias is the work of schone and jurafsky (2000), <papid> W00-0712 </papid>schone and jurafsky (2001), <papid> N01-1024 </papid>who first acquire list of potential morphological variants using an orthographic similarity technique due to gaussier (1999) <papid> W99-0904 </papid>in which pairs of words with the same initial string are identified.</citsent>
<aftsection>
<nextsent>they then apply latent semantic analysis (lsa) to score the potential morphological variants with semantic distance.
</nextsent>
<nextsent>word forms with small semantic distance are proposed as morphological variants of one anther.
</nextsent>
<nextsent>goldsmith (2001), <papid> J01-2001 </papid>by searching over space of morphology models limited to substitution of suffixes, ties morphology yet closer to orthography.</nextsent>
<nextsent>segmenting word forms in corpus, goldsmith creates an inventory of stems and suffixes.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3265">
<title id=" P04-2012.xml">a framework for unsupervised natural language morphology induction </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>they then apply latent semantic analysis (lsa) to score the potential morphological variants with semantic distance.
</prevsent>
<prevsent>word forms with small semantic distance are proposed as morphological variants of one anther.
</prevsent>
</prevsection>
<citsent citstr=" J01-2001 ">
goldsmith (2001), <papid> J01-2001 </papid>by searching over space of morphology models limited to substitution of suffixes, ties morphology yet closer to orthography.</citsent>
<aftsection>
<nextsent>segmenting word forms in corpus, goldsmith creates an inventory of stems and suffixes.
</nextsent>
<nextsent>suffixes which can interchangeably concatenate onto set of stems form signature.
</nextsent>
<nextsent>after defining the space of signatures, goldsmith searches for that choice of word segment ations resulting in minimum description length local optimum.
</nextsent>
<nextsent>finally, the work of harris (1955), work of harris (1967), and later hafer and weiss (1974), has direct bearing on the approach taken in this paper.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3273">
<title id=" P02-1063.xml">revision learning and its application to partofspeech tagging </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recently, corpus-based approaches have been widely studied in many natural language processing tasks, such as part-of-speech (pos) tagging, syntactic analysis, text categorization and word sense disambiguation.
</prevsent>
<prevsent>in corpus-basednatural language processing, one important issue is to decide which learning model to use.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
various learning models have been studied such as hidden markov models (hmms) (rabiner and juang, 1993), decision trees (breiman et al., 1984) and maximum entropy models (bergeret al, 1996).<papid> J96-1002 </papid></citsent>
<aftsection>
<nextsent>recently, support vector machines (svms) (vapnik, 1998; cortes and vap nik, 1995) are getting to be used, which are supervised machine learning algorithm for binary classification.
</nextsent>
<nextsent>svms have good generalization performance and can handle large number of features, and are applied to some tasks ? presently with oki electric industry successfully (joachims, 1998; kudoh and matsumoto, 2000).
</nextsent>
<nextsent>however, their computational cost is large and is weakness of svms.
</nextsent>
<nextsent>in general, trade-off between capacity and computational cost of learning models exists.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3274">
<title id=" P02-1063.xml">revision learning and its application to partofspeech tagging </title>
<section> revision learning.  </section>
<citcontext>
<prevsection>
<prevsent>this problem become more serious when costly binary classifiers are used or when large amount of data is used.
</prevsent>
<prevsent>to cope with this problem, let us consider the task of pos tagging.
</prevsent>
</prevsection>
<citsent citstr=" A00-1031 ">
most portions of pos tagging is not so difficult and simple pos-based hmmslearning 1 achieves more than 95% accuracy simply using the pos context (brants, 2000).<papid> A00-1031 </papid></citsent>
<aftsection>
<nextsent>this means that the low capacity model is enough to do most portions of the task, and we need not use high accuracy but costly algorithm inevery portion of the task.
</nextsent>
<nextsent>this is the base motivation of the revision model we are proposing here.
</nextsent>
<nextsent>revision learning uses binary classifier with higher capacity to revise the errors made bythe stochastic model with lower capacity as fol lows: during the training phase, ranking is assigned to each class by the stochastic model for training example, that is, the candidate classes are sorted in descending order of its conditional probability given the example.
</nextsent>
<nextsent>then, the classes are checked in their ranking order to create binary classifiers as follows.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3276">
<title id=" P02-1063.xml">revision learning and its application to partofspeech tagging </title>
<section> related works.  </section>
<citcontext>
<prevsection>
<prevsent>this is the advantage of our method compared to simplehmms, because hmms have difficulty in handling lot of features such as the lexical forms of words.
</prevsent>
<prevsent>our proposal is to revise the outputs of stochastic model using binary classifiers.
</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
brill studied transformation-based error-driven learning (tbl) (brill, 1995), <papid> J95-4004 </papid>which conducts pos tagging by applying the transformation rules to the pos tags of given sentence, and has are semblance to revision learning in that the second model revises the output of the first model.</citsent>
<aftsection>
<nextsent>word segmentation tagging training testing time time recall precision f-measure recall precision f-measure (hour) (second) pos original 98.06% 98.77% 98.42% 95.61% 96.30% 95.96% 0.02 8 bigram with rl 99.06% 99.27% 99.16% 98.13% 98.33% 98.23% 11 184 chasen original 99.06% 99.20% 99.13% 97.67% 97.81% 97.74% 0.05 15 with rl 99.22% 99.34% 99.28% 98.26% 98.37% 98.32% 6 573 table 3: result of morphological analysis part-of-speech # in test data original with rl difference noun 41512 40355 40556 +201 prefix 817 781 784 +3 verb 8205 8076 8115 +39 adjective 678 632 655 +23 adverb 779 735 750 +15 adnominal 378 373 373 0 conjunction 258 243 243 0 particle 20298 19686 19942 +256 auxiliary 4419 4333 4336 +3 interject ion 94 90 91 +1 symbol 15665 15647 15651 +4 others 1 1 1 0 filler 43 36 36 0 table 4: the number of correctly tagged morphemes for each pos category tag however, our method differs from tbl in two ways.
</nextsent>
<nextsent>first, our revision learner simply answers whether given pattern is correct or not, and any types of binary classifiers are applicable.second, in our model, the second learner is applied to the output of the first learner only once.in contrast, rewriting rules are applied repeatedly in the tbl.
</nextsent>
<nextsent>recently, combinations of multiple learners have been studied to achieve high performance(alpaydm, 1998).
</nextsent>
<nextsent>such methodologies to combine multiple learners can be distinguished into two approaches: one is the multi-expert method and the other is the multi-stage method.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3277">
<title id=" P02-1063.xml">revision learning and its application to partofspeech tagging </title>
<section> related works.  </section>
<citcontext>
<prevsection>
<prevsent>in the latter, the multiple learners are ordered in series, and each learner is trained and answers only if the previous learner rejects the examples.
</prevsent>
<prevsent>revision learning belongs to the latter approach.
</prevsent>
</prevsection>
<citsent citstr=" P98-1029 ">
in pos tagging, some studies using the multi-expert method were conducted (van halteren et al, 2001; ma`rquez et al., 1999), and brill and wu (1998) <papid> P98-1029 </papid>combined maximum entropy models, tbl, unigram and trigram, and achieved higher accuracy than any of the four learners (97.2% for wsj corpus).</citsent>
<aftsection>
<nextsent>regarding the multi-stage methods, cascading (alpaydin and kaynak, 1998) is well known, and even-zohar and roth (2001) proposed the sequential learning model and applied it to pos tagging.
</nextsent>
<nextsent>their methods differ from revision learning in that each learner behaves in the same way and more than one learner is used in their methods, but in revision learning the stochastic model assigns rankings to candidates and the binary classifier selects the output.
</nextsent>
<nextsent>furthermore, mistakes made by former learner are fatal intheir methods, but is not so in revision learning because the binary classifier works to revise them.
</nextsent>
<nextsent>the advantage of the multi-expert method is that each learner can help each other even ifit has some weakness, and generalization errors can be decreased.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3278">
<title id=" P01-1057.xml">using a random ised controlled clinical trial to evaluate an nlg system </title>
<section> evaluation of nlg systems.  </section>
<citcontext>
<prevsection>
<prevsent>the purpose of this paper is to discuss the clinical trial from an nlg evaluation perspective, in order to help future researchers decide when clinical trial (or similar large-scale task effectiveness evaluation) would be an appropriate way to evaluate their systems.
</prevsent>
<prevsent>evaluation is becoming increasingly important in nlg, as in other areas of nlp; see mellish and dale (1998) for summary of nlg evaluation.as mellish and dale point out, we can evaluate the effectiveness of underlying theories, general properties of nlg systems and texts (such as computational speed, or text understandability), or the effectiveness of the generated texts in an actual task or application context.
</prevsent>
</prevsection>
<citsent citstr=" J97-1007 ">
theory evaluations are typically done by comparing predictions of theory to what is observed in human authored corpus (for example, (yeh and mellish,1997)).<papid> J97-1007 </papid></citsent>
<aftsection>
<nextsent>evaluations of text properties are typically done by asking human judges to rate the quality of generated texts (for example, (lester and porter, 1997)); <papid> J97-1004 </papid>sometimes human-authored texts are included in the rated set (without judges knowing which texts are human-authored) to provide baseline.</nextsent>
<nextsent>task evaluations (for example,(young, 1999)) are typically done by showing human subjects different texts, and measuring differences in an outcome variable, such as success in performing task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3279">
<title id=" P01-1057.xml">using a random ised controlled clinical trial to evaluate an nlg system </title>
<section> evaluation of nlg systems.  </section>
<citcontext>
<prevsection>
<prevsent>evaluation is becoming increasingly important in nlg, as in other areas of nlp; see mellish and dale (1998) for summary of nlg evaluation.as mellish and dale point out, we can evaluate the effectiveness of underlying theories, general properties of nlg systems and texts (such as computational speed, or text understandability), or the effectiveness of the generated texts in an actual task or application context.
</prevsent>
<prevsent>theory evaluations are typically done by comparing predictions of theory to what is observed in human authored corpus (for example, (yeh and mellish,1997)).<papid> J97-1007 </papid></prevsent>
</prevsection>
<citsent citstr=" J97-1004 ">
evaluations of text properties are typically done by asking human judges to rate the quality of generated texts (for example, (lester and porter, 1997)); <papid> J97-1004 </papid>sometimes human-authored texts are included in the rated set (without judges knowing which texts are human-authored) to provide baseline.</citsent>
<aftsection>
<nextsent>task evaluations (for example,(young, 1999)) are typically done by showing human subjects different texts, and measuring differences in an outcome variable, such as success in performing task.
</nextsent>
<nextsent>however, despite the above work, we are not aware of any previous evaluation which has compared the effectiveness of nlg texts at meeting communicative goal against the effectiveness of non-nlg control texts.
</nextsent>
<nextsent>youngs task evaluation, which may be the most rigorous previous task evaluation of an nlg system, compared the effectiveness of texts generated by different nlg algorithms, while the idas task evaluation(levine and mellish, 1995) did not include control text of any kind.
</nextsent>
<nextsent>coch (1996) <papid> C96-1043 </papid>and lester and porter (1997) <papid> J97-1004 </papid>have compared nlg texts to human written and (in cochs case) mail-merge texts, butthe comparisons were judgements by human domain experts, they did not measure the actual impact of the texts on users.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3280">
<title id=" P01-1057.xml">using a random ised controlled clinical trial to evaluate an nlg system </title>
<section> evaluation of nlg systems.  </section>
<citcontext>
<prevsection>
<prevsent>however, despite the above work, we are not aware of any previous evaluation which has compared the effectiveness of nlg texts at meeting communicative goal against the effectiveness of non-nlg control texts.
</prevsent>
<prevsent>youngs task evaluation, which may be the most rigorous previous task evaluation of an nlg system, compared the effectiveness of texts generated by different nlg algorithms, while the idas task evaluation(levine and mellish, 1995) did not include control text of any kind.
</prevsent>
</prevsection>
<citsent citstr=" C96-1043 ">
coch (1996) <papid> C96-1043 </papid>and lester and porter (1997) <papid> J97-1004 </papid>have compared nlg texts to human written and (in cochs case) mail-merge texts, butthe comparisons were judgements by human domain experts, they did not measure the actual impact of the texts on users.</citsent>
<aftsection>
<nextsent>carenini and moore(2000) <papid> P00-1020 </papid>probably came closest to controlled evaluation of nlg vs non-nlg alternatives, because they compared the impact of nlg argumentative texts to no-text control (where users had access to the underlying data but were not given any texts arguing for particular choice).</nextsent>
<nextsent>task evaluations that compare the effectiveness of texts from nlg systems to the effectiveness ofnon-nlg alternatives (mail-merge texts, human written texts, or fixed texts) are expensive and difficult to organise, but we believe they are essential to the progress of nlg, both scientifically and technologically.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3282">
<title id=" P01-1057.xml">using a random ised controlled clinical trial to evaluate an nlg system </title>
<section> evaluation of nlg systems.  </section>
<citcontext>
<prevsection>
<prevsent>youngs task evaluation, which may be the most rigorous previous task evaluation of an nlg system, compared the effectiveness of texts generated by different nlg algorithms, while the idas task evaluation(levine and mellish, 1995) did not include control text of any kind.
</prevsent>
<prevsent>coch (1996) <papid> C96-1043 </papid>and lester and porter (1997) <papid> J97-1004 </papid>have compared nlg texts to human written and (in cochs case) mail-merge texts, butthe comparisons were judgements by human domain experts, they did not measure the actual impact of the texts on users.</prevsent>
</prevsection>
<citsent citstr=" P00-1020 ">
carenini and moore(2000) <papid> P00-1020 </papid>probably came closest to controlled evaluation of nlg vs non-nlg alternatives, because they compared the impact of nlg argumentative texts to no-text control (where users had access to the underlying data but were not given any texts arguing for particular choice).</citsent>
<aftsection>
<nextsent>task evaluations that compare the effectiveness of texts from nlg systems to the effectiveness ofnon-nlg alternatives (mail-merge texts, human written texts, or fixed texts) are expensive and difficult to organise, but we believe they are essential to the progress of nlg, both scientifically and technologically.
</nextsent>
<nextsent>in this paper we describe such an evaluation which we performed on thestop system.
</nextsent>
<nextsent>the evaluation was indeed expensive and time-consuming, and ultimately was disappointing in that it suggested stop texts were no more effective than control texts, but we believe that this kind of evaluation was essential to the project.
</nextsent>
<nextsent>we hope that our description of the stop clinical trial and what we learned from it willen courage other researchers to consider performing effectiveness evaluations of nlg systems against non-nlg alternatives.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3284">
<title id=" P01-1057.xml">using a random ised controlled clinical trial to evaluate an nlg system </title>
<section> other evaluation techniques in stop.  </section>
<citcontext>
<prevsection>
<prevsent>under this perspective it is less important to state what lessons or insights can bedrawn from particular negative result, what matters is the overall pattern of positive and negative results in group of related experiments.
</prevsent>
<prevsent>andlike most such procedures, the process of inferring general rules from collection of specific experimental results will work much better if it has access to both positive and negative examples; in other words, if researchers publish their failures as well as their successes.we believe that negative results are also important in nlg, nlp, and ai, even if it is not possible to draw straightforward lessons from them; and we hope that more such results are reported in the future.
</prevsent>
</prevsection>
<citsent citstr=" J00-2005 ">
the clinical trial was by far the biggest evaluation exercise in stop, but we also performed some smaller evaluations in order to test our algorithms and knowledge acquisition methodology (reiter, 2000; <papid> J00-2005 </papid>reiter et al, 2000).<papid> W00-1429 </papid></citsent>
<aftsection>
<nextsent>these included: 1.
</nextsent>
<nextsent>asking smokers or domain experts to read.
</nextsent>
<nextsent>two letters, and state which one they thought was superior; 2.
</nextsent>
<nextsent>statistical analyses of characteristics of.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3285">
<title id=" P01-1057.xml">using a random ised controlled clinical trial to evaluate an nlg system </title>
<section> other evaluation techniques in stop.  </section>
<citcontext>
<prevsection>
<prevsent>under this perspective it is less important to state what lessons or insights can bedrawn from particular negative result, what matters is the overall pattern of positive and negative results in group of related experiments.
</prevsent>
<prevsent>andlike most such procedures, the process of inferring general rules from collection of specific experimental results will work much better if it has access to both positive and negative examples; in other words, if researchers publish their failures as well as their successes.we believe that negative results are also important in nlg, nlp, and ai, even if it is not possible to draw straightforward lessons from them; and we hope that more such results are reported in the future.
</prevsent>
</prevsection>
<citsent citstr=" W00-1429 ">
the clinical trial was by far the biggest evaluation exercise in stop, but we also performed some smaller evaluations in order to test our algorithms and knowledge acquisition methodology (reiter, 2000; <papid> J00-2005 </papid>reiter et al, 2000).<papid> W00-1429 </papid></citsent>
<aftsection>
<nextsent>these included: 1.
</nextsent>
<nextsent>asking smokers or domain experts to read.
</nextsent>
<nextsent>two letters, and state which one they thought was superior; 2.
</nextsent>
<nextsent>statistical analyses of characteristics of.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3287">
<title id=" P01-1015.xml">from rags to riches exploiting the potential of a flexible generation architecture </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper we introduce modular processing architecture with concrete implementation which aims to meet the rags goals of transparency and reusability.
</prevsent>
<prevsent>we illustrate the model with the riches system ? generation system built from simple linguistically motivated modules.
</prevsent>
</prevsection>
<citsent citstr=" A00-1017 ">
as part of the rags (reference architecture for generation systems) project, mellish et al(2000) <papid> A00-1017 </papid>introduces framework for the representation of data in nlg systems, the rags data model?.this model offers formally well-defined declarative representation language, which supports the complex and dynamic data requirements of generation systems, e.g. different levels of representation (conceptual to syntax), mixed representations that cut across levels, partial and shared structures and canned?</citsent>
<aftsection>
<nextsent>representations.
</nextsent>
<nextsent>however  we would like to acknowledge the financial support of the epsrc (rags ? reference architecture for generation systems: grant gr/l77102 to donia scott), as well as the intellectual contribution of our partners at edinburgh (chris mellish and mike reape: grant gr/l77041 to mellish) and other colleagues at the itri, especially nedjet bouayad agha.
</nextsent>
<nextsent>we would also like to acknowledge the contribution of colleagues who worked on the riches system previ ously: neil tipper and rodger kibble.
</nextsent>
<nextsent>we are grateful to our anonymous referees for their helpful comments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3288">
<title id=" P01-1015.xml">from rags to riches exploiting the potential of a flexible generation architecture </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>rags, as described in that paper, says very little about the functional structure of an nlg system,or the issues arising from more complex processing regimes (see for example robin (1994), inuie et al, (1992) for further discussion).
</prevsent>
<prevsent>nlg systems, especially end-to-end, applied nlg systems, have many functional ities in common.
</prevsent>
</prevsection>
<citsent citstr=" W94-0319 ">
reiter (1994) <papid> W94-0319 </papid>proposed an analysis of such systems in terms of simple three stage pipeline.more recently cahill et al(1999) attempted to repeat the analysis, but found that while most systems did implement pipeline, they did not implement the same pipeline ? different functional ities occurred in different ways and different orders in different systems.</citsent>
<aftsection>
<nextsent>but this survey did identify number of core functional ities which seem to occur during the execution of most systems.
</nextsent>
<nextsent>in order to accommodate this result, process model?
</nextsent>
<nextsent>was sketched which aimed to support both pipelines and more complex control regimes inflexible but structured way (see (cahill et al, 1999),(rags, 2000)).
</nextsent>
<nextsent>in this paper, we describe our attempts to test these ideas in simple nlg application that is based on concrete realisation of such an architecture1 .the rags data model aims to promote comparability and re-usability in the nlg research community, as well as insight into the organisation and processing of linguistic data in nlg.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3290">
<title id=" P01-1015.xml">from rags to riches exploiting the potential of a flexible generation architecture </title>
<section> the rags data model.  </section>
<citcontext>
<prevsection>
<prevsent>however, it does not in itself say anything about how modules in such system might interact.
</prevsent>
<prevsent>this paper describes concrete realisation of the rags object and arrows model, oasys, as applied to simple but flexible nlg system called riches.
</prevsent>
</prevsection>
<citsent citstr=" W00-1410 ">
this is not the first such realisation: cahill et al, (2000) <papid> W00-1410 </papid>describes partial re-implementation of the caption generation system?</citsent>
<aftsection>
<nextsent>(mittal et al, 1999) which includes an objects and arrows whiteboard?.
</nextsent>
<nextsent>the oasyssystem includes more specific proposals for processing and inter-module communication, and riches demonstrates how this can be used to support modular architecture based on small scale functionally-motivated units.
</nextsent>
<nextsent>oasys (objects and arrows system) is software library which provides:   an implementation of the rags object and arrows (o/a) data representation,   support for representing the five-layer rags data model in o/a terms,   an event-driven active database server for o/a representations.
</nextsent>
<nextsent>together these components provide central corefor rags-style nlg applications, allowing separate parts of nlg functionality to be specified in independent modules, which communicate exclusively via the oasys server.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3291">
<title id=" P01-1015.xml">from rags to riches exploiting the potential of a flexible generation architecture </title>
<section> riches.  </section>
<citcontext>
<prevsection>
<prevsent>pic2the dashed lines indicate flow of information, solid arrows indicate approximately flow of control between modules, double boxes indicate completely reused module (from another system), while double box with dashed outer indicates module partially reused.
</prevsent>
<prevsent>ellipses indicate information sources, as opposed to processing modules.
</prevsent>
</prevsection>
<citsent citstr=" C00-2093 ">
tures, annotated with their semreps, are part of the picture library, and media selection builds small pieces of docrep referencing the pictures.document planner (dp) the document planner, based on the iconoclast text planner(power, 2000) <papid> C00-2093 </papid>takes the input rhetrep and produces document structure (docrep).</citsent>
<aftsection>
<nextsent>this specifies aspects such as the text-level (e.g.,paragraph, sentence) and the relative ordering of propositions in the docrep.
</nextsent>
<nextsent>its leaves refer to synreps corresponding to syntactic phrases.
</nextsent>
<nextsent>this module is pipe lined after ms, to make sure that it takes account of any pictures that have been included in the document.
</nextsent>
<nextsent>lexical choice (lc) lexical choice happens intwo stages.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3292">
<title id=" P01-1015.xml">from rags to riches exploiting the potential of a flexible generation architecture </title>
<section> riches.  </section>
<citcontext>
<prevsection>
<prevsent>finalise lexical output (flo) riches uses an external sentence realiser component with its own non-rags input specification.
</prevsent>
<prevsent>flo provides the interface to this realiser, extracting (mostlysyntactic) information from oasys and converting it to the appropriate form for the realiser.
</prevsent>
</prevsection>
<citsent citstr=" A97-1039 ">
currently, flo supports the lingo realiser (carrollet al, 1999), but we are also looking at flo modules for realpro (lavoie and rambow, 1997) <papid> A97-1039 </papid>and fuf/surge (elhadad et al, 1997).<papid> J97-2001 </papid></citsent>
<aftsection>
<nextsent>renderer (rend) the renderer is the module that puts the concrete document together.
</nextsent>
<nextsent>guided by the document structure, it produces html formatting for the text and positions and references the pictures.
</nextsent>
<nextsent>individual sentences are produced for it by lingo, via the flo interface.
</nextsent>
<nextsent>flo actually processes sentences independently of rend,so when rend makes request, either the sentence is there already, or the request is queued, and serviced when it becomes available.lingo the lingo realiser uses wide coverage grammar of english in the lkb hpsg framework, (copestake and flickinger, 2000).the tactical generation component accepts input in the minimal recur sion semantics formalism and produces the target text using chart driven algorithm with an optimised treatment of modification (carroll et al, 1999).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3293">
<title id=" P01-1015.xml">from rags to riches exploiting the potential of a flexible generation architecture </title>
<section> riches.  </section>
<citcontext>
<prevsection>
<prevsent>finalise lexical output (flo) riches uses an external sentence realiser component with its own non-rags input specification.
</prevsent>
<prevsent>flo provides the interface to this realiser, extracting (mostlysyntactic) information from oasys and converting it to the appropriate form for the realiser.
</prevsent>
</prevsection>
<citsent citstr=" J97-2001 ">
currently, flo supports the lingo realiser (carrollet al, 1999), but we are also looking at flo modules for realpro (lavoie and rambow, 1997) <papid> A97-1039 </papid>and fuf/surge (elhadad et al, 1997).<papid> J97-2001 </papid></citsent>
<aftsection>
<nextsent>renderer (rend) the renderer is the module that puts the concrete document together.
</nextsent>
<nextsent>guided by the document structure, it produces html formatting for the text and positions and references the pictures.
</nextsent>
<nextsent>individual sentences are produced for it by lingo, via the flo interface.
</nextsent>
<nextsent>flo actually processes sentences independently of rend,so when rend makes request, either the sentence is there already, or the request is queued, and serviced when it becomes available.lingo the lingo realiser uses wide coverage grammar of english in the lkb hpsg framework, (copestake and flickinger, 2000).the tactical generation component accepts input in the minimal recur sion semantics formalism and produces the target text using chart driven algorithm with an optimised treatment of modification (carroll et al, 1999).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3294">
<title id=" P04-1034.xml">the sentimental factor improving review classification via human provided information </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>information, such as classification according to topic; however, interest is growing in producing information about the opinions that document contains; for instance, morinaga et al (2002).
</prevsent>
<prevsent>inmarch, 2004, the american association for artificial intelligence held symposium in this area, entitled exploring affect and attitude in text.one task in opinion extraction is to label review document according to its prevailing sentiment ? {1, 1} (unfavorable or favorable).
</prevsent>
</prevsection>
<citsent citstr=" W02-1011 ">
several previous papers have addressed this problem by building models that rely exclusively upon labeled documents, e.g. pang et al (2002), <papid> W02-1011 </papid>dave et al (2003).</citsent>
<aftsection>
<nextsent>by learning models from labeled data, one can apply familiar, powerful techniques directly; however, in practice it may be difficult to obtain enough labeled reviews to learn model parameters accurately.
</nextsent>
<nextsent>a contrasting approach (turney, 2002) <papid> P02-1053 </papid>relies only upon documents whose labels are unknown.</nextsent>
<nextsent>this makes it possible to use large underlying corpus ? in this case, the entire internet as seen through the alta vista search engine.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3295">
<title id=" P04-1034.xml">the sentimental factor improving review classification via human provided information </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>several previous papers have addressed this problem by building models that rely exclusively upon labeled documents, e.g. pang et al (2002), <papid> W02-1011 </papid>dave et al (2003).</prevsent>
<prevsent>by learning models from labeled data, one can apply familiar, powerful techniques directly; however, in practice it may be difficult to obtain enough labeled reviews to learn model parameters accurately.</prevsent>
</prevsection>
<citsent citstr=" P02-1053 ">
a contrasting approach (turney, 2002) <papid> P02-1053 </papid>relies only upon documents whose labels are unknown.</citsent>
<aftsection>
<nextsent>this makes it possible to use large underlying corpus ? in this case, the entire internet as seen through the alta vista search engine.
</nextsent>
<nextsent>as result, estimates for model parameters are subject to relatively small amount of random variation.
</nextsent>
<nextsent>the corresponding drawback to such an approach is that its predictions are not validated on actual documents.in machine learning, it has often been effective to use labeled and unlabeled examples in tandem, e.g. nigam et al (2000).
</nextsent>
<nextsent>turneys model introduces the further consideration of incorporating human-provided knowledge about language.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3296">
<title id=" P04-1034.xml">the sentimental factor improving review classification via human provided information </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the basic concept behind turneys model is quitesimple.
</prevsent>
<prevsent>the sentiment orientation?
</prevsent>
</prevsection>
<citsent citstr=" P97-1023 ">
(hatzivas siloglou and mckeown, 1997) <papid> P97-1023 </papid>of pair of wordsis taken to be known.</citsent>
<aftsection>
<nextsent>these words serve as an chors?
</nextsent>
<nextsent>for positive and negative sentiment.
</nextsent>
<nextsent>words that co-occur more frequently with one anchor than the other are themselves taken to be predictive of sentiment.
</nextsent>
<nextsent>as result, information about pair of words is generalized to many words, and then to documents.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3300">
<title id=" P02-1020.xml">measuring text reuse </title>
<section> approaches to measuring text.  </section>
<citcontext>
<prevsection>
<prevsent>4.1 ngram overlap.
</prevsent>
<prevsent>an initial, straightforward approach to assessing the reuse between two texts is to measure the number of shared word ngrams.
</prevsent>
</prevsection>
<citsent citstr=" W01-0515 ">
this method underlies many of the approaches used in copy detection including the approach taken by lyon et al (2001).<papid> W01-0515 </papid>they measure similarity using the set theoretic measures of containment and resemblance of shared trigrams to separate texts written independently and those with sucient similarity to indicate some form of copying.we treat each document as set of overlapping n-word sequences (initially considering only n-word types) and compute similarity score from this.</citsent>
<aftsection>
<nextsent>given two sets of ngrams, we use the set-theoretic containment score to measure similarity between the documents for ngrams of length 1 to 10 words.
</nextsent>
<nextsent>for source text and possibly derived text represented by sets of ngrams n (a) and n(b) respectively, the proportion of ngrams in also in a, the ngram containment n (a;b), is given by: n (a;b) = s (a) \ n (b) j n (b) (1) informally containment measures the number of matches between the elements of ngram sets n (a) and n (b), scaled by the size of n (b).
</nextsent>
<nextsent>in other words we measure the proportion of unique n-grams in that are found in a. the score ranges from 0 to 1, indicating none to all newspaper copy shared with pa respectively.
</nextsent>
<nextsent>we also compare texts by counting only those ngrams with low frequency, in particular those occurring once.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3301">
<title id=" P02-1020.xml">measuring text reuse </title>
<section> approaches to measuring text.  </section>
<citcontext>
<prevsection>
<prevsent>pa copy may be subject to various changes during text reuse, e.g. single sentence may derive from parts of several sourcesentences.
</prevsent>
<prevsent>therefore, strong correlations of sentence length between the derived and source sentences cannot be guaranteed.
</prevsent>
</prevsection>
<citsent citstr=" P91-1022 ">
as result,sentence-length based statistical alignment algorithms (brown et al, 1991; <papid> P91-1022 </papid>gale and church, 1993) <papid> J93-1004 </papid>are not appropriate for this case.</citsent>
<aftsection>
<nextsent>on the other hand, cognate-based algorithms (simard et al, 1992; melamed, 1999) <papid> J99-1003 </papid>are more ecientfor coping with change of text format.</nextsent>
<nextsent>therefore, cognate-based approach is adopted for the meter task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3302">
<title id=" P02-1020.xml">measuring text reuse </title>
<section> approaches to measuring text.  </section>
<citcontext>
<prevsection>
<prevsent>pa copy may be subject to various changes during text reuse, e.g. single sentence may derive from parts of several sourcesentences.
</prevsent>
<prevsent>therefore, strong correlations of sentence length between the derived and source sentences cannot be guaranteed.
</prevsent>
</prevsection>
<citsent citstr=" J93-1004 ">
as result,sentence-length based statistical alignment algorithms (brown et al, 1991; <papid> P91-1022 </papid>gale and church, 1993) <papid> J93-1004 </papid>are not appropriate for this case.</citsent>
<aftsection>
<nextsent>on the other hand, cognate-based algorithms (simard et al, 1992; melamed, 1999) <papid> J99-1003 </papid>are more ecientfor coping with change of text format.</nextsent>
<nextsent>therefore, cognate-based approach is adopted for the meter task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3303">
<title id=" P02-1020.xml">measuring text reuse </title>
<section> approaches to measuring text.  </section>
<citcontext>
<prevsection>
<prevsent>therefore, strong correlations of sentence length between the derived and source sentences cannot be guaranteed.
</prevsent>
<prevsent>as result,sentence-length based statistical alignment algorithms (brown et al, 1991; <papid> P91-1022 </papid>gale and church, 1993) <papid> J93-1004 </papid>are not appropriate for this case.</prevsent>
</prevsection>
<citsent citstr=" J99-1003 ">
on the other hand, cognate-based algorithms (simard et al, 1992; melamed, 1999) <papid> J99-1003 </papid>are more ecientfor coping with change of text format.</citsent>
<aftsection>
<nextsent>therefore, cognate-based approach is adopted for the meter task.
</nextsent>
<nextsent>here cognates are de ned as pairs of terms that are identical, share the same stems, or are substitutable in the given context.the algorithm consists of two principal com ponents: comparison strategy and scoringfunction.
</nextsent>
<nextsent>in brief, the comparison works as follows (more details may be found in piao (2001)).
</nextsent>
<nextsent>for each sentence in the candidate derived text dt the sentences in the candidate source text stare compared in order to nd the best match.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3305">
<title id=" P03-1045.xml">kvalued non associative lambek categorial grammars are not learn able from strings </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>g with l(g?) = l(g).
</prevsent>
<prevsent>after pessimistic unlearnability results in (gold, 1967), learn ability of non trivial classes has been proved in (angluin, 1980) and (shinohara, 1990).
</prevsent>
</prevsection>
<citsent citstr=" C02-1111 ">
recent works from (kanazawa, 1998) and (nicolas, 1999) following (buszkowski and penn, 1990) have answered the problem for different sub-classes of classical categorial grammars (we recall that the whole class of classical categorial grammars is equivalent to context free grammars; the same holds for the class of lambek grammars (pentus, 1993) that is thus not learn able in golds model).the extension of such results for lambek grammars is an interesting challenge that is addressed by works on logic types from (dudau-sofronie et al,2001) (these grammars enjoy direct link with montague semantics), learning from structures in (re tor and bonato, september 2001), complexity results from (florencio, 2002) or unlearnability results from (foret and le nir, 2002<papid> C02-1111 </papid>a; foret and le nir, 2002<papid> C02-1111 </papid>b); this result was shown for several variants but the question was left open for the basic variant, the non associative variant nl.</citsent>
<aftsection>
<nextsent>in this paper, we consider the following question:is the non-associative variant nl of k-valued lam bek grammars learn able from strings; we answer by constructing limit point for this class.
</nextsent>
<nextsent>our construction is in some sense more complex than those for the other systems since they do not directly translate as limit point in the more restricted system nl.
</nextsent>
<nextsent>the paper is organized as follows.
</nextsent>
<nextsent>section 2 gives some background knowledge on three main aspects: lambek categorial grammars ; learning in golds model ; lambek pre group grammars that we use later as models in some proofs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3321">
<title id=" P04-1033.xml">learning with unlabeled data for text categorization using a bootstrapping and a feature projection technique </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>many supervised learning algorithms have been applied to this area.
</prevsent>
<prevsent>these algorithms today are reasonably successful when provided with enough labeled or annotated training examples.
</prevsent>
</prevsection>
<citsent citstr=" C02-1074 ">
for example, there are naive bayes (mccallum and nigam, 1998), rocchio (lewis et al ., 1996), nearest neighbor (knn) (yang et al , 2002), tcfp (ko and seo, 2002), <papid> C02-1074 </papid>and support vector machine (svm) (joachims, 1998).</citsent>
<aftsection>
<nextsent>however, the supervised learning approach has some difficulties.
</nextsent>
<nextsent>one key difficulty is that it requires large, often prohibitive, number of labeled training data for accurate learning.
</nextsent>
<nextsent>since labeling task must be done manually, it is painfully time-consuming process.
</nextsent>
<nextsent>furthermore, since the application area of text categorization has diversified from newswire articles and web pages to e-mails and news group postings, it is also difficult task to create training data for each application area (nigam et al , 1998).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3322">
<title id=" P04-1033.xml">learning with unlabeled data for text categorization using a bootstrapping and a feature projection technique </title>
<section> the bootstrapping algorithm for creating.  </section>
<citcontext>
<prevsection>
<prevsent>learned by using the context-clusters 3.1 preprocessing.
</prevsent>
<prevsent>the preprocessing module has two main roles: extracting content words and reconstructing the collected documents into contexts.
</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
we use the brill pos tagger to extract content words (brill, 1995).<papid> J95-4004 </papid></citsent>
<aftsection>
<nextsent>generally, the supervised learning approach with labeled data regards document as unit of meaning.
</nextsent>
<nextsent>but since we can use only the title words and unlabeled data, we define context as unit of meaning and we employ it as the meaning unit to bootstrap the meaning of each category.
</nextsent>
<nextsent>in our system, we regard sequence of 60 content words within document as context.
</nextsent>
<nextsent>to extract contexts from document, we use sliding window techniques (maarek et al , 1991).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3323">
<title id=" P04-1033.xml">learning with unlabeled data for text categorization using a bootstrapping and a feature projection technique </title>
<section> the bootstrapping algorithm for creating.  </section>
<citcontext>
<prevsection>
<prevsent>3.2.3 creating context-clusters we gather the second-order co-occurrence information by assigning remaining contexts to the context-cluster of each category.
</prevsent>
<prevsent>for the assigning criterion, we calculate similarity between remaining contexts and centroid-contexts of each category.
</prevsent>
</prevsection>
<citsent citstr=" J98-1002 ">
thus we employ the similarity measure technique by karov and edelman (1998).<papid> J98-1002 </papid></citsent>
<aftsection>
<nextsent>in our method, part of this technique is reformed for our purpose and remaining contexts are assigned to each context-cluster by that revised technique.
</nextsent>
<nextsent>1) measurement of word and context similarities as similar words tend to appear in similar contexts, we can compute the similarity by using contextual information.
</nextsent>
<nextsent>words and contexts play complementary roles.
</nextsent>
<nextsent>contexts are similar to the extent that they contain similar words, and words are similar to the extent that they appear in similar contexts (karov and edelman, 1998).<papid> J98-1002 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3330">
<title id=" P01-1021.xml">grammars for local and long dependencies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, any its surface realization projects some linear order relation (called also precedence).
</prevsent>
<prevsent>some properties of surface syntactic structure can be expressed only in terms of both dependency (or its transitive closure called dominance) and precedence.
</prevsent>
</prevsection>
<citsent citstr=" C96-2122 ">
one of such properties, projectivity, requires that any word occurring between word and word dependent on be dominated by  in first dependency grammars (gaifman, 1961)and in some more recent proposals: link grammars (sleator and temperly, 1993), projective dependency grammars (lombardo and lesmo, 1996) <papid> C96-2122 </papid>the projectivity is implied by definition.</citsent>
<aftsection>
<nextsent>insome other theories, e.g. in word grammar (hudson, 1984), it is used as one of the axioms defining acceptable surface structures.
</nextsent>
<nextsent>in presence of this property, d-trees are in sense equivalent to phrase structures with head selection 1.
</nextsent>
<nextsent>it is for this reason that d-trees determined by grammars of robinson (robinson, 1970), categorial grammars (bar-hillel et al, 1960), classical lambek calculus (lambek, 1958), and some other formalisms are projective.
</nextsent>
<nextsent>projectivity affects the complexity of parsing : as rule, it allows dynamic programming technics which lead to polynomial time algorithms (cf.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3331">
<title id=" P01-1021.xml">grammars for local and long dependencies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there are various dependency based approaches to this problem.
</prevsent>
<prevsent>in the framework of meaning-text theory (melcukand pertsov, 1987), dependencies between (some 1see (dikovsky and modina, 2000) for more details.
</prevsent>
</prevsection>
<citsent citstr=" P97-1043 ">
times non adjacent) words are determined in terms of their local neighborhood, which leadsto non-tractable parsing (the np-hardness argument of (neuhaus and broker, 1997) <papid> P97-1043 </papid>applies tothem).</citsent>
<aftsection>
<nextsent>more recent versions of dependency grammars (see e.g.(kahane et al, 1998; <papid> P98-1106 </papid>lombardo and lesmo, 1998; <papid> P98-2130 </papid>broker, 1998)) <papid> P98-1026 </papid>impose on non projective d-trees some constraints weaker than projectivity (cf.</nextsent>
<nextsent>meta-projectivity (nasr, 1995) orpseudo-projectivity (kahane et al, 1998)), <papid> P98-1106 </papid>sufficient for existence of polynomial time parsing algorithm.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3332">
<title id=" P01-1021.xml">grammars for local and long dependencies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the framework of meaning-text theory (melcukand pertsov, 1987), dependencies between (some 1see (dikovsky and modina, 2000) for more details.
</prevsent>
<prevsent>times non adjacent) words are determined in terms of their local neighborhood, which leadsto non-tractable parsing (the np-hardness argument of (neuhaus and broker, 1997) <papid> P97-1043 </papid>applies tothem).</prevsent>
</prevsection>
<citsent citstr=" P98-1106 ">
more recent versions of dependency grammars (see e.g.(kahane et al, 1998; <papid> P98-1106 </papid>lombardo and lesmo, 1998; <papid> P98-2130 </papid>broker, 1998)) <papid> P98-1026 </papid>impose on non projective d-trees some constraints weaker than projectivity (cf.</citsent>
<aftsection>
<nextsent>meta-projectivity (nasr, 1995) orpseudo-projectivity (kahane et al, 1998)), <papid> P98-1106 </papid>sufficient for existence of polynomial time parsing algorithm.</nextsent>
<nextsent>still another approach is developed in the context of intuitionistic resource-dependentlogics, where d-trees are constructed from derivations (cf.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3333">
<title id=" P01-1021.xml">grammars for local and long dependencies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the framework of meaning-text theory (melcukand pertsov, 1987), dependencies between (some 1see (dikovsky and modina, 2000) for more details.
</prevsent>
<prevsent>times non adjacent) words are determined in terms of their local neighborhood, which leadsto non-tractable parsing (the np-hardness argument of (neuhaus and broker, 1997) <papid> P97-1043 </papid>applies tothem).</prevsent>
</prevsection>
<citsent citstr=" P98-2130 ">
more recent versions of dependency grammars (see e.g.(kahane et al, 1998; <papid> P98-1106 </papid>lombardo and lesmo, 1998; <papid> P98-2130 </papid>broker, 1998)) <papid> P98-1026 </papid>impose on non projective d-trees some constraints weaker than projectivity (cf.</citsent>
<aftsection>
<nextsent>meta-projectivity (nasr, 1995) orpseudo-projectivity (kahane et al, 1998)), <papid> P98-1106 </papid>sufficient for existence of polynomial time parsing algorithm.</nextsent>
<nextsent>still another approach is developed in the context of intuitionistic resource-dependentlogics, where d-trees are constructed from derivations (cf.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3334">
<title id=" P01-1021.xml">grammars for local and long dependencies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the framework of meaning-text theory (melcukand pertsov, 1987), dependencies between (some 1see (dikovsky and modina, 2000) for more details.
</prevsent>
<prevsent>times non adjacent) words are determined in terms of their local neighborhood, which leadsto non-tractable parsing (the np-hardness argument of (neuhaus and broker, 1997) <papid> P97-1043 </papid>applies tothem).</prevsent>
</prevsection>
<citsent citstr=" P98-1026 ">
more recent versions of dependency grammars (see e.g.(kahane et al, 1998; <papid> P98-1106 </papid>lombardo and lesmo, 1998; <papid> P98-2130 </papid>broker, 1998)) <papid> P98-1026 </papid>impose on non projective d-trees some constraints weaker than projectivity (cf.</citsent>
<aftsection>
<nextsent>meta-projectivity (nasr, 1995) orpseudo-projectivity (kahane et al, 1998)), <papid> P98-1106 </papid>sufficient for existence of polynomial time parsing algorithm.</nextsent>
<nextsent>still another approach is developed in the context of intuitionistic resource-dependentlogics, where d-trees are constructed from derivations (cf.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3336">
<title id=" P01-1021.xml">grammars for local and long dependencies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>meta-projectivity (nasr, 1995) orpseudo-projectivity (kahane et al, 1998)), <papid> P98-1106 </papid>sufficient for existence of polynomial time parsing algorithm.</prevsent>
<prevsent>still another approach is developed in the context of intuitionistic resource-dependentlogics, where d-trees are constructed from derivations (cf.</prevsent>
</prevsection>
<citsent citstr=" C92-1061 ">
e.g. method in (lecomte, 1992) <papid> C92-1061 </papid>for lambek calculus).</citsent>
<aftsection>
<nextsent>in this context, non-projectived-trees are determined with the use of hypothetical reasoning and of structural rules such ascom mutativity and associativity (see e.g.
</nextsent>
<nextsent>(moortgat, 1990)).in this paper, we put forward novel approach to handling discontinuity in terms of dependency structures.
</nextsent>
<nextsent>we propose notion of polarized dependency (pd-) grammar combining several ideas from cf-tree grammars, dependency grammars and resource-dependent logics.
</nextsent>
<nextsent>as most dependency grammars, the pd-grammars are analyzing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3337">
<title id=" P03-1039.xml">chunk based statistical translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the framework of statistical machine translation formulates the problem of translating source sentence in language into target language as the maximization problem of the conditional probability = argmaxe p(e|j).
</prevsent>
<prevsent>the application of the bayes rule resulted in = argmaxe p(e)p(j|e).
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
the former term p(e) is called language model, representing the likelihood of e. the latter term p(j|e)is called translation model, representing the generation probability from into j.as an implementation of p(j|e), the word alignment based statistical translation (brown et al,1993) <papid> J93-2003 </papid>has been successfully applied to similar language pairs, such as french english and german?</citsent>
<aftsection>
<nextsent>english, but not to drastically different ones, such as japaneseenglish.
</nextsent>
<nextsent>this failure has been due to the limited representation by word alignment and the weak model structure for handling complicated word correspondence.
</nextsent>
<nextsent>this paper provides chunk-based statistical translation as an alternative to the word alignment based statistical translation.
</nextsent>
<nextsent>the translation process inside the translation model is structured as follows.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3341">
<title id=" P03-1039.xml">chunk based statistical translation </title>
<section> translate word-by-word. each source word ei,.  </section>
<citcontext>
<prevsection>
<prevsent>the above procedure is iterated until the set of parameters converge.however, this naive algorithm will suffer from severe computational problems.
</prevsent>
<prevsent>the enumeration of all possible chun kings and together with word alignment and chunk alignment requires significant amount of computation.
</prevsent>
</prevsection>
<citsent citstr=" P01-1067 ">
therefore, we have introduced variation of the inside-outside algorithm as seen in (yamada and knight, 2001) <papid> P01-1067 </papid>for step computation.</citsent>
<aftsection>
<nextsent>the details of the procedure are described in appendix a. in addition to the computational problem, there exists local-maximum problem, where the em algorithm converges to maximum solution but does not guarantee finding the global maximum.
</nextsent>
<nextsent>inorder to solve this problem and to make the parameters converge quickly, ibm model 4 parameters were used as the initial parameters for training.
</nextsent>
<nextsent>we directly applied the lexicon model and fertility model to the chunk-based translation model but set other parameters as uniform.
</nextsent>
<nextsent>3.4 decoding.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3342">
<title id=" P03-1039.xml">chunk based statistical translation </title>
<section> translate word-by-word. each source word ei,.  </section>
<citcontext>
<prevsection>
<prevsent>we directly applied the lexicon model and fertility model to the chunk-based translation model but set other parameters as uniform.
</prevsent>
<prevsent>3.4 decoding.
</prevsent>
</prevsection>
<citsent citstr=" C00-2123 ">
the decoding algorithm employed for this chunk based statistical translation is based on the beam search algorithm for word alignment statistical translation presented in (tillmann and ney, 2000), <papid> C00-2123 </papid>which generates outputs in left-to-right order by consuming input in an arbitrary order.</citsent>
<aftsection>
<nextsent>the decoder consists of two stages: 1.
</nextsent>
<nextsent>generate possible output chunks for all possi-.
</nextsent>
<nextsent>ble input chunks.
</nextsent>
<nextsent>2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3344">
<title id=" P03-1039.xml">chunk based statistical translation </title>
<section> translate word-by-word. each source word ei,.  </section>
<citcontext>
<prevsection>
<prevsent>chunks are bracketed and the words with ? to the left are headwords.
</prevsent>
<prevsent>table 2: experimental results for japanese english translation model wer per bleu se [%] [%] [%] [%] a+b a+b+c model4 43.3 37.2 46.5 59.2 74.1 80.2 chunk3 40.9 36.1 48.4 59.8 73.5 78.8 chunk3+ 38.5 33.7 52.1 65.1 76.3 80.6 per: position independent wer, which penalizes without considering positional disfluencies.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
bleu: bleu score, which computes the ratio of n-gram forthe translation results found in reference translations (pa pineni et al, 2002).<papid> P02-1040 </papid></citsent>
<aftsection>
<nextsent>se: subjective evaluation ranks ranging from to (a:perfect, b:fair, c:acceptable and d:nonsense), judged by native speakers.table 2 summarizes the evaluation of japanese-to english translations, and figure 6 presents some of the results by model4 and chunk3+.
</nextsent>
<nextsent>as table 2 indicates, chunk3 performs better than model4 in terms of the non-subjective evaluations,although it scores almost equally in subjective evaluations.
</nextsent>
<nextsent>with the help of example-based decoding, chunk3+ was evaluated as the best among the three systems.
</nextsent>
<nextsent>the chunk-based translation model was originally inspired by transfer-based machine translation but modeled by chunks in order to capture syntax-based correspondence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3345">
<title id=" P03-1039.xml">chunk based statistical translation </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>reference: wait couple of minutes m telephoning now model4: is this the line is busy now few minutes chunk3: m on another phone now please wait couple of minutes figure 6: translation examples by word alignment based model and chunk-based model estimation, where chunk3 took 20 days for 40 iterations, which is roughly the same amount of time required for training ibm model 5 with pegging.
</prevsent>
<prevsent>the unit of chunk in the statistical machine translation framework has been extensively discussed in the literature.
</prevsent>
</prevsection>
<citsent citstr=" W99-0604 ">
och et al (1999) <papid> W99-0604 </papid>proposed translation template approach that computes phrasal mappings from the viterbi alignments of training corpus.</citsent>
<aftsection>
<nextsent>watanabe et al (2002) used syntax-based phrase alignment to obtainchunks.
</nextsent>
<nextsent>marcu and wong (2002) <papid> W02-1018 </papid>argued for different phrase-based translation modeling that directly induces phrase-by-phrase lexicon model from word-wise data.</nextsent>
<nextsent>all of these methods biasthe training and/or decoding with phrase-level examples obtained by preprocessing corpus (och et al., 1999; <papid> W99-0604 </papid>watanabe et al, 2002) or by allowing lexicon model to hold phrases (marcu and wong,2002).<papid> W02-1018 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3346">
<title id=" P03-1039.xml">chunk based statistical translation </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>och et al (1999) <papid> W99-0604 </papid>proposed translation template approach that computes phrasal mappings from the viterbi alignments of training corpus.</prevsent>
<prevsent>watanabe et al (2002) used syntax-based phrase alignment to obtainchunks.</prevsent>
</prevsection>
<citsent citstr=" W02-1018 ">
marcu and wong (2002) <papid> W02-1018 </papid>argued for different phrase-based translation modeling that directly induces phrase-by-phrase lexicon model from word-wise data.</citsent>
<aftsection>
<nextsent>all of these methods biasthe training and/or decoding with phrase-level examples obtained by preprocessing corpus (och et al., 1999; <papid> W99-0604 </papid>watanabe et al, 2002) or by allowing lexicon model to hold phrases (marcu and wong,2002).<papid> W02-1018 </papid></nextsent>
<nextsent>on the other hand, the chunk-based translation model holds the knowledge of how to construct sequence of chunks from sequence of words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3350">
<title id=" P03-1039.xml">chunk based statistical translation </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>both assume that the source partof translation model is structured either with sequence of chunks or with parse tree, while our method directly models string-to-string procedure.it is clear that the string-to-string modeling with hi den chunk-layers is computationally more expensive than those structure-to-string models.
</prevsent>
<prevsent>however, the structure-to-string approaches are already biased by monolingual chunking or parsing, which, in turn, might not be able to uncover the bilingual phrasal or syntactical constraints often observed in corpus.
</prevsent>
</prevsection>
<citsent citstr=" J00-1004 ">
alshawi et al (2000) <papid> J00-1004 </papid>also presented two-levelarranged word ordering and chunk ordering by hierarchically organized collection of finite state trans ducers.</citsent>
<aftsection>
<nextsent>the main difference from our work is that their approach is basically deterministic, while the chunk-based translation model is non-deterministic.the former method, of course, performs more efficient decoding but requires stronger heuristics to generate set of transducers.
</nextsent>
<nextsent>although the latter approach demands large amount of decoding timeand hypothesis space, it can operate on very broad coverage corpus with appropriate translation modeling.
</nextsent>
<nextsent>acknowledgments the research reported here was supported in part bya contract with the telecommunications advancement organization of japan entitled study of speech dialogue translation technology based on large corpus?.
</nextsent>

</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3351">
<title id=" P01-1050.xml">towards a unified approach to memory and statistical based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>ebmt systems work by modifying existing, human produced translation instances, which are stored in translation memory (tmem).
</prevsent>
<prevsent>many methods have been proposed for storing translation pairs in tmem, finding translation examples that are relevant for translating unseen sentences, and modifying and integrating translation fragment sto produce correct outputs.
</prevsent>
</prevsection>
<citsent citstr=" C92-4203 ">
sato (1992), <papid> C92-4203 </papid>forex ample, stores complete parse trees in the tmem and selects and generates new translations by performing similarity matchings on these trees.</citsent>
<aftsection>
<nextsent>veale and way (1997) store complete sentences; new translations are generated by modifying thetmem translation that is most similar to the input sentence.
</nextsent>
<nextsent>others store phrases; new translations are produced by optimally partitioning the input into phrases that match examples from the tmem (maruyana and watanabe, 1992), or by finding all partial matches and then choosing the best possible translation using multi-engine translation system (brown, 1999).
</nextsent>
<nextsent>with few exceptions (wu and wong, 1998),<papid> P98-2230 </papid>most smt systems are couched in the noisy channel framework (see figure 1).</nextsent>
<nextsent>in this framework, the source language, lets say english, is assumed to be generated by noisy probabilistic source.1 most of the current statistical mt systems treat this source as sequence of words (brown et al, 1993)<papid> J93-2003 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3352">
<title id=" P01-1050.xml">towards a unified approach to memory and statistical based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>veale and way (1997) store complete sentences; new translations are generated by modifying thetmem translation that is most similar to the input sentence.
</prevsent>
<prevsent>others store phrases; new translations are produced by optimally partitioning the input into phrases that match examples from the tmem (maruyana and watanabe, 1992), or by finding all partial matches and then choosing the best possible translation using multi-engine translation system (brown, 1999).
</prevsent>
</prevsection>
<citsent citstr=" P98-2230 ">
with few exceptions (wu and wong, 1998),<papid> P98-2230 </papid>most smt systems are couched in the noisy channel framework (see figure 1).</citsent>
<aftsection>
<nextsent>in this framework, the source language, lets say english, is assumed to be generated by noisy probabilistic source.1 most of the current statistical mt systems treat this source as sequence of words (brown et al, 1993)<papid> J93-2003 </papid></nextsent>
<nextsent>(alternative approaches exist, in which the source is taken to be, for example, sequence of aligned templates/phrases (wang, 1998; och et al., 1999) <papid> W99-0604 </papid>or syntactic tree (yamada and knight,2001).)<papid> P01-1067 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3353">
<title id=" P01-1050.xml">towards a unified approach to memory and statistical based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>others store phrases; new translations are produced by optimally partitioning the input into phrases that match examples from the tmem (maruyana and watanabe, 1992), or by finding all partial matches and then choosing the best possible translation using multi-engine translation system (brown, 1999).
</prevsent>
<prevsent>with few exceptions (wu and wong, 1998),<papid> P98-2230 </papid>most smt systems are couched in the noisy channel framework (see figure 1).</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
in this framework, the source language, lets say english, is assumed to be generated by noisy probabilistic source.1 most of the current statistical mt systems treat this source as sequence of words (brown et al, 1993)<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>(alternative approaches exist, in which the source is taken to be, for example, sequence of aligned templates/phrases (wang, 1998; och et al., 1999) <papid> W99-0604 </papid>or syntactic tree (yamada and knight,2001).)<papid> P01-1067 </papid></nextsent>
<nextsent>in the noisy-channel framework, monolingual corpus is used to derive statistical language model that assigns probability to sequence of words or phrases, thus enabling one to distinguish between sequences of words that are grammatically correct and sequences that are not.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3356">
<title id=" P01-1050.xml">towards a unified approach to memory and statistical based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>with few exceptions (wu and wong, 1998),<papid> P98-2230 </papid>most smt systems are couched in the noisy channel framework (see figure 1).</prevsent>
<prevsent>in this framework, the source language, lets say english, is assumed to be generated by noisy probabilistic source.1 most of the current statistical mt systems treat this source as sequence of words (brown et al, 1993)<papid> J93-2003 </papid></prevsent>
</prevsection>
<citsent citstr=" W99-0604 ">
(alternative approaches exist, in which the source is taken to be, for example, sequence of aligned templates/phrases (wang, 1998; och et al., 1999) <papid> W99-0604 </papid>or syntactic tree (yamada and knight,2001).)<papid> P01-1067 </papid></citsent>
<aftsection>
<nextsent>in the noisy-channel framework, monolingual corpus is used to derive statistical language model that assigns probability to sequence of words or phrases, thus enabling one to distinguish between sequences of words that are grammatically correct and sequences that are not.
</nextsent>
<nextsent>a sentence-aligned parallel corpus is then used in order to build probabilistic translation model 1for the rest of this paper, we use the terms source and target languages according to the jargon specific to thenoisy-channel framework.
</nextsent>
<nextsent>in this framework, the source language is the language into which the machine translation system translates.
</nextsent>
<nextsent>source p(e) decoder channel p(f | e) observed best argmax p(e | f) = argmax p(f | e) p(e) e figure 1: the noisy channel model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3357">
<title id=" P01-1050.xml">towards a unified approach to memory and statistical based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>with few exceptions (wu and wong, 1998),<papid> P98-2230 </papid>most smt systems are couched in the noisy channel framework (see figure 1).</prevsent>
<prevsent>in this framework, the source language, lets say english, is assumed to be generated by noisy probabilistic source.1 most of the current statistical mt systems treat this source as sequence of words (brown et al, 1993)<papid> J93-2003 </papid></prevsent>
</prevsection>
<citsent citstr=" P01-1067 ">
(alternative approaches exist, in which the source is taken to be, for example, sequence of aligned templates/phrases (wang, 1998; och et al., 1999) <papid> W99-0604 </papid>or syntactic tree (yamada and knight,2001).)<papid> P01-1067 </papid></citsent>
<aftsection>
<nextsent>in the noisy-channel framework, monolingual corpus is used to derive statistical language model that assigns probability to sequence of words or phrases, thus enabling one to distinguish between sequences of words that are grammatically correct and sequences that are not.
</nextsent>
<nextsent>a sentence-aligned parallel corpus is then used in order to build probabilistic translation model 1for the rest of this paper, we use the terms source and target languages according to the jargon specific to thenoisy-channel framework.
</nextsent>
<nextsent>in this framework, the source language is the language into which the machine translation system translates.
</nextsent>
<nextsent>source p(e) decoder channel p(f | e) observed best argmax p(e | f) = argmax p(f | e) p(e) e figure 1: the noisy channel model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3364">
<title id=" P01-1050.xml">towards a unified approach to memory and statistical based machine translation </title>
<section> the ibm model 4.  </section>
<citcontext>
<prevsection>
<prevsent>for example, the english word no? in figure 2 is word of fertility 2 that is translated into aucun?
</prevsent>
<prevsent>and ne?.
</prevsent>
</prevsection>
<citsent citstr=" P01-1030 ">
a the rest of the factors denote distorsionprobabilities (d), which capture the probability that words change their position when translated from one language into another; the probability of some french words being generated from an invisible english null element (p  ), etc. see (brown et al, 1993)<papid> J93-2003 </papid>or (germann et al, 2001) <papid> P01-1030 </papid>for detailed discussion of this translation model and description of its parameters.</citsent>
<aftsection>
<nextsent>memory companies that specialize in producing high quality human translations of documentation andnews rely often on translation memory tools to increase their productivity (sprung, 2000).
</nextsent>
<nextsent>building high-quality tmem is an expensive process that requires many person-years of work.
</nextsent>
<nextsent>sincewe are not in the fortunate position of having access to an existing tmem, we decided to build one automatically.
</nextsent>
<nextsent>we trained ibm translation model 4 on 500,000 english-french sentence pairs from the hansard corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3370">
<title id=" P01-1050.xml">towards a unified approach to memory and statistical based machine translation </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>the translation systems that use both tmem and the statistical model outperform significantly the two commercial systems.
</prevsent>
<prevsent>the figures in table 6 also reflect the harshness of our evaluationmetric: only 82% of the human translations extracted from the test corpus were considered perfect translation.
</prevsent>
</prevsection>
<citsent citstr=" J99-1003 ">
a few of the errors were genuine, and could be explained by failures of the sentence alignment program that was used to create the corpus (melamed, 1999).<papid> J99-1003 </papid></citsent>
<aftsection>
<nextsent>most of the errors were judged as semantic, reflecting directly the harshness of our evaluation metric.
</nextsent>
<nextsent>the approach to translation described in this paper is quite general.
</nextsent>
<nextsent>it can be applied in conjunction with other statistical translation mod sentence humans greedy with greedy with greedy without commercial commercial length ftmem ptmem tmem system system 6 92 72 70 52 55 59 8 80 53 52 30 38 29 9 84 53 53 37 40 35 10 85 57 60 36 40 37 all(%) 82% 58% 57% 38% 42% 40% table 6: percent of perfect translations produced by various translation systems and algorithms.
</nextsent>
<nextsent>els.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3371">
<title id=" P01-1050.xml">towards a unified approach to memory and statistical based machine translation </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>and it can be applied in conjunction with existing translation memories.
</prevsent>
<prevsent>to do this, one would simply have to train the statistical model onthe translation memory provided as input, determine the viterbi alignments, and enhance the existing translation memory with word-level alignments as produced by the statistical translation model.
</prevsent>
</prevsection>
<citsent citstr=" C00-2172 ">
we suspect that using manually produced tmems can only increase the performance assuch tmems undergo periodic checks for quality assurance.the work that comes closest to using statistical tmem similar to the one we propose here is that of vogel and ney (2000), <papid> C00-2172 </papid>who automatically derive from parallel corpus hierarchical tmem.</citsent>
<aftsection>
<nextsent>the hierarchical tmem consists of set of transducers that encode simple grammar.
</nextsent>
<nextsent>the transducers are automaticallyconstructed: they reflect common patterns of us age at levels of abstractions that are higher than the words.
</nextsent>
<nextsent>vogel and ney (2000) <papid> C00-2172 </papid>do not evaluate their tmem-based system, so it is difficult to empirically compare their approach with ours.</nextsent>
<nextsent>from theoretical perspective, it appears though that the two approaches are complementary: vogel and ney (2000) <papid> C00-2172 </papid>identify abstract patterns of usage and then use them during translation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3376">
<title id=" P01-1050.xml">towards a unified approach to memory and statistical based machine translation </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>if optimal decoding algorithms capable of searching exhaustively the space of all possible translations existed, using tmems in the style presented in this paper would never improve the performance of system.
</prevsent>
<prevsent>our approach works because it biases the decoder to search in sub spaces that are likely to yield translations of high probability, sub spaces which otherwise may not be explored.
</prevsent>
</prevsection>
<citsent citstr=" J99-4005 ">
the bias introduced by tmems isa practical alternative to finding optimal translations, which is np-complete (knight, 1999).<papid> J99-4005 </papid></citsent>
<aftsection>
<nextsent>it is clear that one of the main strengths of thetmem is its ability to encode contextual, long distance dependencies that are incongruous with the parameters learned by current context poor, reductionist channel models.
</nextsent>
<nextsent>unfortunately, the criterion used by the decoder in order to choose between translation produced starting from gloss and one produced starting from tmem is biased in favor of the gloss-based translation.
</nextsent>
<nextsent>it is possible for the decoder to produce perfect translation using phrases from the tmem, and yet, to discard the perfect translation in favor of an incorrect translation of higher probability that was obtained from gloss (or from the tmem).it would be desirable to develop alternative ranking techniques that would permit one to prefer in some instances tmem-based translation, even though that translation is not the best according to the probabilistic channel model.
</nextsent>
<nextsent>the examples in table 7 shows though that this is not trivial: itis not always the case that the translation of high translations does this translation is this is this the translation use tmem translation of highest phrases?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3377">
<title id=" N12-1055.xml">active learning for coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this approach needs manually labeled training data that is expensive to create.
</prevsent>
<prevsent>active learning (al) is technique that can reduce this cost by setting up an interactive training/annotation loop that selects and annotates training examples that are maximally useful for the classifier that is being trained.
</prevsent>
</prevsection>
<citsent citstr=" W07-1516 ">
however, while al has been proven successful for many other nlp tasks, such as part of-speech tagging (ringger et al, 2007), <papid> W07-1516 </papid>parsing (osborne and baldridge, 2004), <papid> N04-1012 </papid>text classification(tong and koller, 2002) and named entity recognition (tomanek et al, 2007), <papid> D07-1051 </papid>al has not been successfully applied to coreference resolution so far.</citsent>
<aftsection>
<nextsent>in this paper, we present novel approach to al for cr based on query-by-committee sampling and bootstrapping and show that it performs better than number of baselines.
</nextsent>
<nextsent>coreference resolution.
</nextsent>
<nextsent>the perhaps most widely used supervised learning approach to cr is the mention-pair model (soon et al, 2001).<papid> J01-4004 </papid></nextsent>
<nextsent>this model classifies links (pairs of two mentions) as corefer ent or dis referent, followed by clustering stage that partitions entities based on the link decisions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3378">
<title id=" N12-1055.xml">active learning for coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this approach needs manually labeled training data that is expensive to create.
</prevsent>
<prevsent>active learning (al) is technique that can reduce this cost by setting up an interactive training/annotation loop that selects and annotates training examples that are maximally useful for the classifier that is being trained.
</prevsent>
</prevsection>
<citsent citstr=" N04-1012 ">
however, while al has been proven successful for many other nlp tasks, such as part of-speech tagging (ringger et al, 2007), <papid> W07-1516 </papid>parsing (osborne and baldridge, 2004), <papid> N04-1012 </papid>text classification(tong and koller, 2002) and named entity recognition (tomanek et al, 2007), <papid> D07-1051 </papid>al has not been successfully applied to coreference resolution so far.</citsent>
<aftsection>
<nextsent>in this paper, we present novel approach to al for cr based on query-by-committee sampling and bootstrapping and show that it performs better than number of baselines.
</nextsent>
<nextsent>coreference resolution.
</nextsent>
<nextsent>the perhaps most widely used supervised learning approach to cr is the mention-pair model (soon et al, 2001).<papid> J01-4004 </papid></nextsent>
<nextsent>this model classifies links (pairs of two mentions) as corefer ent or dis referent, followed by clustering stage that partitions entities based on the link decisions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3379">
<title id=" N12-1055.xml">active learning for coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this approach needs manually labeled training data that is expensive to create.
</prevsent>
<prevsent>active learning (al) is technique that can reduce this cost by setting up an interactive training/annotation loop that selects and annotates training examples that are maximally useful for the classifier that is being trained.
</prevsent>
</prevsection>
<citsent citstr=" D07-1051 ">
however, while al has been proven successful for many other nlp tasks, such as part of-speech tagging (ringger et al, 2007), <papid> W07-1516 </papid>parsing (osborne and baldridge, 2004), <papid> N04-1012 </papid>text classification(tong and koller, 2002) and named entity recognition (tomanek et al, 2007), <papid> D07-1051 </papid>al has not been successfully applied to coreference resolution so far.</citsent>
<aftsection>
<nextsent>in this paper, we present novel approach to al for cr based on query-by-committee sampling and bootstrapping and show that it performs better than number of baselines.
</nextsent>
<nextsent>coreference resolution.
</nextsent>
<nextsent>the perhaps most widely used supervised learning approach to cr is the mention-pair model (soon et al, 2001).<papid> J01-4004 </papid></nextsent>
<nextsent>this model classifies links (pairs of two mentions) as corefer ent or dis referent, followed by clustering stage that partitions entities based on the link decisions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3380">
<title id=" N12-1055.xml">active learning for coreference resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we present novel approach to al for cr based on query-by-committee sampling and bootstrapping and show that it performs better than number of baselines.
</prevsent>
<prevsent>coreference resolution.
</prevsent>
</prevsection>
<citsent citstr=" J01-4004 ">
the perhaps most widely used supervised learning approach to cr is the mention-pair model (soon et al, 2001).<papid> J01-4004 </papid></citsent>
<aftsection>
<nextsent>this model classifies links (pairs of two mentions) as corefer ent or dis referent, followed by clustering stage that partitions entities based on the link decisions.
</nextsent>
<nextsent>our al method is partially based on the class balancing strategy proposed by soon et al (2001).<papid> J01-4004 </papid></nextsent>
<nextsent>while models other than mention-pair have been proposed (culotta et al, 2007), <papid> N07-1011 </papid>none performs clearly better as evidenced by recent shared evaluations such as semeval 2010 (recasens et al, 2010) <papid> S10-1001 </papid>and conll 2011 (pradhan et al, 2011).<papid> W11-1901 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3383">
<title id=" N12-1055.xml">active learning for coreference resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>this model classifies links (pairs of two mentions) as corefer ent or dis referent, followed by clustering stage that partitions entities based on the link decisions.
</prevsent>
<prevsent>our al method is partially based on the class balancing strategy proposed by soon et al (2001).<papid> J01-4004 </papid></prevsent>
</prevsection>
<citsent citstr=" N07-1011 ">
while models other than mention-pair have been proposed (culotta et al, 2007), <papid> N07-1011 </papid>none performs clearly better as evidenced by recent shared evaluations such as semeval 2010 (recasens et al, 2010) <papid> S10-1001 </papid>and conll 2011 (pradhan et al, 2011).<papid> W11-1901 </papid></citsent>
<aftsection>
<nextsent>active learning.
</nextsent>
<nextsent>the only existing publication on al for cr that we are aware of is (gasperin,2009).<papid> W09-1901 </papid></nextsent>
<nextsent>she uses mention-pair model on biomedical corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3384">
<title id=" N12-1055.xml">active learning for coreference resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>this model classifies links (pairs of two mentions) as corefer ent or dis referent, followed by clustering stage that partitions entities based on the link decisions.
</prevsent>
<prevsent>our al method is partially based on the class balancing strategy proposed by soon et al (2001).<papid> J01-4004 </papid></prevsent>
</prevsection>
<citsent citstr=" S10-1001 ">
while models other than mention-pair have been proposed (culotta et al, 2007), <papid> N07-1011 </papid>none performs clearly better as evidenced by recent shared evaluations such as semeval 2010 (recasens et al, 2010) <papid> S10-1001 </papid>and conll 2011 (pradhan et al, 2011).<papid> W11-1901 </papid></citsent>
<aftsection>
<nextsent>active learning.
</nextsent>
<nextsent>the only existing publication on al for cr that we are aware of is (gasperin,2009).<papid> W09-1901 </papid></nextsent>
<nextsent>she uses mention-pair model on biomedical corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3385">
<title id=" N12-1055.xml">active learning for coreference resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>this model classifies links (pairs of two mentions) as corefer ent or dis referent, followed by clustering stage that partitions entities based on the link decisions.
</prevsent>
<prevsent>our al method is partially based on the class balancing strategy proposed by soon et al (2001).<papid> J01-4004 </papid></prevsent>
</prevsection>
<citsent citstr=" W11-1901 ">
while models other than mention-pair have been proposed (culotta et al, 2007), <papid> N07-1011 </papid>none performs clearly better as evidenced by recent shared evaluations such as semeval 2010 (recasens et al, 2010) <papid> S10-1001 </papid>and conll 2011 (pradhan et al, 2011).<papid> W11-1901 </papid></citsent>
<aftsection>
<nextsent>active learning.
</nextsent>
<nextsent>the only existing publication on al for cr that we are aware of is (gasperin,2009).<papid> W09-1901 </papid></nextsent>
<nextsent>she uses mention-pair model on biomedical corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3386">
<title id=" N12-1055.xml">active learning for coreference resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>while models other than mention-pair have been proposed (culotta et al, 2007), <papid> N07-1011 </papid>none performs clearly better as evidenced by recent shared evaluations such as semeval 2010 (recasens et al, 2010) <papid> S10-1001 </papid>and conll 2011 (pradhan et al, 2011).<papid> W11-1901 </papid></prevsent>
<prevsent>active learning.</prevsent>
</prevsection>
<citsent citstr=" W09-1901 ">
the only existing publication on al for cr that we are aware of is (gasperin,2009).<papid> W09-1901 </papid></citsent>
<aftsection>
<nextsent>she uses mention-pair model on biomedical corpus.
</nextsent>
<nextsent>the classifier is naive bayes and the al method uncertainty sampling (lewis and gale,1994).
</nextsent>
<nextsent>the results are negative: al is not better than random sampling.
</nextsent>
<nextsent>in preliminary experiments, we replicated this result for our corpus and our system: uncertainty sampling is not better than random sampling for cr.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3390">
<title id=" N12-1055.xml">active learning for coreference resolution </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>our hypothesis is that, compared to selection of individual links, neighborhood selection yields more balanced sample that covers both positive and negative links for markable.
</prevsent>
<prevsent>at the same time, neighborhood selection retains the benefits of al sampling: difficult (or highly informative) links are selected.
</prevsent>
</prevsection>
<citsent citstr=" P11-1079 ">
we use the mention-pair cr system sucre (kobdani et al, 2011).<papid> P11-1079 </papid></citsent>
<aftsection>
<nextsent>the link classifier is decision tree and the clustering algorithm variant of best-first clustering (ng and cardie, 2002).<papid> P02-1014 </papid></nextsent>
<nextsent>sucre results were competitive in semeval 2010 (recasens et al, 2010).<papid> S10-1001 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3391">
<title id=" N12-1055.xml">active learning for coreference resolution </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>at the same time, neighborhood selection retains the benefits of al sampling: difficult (or highly informative) links are selected.
</prevsent>
<prevsent>we use the mention-pair cr system sucre (kobdani et al, 2011).<papid> P11-1079 </papid></prevsent>
</prevsection>
<citsent citstr=" P02-1014 ">
the link classifier is decision tree and the clustering algorithm variant of best-first clustering (ng and cardie, 2002).<papid> P02-1014 </papid></citsent>
<aftsection>
<nextsent>sucre results were competitive in semeval 2010 (recasens et al, 2010).<papid> S10-1001 </papid></nextsent>
<nextsent>we implemented n-pool bootstrapping and selection methods on top of the al framework of tomanek et al (2007).<papid> D07-1051 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3394">
<title id=" N12-1055.xml">active learning for coreference resolution </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>sucre results were competitive in semeval 2010 (recasens et al, 2010).<papid> S10-1001 </papid></prevsent>
<prevsent>we implemented n-pool bootstrapping and selection methods on top of the al framework of tomanek et al (2007).<papid> D07-1051 </papid></prevsent>
</prevsection>
<citsent citstr=" N06-2015 ">
we use the english part of the semeval-2010 cr task dataset, subset of ontonotes 2.0 (hovy et al, 2006).<papid> N06-2015 </papid></citsent>
<aftsection>
<nextsent>training and test set sizes are about 96,000and 24,000 words.
</nextsent>
<nextsent>since we focus on the coreference resolution subtask, we use the true mention boundaries for the markables.the pool for example selection is created by pairing every mark able with every preceding mark able within window of 100 markables.
</nextsent>
<nextsent>this yields pool of 1.7 million links, of which only 1.5% are labeled as coreferent.
</nextsent>
<nextsent>this drastic class imbalance necessitates our boot strapped class-balancing.we run two baseline experiments for comparison: (i) random selection on the entire pool, with out any class balancing, and (ii) random selection from gold-label-based n-pool.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3395">
<title id=" P00-1022.xml">a computational approach to zero pronouns in spanish </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>finally, we present the results we have obtained with our approach.
</prevsent>
<prevsent>1 background.
</prevsent>
</prevsection>
<citsent citstr=" C96-2137 ">
zero-pronouns have already been studied in other languages, such as japanese, (e.g. nakaiwa and shirai (1996)).<papid> C96-2137 </papid></citsent>
<aftsection>
<nextsent>they have not yet been studied in spanish texts, however.
</nextsent>
<nextsent>among the work done for their resolution in different languages, nevertheless, there are several points that are common for spanish.
</nextsent>
<nextsent>the first point is that they must first be located in the text, and then resolved.
</nextsent>
<nextsent>another common point among, they all employ different kinds of knowledge (e.g. morphologic or syntactic) for their resolution.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3396">
<title id=" P00-1022.xml">a computational approach to zero pronouns in spanish </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the first point is that they must first be located in the text, and then resolved.
</prevsent>
<prevsent>another common point among, they all employ different kinds of knowledge (e.g. morphologic or syntactic) for their resolution.
</prevsent>
</prevsection>
<citsent citstr=" C96-2147 ">
some of these works are based on the centering theory (e.g. okumura and tamura (1996)).<papid> C96-2147 </papid></citsent>
<aftsection>
<nextsent>other works, however, distinguish between restrictions and preferences (e.g. lappin and leass (1994)).<papid> J94-4002 </papid></nextsent>
<nextsent>restrictions tend to be absolute and, therefore, discard any possible antecedents, whereas preferences tend to be relative and require the use of additional criteria, i.e. heuristics that are not always satisfied by all anaphors.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3397">
<title id=" P00-1022.xml">a computational approach to zero pronouns in spanish </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>another common point among, they all employ different kinds of knowledge (e.g. morphologic or syntactic) for their resolution.
</prevsent>
<prevsent>some of these works are based on the centering theory (e.g. okumura and tamura (1996)).<papid> C96-2147 </papid></prevsent>
</prevsection>
<citsent citstr=" J94-4002 ">
other works, however, distinguish between restrictions and preferences (e.g. lappin and leass (1994)).<papid> J94-4002 </papid></citsent>
<aftsection>
<nextsent>restrictions tend to be absolute and, therefore, discard any possible antecedents, whereas preferences tend to be relative and require the use of additional criteria, i.e. heuristics that are not always satisfied by all anaphors.
</nextsent>
<nextsent>our anaphora resolution approach belongs to the second group.
</nextsent>
<nextsent>in computational processing, semantic and domain information is computationally inefficient when compared to other kinds of knowledge.
</nextsent>
<nextsent>consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see mitkov (1998) <papid> P98-2143 </papid>for example).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3398">
<title id=" P00-1022.xml">a computational approach to zero pronouns in spanish </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our anaphora resolution approach belongs to the second group.
</prevsent>
<prevsent>in computational processing, semantic and domain information is computationally inefficient when compared to other kinds of knowledge.
</prevsent>
</prevsection>
<citsent citstr=" P98-2143 ">
consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see mitkov (1998) <papid> P98-2143 </papid>for example).</citsent>
<aftsection>
<nextsent>such approaches, nevertheless, perform notably well.
</nextsent>
<nextsent>lappin and leass (1994) <papid> J94-4002 </papid>describe an algorithm for pronominal anaphora resolution that achieves high rate of correct analyses (85%).</nextsent>
<nextsent>their approach, however, operates almost exclusively on syntactic information.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3402">
<title id=" P00-1022.xml">a computational approach to zero pronouns in spanish </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>lappin and leass (1994) <papid> J94-4002 </papid>describe an algorithm for pronominal anaphora resolution that achieves high rate of correct analyses (85%).</prevsent>
<prevsent>their approach, however, operates almost exclusively on syntactic information.</prevsent>
</prevsection>
<citsent citstr=" C96-1021 ">
more recently, kennedy and boguraev (1996) <papid> C96-1021 </papid>propose an algorithm for anaphora resolution that is actually modified and extended version of the one developed by lappin and leass (1994).<papid> J94-4002 </papid></citsent>
<aftsection>
<nextsent>it works from pos tagger output and achieves an accuracy rate of 75%.
</nextsent>
<nextsent>in order to detect zero-pronouns, the sentences should be divided into clauses since the subject could only appear between the clause constituents.
</nextsent>
<nextsent>after that, noun-phrase (np) or pronoun that agrees in person and number with the clause verb is sought, unless the verb is imperative or impersonal.
</nextsent>
<nextsent>as we are also working on unrestricted textsto which partial parsing is applied, zero pronouns must also be detected when we do not dispose of full syntactic information.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3406">
<title id=" P00-1022.xml">a computational approach to zero pronouns in spanish </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>our system, therefore, improves on this baseline as well.
</prevsent>
<prevsent>lappin and leass (1994) <papid> J94-4002 </papid>has also been implemented in our system and an accuracy of 64% was attained.</prevsent>
</prevsection>
<citsent citstr=" J99-3001 ">
moreover, in order to compare our proposal with centering approach, functional centering by strube and hahn (1999) <papid> J99-3001 </papid>has also been implemented, and an accuracy of 60% was attained.</citsent>
<aftsection>
<nextsent>one of the improvements afforded by our proposal is that statistical information from the text is included with the rest of information (syntactic, morphologic, etc.).
</nextsent>
<nextsent>dagan and itai (1990), <papid> C90-3063 </papid>for example, developed statistical approach for pronominal anaphora, but the information they used was simply the patterns obtained from the previous analysis of the text.</nextsent>
<nextsent>to be able to compare our approach to that of dagan and itai, and to be able to evaluate the importance of this kind of information, our method was applied with statistical information12 only.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3407">
<title id=" P00-1022.xml">a computational approach to zero pronouns in spanish </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>moreover, in order to compare our proposal with centering approach, functional centering by strube and hahn (1999) <papid> J99-3001 </papid>has also been implemented, and an accuracy of 60% was attained.</prevsent>
<prevsent>one of the improvements afforded by our proposal is that statistical information from the text is included with the rest of information (syntactic, morphologic, etc.).</prevsent>
</prevsection>
<citsent citstr=" C90-3063 ">
dagan and itai (1990), <papid> C90-3063 </papid>for example, developed statistical approach for pronominal anaphora, but the information they used was simply the patterns obtained from the previous analysis of the text.</citsent>
<aftsection>
<nextsent>to be able to compare our approach to that of dagan and itai, and to be able to evaluate the importance of this kind of information, our method was applied with statistical information12 only.
</nextsent>
<nextsent>if there is more than one candidate after applying statistical information, preference, and then proximity preference are applied.
</nextsent>
<nextsent>the results obtained were lower than when all the preferences are applied jointly: 50.8%.
</nextsent>
<nextsent>these low results are due to the fact that statistical information has been obtained from the beginning of the text to the pronoun.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3410">
<title id=" P00-1022.xml">a computational approach to zero pronouns in spanish </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>as future project, the authors shall attempt to evaluate the importance of semantic information for zero-pronoun resolutions in unrestricted texts.
</prevsent>
<prevsent>such information will be obtained from lexical tool, (e.g. eurowordnet), which could be consulted automatically.
</prevsent>
</prevsection>
<citsent citstr=" W99-0210 ">
we shall also evaluate our proposal in machine translation application, where we shall test its success rate by its generation of the zero-pronoun in the target language, using the algorithm described in peral et al (1999).<papid> W99-0210 </papid></citsent>
<aftsection>




</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3411">
<title id=" P03-1028.xml">closing the gap learning based information extraction rivaling knowledge engineering methods </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>police sources stated that the bomb attack involving the shining path caused serious damages ...
</prevsent>
<prevsent>figure 1: snippet of muc-4 document to aid in extraction.
</prevsent>
</prevsection>
<citsent citstr=" C02-1025 ">
several benchmark data set shave been used to evaluate ie approaches on semi structured texts (soderland, 1999; ciravegna, 2001; chieu and ng, 2002<papid> C02-1025 </papid>a).</citsent>
<aftsection>
<nextsent>for the task of extracting information from free texts, series of message understanding conferences (muc) provided benchmark datasets for evaluation.
</nextsent>
<nextsent>several subtasks for ie from free texts have been identified.
</nextsent>
<nextsent>the named entity (ne) task extracts person names, organization names, location names,etc. the template element (te) task extracts information centered around an entity, like the acronym, category, and location of company.
</nextsent>
<nextsent>the template relation (tr) task extracts relations between entities.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3429">
<title id=" P03-1028.xml">closing the gap learning based information extraction rivaling knowledge engineering methods </title>
<section> incident: date 19-jan-89.  </section>
<citcontext>
<prevsection>
<prevsent>24 hum tgt: total number -.
</prevsent>
<prevsent>figure 2: example of muc-4 template proach, where manually engineered rules were used for ie.
</prevsent>
</prevsection>
<citsent citstr=" M98-1009 ">
more recently, machine learning approaches have been used for ie from semi-structured texts (califf and mooney, 1999; soderland, 1999; roth and yih, 2001; ciravegna, 2001; chieu and ng, 2002<papid> C02-1025 </papid>a), named entity extraction (chieu and ng, 2002<papid> C02-1025 </papid>b), template element extraction, and template relation extraction (miller et al, 1998).<papid> M98-1009 </papid></citsent>
<aftsection>
<nextsent>these machine learning approaches have been successful for these tasks, achieving accuracy comparable to the knowledge-engineering approach.
</nextsent>
<nextsent>however, for the full-scale st task of generic ie from free texts, the best reported method to date isstill the knowledge-engineering approach.
</nextsent>
<nextsent>forex ample, almost all participating ie systems in muc used the knowledge-engineering approach for the full-scale st task.
</nextsent>
<nextsent>the one notable exception is the work of umass at muc-6 (fisher et al, 1995).<papid> M95-1011 </papid>unfortunately, their learning approach did considerably worse than the best muc-6 systems.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3430">
<title id=" P03-1028.xml">closing the gap learning based information extraction rivaling knowledge engineering methods </title>
<section> incident: date 19-jan-89.  </section>
<citcontext>
<prevsection>
<prevsent>however, for the full-scale st task of generic ie from free texts, the best reported method to date isstill the knowledge-engineering approach.
</prevsent>
<prevsent>forex ample, almost all participating ie systems in muc used the knowledge-engineering approach for the full-scale st task.
</prevsent>
</prevsection>
<citsent citstr=" M95-1011 ">
the one notable exception is the work of umass at muc-6 (fisher et al, 1995).<papid> M95-1011 </papid>unfortunately, their learning approach did considerably worse than the best muc-6 systems.</citsent>
<aftsection>
<nextsent>soderland (1999) and chieu and ng (2002<papid> C02-1025 </papid>a) attempted machine learning approaches for scaled-down version of the st task, where it was assumed that the information needed to fill one template came from one sentence only.</nextsent>
<nextsent>in this paper, we present learning approach to the full-scale st task of extracting information from free texts.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3439">
<title id=" P03-1028.xml">closing the gap learning based information extraction rivaling knowledge engineering methods </title>
<section> the learning approach.  </section>
<citcontext>
<prevsection>
<prevsent>3.1 preprocessing.
</prevsent>
<prevsent>all the preprocessing modules of alice were built with supervised learning techniques.
</prevsent>
</prevsection>
<citsent citstr=" J01-4004 ">
they include sentence segmentation (ratnaparkhi, 1998), part-ofspeech tagging (charniak et al, 1993), named entity recognition (chieu and ng, 2002<papid> C02-1025 </papid>b), full parsing (collins, 1999), and coreference resolution (soon etal., 2001).<papid> J01-4004 </papid></citsent>
<aftsection>
<nextsent>each module performs at or near state of-the-art accuracy, but errors are unavoidable, and later modules in the preprocessing chain have to deal with errors made by the previous modules.
</nextsent>
<nextsent>3.2 features in training and test examples.
</nextsent>
<nextsent>as mentioned earlier, the features of an example are generated based on base noun phrase (denoted as basenp), which is candidate for filling template slot.
</nextsent>
<nextsent>while most strings that fill string slot are base noun phrases, this is not always the case.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3440">
<title id=" P03-1028.xml">closing the gap learning based information extraction rivaling knowledge engineering methods </title>
<section> the learning approach.  </section>
<citcontext>
<prevsection>
<prevsent>the features of an example are derived from thetreebank-style parse tree output by an implementation of collins  parser (collins, 1999).
</prevsent>
<prevsent>in particular, we traverse the full parse tree to determine the verbs, agents, patients, and indirect objects related to noun phrase candidate
</prevsent>
</prevsection>
<citsent citstr=" P00-1065 ">
. while machine learning approach is used in (gildea and jurafsky, 2000) <papid> P00-1065 </papid>to determine general semantic roles, we used simple rule-based traversal of the parse tree instead, which could also reliably determine the generic agent and patient role of sentence, and this suffices for our current purpose.</citsent>
<aftsection>
<nextsent>specifically, forgiven noun phrase candidate
</nextsent>
<nextsent>, the following groups of features are used: verb of agent np (vag) when
</nextsent>
<nextsent>is an agent in sentence, each of its associated verbs is vag feature.
</nextsent>
<nextsent>for example, in sentence (1) of figure 5, if
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3453">
<title id=" P03-1028.xml">closing the gap learning based information extraction rivaling knowledge engineering methods </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>although the best muc-4 participating systems, ge/ge-cmu, still outperform alice-me, it must be noted that forge, 10 1/2 person months?
</prevsent>
<prevsent>were spent on muc-4 using the ge nltoolset , after spending 15 person months?
</prevsent>
</prevsection>
<citsent citstr=" M92-1008 ">
on muc-3 (rau et al., 1992).<papid> M92-1008 </papid></citsent>
<aftsection>
<nextsent>with learning approach, ie systems are more portable across domains.
</nextsent>
<nextsent>not all occurrences of string in document that match slot fill of template provide good positive training examples.
</nextsent>
<nextsent>for example, in the same document, there might be the following sentences the mnr reports the kidnapping of oquelicolindres...?, followed by oqueli colindres arrived in guatemala on 11 jan uary?.
</nextsent>
<nextsent>in this case, only the first occurrence of oqueli colindres should be used as positive example for the human target slot.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3454">
<title id=" N12-1065.xml">identifying comparable corpora using lda </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>comparable texts need to be on the same topic.construction of multilingual topic models usually requires either parallel data or some number of aligned documents across multiple languages.
</prevsent>
<prevsent>zhao and xing (2007) create bilingual topic models from (at least 25%) of parallel data.
</prevsent>
</prevsection>
<citsent citstr=" D09-1092 ">
mimno et al, (2009) <papid> D09-1092 </papid>start from tuples of equivalent documents to build models, and then the same distribution over topics holds in both source and target languages.</citsent>
<aftsection>
<nextsent>while zhao and xing (2007) used their topic models for word alignment from comparable corpora (combined with underlying parallel data), multilingual topic models are usually applied to data to automatically detect word translations based on parallel data, e.g., vulic?
</nextsent>
<nextsent>et al, (2011) exploit shared language independent topic distribution to measure the similarity between topics pertaining to words.
</nextsent>
<nextsent>the novelty of our work is the transformation of source language topic model rather than the creation of language independent model from parallel data.transforming the source language model to the target language allows the classification of the target language documents to source language topics.
</nextsent>
<nextsent>the translated model is applied to two document collections to demonstrate its ability to detect comparable 558 corpora.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3455">
<title id=" N12-1065.xml">identifying comparable corpora using lda </title>
<section> tools.  </section>
<citcontext>
<prevsection>
<prevsent>section 5 draws our conclusions and indicates avenues for future work.
</prevsent>
<prevsent>2.1 named entity recognition.
</prevsent>
</prevsection>
<citsent citstr=" P05-1045 ">
the stanford named entity recognition (ner) soft ware1 (finkel et al, 2005) <papid> P05-1045 </papid>is an implementation of linear chain conditional random field (crf) sequence models, which includes three class (per son, organization, location and other) named entity recognizer for english.</citsent>
<aftsection>
<nextsent>2.2 topic detection.
</nextsent>
<nextsent>lda (blei et al, 2003) is generative probabilistic model where documents are viewed as mixtures over underlying topics, and each topic is distribution over words.
</nextsent>
<nextsent>both the document-topic and the topic word distributions are assumed to have dirichlet prior.
</nextsent>
<nextsent>given set of documents and number of topics, the model returns i, the topic distribution for each document i, and ik, the word distribution for topic k. we employ the publicly available implementation of lda, jgibblda2 (phan et al, 2008), which has two main execution methods: parameter estimation (model building) and inference for newdata (classification of new document).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3456">
<title id=" N12-1065.xml">identifying comparable corpora using lda </title>
<section> tools.  </section>
<citcontext>
<prevsection>
<prevsent>to provide quick searching access to the large text collections, we utilize the high-performance search engine library lucene.4 the stemmed and stop listed documents are stored along with the frequency of occurrence of each word within document.
</prevsent>
<prevsent>2.4 lemmatization / stemming.
</prevsent>
</prevsection>
<citsent citstr=" P06-4020 ">
english text is lemmatized using the lemmatizer available within rasp5 (briscoe et al, 2006).<papid> P06-4020 </papid></citsent>
<aftsection>
<nextsent>stemming is provided for all the non-english languages included in our work within lucene.
</nextsent>
<nextsent>3.1 cross language ner.
</nextsent>
<nextsent>nes extracted from the english text collections are automatically translated into the target languages using the bing translation api6 yielding single translation, which is retained.
</nextsent>
<nextsent>the stemmed, translated version of each ne in the source text is sought in the indexed form of the target language document collection, and the frequency of occurrence of the ne is returned.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3457">
<title id=" P02-1052.xml">using similarity scoring to improve the bilingual dictionary for sub sentential alignment </title>
<section> introduction and related work.  </section>
<citcontext>
<prevsection>
<prevsent>other related work falls in the category of word alignment, where much research has been done.
</prevsent>
<prevsent>anumber of algorithms have been proposed and evaluated for the task.
</prevsent>
</prevsection>
<citsent citstr=" J00-2004 ">
as melamed (2000) <papid> J00-2004 </papid>points out,most of these algorithms are based on word cooccurrences in sentence-aligned bilingual data.</citsent>
<aftsection>
<nextsent>a source language word
</nextsent>
<nextsent>and target language word
</nextsent>
<nextsent>aresaid to cooccur if
</nextsent>
<nextsent>occurs in source language sentence and
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3458">
<title id=" P02-1052.xml">using similarity scoring to improve the bilingual dictionary for sub sentential alignment </title>
<section> introduction and related work.  </section>
<citcontext>
<prevsection>
<prevsent>aside from the classic statistical approach of computational linguistics (acl), philadelphia, july 2002, pp.
</prevsent>
<prevsent>409-416.
</prevsent>
</prevsection>
<citsent citstr=" J90-2002 ">
proceedings of the 40th annual meeting of the association for (brown et al, 1990; <papid> J90-2002 </papid>brown et al, 1993), <papid> J93-2003 </papid>number of other algorithms have been developed.</citsent>
<aftsection>
<nextsent>ahrenberg et al (1998) <papid> P98-1004 </papid>use morphological information onboth the source and the target languages.</nextsent>
<nextsent>this information serves to build equivalence classes of words based on suffices.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3459">
<title id=" P02-1052.xml">using similarity scoring to improve the bilingual dictionary for sub sentential alignment </title>
<section> introduction and related work.  </section>
<citcontext>
<prevsection>
<prevsent>aside from the classic statistical approach of computational linguistics (acl), philadelphia, july 2002, pp.
</prevsent>
<prevsent>409-416.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
proceedings of the 40th annual meeting of the association for (brown et al, 1990; <papid> J90-2002 </papid>brown et al, 1993), <papid> J93-2003 </papid>number of other algorithms have been developed.</citsent>
<aftsection>
<nextsent>ahrenberg et al (1998) <papid> P98-1004 </papid>use morphological information onboth the source and the target languages.</nextsent>
<nextsent>this information serves to build equivalence classes of words based on suffices.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3460">
<title id=" P02-1052.xml">using similarity scoring to improve the bilingual dictionary for sub sentential alignment </title>
<section> introduction and related work.  </section>
<citcontext>
<prevsection>
<prevsent>409-416.
</prevsent>
<prevsent>proceedings of the 40th annual meeting of the association for (brown et al, 1990; <papid> J90-2002 </papid>brown et al, 1993), <papid> J93-2003 </papid>number of other algorithms have been developed.</prevsent>
</prevsection>
<citsent citstr=" P98-1004 ">
ahrenberg et al (1998) <papid> P98-1004 </papid>use morphological information onboth the source and the target languages.</citsent>
<aftsection>
<nextsent>this information serves to build equivalence classes of words based on suffices.
</nextsent>
<nextsent>a different approach was proposed by gaussier (1998).<papid> P98-1074 </papid></nextsent>
<nextsent>this approach models word alignments as flow networks.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3461">
<title id=" P02-1052.xml">using similarity scoring to improve the bilingual dictionary for sub sentential alignment </title>
<section> introduction and related work.  </section>
<citcontext>
<prevsection>
<prevsent>ahrenberg et al (1998) <papid> P98-1004 </papid>use morphological information onboth the source and the target languages.</prevsent>
<prevsent>this information serves to build equivalence classes of words based on suffices.</prevsent>
</prevsection>
<citsent citstr=" P98-1074 ">
a different approach was proposed by gaussier (1998).<papid> P98-1074 </papid></citsent>
<aftsection>
<nextsent>this approach models word alignments as flow networks.
</nextsent>
<nextsent>determining theword alignments then amounts to solving the network, for which there are known algorithms.
</nextsent>
<nextsent>brown(1998) describes an algorithm that starts with an chors?, words that are unambiguous translations ofeach other.
</nextsent>
<nextsent>from these anchors, alignments are expanded in both directions, so that entire segments can be aligned.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3462">
<title id=" P02-1052.xml">using similarity scoring to improve the bilingual dictionary for sub sentential alignment </title>
<section> introduction and related work.  </section>
<citcontext>
<prevsection>
<prevsent>the algorithm that this work was based on is the competitive linking algorithm.
</prevsent>
<prevsent>we used it to test our improved dictionary.
</prevsent>
</prevsection>
<citsent citstr=" P97-1063 ">
competitive linking was described by melamed (1997; <papid> P97-1063 </papid>1998; 2000).</citsent>
<aftsection>
<nextsent>it computes all possible word alignments in parallel data, and ranks them by their cooccurrence or by similar score.
</nextsent>
<nextsent>then links between words (i.e. alignments) are chosen from the top of the list until no more links can be assigned.
</nextsent>
<nextsent>there is limit on the number oflinks word can have.
</nextsent>
<nextsent>in its basic form the competitive linking algorithm (melamed, 1997) <papid> P97-1063 </papid>allows foronly up to one link per word.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3464">
<title id=" P02-1054.xml">is it the right answer exploiting web redundancy for answer validation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the simplicity and the efficiency of this approach make it suitable tobe used as module in question answering systems.
</prevsent>
<prevsent>open domain question-answering (qa) systems search for answers to natural language question either on the web or in local document collection.
</prevsent>
</prevsection>
<citsent citstr=" W01-1205 ">
different techniques, varying from surface patterns (subbotin and sub botin, 2001) to deep semantic analysis (zajac, 2001), <papid> W01-1205 </papid>are used to extract the text fragments containing candidate answers.</citsent>
<aftsection>
<nextsent>several systems apply answer validation techniques with thegoal of filtering out improper candidates by checking how adequate candidate answer is with respect to given question.
</nextsent>
<nextsent>these approaches relyon discovering semantic relations between the question and the answer.
</nextsent>
<nextsent>as an example, (harabagiu and maiorano, 1999) describes answer validation as an abductive inference process, where an answer is valid with respect to question if an explanation for it, based on background knowledge, can be found.although theoretically well motivated, the use of semantic techniques on open domain tasks is quite expensive both in terms of the involved linguistic resources and in terms of computational complexity, thus motivating research on alternative solutions to the problem.
</nextsent>
<nextsent>this paper presents novel approach to answer validation based on the intuition that the amount of implicit knowledge which connects an answer to aquestion can be quantitatively estimated by exploiting the redundancy of web information.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3465">
<title id=" P02-1054.xml">is it the right answer exploiting web redundancy for answer validation </title>
<section> i live in the nations capital, washington </section>
<citcontext>
<prevsection>
<prevsent>  &amp;65  qsp,asp %$  # qsp,asp   # qsp 879 # asp  pmi(qsp,asp) is used as clue to the internal coherence of the question-answer validation patternqap.
</prevsent>
<prevsent>substituting the probabilities in the pmi formula with the previously introduced web statistics, we obtain:  qsp 1234 asp   qsp 879! asp  7 &amp;
</prevsent>
</prevsection>
<citsent citstr=" J93-1003 ">
maximal likelihood ratio (mlhr) is also used for word co-occurrence mining (dunning, 1993).<papid> J93-1003 </papid></citsent>
<aftsection>
<nextsent>we decided to check mlhr for answer validation because it is supposed to outperform pmi in case of sparse data, situation that may happen in case of questions with complex patterns that return small number of hits.
</nextsent>
<nextsent>&amp;6: ; =    fffifl ?$a@cb%dfehgci ij$ : f lknmolpqm  : f lkrslptr  : f m,lknmolpqm  : f r.okr,lptr  where : f oktop 8$u vwc@x y[zv $ vl\ y[\ , $ v] y.]
</nextsent>
<nextsent>#$ v^\_tv] y[\_!y,] m $`   fffifl  , r $`   @cff   pqm $0!ff   , par $0!@cff   here !   @cff  ! is the number of appearances of qsp when asp is not present and it is calculated as  fl *@(  b1234cff   . similarly, !@cff   is the number of web pages where asp does not appear and it is calculated as &amp;
</nextsent>
<nextsent>@cfffifl . corrected conditional probability (ccp) in contrast with pmi and mlhr, ccp is not symmetric (e.g. generally ded #ffi   ff  gf$ ded  #ff    ! ).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3466">
<title id=" P02-1054.xml">is it the right answer exploiting web redundancy for answer validation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>a common feature of these approaches is the use of the web to introduce data redundancy for more reliable answer extraction from local text collections.
</prevsent>
<prevsent>(radev et al, 2001) suggests probabilistic algorithm that learns the best query paraphrase of question searching theweb.
</prevsent>
</prevsection>
<citsent citstr=" W01-1204 ">
other approaches suggest training question answering system on the web (mann, 2001).<papid> W01-1204 </papid>the web-mining algorithm presented in this paper is similar to the pmi-ir (pointwise mutual information - information retrieval) described in (turney, 2001).</citsent>
<aftsection>
<nextsent>turney uses pmi and web retrieval to decide which word in list of candidates is thebest synonym with respect to target word.
</nextsent>
<nextsent>however, the answer validity task poses different peculiarities.
</nextsent>
<nextsent>we search how the occurrence of the question words influence the appearance of answerwords.
</nextsent>
<nextsent>therefore, we introduce additional linguistic techniques for pattern and query formulation, such as keyword extraction, answer type extraction, named entities recognition and pattern relaxation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3467">
<title id=" P04-1001.xml">optimization in multimodal interpretation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>multimodal systems provide natural and effective way for users to interact with computers through multiple modalities such as speech, gesture, and gaze (oviatt 1996).
</prevsent>
<prevsent>since the first appearance of put-that-there?
</prevsent>
</prevsection>
<citsent citstr=" P99-1024 ">
system (bolt 1980), variety of multimodal systems have emerged, from early systems that combine speech, pointing (neal et al, 1991), and gaze (koons et al 1993), to systems that integrate speech with pen inputs (e.g., drawn graphics) (cohen et al, 1996; wahlster 1998; wu et al, 1999), and systems that engage users in intelligent conversation (cassell et al., 1999; stent et al, 1999; <papid> P99-1024 </papid>gustafson et al, 2000; chai et al, 2002; johnston et al, 2002).<papid> P02-1048 </papid></citsent>
<aftsection>
<nextsent>one important aspect of building multimodal systems is multimodal interpretation, which is process that identifies the meanings of user inputs.
</nextsent>
<nextsent>in multimodal conversation, the way users communicate with system depends on the available interaction channels and the situated context (e.g., conversation focus, visual feedback).
</nextsent>
<nextsent>these dependencies form rich set of constraints from various aspects (e.g., semantic, temporal, and contextual).
</nextsent>
<nextsent>a correct interpretation can only be attained by simultaneously considering these constraints.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3468">
<title id=" P04-1001.xml">optimization in multimodal interpretation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>multimodal systems provide natural and effective way for users to interact with computers through multiple modalities such as speech, gesture, and gaze (oviatt 1996).
</prevsent>
<prevsent>since the first appearance of put-that-there?
</prevsent>
</prevsection>
<citsent citstr=" P02-1048 ">
system (bolt 1980), variety of multimodal systems have emerged, from early systems that combine speech, pointing (neal et al, 1991), and gaze (koons et al 1993), to systems that integrate speech with pen inputs (e.g., drawn graphics) (cohen et al, 1996; wahlster 1998; wu et al, 1999), and systems that engage users in intelligent conversation (cassell et al., 1999; stent et al, 1999; <papid> P99-1024 </papid>gustafson et al, 2000; chai et al, 2002; johnston et al, 2002).<papid> P02-1048 </papid></citsent>
<aftsection>
<nextsent>one important aspect of building multimodal systems is multimodal interpretation, which is process that identifies the meanings of user inputs.
</nextsent>
<nextsent>in multimodal conversation, the way users communicate with system depends on the available interaction channels and the situated context (e.g., conversation focus, visual feedback).
</nextsent>
<nextsent>these dependencies form rich set of constraints from various aspects (e.g., semantic, temporal, and contextual).
</nextsent>
<nextsent>a correct interpretation can only be attained by simultaneously considering these constraints.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3469">
<title id=" P04-1001.xml">optimization in multimodal interpretation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a correct interpretation can only be attained by simultaneously considering these constraints.
</prevsent>
<prevsent>in this process, two issues are important: first, mechanism to combine information from various sources to form an overall interpretation given set of constraints; and second, mechanism that achieves the best interpretation among all the possible alternatives given set of constraints.
</prevsent>
</prevsection>
<citsent citstr=" P98-1102 ">
the first issue focuses on the fusion aspect, which has been well studied in earlier work, for example, through unification based approaches (johnston 1998) <papid> P98-1102 </papid>or finite state approaches (johnston and bangalore, 2000).<papid> C00-1054 </papid></citsent>
<aftsection>
<nextsent>this paper focuses on the second issue of optimization.
</nextsent>
<nextsent>as in natural language interpretation, there is strong evidence that competition and ranking of constraints is important to achieve an optimal interpretation for multimodal language processing.
</nextsent>
<nextsent>we have developed graph-based optimization approach for interpreting multimodal references.
</nextsent>
<nextsent>this approach achieves an optimal interpretation by simultaneously applying semantic, temporal, and contextual constraints.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3470">
<title id=" P04-1001.xml">optimization in multimodal interpretation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a correct interpretation can only be attained by simultaneously considering these constraints.
</prevsent>
<prevsent>in this process, two issues are important: first, mechanism to combine information from various sources to form an overall interpretation given set of constraints; and second, mechanism that achieves the best interpretation among all the possible alternatives given set of constraints.
</prevsent>
</prevsection>
<citsent citstr=" C00-1054 ">
the first issue focuses on the fusion aspect, which has been well studied in earlier work, for example, through unification based approaches (johnston 1998) <papid> P98-1102 </papid>or finite state approaches (johnston and bangalore, 2000).<papid> C00-1054 </papid></citsent>
<aftsection>
<nextsent>this paper focuses on the second issue of optimization.
</nextsent>
<nextsent>as in natural language interpretation, there is strong evidence that competition and ranking of constraints is important to achieve an optimal interpretation for multimodal language processing.
</nextsent>
<nextsent>we have developed graph-based optimization approach for interpreting multimodal references.
</nextsent>
<nextsent>this approach achieves an optimal interpretation by simultaneously applying semantic, temporal, and contextual constraints.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3472">
<title id=" P04-1001.xml">optimization in multimodal interpretation </title>
<section> a graph-based optimization approach   </section>
<citcontext>
<prevsection>
<prevsent>furthermore, the salient objects from the prior conversation are also included in the referent graph since they could also be the potential referents (e.g., the rightmost dashed rectangle in figure 32).
</prevsent>
<prevsent>to create these graphs, we apply grammar based natural language parser to process speech inputs and gesture recognition component to process gestures.
</prevsent>
</prevsection>
<citsent citstr=" N04-4011 ">
the details are described in (chai et al 2004<papid> N04-4011 </papid>a).</citsent>
<aftsection>
<nextsent>2 each node from the conversation context is linked to every.
</nextsent>
<nextsent>node corresponding to the first pointing and the second pointing.
</nextsent>
<nextsent>graph-matching process given these graph representations, interpreting multimodal references becomes graph-matching problem.
</nextsent>
<nextsent>the goal is to find the best match between referring graph (gs) and referent graph (gr).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3474">
<title id=" P04-1001.xml">optimization in multimodal interpretation </title>
<section> a graph-based optimization approach   </section>
<citcontext>
<prevsection>
<prevsent>in optimality theory, grammar consists of set of well-formed constraints.
</prevsent>
<prevsent>these constraints are applied simultaneously to identify linguistic structures.
</prevsent>
</prevsection>
<citsent citstr=" P97-1040 ">
optimality theory does not restrict the content of the constraints (eisner 1997).<papid> P97-1040 </papid></citsent>
<aftsection>
<nextsent>an innovation of optimality theory is the conception of these constraints as soft, which means viola ble and conflicting.
</nextsent>
<nextsent>the interpretation that arises for an utterance within certain context maximizes the degree of constraint satisfaction and is consequently the best alternative (hence, optimal interpretation) among the set of possible interpretations.
</nextsent>
<nextsent>the key principles or components of optimality theory can be summarized as the following three components (blutner 1998): 1) given set of input, generator creates set of possible outputs for each input.
</nextsent>
<nextsent>2) from the set of candidate output, evaluator selects the optimal output for that input.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3477">
<title id=" P03-2021.xml">ineats interactive multi document summarization </title>
<section> neats.  </section>
<citcontext>
<prevsection>
<prevsent>the ineats syst emis built on top of the neats multi-document summarization system.
</prevsent>
<prevsent>in the following section we givea brief overview of the neats system and in section 3 describe the interactive version.
</prevsent>
</prevsection>
<citsent citstr=" P02-1058 ">
neats (lin and hovy, 2002) <papid> P02-1058 </papid>is an extraction based multi-document summarization system.</citsent>
<aftsection>
<nextsent>it is among the top two performers in duc 2001 and2002 (over, 2001).
</nextsent>
<nextsent>it consists of three main com ponents: content selection the goal of content selection is to identify important concepts mentioned in document collection.
</nextsent>
<nextsent>neats computes the likelihood ratio (dunning, 1993) <papid> J93-1003 </papid>to identify key concepts in unigrams, bigrams, and trigrams and clusters these concepts in order to identify major sub topics within the main topic.</nextsent>
<nextsent>each sentence in the document set is then ranked, using the key concept structures.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3478">
<title id=" P03-2021.xml">ineats interactive multi document summarization </title>
<section> neats.  </section>
<citcontext>
<prevsection>
<prevsent>it is among the top two performers in duc 2001 and2002 (over, 2001).
</prevsent>
<prevsent>it consists of three main com ponents: content selection the goal of content selection is to identify important concepts mentioned in document collection.
</prevsent>
</prevsection>
<citsent citstr=" J93-1003 ">
neats computes the likelihood ratio (dunning, 1993) <papid> J93-1003 </papid>to identify key concepts in unigrams, bigrams, and trigrams and clusters these concepts in order to identify major sub topics within the main topic.</citsent>
<aftsection>
<nextsent>each sentence in the document set is then ranked, using the key concept structures.
</nextsent>
<nextsent>these n-gram key concepts are called topic signatures.content filtering neats uses three different filters: sentence position, stigma words, andre dundancy filter.
</nextsent>
<nextsent>sentence position has been used as good important content filter since the late 60s (edmundson, 1969).
</nextsent>
<nextsent>neats applies simple sentence filter that only retains the lead sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3479">
<title id=" P03-2021.xml">ineats interactive multi document summarization </title>
<section> interactive summarization.  </section>
<citcontext>
<prevsection>
<prevsent>3.3 alternative summaries.
</prevsent>
<prevsent>the bottom part of the summary panel is occupied by the map-based visualization.
</prevsent>
</prevsection>
<citsent citstr=" A97-1029 ">
we use bbns identifinder (bikel et al, 1997) <papid> A97-1029 </papid>to detect the names of geographic locations in the document set.</citsent>
<aftsection>
<nextsent>we then select the most frequently used location name sand place them on world map.
</nextsent>
<nextsent>each location is identified by black dot followed by frequency chart and the location name.
</nextsent>
<nextsent>the frequency chart is bar chart where each bar corresponds to document.
</nextsent>
<nextsent>the baris painted using the document color and the length of the baris proportional to the number of times the location name is used in the document.the document set we used in our example describes the progress of the hurricane andrew and its effect on florida, louisiana, and texas.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3480">
<title id=" P03-1014.xml">integrated shallow and deep parsing topp meets hpsg </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one of the strongpoints of deep processing (dnlp) technology such as hpsg or lfg parsers certainly lies with the high degree of precision as well as detailed linguistic analysis these systems are able to deliver.
</prevsent>
<prevsent>although considerable progress has been made in the area of processing speed, dnlp systems still cannot rival shallow and medium depth technologies in terms of throughput and robustness.
</prevsent>
</prevsection>
<citsent citstr=" P01-1034 ">
as net effect, the impact of deep parsing technology on application-oriented nlp is still fairly limited.with the advent of xml-based hybrid shallow deep architectures as presented in (grover and lascarides, 2001; <papid> P01-1034 </papid>crysmann et al, 2002; <papid> P02-1056 </papid>uszkoreit, 2002) it has become possible to integrate the added value of deep processing with the performance and robustness of shallow processing.</citsent>
<aftsection>
<nextsent>so far, integration has largely focused on the lexical level, to improve upon the most urgent needs in increasing the robustness and coverage of deep parsing systems, namely 1this work was in part supported by bmbf grant to the dfki project white board (fkz 01 iw 002).
</nextsent>
<nextsent>lexical coverage.
</nextsent>
<nextsent>while integration in (grover and lascarides, 2001) <papid> P01-1034 </papid>was still restricted to morphological and pos information, (crysmann et al, 2002) <papid> P02-1056 </papid>extended shallow-deep integration at the lexical level to lexico-semantic information, and named entity expressions, including multiword expressions.</nextsent>
<nextsent>(crysmann et al, 2002) <papid> P02-1056 </papid>assume vertical, pipeline?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3481">
<title id=" P03-1014.xml">integrated shallow and deep parsing topp meets hpsg </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one of the strongpoints of deep processing (dnlp) technology such as hpsg or lfg parsers certainly lies with the high degree of precision as well as detailed linguistic analysis these systems are able to deliver.
</prevsent>
<prevsent>although considerable progress has been made in the area of processing speed, dnlp systems still cannot rival shallow and medium depth technologies in terms of throughput and robustness.
</prevsent>
</prevsection>
<citsent citstr=" P02-1056 ">
as net effect, the impact of deep parsing technology on application-oriented nlp is still fairly limited.with the advent of xml-based hybrid shallow deep architectures as presented in (grover and lascarides, 2001; <papid> P01-1034 </papid>crysmann et al, 2002; <papid> P02-1056 </papid>uszkoreit, 2002) it has become possible to integrate the added value of deep processing with the performance and robustness of shallow processing.</citsent>
<aftsection>
<nextsent>so far, integration has largely focused on the lexical level, to improve upon the most urgent needs in increasing the robustness and coverage of deep parsing systems, namely 1this work was in part supported by bmbf grant to the dfki project white board (fkz 01 iw 002).
</nextsent>
<nextsent>lexical coverage.
</nextsent>
<nextsent>while integration in (grover and lascarides, 2001) <papid> P01-1034 </papid>was still restricted to morphological and pos information, (crysmann et al, 2002) <papid> P02-1056 </papid>extended shallow-deep integration at the lexical level to lexico-semantic information, and named entity expressions, including multiword expressions.</nextsent>
<nextsent>(crysmann et al, 2002) <papid> P02-1056 </papid>assume vertical, pipeline?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3489">
<title id=" P03-1014.xml">integrated shallow and deep parsing topp meets hpsg </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>within hybrid shallow-deep platform one can take advantage of partial knowledge provided by shallow parsers to pre-structure the search space of the deep parser.
</prevsent>
<prevsent>in this paper, we will thus complement the efforts made on the lexical side by integration at the phrasal level.we will show that this may lead to considerable performance increase for the dnlp component.
</prevsent>
</prevsection>
<citsent citstr=" C02-1093 ">
more specifically, we combine probabilistic topological field parser for german (becker and frank, 2002) <papid> C02-1093 </papid>with the hpsg parser of (callmeier, 2000).</citsent>
<aftsection>
<nextsent>the hpsg grammar used is the one originally developed by (muller and kasper, 2000), with significant performance enhancements by b. crysmann.
</nextsent>
<nextsent>in section 2 we discuss the mapping problem involved with syntactic integration of shallow and deep analyses and motivate our choice to combine the hpsg system with topological parser.
</nextsent>
<nextsent>section 3 outlines our basic approach towards syntacticshallow-deep integration.
</nextsent>
<nextsent>section 4 introduces various confidence measures, to be used for fine-tuning of phrasal integration.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3493">
<title id=" P03-1014.xml">integrated shallow and deep parsing topp meets hpsg </title>
<section> topp meets hpsg.  </section>
<citcontext>
<prevsection>
<prevsent>in figure 1, e.g., the span from the verb hatte?
</prevsent>
<prevsent>to the end of the sentence forms constituent in the hpsg analysis,while in the topological tree the same span is dominated by sequence of categories: lk, mf, rk, nf.yet, due to its linguistic underpinning, the topo logical tree can be used to systematically predict key constituents in the corresponding target?
</prevsent>
</prevsection>
<citsent citstr=" E03-1052 ">
hpsg 2see section 6 for comparison to recent work on integrated chunk-based and dependency parsing in (daum et al, 2003).<papid> E03-1052 </papid></citsent>
<aftsection>
<nextsent>3as, for example, in (duchier and debusmann, 2001).<papid> P01-1024 </papid></nextsent>
<nextsent>analysis.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3494">
<title id=" P03-1014.xml">integrated shallow and deep parsing topp meets hpsg </title>
<section> topp meets hpsg.  </section>
<citcontext>
<prevsection>
<prevsent>to the end of the sentence forms constituent in the hpsg analysis,while in the topological tree the same span is dominated by sequence of categories: lk, mf, rk, nf.yet, due to its linguistic underpinning, the topo logical tree can be used to systematically predict key constituents in the corresponding target?
</prevsent>
<prevsent>hpsg 2see section 6 for comparison to recent work on integrated chunk-based and dependency parsing in (daum et al, 2003).<papid> E03-1052 </papid></prevsent>
</prevsection>
<citsent citstr=" P01-1024 ">
3as, for example, in (duchier and debusmann, 2001).<papid> P01-1024 </papid></citsent>
<aftsection>
<nextsent>analysis.
</nextsent>
<nextsent>we know, for example, that the span from the fronted verb (lk-vfin) till the end of its clause cl-v2 corresponds to an hpsg phrase.
</nextsent>
<nextsent>also, the first position that follows this verb, here the leftmostdaughter of mf, demarcates the left edge of the traditional vp.
</nextsent>
<nextsent>spans of the vorfeld vf and clause categories cl exactly match hpsg constituents.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3499">
<title id=" P03-1014.xml">integrated shallow and deep parsing topp meets hpsg </title>
<section> topp meets hpsg.  </section>
<citcontext>
<prevsection>
<prevsent>3.2 annotation-based integration.
</prevsent>
<prevsent>in the annotation-based architecture of (crysmann et al, 2002), <papid> P02-1056 </papid>xml-encoded analysis results of all components are stored in multi-layer xml chart.</prevsent>
</prevsection>
<citsent citstr=" W03-0802 ">
the architecture employed in this paper improves on (crysmann et al, 2002) <papid> P02-1056 </papid>by providing central white board annotation transformer (what) that supports flexible and powerful access to and transformation of xml annotation based on standardxslt engines6 (see (schafer, 2003) <papid> W03-0802 </papid>for more details on what).</citsent>
<aftsection>
<nextsent>shallow-deep integration is thus fully annotation driven.
</nextsent>
<nextsent>complex xslt transformations are applied to the various analyses, in order to 4we currently extract 34 different bracket types.5we currently assume identical token isation, but could accommodate for distinct token isation regimes, using map tables.
</nextsent>
<nextsent>6advantages we see in the xslt approach are (i) minimised programming effort in the target implementation language forxml access, (ii) reuse of transformation rules in multiple modules, (iii) fast integration of new xml-producing components.
</nextsent>
<nextsent>extractor combine independent knowledge sources, including xpath access to information stored in shallow annotation, complex xslt transformations to the output of the topological parser, and extraction of bracket constraints.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3501">
<title id=" P03-1014.xml">integrated shallow and deep parsing topp meets hpsg </title>
<section> confidence measures.  </section>
<citcontext>
<prevsection>
<prevsent>4.2 conf.
</prevsent>
<prevsent>ent : entropy of parse distribution while precision over bracket types is static measure that is independent from the structural complexity of particular sentence, tree entropy is defined as the entropy over the probability distribution of theset of parsed trees forgiven sentence.
</prevsent>
</prevsection>
<citsent citstr=" W00-1306 ">
it is useful measure to assess how certain the parser is about the best analysis, e.g. to measure the training utility value of data point in the context of sample selection (hwa, 2000).<papid> W00-1306 </papid></citsent>
<aftsection>
<nextsent>we thus employ tree entropy as a9further measures are conceivable: we could extract brackets from some n-best topological parses, associating them with weights, using methods similar to (carroll and briscoe, 2002).<papid> C02-1013 </papid></nextsent>
<nextsent>10 20 30 40 50 60 70 80 90 00.20.40.60.81 in % normalized entropy precision recall coverage figure 3: effect of different thresholds of normalized entropy on precision, recall, and coverage confidence measure for the quality of the best topo logical parse, and the extracted bracket constraints.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3502">
<title id=" P03-1014.xml">integrated shallow and deep parsing topp meets hpsg </title>
<section> confidence measures.  </section>
<citcontext>
<prevsection>
<prevsent>ent : entropy of parse distribution while precision over bracket types is static measure that is independent from the structural complexity of particular sentence, tree entropy is defined as the entropy over the probability distribution of theset of parsed trees forgiven sentence.
</prevsent>
<prevsent>it is useful measure to assess how certain the parser is about the best analysis, e.g. to measure the training utility value of data point in the context of sample selection (hwa, 2000).<papid> W00-1306 </papid></prevsent>
</prevsection>
<citsent citstr=" C02-1013 ">
we thus employ tree entropy as a9further measures are conceivable: we could extract brackets from some n-best topological parses, associating them with weights, using methods similar to (carroll and briscoe, 2002).<papid> C02-1013 </papid></citsent>
<aftsection>
<nextsent>10 20 30 40 50 60 70 80 90 00.20.40.60.81 in % normalized entropy precision recall coverage figure 3: effect of different thresholds of normalized entropy on precision, recall, and coverage confidence measure for the quality of the best topo logical parse, and the extracted bracket constraints.
</nextsent>
<nextsent>we carry out an experiment to assess the effect of varying entropy thresholds  on precision andre call of topological parsing, in terms of perfect match rate, and show way to determine an optimal value for .
</nextsent>
<nextsent>we compute tree entropy over the full probability distribution, and normalise the values to be distributed in range between 0 and 1.
</nextsent>
<nextsent>the normalisation factor is empirically determined as the highest entropy over all sentences of the training set.10experimental setup we randomly split the manually corrected evaluation corpus of (becker and frank, 2002) (<papid> C02-1093 </papid>for sentence length  40) into training set of 600 sentences and test set of 408 sentences.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3509">
<title id=" P02-1008.xml">phonological comprehension and the compilation of optimality theory </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>however, after giving suitably flexible presentation of ot, we show carefully how to treat comprehension under recent variants of otin which grammars can be compiled into finite-state transducers.
</prevsent>
<prevsent>we then unify these variants, showing that compilation is possible if all components of the grammar are regular relations, including the harmony ordering on scored candidates.
</prevsent>
</prevsection>
<citsent citstr=" C00-1038 ">
a side benefit of our construction is far simpler implementation of directional ot (eisner, 2000).<papid> C00-1038 </papid></citsent>
<aftsection>
<nextsent>to produce language is to convert utterances from their underlying (deep?)
</nextsent>
<nextsent>form to surface form.
</nextsent>
<nextsent>optimality theory or ot (prince and smolensky, 1993) proposes to describe phonological production as an optimization process.
</nextsent>
<nextsent>for an underlying x, speaker purportedly chooses the surface form so as to maximize the harmony of the pair (x, z).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3511">
<title id=" P02-1008.xml">phonological comprehension and the compilation of optimality theory </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>present computational problem that production does not.
</prevsent>
<prevsent>even when the ot grammar is required to be finite-state, so that production can be performed with finite-state techniques, comprehension cannot in general be performed with finite-state techniques.
</prevsent>
</prevsection>
<citsent citstr=" J98-2006 ">
this problem (frank and satta, 1998; <papid> J98-2006 </papid>karttunen, 1998; eisner, 2000; <papid> C00-1038 </papid>gerdemann and van noord, 2000).</citsent>
<aftsection>
<nextsent>by altering or approximating the otformalismthat is, by hook or by crook these constructions manage to compile ot grammars into finite-state transducers.
</nextsent>
<nextsent>transducers may readily be inverted to do comprehension as easily as production.
</nextsent>
<nextsent>we carefully lay out how to use them for comprehension in realistic circumstances (in the presence of correspondence theory, lexical constraints, hearer uncertainty, and phonetic postprocessing).
</nextsent>
<nextsent>3.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3514">
<title id=" P02-1008.xml">phonological comprehension and the compilation of optimality theory </title>
<section> previous work on comprehension.  </section>
<citcontext>
<prevsection>
<prevsent>proceedings of the 40th annual meeting of the association for the treatment shows that all the constructions emerge directly from generalized presentation ofot, in which the crucial fact is that the harmony ordering on scored candidates is regular relation.
</prevsent>
<prevsent>work focusing on ot comprehension or even mentioning ithas been surprisingly sparse.
</prevsent>
</prevsection>
<citsent citstr=" P96-1049 ">
while the recent constructions mentioned in 1 can easily be applied to the comprehension problem, as we will explain, they were motivated primarily by desire to pare back ots generative power to that of previous rewrite-rule formalisms (johnson, 1972).fosler (1996) <papid> P96-1049 </papid>noted the existence of the ot comprehension task and speculated that it might succumb to heuristic search.</citsent>
<aftsection>
<nextsent>smolensky (1996) proposed to solve it by optimizing the underlying form, comprehend(z) ? = {x : (@x?)
</nextsent>
<nextsent>(x?, z)   (x, z)} hale and reiss (1998) pointed out in response that any comprehension-by-optimization strategy would have to arrange for multiple optima: after all, phonological comprehension is one-to-many mapping (since phonological production is many-to-one).1 the correctness of smolenskys proposal (i.e., whether it really computes comprehend) depends on the particular harmony measure.
</nextsent>
<nextsent>it can be made to work, multiple optima and all, if the harmony measure is constructed with both production and comprehension in mind.
</nextsent>
<nextsent>indeed, for any phonology, it is trivial to design harmony measure that both production and comprehension optimize.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3515">
<title id=" P02-1008.xml">phonological comprehension and the compilation of optimality theory </title>
<section> a general presentation of ot </section>
<citcontext>
<prevsection>
<prevsent>the underlying form and surface form are represented as strings.
</prevsent>
<prevsent>we often refer to these strings as input and output.
</prevsent>
</prevsection>
<citsent citstr=" P97-1040 ">
following eisner (1997), <papid> P97-1040 </papid>each candidate (x, z) is also represented as string y. the notation (x, z) that we have been using so far for candidates is actually misleading, since in fact the candidates that are compared encode more than just and z. they also encode particular alignment or correspondence between and z. for example, if = abdip and = a[di][bu], then typical candidate would be encoded = aab0[ddii][pb0u] which specifies that corresponds to a, was deleted (has no surface correspondent), voiceless surfaces as voiced b, etc. the harmony of might depend on this alignment as well as on and (just as an outfit might fit worse when worn backwards).</citsent>
<aftsection>
<nextsent>because we are distinguishing underlying and surface material by using disjoint alphabets ? = {a,b, . . .}
</nextsent>
<nextsent>and ? = {[,],a,b, . . .},2 it is easy to extract the underlying and surface forms (x and z) from y. although the above example assumes that andz are simple strings of phonemes and brackets, nothing herein depends on that assumption.
</nextsent>
<nextsent>autoseg mental representations too can be encoded as strings (eisner, 1997).<papid> P97-1040 </papid>in general, an ot grammar consists of 4 com ponents: constraint ranking, harmony ordering,and generating and pronouncing functions.</nextsent>
<nextsent>the constraint ranking is the language-specific part of the grammar; the other components are often supposed to be universal across languages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3517">
<title id=" P02-1008.xml">phonological comprehension and the compilation of optimality theory </title>
<section> comprehension in finite-state ot.  </section>
<citcontext>
<prevsection>
<prevsent>these other strings may represent the surface forms for other members of the same morphological paradigm, or intermediate throwaway candidates to which is sympathetic.
</prevsent>
<prevsent>production still optimizes y, which means that it simultaneously optimizes and the other strings.
</prevsent>
</prevsection>
<citsent citstr=" C94-2163 ">
this section assumes ots traditional harmony ordering, in which the candidates that survive filtering by ci are the ones into which ci inserts fewest s.much computational work on ot has been conducted within finite-state framework (ellison, 1994), <papid> C94-2163 </papid>in keeping with tradition of finite-state phonology (johnson, 1972; kaplan and kay, 1994).<papid> J94-3001 </papid>4 4the tradition already included (inviolable) phonologicalfinite-state ot is restriction of the formalism discussed above.</citsent>
<aftsection>
<nextsent>it specifically assumes that gen, c1, . . .
</nextsent>
<nextsent>cn, and pron are all regular relations, meaning that they can be described by finite-state transducers.
</nextsent>
<nextsent>gen is non deterministic transducer that maps each to multiple candidates y. the other transducers map each to single y?
</nextsent>
<nextsent>or z. these finite-state assumptions were proposed (in different and slightly weaker form) by ellison (1994)<papid> C94-2163 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3518">
<title id=" P02-1008.xml">phonological comprehension and the compilation of optimality theory </title>
<section> comprehension in finite-state ot.  </section>
<citcontext>
<prevsection>
<prevsent>these other strings may represent the surface forms for other members of the same morphological paradigm, or intermediate throwaway candidates to which is sympathetic.
</prevsent>
<prevsent>production still optimizes y, which means that it simultaneously optimizes and the other strings.
</prevsent>
</prevsection>
<citsent citstr=" J94-3001 ">
this section assumes ots traditional harmony ordering, in which the candidates that survive filtering by ci are the ones into which ci inserts fewest s.much computational work on ot has been conducted within finite-state framework (ellison, 1994), <papid> C94-2163 </papid>in keeping with tradition of finite-state phonology (johnson, 1972; kaplan and kay, 1994).<papid> J94-3001 </papid>4 4the tradition already included (inviolable) phonologicalfinite-state ot is restriction of the formalism discussed above.</citsent>
<aftsection>
<nextsent>it specifically assumes that gen, c1, . . .
</nextsent>
<nextsent>cn, and pron are all regular relations, meaning that they can be described by finite-state transducers.
</nextsent>
<nextsent>gen is non deterministic transducer that maps each to multiple candidates y. the other transducers map each to single y?
</nextsent>
<nextsent>or z. these finite-state assumptions were proposed (in different and slightly weaker form) by ellison (1994)<papid> C94-2163 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3540">
<title id=" P04-1035.xml">a sentimental education sentiment analysis using subjectivity summarization based on minimum cuts </title>
<section> method.  </section>
<citcontext>
<prevsection>
<prevsent>s1 s2 s3 s4 s_n +/s4 s1 subjectivity detector yes no no yes nsentence review subjectivesentence?
</prevsent>
<prevsent>msentence extract(m =n) review positive or negative default classifier polarity subjectivity extraction figure 1: polarity classification via subjectivity detec tion.to our knowledge, previous work has not integrated sentence-level subjectivity detection withdocument-level sentiment polarity.
</prevsent>
</prevsection>
<citsent citstr=" W03-1017 ">
yu and hatzivassiloglou (2003) <papid> W03-1017 </papid>provide methods for sentence level analysis and for determining whether document is subjective or not, but do not combine these two types of algorithms or consider document polarity classification.</citsent>
<aftsection>
<nextsent>the motivation behind the single sentence selection method of beineke et al (2004) is to reveal documents sentiment polarity, but they do not evaluate the polarity-classification accuracy that results.
</nextsent>
<nextsent>2.2 context and subjectivity detection.
</nextsent>
<nextsent>as with document-level polarity classification, we could perform subjectivity detection on individual sentences by applying standard classification algorithm on each sentence in isolation.
</nextsent>
<nextsent>however, modeling proximity relationships between sentences would enable us to leverage coherence: text spans occurring near each other (within discourse bound aries) may share the same subjectivity status, other things being equal (wiebe, 1994).<papid> J94-2004 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3542">
<title id=" P04-1035.xml">a sentimental education sentiment analysis using subjectivity summarization based on minimum cuts </title>
<section> method.  </section>
<citcontext>
<prevsection>
<prevsent>2.2 context and subjectivity detection.
</prevsent>
<prevsent>as with document-level polarity classification, we could perform subjectivity detection on individual sentences by applying standard classification algorithm on each sentence in isolation.
</prevsent>
</prevsection>
<citsent citstr=" J94-2004 ">
however, modeling proximity relationships between sentences would enable us to leverage coherence: text spans occurring near each other (within discourse bound aries) may share the same subjectivity status, other things being equal (wiebe, 1994).<papid> J94-2004 </papid></citsent>
<aftsection>
<nextsent>we would therefore like to supply our algorithms with pair-wise interaction information, e.g., to specify that two particular sentences should ideally receive the same subjectivity label but not state which label this should be.
</nextsent>
<nextsent>incorporating such information is somewhat unnatural for classifiers whose in put consists simply of individual feature vectors, such as naive bayes or svms, precisely because such classifiers label each test item in isolation.one could define synthetic features or feature vectors to attempt to overcome this obstacle.
</nextsent>
<nextsent>however, we propose an alternative that avoids the need for such feature engineering: we use an efficient and intuitive graph-based formulation relying on finding minimum cuts.
</nextsent>
<nextsent>our approach is inspired by blum and chawla (2001), although they focused on similarity between items (the motivation being to combine labeled and unlabeled data), whereas we are concerned with physical proximity between the items to be classified; indeed, in computervision, modeling proximity information via graph cuts has led to very effective classification (boykov, veksler, and zabih, 1999).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3545">
<title id=" P04-1035.xml">a sentimental education sentiment analysis using subjectivity summarization based on minimum cuts </title>
<section> method.  </section>
<citcontext>
<prevsection>
<prevsent>for instance, it is perfectly legitimate to use knowledge-rich algorithms employing deep linguistic knowledge about sentiment indicators to derive the individual scores.and we could also simultaneously use knowledge lean methods to assign the association scores.
</prevsent>
<prevsent>interestingly, yu and hatzivassiloglou (2003) <papid> W03-1017 </papid>compared an individual-preference classifier against relationship-based method, but didnt combine the two; the ability to coordinate such algorithms is precisely one of the strengths of our approach.</prevsent>
</prevsection>
<citsent citstr=" P97-1023 ">
but crucial advantage specific to the utilization of minimum-cut-based approach is that we can usemaximum-flow algorithms with polynomial asymp totic running times ? and near-linear running timesin practice ? to exactly compute the minimum cost cut(s), despite the apparent intractability of the optimization problem (cormen, leiser son, and rivest, 1990; ahuja, magnanti, and orlin, 1993).2 in contrast, other graph-partitioning problems that have been previously used to formulate nlp classification problems3 are np-complete (hatzivassi loglou and mckeown, 1997; <papid> P97-1023 </papid>agrawal et al, 2003; joachims, 2003).</citsent>
<aftsection>
<nextsent>2code available at http://www.avglab.com/andrew/soft.html.
</nextsent>
<nextsent>3graph-based approaches to general clustering problems are too numerous to mention here.
</nextsent>
<nextsent>our experiments involve classifying movie reviews as either positive or negative, an appealing task for several reasons.
</nextsent>
<nextsent>first, as mentioned in the introduction, providing polarity information about reviews is useful service: witness the popularity of www.rottentomatoes.com.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3546">
<title id=" P04-1035.xml">a sentimental education sentiment analysis using subjectivity summarization based on minimum cuts </title>
<section> evaluation framework.  </section>
<citcontext>
<prevsection>
<prevsent>our experiments involve classifying movie reviews as either positive or negative, an appealing task for several reasons.
</prevsent>
<prevsent>first, as mentioned in the introduction, providing polarity information about reviews is useful service: witness the popularity of www.rottentomatoes.com.
</prevsent>
</prevsection>
<citsent citstr=" P02-1053 ">
second, movie reviews are apparently harder to classify than reviews of other products (turney, 2002; <papid> P02-1053 </papid>dave, lawrence, andpennock, 2003).</citsent>
<aftsection>
<nextsent>third, the correct label can be extracted automatically from rating information (e.g., number of stars).
</nextsent>
<nextsent>our data4 contains 1000 positive and 1000 negative reviews all written before 2002, with cap of 20 reviews per author (312 authors total) per category.
</nextsent>
<nextsent>we refer to this corpus as the polarity dataset.default polarity classifiers we tested support vector machines (svms) and naive bayes (nb).
</nextsent>
<nextsent>following pang et al (2002), <papid> W02-1011 </papid>we use unigram-presence features: the ith coordinate of feature vector is 1 if the corresponding unigram occurs in the input text, 0 otherwise.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3547">
<title id=" P04-1035.xml">a sentimental education sentiment analysis using subjectivity summarization based on minimum cuts </title>
<section> evaluation framework.  </section>
<citcontext>
<prevsection>
<prevsent>our data4 contains 1000 positive and 1000 negative reviews all written before 2002, with cap of 20 reviews per author (312 authors total) per category.
</prevsent>
<prevsent>we refer to this corpus as the polarity dataset.default polarity classifiers we tested support vector machines (svms) and naive bayes (nb).
</prevsent>
</prevsection>
<citsent citstr=" W02-1011 ">
following pang et al (2002), <papid> W02-1011 </papid>we use unigram-presence features: the ith coordinate of feature vector is 1 if the corresponding unigram occurs in the input text, 0 otherwise.</citsent>
<aftsection>
<nextsent>(for svms, the feature vectors are length-normalized).
</nextsent>
<nextsent>each default document level polarity classifier is trained and tested on the extracts formed by applying one of the sentence level subjectivity detectors to reviews in the polarity dataset.
</nextsent>
<nextsent>subjectivity dataset to train our detectors, we need collection of labeled sentences.
</nextsent>
<nextsent>riloff andwiebe (2003) <papid> W03-1014 </papid>state that it is [very hard] to obtain collections of individual sentences that can be easily identified as subjective or objective?; the polarity-dataset sentences, for example, have not4available at www.cs.cornell.edu/people/pabo/movie review-data/ (review corpus version 2.0).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3548">
<title id=" P04-1035.xml">a sentimental education sentiment analysis using subjectivity summarization based on minimum cuts </title>
<section> evaluation framework.  </section>
<citcontext>
<prevsection>
<prevsent>each default document level polarity classifier is trained and tested on the extracts formed by applying one of the sentence level subjectivity detectors to reviews in the polarity dataset.
</prevsent>
<prevsent>subjectivity dataset to train our detectors, we need collection of labeled sentences.
</prevsent>
</prevsection>
<citsent citstr=" W03-1014 ">
riloff andwiebe (2003) <papid> W03-1014 </papid>state that it is [very hard] to obtain collections of individual sentences that can be easily identified as subjective or objective?; the polarity-dataset sentences, for example, have not4available at www.cs.cornell.edu/people/pabo/movie review-data/ (review corpus version 2.0).</citsent>
<aftsection>
<nextsent>been so annotated.5 fortunately, we were ableto mine the web to create large, automatically labeled sentence corpus6.
</nextsent>
<nextsent>to gather subjective sentences (or phrases), we collected 5000 movie review snippets (e.g., bold, imaginative, and im possible to resist?)
</nextsent>
<nextsent>from www.rottentomatoes.com.to obtain (mostly) objective data, we took 5000 sentences from plot summaries available from the internet movie database (www.imdb.com).
</nextsent>
<nextsent>we only selected sentences or snippets at least ten words long and drawn from reviews or plot summaries of movies released post-2001, which prevents overlap with the polarity dataset.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3549">
<title id=" P02-1045.xml">applying co training to reference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a major obstacle for natural language processing systems which analyze natural language texts or utterances is the need to identify the entities referred to by means of referring expressions.
</prevsent>
<prevsent>among referring expressions, pronouns and definite noun phrases (nps) are the most prominent.
</prevsent>
</prevsection>
<citsent citstr=" W98-1119 ">
supervised machine learning algorithms were used for pronoun resolution with good results (ge etal., 1998), <papid> W98-1119 </papid>and for definite nps with fairly good results (aone and bennett, 1995; mccarthy and lehnert, 1995; soon et al, 2001).<papid> J01-4004 </papid></citsent>
<aftsection>
<nextsent>however, the deficiency of supervised machine learning approaches isthe need for an unknown amount of annotated training data for optimal performance.
</nextsent>
<nextsent>so, researchers in nlp began to experiment with weakly supervised machine learning algorithms such as co-training (blum and mitchell, 1998).
</nextsent>
<nextsent>among others co-training was applied to document classification (blum and mitchell, 1998), named entity recognition (collins and singer, 1999), <papid> W99-0613 </papid>noun phrase bracketing (pierce and cardie, 2001), <papid> W01-0501 </papid>and statistical parsing (sarkar, 2001).<papid> N01-1023 </papid></nextsent>
<nextsent>in this paper weapply co-training to the problem of reference resolution in german texts from the tourism domain in order to provide answers to the following questions:   does co-training work at all for this task (when compared to conventional c4.5 decision tree learning)?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3550">
<title id=" P02-1045.xml">applying co training to reference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a major obstacle for natural language processing systems which analyze natural language texts or utterances is the need to identify the entities referred to by means of referring expressions.
</prevsent>
<prevsent>among referring expressions, pronouns and definite noun phrases (nps) are the most prominent.
</prevsent>
</prevsection>
<citsent citstr=" J01-4004 ">
supervised machine learning algorithms were used for pronoun resolution with good results (ge etal., 1998), <papid> W98-1119 </papid>and for definite nps with fairly good results (aone and bennett, 1995; mccarthy and lehnert, 1995; soon et al, 2001).<papid> J01-4004 </papid></citsent>
<aftsection>
<nextsent>however, the deficiency of supervised machine learning approaches isthe need for an unknown amount of annotated training data for optimal performance.
</nextsent>
<nextsent>so, researchers in nlp began to experiment with weakly supervised machine learning algorithms such as co-training (blum and mitchell, 1998).
</nextsent>
<nextsent>among others co-training was applied to document classification (blum and mitchell, 1998), named entity recognition (collins and singer, 1999), <papid> W99-0613 </papid>noun phrase bracketing (pierce and cardie, 2001), <papid> W01-0501 </papid>and statistical parsing (sarkar, 2001).<papid> N01-1023 </papid></nextsent>
<nextsent>in this paper weapply co-training to the problem of reference resolution in german texts from the tourism domain in order to provide answers to the following questions:   does co-training work at all for this task (when compared to conventional c4.5 decision tree learning)?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3552">
<title id=" P02-1045.xml">applying co training to reference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, the deficiency of supervised machine learning approaches isthe need for an unknown amount of annotated training data for optimal performance.
</prevsent>
<prevsent>so, researchers in nlp began to experiment with weakly supervised machine learning algorithms such as co-training (blum and mitchell, 1998).
</prevsent>
</prevsection>
<citsent citstr=" W99-0613 ">
among others co-training was applied to document classification (blum and mitchell, 1998), named entity recognition (collins and singer, 1999), <papid> W99-0613 </papid>noun phrase bracketing (pierce and cardie, 2001), <papid> W01-0501 </papid>and statistical parsing (sarkar, 2001).<papid> N01-1023 </papid></citsent>
<aftsection>
<nextsent>in this paper weapply co-training to the problem of reference resolution in german texts from the tourism domain in order to provide answers to the following questions:   does co-training work at all for this task (when compared to conventional c4.5 decision tree learning)?
</nextsent>
<nextsent>  how much labeled training data is required for achieving reasonable performance?
</nextsent>
<nextsent>first, we discuss features that have been found to be relevant for the task of reference resolution, and describe the feature set that we are using (section 2).
</nextsent>
<nextsent>then we briefly introduce the co-training paradigm (section 3), which is followed by description of the corpus we use, the corpus annotation, and the way we prepared the data for using binary classifier in the co-training algorithm (section 4).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3553">
<title id=" P02-1045.xml">applying co training to reference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, the deficiency of supervised machine learning approaches isthe need for an unknown amount of annotated training data for optimal performance.
</prevsent>
<prevsent>so, researchers in nlp began to experiment with weakly supervised machine learning algorithms such as co-training (blum and mitchell, 1998).
</prevsent>
</prevsection>
<citsent citstr=" W01-0501 ">
among others co-training was applied to document classification (blum and mitchell, 1998), named entity recognition (collins and singer, 1999), <papid> W99-0613 </papid>noun phrase bracketing (pierce and cardie, 2001), <papid> W01-0501 </papid>and statistical parsing (sarkar, 2001).<papid> N01-1023 </papid></citsent>
<aftsection>
<nextsent>in this paper weapply co-training to the problem of reference resolution in german texts from the tourism domain in order to provide answers to the following questions:   does co-training work at all for this task (when compared to conventional c4.5 decision tree learning)?
</nextsent>
<nextsent>  how much labeled training data is required for achieving reasonable performance?
</nextsent>
<nextsent>first, we discuss features that have been found to be relevant for the task of reference resolution, and describe the feature set that we are using (section 2).
</nextsent>
<nextsent>then we briefly introduce the co-training paradigm (section 3), which is followed by description of the corpus we use, the corpus annotation, and the way we prepared the data for using binary classifier in the co-training algorithm (section 4).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3554">
<title id=" P02-1045.xml">applying co training to reference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, the deficiency of supervised machine learning approaches isthe need for an unknown amount of annotated training data for optimal performance.
</prevsent>
<prevsent>so, researchers in nlp began to experiment with weakly supervised machine learning algorithms such as co-training (blum and mitchell, 1998).
</prevsent>
</prevsection>
<citsent citstr=" N01-1023 ">
among others co-training was applied to document classification (blum and mitchell, 1998), named entity recognition (collins and singer, 1999), <papid> W99-0613 </papid>noun phrase bracketing (pierce and cardie, 2001), <papid> W01-0501 </papid>and statistical parsing (sarkar, 2001).<papid> N01-1023 </papid></citsent>
<aftsection>
<nextsent>in this paper weapply co-training to the problem of reference resolution in german texts from the tourism domain in order to provide answers to the following questions:   does co-training work at all for this task (when compared to conventional c4.5 decision tree learning)?
</nextsent>
<nextsent>  how much labeled training data is required for achieving reasonable performance?
</nextsent>
<nextsent>first, we discuss features that have been found to be relevant for the task of reference resolution, and describe the feature set that we are using (section 2).
</nextsent>
<nextsent>then we briefly introduce the co-training paradigm (section 3), which is followed by description of the corpus we use, the corpus annotation, and the way we prepared the data for using binary classifier in the co-training algorithm (section 4).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3557">
<title id=" P02-1045.xml">applying co training to reference resolution </title>
<section> features for reference resolution.  </section>
<citcontext>
<prevsection>
<prevsent>and features which focus on the anaphoric relation (e.g. do both share common np?).
</prevsent>
<prevsent>it was criticized (soon et al, 2001) <papid> J01-4004 </papid>that the features used by mccarthy and lehnert (1995) are highly idiosyncratic and applicable only to one particular domain.</prevsent>
</prevsection>
<citsent citstr=" M95-1005 ">
mccarthy and lehnert (1995) achieved results of about 86% f-measure (evaluated according to vilain et al (1995)) <papid> M95-1005 </papid>on the muc-5 data set.however, only defined subset of all possible reference resolution cases was considered relevant inthe muc-5 task description, e.g., only entity refer ences.</citsent>
<aftsection>
<nextsent>for this case, the domain-dependent features may have been particularly important, making it difficult to compare the results of this approach tooth ers working on less restricted domains.soon et al (2001)<papid> J01-4004 </papid>use twelve features (see table 1).</nextsent>
<nextsent>they show part of their decision tree inwhich the weak string identity feature (i.e. identity after determiners have been removed) appears to be the most important one.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3563">
<title id=" P02-1045.xml">applying co training to reference resolution </title>
<section> features for reference resolution.  </section>
<citcontext>
<prevsection>
<prevsent>an alias feature (used for proper names and acronyms) ? an appositive feature table 1: features used by soon et al the three features weak string identity, alias (whichmaps named entities in order to resolve dates, person names, acronyms, etc.) and appositive seem tocover most of the cases (the other nine features contribute only 2.3% f-measure for muc-6 texts and 1% f-measure for muc-7 texts).
</prevsent>
<prevsent>soon et al (2001)<papid> J01-4004 </papid>include all noun phrases returned by their np identifier and report an f-measure of 62.6% for muc-6 data and 60.4% for muc-7 data.</prevsent>
</prevsection>
<citsent citstr=" W99-0611 ">
they only used pairs of anaphors and their closest antecedents as positive examples in training, but evaluated according to vilain et al (1995).<papid> M95-1005 </papid>cardie and wagstaff (1999) <papid> W99-0611 </papid>describe an unsupervised clustering approach to noun phrase coreference resolution in which features are assigned to single noun phrases only.</citsent>
<aftsection>
<nextsent>they use the features shown in table 2, all of which are obtained automatically without any manual tagging.
</nextsent>
<nextsent>position (nps are numbered sequentially) ? pronoun type (nom., acc., possessive, ambiguous) ? article (indefinite, definite, none) ? appositive (yes, no) ? number (singular, plural) ? proper name (yes, no) ? semantic class (based on wordnet: time, city, animal, human, object; based on separate algorithm: number, money, company) ? gender (masculine, feminine, either, neuter) ? animacy (anim, inanim) table 2: features used by cardie and wagstaff the feature semantic class used by cardie and wagstaff (1999) <papid> W99-0611 </papid>seems to be domain-dependent one which can only be used for the muc domain and similar ones.</nextsent>
<nextsent>cardie and wagstaff (1999) <papid> W99-0611 </papid>report performance of 53,6% f-measure (evaluated according to vilain et al (1995)).<papid> M95-1005 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3571">
<title id=" P02-1045.xml">applying co training to reference resolution </title>
<section> features for reference resolution.  </section>
<citcontext>
<prevsection>
<prevsent>since in german the gender and the semantic class do not necessarily coincide (i.e. objects are not necessarily neuter as in english) we also provide semantic class feature which captures the difference between human, concrete, and abstract objects.
</prevsent>
<prevsent>this basically corresponds to the gender attribute in english.the feature wdist captures the distance in words between anaphor and antecedent, the feature ddist captures the distance in sentences, the feature mdist the number of markables (nps) between anaphor andantecedent.
</prevsent>
</prevsection>
<citsent citstr=" W02-1040 ">
features like the string ident and substring match features were used by other researchers (soon et al, 2001), <papid> J01-4004 </papid>while the features ante med and ana med were used by strube et al (2002) <papid> W02-1040 </papid>in order to improve the performance for definite nps.</citsent>
<aftsection>
<nextsent>the minimum edit distance (med) computes the similarity of strings by taking into account the minimum number of editing operations (substitutions s, insertions i, deletions d) needed to transform one string into the other (wagner and fischer, 1974).
</nextsent>
<nextsent>themed is computed from these editing operations and the length of the potential antecedent or the length of the anaphor n.
</nextsent>
<nextsent>co-training (blum and mitchell, 1998) is meta learning algorithm which exploits unlabeled in addition to labeled training data for classifier learning.
</nextsent>
<nextsent>a co-training classifier is complex in the sense that it consists of two simple classifiers (most often naive bayes, e.g. by blum and mitchell (1998) and pierce and cardie (2001)).<papid> W01-0501 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3574">
<title id=" P02-1045.xml">applying co training to reference resolution </title>
<section> data.  </section>
<citcontext>
<prevsection>
<prevsent>our corpus consists of 250 short german texts (total 36924 tokens, 9399 nps, 2179 anaphoric nps) about sights, historic events and persons in heidelberg.
</prevsent>
<prevsent>the average length of the texts was 149 tokens.
</prevsent>
</prevsection>
<citsent citstr=" A00-1031 ">
the texts were pos-tagged using tnt (brants, 2000).<papid> A00-1031 </papid></citsent>
<aftsection>
<nextsent>abasic identification of markables (i.e. nps) was obtained by using the np-chunker chunkie (skut and brants, 1998).<papid> W98-1117 </papid></nextsent>
<nextsent>the pos-tagger was also used for assigning attributes to markables (e.g. the np form).the automatic annotation was followed by man document level features 1.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3575">
<title id=" P02-1045.xml">applying co training to reference resolution </title>
<section> data.  </section>
<citcontext>
<prevsection>
<prevsent>the average length of the texts was 149 tokens.
</prevsent>
<prevsent>the texts were pos-tagged using tnt (brants, 2000).<papid> A00-1031 </papid></prevsent>
</prevsection>
<citsent citstr=" W98-1117 ">
abasic identification of markables (i.e. nps) was obtained by using the np-chunker chunkie (skut and brants, 1998).<papid> W98-1117 </papid></citsent>
<aftsection>
<nextsent>the pos-tagger was also used for assigning attributes to markables (e.g. the np form).the automatic annotation was followed by man document level features 1.
</nextsent>
<nextsent>doc id document number (1 . . .
</nextsent>
<nextsent>250) np-level features 2.
</nextsent>
<nextsent>ante gram func grammatical function of antecedent (subject, object, other) 3.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3576">
<title id=" P02-1045.xml">applying co training to reference resolution </title>
<section> data.  </section>
<citcontext>
<prevsection>
<prevsent>markables with the same value in this attribute are considered co referring expressions.
</prevsent>
<prevsent>the annotation was performed by two students.
</prevsent>
</prevsection>
<citsent citstr=" J96-2004 ">
the reliability of the annotations was checked using the kappa statistic (carletta, 1996).<papid> J96-2004 </papid></citsent>
<aftsection>
<nextsent>4.2 coreference resolution as binary.
</nextsent>
<nextsent>classification the problem of coreference resolution can easily be formulated in such way as to be amenable to co training.
</nextsent>
<nextsent>the most straightforward definition turns the task into binary classification: given pair of potential anaphor and potential antecedent, classify as positive if the antecedent is in fact the closest antecedent, and as negative otherwise.
</nextsent>
<nextsent>note that there striction of this rule to the closest antecedent means that transitive antecedents (i.e. those occuring further upwards in the text as the direct antecedent) are treated as negative in the training data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3585">
<title id=" P04-1084.xml">generalized multi text grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper investigates the generative capacity of gmtg, proves that each component grammar of gmtg retains its generative power, and proposes generalization of chomsky normal form, which is necessary for synchronous cky-style parsing.
</prevsent>
<prevsent>synchronous grammars have been proposed for the formal description of parallel texts representing translations of the same document.
</prevsent>
</prevsection>
<citsent citstr=" N03-1021 ">
as shown by melamed (2003), <papid> N03-1021 </papid>plausible model of parallel text must be able to express discontinuous constituents.since linguistic expressions can vanish in translation, good model must be able to express independent (in addition to synchronous) rewriting.</citsent>
<aftsection>
<nextsent>inversion transduction grammar (itg) (wu, 1997) <papid> J97-3002 </papid>and syntax-directed translation schema (sdts)(aho and ullman, 1969) lack both of these prop erties.</nextsent>
<nextsent>synchronous tree adjoining grammar (stag) (shieber, 1994) lacks the latter and allows only limited discontinuities in each tree.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3587">
<title id=" P04-1084.xml">generalized multi text grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>synchronous grammars have been proposed for the formal description of parallel texts representing translations of the same document.
</prevsent>
<prevsent>as shown by melamed (2003), <papid> N03-1021 </papid>plausible model of parallel text must be able to express discontinuous constituents.since linguistic expressions can vanish in translation, good model must be able to express independent (in addition to synchronous) rewriting.</prevsent>
</prevsection>
<citsent citstr=" J97-3002 ">
inversion transduction grammar (itg) (wu, 1997) <papid> J97-3002 </papid>and syntax-directed translation schema (sdts)(aho and ullman, 1969) lack both of these prop erties.</citsent>
<aftsection>
<nextsent>synchronous tree adjoining grammar (stag) (shieber, 1994) lacks the latter and allows only limited discontinuities in each tree.
</nextsent>
<nextsent>generalized multi text grammar (gmtg) offers way to synchronize mildly context-sensitive grammar (mcsg), while satisfying both of the above criteria.
</nextsent>
<nextsent>the move to mcsg is motivated by our desire to more perspicuously account for certain syntactic phenomena that cannot be easily captured by context-free grammars, such as cliticclimbing, extra position, and other types of long distance movement (becker et al, 1991).<papid> E91-1005 </papid></nextsent>
<nextsent>on the other hand, mcsg still observes some restrictions that make the set of languages it generates less expensive to analyze than the languages generated by (properly) context-sensitive formalisms.more technically, our proposal starts from multi text grammar (mtg), formalism for synchronizing context-free grammars recently proposed by melamed (2003).<papid> N03-1021 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3588">
<title id=" P04-1084.xml">generalized multi text grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>synchronous tree adjoining grammar (stag) (shieber, 1994) lacks the latter and allows only limited discontinuities in each tree.
</prevsent>
<prevsent>generalized multi text grammar (gmtg) offers way to synchronize mildly context-sensitive grammar (mcsg), while satisfying both of the above criteria.
</prevsent>
</prevsection>
<citsent citstr=" E91-1005 ">
the move to mcsg is motivated by our desire to more perspicuously account for certain syntactic phenomena that cannot be easily captured by context-free grammars, such as cliticclimbing, extra position, and other types of long distance movement (becker et al, 1991).<papid> E91-1005 </papid></citsent>
<aftsection>
<nextsent>on the other hand, mcsg still observes some restrictions that make the set of languages it generates less expensive to analyze than the languages generated by (properly) context-sensitive formalisms.more technically, our proposal starts from multi text grammar (mtg), formalism for synchronizing context-free grammars recently proposed by melamed (2003).<papid> N03-1021 </papid></nextsent>
<nextsent>in mtg, synchronous rewriting is implemented by means of an indexing relation that is maintained over occurrences of nonterminal sin sentential form, using essentially the same machinery as sdts.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3591">
<title id=" P04-1084.xml">generalized multi text grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper begins with an informal description of gmtg.
</prevsent>
<prevsent>it continues with an investigation of this formalisms generative capacity.
</prevsent>
</prevsection>
<citsent citstr=" P96-1016 ">
next, we prove that in gmtg each component grammar retains its generative power, requirement for synchronous formalisms that rambow and satta (1996) <papid> P96-1016 </papid>called the weak language preservation property.?</citsent>
<aftsection>
<nextsent>lastly,we propose synchronous generalization of chomsky normal form, which lays the groundwork for synchronous parsing under gmtg using cky style algorithm (younger, 1967; melamed, 2004).<papid> P04-1083 </papid></nextsent>
<nextsent>gmtg is generalization of mtg, which is itself generalization of cfg to the synchronous case.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3592">
<title id=" P04-1084.xml">generalized multi text grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it continues with an investigation of this formalisms generative capacity.
</prevsent>
<prevsent>next, we prove that in gmtg each component grammar retains its generative power, requirement for synchronous formalisms that rambow and satta (1996) <papid> P96-1016 </papid>called the weak language preservation property.?</prevsent>
</prevsection>
<citsent citstr=" P04-1083 ">
lastly,we propose synchronous generalization of chomsky normal form, which lays the groundwork for synchronous parsing under gmtg using cky style algorithm (younger, 1967; melamed, 2004).<papid> P04-1083 </papid></citsent>
<aftsection>
<nextsent>gmtg is generalization of mtg, which is itself generalization of cfg to the synchronous case.
</nextsent>
<nextsent>here we present mtg in new notation that shows the relation to cfg more clearly.
</nextsent>
<nextsent>for example, the following mtg productions can generate the multi text [(i fed the cat), (ya kota kormil)]:1   (s)
</nextsent>
<nextsent>(s)    pn  vp
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3603">
<title id=" P02-1004.xml">machine learned contexts for linguistic operations in german sentence realization </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>furthermore, the mapping can be performed purely by rules, by application of statistical models, or by combination of both techniques.
</prevsent>
<prevsent>among the systems that use statistical or machine learned techniques in sentence realization, there are various degrees of intermediate syntactic structure.
</prevsent>
</prevsection>
<citsent citstr=" W98-1426 ">
nitrogen (langkilde and knight, 1998<papid> W98-1426 </papid>a, 1998b) produces large set of alternative surface realizations of an input structure (which can vary in abstractness).</citsent>
<aftsection>
<nextsent>this set of candidate surface strings, represented as word lattice, is then rescored by word bigram language model, to produce the best ranked output sentence.
</nextsent>
<nextsent>fergus (bangalore and rambow, 2000), <papid> C00-1007 </papid>on the other hand, employs model of syntactic structure during sentence realization.</nextsent>
<nextsent>in simple terms, it adds tree-based stochastic model to the approach taken by the nitrogen system.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3605">
<title id=" P02-1004.xml">machine learned contexts for linguistic operations in german sentence realization </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>nitrogen (langkilde and knight, 1998<papid> W98-1426 </papid>a, 1998b) produces large set of alternative surface realizations of an input structure (which can vary in abstractness).</prevsent>
<prevsent>this set of candidate surface strings, represented as word lattice, is then rescored by word bigram language model, to produce the best ranked output sentence.</prevsent>
</prevsection>
<citsent citstr=" C00-1007 ">
fergus (bangalore and rambow, 2000), <papid> C00-1007 </papid>on the other hand, employs model of syntactic structure during sentence realization.</citsent>
<aftsection>
<nextsent>in simple terms, it adds tree-based stochastic model to the approach taken by the nitrogen system.
</nextsent>
<nextsent>this tree-based model chooses best-ranked xtag representation forgiven dependency structure.
</nextsent>
<nextsent>possible linearizations of the xtag representation are generated and then evaluated by language model to pick the best possible linearization, as in nitrogen.
</nextsent>
<nextsent>in contrast, the sentence realization system code-named amalgam (a machine learned generation module) (corston-oliver et al, 2002; gamon et al, 2002<papid> C02-1036 </papid>b) employs series of linguistic operations which map semantic representation to surface syntactic tree via intermediate syntactic representations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3606">
<title id=" P02-1004.xml">machine learned contexts for linguistic operations in german sentence realization </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this tree-based model chooses best-ranked xtag representation forgiven dependency structure.
</prevsent>
<prevsent>possible linearizations of the xtag representation are generated and then evaluated by language model to pick the best possible linearization, as in nitrogen.
</prevsent>
</prevsection>
<citsent citstr=" C02-1036 ">
in contrast, the sentence realization system code-named amalgam (a machine learned generation module) (corston-oliver et al, 2002; gamon et al, 2002<papid> C02-1036 </papid>b) employs series of linguistic operations which map semantic representation to surface syntactic tree via intermediate syntactic representations.</citsent>
<aftsection>
<nextsent>the contexts for most of these operations in amalgam are machine learned.
</nextsent>
<nextsent>the resulting syntactic tree contains all the necessary information on its leaf nodes from which surface string can be read.
</nextsent>
<nextsent>the goal of this paper is to show that it is possible to learn accurately the contexts for linguistically complex operations in sentence realization.
</nextsent>
<nextsent>we propose that learning the contexts for the application of these linguistic operations can be viewed as per-operation classification problems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3616">
<title id=" P02-1004.xml">machine learned contexts for linguistic operations in german sentence realization </title>
<section> syntactic aggregation.  </section>
<citcontext>
<prevsection>
<prevsent>extraposable clause accuracy baseline relcl 0.8387 0.6093 infcl 0.9202 0.9370 compcl 0.9857 0.9429 overall 0.8612 0.6758
</prevsent>
<prevsent>any sentence realization component that generates from an abstract semantic representation and strives to produce fluent output beyond simple templates will have to deal with coordination and the problem of duplicated material in coordination.
</prevsent>
</prevsection>
<citsent citstr=" P98-2199 ">
this is generally viewed as subarea of aggregation in the generation literature (wilkinson, 1995; shaw, 1998; <papid> P98-2199 </papid>reape and mellish, 1999; dalianis and hovy, 1993).</citsent>
<aftsection>
<nextsent>in amalgam, the approach we take is strictly intra sentential, along the lines of what has been called conjunction reduction in the linguistic literature (mccawley, 1988).
</nextsent>
<nextsent>while this may seem fairly straightforward task compared to inter-sentential, semantic and lexical aggregation, it should be noted that the cross-linguistic complexity of the phenomenon makes it much less trivial than first glance at english would suggest.
</nextsent>
<nextsent>in german, for example, position of the verb in the coordinated vps plays an important role in determining which duplicated constituent can be omitted.
</nextsent>
<nextsent>the target feature for the classification task is formulated as follows: in which coordinated constituent is the duplicated constituent to be realized??.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3617">
<title id=" P04-1064.xml">aligning words using matrix factorisation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this is illustrated on french-english alignment task from the hansard.
</prevsent>
<prevsent>aligning words from mutually translated sentence sin two different languages is an important and difficult problem.
</prevsent>
</prevsection>
<citsent citstr=" W99-0604 ">
it is important because word aligned corpus is typically used as first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (<papid> W99-0604 </papid>tillmann and xia, 2003), (<papid> N03-2036 </papid>koehn et al, 2003, <papid> N03-1017 </papid>sec.</citsent>
<aftsection>
<nextsent>3), or for projecting linguistic annotation across languages (yarowsky et al, 2001).<papid> H01-1035 </papid></nextsent>
<nextsent>obtaining word-alignedcorpus usually involves training word-based translation models (brown et al, 1993) <papid> J93-2003 </papid>in each directions and combining the resulting alignments.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3618">
<title id=" P04-1064.xml">aligning words using matrix factorisation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this is illustrated on french-english alignment task from the hansard.
</prevsent>
<prevsent>aligning words from mutually translated sentence sin two different languages is an important and difficult problem.
</prevsent>
</prevsection>
<citsent citstr=" N03-2036 ">
it is important because word aligned corpus is typically used as first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (<papid> W99-0604 </papid>tillmann and xia, 2003), (<papid> N03-2036 </papid>koehn et al, 2003, <papid> N03-1017 </papid>sec.</citsent>
<aftsection>
<nextsent>3), or for projecting linguistic annotation across languages (yarowsky et al, 2001).<papid> H01-1035 </papid></nextsent>
<nextsent>obtaining word-alignedcorpus usually involves training word-based translation models (brown et al, 1993) <papid> J93-2003 </papid>in each directions and combining the resulting alignments.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3619">
<title id=" P04-1064.xml">aligning words using matrix factorisation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this is illustrated on french-english alignment task from the hansard.
</prevsent>
<prevsent>aligning words from mutually translated sentence sin two different languages is an important and difficult problem.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
it is important because word aligned corpus is typically used as first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (<papid> W99-0604 </papid>tillmann and xia, 2003), (<papid> N03-2036 </papid>koehn et al, 2003, <papid> N03-1017 </papid>sec.</citsent>
<aftsection>
<nextsent>3), or for projecting linguistic annotation across languages (yarowsky et al, 2001).<papid> H01-1035 </papid></nextsent>
<nextsent>obtaining word-alignedcorpus usually involves training word-based translation models (brown et al, 1993) <papid> J93-2003 </papid>in each directions and combining the resulting alignments.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3620">
<title id=" P04-1064.xml">aligning words using matrix factorisation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>aligning words from mutually translated sentence sin two different languages is an important and difficult problem.
</prevsent>
<prevsent>it is important because word aligned corpus is typically used as first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (<papid> W99-0604 </papid>tillmann and xia, 2003), (<papid> N03-2036 </papid>koehn et al, 2003, <papid> N03-1017 </papid>sec.</prevsent>
</prevsection>
<citsent citstr=" H01-1035 ">
3), or for projecting linguistic annotation across languages (yarowsky et al, 2001).<papid> H01-1035 </papid></citsent>
<aftsection>
<nextsent>obtaining word-alignedcorpus usually involves training word-based translation models (brown et al, 1993) <papid> J93-2003 </papid>in each directions and combining the resulting alignments.</nextsent>
<nextsent>besides processing time, important issues are completeness and propriety of the resulting alignment, and the ability to reliably identify general nto-m alignments.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3621">
<title id=" P04-1064.xml">aligning words using matrix factorisation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it is important because word aligned corpus is typically used as first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (<papid> W99-0604 </papid>tillmann and xia, 2003), (<papid> N03-2036 </papid>koehn et al, 2003, <papid> N03-1017 </papid>sec.</prevsent>
<prevsent>3), or for projecting linguistic annotation across languages (yarowsky et al, 2001).<papid> H01-1035 </papid></prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
obtaining word-alignedcorpus usually involves training word-based translation models (brown et al, 1993) <papid> J93-2003 </papid>in each directions and combining the resulting alignments.</citsent>
<aftsection>
<nextsent>besides processing time, important issues are completeness and propriety of the resulting alignment, and the ability to reliably identify general nto-m alignments.
</nextsent>
<nextsent>in the following section, we introduce the problem of aligning words from corpus that is already aligned at the sentence level.
</nextsent>
<nextsent>we show how this problem may be phrased in terms of matrix factorisation.
</nextsent>
<nextsent>we then identify number of constraints on word alignment, show that these constraints entail that word alignment is equivalent to orthogonal non-negative matrix factorisation, and we give novel algorithm that solves this problem.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3622">
<title id=" P04-1064.xml">aligning words using matrix factorisation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we then identify number of constraints on word alignment, show that these constraints entail that word alignment is equivalent to orthogonal non-negative matrix factorisation, and we give novel algorithm that solves this problem.
</prevsent>
<prevsent>this is illustrated using data from the shared tasks of the 2003 hlt-naacl workshop on building le droit de permis ne augmente pas the licence fee does not increase figure 1: 1-1, m-1, 1-n and m-n alignments.
</prevsent>
</prevsection>
<citsent citstr=" W03-0301 ">
and using parallel texts (mihalcea and pedersen, 2003).<papid> W03-0301 </papid></citsent>
<aftsection>
<nextsent>we address the following problem: given source sentence = f1 . . .
</nextsent>
<nextsent>fi . . .
</nextsent>
<nextsent>fi and target sentence = e1 . . .
</nextsent>
<nextsent>ej . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3634">
<title id=" P04-1064.xml">aligning words using matrix factorisation </title>
<section> example.  </section>
<citcontext>
<prevsection>
<prevsent>we first illustrate the factorisation process on simple example.
</prevsent>
<prevsent>we use the data provided forthe french-english shared task of the 2003 hltnaacl workshop on building and using parallel texts (mihalcea and pedersen, 2003).<papid> W03-0301 </papid></prevsent>
</prevsection>
<citsent citstr=" C00-2163 ">
the data is from the canadian hansard, and reference alignments were originally produced by franz och and hermann ney (och and ney, 2000).<papid> C00-2163 </papid></citsent>
<aftsection>
<nextsent>using the entire corpus (20 million words), we trainedenglishfrench and french english ibm4 models using giza++.
</nextsent>
<nextsent>for all sentences from the trial and test set (37 and 447 sentences), we generated up to 100 best alignments for each sentence and in each direction.
</nextsent>
<nextsent>for each pair of source and target words (fi, ej), the association measure mij is simply the number of times these words were aligned together in the two n-best lists, leading to count between 0 (never aligned) and 200 (always aligned).
</nextsent>
<nextsent>we focus on sentence 1023, from the trial set.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3637">
<title id=" P04-1064.xml">aligning words using matrix factorisation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>method ps rs fs pp rp fp aer onmf + aic 45.26% 94.67% 61.24% 86.56% 34.30% 49.14% 10.81% onmf + bic 42.69% 96.75% 59.24% 83.42% 35.82% 50.12% 12.50% table 1: performance on the 37 trial sentences for orthogonal non-negative matrix factorisation (onmf) using the aic and bic criterion for choosing the number of cepts, discounting null alignments.
</prevsent>
<prevsent>we also compared the performance on the 447test sentences to 1/ the intersection of the alignments produced by the top ibm4 alignments in either directions, and 2/ the best systems from (mi halcea and pedersen, 2003).<papid> W03-0301 </papid></prevsent>
</prevsection>
<citsent citstr=" W03-0304 ">
on limited resources, ralign.ef.1 (simard and langlais, 2003) <papid> W03-0304 </papid>produced the best -score, as well as the best aer when null alignments were taken into account, while xrce.nolem.ef.3 (dejean et al, 2003) <papid> W03-0305 </papid>produced the best aer when null alignments were dis counted.</citsent>
<aftsection>
<nextsent>tables 2 and 3 show that onmf improve son several of these results.
</nextsent>
<nextsent>in particular, we get better recall and -score on the probable alignments(and even better precision than ralign.ef.1 in table 2).
</nextsent>
<nextsent>on the other hand, the performance, and in particular the precision, on sure alignments is dismal.
</nextsent>
<nextsent>we attribute this at least partly to key difference between our model and the reference data: method ps rs fs pp rp fp aer onmf + aic 49.86% 95.12% 65.42% 84.63% 37.39% 51.87% 11.76% onmf + bic 46.50% 96.01% 62.65% 80.92% 38.69% 52.35% 14.16% ibm4 intersection 71.46% 90.04% 79.68% 97.66% 28.44% 44.12% 5.71% hlt-03 best 72.54% 80.61% 76.36% 77.56% 38.19% 51.18% 18.50% hlt-03 best aer 55.43% 93.81% 69.68% 90.09% 35.30% 50.72% 8.53%table 2: performance on the 447 english-french test sentences, discounting null alignments, for orthogonal non-negative matrix factorisation (onmf) using the aic and bic criterion for choosing the number of cepts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3638">
<title id=" P04-1064.xml">aligning words using matrix factorisation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>method ps rs fs pp rp fp aer onmf + aic 45.26% 94.67% 61.24% 86.56% 34.30% 49.14% 10.81% onmf + bic 42.69% 96.75% 59.24% 83.42% 35.82% 50.12% 12.50% table 1: performance on the 37 trial sentences for orthogonal non-negative matrix factorisation (onmf) using the aic and bic criterion for choosing the number of cepts, discounting null alignments.
</prevsent>
<prevsent>we also compared the performance on the 447test sentences to 1/ the intersection of the alignments produced by the top ibm4 alignments in either directions, and 2/ the best systems from (mi halcea and pedersen, 2003).<papid> W03-0301 </papid></prevsent>
</prevsection>
<citsent citstr=" W03-0305 ">
on limited resources, ralign.ef.1 (simard and langlais, 2003) <papid> W03-0304 </papid>produced the best -score, as well as the best aer when null alignments were taken into account, while xrce.nolem.ef.3 (dejean et al, 2003) <papid> W03-0305 </papid>produced the best aer when null alignments were dis counted.</citsent>
<aftsection>
<nextsent>tables 2 and 3 show that onmf improve son several of these results.
</nextsent>
<nextsent>in particular, we get better recall and -score on the probable alignments(and even better precision than ralign.ef.1 in table 2).
</nextsent>
<nextsent>on the other hand, the performance, and in particular the precision, on sure alignments is dismal.
</nextsent>
<nextsent>we attribute this at least partly to key difference between our model and the reference data: method ps rs fs pp rp fp aer onmf + aic 49.86% 95.12% 65.42% 84.63% 37.39% 51.87% 11.76% onmf + bic 46.50% 96.01% 62.65% 80.92% 38.69% 52.35% 14.16% ibm4 intersection 71.46% 90.04% 79.68% 97.66% 28.44% 44.12% 5.71% hlt-03 best 72.54% 80.61% 76.36% 77.56% 38.19% 51.18% 18.50% hlt-03 best aer 55.43% 93.81% 69.68% 90.09% 35.30% 50.72% 8.53%table 2: performance on the 447 english-french test sentences, discounting null alignments, for orthogonal non-negative matrix factorisation (onmf) using the aic and bic criterion for choosing the number of cepts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3655">
<title id=" P03-1016.xml">synonymous collocation extraction using translation information </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>synonymous collocations can be considered as an extension of the concept of synonymous expressions which conventionally include synonymous words, phrases and sentence patterns.
</prevsent>
<prevsent>synonymous expressions are very useful in number of nlp applications.
</prevsent>
</prevsection>
<citsent citstr=" C02-1084 ">
they are used in information retrieval and question answering (kiyota et al, 2002; <papid> C02-1084 </papid>drago mia et al, 2001) to bridge the expression gap between the query space and the document space.</citsent>
<aftsection>
<nextsent>for instance, buy book?
</nextsent>
<nextsent>extracted from the users?
</nextsent>
<nextsent>query should also in some way match order book?
</nextsent>
<nextsent>indexed in the documents.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3656">
<title id=" P03-1016.xml">synonymous collocation extraction using translation information </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>query should also in some way match order book?
</prevsent>
<prevsent>indexed in the documents.
</prevsent>
</prevsection>
<citsent citstr=" P98-1116 ">
besides, the synonymous expressions are also important in language generation (langkilde and knight, 1998) <papid> P98-1116 </papid>and computer assisted authoring to produce vivid texts.</citsent>
<aftsection>
<nextsent>up to now, there have been few researches which directly address the problem of extracting synonymous collocations.
</nextsent>
<nextsent>however, number of studies investigate the extraction of synonymous words from monolingual corpora (carolyn et al, 1992; grefenstatte, 1994; lin, 1998; <papid> P98-2127 </papid>gasperin et al, 2001).</nextsent>
<nextsent>the methods used the contexts around the investigated words to discover synonyms.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3657">
<title id=" P03-1016.xml">synonymous collocation extraction using translation information </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>besides, the synonymous expressions are also important in language generation (langkilde and knight, 1998) <papid> P98-1116 </papid>and computer assisted authoring to produce vivid texts.</prevsent>
<prevsent>up to now, there have been few researches which directly address the problem of extracting synonymous collocations.</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
however, number of studies investigate the extraction of synonymous words from monolingual corpora (carolyn et al, 1992; grefenstatte, 1994; lin, 1998; <papid> P98-2127 </papid>gasperin et al, 2001).</citsent>
<aftsection>
<nextsent>the methods used the contexts around the investigated words to discover synonyms.
</nextsent>
<nextsent>the problem of the methods is that the precision of the extracted synonymous words is low because it extracts many word pairs such as cat?
</nextsent>
<nextsent>and dog?, which are similar but not synonymous.
</nextsent>
<nextsent>in addition, some studies investigate the extraction of synonymous words and/or patterns from bilingual corpora (barzilay and mckeown, 2001; <papid> P01-1008 </papid>shimohata and sumita, 2002).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3658">
<title id=" P03-1016.xml">synonymous collocation extraction using translation information </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the problem of the methods is that the precision of the extracted synonymous words is low because it extracts many word pairs such as cat?
</prevsent>
<prevsent>and dog?, which are similar but not synonymous.
</prevsent>
</prevsection>
<citsent citstr=" P01-1008 ">
in addition, some studies investigate the extraction of synonymous words and/or patterns from bilingual corpora (barzilay and mckeown, 2001; <papid> P01-1008 </papid>shimohata and sumita, 2002).</citsent>
<aftsection>
<nextsent>however, these methods can only extract synonymous expressions which occur in the bilingual corpus.
</nextsent>
<nextsent>due to the limited size of the bilingual corpus, the coverage of the extracted expressions is very low.
</nextsent>
<nextsent>given the fact that we usually have large monolingual corpora (unlimited in some sense) and very limited bilingual corpora, this paper proposes method that tries to make full use of these different resources to get an optimal compromise of precision and coverage for synonymous collocation extraction.
</nextsent>
<nextsent>we first obtain candidates of synonymous collocation pairs based on monolingual corpus and word thesaurus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3659">
<title id=" P03-1016.xml">synonymous collocation extraction using translation information </title>
<section> our approach.  </section>
<citcontext>
<prevsection>
<prevsent>assumption 1: for chinese collocation ccol andre, we assume that e1 and e2 are conditionally independent.
</prevsent>
<prevsent>the translation model is rewritten as: )|(),|(),|( )|,,()|( 21 21 colecolecole colecolcol crpcrepcrep cerepcep = = (2) assumption 2: given chinese collocation  c1, rc, c2 , we assume that the translation probability p(ei|ccol) only depends on ei and ci (i=1,2), and p(re|ccol) only depends on re and rc.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
equation (2) is rewritten as: )|()|()|( )|()|()|()|( 2211 21 ce colecolcolcolcol rrpcepcep crpcepcepcep = = (3) it is equal to word translation model if we take the relation type in the collocations as an element like word, which is similar to model 1 in (brown et al, 1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>assumption 3: we assume that one type of english 2 some english collocations can be translated into chinese words, phrases or patterns.
</nextsent>
<nextsent>here we only consider the case of being translated into collocations.
</nextsent>
<nextsent>collocation can only be translated to the same type of chinese collocations3.
</nextsent>
<nextsent>thus, p(re| rc) =1 in our case.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3665">
<title id=" N12-3004.xml">surf shop combing a product ontology with topic model results for online window shopping </title>
<section> theme pages.  </section>
<citcontext>
<prevsection>
<prevsent>it includes clusters of product categories which exemplify the page theme, such as bread andjam or cheese and dairy.
</prevsent>
<prevsent>each theme page corresponds to hidden topic discovered by the lda model5.
</prevsent>
</prevsection>
<citsent citstr=" N10-1012 ">
human interpretation of topic models has been focus of some recent work (chang et al, 2009; newman et al, 2010; <papid> N10-1012 </papid>mimno et al, 2010).however, previous approaches concentrate on representing topic by its top most probable words.</citsent>
<aftsection>
<nextsent>in contrast, our goal is to illustrate topic by choosing the most representative documents from the collection, which also correspond to product categories associated with the topic.
</nextsent>
<nextsent>since this is novel task, we decided to concentrate on the issue of building and evaluating theme pages before conducting broader user studies of the prototype.
</nextsent>
<nextsent>there are few possible ways to select documents which best represent topic.
</nextsent>
<nextsent>the simplest would be to consider the rank of this topic in the document.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3666">
<title id=" P02-1032.xml">the descent of hierarchy and selection in relational semantics </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>several approaches have been proposed for empirical noun compound interpretation.
</prevsent>
<prevsent>lauer &amp; dras (1994)point out that there are three components to the prob lem: identification of the compound from within the text,syntactic analysis of the compound (left versus right association), and the interpretation of the underlying semantics.
</prevsent>
</prevsection>
<citsent citstr=" P95-1007 ">
several researchers have tackled the syntactic analysis (lauer, 1995), (<papid> P95-1007 </papid>pustejovsky et al, 1993), (<papid> J93-2005 </papid>liberman and church, 1992), usually using variation of theidea of finding the sub constituents elsewhere in the corpus and using those to predict how the larger compounds are structured.</citsent>
<aftsection>
<nextsent>we are interested in the third task, interpretation of the underlying semantics.
</nextsent>
<nextsent>most related work relies on handwritten rules of one kind or another.
</nextsent>
<nextsent>finin (1980) examines the problem of noun compound interpretation in detail, and constructs complex set of rules.
</nextsent>
<nextsent>vanderwende(1994) <papid> C94-2125 </papid>uses sophisticated system to extract semantic information automatically from an on-line dictionary, andthen manipulates set of hand-written rules with hand assigned weights to create an interpretation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3667">
<title id=" P02-1032.xml">the descent of hierarchy and selection in relational semantics </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>several approaches have been proposed for empirical noun compound interpretation.
</prevsent>
<prevsent>lauer &amp; dras (1994)point out that there are three components to the prob lem: identification of the compound from within the text,syntactic analysis of the compound (left versus right association), and the interpretation of the underlying semantics.
</prevsent>
</prevsection>
<citsent citstr=" J93-2005 ">
several researchers have tackled the syntactic analysis (lauer, 1995), (<papid> P95-1007 </papid>pustejovsky et al, 1993), (<papid> J93-2005 </papid>liberman and church, 1992), usually using variation of theidea of finding the sub constituents elsewhere in the corpus and using those to predict how the larger compounds are structured.</citsent>
<aftsection>
<nextsent>we are interested in the third task, interpretation of the underlying semantics.
</nextsent>
<nextsent>most related work relies on handwritten rules of one kind or another.
</nextsent>
<nextsent>finin (1980) examines the problem of noun compound interpretation in detail, and constructs complex set of rules.
</nextsent>
<nextsent>vanderwende(1994) <papid> C94-2125 </papid>uses sophisticated system to extract semantic information automatically from an on-line dictionary, andthen manipulates set of hand-written rules with hand assigned weights to create an interpretation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3668">
<title id=" P02-1032.xml">the descent of hierarchy and selection in relational semantics </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>most related work relies on handwritten rules of one kind or another.
</prevsent>
<prevsent>finin (1980) examines the problem of noun compound interpretation in detail, and constructs complex set of rules.
</prevsent>
</prevsection>
<citsent citstr=" C94-2125 ">
vanderwende(1994) <papid> C94-2125 </papid>uses sophisticated system to extract semantic information automatically from an on-line dictionary, andthen manipulates set of hand-written rules with hand assigned weights to create an interpretation.</citsent>
<aftsection>
<nextsent>rindflesch et al (2000) use hand-coded rule-based systems to extract the factual assertions from biomedical text.
</nextsent>
<nextsent>lapata (2000) classifies nominalizations according to whether the modifier is the subject or the object of the underlying verb expressed by the head noun.barker &amp; szpakowicz (1998) <papid> P98-1015 </papid>describe noun compounds as triplets of information: the first constituent, the second constituent, and marker that can indicate number of syntactic clues.</nextsent>
<nextsent>relations are initially assigned byhand, and then new ones are classified based on their similarity to previously classified ncs.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3669">
<title id=" P02-1032.xml">the descent of hierarchy and selection in relational semantics </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>vanderwende(1994) <papid> C94-2125 </papid>uses sophisticated system to extract semantic information automatically from an on-line dictionary, andthen manipulates set of hand-written rules with hand assigned weights to create an interpretation.</prevsent>
<prevsent>rindflesch et al (2000) use hand-coded rule-based systems to extract the factual assertions from biomedical text.</prevsent>
</prevsection>
<citsent citstr=" P98-1015 ">
lapata (2000) classifies nominalizations according to whether the modifier is the subject or the object of the underlying verb expressed by the head noun.barker &amp; szpakowicz (1998) <papid> P98-1015 </papid>describe noun compounds as triplets of information: the first constituent, the second constituent, and marker that can indicate number of syntactic clues.</citsent>
<aftsection>
<nextsent>relations are initially assigned byhand, and then new ones are classified based on their similarity to previously classified ncs.
</nextsent>
<nextsent>however, similarity at the lexical level means only that the same word occurs;no generalization over lexical items is made.
</nextsent>
<nextsent>the algorithm is assessed in terms of how much it speeds up the hand-labeling of relations.
</nextsent>
<nextsent>barrett et al (2001) have somewhat similar approach, using wordnet and creating heuristics about how to classify new nc given its similarity to one that has already been seen.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3670">
<title id=" P02-1032.xml">the descent of hierarchy and selection in relational semantics </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the algorithm is assessed in terms of how much it speeds up the hand-labeling of relations.
</prevsent>
<prevsent>barrett et al (2001) have somewhat similar approach, using wordnet and creating heuristics about how to classify new nc given its similarity to one that has already been seen.
</prevsent>
</prevsection>
<citsent citstr=" W01-0511 ">
in previous work (rosario and hearst, 2001), <papid> W01-0511 </papid>we demonstrated the utility of using lexical hierarchy for assigning relations to two-word noun compounds.</citsent>
<aftsection>
<nextsent>weuse machine learning algorithms and mesh to successfully generalize from training instances, achieving about60% accuracy on an 18-way classification problem using very small training set.
</nextsent>
<nextsent>that approach is bottom up and requires good coverage in the training set; the approach described in this paper is top-down, characterizing the lexical hierarchies explicitly rather than implicitly through machine learning algorithms.
</nextsent>
<nextsent>6.2 using lexical hierarchies.
</nextsent>
<nextsent>many approaches attempt to automatically assign semantic roles (such as case roles) by computing semantic similarity measures across large lexical hierarchy; primarily using wordnet (fellbaum, 1998).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3671">
<title id=" P02-1032.xml">the descent of hierarchy and selection in relational semantics </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>budanitsky &hirst; (2001) provide comparative analysis of such algo rithms.however, it is uncommon to simply use the hierarchy directly for generalization purposes.
</prevsent>
<prevsent>many researchers have noted that wordnets words are classified into senses that are too fine-grained for standard nlp tasks.
</prevsent>
</prevsection>
<citsent citstr=" W97-0205 ">
for example, buitelaar (1997) <papid> W97-0205 </papid>notes that the noun book is assigned to seven different senses, including fact and section, subdivision.</citsent>
<aftsection>
<nextsent>thus most users of wordnet must contend with the sense disambiguation issue in order to use the lexicon.
</nextsent>
<nextsent>the most closely related use of lexical hierarchy that we know of is that of li &amp; abe (1998), <papid> J98-2002 </papid>which uses an information-theoretic measure to make cut through the top levels of the noun portion of wordnet.</nextsent>
<nextsent>this isthen used to determine acceptable classes for verb argument structure, and for the prepositional phrase attachment problem and is found to perform as well as or better than existing algorithms.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3672">
<title id=" P02-1032.xml">the descent of hierarchy and selection in relational semantics </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>for example, buitelaar (1997) <papid> W97-0205 </papid>notes that the noun book is assigned to seven different senses, including fact and section, subdivision.</prevsent>
<prevsent>thus most users of wordnet must contend with the sense disambiguation issue in order to use the lexicon.</prevsent>
</prevsection>
<citsent citstr=" J98-2002 ">
the most closely related use of lexical hierarchy that we know of is that of li &amp; abe (1998), <papid> J98-2002 </papid>which uses an information-theoretic measure to make cut through the top levels of the noun portion of wordnet.</citsent>
<aftsection>
<nextsent>this isthen used to determine acceptable classes for verb argument structure, and for the prepositional phrase attachment problem and is found to perform as well as or better than existing algorithms.
</nextsent>
<nextsent>additionally, boggess et al (1991) tag?
</nextsent>
<nextsent>veterinary text using small set of semantic labels, assigned in much the same way parser works, and describe this in the context of prepositional phrase attachment.
</nextsent>
<nextsent>we have provided evidence that the upper levels of lexical hierarchy can be used to accurately classify the relations that hold between two-word technical noun compounds.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3673">
<title id=" P01-1039.xml">information extraction from voicemail </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>such as proper names, organizations, or numerics.
</prevsent>
<prevsent>though most of the earlier ie work was done in the context of text sources, recently great deal of work has also focused on extracting information from speech sources.
</prevsent>
</prevsection>
<citsent citstr=" A00-1044 ">
examples of this are the spoken document retrieval (sdr) task (nist, 1999), named entity (ne) extraction (darpa, 1999; miller et al, 2000; <papid> A00-1044 </papid>kim and woodland, 2000).</citsent>
<aftsection>
<nextsent>the sdr task focused on broadcast news and the ne task focused on both broadcast news and telephone conversations.in this paper, we focus on source of conversational speech data, voicemail, that is found in relatively large volumes in the real-world, andthat could benefit greatly from the use of ie techniques.
</nextsent>
<nextsent>the goal here is to query ones personal voicemail for items of information, without having to listen to the entire message.
</nextsent>
<nextsent>for instance,who called today??, or what is xs phone num ber??.
</nextsent>
<nextsent>because of the importance of these key pieces of information, in this paper, we focus precisely on extracting the identity and the phone number of the caller.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3674">
<title id=" P01-1039.xml">information extraction from voicemail </title>
<section> maximum entropy model.  </section>
<citcontext>
<prevsection>
<prevsent>it is the simplest ofthe systems presented, and achieves good performance level, but suffers from the fact that skilled person is required to identify the rules.
</prevsent>
<prevsent>maximum entropy modeling is powerful framework for constructing statistical models from data.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
it has been used in variety of difficult classification tasks such as part-of-speech tagging(ratnaparkhi, 1996), <papid> W96-0213 </papid>prepositional phrase attachment (ratnaparkhi et al, 1994) <papid> H94-1048 </papid>and named entity tagging (borthwick et al, 1998), <papid> M98-1018 </papid>and achieves state of the art performance.</citsent>
<aftsection>
<nextsent>in the following, we briefly describe the application of these models to extracting callers information from voicemail messages.the problem of extracting the information pertaining to the callers identity and phone number can be thought of as tagging problem, where thetags are callers identity,?
</nextsent>
<nextsent>callers phone num ber?
</nextsent>
<nextsent>and other.?
</nextsent>
<nextsent>the objective is to tag each word in message into one of these categories.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3675">
<title id=" P01-1039.xml">information extraction from voicemail </title>
<section> maximum entropy model.  </section>
<citcontext>
<prevsection>
<prevsent>it is the simplest ofthe systems presented, and achieves good performance level, but suffers from the fact that skilled person is required to identify the rules.
</prevsent>
<prevsent>maximum entropy modeling is powerful framework for constructing statistical models from data.
</prevsent>
</prevsection>
<citsent citstr=" H94-1048 ">
it has been used in variety of difficult classification tasks such as part-of-speech tagging(ratnaparkhi, 1996), <papid> W96-0213 </papid>prepositional phrase attachment (ratnaparkhi et al, 1994) <papid> H94-1048 </papid>and named entity tagging (borthwick et al, 1998), <papid> M98-1018 </papid>and achieves state of the art performance.</citsent>
<aftsection>
<nextsent>in the following, we briefly describe the application of these models to extracting callers information from voicemail messages.the problem of extracting the information pertaining to the callers identity and phone number can be thought of as tagging problem, where thetags are callers identity,?
</nextsent>
<nextsent>callers phone num ber?
</nextsent>
<nextsent>and other.?
</nextsent>
<nextsent>the objective is to tag each word in message into one of these categories.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3676">
<title id=" P01-1039.xml">information extraction from voicemail </title>
<section> maximum entropy model.  </section>
<citcontext>
<prevsection>
<prevsent>it is the simplest ofthe systems presented, and achieves good performance level, but suffers from the fact that skilled person is required to identify the rules.
</prevsent>
<prevsent>maximum entropy modeling is powerful framework for constructing statistical models from data.
</prevsent>
</prevsection>
<citsent citstr=" M98-1018 ">
it has been used in variety of difficult classification tasks such as part-of-speech tagging(ratnaparkhi, 1996), <papid> W96-0213 </papid>prepositional phrase attachment (ratnaparkhi et al, 1994) <papid> H94-1048 </papid>and named entity tagging (borthwick et al, 1998), <papid> M98-1018 </papid>and achieves state of the art performance.</citsent>
<aftsection>
<nextsent>in the following, we briefly describe the application of these models to extracting callers information from voicemail messages.the problem of extracting the information pertaining to the callers identity and phone number can be thought of as tagging problem, where thetags are callers identity,?
</nextsent>
<nextsent>callers phone num ber?
</nextsent>
<nextsent>and other.?
</nextsent>
<nextsent>the objective is to tag each word in message into one of these categories.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3678">
<title id=" P04-1018.xml">a mention synchronous coreference resolution algorithm based on the bell tree </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>group needs stronger ethics and new leadership.?
</prevsent>
<prevsent>american medical association?, its?
</prevsent>
</prevsection>
<citsent citstr=" W98-1119 ">
and group belong to the same entity as they refer to the same ob ject.early work of anaphora resolution focuses on finding antecedents of pronouns (hobbs, 1976; ge et al, 1998; <papid> W98-1119 </papid>mitkov, 1998), <papid> P98-2143 </papid>while recent advances (soon etal., 2001; <papid> J01-4004 </papid>yang et al, 2003; <papid> P03-1023 </papid>ng and cardie, 2002; <papid> P02-1014 </papid>ittycheriah et al, 2003) <papid> N03-2014 </papid>employ statistical machine learning methods and try to resolve reference among all kinds of noun phrases (np), be it name, nominal, or pronominal phrase ? which is the scope of this paper as well.</citsent>
<aftsection>
<nextsent>one common strategy shared by (soon et al, 2001; <papid> J01-4004 </papid>ng and cardie, 2002; <papid> P02-1014 </papid>ittycheriah et al, 2003) <papid> N03-2014 </papid>is that statistical model is trained to measure how likely pair of mentions corefer; then greedy procedure is followed to group mentions into entities.</nextsent>
<nextsent>while this approach has yielded encouraging results, the way mentions are linked is arguably sub optimal in that an instant decision is made when considering whether two mentions are linked or not.in this paper, we propose to use the bell tree to represent the process of forming entities from mentions.the bell tree represents the search space of the coreference resolution problem ? each leaf node corresponds to possible coreference outcome.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3679">
<title id=" P04-1018.xml">a mention synchronous coreference resolution algorithm based on the bell tree </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>group needs stronger ethics and new leadership.?
</prevsent>
<prevsent>american medical association?, its?
</prevsent>
</prevsection>
<citsent citstr=" P98-2143 ">
and group belong to the same entity as they refer to the same ob ject.early work of anaphora resolution focuses on finding antecedents of pronouns (hobbs, 1976; ge et al, 1998; <papid> W98-1119 </papid>mitkov, 1998), <papid> P98-2143 </papid>while recent advances (soon etal., 2001; <papid> J01-4004 </papid>yang et al, 2003; <papid> P03-1023 </papid>ng and cardie, 2002; <papid> P02-1014 </papid>ittycheriah et al, 2003) <papid> N03-2014 </papid>employ statistical machine learning methods and try to resolve reference among all kinds of noun phrases (np), be it name, nominal, or pronominal phrase ? which is the scope of this paper as well.</citsent>
<aftsection>
<nextsent>one common strategy shared by (soon et al, 2001; <papid> J01-4004 </papid>ng and cardie, 2002; <papid> P02-1014 </papid>ittycheriah et al, 2003) <papid> N03-2014 </papid>is that statistical model is trained to measure how likely pair of mentions corefer; then greedy procedure is followed to group mentions into entities.</nextsent>
<nextsent>while this approach has yielded encouraging results, the way mentions are linked is arguably sub optimal in that an instant decision is made when considering whether two mentions are linked or not.in this paper, we propose to use the bell tree to represent the process of forming entities from mentions.the bell tree represents the search space of the coreference resolution problem ? each leaf node corresponds to possible coreference outcome.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3680">
<title id=" P04-1018.xml">a mention synchronous coreference resolution algorithm based on the bell tree </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>group needs stronger ethics and new leadership.?
</prevsent>
<prevsent>american medical association?, its?
</prevsent>
</prevsection>
<citsent citstr=" J01-4004 ">
and group belong to the same entity as they refer to the same ob ject.early work of anaphora resolution focuses on finding antecedents of pronouns (hobbs, 1976; ge et al, 1998; <papid> W98-1119 </papid>mitkov, 1998), <papid> P98-2143 </papid>while recent advances (soon etal., 2001; <papid> J01-4004 </papid>yang et al, 2003; <papid> P03-1023 </papid>ng and cardie, 2002; <papid> P02-1014 </papid>ittycheriah et al, 2003) <papid> N03-2014 </papid>employ statistical machine learning methods and try to resolve reference among all kinds of noun phrases (np), be it name, nominal, or pronominal phrase ? which is the scope of this paper as well.</citsent>
<aftsection>
<nextsent>one common strategy shared by (soon et al, 2001; <papid> J01-4004 </papid>ng and cardie, 2002; <papid> P02-1014 </papid>ittycheriah et al, 2003) <papid> N03-2014 </papid>is that statistical model is trained to measure how likely pair of mentions corefer; then greedy procedure is followed to group mentions into entities.</nextsent>
<nextsent>while this approach has yielded encouraging results, the way mentions are linked is arguably sub optimal in that an instant decision is made when considering whether two mentions are linked or not.in this paper, we propose to use the bell tree to represent the process of forming entities from mentions.the bell tree represents the search space of the coreference resolution problem ? each leaf node corresponds to possible coreference outcome.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3681">
<title id=" P04-1018.xml">a mention synchronous coreference resolution algorithm based on the bell tree </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>group needs stronger ethics and new leadership.?
</prevsent>
<prevsent>american medical association?, its?
</prevsent>
</prevsection>
<citsent citstr=" P03-1023 ">
and group belong to the same entity as they refer to the same ob ject.early work of anaphora resolution focuses on finding antecedents of pronouns (hobbs, 1976; ge et al, 1998; <papid> W98-1119 </papid>mitkov, 1998), <papid> P98-2143 </papid>while recent advances (soon etal., 2001; <papid> J01-4004 </papid>yang et al, 2003; <papid> P03-1023 </papid>ng and cardie, 2002; <papid> P02-1014 </papid>ittycheriah et al, 2003) <papid> N03-2014 </papid>employ statistical machine learning methods and try to resolve reference among all kinds of noun phrases (np), be it name, nominal, or pronominal phrase ? which is the scope of this paper as well.</citsent>
<aftsection>
<nextsent>one common strategy shared by (soon et al, 2001; <papid> J01-4004 </papid>ng and cardie, 2002; <papid> P02-1014 </papid>ittycheriah et al, 2003) <papid> N03-2014 </papid>is that statistical model is trained to measure how likely pair of mentions corefer; then greedy procedure is followed to group mentions into entities.</nextsent>
<nextsent>while this approach has yielded encouraging results, the way mentions are linked is arguably sub optimal in that an instant decision is made when considering whether two mentions are linked or not.in this paper, we propose to use the bell tree to represent the process of forming entities from mentions.the bell tree represents the search space of the coreference resolution problem ? each leaf node corresponds to possible coreference outcome.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3682">
<title id=" P04-1018.xml">a mention synchronous coreference resolution algorithm based on the bell tree </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>group needs stronger ethics and new leadership.?
</prevsent>
<prevsent>american medical association?, its?
</prevsent>
</prevsection>
<citsent citstr=" P02-1014 ">
and group belong to the same entity as they refer to the same ob ject.early work of anaphora resolution focuses on finding antecedents of pronouns (hobbs, 1976; ge et al, 1998; <papid> W98-1119 </papid>mitkov, 1998), <papid> P98-2143 </papid>while recent advances (soon etal., 2001; <papid> J01-4004 </papid>yang et al, 2003; <papid> P03-1023 </papid>ng and cardie, 2002; <papid> P02-1014 </papid>ittycheriah et al, 2003) <papid> N03-2014 </papid>employ statistical machine learning methods and try to resolve reference among all kinds of noun phrases (np), be it name, nominal, or pronominal phrase ? which is the scope of this paper as well.</citsent>
<aftsection>
<nextsent>one common strategy shared by (soon et al, 2001; <papid> J01-4004 </papid>ng and cardie, 2002; <papid> P02-1014 </papid>ittycheriah et al, 2003) <papid> N03-2014 </papid>is that statistical model is trained to measure how likely pair of mentions corefer; then greedy procedure is followed to group mentions into entities.</nextsent>
<nextsent>while this approach has yielded encouraging results, the way mentions are linked is arguably sub optimal in that an instant decision is made when considering whether two mentions are linked or not.in this paper, we propose to use the bell tree to represent the process of forming entities from mentions.the bell tree represents the search space of the coreference resolution problem ? each leaf node corresponds to possible coreference outcome.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3684">
<title id=" P04-1018.xml">a mention synchronous coreference resolution algorithm based on the bell tree </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>group needs stronger ethics and new leadership.?
</prevsent>
<prevsent>american medical association?, its?
</prevsent>
</prevsection>
<citsent citstr=" N03-2014 ">
and group belong to the same entity as they refer to the same ob ject.early work of anaphora resolution focuses on finding antecedents of pronouns (hobbs, 1976; ge et al, 1998; <papid> W98-1119 </papid>mitkov, 1998), <papid> P98-2143 </papid>while recent advances (soon etal., 2001; <papid> J01-4004 </papid>yang et al, 2003; <papid> P03-1023 </papid>ng and cardie, 2002; <papid> P02-1014 </papid>ittycheriah et al, 2003) <papid> N03-2014 </papid>employ statistical machine learning methods and try to resolve reference among all kinds of noun phrases (np), be it name, nominal, or pronominal phrase ? which is the scope of this paper as well.</citsent>
<aftsection>
<nextsent>one common strategy shared by (soon et al, 2001; <papid> J01-4004 </papid>ng and cardie, 2002; <papid> P02-1014 </papid>ittycheriah et al, 2003) <papid> N03-2014 </papid>is that statistical model is trained to measure how likely pair of mentions corefer; then greedy procedure is followed to group mentions into entities.</nextsent>
<nextsent>while this approach has yielded encouraging results, the way mentions are linked is arguably sub optimal in that an instant decision is made when considering whether two mentions are linked or not.in this paper, we propose to use the bell tree to represent the process of forming entities from mentions.the bell tree represents the search space of the coreference resolution problem ? each leaf node corresponds to possible coreference outcome.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3692">
<title id=" P04-1018.xml">a mention synchronous coreference resolution algorithm based on the bell tree </title>
<section> coreference model.  </section>
<citcontext>
<prevsection>
<prevsent>u  &amp;\w + +    (9) from (7) to (8), entities other than the one in focus, 7 , are assumed to have no influence on the decision of linking +  with 7 .
</prevsent>
<prevsent>(9) further assumes that the entity-mention score can be obtained by the maximum mention pair score.
</prevsent>
</prevsection>
<citsent citstr=" P00-1023 ">
the model (9) is very similar to the model in (morton, 2000; <papid> P00-1023 </papid>soon et al, 2001; <papid> J01-4004 </papid>ng and cardie, 2002) <papid> P02-1014 </papid>while (8) has more conditions.</citsent>
<aftsection>
<nextsent>we use maximum entropy model (berger et al, 1996) <papid> J96-1002 </papid>for both the mention-pair model (9) and the entity-mention model (8): st</nextsent>
<nextsent>vuxw + , +    7# $ #%  &amp;(*) ,+-   - .0/1 2</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3698">
<title id=" P04-1018.xml">a mention synchronous coreference resolution algorithm based on the bell tree </title>
<section> coreference model.  </section>
<citcontext>
<prevsection>
<prevsent>(9) further assumes that the entity-mention score can be obtained by the maximum mention pair score.
</prevsent>
<prevsent>the model (9) is very similar to the model in (morton, 2000; <papid> P00-1023 </papid>soon et al, 2001; <papid> J01-4004 </papid>ng and cardie, 2002) <papid> P02-1014 </papid>while (8) has more conditions.</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
we use maximum entropy model (berger et al, 1996) <papid> J96-1002 </papid>for both the mention-pair model (9) and the entity-mention model (8): st</citsent>
<aftsection>
<nextsent>vuxw + , +    7# $ #%  &amp;(*) ,+-   - .0/1 2
</nextsent>
<nextsent>+ , +   (10) st
</nextsent>
<nextsent>u 7 g +    7#  $  %  &amp;(*)  -   - .0/ 1 2
</nextsent>
<nextsent>7 g +   (11) where 9
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3700">
<title id=" P04-1018.xml">a mention synchronous coreference resolution algorithm based on the bell tree </title>
<section> coreference model.  </section>
<citcontext>
<prevsection>
<prevsent>features in the lexical category are applicable tonon-pronominal mentions only.
</prevsent>
<prevsent>distance features characterize how far the two mentions are, either by the number of tokens, by the number of sentences, or bythe number of mentions in-between.
</prevsent>
</prevsection>
<citsent citstr=" W97-0301 ">
syntactic features are derived from parse trees output from maximum entropy parser (ratnaparkhi, 1997).<papid> W97-0301 </papid></citsent>
<aftsection>
<nextsent>the count?
</nextsent>
<nextsent>feature calculates how many times mention string isseen.
</nextsent>
<nextsent>for pronominal mentions, attributes such as gender, number, possessive ness and reflexive ness are also used.
</nextsent>
<nextsent>apart from basic features in table 1, composite features can be generated by taking conjunction of basic features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3701">
<title id=" P04-1018.xml">a mention synchronous coreference resolution algorithm based on the bell tree </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>sures the percentage of mentions that are in the right?
</prevsent>
<prevsent>entities.
</prevsent>
</prevsection>
<citsent citstr=" M95-1005 ">
for tests on the muc data, we report both f-measure using the official muc score (vilain et al, 1995) <papid> M95-1005 </papid>andecm-f.</citsent>
<aftsection>
<nextsent>the muc score counts the common links between the reference and the system output.
</nextsent>
<nextsent>5.2 results on the ace data.
</nextsent>
<nextsent>the system is first developed and tested using the ace data.
</nextsent>
<nextsent>the ace coreference system is trained with  &amp; documents (about &amp;bff words) of ace 2002 training data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3702">
<title id=" P04-1018.xml">a mention synchronous coreference resolution algorithm based on the bell tree </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>ace-value on the system mentions of ace 2003 evaluation data for chinese and arabic, respectively.
</prevsent>
<prevsent>the results for all three languages are among the top-tier submissionsystems.
</prevsent>
</prevsection>
<citsent citstr=" N04-1001 ">
details of the mention detection and coreference system can be found in (florian et al, 2004).<papid> N04-1001 </papid></citsent>
<aftsection>
<nextsent>since the mention-pair model is better, subsequent analyses are done with the mention pair model only.
</nextsent>
<nextsent>5.2.1 feature impact to see how each category of features affects the performance, we start with the aforementioned mention pair model, incrementally remove each feature category, retrain the system and test it on the devtest set.
</nextsent>
<nextsent>the result is summarized in table 4.
</nextsent>
<nextsent>the last column lists the number of features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3703">
<title id=" P04-1018.xml">a mention synchronous coreference resolution algorithm based on the bell tree </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>precision of links, which gives an #
</prevsent>
<prevsent>f-measure).
</prevsent>
</prevsection>
<citsent citstr=" N01-1008 ">
the muc6-small system compares favorably with the similar experiment in harabagiu et al (2001) <papid> N01-1008 </papid>in which an  &b;  </citsent>
<aftsection>
<nextsent>f-measure is reported.
</nextsent>
<nextsent>when measured by the ecm-f measure, the muc6-small system has the same level of performance as the ace system, while the muc6-big system performs better than the ace system.
</nextsent>
<nextsent>the results show that the algorithm works well on the muc6 data despite some information is lost inthe conversion from the muc format to the ace format.
</nextsent>
<nextsent>system muc f-measure ecm-f muc6-small 83.9% 72.1% muc6-big 85.7% 76.8% table 5: results on the muc6 formal test set.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3719">
<title id=" P04-1018.xml">a mention synchronous coreference resolution algorithm based on the bell tree </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, models in (mccallum and wellner, 2003) compute directly the probability of an entity configuration conditioned on mentions, and it is not clear how the models can be factored todo the incremental search, as it is impractical to enumerate all possible entities even for documents with amoderate number of mentions.
</prevsent>
<prevsent>the bell tree representation proposed in this paper, however, provides us witha naturally incremental framework for coreference res olution.maximum entropy method has been used in coreference resolution before.
</prevsent>
</prevsection>
<citsent citstr=" W97-0319 ">
for example, kehler (1997) <papid> W97-0319 </papid>uses mention-pair maximum entropy model, and two methods are proposed to compute entity scores basedon the mention-pair model: 1) distribution over entity space is deduced; 2) the most recent mention of an entity, together with the candidate mention, is used to compute the entity-mention score.</citsent>
<aftsection>
<nextsent>in contrast, in our mention pair model, an entity-mention pair is scored by taking the maximum score among possible mention pairs.
</nextsent>
<nextsent>our entity-mention model eliminates the need to synthesize an entity-mention score from mention-pair scores.
</nextsent>
<nextsent>morton (2000) <papid> P00-1023 </papid>also uses maximum entropy mention-pair model, and special dummy?</nextsent>
<nextsent>mention is used to model the event of starting new entity.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3721">
<title id=" P03-1064.xml">a snow based super tagger with application to np chunking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the use of supertags in np chunking gives rise to almost  absolute increase (from  to  ) in f-score under transformation based learning(tbl) frame.
</prevsent>
<prevsent>the surpertagger described here provides an effective and efficient way to exploit syntactic information.
</prevsent>
</prevsection>
<citsent citstr=" C94-1024 ">
in lexicalized tree-adjoining grammar (ltag) (joshi and schabes, 1997; xtag-group, 2001),each word in sentence is associated with an elementary tree, or super tag (joshi and srinivas, 1994).<papid> C94-1024 </papid></citsent>
<aftsection>
<nextsent>super tagging is the process of assigning the correct super tag to each word of an input sentence.the following two facts make super tagging attractive.
</nextsent>
<nextsent>firstly supertags encode much more syntactical information than pos tags, which makes super tagging useful pre-parsing tool, so-called, almost parsing (srinivas and joshi, 1999).
</nextsent>
<nextsent>on the 1by the correct super tag we mean the super tag that an ltag parser would assign to word in sentence.
</nextsent>
<nextsent>other hand, as the term supertagging?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3722">
<title id=" P03-1064.xml">a snow based super tagger with application to np chunking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>other hand, as the term supertagging?
</prevsent>
<prevsent>suggests, the time complexity of super tagging is similar to that ofpos tagging, which is linear in the length of the in put sentence.in this paper, we will focus on the np chunking task, and use it as an application of supertagging.
</prevsent>
</prevsection>
<citsent citstr=" W95-0107 ">
(abney, 1991) proposed two-phase parsing model which includes chunking and attaching.(ramshaw and marcus, 1995) <papid> W95-0107 </papid>approached chucking by using transformation based learning(tbl).many machine learning techniques have been successfully applied to chunking tasks, such as regularized winnow (zhang et al, 2001), <papid> P01-1069 </papid>svms (kudo and matsumoto, 2001), <papid> N01-1025 </papid>crfs (sha and pereira, 2003), <papid> N03-1028 </papid>maximum entropy model (collins, 2002), <papid> W02-1001 </papid>memory based learning (sang, 2002) and snow (munoz et al., 1999).<papid> W99-0621 </papid></citsent>
<aftsection>
<nextsent>the previous best result on chunking in literature was achieved by regularized winnow (zhang et al, 2001), <papid> P01-1069 </papid>which took some of the parsing results given by an english slot grammar-based parser as input to the chunker.</nextsent>
<nextsent>the use of parsing results contributed  absolute increase in f-score.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3725">
<title id=" P03-1064.xml">a snow based super tagger with application to np chunking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>other hand, as the term supertagging?
</prevsent>
<prevsent>suggests, the time complexity of super tagging is similar to that ofpos tagging, which is linear in the length of the in put sentence.in this paper, we will focus on the np chunking task, and use it as an application of supertagging.
</prevsent>
</prevsection>
<citsent citstr=" P01-1069 ">
(abney, 1991) proposed two-phase parsing model which includes chunking and attaching.(ramshaw and marcus, 1995) <papid> W95-0107 </papid>approached chucking by using transformation based learning(tbl).many machine learning techniques have been successfully applied to chunking tasks, such as regularized winnow (zhang et al, 2001), <papid> P01-1069 </papid>svms (kudo and matsumoto, 2001), <papid> N01-1025 </papid>crfs (sha and pereira, 2003), <papid> N03-1028 </papid>maximum entropy model (collins, 2002), <papid> W02-1001 </papid>memory based learning (sang, 2002) and snow (munoz et al., 1999).<papid> W99-0621 </papid></citsent>
<aftsection>
<nextsent>the previous best result on chunking in literature was achieved by regularized winnow (zhang et al, 2001), <papid> P01-1069 </papid>which took some of the parsing results given by an english slot grammar-based parser as input to the chunker.</nextsent>
<nextsent>the use of parsing results contributed  absolute increase in f-score.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3727">
<title id=" P03-1064.xml">a snow based super tagger with application to np chunking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>other hand, as the term supertagging?
</prevsent>
<prevsent>suggests, the time complexity of super tagging is similar to that ofpos tagging, which is linear in the length of the in put sentence.in this paper, we will focus on the np chunking task, and use it as an application of supertagging.
</prevsent>
</prevsection>
<citsent citstr=" N01-1025 ">
(abney, 1991) proposed two-phase parsing model which includes chunking and attaching.(ramshaw and marcus, 1995) <papid> W95-0107 </papid>approached chucking by using transformation based learning(tbl).many machine learning techniques have been successfully applied to chunking tasks, such as regularized winnow (zhang et al, 2001), <papid> P01-1069 </papid>svms (kudo and matsumoto, 2001), <papid> N01-1025 </papid>crfs (sha and pereira, 2003), <papid> N03-1028 </papid>maximum entropy model (collins, 2002), <papid> W02-1001 </papid>memory based learning (sang, 2002) and snow (munoz et al., 1999).<papid> W99-0621 </papid></citsent>
<aftsection>
<nextsent>the previous best result on chunking in literature was achieved by regularized winnow (zhang et al, 2001), <papid> P01-1069 </papid>which took some of the parsing results given by an english slot grammar-based parser as input to the chunker.</nextsent>
<nextsent>the use of parsing results contributed  absolute increase in f-score.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3728">
<title id=" P03-1064.xml">a snow based super tagger with application to np chunking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>other hand, as the term supertagging?
</prevsent>
<prevsent>suggests, the time complexity of super tagging is similar to that ofpos tagging, which is linear in the length of the in put sentence.in this paper, we will focus on the np chunking task, and use it as an application of supertagging.
</prevsent>
</prevsection>
<citsent citstr=" N03-1028 ">
(abney, 1991) proposed two-phase parsing model which includes chunking and attaching.(ramshaw and marcus, 1995) <papid> W95-0107 </papid>approached chucking by using transformation based learning(tbl).many machine learning techniques have been successfully applied to chunking tasks, such as regularized winnow (zhang et al, 2001), <papid> P01-1069 </papid>svms (kudo and matsumoto, 2001), <papid> N01-1025 </papid>crfs (sha and pereira, 2003), <papid> N03-1028 </papid>maximum entropy model (collins, 2002), <papid> W02-1001 </papid>memory based learning (sang, 2002) and snow (munoz et al., 1999).<papid> W99-0621 </papid></citsent>
<aftsection>
<nextsent>the previous best result on chunking in literature was achieved by regularized winnow (zhang et al, 2001), <papid> P01-1069 </papid>which took some of the parsing results given by an english slot grammar-based parser as input to the chunker.</nextsent>
<nextsent>the use of parsing results contributed  absolute increase in f-score.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3729">
<title id=" P03-1064.xml">a snow based super tagger with application to np chunking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>other hand, as the term supertagging?
</prevsent>
<prevsent>suggests, the time complexity of super tagging is similar to that ofpos tagging, which is linear in the length of the in put sentence.in this paper, we will focus on the np chunking task, and use it as an application of supertagging.
</prevsent>
</prevsection>
<citsent citstr=" W02-1001 ">
(abney, 1991) proposed two-phase parsing model which includes chunking and attaching.(ramshaw and marcus, 1995) <papid> W95-0107 </papid>approached chucking by using transformation based learning(tbl).many machine learning techniques have been successfully applied to chunking tasks, such as regularized winnow (zhang et al, 2001), <papid> P01-1069 </papid>svms (kudo and matsumoto, 2001), <papid> N01-1025 </papid>crfs (sha and pereira, 2003), <papid> N03-1028 </papid>maximum entropy model (collins, 2002), <papid> W02-1001 </papid>memory based learning (sang, 2002) and snow (munoz et al., 1999).<papid> W99-0621 </papid></citsent>
<aftsection>
<nextsent>the previous best result on chunking in literature was achieved by regularized winnow (zhang et al, 2001), <papid> P01-1069 </papid>which took some of the parsing results given by an english slot grammar-based parser as input to the chunker.</nextsent>
<nextsent>the use of parsing results contributed  absolute increase in f-score.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3730">
<title id=" P03-1064.xml">a snow based super tagger with application to np chunking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>other hand, as the term supertagging?
</prevsent>
<prevsent>suggests, the time complexity of super tagging is similar to that ofpos tagging, which is linear in the length of the in put sentence.in this paper, we will focus on the np chunking task, and use it as an application of supertagging.
</prevsent>
</prevsection>
<citsent citstr=" W99-0621 ">
(abney, 1991) proposed two-phase parsing model which includes chunking and attaching.(ramshaw and marcus, 1995) <papid> W95-0107 </papid>approached chucking by using transformation based learning(tbl).many machine learning techniques have been successfully applied to chunking tasks, such as regularized winnow (zhang et al, 2001), <papid> P01-1069 </papid>svms (kudo and matsumoto, 2001), <papid> N01-1025 </papid>crfs (sha and pereira, 2003), <papid> N03-1028 </papid>maximum entropy model (collins, 2002), <papid> W02-1001 </papid>memory based learning (sang, 2002) and snow (munoz et al., 1999).<papid> W99-0621 </papid></citsent>
<aftsection>
<nextsent>the previous best result on chunking in literature was achieved by regularized winnow (zhang et al, 2001), <papid> P01-1069 </papid>which took some of the parsing results given by an english slot grammar-based parser as input to the chunker.</nextsent>
<nextsent>the use of parsing results contributed  absolute increase in f-score.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3736">
<title id=" P03-1064.xml">a snow based super tagger with application to np chunking </title>
<section> super tagging and np chunking.  </section>
<citcontext>
<prevsection>
<prevsent>in (srinivas, 1997), super tagging was used for np chunking and it achieved an f-score of  .(chen, 2001) reported similar result with trigram supertagger.
</prevsent>
<prevsent>in their approaches, they first su per tagged the test data and then uesd heuristic rules to detect np chunks.
</prevsent>
</prevsection>
<citsent citstr=" N01-1006 ">
but it is hard to say whether it is the use of supertags or the heuristic rules that makes their system achieve the good results.as first attempt, we use fast tbl (ngai and florian, 2001), <papid> N01-1006 </papid>tbl program, to repeat ramshaw and marcus?</citsent>
<aftsection>
<nextsent>experiment on the standard dataset.
</nextsent>
<nextsent>thenwe use srinivas?
</nextsent>
<nextsent>super tagger (srinivas, 1997) to su pertag both the training and test data.
</nextsent>
<nextsent>we run thefast tbl for the second round by using supertags instead of pos tags in the dataset.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3739">
<title id=" P03-1064.xml">a snow based super tagger with application to np chunking </title>
<section> modeling super tagging.  </section>
<citcontext>
<prevsection>
<prevsent>the other approach is to as sign pos tags with traditional pos tagger first,and then use them as input to the supertagger.
</prevsent>
<prevsent>su per tagging an unknown word becomes problem for super tagging due to the huge size of the super tag set, hence we use the second approach in our paper.
</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
we first run the brill pos tagger (brill, 1995) <papid> J95-4004 </papid>on both the training and the test data, and use pos tags as part of the input.</citsent>
<aftsection>
<nextsent>let * [ 6 [ 1a88[ - be the sentence, \ * ] 6 ] 1a88 ] - be the pos tags, and s^*_v 6 v`1a88v - be the supertags respectively.
</nextsent>
<nextsent>given 7 \ , we can find the most likely super tag sequence given 7 \ by maximizing #%$ sa&amp;z 7 \ (b*c, . /21 #%$ d &amp; 6feee 9 6g7 7 \ ( = #6a$ 6 &amp; [ 6ff7 ] 6 ( analogous to pmm, we decompose #%$ d &amp; 6feee 9 6h7 7\)( into sub-classifiers.
</nextsent>
<nextsent>how ever, in our model, we divide it with respect to pos tags as follows #i$ d &amp; 6feee 9 6g7 7 \ (j #lkbmn$ d &amp; 6feee 9 6g7 7 \ ( (2) there are several reasons for decomposing #%$ d &amp; 6feee 9 6h7 7 \)( with respect to the pos tag ofthe current word, instead of the super tag of the previous word.
</nextsent>
<nextsent>o to avoid sparse-data problem.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3743">
<title id=" P03-1064.xml">a snow based super tagger with application to np chunking </title>
<section> modeling super tagging.  </section>
<citcontext>
<prevsection>
<prevsent>the value of feature of [ is set to 1 if this feature is active for [ , or 0 otherwise.
</prevsent>
<prevsent>4.4 related work.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
(chen, 2001) implemented an memm model for su per tagging which is analogous to the pos tagging model of (ratnaparkhi, 1996).<papid> W96-0213 </papid></citsent>
<aftsection>
<nextsent>the feature sets usedin the memm model were similar to ours.
</nextsent>
<nextsent>in addition, prefix and suffix features were used to handle rare words.
</nextsent>
<nextsent>several memm super taggers were implemented based on distinct feature sets.
</nextsent>
<nextsent>in (munoz et al, 1999), <papid> W99-0621 </papid>snow was used fortext chunking.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3751">
<title id=" P04-1051.xml">computing locally coherent discourses </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one central problem in discourse generation and summarisation is to structure the discourse in way that maximises coherence.
</prevsent>
<prevsent>coherence is the property of good human-authored text that makesit easier to read and understand than randomly ordered collection of sentences.
</prevsent>
</prevsection>
<citsent citstr=" W98-1411 ">
several papers in the recent literature (mellish etal., 1998; <papid> W98-1411 </papid>barzilay et al, 2002; karamanis and manurung, 2002; lapata, 2003; <papid> P03-1069 </papid>karamanis et al, 2004) <papid> P04-1050 </papid>have focused on defining local coherence, which evaluates the quality of sentence-to-sentence transitions.</citsent>
<aftsection>
<nextsent>this is in contrast to theories of global coherence, which can consider relations between larger chunks of the discourse and e.g. structures them into tree (mann and thompson, 1988; marcu, 1997; webber et al, 1999).
</nextsent>
<nextsent>measures of local coherence specify which ordering of the sentences makes for the most coherent discourse, and can be based e.g. on centering theory (walker et al, 1998; brennan et al, 1987; <papid> P87-1022 </papid>kibble and power, 2000; <papid> W00-1411 </papid>karamanis and manurung, 2002) or on statistical models (lap ata, 2003).<papid> P03-1069 </papid></nextsent>
<nextsent>but while formal models of local coherence have made substantial progress over the past few years,the question of how to efficiently compute an ordering of the sentences in discourse that maximises local coherence is still largely unsolved.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3752">
<title id=" P04-1051.xml">computing locally coherent discourses </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one central problem in discourse generation and summarisation is to structure the discourse in way that maximises coherence.
</prevsent>
<prevsent>coherence is the property of good human-authored text that makesit easier to read and understand than randomly ordered collection of sentences.
</prevsent>
</prevsection>
<citsent citstr=" P03-1069 ">
several papers in the recent literature (mellish etal., 1998; <papid> W98-1411 </papid>barzilay et al, 2002; karamanis and manurung, 2002; lapata, 2003; <papid> P03-1069 </papid>karamanis et al, 2004) <papid> P04-1050 </papid>have focused on defining local coherence, which evaluates the quality of sentence-to-sentence transitions.</citsent>
<aftsection>
<nextsent>this is in contrast to theories of global coherence, which can consider relations between larger chunks of the discourse and e.g. structures them into tree (mann and thompson, 1988; marcu, 1997; webber et al, 1999).
</nextsent>
<nextsent>measures of local coherence specify which ordering of the sentences makes for the most coherent discourse, and can be based e.g. on centering theory (walker et al, 1998; brennan et al, 1987; <papid> P87-1022 </papid>kibble and power, 2000; <papid> W00-1411 </papid>karamanis and manurung, 2002) or on statistical models (lap ata, 2003).<papid> P03-1069 </papid></nextsent>
<nextsent>but while formal models of local coherence have made substantial progress over the past few years,the question of how to efficiently compute an ordering of the sentences in discourse that maximises local coherence is still largely unsolved.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3753">
<title id=" P04-1051.xml">computing locally coherent discourses </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one central problem in discourse generation and summarisation is to structure the discourse in way that maximises coherence.
</prevsent>
<prevsent>coherence is the property of good human-authored text that makesit easier to read and understand than randomly ordered collection of sentences.
</prevsent>
</prevsection>
<citsent citstr=" P04-1050 ">
several papers in the recent literature (mellish etal., 1998; <papid> W98-1411 </papid>barzilay et al, 2002; karamanis and manurung, 2002; lapata, 2003; <papid> P03-1069 </papid>karamanis et al, 2004) <papid> P04-1050 </papid>have focused on defining local coherence, which evaluates the quality of sentence-to-sentence transitions.</citsent>
<aftsection>
<nextsent>this is in contrast to theories of global coherence, which can consider relations between larger chunks of the discourse and e.g. structures them into tree (mann and thompson, 1988; marcu, 1997; webber et al, 1999).
</nextsent>
<nextsent>measures of local coherence specify which ordering of the sentences makes for the most coherent discourse, and can be based e.g. on centering theory (walker et al, 1998; brennan et al, 1987; <papid> P87-1022 </papid>kibble and power, 2000; <papid> W00-1411 </papid>karamanis and manurung, 2002) or on statistical models (lap ata, 2003).<papid> P03-1069 </papid></nextsent>
<nextsent>but while formal models of local coherence have made substantial progress over the past few years,the question of how to efficiently compute an ordering of the sentences in discourse that maximises local coherence is still largely unsolved.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3754">
<title id=" P04-1051.xml">computing locally coherent discourses </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>several papers in the recent literature (mellish etal., 1998; <papid> W98-1411 </papid>barzilay et al, 2002; karamanis and manurung, 2002; lapata, 2003; <papid> P03-1069 </papid>karamanis et al, 2004) <papid> P04-1050 </papid>have focused on defining local coherence, which evaluates the quality of sentence-to-sentence transitions.</prevsent>
<prevsent>this is in contrast to theories of global coherence, which can consider relations between larger chunks of the discourse and e.g. structures them into tree (mann and thompson, 1988; marcu, 1997; webber et al, 1999).</prevsent>
</prevsection>
<citsent citstr=" P87-1022 ">
measures of local coherence specify which ordering of the sentences makes for the most coherent discourse, and can be based e.g. on centering theory (walker et al, 1998; brennan et al, 1987; <papid> P87-1022 </papid>kibble and power, 2000; <papid> W00-1411 </papid>karamanis and manurung, 2002) or on statistical models (lap ata, 2003).<papid> P03-1069 </papid></citsent>
<aftsection>
<nextsent>but while formal models of local coherence have made substantial progress over the past few years,the question of how to efficiently compute an ordering of the sentences in discourse that maximises local coherence is still largely unsolved.
</nextsent>
<nextsent>the fundamental problem is that any of the facto rial number of permutations of the sentences could be the optimal discourse, which makes for formidable search space for non trivial discourses.
</nextsent>
<nextsent>mellish et al.
</nextsent>
<nextsent>(1998) and karamanis and manurung (2002) present algorithms based on genetic programming,and lapata (2003) <papid> P03-1069 </papid>uses graph-based heuristic algorithm, but none of them can give any guarantees about the quality of the computed ordering.this paper presents the first algorithm that computes optimal locally coherent discourses, andes tablishes the complexity of the discourse orderingproblem.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3755">
<title id=" P04-1051.xml">computing locally coherent discourses </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>several papers in the recent literature (mellish etal., 1998; <papid> W98-1411 </papid>barzilay et al, 2002; karamanis and manurung, 2002; lapata, 2003; <papid> P03-1069 </papid>karamanis et al, 2004) <papid> P04-1050 </papid>have focused on defining local coherence, which evaluates the quality of sentence-to-sentence transitions.</prevsent>
<prevsent>this is in contrast to theories of global coherence, which can consider relations between larger chunks of the discourse and e.g. structures them into tree (mann and thompson, 1988; marcu, 1997; webber et al, 1999).</prevsent>
</prevsection>
<citsent citstr=" W00-1411 ">
measures of local coherence specify which ordering of the sentences makes for the most coherent discourse, and can be based e.g. on centering theory (walker et al, 1998; brennan et al, 1987; <papid> P87-1022 </papid>kibble and power, 2000; <papid> W00-1411 </papid>karamanis and manurung, 2002) or on statistical models (lap ata, 2003).<papid> P03-1069 </papid></citsent>
<aftsection>
<nextsent>but while formal models of local coherence have made substantial progress over the past few years,the question of how to efficiently compute an ordering of the sentences in discourse that maximises local coherence is still largely unsolved.
</nextsent>
<nextsent>the fundamental problem is that any of the facto rial number of permutations of the sentences could be the optimal discourse, which makes for formidable search space for non trivial discourses.
</nextsent>
<nextsent>mellish et al.
</nextsent>
<nextsent>(1998) and karamanis and manurung (2002) present algorithms based on genetic programming,and lapata (2003) <papid> P03-1069 </papid>uses graph-based heuristic algorithm, but none of them can give any guarantees about the quality of the computed ordering.this paper presents the first algorithm that computes optimal locally coherent discourses, andes tablishes the complexity of the discourse orderingproblem.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3762">
<title id=" P04-1051.xml">computing locally coherent discourses </title>
<section> the discourse ordering problem.  </section>
<citcontext>
<prevsection>
<prevsent>table 1 shows the most common classification into the four types continue, retain,smooth-shift, and rough-shift, which are predicted to be less and less coherent in this order (brennan et al, 1987).<papid> P87-1022 </papid></prevsent>
<prevsent>kibble and power (2000)<papid> W00-1411 </papid>define three further classes of transitions: coherence and salience, which are both defined in table 1 as well, and nocb, the class of transitions for which cb(ui) is undefined.</prevsent>
</prevsection>
<citsent citstr=" J99-3001 ">
finally, transition is considered to satisfy the cheapness constraint (strube and hahn, 1999) <papid> J99-3001 </papid>if cb(ui) = cp(ui1).</citsent>
<aftsection>
<nextsent>table 2 summarises some cost functions from the literature, in the reconstruction of karamanis et al (2004).<papid> P04-1050 </papid></nextsent>
<nextsent>each line shows the name of the coherence measure, the arity from definition 1, and the initial and transition cost functions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3776">
<title id=" P03-1029.xml">an improved extraction pattern representation model for automatic ie pattern acquisition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we describe discovery procedure for this model and demonstrate experimentally an improvement in recall using subtree patterns.
</prevsent>
<prevsent>information extraction (ie) is the process of identifying events or actions of interest and their participating entities from text.
</prevsent>
</prevsection>
<citsent citstr=" A00-1039 ">
as the field of ie has developed, the focus of study has moved towards automatic knowledge acquisition for information extraction, including domain-specific lexicons (riloff,1993; riloff and jones, 1999) and extraction patterns (riloff, 1996; yangarber et al, 2000; <papid> A00-1039 </papid>sudo et al, 2001)<papid> H01-1009 </papid></citsent>
<aftsection>
<nextsent>in particular, methods have recently emerged for the acquisition of event extraction patterns without corpus annotation in view of the cost of manual labor for annotation.
</nextsent>
<nextsent>however, there has been little study of alternative representation models of extraction patterns for unsupervised acquisition.
</nextsent>
<nextsent>in the prior work on extraction pattern acquisition, the representation model of the patterns was based on fixed set of pattern templates (riloff, 1996), or predicate-argument relations, such as subject-verb, and object-verb (yangarber et al, 2000).<papid> A00-1039 </papid></nextsent>
<nextsent>the model of our previous work (sudo et al, 2001)<papid> H01-1009 </papid>was based on the paths from predicate nodes in dependency trees.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3777">
<title id=" P03-1029.xml">an improved extraction pattern representation model for automatic ie pattern acquisition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we describe discovery procedure for this model and demonstrate experimentally an improvement in recall using subtree patterns.
</prevsent>
<prevsent>information extraction (ie) is the process of identifying events or actions of interest and their participating entities from text.
</prevsent>
</prevsection>
<citsent citstr=" H01-1009 ">
as the field of ie has developed, the focus of study has moved towards automatic knowledge acquisition for information extraction, including domain-specific lexicons (riloff,1993; riloff and jones, 1999) and extraction patterns (riloff, 1996; yangarber et al, 2000; <papid> A00-1039 </papid>sudo et al, 2001)<papid> H01-1009 </papid></citsent>
<aftsection>
<nextsent>in particular, methods have recently emerged for the acquisition of event extraction patterns without corpus annotation in view of the cost of manual labor for annotation.
</nextsent>
<nextsent>however, there has been little study of alternative representation models of extraction patterns for unsupervised acquisition.
</nextsent>
<nextsent>in the prior work on extraction pattern acquisition, the representation model of the patterns was based on fixed set of pattern templates (riloff, 1996), or predicate-argument relations, such as subject-verb, and object-verb (yangarber et al, 2000).<papid> A00-1039 </papid></nextsent>
<nextsent>the model of our previous work (sudo et al, 2001)<papid> H01-1009 </papid>was based on the paths from predicate nodes in dependency trees.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3797">
<title id=" N12-2009.xml">deep unsupervised feature learning for natural language processing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>?(~x) is feature representation for the input text ~x and the bottom row represents the output named entity tags in more standard form.
</prevsent>
<prevsent>is generally that features represent strong discriminating characteristics of the problem gained through manual engineering and domain-specific insight.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
as concrete example, consider the task of syntactic chunking, also called shallow parsing?, (gildea and jurafsky, 2002): <papid> J02-3001 </papid>given an input string, e.g. the cat sits on the mat?, the chunking problem consists of labelling segments of sentence with syntactic constituents such as noun or verb phrases (nps or vps).</citsent>
<aftsection>
<nextsent>each word is assigned one unique tag often encoded using the bio encoding1.
</nextsent>
<nextsent>we represent the input text as vector of words xi ? ~x, and each words corresponding label is represented by yi ? ~y (see table 1).
</nextsent>
<nextsent>given feature generating function ?(xi) and set of labelled training pairs (xi, yi) ? ? , the task then reduces to learning suitable mapping : ?(x ) ? .most previous works have focused on manually engineered features and simpler, linear models, including shallow?
</nextsent>
<nextsent>model architectures, like the perceptron (rosenblatt, 1957), linear svm (cortes and vap nik, 1995) and linear-chain conditional random fields(crfs) (lafferty, 2001).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3798">
<title id=" N12-2009.xml">deep unsupervised feature learning for natural language processing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>prior to2006, it was computationally infeasible to perform inference in hierarchical (deep?), non-linear models such as multi-layer perceptrons with more than one hidden layer.
</prevsent>
<prevsent>however, hinton (2006) proposed an efficient, layer-wise greedy method for learning the model parameters in these architectures, which spurred renewed interest in deep learning research.still, creating annotated training data is labour intensive and costly, and manually designing and extracting discriminating features from the data to be used inthe learning process is costly procedure requiring significant levels of domain expertise.
</prevsent>
</prevsection>
<citsent citstr=" J92-4003 ">
over the last two decades, the growth of available unlabeled data ? and the ubiquity of scalable computing power has shifted research focus to unsupervised approaches for automatically learning appropriate feature representations ?(x) from large collections of unlabeled text.several methods have been proposed for unsupervised feature learning, including simple k-means clustering (lloyd, 1982), brown clustering (brown et al, 1992),<papid> J92-4003 </papid>mutual information (shannon and weaver, 1962), principal components analysis (pca) (jolliffe, 2002), and independent component analysis (ica) (hyvarinen et al, 2001).</citsent>
<aftsection>
<nextsent>however, natural language has complex mappings from text to meaning, arguably involving higher-ordercorrelations between words which these simpler methods struggle to model adequately.
</nextsent>
<nextsent>advances in the deeplearning?
</nextsent>
<nextsent>community allow us to perform efficient unsupervised feature learning in highly complex and high dimensional input feature spaces, making it an attractive method for learning features in e.g. vision or language (bengio, 2009).
</nextsent>
<nextsent>the standard deep learning approach is to learnlower-dimensional embed dings from the raw high dimensional2 input space to lower dimensional (e.g.50-dimensional) feature spaces in an unsupervised manner, via repeated, layer-wise, non-linear transformation of the input features, e.g. y?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3800">
<title id=" P04-1007.xml">discriminative language modeling with conditional random fields and the perceptron algorithm </title>
<section> linear models, the perceptron.  </section>
<citcontext>
<prevsection>
<prevsent>in particular, we focus on how the decoding and parameter estimation problem scan be implemented over lattices using finite-state techniques.
</prevsent>
<prevsent>2.1 global linear models.
</prevsent>
</prevsection>
<citsent citstr=" W02-1001 ">
we follow the framework outlined in collins (2002), <papid> W02-1001 </papid>outlined in collins (2004).</citsent>
<aftsection>
<nextsent>the task is to learn mapping from inputs ? xto outputs ? . we assume the following compo nents: (1) training examples (xi, yi) for = 1 . . .
</nextsent>
<nextsent>n .(2) function gen which enumerates set of candidates gen(x) for an input x.
</nextsent>
<nextsent>(3) representation ? mapping each (x, y) ? ? to feature vector ?(x, y) ? rd.
</nextsent>
<nextsent>(4) parameter vector ??
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3805">
<title id=" P04-1007.xml">discriminative language modeling with conditional random fields and the perceptron algorithm </title>
<section> linear models, the perceptron.  </section>
<citcontext>
<prevsection>
<prevsent>t i/nt . freund and schapire (1999) originally proposed the averaged parameter method; it was shown to give substantial improvements inaccuracy for tagging tasks in collins (2002).<papid> W02-1001 </papid></prevsent>
<prevsent>2.3 conditional random fields.</prevsent>
</prevsection>
<citsent citstr=" P99-1069 ">
conditional random fields have been applied to nlp tasks such as parsing (ratnaparkhi et al, 1994; johnson et al, 1999), <papid> P99-1069 </papid>and tagging or segmentation tasks (lafferty et al, 2001; sha and pereira, 2003; <papid> N03-1028 </papid>mccallum and li, 2003; <papid> W03-0430 </papid>pinto et al, 2003).</citsent>
<aftsection>
<nextsent>crfs use the parameters ??
</nextsent>
<nextsent>to define conditional distribution over the members of gen(x) forgiven input x: p??(y|x) = 1 z(x, ??)
</nextsent>
<nextsent>exp (?(x, y) ? ??)
</nextsent>
<nextsent>where z(x, ??)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3806">
<title id=" P04-1007.xml">discriminative language modeling with conditional random fields and the perceptron algorithm </title>
<section> linear models, the perceptron.  </section>
<citcontext>
<prevsection>
<prevsent>t i/nt . freund and schapire (1999) originally proposed the averaged parameter method; it was shown to give substantial improvements inaccuracy for tagging tasks in collins (2002).<papid> W02-1001 </papid></prevsent>
<prevsent>2.3 conditional random fields.</prevsent>
</prevsection>
<citsent citstr=" N03-1028 ">
conditional random fields have been applied to nlp tasks such as parsing (ratnaparkhi et al, 1994; johnson et al, 1999), <papid> P99-1069 </papid>and tagging or segmentation tasks (lafferty et al, 2001; sha and pereira, 2003; <papid> N03-1028 </papid>mccallum and li, 2003; <papid> W03-0430 </papid>pinto et al, 2003).</citsent>
<aftsection>
<nextsent>crfs use the parameters ??
</nextsent>
<nextsent>to define conditional distribution over the members of gen(x) forgiven input x: p??(y|x) = 1 z(x, ??)
</nextsent>
<nextsent>exp (?(x, y) ? ??)
</nextsent>
<nextsent>where z(x, ??)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3807">
<title id=" P04-1007.xml">discriminative language modeling with conditional random fields and the perceptron algorithm </title>
<section> linear models, the perceptron.  </section>
<citcontext>
<prevsection>
<prevsent>t i/nt . freund and schapire (1999) originally proposed the averaged parameter method; it was shown to give substantial improvements inaccuracy for tagging tasks in collins (2002).<papid> W02-1001 </papid></prevsent>
<prevsent>2.3 conditional random fields.</prevsent>
</prevsection>
<citsent citstr=" W03-0430 ">
conditional random fields have been applied to nlp tasks such as parsing (ratnaparkhi et al, 1994; johnson et al, 1999), <papid> P99-1069 </papid>and tagging or segmentation tasks (lafferty et al, 2001; sha and pereira, 2003; <papid> N03-1028 </papid>mccallum and li, 2003; <papid> W03-0430 </papid>pinto et al, 2003).</citsent>
<aftsection>
<nextsent>crfs use the parameters ??
</nextsent>
<nextsent>to define conditional distribution over the members of gen(x) forgiven input x: p??(y|x) = 1 z(x, ??)
</nextsent>
<nextsent>exp (?(x, y) ? ??)
</nextsent>
<nextsent>where z(x, ??)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3809">
<title id=" P04-1007.xml">discriminative language modeling with conditional random fields and the perceptron algorithm </title>
<section> linear models, the perceptron.  </section>
<citcontext>
<prevsection>
<prevsent>we use limited memory variable metric method (benson and more?, 2002) to optimize llr.
</prevsent>
<prevsent>there is general implementation of this method in the tao/petsc software libraries (balay et al, 2002; benson et al,2002).
</prevsent>
</prevsection>
<citsent citstr=" W02-2018 ">
this technique has been shown to be very effective in variety of nlp tasks (malouf, 2002; <papid> W02-2018 </papid>wallach, 2002).</citsent>
<aftsection>
<nextsent>the main interface between the optimizer and the training data is procedure which takes parameter vector ??
</nextsent>
<nextsent>as input, and in turn returns llr(??)
</nextsent>
<nextsent>as well asthe gradient of llr at ??.
</nextsent>
<nextsent>the derivative of the objective function with respect to parameter at parameter values ??
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3810">
<title id=" P04-1007.xml">discriminative language modeling with conditional random fields and the perceptron algorithm </title>
<section> linear models for speech recognition.  </section>
<citcontext>
<prevsection>
<prevsent>d which assign weights to the n-gram features as well as the baseline feature 0.before describing methods for training discriminative language model using perceptron and crf algorithms, we give little more detail about the structure of d, focusing on how n-gram language models can be implemented with finite-state techniques.
</prevsent>
<prevsent>3.3 representation of n-gram language models.
</prevsent>
</prevsection>
<citsent citstr=" P03-1006 ">
an n-gram model can be efficiently represented in deterministic wfa, through the use of failure transitions (allauzen et al, 2003).<papid> P03-1006 </papid></citsent>
<aftsection>
<nextsent>every string accepted by such an automaton has single path through the automaton, and the weight of the string is the sum of the weights of the transitions in that path.
</nextsent>
<nextsent>in such representation, every state in the automaton represents an n-gram history h, e.g. wi2wi1, and there are transitions leaving the state for every word wi such that the feature hwi has weight.
</nextsent>
<nextsent>there is also failure transition leaving the state, labeled with some reserved symbol ?, which can only be traversed if the next symbol in the input does not match any transition leaving the state.
</nextsent>
<nextsent>this failure transition points to the backoff state h?, i.e. the n-gram history minus its initial word.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3813">
<title id=" N12-1090.xml">translation based projection for multilingual coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>specifically, for each new language of interest, one has to hire native speakers ofthe language to go through the labor-intensive, time consuming process of hand-annotating potentially large number of documents with coreference annotation before supervised re solver can be trained.
</prevsent>
<prevsent>one may argue that potential solution to this corpus annotation bottleneck is to employ an unsupervised or heuristic approach to coreference resolution, especially in light of the fact that they have recently started to rival their supervised counterparts.however, by adopting these approaches, we are simply replacing the corpus annotation bottleneck by another, possibly equally serious, bottleneck, the knowledge acquisition bottleneck.
</prevsent>
</prevsection>
<citsent citstr=" D08-1068 ">
specifically, in these approaches, one has to employ knowledge of the target language to design coreference rules (e.g.,mitkov (1999), poon and domingos (2008), <papid> D08-1068 </papid>raghunathan et al  (2010)) <papid> D10-1048 </papid>or sophisticated generative models (e.g., haghighi and klein (2007), <papid> P07-1107 </papid>haghighi and klein (2010), <papid> N10-1061 </papid>ng (2008)) <papid> D08-1067 </papid>to combine the available knowledge sources.</citsent>
<aftsection>
<nextsent>one could argue that designing coreference rules and generative models may not be as time consuming as annotating large coreference corpus.
</nextsent>
<nextsent>this may be true for well-studied language like english, where we can easily compose rule that disallows coreference between two mentions if they disagree in number and gender, for instance.
</nextsent>
<nextsent>how ever, computing these features may not be as simple as we hope for language like chinese: the lack of morphology complicates the determination of number information, and the fact that most chinese first names are used by both genders makes gender determination difficult.
</nextsent>
<nextsent>the difficulty inaccurately computing features translates to difficulties in composing coreference rules: for example, the aforementioned rule involving gender and number agreement, as well as rules that implement traditional linguistic 720constraints on coreference, may no longer be accurate and desirable to have if the features involved cannot be accurately computed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3814">
<title id=" N12-1090.xml">translation based projection for multilingual coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>specifically, for each new language of interest, one has to hire native speakers ofthe language to go through the labor-intensive, time consuming process of hand-annotating potentially large number of documents with coreference annotation before supervised re solver can be trained.
</prevsent>
<prevsent>one may argue that potential solution to this corpus annotation bottleneck is to employ an unsupervised or heuristic approach to coreference resolution, especially in light of the fact that they have recently started to rival their supervised counterparts.however, by adopting these approaches, we are simply replacing the corpus annotation bottleneck by another, possibly equally serious, bottleneck, the knowledge acquisition bottleneck.
</prevsent>
</prevsection>
<citsent citstr=" D10-1048 ">
specifically, in these approaches, one has to employ knowledge of the target language to design coreference rules (e.g.,mitkov (1999), poon and domingos (2008), <papid> D08-1068 </papid>raghunathan et al  (2010)) <papid> D10-1048 </papid>or sophisticated generative models (e.g., haghighi and klein (2007), <papid> P07-1107 </papid>haghighi and klein (2010), <papid> N10-1061 </papid>ng (2008)) <papid> D08-1067 </papid>to combine the available knowledge sources.</citsent>
<aftsection>
<nextsent>one could argue that designing coreference rules and generative models may not be as time consuming as annotating large coreference corpus.
</nextsent>
<nextsent>this may be true for well-studied language like english, where we can easily compose rule that disallows coreference between two mentions if they disagree in number and gender, for instance.
</nextsent>
<nextsent>how ever, computing these features may not be as simple as we hope for language like chinese: the lack of morphology complicates the determination of number information, and the fact that most chinese first names are used by both genders makes gender determination difficult.
</nextsent>
<nextsent>the difficulty inaccurately computing features translates to difficulties in composing coreference rules: for example, the aforementioned rule involving gender and number agreement, as well as rules that implement traditional linguistic 720constraints on coreference, may no longer be accurate and desirable to have if the features involved cannot be accurately computed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3815">
<title id=" N12-1090.xml">translation based projection for multilingual coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>specifically, for each new language of interest, one has to hire native speakers ofthe language to go through the labor-intensive, time consuming process of hand-annotating potentially large number of documents with coreference annotation before supervised re solver can be trained.
</prevsent>
<prevsent>one may argue that potential solution to this corpus annotation bottleneck is to employ an unsupervised or heuristic approach to coreference resolution, especially in light of the fact that they have recently started to rival their supervised counterparts.however, by adopting these approaches, we are simply replacing the corpus annotation bottleneck by another, possibly equally serious, bottleneck, the knowledge acquisition bottleneck.
</prevsent>
</prevsection>
<citsent citstr=" P07-1107 ">
specifically, in these approaches, one has to employ knowledge of the target language to design coreference rules (e.g.,mitkov (1999), poon and domingos (2008), <papid> D08-1068 </papid>raghunathan et al  (2010)) <papid> D10-1048 </papid>or sophisticated generative models (e.g., haghighi and klein (2007), <papid> P07-1107 </papid>haghighi and klein (2010), <papid> N10-1061 </papid>ng (2008)) <papid> D08-1067 </papid>to combine the available knowledge sources.</citsent>
<aftsection>
<nextsent>one could argue that designing coreference rules and generative models may not be as time consuming as annotating large coreference corpus.
</nextsent>
<nextsent>this may be true for well-studied language like english, where we can easily compose rule that disallows coreference between two mentions if they disagree in number and gender, for instance.
</nextsent>
<nextsent>how ever, computing these features may not be as simple as we hope for language like chinese: the lack of morphology complicates the determination of number information, and the fact that most chinese first names are used by both genders makes gender determination difficult.
</nextsent>
<nextsent>the difficulty inaccurately computing features translates to difficulties in composing coreference rules: for example, the aforementioned rule involving gender and number agreement, as well as rules that implement traditional linguistic 720constraints on coreference, may no longer be accurate and desirable to have if the features involved cannot be accurately computed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3816">
<title id=" N12-1090.xml">translation based projection for multilingual coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>specifically, for each new language of interest, one has to hire native speakers ofthe language to go through the labor-intensive, time consuming process of hand-annotating potentially large number of documents with coreference annotation before supervised re solver can be trained.
</prevsent>
<prevsent>one may argue that potential solution to this corpus annotation bottleneck is to employ an unsupervised or heuristic approach to coreference resolution, especially in light of the fact that they have recently started to rival their supervised counterparts.however, by adopting these approaches, we are simply replacing the corpus annotation bottleneck by another, possibly equally serious, bottleneck, the knowledge acquisition bottleneck.
</prevsent>
</prevsection>
<citsent citstr=" N10-1061 ">
specifically, in these approaches, one has to employ knowledge of the target language to design coreference rules (e.g.,mitkov (1999), poon and domingos (2008), <papid> D08-1068 </papid>raghunathan et al  (2010)) <papid> D10-1048 </papid>or sophisticated generative models (e.g., haghighi and klein (2007), <papid> P07-1107 </papid>haghighi and klein (2010), <papid> N10-1061 </papid>ng (2008)) <papid> D08-1067 </papid>to combine the available knowledge sources.</citsent>
<aftsection>
<nextsent>one could argue that designing coreference rules and generative models may not be as time consuming as annotating large coreference corpus.
</nextsent>
<nextsent>this may be true for well-studied language like english, where we can easily compose rule that disallows coreference between two mentions if they disagree in number and gender, for instance.
</nextsent>
<nextsent>how ever, computing these features may not be as simple as we hope for language like chinese: the lack of morphology complicates the determination of number information, and the fact that most chinese first names are used by both genders makes gender determination difficult.
</nextsent>
<nextsent>the difficulty inaccurately computing features translates to difficulties in composing coreference rules: for example, the aforementioned rule involving gender and number agreement, as well as rules that implement traditional linguistic 720constraints on coreference, may no longer be accurate and desirable to have if the features involved cannot be accurately computed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3817">
<title id=" N12-1090.xml">translation based projection for multilingual coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>specifically, for each new language of interest, one has to hire native speakers ofthe language to go through the labor-intensive, time consuming process of hand-annotating potentially large number of documents with coreference annotation before supervised re solver can be trained.
</prevsent>
<prevsent>one may argue that potential solution to this corpus annotation bottleneck is to employ an unsupervised or heuristic approach to coreference resolution, especially in light of the fact that they have recently started to rival their supervised counterparts.however, by adopting these approaches, we are simply replacing the corpus annotation bottleneck by another, possibly equally serious, bottleneck, the knowledge acquisition bottleneck.
</prevsent>
</prevsection>
<citsent citstr=" D08-1067 ">
specifically, in these approaches, one has to employ knowledge of the target language to design coreference rules (e.g.,mitkov (1999), poon and domingos (2008), <papid> D08-1068 </papid>raghunathan et al  (2010)) <papid> D10-1048 </papid>or sophisticated generative models (e.g., haghighi and klein (2007), <papid> P07-1107 </papid>haghighi and klein (2010), <papid> N10-1061 </papid>ng (2008)) <papid> D08-1067 </papid>to combine the available knowledge sources.</citsent>
<aftsection>
<nextsent>one could argue that designing coreference rules and generative models may not be as time consuming as annotating large coreference corpus.
</nextsent>
<nextsent>this may be true for well-studied language like english, where we can easily compose rule that disallows coreference between two mentions if they disagree in number and gender, for instance.
</nextsent>
<nextsent>how ever, computing these features may not be as simple as we hope for language like chinese: the lack of morphology complicates the determination of number information, and the fact that most chinese first names are used by both genders makes gender determination difficult.
</nextsent>
<nextsent>the difficulty inaccurately computing features translates to difficulties in composing coreference rules: for example, the aforementioned rule involving gender and number agreement, as well as rules that implement traditional linguistic 720constraints on coreference, may no longer be accurate and desirable to have if the features involved cannot be accurately computed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3818">
<title id=" N12-1090.xml">translation based projection for multilingual coreference resolution </title>
<section> related work on projection.  </section>
<citcontext>
<prevsection>
<prevsent>our goal in this paper is to explore the extent to which projection, which does not require that we have any knowledge of the target language,can push the limits of multilingual coreference resolution.
</prevsent>
<prevsent>if our results indicate that projection is promising approach, then the automatic coreference annotations it produces can be used to augment the manual annotations that capture the properties specific to the target language, thus alleviating the corpus annotation bottleneck.
</prevsent>
</prevsection>
<citsent citstr=" N01-1026 ">
the idea of projecting annotations from resource rich language to resource-scarce language was originally proposed by yarowsky and ngai (2001) <papid> N01-1026 </papid>and subsequently developed by others (e.g., resnik(2004), hwa et al  (2005)).</citsent>
<aftsection>
<nextsent>these projection algorithms assume as input parallel corpus for the source language and the target language.
</nextsent>
<nextsent>given the recent availability of machine translation (mt) services on the web, researchers have focused more on translated-based projection rather than acquiring parallel corpus themselves.
</nextsent>
<nextsent>mt-based projection has been applied to various nlp tasks, such as part of-speech tagging (e.g., das and petrov (2011)), <papid> P11-1061 </papid>mention detection (e.g., zitouni and florian (2008)), <papid> D08-1063 </papid>and sentiment analysis (e.g., mihalcea et al  (2007)).<papid> P07-1123 </papid>there have been two initial attempts to apply projection to create coreference-annotated data for aresource-poor language, both of which involve projecting hand-annotated coreference data from english to romanian via parallel corpus.</nextsent>
<nextsent>specifically,harabagiu and maiorano (2000) <papid> A00-1020 </papid>create an english romanian corpus by manually translating the muc 6 corpus into romanian and manually project the english annotations to romanian.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3820">
<title id=" N12-1090.xml">translation based projection for multilingual coreference resolution </title>
<section> related work on projection.  </section>
<citcontext>
<prevsection>
<prevsent>these projection algorithms assume as input parallel corpus for the source language and the target language.
</prevsent>
<prevsent>given the recent availability of machine translation (mt) services on the web, researchers have focused more on translated-based projection rather than acquiring parallel corpus themselves.
</prevsent>
</prevsection>
<citsent citstr=" P11-1061 ">
mt-based projection has been applied to various nlp tasks, such as part of-speech tagging (e.g., das and petrov (2011)), <papid> P11-1061 </papid>mention detection (e.g., zitouni and florian (2008)), <papid> D08-1063 </papid>and sentiment analysis (e.g., mihalcea et al  (2007)).<papid> P07-1123 </papid>there have been two initial attempts to apply projection to create coreference-annotated data for aresource-poor language, both of which involve projecting hand-annotated coreference data from english to romanian via parallel corpus.</citsent>
<aftsection>
<nextsent>specifically,harabagiu and maiorano (2000) <papid> A00-1020 </papid>create an english romanian corpus by manually translating the muc 6 corpus into romanian and manually project the english annotations to romanian.</nextsent>
<nextsent>on the other hand, postolache et al  (2006) apply word alignment algorithm to project the hand-annotated english coreference chains and then manually fix the projection errors on the romanian side.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3821">
<title id=" N12-1090.xml">translation based projection for multilingual coreference resolution </title>
<section> related work on projection.  </section>
<citcontext>
<prevsection>
<prevsent>these projection algorithms assume as input parallel corpus for the source language and the target language.
</prevsent>
<prevsent>given the recent availability of machine translation (mt) services on the web, researchers have focused more on translated-based projection rather than acquiring parallel corpus themselves.
</prevsent>
</prevsection>
<citsent citstr=" D08-1063 ">
mt-based projection has been applied to various nlp tasks, such as part of-speech tagging (e.g., das and petrov (2011)), <papid> P11-1061 </papid>mention detection (e.g., zitouni and florian (2008)), <papid> D08-1063 </papid>and sentiment analysis (e.g., mihalcea et al  (2007)).<papid> P07-1123 </papid>there have been two initial attempts to apply projection to create coreference-annotated data for aresource-poor language, both of which involve projecting hand-annotated coreference data from english to romanian via parallel corpus.</citsent>
<aftsection>
<nextsent>specifically,harabagiu and maiorano (2000) <papid> A00-1020 </papid>create an english romanian corpus by manually translating the muc 6 corpus into romanian and manually project the english annotations to romanian.</nextsent>
<nextsent>on the other hand, postolache et al  (2006) apply word alignment algorithm to project the hand-annotated english coreference chains and then manually fix the projection errors on the romanian side.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3822">
<title id=" N12-1090.xml">translation based projection for multilingual coreference resolution </title>
<section> related work on projection.  </section>
<citcontext>
<prevsection>
<prevsent>these projection algorithms assume as input parallel corpus for the source language and the target language.
</prevsent>
<prevsent>given the recent availability of machine translation (mt) services on the web, researchers have focused more on translated-based projection rather than acquiring parallel corpus themselves.
</prevsent>
</prevsection>
<citsent citstr=" P07-1123 ">
mt-based projection has been applied to various nlp tasks, such as part of-speech tagging (e.g., das and petrov (2011)), <papid> P11-1061 </papid>mention detection (e.g., zitouni and florian (2008)), <papid> D08-1063 </papid>and sentiment analysis (e.g., mihalcea et al  (2007)).<papid> P07-1123 </papid>there have been two initial attempts to apply projection to create coreference-annotated data for aresource-poor language, both of which involve projecting hand-annotated coreference data from english to romanian via parallel corpus.</citsent>
<aftsection>
<nextsent>specifically,harabagiu and maiorano (2000) <papid> A00-1020 </papid>create an english romanian corpus by manually translating the muc 6 corpus into romanian and manually project the english annotations to romanian.</nextsent>
<nextsent>on the other hand, postolache et al  (2006) apply word alignment algorithm to project the hand-annotated english coreference chains and then manually fix the projection errors on the romanian side.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3823">
<title id=" N12-1090.xml">translation based projection for multilingual coreference resolution </title>
<section> related work on projection.  </section>
<citcontext>
<prevsection>
<prevsent>given the recent availability of machine translation (mt) services on the web, researchers have focused more on translated-based projection rather than acquiring parallel corpus themselves.
</prevsent>
<prevsent>mt-based projection has been applied to various nlp tasks, such as part of-speech tagging (e.g., das and petrov (2011)), <papid> P11-1061 </papid>mention detection (e.g., zitouni and florian (2008)), <papid> D08-1063 </papid>and sentiment analysis (e.g., mihalcea et al  (2007)).<papid> P07-1123 </papid>there have been two initial attempts to apply projection to create coreference-annotated data for aresource-poor language, both of which involve projecting hand-annotated coreference data from english to romanian via parallel corpus.</prevsent>
</prevsection>
<citsent citstr=" A00-1020 ">
specifically,harabagiu and maiorano (2000) <papid> A00-1020 </papid>create an english romanian corpus by manually translating the muc 6 corpus into romanian and manually project the english annotations to romanian.</citsent>
<aftsection>
<nextsent>on the other hand, postolache et al  (2006) apply word alignment algorithm to project the hand-annotated english coreference chains and then manually fix the projection errors on the romanian side.
</nextsent>
<nextsent>hence,their goal is different from ours in at least two respects.
</nextsent>
<nextsent>first, while they employ significant knowledge of the target language to create clean coreference corpus, we examine the quality of coreference annotated data created via an entirely automatic process, determining quality by the performance of the re solver trained on the data.
</nextsent>
<nextsent>second, unlike ours, neither of these attempts is at the level of defininga technology for projection annotations that can potentially be deployed across large number of languages without coreference-annotated data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3824">
<title id=" N12-1090.xml">translation based projection for multilingual coreference resolution </title>
<section> translation-based projection.  </section>
<citcontext>
<prevsection>
<prevsent>in this setting, we assume that we do not have access to any french tagger that we can exploit to improve projection.
</prevsent>
<prevsent>hence, all we can do is to employ the three steps involved in the projection approach as described at the beginning of this section to create coreference-annotated data for french.
</prevsent>
</prevsection>
<citsent citstr=" P10-2029 ">
specifically, we translate french text to an english text using googletranslate1 , and create coreference chains forthe translated english text using reconcile2 (stoyanov et al , 2010).<papid> P10-2029 </papid></citsent>
<aftsection>
<nextsent>to project mentions from english to french, we first align the english and french words in each pair of parallel sentences, and then project the english mentions onto the french text using the alignment.
</nextsent>
<nextsent>however, since the alignment is noisy, the french words to which the words in the english mention are aligned may not form contiguous text span.
</nextsent>
<nextsent>to fix this problem, we follow yarowsky and ngai (2001) <papid> N01-1026 </papid>and use the smallest text span that covers all the aligned french words to create the french mention.3 we process the english mentions in the text in left-to-right manner, as processing the mentions sequentially enables us to ensure that an english mention is not mapped to 1see http://translate.google.com.</nextsent>
<nextsent>2see http://www.cs.utah.edu/nlp/reconcile.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3827">
<title id=" N12-1090.xml">translation based projection for multilingual coreference resolution </title>
<section> translation-based projection.  </section>
<citcontext>
<prevsection>
<prevsent>2see http://www.cs.utah.edu/nlp/reconcile.
</prevsent>
<prevsent>we use the re solver pre-trained on the wolverhampton corpus.3other methods for projecting mentions can be found in postolache et al  (2006), for example.
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
french text span that has already been mapped to by previously-processed english mention.4 to align english and french words, we trained word alignment model using giza++5 (och and ney, 2000) <papid> P00-1056 </papid>on parallel corpus comprising the english-french section of europarl6 (koehn, 2005) as well as all the french texts (and their translated english counterparts) for which we want to automatically create coreference chains.</citsent>
<aftsection>
<nextsent>following common practice, we stemmed the parallel corpus using the porter stemmer (porter, 1980) in order to reduce data sparseness.
</nextsent>
<nextsent>however, even with stemming, we found that many english words were not aligned to any french words by the resulting alignment model.
</nextsent>
<nextsent>this would prevent many english mentions from being projected to the french side, potentially harming the recall of the french coreferenceannotations.
</nextsent>
<nextsent>to improve alignment coverage, we retrained the alignment model by supplying giza++ with an english-french bilingual dictionary that we assembled using three online dictionary databases: omegawiki, wiktionary, and universal dictionary.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3828">
<title id=" N12-1090.xml">translation based projection for multilingual coreference resolution </title>
<section> translation-based projection.  </section>
<citcontext>
<prevsection>
<prevsent>to see the reason, recall that one source of errors inherent in projection approach is word alignment errors.
</prevsent>
<prevsent>in setting 1, when we tried to project english mentions to the french text, word alignment errors would adversely affect the ability of the np projection algorithm to correctly define the boundaries of the french mentions.
</prevsent>
</prevsection>
<citsent citstr=" P09-1074 ">
since coreference performance depends crucially on the ability to correctly identify mentions (stoyanov et al ,2009), <papid> P09-1074 </papid>the presence of word alignment errors implies that the resulting french coreference annotations could score poorly even if the english coreference annotations produced by reconcile were of high quality.</citsent>
<aftsection>
<nextsent>in the current setting, on the other hand, we reduce the sensitivity of coreference performance to word alignment errors via the use of the french mention extractor to produce more accurate french mention boundaries.
</nextsent>
<nextsent>3.3 setting 3: additional taggers available.
</nextsent>
<nextsent>finally, we consider setting that is the leastresource-scarce of the three.
</nextsent>
<nextsent>we assume that in addition to french mention extractor, we have access to other french linguistic taggers (e.g., syntactic and semantic parsers) that will allow us to generate the linguistic features needed to train french re solver on the projected coreference annotations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3830">
<title id=" N12-1090.xml">translation based projection for multilingual coreference resolution </title>
<section> translation-based projection.  </section>
<citcontext>
<prevsection>
<prevsent>specifically, assume that test is set of french texts we want to coreference-annotate, and training is set of french texts that is disjoint from test but is drawn from the same domain as test.8 to annotate the test texts, we perform the following steps.
</prevsent>
<prevsent>first,we employ the french mention extractor in combination with the method described in setting 2 to automatically coreference-annotate the training texts.
</prevsent>
</prevsection>
<citsent citstr=" P11-1079 ">
next, motivated by kobdani et al  (2011), <papid> P11-1079 </papid>we train french coreference re solver on the automaticallycoreference-annotated training texts, using the features provided by the available linguistic taggers.</citsent>
<aftsection>
<nextsent>finally, we apply the re solver to generate coreference chains for each test text.two questions arise.
</nextsent>
<nextsent>first, is this method necessarily better than the one described in setting 2?
</nextsent>
<nextsent>we hypothesize that the answer is affirmative: not onlycan this method exploit the knowledge about the target language provided by the additional linguistic taggers, but the resulting coreference re solver may allow us to generalize from the (noisily labeled) dataand make this method more robust to the noise in 8we assume that it is easy to assemble the training set, since unlabeled texts are typically easy to collect in practice.
</nextsent>
<nextsent>723 herent in the projected coreference annotations than the previously-described methods.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3831">
<title id=" N12-1090.xml">translation based projection for multilingual coreference resolution </title>
<section> coreference resolution system.  </section>
<citcontext>
<prevsection>
<prevsent>each dataset comprises not only training and test documents that are coreference-annotated, but also number of word-based linguistic features from which we derivemention-based linguistic features for training resolver.
</prevsent>
<prevsent>in this section, we will describe how this re solver is trained and then applied to generate coreference chains for unseen documents.training the coreference classifier.
</prevsent>
</prevsection>
<citsent citstr=" J01-4004 ">
as our coreference model, we train mention-pair model, which is classifier that determines whether two mentions are co-referring or not (e.g., soon et al  (2001), <papid> J01-4004 </papid>ngand cardie (2002)).<papid> P02-1014 </papid>9 each instance i(mj ,mk) corresponds to mj (a candidate antecedent) and mk (the mention to be resolved), and is represented by set of 23 features shown in table 1.</citsent>
<aftsection>
<nextsent>as we can see, each feature is either relational, capturing the relation between mj and mk, or non-relational, capturing the linguistic property of mk.
</nextsent>
<nextsent>the possible values ofa relational feature (except lexical) are (com patible), (incompatible), and na (the comparison 9note that any supervised coreference model can be used, such as an entity-mention model (e.g., luo et al  (2004), <papid> P04-1018 </papid>yang et al  (2008)) <papid> P08-1096 </papid>or ranking model (e.g., denis and baldridge (2008), <papid> D08-1069 </papid>rahman and ng (2009)).<papid> D09-1101 </papid>cannot be made due to missing data).</nextsent>
<nextsent>for non relational feature, we refer the reader to the datasets for the list of possible values.10we follow soon et al (2001) <papid> J01-4004 </papid>method for creating training instances.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3832">
<title id=" N12-1090.xml">translation based projection for multilingual coreference resolution </title>
<section> coreference resolution system.  </section>
<citcontext>
<prevsection>
<prevsent>each dataset comprises not only training and test documents that are coreference-annotated, but also number of word-based linguistic features from which we derivemention-based linguistic features for training resolver.
</prevsent>
<prevsent>in this section, we will describe how this re solver is trained and then applied to generate coreference chains for unseen documents.training the coreference classifier.
</prevsent>
</prevsection>
<citsent citstr=" P02-1014 ">
as our coreference model, we train mention-pair model, which is classifier that determines whether two mentions are co-referring or not (e.g., soon et al  (2001), <papid> J01-4004 </papid>ngand cardie (2002)).<papid> P02-1014 </papid>9 each instance i(mj ,mk) corresponds to mj (a candidate antecedent) and mk (the mention to be resolved), and is represented by set of 23 features shown in table 1.</citsent>
<aftsection>
<nextsent>as we can see, each feature is either relational, capturing the relation between mj and mk, or non-relational, capturing the linguistic property of mk.
</nextsent>
<nextsent>the possible values ofa relational feature (except lexical) are (com patible), (incompatible), and na (the comparison 9note that any supervised coreference model can be used, such as an entity-mention model (e.g., luo et al  (2004), <papid> P04-1018 </papid>yang et al  (2008)) <papid> P08-1096 </papid>or ranking model (e.g., denis and baldridge (2008), <papid> D08-1069 </papid>rahman and ng (2009)).<papid> D09-1101 </papid>cannot be made due to missing data).</nextsent>
<nextsent>for non relational feature, we refer the reader to the datasets for the list of possible values.10we follow soon et al (2001) <papid> J01-4004 </papid>method for creating training instances.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3833">
<title id=" N12-1090.xml">translation based projection for multilingual coreference resolution </title>
<section> coreference resolution system.  </section>
<citcontext>
<prevsection>
<prevsent>as our coreference model, we train mention-pair model, which is classifier that determines whether two mentions are co-referring or not (e.g., soon et al  (2001), <papid> J01-4004 </papid>ngand cardie (2002)).<papid> P02-1014 </papid>9 each instance i(mj ,mk) corresponds to mj (a candidate antecedent) and mk (the mention to be resolved), and is represented by set of 23 features shown in table 1.</prevsent>
<prevsent>as we can see, each feature is either relational, capturing the relation between mj and mk, or non-relational, capturing the linguistic property of mk.</prevsent>
</prevsection>
<citsent citstr=" P04-1018 ">
the possible values ofa relational feature (except lexical) are (com patible), (incompatible), and na (the comparison 9note that any supervised coreference model can be used, such as an entity-mention model (e.g., luo et al  (2004), <papid> P04-1018 </papid>yang et al  (2008)) <papid> P08-1096 </papid>or ranking model (e.g., denis and baldridge (2008), <papid> D08-1069 </papid>rahman and ng (2009)).<papid> D09-1101 </papid>cannot be made due to missing data).</citsent>
<aftsection>
<nextsent>for non relational feature, we refer the reader to the datasets for the list of possible values.10we follow soon et al (2001) <papid> J01-4004 </papid>method for creating training instances.</nextsent>
<nextsent>specifically, we create (1) positive instance for each anaphoric mention mk and its closest antecedent mj; and (2) negative instance for mk paired with each of the intervening mentions,mj+1,mj+2, . . .</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3834">
<title id=" N12-1090.xml">translation based projection for multilingual coreference resolution </title>
<section> coreference resolution system.  </section>
<citcontext>
<prevsection>
<prevsent>as our coreference model, we train mention-pair model, which is classifier that determines whether two mentions are co-referring or not (e.g., soon et al  (2001), <papid> J01-4004 </papid>ngand cardie (2002)).<papid> P02-1014 </papid>9 each instance i(mj ,mk) corresponds to mj (a candidate antecedent) and mk (the mention to be resolved), and is represented by set of 23 features shown in table 1.</prevsent>
<prevsent>as we can see, each feature is either relational, capturing the relation between mj and mk, or non-relational, capturing the linguistic property of mk.</prevsent>
</prevsection>
<citsent citstr=" P08-1096 ">
the possible values ofa relational feature (except lexical) are (com patible), (incompatible), and na (the comparison 9note that any supervised coreference model can be used, such as an entity-mention model (e.g., luo et al  (2004), <papid> P04-1018 </papid>yang et al  (2008)) <papid> P08-1096 </papid>or ranking model (e.g., denis and baldridge (2008), <papid> D08-1069 </papid>rahman and ng (2009)).<papid> D09-1101 </papid>cannot be made due to missing data).</citsent>
<aftsection>
<nextsent>for non relational feature, we refer the reader to the datasets for the list of possible values.10we follow soon et al (2001) <papid> J01-4004 </papid>method for creating training instances.</nextsent>
<nextsent>specifically, we create (1) positive instance for each anaphoric mention mk and its closest antecedent mj; and (2) negative instance for mk paired with each of the intervening mentions,mj+1,mj+2, . . .</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3835">
<title id=" N12-1090.xml">translation based projection for multilingual coreference resolution </title>
<section> coreference resolution system.  </section>
<citcontext>
<prevsection>
<prevsent>as our coreference model, we train mention-pair model, which is classifier that determines whether two mentions are co-referring or not (e.g., soon et al  (2001), <papid> J01-4004 </papid>ngand cardie (2002)).<papid> P02-1014 </papid>9 each instance i(mj ,mk) corresponds to mj (a candidate antecedent) and mk (the mention to be resolved), and is represented by set of 23 features shown in table 1.</prevsent>
<prevsent>as we can see, each feature is either relational, capturing the relation between mj and mk, or non-relational, capturing the linguistic property of mk.</prevsent>
</prevsection>
<citsent citstr=" D08-1069 ">
the possible values ofa relational feature (except lexical) are (com patible), (incompatible), and na (the comparison 9note that any supervised coreference model can be used, such as an entity-mention model (e.g., luo et al  (2004), <papid> P04-1018 </papid>yang et al  (2008)) <papid> P08-1096 </papid>or ranking model (e.g., denis and baldridge (2008), <papid> D08-1069 </papid>rahman and ng (2009)).<papid> D09-1101 </papid>cannot be made due to missing data).</citsent>
<aftsection>
<nextsent>for non relational feature, we refer the reader to the datasets for the list of possible values.10we follow soon et al (2001) <papid> J01-4004 </papid>method for creating training instances.</nextsent>
<nextsent>specifically, we create (1) positive instance for each anaphoric mention mk and its closest antecedent mj; and (2) negative instance for mk paired with each of the intervening mentions,mj+1,mj+2, . . .</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3836">
<title id=" N12-1090.xml">translation based projection for multilingual coreference resolution </title>
<section> coreference resolution system.  </section>
<citcontext>
<prevsection>
<prevsent>as our coreference model, we train mention-pair model, which is classifier that determines whether two mentions are co-referring or not (e.g., soon et al  (2001), <papid> J01-4004 </papid>ngand cardie (2002)).<papid> P02-1014 </papid>9 each instance i(mj ,mk) corresponds to mj (a candidate antecedent) and mk (the mention to be resolved), and is represented by set of 23 features shown in table 1.</prevsent>
<prevsent>as we can see, each feature is either relational, capturing the relation between mj and mk, or non-relational, capturing the linguistic property of mk.</prevsent>
</prevsection>
<citsent citstr=" D09-1101 ">
the possible values ofa relational feature (except lexical) are (com patible), (incompatible), and na (the comparison 9note that any supervised coreference model can be used, such as an entity-mention model (e.g., luo et al  (2004), <papid> P04-1018 </papid>yang et al  (2008)) <papid> P08-1096 </papid>or ranking model (e.g., denis and baldridge (2008), <papid> D08-1069 </papid>rahman and ng (2009)).<papid> D09-1101 </papid>cannot be made due to missing data).</citsent>
<aftsection>
<nextsent>for non relational feature, we refer the reader to the datasets for the list of possible values.10we follow soon et al (2001) <papid> J01-4004 </papid>method for creating training instances.</nextsent>
<nextsent>specifically, we create (1) positive instance for each anaphoric mention mk and its closest antecedent mj; and (2) negative instance for mk paired with each of the intervening mentions,mj+1,mj+2, . . .</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3838">
<title id=" N12-1090.xml">translation based projection for multilingual coreference resolution </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>724 features describing mk, the mention to be resolved 1 num words the number of words in mk.
</prevsent>
<prevsent>2 coarse pos the coarse pos of mk (see pos?
</prevsent>
</prevsection>
<citsent citstr=" S10-1001 ">
in recasens et al  (2010)).<papid> S10-1001 </papid></citsent>
<aftsection>
<nextsent>3 fine pos the fine-grained pos of mk (see pos type?
</nextsent>
<nextsent>in recasens et al  (2010)).<papid> S10-1001 </papid></nextsent>
<nextsent>4 ne the named entity tag of mk if mk is named entity; else na.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3842">
<title id=" N12-1090.xml">translation based projection for multilingual coreference resolution </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>23 lexical the concatenation of the heads of the two mentions.
</prevsent>
<prevsent>table 1: feature set for coreference resolution.scoring programs.
</prevsent>
</prevsection>
<citsent citstr=" M95-1005 ">
to score the output of coreference re solver, we employ four scoring programs, muc (vilain et al , 1995), <papid> M95-1005 </papid>b3 (bagga and baldwin,1998), 3-ceaf (luo, 2005), <papid> H05-1004 </papid>and blanc (re casens and hovy, 2011), which were downloaded from the shared task website (see footnote 10).gold-standard versus regular settings.</citsent>
<aftsection>
<nextsent>the format of each dataset follows that of typical conll shared task dataset.
</nextsent>
<nextsent>in other words, each row corresponds to word in document; moreover, all butthe last column contain the linguistic features computed for the words, and the last column stores the coreference information.
</nextsent>
<nextsent>some of the features we recomputed via automatic means, but some were extracted from human annotations.
</nextsent>
<nextsent>given this distinction, the shared task organizers defined two evaluation settings: in the regular setting, only the columns that were computed automatically can be used to derive coreference features for classifier training, and results should be reported on system mentions; on the other hand, in the gold-standard setting, onlythe columns that were extracted from human annotations can be used to derive coreference features, and results should be reported on true mentions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3843">
<title id=" N12-1090.xml">translation based projection for multilingual coreference resolution </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>23 lexical the concatenation of the heads of the two mentions.
</prevsent>
<prevsent>table 1: feature set for coreference resolution.scoring programs.
</prevsent>
</prevsection>
<citsent citstr=" H05-1004 ">
to score the output of coreference re solver, we employ four scoring programs, muc (vilain et al , 1995), <papid> M95-1005 </papid>b3 (bagga and baldwin,1998), 3-ceaf (luo, 2005), <papid> H05-1004 </papid>and blanc (re casens and hovy, 2011), which were downloaded from the shared task website (see footnote 10).gold-standard versus regular settings.</citsent>
<aftsection>
<nextsent>the format of each dataset follows that of typical conll shared task dataset.
</nextsent>
<nextsent>in other words, each row corresponds to word in document; moreover, all butthe last column contain the linguistic features computed for the words, and the last column stores the coreference information.
</nextsent>
<nextsent>some of the features we recomputed via automatic means, but some were extracted from human annotations.
</nextsent>
<nextsent>given this distinction, the shared task organizers defined two evaluation settings: in the regular setting, only the columns that were computed automatically can be used to derive coreference features for classifier training, and results should be reported on system mentions; on the other hand, in the gold-standard setting, onlythe columns that were extracted from human annotations can be used to derive coreference features, and results should be reported on true mentions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3846">
<title id=" N12-1090.xml">translation based projection for multilingual coreference resolution </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>to determine whether the upper bounds established by our supervised systems are reasonable, we show there sults of the best-performing re solvers participating in the shared task for both languages under the gold standard and regular settings in rows 3 and 4 of tables 3 and 4.
</prevsent>
<prevsent>since none of the participating systems achieved the best score over all four scorers, we report the performance of the system that has the highest average f-score.
</prevsent>
</prevsection>
<citsent citstr=" S10-1022 ">
according to the shared task website, tanl-1 (attardi et al , 2010) <papid> S10-1022 </papid>achieved thebest average f-score in the regular setting for spanish, whereas sucre (kobdani and schutze, 2010) outperformed others in the remaining settings.</citsent>
<aftsection>
<nextsent>comparing these best shared task results with our supervised results in rows 1 and 2, we see that our average f-score for spanish/gold is worse than its shared task counterpart by 0.7 points, but otherwise our system outperforms in other settings w.r.t. average f-score, specifically by 5.0 points for span ish/regular (due to better muc f-score), by 3.4?
</nextsent>
<nextsent>4.7 points for italian (due to better ceaf, b3, and blanc scores).
</nextsent>
<nextsent>overall, these results suggest that the scores achieved by our systems are at least as competitive as the best shared task scores.
</nextsent>
<nextsent>5.2.2 unsupervised results next, we evaluate our projection algorithm.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3847">
<title id=" P01-1055.xml">using machine learning to maintain rule based named entity recognition and classification systems </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>as mentioned above, the exploitation of learning techniques to support the domain adaptation ofnerc systems has recently attracted the attention of several researchers.
</prevsent>
<prevsent>some of these approaches are briefly discussed in this section.
</prevsent>
</prevsection>
<citsent citstr=" A97-1029 ">
nymble (bikel et al, 1997) <papid> A97-1029 </papid>uses statistical learning to acquire hidden markov model (hmm) that recognises nes in text.</citsent>
<aftsection>
<nextsent>nymble did particularly well in the muc-7 competition (darpa, 1998), due mainly to the use of the correct features in the encoding of words, e.g. capitalisation, and the probabilistic modelling of the recognition system.
</nextsent>
<nextsent>named-entity recognition in alembic (vilain and day, 1996) <papid> C96-1047 </papid>uses the transformation-based rule learning approach introduced in brills work on part-of-speech tagging (brill, 1993).</nextsent>
<nextsent>an important aspect of this approach is the fact thatthe system learns rules that can be freely intermixed with hand-engineered ones.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3848">
<title id=" P01-1055.xml">using machine learning to maintain rule based named entity recognition and classification systems </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>nymble (bikel et al, 1997) <papid> A97-1029 </papid>uses statistical learning to acquire hidden markov model (hmm) that recognises nes in text.</prevsent>
<prevsent>nymble did particularly well in the muc-7 competition (darpa, 1998), due mainly to the use of the correct features in the encoding of words, e.g. capitalisation, and the probabilistic modelling of the recognition system.</prevsent>
</prevsection>
<citsent citstr=" C96-1047 ">
named-entity recognition in alembic (vilain and day, 1996) <papid> C96-1047 </papid>uses the transformation-based rule learning approach introduced in brills work on part-of-speech tagging (brill, 1993).</citsent>
<aftsection>
<nextsent>an important aspect of this approach is the fact thatthe system learns rules that can be freely intermixed with hand-engineered ones.
</nextsent>
<nextsent>the robotag system presented in (bennettet al, 1997) constructs decision trees that classify words as being start or endpoints of particular named-entity type.
</nextsent>
<nextsent>a variant of this approach was used in the system presented by the new york university (nyu) in the multilingual entity task (met-2) of muc-7 (sekine, 1998).<papid> M98-1019 </papid></nextsent>
<nextsent>the system developed for italian in ecran (cuchiarelli et al, 1998), uses unsupervised learning to expand manually constructed system and improve its performance.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3849">
<title id=" P01-1055.xml">using machine learning to maintain rule based named entity recognition and classification systems </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>an important aspect of this approach is the fact thatthe system learns rules that can be freely intermixed with hand-engineered ones.
</prevsent>
<prevsent>the robotag system presented in (bennettet al, 1997) constructs decision trees that classify words as being start or endpoints of particular named-entity type.
</prevsent>
</prevsection>
<citsent citstr=" M98-1019 ">
a variant of this approach was used in the system presented by the new york university (nyu) in the multilingual entity task (met-2) of muc-7 (sekine, 1998).<papid> M98-1019 </papid></citsent>
<aftsection>
<nextsent>the system developed for italian in ecran (cuchiarelli et al, 1998), uses unsupervised learning to expand manually constructed system and improve its performance.
</nextsent>
<nextsent>the learning algorithm tries to supplement the manually constructed system by classifying recognised but unclassified nes.
</nextsent>
<nextsent>in (petasis et al, 2000) the manually constructed system was replaced by the supervised tree induction algorithm c4.5(quinlan, 1993), reaching very good performance on the muc-6 corpora.the partially supervised multi-level bootstrapping approach presented in (riloff and jones, 1999) induces set of information extraction patterns, which can be used to identify and classify nes.
</nextsent>
<nextsent>the system starts by generating exhaustively all candidate extraction patterns, using an earlier system called auto slog (riloff, 1993).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3850">
<title id=" P01-1055.xml">using machine learning to maintain rule based named entity recognition and classification systems </title>
<section> rule-based nerc systems.  </section>
<citcontext>
<prevsection>
<prevsent>at the partial matching sub-stage, classified names are matched against unclassified ones aiming at the recognition of the truncated or variable forms of names.
</prevsent>
<prevsent>3.2 the french nerc system.
</prevsent>
</prevsection>
<citsent citstr=" E95-1004 ">
the french nerc system has been implemented with the use of rule-based inference engine (wolinski et al, 1995).<papid> E95-1004 </papid></citsent>
<aftsection>
<nextsent>it is based on large knowledge base (lexicon) including 8,000proper names that share 10,000 forms and consist of 11,000 words.
</nextsent>
<nextsent>it has been used continuously since 1995 in several real-time document filtering applications (wolinski et al, 2000).the uses of the nerc system in these applications are the following: 1.
</nextsent>
<nextsent>segmentation of nes, in order to improve.
</nextsent>
<nextsent>the performance of the syntactic analyser, particularly in the case of long proper names which contain grammatical markers (e.g. prepositions, conjunctions, commas, full stops).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3851">
<title id=" P00-1047.xml">a polynomialtime fragment of dominance constraints </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>here we identify the natural fragment of normal dominance constraints and show that its satisfiability problem is in deterministic polynomial time.
</prevsent>
<prevsent>dominance constraints are used as partial descriptions of trees in problems through out computational linguistics.
</prevsent>
</prevsection>
<citsent citstr=" P83-1020 ">
they have been applied to incremental parsing (marcus et al, 1983), <papid> P83-1020 </papid>grammar formalisms (vijay shanker, 1992; rambow et al, 1995; <papid> P95-1021 </papid>duchier and thater, 1999; perrier, 2000), discourse(gardent and webber, 1998), and scope un der specification (muskens, 1995; egg et al, 1998).<papid> P98-1058 </papid></citsent>
<aftsection>
<nextsent>logical properties of dominance constraints have been studied e.g. in (backofen et al, 1995), and computational properties have been addressed in (rogers and vijay-shanker, 1994; duchier and gardent, 1999).
</nextsent>
<nextsent>here, thetwo most important operations are satisfia bility testing ? does the constraint describe tree?
</nextsent>
<nextsent>and enumerating solutions, i.e. the described trees.
</nextsent>
<nextsent>unfortunately, even the satisfiability problem has been shown to be np complete (koller et al, 1998).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3852">
<title id=" P00-1047.xml">a polynomialtime fragment of dominance constraints </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>here we identify the natural fragment of normal dominance constraints and show that its satisfiability problem is in deterministic polynomial time.
</prevsent>
<prevsent>dominance constraints are used as partial descriptions of trees in problems through out computational linguistics.
</prevsent>
</prevsection>
<citsent citstr=" P95-1021 ">
they have been applied to incremental parsing (marcus et al, 1983), <papid> P83-1020 </papid>grammar formalisms (vijay shanker, 1992; rambow et al, 1995; <papid> P95-1021 </papid>duchier and thater, 1999; perrier, 2000), discourse(gardent and webber, 1998), and scope un der specification (muskens, 1995; egg et al, 1998).<papid> P98-1058 </papid></citsent>
<aftsection>
<nextsent>logical properties of dominance constraints have been studied e.g. in (backofen et al, 1995), and computational properties have been addressed in (rogers and vijay-shanker, 1994; duchier and gardent, 1999).
</nextsent>
<nextsent>here, thetwo most important operations are satisfia bility testing ? does the constraint describe tree?
</nextsent>
<nextsent>and enumerating solutions, i.e. the described trees.
</nextsent>
<nextsent>unfortunately, even the satisfiability problem has been shown to be np complete (koller et al, 1998).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3853">
<title id=" P00-1047.xml">a polynomialtime fragment of dominance constraints </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>here we identify the natural fragment of normal dominance constraints and show that its satisfiability problem is in deterministic polynomial time.
</prevsent>
<prevsent>dominance constraints are used as partial descriptions of trees in problems through out computational linguistics.
</prevsent>
</prevsection>
<citsent citstr=" P98-1058 ">
they have been applied to incremental parsing (marcus et al, 1983), <papid> P83-1020 </papid>grammar formalisms (vijay shanker, 1992; rambow et al, 1995; <papid> P95-1021 </papid>duchier and thater, 1999; perrier, 2000), discourse(gardent and webber, 1998), and scope un der specification (muskens, 1995; egg et al, 1998).<papid> P98-1058 </papid></citsent>
<aftsection>
<nextsent>logical properties of dominance constraints have been studied e.g. in (backofen et al, 1995), and computational properties have been addressed in (rogers and vijay-shanker, 1994; duchier and gardent, 1999).
</nextsent>
<nextsent>here, thetwo most important operations are satisfia bility testing ? does the constraint describe tree?
</nextsent>
<nextsent>and enumerating solutions, i.e. the described trees.
</nextsent>
<nextsent>unfortunately, even the satisfiability problem has been shown to be np complete (koller et al, 1998).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3854">
<title id=" P00-1047.xml">a polynomialtime fragment of dominance constraints </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the dotted lines signify dominance relations, which require the upper node to be an ancestor of the lower one in any tree that fits the description.
</prevsent>
<prevsent>(1) some representative of every department in all companies saw sample of each product.
</prevsent>
</prevsection>
<citsent citstr=" J87-1005 ">
the sentence has 42 readings (hobbs and shieber, 1987), <papid> J87-1005 </papid>and it is easy to imagine how the number of readings grows exponentially (or worse) in the length of the sen tence.</citsent>
<aftsection>
<nextsent>efficient enumeration of readings from the description is longstanding problem in scope underspecification.
</nextsent>
<nextsent>our polynomial algorithm solves this problem.
</nextsent>
<nextsent>moreover, the investigation of graph problems that are closely related to normal constraints allows us to prove that many other underspecificationformalisms ? e.g. minimal recur sion semantics (copestake et al, 1997) and hole semantics (bos, 1996) ? have np-hard satisfiability problems.
</nextsent>
<nextsent>our algorithm can still be used as preprocessing step for these approaches; in fact, experience shows that it seems to solve all encodings of descriptions in hole semantics that actually occur.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3855">
<title id=" P00-1047.xml">a polynomialtime fragment of dominance constraints </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>mentioned?
</prevsent>
<prevsent>in the constraint.
</prevsent>
</prevsection>
<citsent citstr=" P99-1038 ">
this eliminates any doubts about the computational practicability of dominance constraints which were raised by the np completeness result for the general language (koller et al, 1998) and expressed e.g. in(willis and manandhar, 1999).<papid> P99-1038 </papid></citsent>
<aftsection>
<nextsent>first experiments confirm the efficiency of the new algorithm ? it is superior to the np algorithms especially on larger constraints.
</nextsent>
<nextsent>on the other hand, we have argued that the problem of finding constructive solution seven of normal dominance constraint is np complete.
</nextsent>
<nextsent>this result carries over to other under specification formalisms, such as hole semantics and mrs. in practice, however, itseems that the enumeration algorithm presented here can be adapted to those problems.
</nextsent>
<nextsent>acknowledgments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3856">
<title id=" P04-1032.xml">minimal recur sion semantics as dominance constraints translation evaluation and analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the main assumption of the translation?
</prevsent>
<prevsent>that all relevant underspecified descriptions are netsis validated for large majority of cases; allnon-nets computed by the erg seem to be systematically incomplete.
</prevsent>
</prevsection>
<citsent citstr=" P92-1005 ">
under specification is the standard approach to dealing with scope ambiguity (alshawi and crouch, 1992; <papid> P92-1005 </papid>pinkal, 1996).</citsent>
<aftsection>
<nextsent>the readings of underspecified expressions are represented by compact and concise descriptions, instead of being enumerated explicitly.
</nextsent>
<nextsent>underspecified descriptions are easier to derive in syntax-semantics interfaces (egg et al, 2001; copestake et al, 2001), <papid> P01-1019 </papid>useful in applications such as machine translation (copestake et al, 1995), and can be resolved by need.</nextsent>
<nextsent>two important under specification formalisms inthe recent literature are minimal recur sion semantics (mrs) (copestake et al, 2004) and dominance constraints (egg et al, 2001).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3857">
<title id=" P04-1032.xml">minimal recur sion semantics as dominance constraints translation evaluation and analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>under specification is the standard approach to dealing with scope ambiguity (alshawi and crouch, 1992; <papid> P92-1005 </papid>pinkal, 1996).</prevsent>
<prevsent>the readings of underspecified expressions are represented by compact and concise descriptions, instead of being enumerated explicitly.</prevsent>
</prevsection>
<citsent citstr=" P01-1019 ">
underspecified descriptions are easier to derive in syntax-semantics interfaces (egg et al, 2001; copestake et al, 2001), <papid> P01-1019 </papid>useful in applications such as machine translation (copestake et al, 1995), and can be resolved by need.</citsent>
<aftsection>
<nextsent>two important under specification formalisms inthe recent literature are minimal recur sion semantics (mrs) (copestake et al, 2004) and dominance constraints (egg et al, 2001).
</nextsent>
<nextsent>mrs is the under specification language which is used in large-scale hpsg grammars, such as the english resource grammar (erg) (copestake and flickinger, 2000).
</nextsent>
<nextsent>the main advantage of dominance constraints is that they can be solved very efficiently (althaus et al., 2003; bodirsky et al, 2004).niehren and thater (2003) <papid> P03-1047 </papid>defined, in theoretical paper, translation from mrs into normal dominance constraints.</nextsent>
<nextsent>this translation clarified the precise relationship between these two related formalisms, and made the powerful meta-theory of dominance constraints accessible to mrs. their goal was to also make the large grammars for mrs ? supported by the chorus project of the sfb 378 of the dfg.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3858">
<title id=" P04-1032.xml">minimal recur sion semantics as dominance constraints translation evaluation and analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>two important under specification formalisms inthe recent literature are minimal recur sion semantics (mrs) (copestake et al, 2004) and dominance constraints (egg et al, 2001).
</prevsent>
<prevsent>mrs is the under specification language which is used in large-scale hpsg grammars, such as the english resource grammar (erg) (copestake and flickinger, 2000).
</prevsent>
</prevsection>
<citsent citstr=" P03-1047 ">
the main advantage of dominance constraints is that they can be solved very efficiently (althaus et al., 2003; bodirsky et al, 2004).niehren and thater (2003) <papid> P03-1047 </papid>defined, in theoretical paper, translation from mrs into normal dominance constraints.</citsent>
<aftsection>
<nextsent>this translation clarified the precise relationship between these two related formalisms, and made the powerful meta-theory of dominance constraints accessible to mrs. their goal was to also make the large grammars for mrs ? supported by the chorus project of the sfb 378 of the dfg.
</nextsent>
<nextsent>and the efficient constraint solvers for dominance constraints available to the other formalism.however, niehren and thater made three technical assumptions:1.
</nextsent>
<nextsent>that ep-conjunction can be resolved in preprocessing step;2.
</nextsent>
<nextsent>that the qeq relation in mrs is simply domi nance; 3.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3860">
<title id=" P04-1032.xml">minimal recur sion semantics as dominance constraints translation evaluation and analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>that the qeq relation in mrs is simply domi nance; 3.
</prevsent>
<prevsent>and (most importantly) that all linguistically correct and relevant mrs expressions belong to certain class of constraints called nets.
</prevsent>
</prevsection>
<citsent citstr=" C02-2025 ">
this means that it is not obvious whether their result can be immediately applied to the output of practical grammars like the erg.in this paper, we evaluate the truth of these assumptions on the mrs expressions which the erg computes for the sentences in the redwoods tree bank (oepen et al, 2002).<papid> C02-2025 </papid></citsent>
<aftsection>
<nextsent>the main result of our evaluation is that 83% of the redwoods sentences are indeed nets, and 17% arent. closer analysis of the non-nets reveals that they seem to be systematically incomplete, i. e. they predict more readings than the sentence actually has.
</nextsent>
<nextsent>this supports the claim that all linguistically correct mrs expressions are indeed nets.
</nextsent>
<nextsent>we also verify the other two assumptions, one empirically and one by proof.our results are practically relevant because dominance constraint solvers are much faster and have more predictable run times when solving nets than the lkb solver for mrs (copestake, 2002), as we also show here.
</nextsent>
<nextsent>in addition, nets might be useful as debugging tool to identify potentially problematic semantic outputs when designing grammar.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3873">
<title id=" P03-1031.xml">corpus based discourse understanding in spoken dialogue systems </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>such component must choose the best combination of dialogue state and dialogue act out of all possibilities.
</prevsent>
<prevsent>an appropriate scoring method for the dialogue states is therefore required.
</prevsent>
</prevsection>
<citsent citstr=" P99-1026 ">
nakano et al  (1999) <papid> P99-1026 </papid>proposed method that holds multiple dialogue states ordered by priority to deal with the problem that some utterances convey meaning over several speech intervals and that the understanding result cannot be determined at each interval end.</citsent>
<aftsection>
<nextsent>miyazaki et al  (2002) proposed method combining nakano et al (1999) <papid> P99-1026 </papid>method and n-best recognition hypotheses, and reported improvement in discourse understanding accuracy.</nextsent>
<nextsent>they used ametric similar to the concept error rate for the evalu [system utterance (s1)] what time would you like to reserve meeting room??</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3875">
<title id=" P03-1031.xml">corpus based discourse understanding in spoken dialogue systems </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>[room=nil, start=nil, end=15:00] figure 3: detailed description of the understanding of the example dialogue.ation of discourse accuracy, comparing reference dialogue states with hypothesis dialogue states.
</prevsent>
<prevsent>both these methods employ hand-crafted rules to score the dialogue states to decide the best dialogue state.
</prevsent>
</prevsection>
<citsent citstr=" P95-1016 ">
creating such rules requires expert knowledge, and is also time consuming.there are approaches that propose statistically estimating the dialogue act type from several previous dialogue act types using n-gram probability (nagata and morimoto, 1994; reithinger and maier, 1995).<papid> P95-1016 </papid>although their approaches can be used for disambiguating user utterance using discourse information, they do not consider holding multiple dialogue states.in the context of plan-based utterance understanding (allen and perrault, 1980; carberry, 1990),when there is ambiguity in the understanding result of user utterance, an interpretation best suited to the estimated plan should be selected.</citsent>
<aftsection>
<nextsent>in addition, the system must choose the most plausible plans from multiple possible candidates.
</nextsent>
<nextsent>although we do not adopt plan-based representation of dialogue states as noted before, this problem is close to what we are dealing with.
</nextsent>
<nextsent>unfortunately, however,it seems that no systematic ways to score the candidates for disambiguation have been proposed.
</nextsent>
<nextsent>the discourse understanding method that we propose takes the same approach as miyazaki et al  (2002).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3877">
<title id=" N12-1059.xml">trait based hypothesis selection for machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>hr0011-12-c-0014 under the bolt program (approved for public release, distribution unlimited).
</prevsent>
<prevsent>the views, opinions,and/or findings contained in this article are those of the author and should not be interpreted as representing the official views or policies, either expressed or implied, of the defense advanced research projects agency or the department of defense.
</prevsent>
</prevsection>
<citsent citstr=" N09-2019 ">
2010) or tokenization algorithm (de gispert et al, 2009).<papid> N09-2019 </papid></citsent>
<aftsection>
<nextsent>unfortunately, creating novel algorithms to perform some important aspect of mt decoding is obviously quite challenging.
</nextsent>
<nextsent>thus, it is difficult to increase the number of input systems in meaningful way.
</nextsent>
<nextsent>in this paper, we show it is possible to create diverse input hypotheses for combination without making any algorithmic changes.
</nextsent>
<nextsent>instead, we use traits, which are very simple attributes of the mt output, such as output length?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3878">
<title id=" N12-1059.xml">trait based hypothesis selection for machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we then combine these to produce substantial gain.
</prevsent>
<prevsent>note that all of the hypotheses are generated from single decode of single input system.additionally, our method is completely compatible with multi-system combination, since our procedure can be applied to each input system, and then these systems can be combined as normal.methods for automatically creating diverse hypotheses from single system have been explored in speech recognition (siohan et al, 2005), but we know of no analogous work applied to machine translation.
</prevsent>
</prevsection>
<citsent citstr=" P09-1067 ">
our procedure does share some surface similarities with techniques such as variational decoding (vd) (li et al, 2009), <papid> P09-1067 </papid>but the goal in those techniques is to find output which is consistent with the entire forest, rather than to select hypotheses with particular attributes.</citsent>
<aftsection>
<nextsent>in fact, vd can be applied in conjunction by running vd on the rescored forest 528 for each trait condition.1
</nextsent>
<nextsent>our machine translation system is string-to dependency hierarchical decoder based on (shen et al., 2008) <papid> P08-1066 </papid>and (chiang, 2007).<papid> J07-2003 </papid></nextsent>
<nextsent>bottom-up chart parsing is performed to produce shared forest ofderivations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3879">
<title id=" N12-1059.xml">trait based hypothesis selection for machine translation </title>
<section> description of mt system.  </section>
<citcontext>
<prevsection>
<prevsent>our procedure does share some surface similarities with techniques such as variational decoding (vd) (li et al, 2009), <papid> P09-1067 </papid>but the goal in those techniques is to find output which is consistent with the entire forest, rather than to select hypotheses with particular attributes.</prevsent>
<prevsent>in fact, vd can be applied in conjunction by running vd on the rescored forest 528 for each trait condition.1</prevsent>
</prevsection>
<citsent citstr=" P08-1066 ">
our machine translation system is string-to dependency hierarchical decoder based on (shen et al., 2008) <papid> P08-1066 </papid>and (chiang, 2007).<papid> J07-2003 </papid></citsent>
<aftsection>
<nextsent>bottom-up chart parsing is performed to produce shared forest ofderivations.
</nextsent>
<nextsent>the decoder uses log-linear translation model, so the score of derivation is defined as: sd(~w) = m?
</nextsent>
<nextsent>i=1 wi ? rr(d) fri (1) where r(d) is the set of translation rules that make up derivation d, is the number of features, fri is the score of the ith feature in rule r, and wi isthe weight of feature i. this weight vector is optimized discriminatively to maximize bleu score on tuning set, using the expected-bleu optimization procedure (rosti et al, 2010).<papid> W10-1748 </papid></nextsent>
<nextsent>our decoder uses all of the standard statistical mtfeatures, such as the language model, rule probabilities, and lexical probabilities.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3880">
<title id=" N12-1059.xml">trait based hypothesis selection for machine translation </title>
<section> description of mt system.  </section>
<citcontext>
<prevsection>
<prevsent>our procedure does share some surface similarities with techniques such as variational decoding (vd) (li et al, 2009), <papid> P09-1067 </papid>but the goal in those techniques is to find output which is consistent with the entire forest, rather than to select hypotheses with particular attributes.</prevsent>
<prevsent>in fact, vd can be applied in conjunction by running vd on the rescored forest 528 for each trait condition.1</prevsent>
</prevsection>
<citsent citstr=" J07-2003 ">
our machine translation system is string-to dependency hierarchical decoder based on (shen et al., 2008) <papid> P08-1066 </papid>and (chiang, 2007).<papid> J07-2003 </papid></citsent>
<aftsection>
<nextsent>bottom-up chart parsing is performed to produce shared forest ofderivations.
</nextsent>
<nextsent>the decoder uses log-linear translation model, so the score of derivation is defined as: sd(~w) = m?
</nextsent>
<nextsent>i=1 wi ? rr(d) fri (1) where r(d) is the set of translation rules that make up derivation d, is the number of features, fri is the score of the ith feature in rule r, and wi isthe weight of feature i. this weight vector is optimized discriminatively to maximize bleu score on tuning set, using the expected-bleu optimization procedure (rosti et al, 2010).<papid> W10-1748 </papid></nextsent>
<nextsent>our decoder uses all of the standard statistical mtfeatures, such as the language model, rule probabilities, and lexical probabilities.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3881">
<title id=" N12-1059.xml">trait based hypothesis selection for machine translation </title>
<section> description of mt system.  </section>
<citcontext>
<prevsection>
<prevsent>bottom-up chart parsing is performed to produce shared forest ofderivations.
</prevsent>
<prevsent>the decoder uses log-linear translation model, so the score of derivation is defined as: sd(~w) = m?
</prevsent>
</prevsection>
<citsent citstr=" W10-1748 ">
i=1 wi ? rr(d) fri (1) where r(d) is the set of translation rules that make up derivation d, is the number of features, fri is the score of the ith feature in rule r, and wi isthe weight of feature i. this weight vector is optimized discriminatively to maximize bleu score on tuning set, using the expected-bleu optimization procedure (rosti et al, 2010).<papid> W10-1748 </papid></citsent>
<aftsection>
<nextsent>our decoder uses all of the standard statistical mtfeatures, such as the language model, rule probabilities, and lexical probabilities.
</nextsent>
<nextsent>additionally, we use 50,000 sparse, binary-valued features such as is the bi-gram united states?
</nextsent>
<nextsent>present in the output??, based on (chiang et al, 2009).<papid> N09-1025 </papid></nextsent>
<nextsent>we use 3-gram lm for decoding and 5-gram lm for rescoring.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3883">
<title id=" N12-1059.xml">trait based hypothesis selection for machine translation </title>
<section> description of mt system.  </section>
<citcontext>
<prevsection>
<prevsent>our decoder uses all of the standard statistical mtfeatures, such as the language model, rule probabilities, and lexical probabilities.
</prevsent>
<prevsent>additionally, we use 50,000 sparse, binary-valued features such as is the bi-gram united states?
</prevsent>
</prevsection>
<citsent citstr=" N09-1025 ">
present in the output??, based on (chiang et al, 2009).<papid> N09-1025 </papid></citsent>
<aftsection>
<nextsent>we use 3-gram lm for decoding and 5-gram lm for rescoring.
</nextsent>
<nextsent>an mt trait represents high-level property of the mt output.
</nextsent>
<nextsent>the traits used in this paper are: ? null source words ? the percentage of source content words which align to null, i.e., are not translated.
</nextsent>
<nextsent>source reorder ? the percentage of source terminals/non-terminals which cross alignment links inside their decoding rule.?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3888">
<title id=" N12-1059.xml">trait based hypothesis selection for machine translation </title>
<section> combination.  </section>
<citcontext>
<prevsection>
<prevsent>here, we use confusion network decoder based on (rosti et al, 2010).<papid> W10-1748 </papid></prevsent>
<prevsent>the basic procedure is to 6for example if the held-out baseline bleu is 40.0 and ? = 0.5, the bleu after trait optimization can be no less than 39.5.</prevsent>
</prevsection>
<citsent citstr=" D09-1147 ">
7forest-based optimization such as (pauls et al, 2009) <papid> D09-1147 </papid>could be used instead.</citsent>
<aftsection>
<nextsent>530select one hypothesis as the skeleton?
</nextsent>
<nextsent>and then incrementally align the remaining hypotheses to createa confusion network.
</nextsent>
<nextsent>the confusion network is decoded using an arc-level confidence score for each input system and language model, the weights for which are estimated discriminatively to maximize bleu.
</nextsent>
<nextsent>we present mt results in table 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3889">
<title id=" P04-1021.xml">a joint source channel model for machine transliteration </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>transliterating english names into chinese is not straightforward.
</prevsent>
<prevsent>however, recalling the original from chinese transliteration is even more challenging as the e2c transliteration may have lost some original phonemic evidences.
</prevsent>
</prevsection>
<citsent citstr=" J98-4003 ">
the chinese-english backward transliteration process is also called back-transliteration, or c2e (knight &amp; graehl, 1998).<papid> J98-4003 </papid></citsent>
<aftsection>
<nextsent>in machine transliteration, the noisy channel model (ncm), based on phoneme-based approach, has recently received considerable attention (meng et al  2001; jung et al  2000; <papid> C00-1056 </papid>virga &amp; khudanpur, 2003; <papid> W03-1508 </papid>knight &amp; graehl, 1998).<papid> J98-4003 </papid></nextsent>
<nextsent>in this paper we discuss the limitations of such an approach and address its problems by firstly proposing paradigm that allows direct orthographic mapping (dom), secondly further proposing joint source-channel model as realization of dom.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3891">
<title id=" P04-1021.xml">a joint source channel model for machine transliteration </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, recalling the original from chinese transliteration is even more challenging as the e2c transliteration may have lost some original phonemic evidences.
</prevsent>
<prevsent>the chinese-english backward transliteration process is also called back-transliteration, or c2e (knight &amp; graehl, 1998).<papid> J98-4003 </papid></prevsent>
</prevsection>
<citsent citstr=" C00-1056 ">
in machine transliteration, the noisy channel model (ncm), based on phoneme-based approach, has recently received considerable attention (meng et al  2001; jung et al  2000; <papid> C00-1056 </papid>virga &amp; khudanpur, 2003; <papid> W03-1508 </papid>knight &amp; graehl, 1998).<papid> J98-4003 </papid></citsent>
<aftsection>
<nextsent>in this paper we discuss the limitations of such an approach and address its problems by firstly proposing paradigm that allows direct orthographic mapping (dom), secondly further proposing joint source-channel model as realization of dom.
</nextsent>
<nextsent>two other machine learning techniques, ncm and id3 (quinlan, 1993) decision tree, also are implemented under dom as reference to compare with the proposed n-gram tm.
</nextsent>
<nextsent>this paper is organized as follows: in section 2, we present the transliteration problems.
</nextsent>
<nextsent>in section 3, joint source-channel model is formulated.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3893">
<title id=" P04-1021.xml">a joint source channel model for machine transliteration </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, recalling the original from chinese transliteration is even more challenging as the e2c transliteration may have lost some original phonemic evidences.
</prevsent>
<prevsent>the chinese-english backward transliteration process is also called back-transliteration, or c2e (knight &amp; graehl, 1998).<papid> J98-4003 </papid></prevsent>
</prevsection>
<citsent citstr=" W03-1508 ">
in machine transliteration, the noisy channel model (ncm), based on phoneme-based approach, has recently received considerable attention (meng et al  2001; jung et al  2000; <papid> C00-1056 </papid>virga &amp; khudanpur, 2003; <papid> W03-1508 </papid>knight &amp; graehl, 1998).<papid> J98-4003 </papid></citsent>
<aftsection>
<nextsent>in this paper we discuss the limitations of such an approach and address its problems by firstly proposing paradigm that allows direct orthographic mapping (dom), secondly further proposing joint source-channel model as realization of dom.
</nextsent>
<nextsent>two other machine learning techniques, ncm and id3 (quinlan, 1993) decision tree, also are implemented under dom as reference to compare with the proposed n-gram tm.
</nextsent>
<nextsent>this paper is organized as follows: in section 2, we present the transliteration problems.
</nextsent>
<nextsent>in section 3, joint source-channel model is formulated.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3903">
<title id=" P01-1059.xml">producing biographical summaries combining linguistic knowledge with corpus statistics </title>
<section> producing biographical descriptions.  </section>
<citcontext>
<prevsection>
<prevsent>73 docs, 38,000 words, 24 polay sentences, 10 extracted appositives, 3 groups: leader, founder and commander-in-chief.
</prevsent>
<prevsent>2.1 preprocessing.
</prevsent>
</prevsection>
<citsent citstr=" M95-1012 ">
each document in the collection to be summarized is processed by sentence tokenizer, the alembic part-of-speech tagger (aberdeen et al 1995), <papid> M95-1012 </papid>the nametag named entity tagger (krupka 1995) <papid> M95-1018 </papid>restricted to people names, and the cass parser (abney 1996).</citsent>
<aftsection>
<nextsent>the tagged sentences are further analyzed by cascade of finite state machines leveraging patterns with lexical and syntactic information,to identify constructions such as pre- and post modifying appositive phrases, e.g., presidential candidate george bush?, bush, the presidential candidate?, and relative clauses, e.g., senator ..., who is running for re-election this fall,?.
</nextsent>
<nextsent>these appositive phrases and relative clauses capture descriptive information which can correspond variously to persons age, occupation, or some role person played in an incident.
</nextsent>
<nextsent>in addition, we also extract sentential descriptions in the form of sentences whose (deep) subjects are person names.
</nextsent>
<nextsent>2.2 cross-document coreference.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3904">
<title id=" P01-1059.xml">producing biographical summaries combining linguistic knowledge with corpus statistics </title>
<section> producing biographical descriptions.  </section>
<citcontext>
<prevsection>
<prevsent>73 docs, 38,000 words, 24 polay sentences, 10 extracted appositives, 3 groups: leader, founder and commander-in-chief.
</prevsent>
<prevsent>2.1 preprocessing.
</prevsent>
</prevsection>
<citsent citstr=" M95-1018 ">
each document in the collection to be summarized is processed by sentence tokenizer, the alembic part-of-speech tagger (aberdeen et al 1995), <papid> M95-1012 </papid>the nametag named entity tagger (krupka 1995) <papid> M95-1018 </papid>restricted to people names, and the cass parser (abney 1996).</citsent>
<aftsection>
<nextsent>the tagged sentences are further analyzed by cascade of finite state machines leveraging patterns with lexical and syntactic information,to identify constructions such as pre- and post modifying appositive phrases, e.g., presidential candidate george bush?, bush, the presidential candidate?, and relative clauses, e.g., senator ..., who is running for re-election this fall,?.
</nextsent>
<nextsent>these appositive phrases and relative clauses capture descriptive information which can correspond variously to persons age, occupation, or some role person played in an incident.
</nextsent>
<nextsent>in addition, we also extract sentential descriptions in the form of sentences whose (deep) subjects are person names.
</nextsent>
<nextsent>2.2 cross-document coreference.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3905">
<title id=" P01-1059.xml">producing biographical summaries combining linguistic knowledge with corpus statistics </title>
<section> producing biographical descriptions.  </section>
<citcontext>
<prevsection>
<prevsent>are recorded.
</prevsent>
<prevsent>passive constructions are also recognized and the object of the by-pp following the verb is taken as the deep subject.
</prevsent>
</prevsection>
<citsent citstr=" J90-1003 ">
strength of association between subject and verb is measured using mutual information (church and hanks 1990): )<papid> J90-1003 </papid>ln(),( ji ij tftf tfnjimi ? ?</citsent>
<aftsection>
<nextsent>= . here tfij is the maximum frequency of subject-verb pair ij in the reuters corpus, tfi is the frequency of subject head noun in the corpus, tfj is the frequency of verb in the corpus, and is the number of terms in the corpus.
</nextsent>
<nextsent>the associations are only scored for tf counts greater than 4, and threshold 3 (set to log score   -21 in our work) is used for strong association.
</nextsent>
<nextsent>the relative clauses are thus filtered initially (filter 1) by excluding those whose main verbs are highly promiscuous.
</nextsent>
<nextsent>next, they are filtered (filter 2) based on various syntactic features, as well as the number of proper names and pronouns.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3906">
<title id=" P01-1059.xml">producing biographical summaries combining linguistic knowledge with corpus statistics </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>methods for evaluating text summarization can be broadly classified into two categories (sparck-jones and galli ers 1996).
</prevsent>
<prevsent>the first, an extrinsic evaluation, tests the summarization based on how it affects the completion of some other task, such as comprehension, e.g., (morris et al 1992), or relevance assessment (brandow et al 1995) (jing et al 1998) (tombros and sanderson 1998) (mani et al 1998).
</prevsent>
</prevsection>
<citsent citstr=" W00-0401 ">
an intrinsic evaluation, on the other hand, can involve assessing the coherence of the summary (brandow et al 1995) (saggion and lapalme 2000).<papid> W00-0401 </papid></citsent>
<aftsection>
<nextsent>another intrinsic approach involves assessing the informative ness of the summary, based on to what extent key information from the source is preserved in the system summary at different levels of compression (paice and jones 1993), (brandow et al 1995).
</nextsent>
<nextsent>informative ness can also be assessed in terms of how much information in an ideal (or reference?)
</nextsent>
<nextsent>summary is preserved in the system summary, where the summaries being compared are at similar levels of compression (edmundson 1969).
</nextsent>
<nextsent>we have carried out number of intrinsic evaluations of the accuracy of components involved in the summarization process, as well as the succinct ness, coherence and informative ness of the descriptions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3907">
<title id=" P01-1059.xml">producing biographical summaries combining linguistic knowledge with corpus statistics </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in the learners, the best verb feature is used heavily in tests for the negative class, whereas in barrys rules it occurs in tests for the positive class.
</prevsent>
<prevsent>our work on measuring subject-verb associations has different focus from the previous work.
</prevsent>
</prevsection>
<citsent citstr=" P99-1005 ">
(lee and pereira 1999), <papid> P99-1005 </papid>for example, examined verb-object pairs.</citsent>
<aftsection>
<nextsent>their focus was on method that would improve techniques for gathering statistics where there are multitude of sparse examples.
</nextsent>
<nextsent>we are focusing on the use of the verbs for the specific purpose of finding associations that we have previously observed to be strong, with view towards selecting clause or sentence, rather than just to measure similarity.
</nextsent>
<nextsent>we also try to strengthen the numbers by dealing with gapped?
</nextsent>
<nextsent>constructions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3908">
<title id=" P01-1059.xml">producing biographical summaries combining linguistic knowledge with corpus statistics </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>we also try to strengthen the numbers by dealing with gapped?
</prevsent>
<prevsent>constructions.
</prevsent>
</prevsection>
<citsent citstr=" J98-3005 ">
while there has been plenty of work on extracting named entities and relations between them, e.g., (muc-7 1998), the main previous body of work on biographical summarization is that of (radev and mckeown 1998).<papid> J98-3005 </papid></citsent>
<aftsection>
<nextsent>the fundamental differences in our work are as follows: (1) we extract not only appositive phrases, but also clauses at large based on corpus statistics; (2) we make heavy use of coreference, whereas they dont use coreference at all; (3) we focus on generating succinct descriptions by removing redundancy and merging, whereas they categorize descriptions using wordnet, without focus on succinctness.
</nextsent>
<nextsent>this research has described and evaluated techniques for producing novel kind of summary called biographical summaries.
</nextsent>
<nextsent>the techniques use syntactic analysis and semantic type-checking (from wordnet), in combination with variety of corpus statistics.
</nextsent>
<nextsent>future directions could include improved sentential descriptions as well as further intrinsic and extrinsic evaluations of the summarizer as whole (i.e., including canned text).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3909">
<title id=" N12-1061.xml">automatic parallel fragment extraction from noisy data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>isolating these parallel fragments from the noisy data in which they are contained frees us from noisy alignments and stray links that can severely constrain translation-rule extraction.
</prevsent>
<prevsent>we do this with existing machinery, making use of an existing word alignment model for this task.we evaluate the quality and utility of the extracted data on large-scale chinese-english andarabic-english translation tasks and show significant improvements over state-of-the-art baseline.
</prevsent>
</prevsection>
<citsent citstr=" P01-1005 ">
a decade ago, banko and brill (2001) <papid> P01-1005 </papid>showed that scaling to very large corpora is game-changing for avariety of tasks.</citsent>
<aftsection>
<nextsent>methods that work well in small data setting often lose their luster when moving to large data.
</nextsent>
<nextsent>conversely, other methods that seem to perform poorly in that same small-data setting, may perform markedly differently when trained on large data.
</nextsent>
<nextsent>perhaps most importantly, banko and brill showed that there was no significant variation in performance among variety of methods trained at scale with large training data.
</nextsent>
<nextsent>the takeaway?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3910">
<title id=" N12-1061.xml">automatic parallel fragment extraction from noisy data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we need to learn how to do more with the data we already have.
</prevsent>
<prevsent>previous work has focused on detecting parallel documents and sentences on theweb, e.g.
</prevsent>
</prevsection>
<citsent citstr=" W04-3208 ">
(zhao and vogel, 2002; fung and cheung, 2004; <papid> W04-3208 </papid>wu and fung, 2005).<papid> I05-1023 </papid></citsent>
<aftsection>
<nextsent>munteanu and marcu (2006), <papid> P06-1011 </papid>and later quirk et al (2007), extend the state-of-the-art for this task to parallel fragments.in this paper, we present novel method for detecting parallel fragments in large, existing and potentially noisy parallel corpora using existing ma 538 chinery and show significant improvements to two state-of-the-art mt systems.</nextsent>
<nextsent>we also depart from previous work in that we only consider parallel corpora that have previously been cleaned, sanitized, and thought to be non-noisy, e.g. parallel corpora available from ldc.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3911">
<title id=" N12-1061.xml">automatic parallel fragment extraction from noisy data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we need to learn how to do more with the data we already have.
</prevsent>
<prevsent>previous work has focused on detecting parallel documents and sentences on theweb, e.g.
</prevsent>
</prevsection>
<citsent citstr=" I05-1023 ">
(zhao and vogel, 2002; fung and cheung, 2004; <papid> W04-3208 </papid>wu and fung, 2005).<papid> I05-1023 </papid></citsent>
<aftsection>
<nextsent>munteanu and marcu (2006), <papid> P06-1011 </papid>and later quirk et al (2007), extend the state-of-the-art for this task to parallel fragments.in this paper, we present novel method for detecting parallel fragments in large, existing and potentially noisy parallel corpora using existing ma 538 chinery and show significant improvements to two state-of-the-art mt systems.</nextsent>
<nextsent>we also depart from previous work in that we only consider parallel corpora that have previously been cleaned, sanitized, and thought to be non-noisy, e.g. parallel corpora available from ldc.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3912">
<title id=" N12-1061.xml">automatic parallel fragment extraction from noisy data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>previous work has focused on detecting parallel documents and sentences on theweb, e.g.
</prevsent>
<prevsent>(zhao and vogel, 2002; fung and cheung, 2004; <papid> W04-3208 </papid>wu and fung, 2005).<papid> I05-1023 </papid></prevsent>
</prevsection>
<citsent citstr=" P06-1011 ">
munteanu and marcu (2006), <papid> P06-1011 </papid>and later quirk et al (2007), extend the state-of-the-art for this task to parallel fragments.in this paper, we present novel method for detecting parallel fragments in large, existing and potentially noisy parallel corpora using existing ma 538 chinery and show significant improvements to two state-of-the-art mt systems.</citsent>
<aftsection>
<nextsent>we also depart from previous work in that we only consider parallel corpora that have previously been cleaned, sanitized, and thought to be non-noisy, e.g. parallel corpora available from ldc.
</nextsent>
<nextsent>in order to extract previously un extractable good parallel data, we must first detect the bad data.
</nextsent>
<nextsent>in doing so, we will make use of existing machinery in novel way.
</nextsent>
<nextsent>we directly use the alignment model to detect weak or undesirable data for translation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3913">
<title id=" N12-1061.xml">automatic parallel fragment extraction from noisy data </title>
<section> detecting noisy data.  </section>
<citcontext>
<prevsection>
<prevsent>we directly use the alignment model to detect weak or undesirable data for translation.
</prevsent>
<prevsent>2.1 alignment model as noisy data detector.
</prevsent>
</prevsection>
<citsent citstr=" D11-1046 ">
the alignment model we use in our experiments is that described in (riesa et al, 2011), <papid> D11-1046 </papid>modified to output full derivation trees and model scores along with alignments.</citsent>
<aftsection>
<nextsent>our reasons for using this particular alignment method are twofold: it provides natural way to hierarchically partition sub sentential segments, and is also empirically quite accurate in modeling word alignments, in general.
</nextsent>
<nextsent>this latter quality is important, not solely for downstream translation quality, but also for the basis of our claims with respect to detecting noisy or unsuitable data:the alignment model we employ is discriminatively trained to know what good alignments between parallel data look like.
</nextsent>
<nextsent>when this model predicts an alignment with low model score, given aninput sentence pair, we might say the model is con fused.?
</nextsent>
<nextsent>in this case, the alignment probably doesnt look like the examples it has been trained on.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3917">
<title id=" N12-1061.xml">automatic parallel fragment extraction from noisy data </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>we make the rather strong as 540 sump tion that this is the bottom 10% of the data.4
</prevsent>
<prevsent>we evaluate our parallel fragment extraction in large-scale chinese-english and arabic-english mt setting.
</prevsent>
</prevsection>
<citsent citstr=" N04-1035 ">
in our experiments we use tree-to-string syntax-based mt system (galley et al, 2004), <papid> N04-1035 </papid>and evaluate on standard test set, nist08.</citsent>
<aftsection>
<nextsent>we parse the english side of our parallel corpus with the berkeley parser (petrov et al, 2006), <papid> P06-1055 </papid>and tune parameters of themt systemwithmira (chiang et al, 2008).<papid> D08-1024 </papid></nextsent>
<nextsent>we decode with an integrated language model trained on about 4 billion words of english.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3918">
<title id=" N12-1061.xml">automatic parallel fragment extraction from noisy data </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>we evaluate our parallel fragment extraction in large-scale chinese-english and arabic-english mt setting.
</prevsent>
<prevsent>in our experiments we use tree-to-string syntax-based mt system (galley et al, 2004), <papid> N04-1035 </papid>and evaluate on standard test set, nist08.</prevsent>
</prevsection>
<citsent citstr=" P06-1055 ">
we parse the english side of our parallel corpus with the berkeley parser (petrov et al, 2006), <papid> P06-1055 </papid>and tune parameters of themt systemwithmira (chiang et al, 2008).<papid> D08-1024 </papid></citsent>
<aftsection>
<nextsent>we decode with an integrated language model trained on about 4 billion words of english.
</nextsent>
<nextsent>chinese-english we align parallel corpus of8.4m parallel segments, with 210m words of english and 193m words of chinese.
</nextsent>
<nextsent>from this we extract 868,870 parallel fragments according to the process described in section 2, and append these fragments to the end of the parallel corpus.
</nextsent>
<nextsent>in doing so, we have created larger parallel corpus of 9.2m parallel segments, consisting of 217m and 198m words of english and chinese, respectively.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3919">
<title id=" N12-1061.xml">automatic parallel fragment extraction from noisy data </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>we evaluate our parallel fragment extraction in large-scale chinese-english and arabic-english mt setting.
</prevsent>
<prevsent>in our experiments we use tree-to-string syntax-based mt system (galley et al, 2004), <papid> N04-1035 </papid>and evaluate on standard test set, nist08.</prevsent>
</prevsection>
<citsent citstr=" D08-1024 ">
we parse the english side of our parallel corpus with the berkeley parser (petrov et al, 2006), <papid> P06-1055 </papid>and tune parameters of themt systemwithmira (chiang et al, 2008).<papid> D08-1024 </papid></citsent>
<aftsection>
<nextsent>we decode with an integrated language model trained on about 4 billion words of english.
</nextsent>
<nextsent>chinese-english we align parallel corpus of8.4m parallel segments, with 210m words of english and 193m words of chinese.
</nextsent>
<nextsent>from this we extract 868,870 parallel fragments according to the process described in section 2, and append these fragments to the end of the parallel corpus.
</nextsent>
<nextsent>in doing so, we have created larger parallel corpus of 9.2m parallel segments, consisting of 217m and 198m words of english and chinese, respectively.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3920">
<title id=" N12-1061.xml">automatic parallel fragment extraction from noisy data </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>summing up, parallel data in the world is not unlimited.
</prevsent>
<prevsent>we cannot always continue to double our data for increased performance.
</prevsent>
</prevsection>
<citsent citstr=" C10-1124 ">
parallel data creation is expensive, and automatic discovery is resource-intensive (uszkoreit et al, 2010).<papid> C10-1124 </papid></citsent>
<aftsection>
<nextsent>we have presented technique that helps to squeeze more outof an already large, state-of-the-art mt system, using existing pieces of the pipeline to do so in novel way.
</nextsent>
<nextsent>acknowledgements this work was supported bydarpabolt via bbn subcontract hr0011-12-c-0014.
</nextsent>
<nextsent>we thank our three anonymous reviewers for thoughtful comments.
</nextsent>
<nextsent>thanks also to kevin knight, david chiang, liang huang, and philipp koehn for helpful discussions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3921">
<title id=" P01-1026.xml">organizing encyclopedic knowledge based on the web and its application to question answering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in addition, we apply an automatically generated encyclopedia to question answering system targeting the japanese information technology engineers examination.
</prevsent>
<prevsent>reflecting the growth in utilization of the world wide web, number of web-based language processing methods have been proposed within the natural language processing (nlp), information retrieval (ir)and artificial intelligence (ai) communities.
</prevsent>
</prevsection>
<citsent citstr=" P00-1062 ">
a sample of these includes methods to extract linguistic resources (fujii and ishikawa, 2000; <papid> P00-1062 </papid>resnik, 1999;<papid> P99-1068 </papid>soderland, 1997), retrieve useful information in response to user queries (etzioni, 1997; mccallum et al., 1999) and mine/discover knowledge latent in the web (inokuchi et al, 1999).</citsent>
<aftsection>
<nextsent>in this paper, mainly from an nlp point of view, we explore method to produce linguistic resources.specifically, we enhance the method proposed by fujii and ishikawa (2000), <papid> P00-1062 </papid>which extracts encyclopedic knowledge (i.e., term descriptions) from the web.</nextsent>
<nextsent>in brief, their method searches the web for pages containing term in question, and uses linguistic expressions and html layouts to extract fragments describing the term.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3922">
<title id=" P01-1026.xml">organizing encyclopedic knowledge based on the web and its application to question answering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in addition, we apply an automatically generated encyclopedia to question answering system targeting the japanese information technology engineers examination.
</prevsent>
<prevsent>reflecting the growth in utilization of the world wide web, number of web-based language processing methods have been proposed within the natural language processing (nlp), information retrieval (ir)and artificial intelligence (ai) communities.
</prevsent>
</prevsection>
<citsent citstr=" P99-1068 ">
a sample of these includes methods to extract linguistic resources (fujii and ishikawa, 2000; <papid> P00-1062 </papid>resnik, 1999;<papid> P99-1068 </papid>soderland, 1997), retrieve useful information in response to user queries (etzioni, 1997; mccallum et al., 1999) and mine/discover knowledge latent in the web (inokuchi et al, 1999).</citsent>
<aftsection>
<nextsent>in this paper, mainly from an nlp point of view, we explore method to produce linguistic resources.specifically, we enhance the method proposed by fujii and ishikawa (2000), <papid> P00-1062 </papid>which extracts encyclopedic knowledge (i.e., term descriptions) from the web.</nextsent>
<nextsent>in brief, their method searches the web for pages containing term in question, and uses linguistic expressions and html layouts to extract fragments describing the term.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3926">
<title id=" P01-1026.xml">organizing encyclopedic knowledge based on the web and its application to question answering </title>
<section> system design.  </section>
<citcontext>
<prevsection>
<prevsent>for this purpose, we classify extracted term descriptions based on word senses and domains.
</prevsent>
<prevsent>although number of methods have been proposed to generate word senses (for example, one based on the vector space model (schutze, 1998)), it is still difficult to accurately identify word senses without explicit dictionaries that define sense candidates.
</prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
in addition, since word senses are often associated with domains (yarowsky, 1995), <papid> P95-1026 </papid>word senses can be consequently distinguished by way of determining the domain of each description.</citsent>
<aftsection>
<nextsent>for example, different senses for pipeline (processing method/transportationpipe)?
</nextsent>
<nextsent>are associated with the computer and construction domains (fields), respectively.
</nextsent>
<nextsent>to sum up, the organization module classifies term descriptions based on domains, for which we use domain and description models.
</nextsent>
<nextsent>in section 3, we elaborate on our organization model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3928">
<title id=" P01-1026.xml">organizing encyclopedic knowledge based on the web and its application to question answering </title>
<section> statistical organization model.  </section>
<citcontext>
<prevsection>
<prevsent>3.2 domain model.
</prevsent>
<prevsent>the domain model quantifies the extent to which description is associated with domain c, which is fundamentally categorization task.
</prevsent>
</prevsection>
<citsent citstr=" A94-1027 ">
among number of existing categorization methods, we experimentally used one proposed by iwayama and tokunaga (1994), <papid> A94-1027 </papid>which formulates (c|d) as in equation (2).</citsent>
<aftsection>
<nextsent>p (c|d) = (c) ? ?
</nextsent>
<nextsent>t (t|c) ? (t|d) (t) (2) here, (t|d), (t|c) and (t) denote probabilities that word appears in d, and all the domains, respectively.
</nextsent>
<nextsent>we regard (c) as constant.
</nextsent>
<nextsent>while (t|d) is simply relative frequency of in d, we need predefined domains to compute (t|c) and (t).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3929">
<title id=" P01-1026.xml">organizing encyclopedic knowledge based on the web and its application to question answering </title>
<section> statistical organization model.  </section>
<citcontext>
<prevsection>
<prevsent>however, since google (i.e., the search engine used in our system) rates the quality of pages based on hyper link information, and selectively retrieves those with higher quality (brin and page, 1998), we tentatively regarded q (d) as constant.
</prevsent>
<prevsent>thus, in practice the description model is approximated solely with the language model as in equation (4).
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
p (d) ? l (d) (4) statistical approaches to language modeling have been used in much nlp research, such as machine translation (brown et al, 1993) <papid> J93-2003 </papid>and speech recognition (bahl et al, 1983).</citsent>
<aftsection>
<nextsent>our model is almost the same as existing models, but is different in two respects.
</nextsent>
<nextsent>first, while general language models quantify the extent to which given word sequence is linguistically acceptable, our model also quantifies the extent to which the input is acceptable as term description.thus, we trained the model based on an existing machine readable encyclopedia.
</nextsent>
<nextsent>we used the chasen morphological analyzer to segment the japanese cd-rom world encyclopedia (heibonsha, 1998) into words (we replaced headwords with common symbol), and then used the cmu-cambridge toolkit (clarkson and rosenfeld, 1997) to model word-based trigram.consequently, descriptions in which word sequences are more similar to those in the world encyclopedia are assigned greater probability scores through our language model.
</nextsent>
<nextsent>second, (d), which is product of probabilities for -grams in d, is quite sensitive to the length of d.in the cases of machine translation and speech recognition, this problem is less crucial because multiple candidates compared based on the language model are almost equivalent in terms of length.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3930">
<title id=" P01-1026.xml">organizing encyclopedic knowledge based on the web and its application to question answering </title>
<section> application.  </section>
<citcontext>
<prevsection>
<prevsent>to avoid this problem, we normalize (d) by the number of words contained in d.
</prevsent>
<prevsent>4.1 overview.
</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
encyclopedias generated through our web-basedmethod can be used in number of applications, including human usage, thesaurus production (hearst,1992; <papid> C92-2082 </papid>nakamura and nagao, 1988) <papid> C88-2098 </papid>and natural language understanding in general.among the above applications, natural language understanding (nlu) is the most challenging from scientific point of view.</citsent>
<aftsection>
<nextsent>current practical nlu research includes dialogue, information extraction and question answering, among which we focus solely on question answering (qa) in this paper.a straightforward application is to answer inter rogative questions like what is x??
</nextsent>
<nextsent>in which qa system searches the encyclopedia database for one or more descriptions related to (this application is also effective for dialog systems).in general, the performance of qa systems are evaluated based on coverage and accuracy.
</nextsent>
<nextsent>coverage is the ratio between the number of questions answered (disregarding their correctness) and the total number of questions.
</nextsent>
<nextsent>accuracy is the ratio between the number of correct answers and the total number of answers made by the system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3931">
<title id=" P01-1026.xml">organizing encyclopedic knowledge based on the web and its application to question answering </title>
<section> application.  </section>
<citcontext>
<prevsection>
<prevsent>to avoid this problem, we normalize (d) by the number of words contained in d.
</prevsent>
<prevsent>4.1 overview.
</prevsent>
</prevsection>
<citsent citstr=" C88-2098 ">
encyclopedias generated through our web-basedmethod can be used in number of applications, including human usage, thesaurus production (hearst,1992; <papid> C92-2082 </papid>nakamura and nagao, 1988) <papid> C88-2098 </papid>and natural language understanding in general.among the above applications, natural language understanding (nlu) is the most challenging from scientific point of view.</citsent>
<aftsection>
<nextsent>current practical nlu research includes dialogue, information extraction and question answering, among which we focus solely on question answering (qa) in this paper.a straightforward application is to answer inter rogative questions like what is x??
</nextsent>
<nextsent>in which qa system searches the encyclopedia database for one or more descriptions related to (this application is also effective for dialog systems).in general, the performance of qa systems are evaluated based on coverage and accuracy.
</nextsent>
<nextsent>coverage is the ratio between the number of questions answered (disregarding their correctness) and the total number of questions.
</nextsent>
<nextsent>accuracy is the ratio between the number of correct answers and the total number of answers made by the system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3932">
<title id=" P01-1026.xml">organizing encyclopedic knowledge based on the web and its application to question answering </title>
<section> application.  </section>
<citcontext>
<prevsection>
<prevsent>4.4 related work.
</prevsent>
<prevsent>motivated partially by the trec-8 qa collection (voorhees and tice, 2000), question answering has of late become one of the major topics within the nlp/ir communities.
</prevsent>
</prevsection>
<citsent citstr=" C00-1043 ">
in fact, number of qa systems targeting the trec qa collection have recently been proposed (harabagiu et al, 2000; <papid> C00-1043 </papid>moldovan and harabagiu, 2000; prager et al, 2000).</citsent>
<aftsection>
<nextsent>those systems are commonly termed open-domain?
</nextsent>
<nextsent>systems, because questions expressed in natural language are not necessarily limited to explicit axes, including who, what, when, where, how and why.
</nextsent>
<nextsent>however, moldovan and harabagiu (2000) found that each of the trec questions can be recast as either single axis or combination of axes.
</nextsent>
<nextsent>they also found that out of the 200 trec questions, 64 questions (approximately one third) were associated with the what axis, for which the web-based encyclopedia is expected to improve the quality of answers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3934">
<title id=" P02-1031.xml">the necessity of parsing for predicate argument recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>statistical systems have be entrained to automatically label semantic roles from the output of statistical parsers on unannotated text.
</prevsent>
<prevsent>in this paper, we quantify the eect of parser accuracy on these systems  performance, and examine the question of whether atter \chunked  representation of the in put can be as eective for the purposes of semantic role identi cation.
</prevsent>
</prevsection>
<citsent citstr=" M98-1009 ">
over the past decade, most work in the eld of information extraction has shifted from complex rule-based, systems designed to handle wide variety of semantic phenomena including quan ti cation, anaphora, aspect and modality (e.g.alshawi (1992)), to simpler nite-state or statistical systems such as hobbs et al (1997) and miller et al (1998).<papid> M98-1009 </papid></citsent>
<aftsection>
<nextsent>much of the evaluation of these systems has been conducted on extracting relations for speci semantic domains such as corporate acquisitions or terrorist events in the framework of the darpa message understanding conferences.recently, attention has turned to creating corpora annotated for argument structure for broader range of predicates.
</nextsent>
<nextsent>the propbank project at the university of pennsylvania (kings bury and palmer, 2002) and the framenet project at the international computer science institute(baker et al, 1998) <papid> P98-1013 </papid>share the goal of documenting the syntactic realization of arguments of the predicates of the general english lexicon by annotating corpus with semantic roles.</nextsent>
<nextsent>even for single predicate, semantic arguments often have multiple syntactic realizations, as shown by the following paraphrases: (1) john will meet with mary.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3935">
<title id=" P02-1031.xml">the necessity of parsing for predicate argument recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>over the past decade, most work in the eld of information extraction has shifted from complex rule-based, systems designed to handle wide variety of semantic phenomena including quan ti cation, anaphora, aspect and modality (e.g.alshawi (1992)), to simpler nite-state or statistical systems such as hobbs et al (1997) and miller et al (1998).<papid> M98-1009 </papid></prevsent>
<prevsent>much of the evaluation of these systems has been conducted on extracting relations for speci semantic domains such as corporate acquisitions or terrorist events in the framework of the darpa message understanding conferences.recently, attention has turned to creating corpora annotated for argument structure for broader range of predicates.</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
the propbank project at the university of pennsylvania (kings bury and palmer, 2002) and the framenet project at the international computer science institute(baker et al, 1998) <papid> P98-1013 </papid>share the goal of documenting the syntactic realization of arguments of the predicates of the general english lexicon by annotating corpus with semantic roles.</citsent>
<aftsection>
<nextsent>even for single predicate, semantic arguments often have multiple syntactic realizations, as shown by the following paraphrases: (1) john will meet with mary.
</nextsent>
<nextsent>john will meet mary.
</nextsent>
<nextsent>john and mary will meet.
</nextsent>
<nextsent>(2) the door opened.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3936">
<title id=" P02-1031.xml">the necessity of parsing for predicate argument recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>mary opened the door.
</prevsent>
<prevsent>correctly identifying the semantic roles of the sentence constituents is crucial part of interpreting text, and in addition to forming an important part of the information extraction problem, can serve as an intermediate step in machine translation or automatic summarization.
</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
in this paper, we examine how the information provided by modern statistical parsers such as collins (1997) <papid> P97-1003 </papid>and charniak (1997) contributes to solving thisproblem.</citsent>
<aftsection>
<nextsent>we measure the eect of parser accuracy on semantic role prediction from parse trees, and determine whether complete tree is indeed necessary for accurate role prediction.gildea and jurafsky (2002) <papid> J02-3001 </papid>describe statistical system trained on the data from the framenet project to automatically assign semantic roles.the system rst passed sentences through an automatic parser, extracted syntactic features fromthe parses, and estimated probabilities for semantic roles from the syntactic and lexical features.both training and test sentences were automatically parsed, as no hand-annotated parse trees were available for the corpus.</nextsent>
<nextsent>while the errors introduced by the parser no doubt negatively affected the results obtained, there was no direct way of quantifying this eect.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3937">
<title id=" P02-1031.xml">the necessity of parsing for predicate argument recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>correctly identifying the semantic roles of the sentence constituents is crucial part of interpreting text, and in addition to forming an important part of the information extraction problem, can serve as an intermediate step in machine translation or automatic summarization.
</prevsent>
<prevsent>in this paper, we examine how the information provided by modern statistical parsers such as collins (1997) <papid> P97-1003 </papid>and charniak (1997) contributes to solving thisproblem.</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
we measure the eect of parser accuracy on semantic role prediction from parse trees, and determine whether complete tree is indeed necessary for accurate role prediction.gildea and jurafsky (2002) <papid> J02-3001 </papid>describe statistical system trained on the data from the framenet project to automatically assign semantic roles.the system rst passed sentences through an automatic parser, extracted syntactic features fromthe parses, and estimated probabilities for semantic roles from the syntactic and lexical features.both training and test sentences were automatically parsed, as no hand-annotated parse trees were available for the corpus.</citsent>
<aftsection>
<nextsent>while the errors introduced by the parser no doubt negatively affected the results obtained, there was no direct way of quantifying this eect.
</nextsent>
<nextsent>of the systems evaluated for the message understanding conference task, miller et al (1998) <papid> M98-1009 </papid>made use of an integrated syntactic and semantic model producing full parse tree, and achieved results comparable to other systems that did not make use of complete parse.</nextsent>
<nextsent>as in the framenet case, the parser wasnot trained on the corpus for which semantic annotations were available, and the eect of better, or even perfect, parses could not be measured.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3945">
<title id=" P02-1031.xml">the necessity of parsing for predicate argument recognition </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>both propbank and framenet tend to include longer arguments with internal syntactic structure, making parsing decisions more important in nding argument boundaries.
</prevsent>
<prevsent>they also involve abstract relations, with wide variety of possible llers for each role.
</prevsent>
</prevsection>
<citsent citstr=" A97-1029 ">
our chunk-based system takes the last word of the chunk as its head word for the purposes of predicting roles, but does not make use of the identities of the chunk other words or the intervening words between chunk and the predicate, unlike hidden markov model-like systems such as bikel et al (1997), <papid> A97-1029 </papid>mccallum et al (2000) and laerty et al (2001).</citsent>
<aftsection>
<nextsent>while more elaborate nite-state system might do better, it is possible that additional features would not be helpful given the small amount of data for each predicate.
</nextsent>
<nextsent>by using gold-standard chunking representation, we have obtained higher performance over what could be expected from an entirely automatic system based on at representation of the data.
</nextsent>
<nextsent>we feel that our results show that statistical parsers, although computationally expensive, do good job of providing relevant information for semantic interpretation.
</nextsent>
<nextsent>not only the constituent structure but also head word information, produced as side product, are important features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3946">
<title id=" P02-1056.xml">an integrated architecture for shallow and deep processing </title>
<section> architecture.  </section>
<citcontext>
<prevsection>
<prevsent>representation), and an internal online?
</prevsent>
<prevsent>multi-levelannotation chart (index-sequential access).
</prevsent>
</prevsection>
<citsent citstr=" A97-1035 ">
following the trichotomy of nlp data representation models in (cunningham et al, 1997), <papid> A97-1035 </papid>the xml markup contains additive information, while the multi-levelchart contains positional and abstraction-based information, e.g., feature structures representing nlp entities in uniform, linguistically motivated form.applications and the integrated components access the wham results through an object-oriented programming (oop) interface which is designed as general as possible in order to abstract from component-specific details (but preserving shallow and deep paradigms).</citsent>
<aftsection>
<nextsent>the interfaces of the actually integrated components form subclasses of the generic interface.
</nextsent>
<nextsent>new components can be integrated by implementing this interface and specifying dtds and/or transformation rules for the chart.
</nextsent>
<nextsent>the oop interface consists of iterators that walk through the different annotation levels (e.g., token spans, sentences), reference and seek operators that allow to switch to corresponding annotations on different level (e.g., give all tokens of the current sentence, or move to next named entity starting from given token position), and access or methods that return the linguistic information contained in the chart.
</nextsent>
<nextsent>similarily, general methods support navigating the type system and feature structures of the dnlp components.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3947">
<title id=" P02-1056.xml">an integrated architecture for shallow and deep processing </title>
<section> integration.  </section>
<citcontext>
<prevsection>
<prevsent>in the integrated system, unknown nouns and nes canbe recognized by sppc, which determines morphosyntactic information.
</prevsent>
<prevsent>it is essential for the deep system to associate nouns with their semantic sorts bothfor semantics construction, and for providing semantically based selectional restrictions to help constraining the search space during deep parsing.
</prevsent>
</prevsection>
<citsent citstr=" W97-0802 ">
germanet (hamp and feldweg, 1997) <papid> W97-0802 </papid>is large lexical database, where words are associated with pos information and semantic sorts, which are organized in fine-grained hierarchy.</citsent>
<aftsection>
<nextsent>the hpsg lexicon, on the other hand, is comparatively small and has more coarse-grained semantic classification.to provide the missing sort information when recovering unknown noun entries via sppc, mapping from the germanet semantic classification to the hpsg semantic classification (siegel et al,2001) is applied which has been automatically acquired.
</nextsent>
<nextsent>the training material for this learning process are those words that are both annotated with semantic sorts in the hpsg lexicon and with synsets of germanet.
</nextsent>
<nextsent>the learning algorithm computes amapping relevance measure for associating semantic concepts in germanet with semantic sorts in thehpsg lexicon.
</nextsent>
<nextsent>for evaluation, we examined corpus of 4664 nouns extracted from business news that were not contained in the hpsg lexicon.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3948">
<title id=" P02-1056.xml">an integrated architecture for shallow and deep processing </title>
<section> integration.  </section>
<citcontext>
<prevsection>
<prevsent>this topological model of german clause structure is underspecified or partial as to non-sentential constituent boundaries, but provides linguistically well-motivated, and theory-neutral macro structure for complex sentences.
</prevsent>
<prevsent>due to its linguistic underpinning the topological model provides pre-partitioning of complex sentences that is (i) highly compatible with deep syntactic structure sand (ii) maximally effective to increase parsing efficiency.
</prevsent>
</prevsection>
<citsent citstr=" C02-1093 ">
at the same time (iii) partiality regarding the constituency of non-sentential material ensures the important aspects of robustness, coverage, and processing efficiency.in (becker and frank, 2002) <papid> C02-1093 </papid>we present corpus driven stochastic topological parser for german, based on topological restructuring of the negra corpus (brants et al, 1999).</citsent>
<aftsection>
<nextsent>for topological tree bank conversion we build on methods and results in (frank, 2001).
</nextsent>
<nextsent>the stochastic topological parser follows the probabilistic model of non-lexicalised pcfgs (charniak, 1996).
</nextsent>
<nextsent>due to abstraction from constituency decisions at the sub-sentential level,and the essentially pos-driven nature of topol ogi cal structure, this rather simple probabilistic model yields surprisingly high figures of accuracy and coverage (see fig.2 and (becker and frank, 2002) <papid> C02-1093 </papid>for more detail), while context-free parsing guarantees efficient processing.the next step is to elaborate (partial) mapping of shallow topological and deep syntactic structures that is maximally effective for preference-gui topological structure: cl-v2 vf-topic lk-fin mf rk-t nn vvfin adv nn prep nn vvfin [   [     peter] [   it] [  gerne wurstchen mit kartoffelsalat] [  ff -]] peter eats happily sausages with potato salad deep syntactic structure: [ fi [ fl peter] [ ffi [  it] [   gerne [  [ fl wurstchen [ fi mit [ fl kartoffelsalat]]] [  ff -]]]]] mapping: cl-v2 ! cp, vf-topic ! xp, lk-fin ! v,   lk-fin mf rk-t #!</nextsent>
<nextsent>c?,   mf rk-t #fi!</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3952">
<title id=" P02-1056.xml">an integrated architecture for shallow and deep processing </title>
<section> applications.  </section>
<citcontext>
<prevsection>
<prevsent>the pattern based grammar yields good results by recognition of local relationships as in (1).
</prevsent>
<prevsent>the unification based rules are applied to the deep analysis results.
</prevsent>
</prevsection>
<citsent citstr=" P01-1019 ">
given the fine-grained syntactic and semantic analysis of the hpsg grammar and its robustness (through snlp integration), we decided to use the semantic representation (mrs, see (copestake et al, 2001)) <papid> P01-1019 </papid>as additional input for ie.</citsent>
<aftsection>
<nextsent>the reason is that mrss express precise relationships between the chunks, in particular, in constructions involving(combinations of) free word order, long distance dependencies, control and raising, or passive, which are very difficult, if not impossible, to recognize for pattern-based grammar.
</nextsent>
<nextsent>e.g., the short sentence(2) illustrates combination of free word order, control, and passive.
</nextsent>
<nextsent>the subject of the passive verb wurde gebeten is located in the middle field and is at the same time the subject of the infinitive verbzu ubernehmen.
</nextsent>
<nextsent>a deep (hpsg) analysis can recognize the dependencies quite easily, whereas pattern based grammar cannot determine, e.g., for which verb peter miscke or dietmar hopp is the subject.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3953">
<title id=" P02-1056.xml">an integrated architecture for shallow and deep processing </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>the integration is realized through the metaphor of textual annotation.
</prevsent>
<prevsent>to best of our knowledge, this is the first implemented system which integrates high-performance shallow processing with an advanced deep hpsg based analysis system.
</prevsent>
</prevsection>
<citsent citstr=" P01-1034 ">
there exists only very little other work that considers integration of shallow and deep nlp using an xml based architecture, most notably (grover and lascarides, 2001).<papid> P01-1034 </papid></citsent>
<aftsection>
<nextsent>however, their integration efforts are largly limited to the level of pos tag information.
</nextsent>
<nextsent>acknowledgements this work was supported by research grant from the german federal ministry of education, science, research and technology (bmbf) to the dfki project white board, fkz: 01 iw 002.
</nextsent>
<nextsent>special thanks to ulrich callmeier for his technical support concerning the integration of pet.
</nextsent>

</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3954">
<title id=" P02-1065.xml">memory based learning of morphology with stochastic transducers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>two approaches are presented: first, using the transducers directly to model the process,and secondly using them to define similarity measure, related to the fisher kernel method (jaakkola and haussler, 1998),and then using memory-based learning (mbl) technique.
</prevsent>
<prevsent>these are evaluated and compared on datasets from english, german, slovene and arabic.
</prevsent>
</prevsection>
<citsent citstr=" C94-1029 ">
finite-state methods are in large part adequate to model morphological processes in many languages.a standard methodology is that of two-level morphology (koskenniemi, 1983) which is capable of handling the complexity of finnish, though it needs substantial extensions to handle non-concatenativelanguages such as arabic (kiraz, 1994).<papid> C94-1029 </papid></citsent>
<aftsection>
<nextsent>these models are primarily concerned with the mapping from deep lexical strings to surface strings, and within this framework learning is in general difficult (itai,1994).
</nextsent>
<nextsent>in this paper present algorithms for learning the finite-state transduction between pairs of uninflected and inflected words.
</nextsent>
<nextsent>supervised learning of morphology.
</nextsent>
<nextsent>the techniques presented here are, however, applicable to learning other types of string transductions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3955">
<title id=" P02-1042.xml">building deep dependency structures using a wide coverage ccg parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a setof dependency structures used for training and testing the parser is obtained froma treebank of ccg normal-form derivations, which have been derived (semi-) automatically from the penn treebank.
</prevsent>
<prevsent>the parser correctly recovers over 80% of labelled dependencies, and around 90% of un labelled dependencies.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
most recent wide-coverage statistical parsers have used models based on lexical dependencies (e.g.collins (1999), charniak (2000)).<papid> A00-2018 </papid></citsent>
<aftsection>
<nextsent>however, the dependencies are typically derived from context-free phrase structure tree using simple head percolation heuristics.
</nextsent>
<nextsent>this approach does not work well for thelong-range dependencies involved in raising, control, extraction and coordination, all of which are common in text such as the wall street journal.
</nextsent>
<nextsent>chiang (2000) <papid> P00-1058 </papid>uses tree adjoining grammar as an alternative to context-free grammar, andhere we use another mildly context-sensitive?</nextsent>
<nextsent>formalism, combinatory categorial grammar (ccg, steedman (2000)), which arguably provides themost linguistically satisfactory account of the dependencies inherent in coordinate constructions and extraction phenomena.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3956">
<title id=" P02-1042.xml">building deep dependency structures using a wide coverage ccg parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, the dependencies are typically derived from context-free phrase structure tree using simple head percolation heuristics.
</prevsent>
<prevsent>this approach does not work well for thelong-range dependencies involved in raising, control, extraction and coordination, all of which are common in text such as the wall street journal.
</prevsent>
</prevsection>
<citsent citstr=" P00-1058 ">
chiang (2000) <papid> P00-1058 </papid>uses tree adjoining grammar as an alternative to context-free grammar, andhere we use another mildly context-sensitive?</citsent>
<aftsection>
<nextsent>formalism, combinatory categorial grammar (ccg, steedman (2000)), which arguably provides themost linguistically satisfactory account of the dependencies inherent in coordinate constructions and extraction phenomena.
</nextsent>
<nextsent>the potential advantage from using such an expressive grammar is to facilitate recovery of such unbounded dependencies.
</nextsent>
<nextsent>as well as having potential impact on the accuracy of the parser, recovering such dependencies may make the output more useful.ccg is unlike other formalisms in that the standard predicate-argument relations relevant to interpretation can be derived via extremely non-standardsurface derivations.
</nextsent>
<nextsent>this impacts on how best to define probability model for ccg, since the spurious ambiguity?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3957">
<title id=" P02-1042.xml">building deep dependency structures using a wide coverage ccg parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>of ccg derivations may lead to an exponential number of derivations forgiven constituent.
</prevsent>
<prevsent>in addition, some of the spurious derivations may not be present in the training data.
</prevsent>
</prevsection>
<citsent citstr=" P96-1011 ">
one solution is to consider only the normal-form (eis ner, 1996<papid> P96-1011 </papid>a) derivation, which is the route taken in hockenmaier and steedman (2002<papid> P02-1043 </papid>b).1 another problem with the non-standard surface derivations is that the standard parseval performance measures over such derivations are uninformative (clark and hockenmaier, 2002).</citsent>
<aftsection>
<nextsent>such measures have been criticised by lin (1995) and carroll et al (1998), who propose recovery of head dependencies characterising predicate-argument relations as more meaningful measure.
</nextsent>
<nextsent>if the end-result of parsing is interpretablepredicate-argument structure or the related dependency structure, then the question arises: why build derivation structure at all?
</nextsent>
<nextsent>a ccg parser can directly build derived structures, including long1another, more speculative, possibility is to treat the alternative derivations as hidden and apply the em algorithm.
</nextsent>
<nextsent>computational linguistics (acl), philadelphia, july 2002, pp.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3959">
<title id=" P02-1042.xml">building deep dependency structures using a wide coverage ccg parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>of ccg derivations may lead to an exponential number of derivations forgiven constituent.
</prevsent>
<prevsent>in addition, some of the spurious derivations may not be present in the training data.
</prevsent>
</prevsection>
<citsent citstr=" P02-1043 ">
one solution is to consider only the normal-form (eis ner, 1996<papid> P96-1011 </papid>a) derivation, which is the route taken in hockenmaier and steedman (2002<papid> P02-1043 </papid>b).1 another problem with the non-standard surface derivations is that the standard parseval performance measures over such derivations are uninformative (clark and hockenmaier, 2002).</citsent>
<aftsection>
<nextsent>such measures have been criticised by lin (1995) and carroll et al (1998), who propose recovery of head dependencies characterising predicate-argument relations as more meaningful measure.
</nextsent>
<nextsent>if the end-result of parsing is interpretablepredicate-argument structure or the related dependency structure, then the question arises: why build derivation structure at all?
</nextsent>
<nextsent>a ccg parser can directly build derived structures, including long1another, more speculative, possibility is to treat the alternative derivations as hidden and apply the em algorithm.
</nextsent>
<nextsent>computational linguistics (acl), philadelphia, july 2002, pp.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3966">
<title id=" P02-1042.xml">building deep dependency structures using a wide coverage ccg parser </title>
<section> the probability model.  </section>
<citcontext>
<prevsection>
<prevsent>of to), since our philosophy at this stage is to encode every argument as dependency, where possible.
</prevsent>
<prevsent>the number of dependency types may be reduced in future work.
</prevsent>
</prevsection>
<citsent citstr=" J97-4005 ">
the dag-like nature of the dependency structures makes it difficult to apply generative modelling techniques (abney, 1997; <papid> J97-4005 </papid>johnson et al, 1999), <papid> P99-1069 </papid>so we have defined conditional model, similar tothe model of collins (1996) <papid> P96-1025 </papid>see also the conditional model in eisner (1996<papid> P96-1011 </papid>b)).</citsent>
<aftsection>
<nextsent>while the model of collins (1996) <papid> P96-1025 </papid>is technically unsound (collins, 1999), our aim at this stage is to demonstrate that accurate, efficient wide-coverage parsing is possible with ccg, even with an over-simplified statistical model.</nextsent>
<nextsent>future work will look at alternative models.4 4the reentrancies creating the dag-like structures are fairly limited, and moreover determined by the lexical categories.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3967">
<title id=" P02-1042.xml">building deep dependency structures using a wide coverage ccg parser </title>
<section> the probability model.  </section>
<citcontext>
<prevsection>
<prevsent>of to), since our philosophy at this stage is to encode every argument as dependency, where possible.
</prevsent>
<prevsent>the number of dependency types may be reduced in future work.
</prevsent>
</prevsection>
<citsent citstr=" P99-1069 ">
the dag-like nature of the dependency structures makes it difficult to apply generative modelling techniques (abney, 1997; <papid> J97-4005 </papid>johnson et al, 1999), <papid> P99-1069 </papid>so we have defined conditional model, similar tothe model of collins (1996) <papid> P96-1025 </papid>see also the conditional model in eisner (1996<papid> P96-1011 </papid>b)).</citsent>
<aftsection>
<nextsent>while the model of collins (1996) <papid> P96-1025 </papid>is technically unsound (collins, 1999), our aim at this stage is to demonstrate that accurate, efficient wide-coverage parsing is possible with ccg, even with an over-simplified statistical model.</nextsent>
<nextsent>future work will look at alternative models.4 4the reentrancies creating the dag-like structures are fairly limited, and moreover determined by the lexical categories.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3968">
<title id=" P02-1042.xml">building deep dependency structures using a wide coverage ccg parser </title>
<section> the probability model.  </section>
<citcontext>
<prevsection>
<prevsent>of to), since our philosophy at this stage is to encode every argument as dependency, where possible.
</prevsent>
<prevsent>the number of dependency types may be reduced in future work.
</prevsent>
</prevsection>
<citsent citstr=" P96-1025 ">
the dag-like nature of the dependency structures makes it difficult to apply generative modelling techniques (abney, 1997; <papid> J97-4005 </papid>johnson et al, 1999), <papid> P99-1069 </papid>so we have defined conditional model, similar tothe model of collins (1996) <papid> P96-1025 </papid>see also the conditional model in eisner (1996<papid> P96-1011 </papid>b)).</citsent>
<aftsection>
<nextsent>while the model of collins (1996) <papid> P96-1025 </papid>is technically unsound (collins, 1999), our aim at this stage is to demonstrate that accurate, efficient wide-coverage parsing is possible with ccg, even with an over-simplified statistical model.</nextsent>
<nextsent>future work will look at alternative models.4 4the reentrancies creating the dag-like structures are fairly limited, and moreover determined by the lexical categories.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3975">
<title id=" P02-1042.xml">building deep dependency structures using a wide coverage ccg parser </title>
<section> the probability model.  </section>
<citcontext>
<prevsection>
<prevsent>h fi  fi  si  hai #  fl 1  $ is the set of dependencies.
</prevsent>
<prevsent>the probability of dependency structure can be written as follows: (7)  pi %fl     &fl;          the probability     can be approximated as follows: (8)    &amp;  ni ( 1  ci   xi  where xi is the local context for the ith word.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
wehave explained elsewhere (clark, 2002) how suit able features can be defined in terms of the  word, pos-tag pairs in the context, and how maximum entropy techniques can be used to estimate the probabilities, following ratnaparkhi (1996).<papid> W96-0213 </papid>we assume that each argument slot in the category sequence is filled independently, and write      as follows: (9)     %fl mi ( 1  hai     where hai is the head word filling the argument slotof the ith dependency, and is the number of dependencies entailed by the category sequence c. 3.1 estimating the dependency probabilities.</citsent>
<aftsection>
<nextsent>the estimation method is based on collins (1996).<papid> P96-1025 </papid></nextsent>
<nextsent>we assume that the probability of dependency only depends on those words involved in the dependency, together with their categories.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3979">
<title id=" P02-1042.xml">building deep dependency structures using a wide coverage ccg parser </title>
<section> the parser.  </section>
<citcontext>
<prevsection>
<prevsent>the parser analyses sentence in two stages.
</prevsent>
<prevsent>first, in order to limit the number of categories assigned to each word in the sentence, supertagger?
</prevsent>
</prevsection>
<citsent citstr=" J99-2004 ">
(ban galore and joshi, 1999) <papid> J99-2004 </papid>assigns to each word small number of possible lexical categories.</citsent>
<aftsection>
<nextsent>the super tag ger (described in clark (2002)) assigns to each word all categories whose probabilities are within some constant factor, ?, of the highest probability category for that word, given the surrounding context.
</nextsent>
<nextsent>note that the super tagger does not provide single category sequence for each sentence, and the final sequence returned by the parser (along with the de pendencies) is determined by the probability model described in the previous section.
</nextsent>
<nextsent>the super tagger is performing two roles: cutting down the search space explored by the parser, and providing the category sequence model in equation 8.
</nextsent>
<nextsent>the super tagger consults category dictionary?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3987">
<title id=" P04-1006.xml">attention shifting for parsing speech </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this attention-shifting technique provides six-times increase in speed(measured as the number of parser analyses evalu ated) while performing equivalently when used asthe first-stage of multi-stage parsing-based language model.
</prevsent>
<prevsent>success in language modeling has been dominated by the linear n-gram for the past few decades.
</prevsent>
</prevsection>
<citsent citstr=" J01-2004 ">
a number of syntactic language models have proven to be competitive with the n-gram and better than the most popular n-gram, the trigram (roark, 2001; <papid> J01-2004 </papid>xu et al, 2002; <papid> P02-1025 </papid>charniak, 2001; <papid> P01-1017 </papid>hall and johnson, 2003).</citsent>
<aftsection>
<nextsent>language modeling for speech could well be the first real problem for which syntactic techniques are useful.
</nextsent>
<nextsent>john ate the pizza on plate with fork . np:plate np:fork pp:withpp:on in invb np vp:atefigure 1: an incomplete parse tree with head-word annotations.
</nextsent>
<nextsent>one reason that we expect syntactic models to perform well is that they are capable of modeling long-distance dependencies that simple n-gram ? this research was supported in part by nsf grants 9870676 and 0085940.
</nextsent>
<nextsent>models cannot.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3988">
<title id=" P04-1006.xml">attention shifting for parsing speech </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this attention-shifting technique provides six-times increase in speed(measured as the number of parser analyses evalu ated) while performing equivalently when used asthe first-stage of multi-stage parsing-based language model.
</prevsent>
<prevsent>success in language modeling has been dominated by the linear n-gram for the past few decades.
</prevsent>
</prevsection>
<citsent citstr=" P02-1025 ">
a number of syntactic language models have proven to be competitive with the n-gram and better than the most popular n-gram, the trigram (roark, 2001; <papid> J01-2004 </papid>xu et al, 2002; <papid> P02-1025 </papid>charniak, 2001; <papid> P01-1017 </papid>hall and johnson, 2003).</citsent>
<aftsection>
<nextsent>language modeling for speech could well be the first real problem for which syntactic techniques are useful.
</nextsent>
<nextsent>john ate the pizza on plate with fork . np:plate np:fork pp:withpp:on in invb np vp:atefigure 1: an incomplete parse tree with head-word annotations.
</nextsent>
<nextsent>one reason that we expect syntactic models to perform well is that they are capable of modeling long-distance dependencies that simple n-gram ? this research was supported in part by nsf grants 9870676 and 0085940.
</nextsent>
<nextsent>models cannot.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3989">
<title id=" P04-1006.xml">attention shifting for parsing speech </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this attention-shifting technique provides six-times increase in speed(measured as the number of parser analyses evalu ated) while performing equivalently when used asthe first-stage of multi-stage parsing-based language model.
</prevsent>
<prevsent>success in language modeling has been dominated by the linear n-gram for the past few decades.
</prevsent>
</prevsection>
<citsent citstr=" P01-1017 ">
a number of syntactic language models have proven to be competitive with the n-gram and better than the most popular n-gram, the trigram (roark, 2001; <papid> J01-2004 </papid>xu et al, 2002; <papid> P02-1025 </papid>charniak, 2001; <papid> P01-1017 </papid>hall and johnson, 2003).</citsent>
<aftsection>
<nextsent>language modeling for speech could well be the first real problem for which syntactic techniques are useful.
</nextsent>
<nextsent>john ate the pizza on plate with fork . np:plate np:fork pp:withpp:on in invb np vp:atefigure 1: an incomplete parse tree with head-word annotations.
</nextsent>
<nextsent>one reason that we expect syntactic models to perform well is that they are capable of modeling long-distance dependencies that simple n-gram ? this research was supported in part by nsf grants 9870676 and 0085940.
</nextsent>
<nextsent>models cannot.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3997">
<title id=" P04-1006.xml">attention shifting for parsing speech </title>
<section> parsing speech word-lattices.  </section>
<citcontext>
<prevsection>
<prevsent>although the language model can be used to rescore1 the word-lattice, it is typically used to select single hypothesis.
</prevsent>
<prevsent>we focus our attention in this paper to syntactic language modeling techniques that perform complete parsing, meaning that parse trees are built upon the strings in the word-lattice.
</prevsent>
</prevsection>
<citsent citstr=" J98-2004 ">
2.1 nbest list reranking much effort has been put forth in developing efficient probabilistic models for parsing strings (cara ballo and charniak, 1998; <papid> J98-2004 </papid>goldwater et al, 1998;blaheta and charniak, 1999; <papid> P99-1066 </papid>charniak, 2000; <papid> A00-2018 </papid>charniak, 2001); <papid> P01-1017 </papid>an obvious solution to parsing word lattices is to use nbest list reranking.</citsent>
<aftsection>
<nextsent>the nbestlist reranking procedure, depicted in figure 3, utilizes an external language model that selects set of strings from the word-lattice.
</nextsent>
<nextsent>these strings are analyzed by the parser which computes language model probability.
</nextsent>
<nextsent>this probability is combined 1to rescore word-lattice, each arch is assigned new score (probability) defined by new model (in combination with the acoustic model).
</nextsent>
<nextsent>w1, ..., wi, ..., wn1 ...
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3998">
<title id=" P04-1006.xml">attention shifting for parsing speech </title>
<section> parsing speech word-lattices.  </section>
<citcontext>
<prevsection>
<prevsent>although the language model can be used to rescore1 the word-lattice, it is typically used to select single hypothesis.
</prevsent>
<prevsent>we focus our attention in this paper to syntactic language modeling techniques that perform complete parsing, meaning that parse trees are built upon the strings in the word-lattice.
</prevsent>
</prevsection>
<citsent citstr=" P99-1066 ">
2.1 nbest list reranking much effort has been put forth in developing efficient probabilistic models for parsing strings (cara ballo and charniak, 1998; <papid> J98-2004 </papid>goldwater et al, 1998;blaheta and charniak, 1999; <papid> P99-1066 </papid>charniak, 2000; <papid> A00-2018 </papid>charniak, 2001); <papid> P01-1017 </papid>an obvious solution to parsing word lattices is to use nbest list reranking.</citsent>
<aftsection>
<nextsent>the nbestlist reranking procedure, depicted in figure 3, utilizes an external language model that selects set of strings from the word-lattice.
</nextsent>
<nextsent>these strings are analyzed by the parser which computes language model probability.
</nextsent>
<nextsent>this probability is combined 1to rescore word-lattice, each arch is assigned new score (probability) defined by new model (in combination with the acoustic model).
</nextsent>
<nextsent>w1, ..., wi, ..., wn1 ...
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q3999">
<title id=" P04-1006.xml">attention shifting for parsing speech </title>
<section> parsing speech word-lattices.  </section>
<citcontext>
<prevsection>
<prevsent>although the language model can be used to rescore1 the word-lattice, it is typically used to select single hypothesis.
</prevsent>
<prevsent>we focus our attention in this paper to syntactic language modeling techniques that perform complete parsing, meaning that parse trees are built upon the strings in the word-lattice.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
2.1 nbest list reranking much effort has been put forth in developing efficient probabilistic models for parsing strings (cara ballo and charniak, 1998; <papid> J98-2004 </papid>goldwater et al, 1998;blaheta and charniak, 1999; <papid> P99-1066 </papid>charniak, 2000; <papid> A00-2018 </papid>charniak, 2001); <papid> P01-1017 </papid>an obvious solution to parsing word lattices is to use nbest list reranking.</citsent>
<aftsection>
<nextsent>the nbestlist reranking procedure, depicted in figure 3, utilizes an external language model that selects set of strings from the word-lattice.
</nextsent>
<nextsent>these strings are analyzed by the parser which computes language model probability.
</nextsent>
<nextsent>this probability is combined 1to rescore word-lattice, each arch is assigned new score (probability) defined by new model (in combination with the acoustic model).
</nextsent>
<nextsent>w1, ..., wi, ..., wn1 ...
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4002">
<title id=" P04-1006.xml">attention shifting for parsing speech </title>
<section> parsing speech word-lattices.  </section>
<citcontext>
<prevsection>
<prevsent>pcfg parser ? ?
</prevsent>
<prevsent>lexicalized parser figure 4: coarse-to-fine lattice parsing.
</prevsent>
</prevsection>
<citsent citstr=" W97-0302 ">
in figure 4 we present the general overview of multi-stage parsing technique (goodman, 1997; <papid> W97-0302 </papid>charniak, 2000; <papid> A00-2018 </papid>charniak, 2001).<papid> P01-1017 </papid></citsent>
<aftsection>
<nextsent>this process 1.
</nextsent>
<nextsent>parse word-lattice with pcfg parser.
</nextsent>
<nextsent>2.
</nextsent>
<nextsent>over parse, generating additional candidates.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4024">
<title id=" P04-1006.xml">attention shifting for parsing speech </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the hub1 is collection of 213 word-lattices resulting from an acousticrecognizers analysis of speech utterances.
</prevsent>
<prevsent>professional readers reading wall street journal articles generated the utterances.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
the first stage parser is best-first pcfg parser trained on sections 2 through 22, and 24 of the pennwsj treebank (marcus et al, 1993).<papid> J93-2004 </papid></citsent>
<aftsection>
<nextsent>prior to training, the treebank is transformed into speech-liketext, removing punctuation and expanding numerals, etc.5 over parsing is performed using an edge pop6 multiplicative factor.
</nextsent>
<nextsent>the parser records the number of edge pops required to reach the first complete parse.
</nextsent>
<nextsent>the parser continues to parse until multiple of the number of edge pops required for the first parse are popped off the agenda.the second stage parser used is modified version of the charniak language modeling parser described in (charniak, 2001).<papid> P01-1017 </papid></nextsent>
<nextsent>we trained this parser 5brian roark of at&t; provided tool to perform the speech normalization.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4032">
<title id=" P04-1006.xml">attention shifting for parsing speech </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>attention shifting can be thought of as meta-process around the first stage of multi-stage word-lattice parser.
</prevsent>
<prevsent>we show that this technique reduces the amount of work exerted by the first stage pcfg parser while maintaining comparable language modeling perfor mance.attention shifting is simple technique that attempts to make word-lattice parsing more efficient.
</prevsent>
</prevsection>
<citsent citstr=" J98-4004 ">
as suggested by the results for the acoustic lattice experiments, this technique alone is not sufficient.solutions to improve these results include modifying the first-stage grammar by annotating the category labels with local syntactic features as suggested in (johnson, 1998) <papid> J98-4004 </papid>and (klein and manning,2003) <papid> P03-1054 </papid>as well as incorporating some level of lexical ization.</citsent>
<aftsection>
<nextsent>improving the quality of the parses selected by the first stage should reduce the need for generating such large number of candidates prior to pruning, improving efficiency as well as overall accuracy.
</nextsent>
<nextsent>we believe that attention shifting, or some variety of this technique, will be an integral part of efficient solutions for word-lattice parsing.
</nextsent>


</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4033">
<title id=" P04-1006.xml">attention shifting for parsing speech </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>attention shifting can be thought of as meta-process around the first stage of multi-stage word-lattice parser.
</prevsent>
<prevsent>we show that this technique reduces the amount of work exerted by the first stage pcfg parser while maintaining comparable language modeling perfor mance.attention shifting is simple technique that attempts to make word-lattice parsing more efficient.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
as suggested by the results for the acoustic lattice experiments, this technique alone is not sufficient.solutions to improve these results include modifying the first-stage grammar by annotating the category labels with local syntactic features as suggested in (johnson, 1998) <papid> J98-4004 </papid>and (klein and manning,2003) <papid> P03-1054 </papid>as well as incorporating some level of lexical ization.</citsent>
<aftsection>
<nextsent>improving the quality of the parses selected by the first stage should reduce the need for generating such large number of candidates prior to pruning, improving efficiency as well as overall accuracy.
</nextsent>
<nextsent>we believe that attention shifting, or some variety of this technique, will be an integral part of efficient solutions for word-lattice parsing.
</nextsent>


</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4034">
<title id=" P03-1001.xml">offline strategies for online question answering answering questions before they are asked </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>finally, we discuss the results of this evaluation and the implications and limitations of our strategy.
</prevsent>
<prevsent>3.1 2 3 3.2 related work great deal of work has examined the problem of extracting semantic relations from unstructured text.
</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
hearst (1992) <papid> C92-2082 </papid>examined extracting hyponym data by taking advantage of lexical patterns in text.</citsent>
<aftsection>
<nextsent>using patterns involving the phrase such as?, she reports finding only 46 relations in 20m of new york times text.
</nextsent>
<nextsent>berland and charniak (1999) <papid> P99-1008 </papid>extract part-of?</nextsent>
<nextsent>relations between lexical items in text, achieving only 55% accuracy with their method.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4035">
<title id=" P03-1001.xml">offline strategies for online question answering answering questions before they are asked </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>hearst (1992) <papid> C92-2082 </papid>examined extracting hyponym data by taking advantage of lexical patterns in text.</prevsent>
<prevsent>using patterns involving the phrase such as?, she reports finding only 46 relations in 20m of new york times text.</prevsent>
</prevsection>
<citsent citstr=" P99-1008 ">
berland and charniak (1999) <papid> P99-1008 </papid>extract part-of?</citsent>
<aftsection>
<nextsent>relations between lexical items in text, achieving only 55% accuracy with their method.
</nextsent>
<nextsent>finally, mann (2002) <papid> W02-1111 </papid>describes method for extracting instances from text that takes advantage of part of speech patterns involving proper nouns.</nextsent>
<nextsent>mann reports extracting 200,000 concept-instance pairs from 1gb of associated press text, only 60% of which were found to be legitimate descriptions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4036">
<title id=" P03-1001.xml">offline strategies for online question answering answering questions before they are asked </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>berland and charniak (1999) <papid> P99-1008 </papid>extract part-of?</prevsent>
<prevsent>relations between lexical items in text, achieving only 55% accuracy with their method.</prevsent>
</prevsection>
<citsent citstr=" W02-1111 ">
finally, mann (2002) <papid> W02-1111 </papid>describes method for extracting instances from text that takes advantage of part of speech patterns involving proper nouns.</citsent>
<aftsection>
<nextsent>mann reports extracting 200,000 concept-instance pairs from 1gb of associated press text, only 60% of which were found to be legitimate descriptions.
</nextsent>
<nextsent>these studies indicate two distinct problems associated with using patterns to extract semantic information from text.
</nextsent>
<nextsent>first, the patterns yield only small amount of the information that may be present in text (the recall problem).
</nextsent>
<nextsent>second, only small fraction of the information that the patterns yield is reliable (the precision problem).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4039">
<title id=" P03-1001.xml">offline strategies for online question answering answering questions before they are asked </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, we extend this work by directly addressing the two problems stated above.
</prevsent>
<prevsent>in order to address the recall problem, we extend the list of patterns used for extraction to take advantage of appositions.
</prevsent>
</prevsection>
<citsent citstr=" P01-1005 ">
further, following banko and brill (2001), <papid> P01-1005 </papid>we increase our yield by increasing the amount of data used by an order of magnitude over previously published work.</citsent>
<aftsection>
<nextsent>finally, in order to address the precision problem, we use machine learning techniques to filter the output of the part of speech patterns, thus purifying the extracted instances.
</nextsent>
<nextsent>data collection and preprocessing approximately 15gb of newspaper text was collected from: the trec 9 corpus (~3.5gb), the trec 2002 corpus (~3.5gb), yahoo!
</nextsent>
<nextsent>news (.5gb), the ap newswire (~2gb), the los angeles times (~.5gb), the new york times (~2gb), reuters (~.8gb), the wall street journal (~1.2gb), and various online news web sites (~.7gb).
</nextsent>
<nextsent>the text was cleaned of html (when necessary), word and sentence segmented, and part of speech tagged using brills tagger (brill, 1994).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4044">
<title id=" P03-1001.xml">offline strategies for online question answering answering questions before they are asked </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>if all pairs appear with equal frequency, selection is made at random.
</prevsent>
<prevsent>answers for both systems are then classified by hand into three categories based upon their director.?
</prevsent>
</prevsection>
<citsent citstr=" C02-1130 ">
see fleischman and hovy (2002) <papid> C02-1130 </papid>for techniques useful in disambiguating such instances.</citsent>
<aftsection>
<nextsent>4 integration of multiple answers is an open research question.
</nextsent>
<nextsent>and is not addressed in this work.
</nextsent>
<nextsent>information content.
</nextsent>
<nextsent>5 answers that unequivocally identify an instances celebrity (e.g., jennifer capriati is tennis star?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4045">
<title id=" P03-1001.xml">offline strategies for online question answering answering questions before they are asked </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we imagine huge data warehouses where each repository contains relations, such as birthplace-of, location-of, creator-of, etc. these repositories would be automatically filled by system that continuously watches various online news sources, scouring them for useful information.
</prevsent>
<prevsent>such system would have large library of extraction patterns for many different types of relations.
</prevsent>
</prevsection>
<citsent citstr=" P02-1006 ">
these patterns could be manually generated, such as the ones described here, or learned from text, as described in ravichandran and hovy (2002).<papid> P02-1006 </papid></citsent>
<aftsection>
<nextsent>each pattern would have machine-learned filter in order to insure high precision output relations.
</nextsent>
<nextsent>these relations would then be stored in repositories that could be quickly and easily searched to answer user queries.
</nextsent>
<nextsent>7 in this way, we envision system similar to (lin et al, 2002).
</nextsent>
<nextsent>however, instead of relying on costly structured databases and painstakingly generated wrappers, repositories are automatically filled with information from many different patterns.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4046">
<title id=" P03-1063.xml">text chunking by combining handcrafted rules and memory based learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>thus, the proposed method is primarily based on the rules, and then the residual errors are corrected by adopting memory-based machine learning method.
</prevsent>
<prevsent>since the memory-based learning is an efficient method to handle exceptions in natural language processing, it is good at checking whether the estimates are exceptional cases of the rules and revising them.an evaluation of the method yields the improvement in f-score over the rules or various machine learning methods alone.
</prevsent>
</prevsection>
<citsent citstr=" W95-0107 ">
text chunking has been one of the most interesting problems in natural language learning community since the first work of (ramshaw and marcus, 1995) <papid> W95-0107 </papid>using machine learning method.</citsent>
<aftsection>
<nextsent>the main purpose of the machine learning methods applied tothis task is to capture the hypothesis that best determine the chunk type of word, and such methods have shown relatively high performance in english (kudo and matsumoto, 2000; <papid> W00-0730 </papid>zhang et. al, 2001).<papid> P01-1069 </papid></nextsent>
<nextsent>in order to do it, various kinds of information, suchas lexical information, part-of-speech and grammatical relation, of the neighboring words is used.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4047">
<title id=" P03-1063.xml">text chunking by combining handcrafted rules and memory based learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>since the memory-based learning is an efficient method to handle exceptions in natural language processing, it is good at checking whether the estimates are exceptional cases of the rules and revising them.an evaluation of the method yields the improvement in f-score over the rules or various machine learning methods alone.
</prevsent>
<prevsent>text chunking has been one of the most interesting problems in natural language learning community since the first work of (ramshaw and marcus, 1995) <papid> W95-0107 </papid>using machine learning method.</prevsent>
</prevsection>
<citsent citstr=" W00-0730 ">
the main purpose of the machine learning methods applied tothis task is to capture the hypothesis that best determine the chunk type of word, and such methods have shown relatively high performance in english (kudo and matsumoto, 2000; <papid> W00-0730 </papid>zhang et. al, 2001).<papid> P01-1069 </papid></citsent>
<aftsection>
<nextsent>in order to do it, various kinds of information, suchas lexical information, part-of-speech and grammatical relation, of the neighboring words is used.
</nextsent>
<nextsent>since the position of word plays an important role as asyntactic constraint in english, the methods are successful even with local information.
</nextsent>
<nextsent>however, these methods are not appropriate for chunking korean and japanese, because such languages have characteristic of partially free wordorder.
</nextsent>
<nextsent>that is, there is very weak positional constraint in these languages.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4048">
<title id=" P03-1063.xml">text chunking by combining handcrafted rules and memory based learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>since the memory-based learning is an efficient method to handle exceptions in natural language processing, it is good at checking whether the estimates are exceptional cases of the rules and revising them.an evaluation of the method yields the improvement in f-score over the rules or various machine learning methods alone.
</prevsent>
<prevsent>text chunking has been one of the most interesting problems in natural language learning community since the first work of (ramshaw and marcus, 1995) <papid> W95-0107 </papid>using machine learning method.</prevsent>
</prevsection>
<citsent citstr=" P01-1069 ">
the main purpose of the machine learning methods applied tothis task is to capture the hypothesis that best determine the chunk type of word, and such methods have shown relatively high performance in english (kudo and matsumoto, 2000; <papid> W00-0730 </papid>zhang et. al, 2001).<papid> P01-1069 </papid></citsent>
<aftsection>
<nextsent>in order to do it, various kinds of information, suchas lexical information, part-of-speech and grammatical relation, of the neighboring words is used.
</nextsent>
<nextsent>since the position of word plays an important role as asyntactic constraint in english, the methods are successful even with local information.
</nextsent>
<nextsent>however, these methods are not appropriate for chunking korean and japanese, because such languages have characteristic of partially free wordorder.
</nextsent>
<nextsent>that is, there is very weak positional constraint in these languages.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4057">
<title id=" P03-1062.xml">learning to predict pitch accents and prosodic boundaries in dutch </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>predicting prosody is known tobe hard problem that is thought to require information on syntactic boundaries, syntactic and semantic relations between constituents, discourse-levelknowledge, and phonological well-formedness constraints (hirschberg, 1993).
</prevsent>
<prevsent>however, producing allthis information ? using full parsing, including establishing semanto-syntactic relations, and full discourse analysis ? is currently infeasible for real time system.
</prevsent>
</prevsection>
<citsent citstr=" W99-0619 ">
resolving this dilemma has been the topic of several studies in pitch accent placement(hirschberg, 1993; black, 1995; pan and mckeown, 1999; <papid> W99-0619 </papid>pan and hirschberg, 2000; <papid> P00-1030 </papid>marsi et al, 2002) and in prosodic boundary placement (wang and hirschberg, 1997; taylor and black, 1998).</citsent>
<aftsection>
<nextsent>the commonly adopted solution is to use shallow information sources that approximate full syntactic, semantic and discourse information, such as the words of the text themselves, their part-of-speech tags, or their information content (in general, or in the textat hand), since words with high (semantic) information content or load tend to receive pitch accents (ladd, 1996).
</nextsent>
<nextsent>within this research paradigm, we investigate pitch accent and prosodic boundary placement for dutch, using an annotated corpus of newspaper text,and machine learning algorithms to produce classifiers for both tasks.
</nextsent>
<nextsent>we address two questions that have been left open thus far in previous work: 1.
</nextsent>
<nextsent>is there an advantage in inducing decision trees.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4058">
<title id=" P03-1062.xml">learning to predict pitch accents and prosodic boundaries in dutch </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>predicting prosody is known tobe hard problem that is thought to require information on syntactic boundaries, syntactic and semantic relations between constituents, discourse-levelknowledge, and phonological well-formedness constraints (hirschberg, 1993).
</prevsent>
<prevsent>however, producing allthis information ? using full parsing, including establishing semanto-syntactic relations, and full discourse analysis ? is currently infeasible for real time system.
</prevsent>
</prevsection>
<citsent citstr=" P00-1030 ">
resolving this dilemma has been the topic of several studies in pitch accent placement(hirschberg, 1993; black, 1995; pan and mckeown, 1999; <papid> W99-0619 </papid>pan and hirschberg, 2000; <papid> P00-1030 </papid>marsi et al, 2002) and in prosodic boundary placement (wang and hirschberg, 1997; taylor and black, 1998).</citsent>
<aftsection>
<nextsent>the commonly adopted solution is to use shallow information sources that approximate full syntactic, semantic and discourse information, such as the words of the text themselves, their part-of-speech tags, or their information content (in general, or in the textat hand), since words with high (semantic) information content or load tend to receive pitch accents (ladd, 1996).
</nextsent>
<nextsent>within this research paradigm, we investigate pitch accent and prosodic boundary placement for dutch, using an annotated corpus of newspaper text,and machine learning algorithms to produce classifiers for both tasks.
</nextsent>
<nextsent>we address two questions that have been left open thus far in previous work: 1.
</nextsent>
<nextsent>is there an advantage in inducing decision trees.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4059">
<title id=" P03-1062.xml">learning to predict pitch accents and prosodic boundaries in dutch </title>
<section> task definition, data, and machine.  </section>
<citcontext>
<prevsection>
<prevsent>word forms (wrd) ? the word form tokens form the central unit to which other features are added.
</prevsent>
<prevsent>pre- and post-punctuation ? all punctuation marks in the data are transferred to two separate features: pre-punctuation feature (prep) for punctuation marks such as quotation marks appearing before the token, and post-punctuation feature (postp) for punctuation marks such as periods, commas, and question marks following the token.
</prevsent>
</prevsection>
<citsent citstr=" W96-0102 ">
part-of-speech (pos) tagging ? we used mbt version 1.0 (daelemans et al, 1996) <papid> W96-0102 </papid>to develop memory-based pos tagger trained on the eindhoven corpus of written dutch, which does not overlap with our base data.</citsent>
<aftsection>
<nextsent>we split up the full pos tags into two features, the first (posc) containing the mainpos category, the second (posf) the pos subfea tures.diacritical accent ? some tokens bear an ortho graphical dia critical accent put there by the author to particularly emphasize the token in question.
</nextsent>
<nextsent>these accents were stripped off the accented letter, and transferred to binary feature (dia).np and vp chunking (npc &amp; vpc) ? an approximation of the syntactic structure is provided by simple noun phrase and verb phrase chunk ers, which take word and pos information as input and are based on small number of manually written regular expressions.
</nextsent>
<nextsent>phrase boundaries are encoded per word using three tags: b? for chunk-initial words,i? for chunk-internal words, and o? for words out side chunks.
</nextsent>
<nextsent>the nps are identified according to thebase principle of one semantic head per chunk (non recursive, base nps).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4061">
<title id=" P03-1047.xml">bridging the gap between under specification formalisms minimal recur sion semantics as dominance constraints </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>minimal recur sion semantics (mrs) is the standard formalism used in large-scale hpsg grammars to model underspecified semantics.
</prevsent>
<prevsent>we present the first provablyefficient algorithm to enumerate the readings of mrs structures, by translating them into normal dominance constraints.
</prevsent>
</prevsection>
<citsent citstr=" P92-1005 ">
in the past few years there has been considerable activity in the development of formalisms for underspecified semantics (alshawi and crouch, 1992; <papid> P92-1005 </papid>reyle, 1993; bos, 1996; copestake et al, 1999; egget al, 2001).</citsent>
<aftsection>
<nextsent>the common idea is to delay the enumeration of all readings for as long as possible.
</nextsent>
<nextsent>instead, they work with compact underspecified representation; readings are enumerated from this representation by need.minimal recur sion semantics (mrs) (copestake et al, 1999) is the standard formalism for semantic under specification used in large-scale hpsg grammars (pollard and sag, 1994; copestake and flickinger, ).
</nextsent>
<nextsent>despite this clear relevance, the most obvious questions about mrs are still open: 1.
</nextsent>
<nextsent>is it possible to enumerate the readings of.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4062">
<title id=" P03-1047.xml">bridging the gap between under specification formalisms minimal recur sion semantics as dominance constraints </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we distinguish the sublanguages of mrs nets and normal dominance nets, and show that they can be intertranslated.
</prevsent>
<prevsent>this translation answers the first question: existing constraint solvers for normal dominance constraints can be used to enumerate the readings of mrs nets in low polynomial time.the translation also answers the second question restricted to pure scope underspecification.
</prevsent>
</prevsection>
<citsent citstr=" E03-1024 ">
it shows the equivalence of large fragment of mrss and corresponding fragment of normal dominance constraints, which in turn is equivalent to large fragment of hole semantics (bos, 1996) as proven in (koller et al, 2003).<papid> E03-1024 </papid></citsent>
<aftsection>
<nextsent>additional underspecified treatments of ellipsis or reinterpretation, however, are available for extensions of dominance constraint only (clls, the constraint language for lambda structures (egg et al, 2001)).our results are subject to new proof technique which reduces reasoning about mrs structures to reasoning about weakly normal dominance constraints (bodirsky et al, 2003).
</nextsent>
<nextsent>the previous proof techniques for normal dominance constraints (koller et al, 2003) <papid> E03-1024 </papid>do not apply.</nextsent>
<nextsent>we define simplified version of minimal recur sion semantics and discuss differences to the original definitions presented in (copestake et al, 1999).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4064">
<title id=" P03-1047.xml">bridging the gap between under specification formalisms minimal recur sion semantics as dominance constraints </title>
<section> function symbols..  </section>
<citcontext>
<prevsection>
<prevsent>implies ? h?, but not the other way round.
</prevsent>
<prevsent>we believe that the additional strength of qeq-constraints is not needed in practice for modeling scope.
</prevsent>
</prevsection>
<citsent citstr=" P01-1019 ">
recent work in semantic construction for hpsg (copestake etal., 2001) <papid> P01-1019 </papid>supports our conjecture: the examples discussed there are compatible with our simplification.</citsent>
<aftsection>
<nextsent>third, we depart in some minor details: we use sets instead of multi-sets and omit top-handles which are useful only during semantics construction.
</nextsent>
<nextsent>3 dominance constraints.
</nextsent>
<nextsent>dominance constraints are general framework for describing trees, and thus syntax trees of logical formulas.
</nextsent>
<nextsent>dominance constraints are the core language underlying clls (egg et al, 2001) which adds parallelism and binding constraints.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4066">
<title id=" P03-1035.xml">improved source channel models for chinese word segmentation </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>for instance, one would identify string as unit, but not identify whether it is person name.
</prevsent>
<prevsent>this is not always sufficient.
</prevsent>
</prevsection>
<citsent citstr=" J00-3004 ">
second, the probabilistic models used in these methods (e.g. teahan et al, 2000) <papid> J00-3004 </papid>are trained on segmented corpus which is not always available.</citsent>
<aftsection>
<nextsent>third, the identified unknown words are likely to be linguistically implausible (e.g. dai et al, 1999), and additional manual checking is needed for some subsequent tasks such as parsing.
</nextsent>
<nextsent>we believe that the identification of unknown words should not be defined as separate problem from word segmentation.
</nextsent>
<nextsent>these two problems are better solved simultaneously in unified approach.
</nextsent>
<nextsent>one example of such approaches is sproat et al (1996), <papid> J96-3004 </papid>which is based on weighted finite-state transducers (fsts).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4067">
<title id=" P03-1035.xml">improved source channel models for chinese word segmentation </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>we believe that the identification of unknown words should not be defined as separate problem from word segmentation.
</prevsent>
<prevsent>these two problems are better solved simultaneously in unified approach.
</prevsent>
</prevsection>
<citsent citstr=" J96-3004 ">
one example of such approaches is sproat et al (1996), <papid> J96-3004 </papid>which is based on weighted finite-state transducers (fsts).</citsent>
<aftsection>
<nextsent>our approach is motivated by the same inspiration, but is based on different mechanism: the improved source-channel models.
</nextsent>
<nextsent>as we shall see, these models provide more flexible framework to incorporate various kinds of lexical and statistical information.
</nextsent>
<nextsent>some types of unknown words that are not discussed in sproats system are dealt with in our system.
</nextsent>
<nextsent>there is no standard definition of chinese words ? linguists may define words from many aspects (e.g. packard, 2000), but none of these definitions will completely line up with any other.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4069">
<title id=" P03-1035.xml">improved source channel models for chinese word segmentation </title>
<section> class model probabilities.  </section>
<citcontext>
<prevsection>
<prevsent>p(?
</prevsent>
<prevsent>p(?
</prevsent>
</prevsection>
<citsent citstr=" C02-1012 ">
4 the detailed description of these models are in sun et al (2002), <papid> C02-1012 </papid>which also describes the use of cache model and the way the abbreviations of ln and on are handled.</citsent>
<aftsection>
<nextsent>5 for better understanding, the constraint is simplified version of that used in our system.
</nextsent>
<nextsent>p( /ln |?), where  ln  and  /ln  are symbols denoting the beginning and the end of ln, respectively.
</nextsent>
<nextsent>5.2.3 organization names ons are more difficult to identify than pns and lns because ons are usually nested named entities.
</nextsent>
<nextsent>consider an on ????????
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4071">
<title id=" N12-2011.xml">a weighting scheme for open information extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>many challenges existin developing an open ie solution, such as recognizing and disambiguating entities in multi-document setting, and identifying all so-called relational terms 1this thesis proposal has been accepted for publication in (merhav et al, 2012).in the sentences connecting pairs of entities.
</prevsent>
<prevsent>relational terms are words (usually one or two) that describe relation between entities (for instance, terms like running mate?, opponent?, governor of?
</prevsent>
</prevsection>
<citsent citstr=" P04-1053 ">
are relational terms).one approach for open ie is based on clustering of entity pairs to produce relations, as introduced by hasegawa et al (hasegawa et al, 2004).<papid> P04-1053 </papid></citsent>
<aftsection>
<nextsent>their and follow-up works (e.g., (mesquita et al, 2010)) extract terms in small window between two named entities to build the context vector of each entity pair, and then apply clustering algorithm to cluster together entity pairs that share the same relation (e.g., googleyoutube and google motorola mobility in cluster about the acquired?
</nextsent>
<nextsent>relation).
</nextsent>
<nextsent>contexts of entity pairs are represented using the vector space model.
</nextsent>
<nextsent>the state-of the-art in clustering-based open ie assigns weights to the terms according to the standard tf idf scheme.motivation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4072">
<title id=" N12-2011.xml">a weighting scheme for open information extraction </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>selectional preferences are semantic constraints on arguments (e.g. verb like eat?
</prevsent>
<prevsent>prefers as object edible things).
</prevsent>
</prevsection>
<citsent citstr=" P07-1073 ">
different approaches for open ie have been proposed in the literature, such as bootstrapping (e.g., (zhu et al, 2009) (bunescu and mooney, 2007)), <papid> P07-1073 </papid>self or distant supervision (e.g., (banko et al, 2007) (mintz et al, 2009)) <papid> P09-1113 </papid>and rule based (e.g., (fader et al, 2011)).<papid> D11-1142 </papid></citsent>
<aftsection>
<nextsent>in this work we focus on unsupervised approaches.
</nextsent>
<nextsent>fully unsupervised open ie systems are mainly based on clustering of entity pair contexts to produce clusters of entity pairs that share the same relations, as introduced by hasegawa et al (hasegawa et al, 2004) <papid> P04-1053 </papid>this is the system we use in this workas our baseline).</nextsent>
<nextsent>hasegawa et al used word unigrams weighted by tf idf to build the context vectors and applied hierarchical agglomerative clustering (hac) with complete linkage deployed on 1995 new york times corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4073">
<title id=" N12-2011.xml">a weighting scheme for open information extraction </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>selectional preferences are semantic constraints on arguments (e.g. verb like eat?
</prevsent>
<prevsent>prefers as object edible things).
</prevsent>
</prevsection>
<citsent citstr=" P09-1113 ">
different approaches for open ie have been proposed in the literature, such as bootstrapping (e.g., (zhu et al, 2009) (bunescu and mooney, 2007)), <papid> P07-1073 </papid>self or distant supervision (e.g., (banko et al, 2007) (mintz et al, 2009)) <papid> P09-1113 </papid>and rule based (e.g., (fader et al, 2011)).<papid> D11-1142 </papid></citsent>
<aftsection>
<nextsent>in this work we focus on unsupervised approaches.
</nextsent>
<nextsent>fully unsupervised open ie systems are mainly based on clustering of entity pair contexts to produce clusters of entity pairs that share the same relations, as introduced by hasegawa et al (hasegawa et al, 2004) <papid> P04-1053 </papid>this is the system we use in this workas our baseline).</nextsent>
<nextsent>hasegawa et al used word unigrams weighted by tf idf to build the context vectors and applied hierarchical agglomerative clustering (hac) with complete linkage deployed on 1995 new york times corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4074">
<title id=" N12-2011.xml">a weighting scheme for open information extraction </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>selectional preferences are semantic constraints on arguments (e.g. verb like eat?
</prevsent>
<prevsent>prefers as object edible things).
</prevsent>
</prevsection>
<citsent citstr=" D11-1142 ">
different approaches for open ie have been proposed in the literature, such as bootstrapping (e.g., (zhu et al, 2009) (bunescu and mooney, 2007)), <papid> P07-1073 </papid>self or distant supervision (e.g., (banko et al, 2007) (mintz et al, 2009)) <papid> P09-1113 </papid>and rule based (e.g., (fader et al, 2011)).<papid> D11-1142 </papid></citsent>
<aftsection>
<nextsent>in this work we focus on unsupervised approaches.
</nextsent>
<nextsent>fully unsupervised open ie systems are mainly based on clustering of entity pair contexts to produce clusters of entity pairs that share the same relations, as introduced by hasegawa et al (hasegawa et al, 2004) <papid> P04-1053 </papid>this is the system we use in this workas our baseline).</nextsent>
<nextsent>hasegawa et al used word unigrams weighted by tf idf to build the context vectors and applied hierarchical agglomerative clustering (hac) with complete linkage deployed on 1995 new york times corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4078">
<title id=" N12-2011.xml">a weighting scheme for open information extraction </title>
<section> data and evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>the idea of domain frequency was first proposed for predicting entities which are erroneously typed byner systems (merhav et al, 2010).
</prevsent>
<prevsent>this work was implemented on top of the sonex system (mesquita et al, 2010), deployed on the icwsm 2009 spinn3r corpus (burton et al, 2009), focusing on posts in english (25 million out of 44 million in total), collected between august 1st, 2008and october 1st, 2008.
</prevsent>
</prevsection>
<citsent citstr=" W09-1119 ">
the system uses the illinois entity tagger (ratinov and roth, 2009) <papid> W09-1119 </papid>and orthomatcher from the gate framework2 for within a-document co-reference resolution.evaluating open ie systems is difficult problem.</citsent>
<aftsection>
<nextsent>mesquita et al evaluated sonex by automatically matching sample of the entity pairs their system identified from the spinn3r corpus against publicly available curated database3.
</nextsent>
<nextsent>their approach generated two datasets: inter and 10perc.
</nextsent>
<nextsent>inter contains the intersection pairs only (i.e., intersection pairs are those from spinn3r and free base that match both entity names and types ex actly), while 10perc contains 10% of the total pairs sonex identified, including the intersection pairs.we extended these two datasets by adding more entity pairs and relations.
</nextsent>
<nextsent>we call the resulting datasets inter (395 entity pairs and 20 different relations) and noisy (contains inter plus approximately 30,000 entity pairs as compared to the 13,000 pairs in 10perc ).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4083">
<title id=" P03-1002.xml">using predicate argument structures for information extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>such patterns are either handcrafted or acquired automatically.
</prevsent>
<prevsent>a rich literature covers methods of automatically acquiring ie patterns.
</prevsent>
</prevsection>
<citsent citstr=" C00-2136 ">
some of the most recent methods were reported in (riloff, 1996; yangarber et al, 2000).<papid> C00-2136 </papid>to process texts efficiently and fast, domain patterns are ideally implemented as finite state automata (fsas), methodology pioneered in the fastus ie system (hobbs et al, 1997).</citsent>
<aftsection>
<nextsent>although this paradigm is simple and elegant, it has the disadvantage that it is not easily portable from one do main of interest to the next.
</nextsent>
<nextsent>in contrast, new, truly domain-independent ie paradigm may be designed if we know (a) predicates relevant to domain; and (b) which of their arguments fill templette slots.
</nextsent>
<nextsent>central to this new way of extracting information from texts are systems that label predicate-argument structures on the output of full parsers.
</nextsent>
<nextsent>one such augmented parser, trained on data available from the propbank project has been recently presented in (gildea and palmer, 2002).<papid> P02-1031 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4084">
<title id=" P03-1002.xml">using predicate argument structures for information extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in contrast, new, truly domain-independent ie paradigm may be designed if we know (a) predicates relevant to domain; and (b) which of their arguments fill templette slots.
</prevsent>
<prevsent>central to this new way of extracting information from texts are systems that label predicate-argument structures on the output of full parsers.
</prevsent>
</prevsection>
<citsent citstr=" P02-1031 ">
one such augmented parser, trained on data available from the propbank project has been recently presented in (gildea and palmer, 2002).<papid> P02-1031 </papid></citsent>
<aftsection>
<nextsent>in this paper we describe domain-independent ie paradigm that is based on predicate-argument structures identified automatically by two different meth ods: (1) the statistical method reported in (gildea and palmer, 2002); <papid> P02-1031 </papid>and (2) new method basedon inductive learning which obtains 17% higher score over the first method when tested on the samedata.</nextsent>
<nextsent>the accuracy enhancement of predicate argument recognition determines up to 14% better ie re sults.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4096">
<title id=" P03-1002.xml">using predicate argument structures for information extraction </title>
<section> learning to recognize.  </section>
<citcontext>
<prevsection>
<prevsent>additionally, the argument may include functional tags from treebank, e.g. argm-dir indicates directional, argm-loc indicates locative, and argm-tmp stands for temporal.
</prevsent>
<prevsent>2.2 the model.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
in previous work using the propbank corpus,(gildea and palmer, 2002) <papid> P02-1031 </papid>proposed model predicting argument roles using the same statistical method as the one employed by (gildea and jurafsky, 2002) <papid> J02-3001 </papid>for predicting semantic roles based on the framenet corpus (baker et al, 1998).<papid> P98-1013 </papid></citsent>
<aftsection>
<nextsent>this statistical technique of labeling predicate argument operates on the output of the probabilistic parser reported in (collins, 1997).<papid> P97-1003 </papid></nextsent>
<nextsent>it consists of two tasks: (1) identifying the parse tree constituents corresponding to arguments of each predicate encoded in propbank; and (2) recognizing the role corresponding to each argument.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4097">
<title id=" P03-1002.xml">using predicate argument structures for information extraction </title>
<section> learning to recognize.  </section>
<citcontext>
<prevsection>
<prevsent>additionally, the argument may include functional tags from treebank, e.g. argm-dir indicates directional, argm-loc indicates locative, and argm-tmp stands for temporal.
</prevsent>
<prevsent>2.2 the model.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
in previous work using the propbank corpus,(gildea and palmer, 2002) <papid> P02-1031 </papid>proposed model predicting argument roles using the same statistical method as the one employed by (gildea and jurafsky, 2002) <papid> J02-3001 </papid>for predicting semantic roles based on the framenet corpus (baker et al, 1998).<papid> P98-1013 </papid></citsent>
<aftsection>
<nextsent>this statistical technique of labeling predicate argument operates on the output of the probabilistic parser reported in (collins, 1997).<papid> P97-1003 </papid></nextsent>
<nextsent>it consists of two tasks: (1) identifying the parse tree constituents corresponding to arguments of each predicate encoded in propbank; and (2) recognizing the role corresponding to each argument.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4098">
<title id=" P03-1002.xml">using predicate argument structures for information extraction </title>
<section> learning to recognize.  </section>
<citcontext>
<prevsection>
<prevsent>2.2 the model.
</prevsent>
<prevsent>in previous work using the propbank corpus,(gildea and palmer, 2002) <papid> P02-1031 </papid>proposed model predicting argument roles using the same statistical method as the one employed by (gildea and jurafsky, 2002) <papid> J02-3001 </papid>for predicting semantic roles based on the framenet corpus (baker et al, 1998).<papid> P98-1013 </papid></prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
this statistical technique of labeling predicate argument operates on the output of the probabilistic parser reported in (collins, 1997).<papid> P97-1003 </papid></citsent>
<aftsection>
<nextsent>it consists of two tasks: (1) identifying the parse tree constituents corresponding to arguments of each predicate encoded in propbank; and (2) recognizing the role corresponding to each argument.
</nextsent>
<nextsent>each task can be cast separate classifier.
</nextsent>
<nextsent>for example, the result of the first classifier on the sentence illustrated in figure 2 is the identification of the two nps as arguments.
</nextsent>
<nextsent>the second classifier assigns the specific roles arg1 and arg0 given the predicate assailed?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4121">
<title id=" P03-1002.xml">using predicate argument structures for information extraction </title>
<section> the ie paradigm.  </section>
<citcontext>
<prevsection>
<prevsent>figure 7(a) illustrates an ie architecture that employs predicate argument structures.
</prevsent>
<prevsent>documents are processed in parallel to: (1) parse them syntactically,and (2) recognize the nes.
</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
the full parser first performs part-of-speech (pos) tagging using transformation based learning (tbl) (brill, 1995).<papid> J95-4004 </papid></citsent>
<aftsection>
<nextsent>then non-recursive, or basic, noun phrases (npb) are identified using the tbl method reported in (ngai and florian, 2001).<papid> N01-1006 </papid></nextsent>
<nextsent>at last, the dependency parser presented in (collins, 1997) <papid> P97-1003 </papid>is used to generate thefull parse.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4122">
<title id=" P03-1002.xml">using predicate argument structures for information extraction </title>
<section> the ie paradigm.  </section>
<citcontext>
<prevsection>
<prevsent>documents are processed in parallel to: (1) parse them syntactically,and (2) recognize the nes.
</prevsent>
<prevsent>the full parser first performs part-of-speech (pos) tagging using transformation based learning (tbl) (brill, 1995).<papid> J95-4004 </papid></prevsent>
</prevsection>
<citsent citstr=" N01-1006 ">
then non-recursive, or basic, noun phrases (npb) are identified using the tbl method reported in (ngai and florian, 2001).<papid> N01-1006 </papid></citsent>
<aftsection>
<nextsent>at last, the dependency parser presented in (collins, 1997) <papid> P97-1003 </papid>is used to generate thefull parse.</nextsent>
<nextsent>this approach allows us to parse the sentences with less than 40 words from treebank section 23 with an f-measure slightly over 85% at an average of 0.12 seconds/sentence on 2ghz pentium iv computer.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4129">
<title id=" P01-1032.xml">mapping lexical entries in a verbs database to wordnet senses </title>
<section> lexical resources.  </section>
<citcontext>
<prevsection>
<prevsent>there sulting 491 classes (e.g., roll verbs, group i?, which includes drift, drop, glide, roll, swing) are referred to here as levin+ classes.
</prevsent>
<prevsent>as verbs may be assigned to multiple levin+ classes, the actual number of entries in the database is larger, 9611.
</prevsent>
</prevsection>
<citsent citstr=" P97-1020 ">
following the model of (dorr and olsen, 1997), <papid> P97-1020 </papid>each levin+ class is associated with thematic grid (henceforth abbreviated  -grid), which summarizes verbs syntactic behavior by specifying its predicate argument structure.</citsent>
<aftsection>
<nextsent>for example, the levin+ class roll verbs, group i?
</nextsent>
<nextsent>is associated with the  -grid [th goal], in which theme and goal are used (e.g., the ball dropped to the ground).1 each  -grid specification corresponds to grid class.
</nextsent>
<nextsent>there are 48 grid classes, with one-to-many relationship between grid and levin+ classes.
</nextsent>
<nextsent>wordnet, the lexical resource to which we are mapping entries from the lexical database, groups synonymous word senses into synsets?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4130">
<title id=" P01-1032.xml">mapping lexical entries in a verbs database to wordnet senses </title>
<section> lexical resources.  </section>
<citcontext>
<prevsection>
<prevsent>using information content to quantify the value?
</prevsent>
<prevsent>of node in the wordnet hierarchy hasalso been used for measuring semantic similarity in taxonomy (resnik, 1999b).
</prevsent>
</prevsection>
<citsent citstr=" P00-1059 ">
more recently, context-based models of disambiguation have been shown to represent significant improvements over the baseline (bangalore and ram bow, 2000), (<papid> P00-1059 </papid>ratnaparkhi, 2000).<papid> A00-2026 </papid></citsent>
<aftsection>
<nextsent>levin+ grid/example wn sense spanish verb(s) 9.4 directional put [ag th mod-loc src goal] dropped the stone 1.
</nextsent>
<nextsent>move, displace 2.
</nextsent>
<nextsent>descend, fall, go down 8.
</nextsent>
<nextsent>drop set down, put down 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4131">
<title id=" P01-1032.xml">mapping lexical entries in a verbs database to wordnet senses </title>
<section> lexical resources.  </section>
<citcontext>
<prevsection>
<prevsent>using information content to quantify the value?
</prevsent>
<prevsent>of node in the wordnet hierarchy hasalso been used for measuring semantic similarity in taxonomy (resnik, 1999b).
</prevsent>
</prevsection>
<citsent citstr=" A00-2026 ">
more recently, context-based models of disambiguation have been shown to represent significant improvements over the baseline (bangalore and ram bow, 2000), (<papid> P00-1059 </papid>ratnaparkhi, 2000).<papid> A00-2026 </papid></citsent>
<aftsection>
<nextsent>levin+ grid/example wn sense spanish verb(s) 9.4 directional put [ag th mod-loc src goal] dropped the stone 1.
</nextsent>
<nextsent>move, displace 2.
</nextsent>
<nextsent>descend, fall, go down 8.
</nextsent>
<nextsent>drop set down, put down 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4132">
<title id=" P01-1032.xml">mapping lexical entries in a verbs database to wordnet senses </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>on the one hand, even the higher ofthe kappa coefficients mentioned above is significantly lower than the standard suggested for good reliability ( |~}???
</prevsent>
<prevsent>) or even the level where tentative conclusions may be drawn ( h| ? ??
</prevsent>
</prevsection>
<citsent citstr=" J96-2004 ">
) (carletta, 1996), (<papid> J96-2004 </papid>krippendorff, 1980).</citsent>
<aftsection>
<nextsent>on the other hand, if the automatic assignments agree with human coding at levels comparable to the degree of agreement among humans, it may be used to identify current assignments that need review6the kappa statistic measures the degree to which pairwise agreement of coders on classification task surpasses what would be expected by chance; the standard definition of this coefficient is: ?????qv!q?!cc3c!q?!c? , where qv???
</nextsent>
<nextsent>is the actual percentage of agreement and q??!?
</nextsent>
<nextsent>is the expected percentage of agreement, averaged over all pairs of assignments.
</nextsent>
<nextsent>several adjustments in the computation of the kappa coefficient were made necessary by the possible assignment of multiple senses for each verb in levin+ class, since without prior knowledge of how many senses are to be assigned, there is no basis on which to compute q??!?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4133">
<title id=" P03-2033.xml">a debug tool for practical grammar development </title>
<section> what is the ideal grammar debugging?.  </section>
<citcontext>
<prevsection>
<prevsent>first, it reduces human workload to improve the general-purpose grammar through using language intuition encoded in syntactically tagged corpora in xml format.
</prevsent>
<prevsent>second, it records data of grammar defects to allow developers to have whole picture of parsing errors found in the target corpora to save debugging time and effort by prioritizing them.
</prevsent>
</prevsection>
<citsent citstr=" A92-1030 ">
there are already other grammar developing tools, such as grammar writer of xtag (paroubek et al, 1992), <papid> A92-1030 </papid>alep (schmidt et al, 1996), <papid> C96-1049 </papid>con troll (gotzand meurers, 1997), <papid> W97-1506 </papid>tool by nara institute of science and technology (miyata et al, 1999), and [incr tsdb()] (oepen et al, 2002).<papid> W02-1508 </papid></citsent>
<aftsection>
<nextsent>but these tools have following problems; they largely depend on human debuggers?
</nextsent>
<nextsent>language intuition, they do not help users to handle large amount of parsing results effectively, and they let human debug gers correct the bugs one after another manually and locally.
</nextsent>
<nextsent>to cope with these shortcomings, willex proposes an alternative method for more efficient debugging process.the workflow of the conventional grammar developing tools and willex are different in the followingways.
</nextsent>
<nextsent>with the conventional tools, human debug gers must check each sentence to find out grammar defects and modify them one by one.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4134">
<title id=" P03-2033.xml">a debug tool for practical grammar development </title>
<section> what is the ideal grammar debugging?.  </section>
<citcontext>
<prevsection>
<prevsent>first, it reduces human workload to improve the general-purpose grammar through using language intuition encoded in syntactically tagged corpora in xml format.
</prevsent>
<prevsent>second, it records data of grammar defects to allow developers to have whole picture of parsing errors found in the target corpora to save debugging time and effort by prioritizing them.
</prevsent>
</prevsection>
<citsent citstr=" C96-1049 ">
there are already other grammar developing tools, such as grammar writer of xtag (paroubek et al, 1992), <papid> A92-1030 </papid>alep (schmidt et al, 1996), <papid> C96-1049 </papid>con troll (gotzand meurers, 1997), <papid> W97-1506 </papid>tool by nara institute of science and technology (miyata et al, 1999), and [incr tsdb()] (oepen et al, 2002).<papid> W02-1508 </papid></citsent>
<aftsection>
<nextsent>but these tools have following problems; they largely depend on human debuggers?
</nextsent>
<nextsent>language intuition, they do not help users to handle large amount of parsing results effectively, and they let human debug gers correct the bugs one after another manually and locally.
</nextsent>
<nextsent>to cope with these shortcomings, willex proposes an alternative method for more efficient debugging process.the workflow of the conventional grammar developing tools and willex are different in the followingways.
</nextsent>
<nextsent>with the conventional tools, human debug gers must check each sentence to find out grammar defects and modify them one by one.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4135">
<title id=" P03-2033.xml">a debug tool for practical grammar development </title>
<section> what is the ideal grammar debugging?.  </section>
<citcontext>
<prevsection>
<prevsent>first, it reduces human workload to improve the general-purpose grammar through using language intuition encoded in syntactically tagged corpora in xml format.
</prevsent>
<prevsent>second, it records data of grammar defects to allow developers to have whole picture of parsing errors found in the target corpora to save debugging time and effort by prioritizing them.
</prevsent>
</prevsection>
<citsent citstr=" W97-1506 ">
there are already other grammar developing tools, such as grammar writer of xtag (paroubek et al, 1992), <papid> A92-1030 </papid>alep (schmidt et al, 1996), <papid> C96-1049 </papid>con troll (gotzand meurers, 1997), <papid> W97-1506 </papid>tool by nara institute of science and technology (miyata et al, 1999), and [incr tsdb()] (oepen et al, 2002).<papid> W02-1508 </papid></citsent>
<aftsection>
<nextsent>but these tools have following problems; they largely depend on human debuggers?
</nextsent>
<nextsent>language intuition, they do not help users to handle large amount of parsing results effectively, and they let human debug gers correct the bugs one after another manually and locally.
</nextsent>
<nextsent>to cope with these shortcomings, willex proposes an alternative method for more efficient debugging process.the workflow of the conventional grammar developing tools and willex are different in the followingways.
</nextsent>
<nextsent>with the conventional tools, human debug gers must check each sentence to find out grammar defects and modify them one by one.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4136">
<title id=" P03-2033.xml">a debug tool for practical grammar development </title>
<section> what is the ideal grammar debugging?.  </section>
<citcontext>
<prevsection>
<prevsent>first, it reduces human workload to improve the general-purpose grammar through using language intuition encoded in syntactically tagged corpora in xml format.
</prevsent>
<prevsent>second, it records data of grammar defects to allow developers to have whole picture of parsing errors found in the target corpora to save debugging time and effort by prioritizing them.
</prevsent>
</prevsection>
<citsent citstr=" W02-1508 ">
there are already other grammar developing tools, such as grammar writer of xtag (paroubek et al, 1992), <papid> A92-1030 </papid>alep (schmidt et al, 1996), <papid> C96-1049 </papid>con troll (gotzand meurers, 1997), <papid> W97-1506 </papid>tool by nara institute of science and technology (miyata et al, 1999), and [incr tsdb()] (oepen et al, 2002).<papid> W02-1508 </papid></citsent>
<aftsection>
<nextsent>but these tools have following problems; they largely depend on human debuggers?
</nextsent>
<nextsent>language intuition, they do not help users to handle large amount of parsing results effectively, and they let human debug gers correct the bugs one after another manually and locally.
</nextsent>
<nextsent>to cope with these shortcomings, willex proposes an alternative method for more efficient debugging process.the workflow of the conventional grammar developing tools and willex are different in the followingways.
</nextsent>
<nextsent>with the conventional tools, human debug gers must check each sentence to find out grammar defects and modify them one by one.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4137">
<title id=" P04-1004.xml">analysis of mixed natural and symbolic input in mathematical dialogs </title>
<section> linguistic data.  </section>
<citcontext>
<prevsection>
<prevsent>the students?
</prevsent>
<prevsent>turns consisted on average of 1 sentence, the tutors of 2.
</prevsent>
</prevsection>
<citsent citstr=" W04-0911 ">
more details on the corpus itself and annotation efforts that guide the development of the system components can be found in (wolska et al, 2004).<papid> W04-0911 </papid></citsent>
<aftsection>
<nextsent>2 3 stands for set complement and 4 for power set.
</nextsent>
<nextsent>3.2 language phenomena.
</nextsent>
<nextsent>to indicate the overall complexity of input understanding in our setting, we present an overview of common language phenomena in our dialogs.3 in the remainder of this paper, we then concentrate onthe issue of interleaved natural language and mathematical expressions, and present an approach to processing this type of input.
</nextsent>
<nextsent>interleaved natural language and formulae mathematical language, often semi-formal, is interleaved with natural language informally verbalizing proof steps.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4138">
<title id=" P04-1004.xml">analysis of mixed natural and symbolic input in mathematical dialogs </title>
<section> uniform input analysis strategy.  </section>
<citcontext>
<prevsection>
<prevsent>more details on the investigation into tectogrammatical relations that build up linguistic meaning of informal mathematical text can be found in (wolska and kruijff-korbayova?, 2004a).implementation the syntactic analysis is performed using openccg8, an open source parser for multi-modal combinatory categorial grammar (mmccg).
</prevsent>
<prevsent>mmccg is lexical ist grammar formalism in which application of combinatoryrules is controlled though context-sensitive specification of modes on slashes (baldridge and kruijff, 2003).
</prevsent>
</prevsection>
<citsent citstr=" P02-1041 ">
the linguistic meaning, built in parallel with the syntax, is represented using hybrid logic dependency semantics (hlds), hybrid logic representation which allows compositional, unification-based construction of hlds terms with ccg (baldridge and kruijff, 2002).<papid> P02-1041 </papid></citsent>
<aftsection>
<nextsent>an hldsterm is relational structure where dependency relations between heads and dependents are encoded asmodal relations.
</nextsent>
<nextsent>the syntactic categories for lexical entry formula, corresponding to mathematical expressions of type formula?, are , fl , and . for example, in one of the readings of enthaelt  ff  ?, enthaelt?
</nextsent>
<nextsent>represents the meaning contain taking dependents in the relations actor and patient, shown schematically in fig.
</nextsent>
<nextsent>2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4139">
<title id=" P03-1021.xml">minimum error rate training in statistical machine translation </title>
<section> automatic assessment of translation.  </section>
<citcontext>
<prevsection>
<prevsent>in section 7, we evaluate the different training criteria in the context of several mt experiments.
</prevsent>
<prevsent>quality in recent years, various methods have been proposed to automatically evaluate machine translation quality by comparing hypothesis translations with reference translations.
</prevsent>
</prevsection>
<citsent citstr=" W00-1401 ">
examples of such methods are word error rate, position-independent word error rate (tillmann et al, 1997), generation string accuracy (bangalore et al, 2000), <papid> W00-1401 </papid>multi-reference word error rate (nieen et al, 2000), bleu score (pap ineni et al, 2001), nist score (doddington, 2002).all these criteria try to approximate human assessment and often achieve an astonishing degree of correlation to human subjective evaluation of fluency and adequacy (papineni et al, 2001; doddington, 2002).</citsent>
<aftsection>
<nextsent>in this paper, we use the following methods: - multi-reference word error rate (mwer):when this method is used, the hypothesis translation is compared to various reference translations by computing the edit distance (minimum number of substitutions, insertions, deletions) between the hypothesis and the closest of the given reference translations.
</nextsent>
<nextsent>- multi-reference position independent error rate (mper): this criterion ignores the word order by treating sentence as bag-of-words and computing the minimum number of substitutions, insertions, deletions needed to transform the hypothesis into the closest of the given reference translations.- bleu score: this criterion computes the geometric mean of the precision of . -grams of various lengths between hypothesis and set of reference translations multiplied by factor bp 0/  that penalizes short sentences: bleu
</nextsent>
<nextsent>bp 0/  /1 $325476 &amp; 8   (*)    8 9 : here   8 denotes the precision of . -grams in the hypothesis translation.
</nextsent>
<nextsent>we use 9
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4140">
<title id=" P03-1021.xml">minimum error rate training in statistical machine translation </title>
<section> baseline translation approach.  </section>
<citcontext>
<prevsection>
<prevsent>the optimal can now be computed easily by traversing the sequence of interval boundaries while updating an error count.
</prevsent>
<prevsent>it is straightforward to refine this algorithm to also handle the bleu and nist scores instead ofsentence-level error counts by accumulating the relevant statistics for computing these scores (n-gram precision, translation length and reference length) .
</prevsent>
</prevsection>
<citsent citstr=" P02-1038 ">
the basic feature functions of our model are identical to the alignment template approach (och and ney, 2002).<papid> P02-1038 </papid></citsent>
<aftsection>
<nextsent>in this translation model, sentence is translated by segmenting the input sentence into phrases, translating these phrases and reordering the translations in the target language.
</nextsent>
<nextsent>in addition to the feature functions described in (och and ney, 2002), <papid> P02-1038 </papid>our system includes phrase penalty (the number of alignment templates used) and special alignment features.</nextsent>
<nextsent>altogether, the log-linear model includes</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4142">
<title id=" P03-1021.xml">minimum error rate training in statistical machine translation </title>
<section> baseline translation approach.  </section>
<citcontext>
<prevsection>
<prevsent>therefore, the feature functions are much more informative?
</prevsent>
<prevsent>than for instance the binary feature functions used in standard maximum entropy models in natural language processing.
</prevsent>
</prevsection>
<citsent citstr=" W99-0604 ">
for search, we use dynamic programmingbeam-search algorithm to explore subset of all possible translations (och et al, 1999) <papid> W99-0604 </papid>and extract . best candidate translations using a* search (ueffing et al, 2002).<papid> W02-1021 </papid></citsent>
<aftsection>
<nextsent>using an . -best approximation, we might face the problem that the parameters trained are good for thelist of . translations used, but yield worse translation results if these parameters are used in the dynamic programming search.
</nextsent>
<nextsent>hence, it is possible that our new search produces translations with more errors on the training corpus.
</nextsent>
<nextsent>this can happen be cause with the modified model scaling factors the . -best list can change significantly and can include sentences not in the existing . -best list.
</nextsent>
<nextsent>to avoid this problem, we adopt the following solution: first, we perform search (using manually defined set of parameter values) and compute an . -best list, and use this . -best list to train the model parameters.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4143">
<title id=" P03-1021.xml">minimum error rate training in statistical machine translation </title>
<section> baseline translation approach.  </section>
<citcontext>
<prevsection>
<prevsent>therefore, the feature functions are much more informative?
</prevsent>
<prevsent>than for instance the binary feature functions used in standard maximum entropy models in natural language processing.
</prevsent>
</prevsection>
<citsent citstr=" W02-1021 ">
for search, we use dynamic programmingbeam-search algorithm to explore subset of all possible translations (och et al, 1999) <papid> W99-0604 </papid>and extract . best candidate translations using a* search (ueffing et al, 2002).<papid> W02-1021 </papid></citsent>
<aftsection>
<nextsent>using an . -best approximation, we might face the problem that the parameters trained are good for thelist of . translations used, but yield worse translation results if these parameters are used in the dynamic programming search.
</nextsent>
<nextsent>hence, it is possible that our new search produces translations with more errors on the training corpus.
</nextsent>
<nextsent>this can happen be cause with the modified model scaling factors the . -best list can change significantly and can include sentences not in the existing . -best list.
</nextsent>
<nextsent>to avoid this problem, we adopt the following solution: first, we perform search (using manually defined set of parameter values) and compute an . -best list, and use this . -best list to train the model parameters.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4145">
<title id=" P03-1021.xml">minimum error rate training in statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the loss function is either identical or closely related to the final evaluation criterion.
</prevsent>
<prevsent>in contrast to the approach presentedin this paper, the training criterion and the statistical models used remain unchanged in the minimum bayes risk approach.
</prevsent>
</prevsection>
<citsent citstr=" P96-1024 ">
in the field of natural language processing this approach has been applied for example in parsing (goodman, 1996) <papid> P96-1024 </papid>and word alignment (kumar and byrne, 2002).<papid> W02-1019 </papid></citsent>
<aftsection>
<nextsent>we presented alternative training criteria for loglinear statistical machine translation models which are directly related to translation quality: an un smoothed error count and smoothed error counton development corpus.
</nextsent>
<nextsent>for the un smoothed error count, we presented new line optimization algorithm which can efficiently find the optimal solution along line.
</nextsent>
<nextsent>we showed that this approach obtains significantly better results than using the mmi training criterion (with our method to define pseudo references) and that optimizing error rate as part of the training criterion helps to obtain better error rateon unseen test data.
</nextsent>
<nextsent>as result, we expect that actual true?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4146">
<title id=" P03-1021.xml">minimum error rate training in statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the loss function is either identical or closely related to the final evaluation criterion.
</prevsent>
<prevsent>in contrast to the approach presentedin this paper, the training criterion and the statistical models used remain unchanged in the minimum bayes risk approach.
</prevsent>
</prevsection>
<citsent citstr=" W02-1019 ">
in the field of natural language processing this approach has been applied for example in parsing (goodman, 1996) <papid> P96-1024 </papid>and word alignment (kumar and byrne, 2002).<papid> W02-1019 </papid></citsent>
<aftsection>
<nextsent>we presented alternative training criteria for loglinear statistical machine translation models which are directly related to translation quality: an un smoothed error count and smoothed error counton development corpus.
</nextsent>
<nextsent>for the un smoothed error count, we presented new line optimization algorithm which can efficiently find the optimal solution along line.
</nextsent>
<nextsent>we showed that this approach obtains significantly better results than using the mmi training criterion (with our method to define pseudo references) and that optimizing error rate as part of the training criterion helps to obtain better error rateon unseen test data.
</nextsent>
<nextsent>as result, we expect that actual true?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4147">
<title id=" P03-1009.xml">clustering polysemic subcategorization frame distributions semantically </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a novel evaluation scheme is proposed which accounts forthe effect of polysemy on the clusters, offering us good insight into the potential and limitations of semantically classifying undisambiguated scf data.
</prevsent>
<prevsent>classifications which aim to capture the close relation between the syntax and semantics of verbs have attracted considerable research interest in both linguistics and computational linguistics (e.g.
</prevsent>
</prevsection>
<citsent citstr=" P98-1046 ">
(jack endoff, 1990; levin, 1993; pinker, 1989; dang et al., 1998; <papid> P98-1046 </papid>dorr, 1997; merlo and stevenson, 2001)).<papid> J01-3003 </papid></citsent>
<aftsection>
<nextsent>while such classifications may not provide means for full semantic inferencing, they can capture generalizations over range of linguistic properties, andcan therefore be used as means of reducing redundancy in the lexicon and for filling gaps in lexical knowledge.
</nextsent>
<nextsent>this work was partly supported by uk epsrc project gr/n36462/93: robust accurate statistical parsing (rasp)?.
</nextsent>
<nextsent>verb classifications have, in fact, been used to support many natural language processing (nlp)tasks, such as language generation, machine translation (dorr, 1997), document classification (klavans and kan, 1998), <papid> P98-1112 </papid>word sense disambiguation (dorr and jones, 1996) <papid> C96-1055 </papid>and subcategorization acquisition (korhonen, 2002).</nextsent>
<nextsent>one attractive property of these classifications isthat they make it possible, to certain extent, to infer the semantics of verb on the basis of its syntactic behaviour.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4148">
<title id=" P03-1009.xml">clustering polysemic subcategorization frame distributions semantically </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a novel evaluation scheme is proposed which accounts forthe effect of polysemy on the clusters, offering us good insight into the potential and limitations of semantically classifying undisambiguated scf data.
</prevsent>
<prevsent>classifications which aim to capture the close relation between the syntax and semantics of verbs have attracted considerable research interest in both linguistics and computational linguistics (e.g.
</prevsent>
</prevsection>
<citsent citstr=" J01-3003 ">
(jack endoff, 1990; levin, 1993; pinker, 1989; dang et al., 1998; <papid> P98-1046 </papid>dorr, 1997; merlo and stevenson, 2001)).<papid> J01-3003 </papid></citsent>
<aftsection>
<nextsent>while such classifications may not provide means for full semantic inferencing, they can capture generalizations over range of linguistic properties, andcan therefore be used as means of reducing redundancy in the lexicon and for filling gaps in lexical knowledge.
</nextsent>
<nextsent>this work was partly supported by uk epsrc project gr/n36462/93: robust accurate statistical parsing (rasp)?.
</nextsent>
<nextsent>verb classifications have, in fact, been used to support many natural language processing (nlp)tasks, such as language generation, machine translation (dorr, 1997), document classification (klavans and kan, 1998), <papid> P98-1112 </papid>word sense disambiguation (dorr and jones, 1996) <papid> C96-1055 </papid>and subcategorization acquisition (korhonen, 2002).</nextsent>
<nextsent>one attractive property of these classifications isthat they make it possible, to certain extent, to infer the semantics of verb on the basis of its syntactic behaviour.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4149">
<title id=" P03-1009.xml">clustering polysemic subcategorization frame distributions semantically </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>while such classifications may not provide means for full semantic inferencing, they can capture generalizations over range of linguistic properties, andcan therefore be used as means of reducing redundancy in the lexicon and for filling gaps in lexical knowledge.
</prevsent>
<prevsent>this work was partly supported by uk epsrc project gr/n36462/93: robust accurate statistical parsing (rasp)?.
</prevsent>
</prevsection>
<citsent citstr=" P98-1112 ">
verb classifications have, in fact, been used to support many natural language processing (nlp)tasks, such as language generation, machine translation (dorr, 1997), document classification (klavans and kan, 1998), <papid> P98-1112 </papid>word sense disambiguation (dorr and jones, 1996) <papid> C96-1055 </papid>and subcategorization acquisition (korhonen, 2002).</citsent>
<aftsection>
<nextsent>one attractive property of these classifications isthat they make it possible, to certain extent, to infer the semantics of verb on the basis of its syntactic behaviour.
</nextsent>
<nextsent>in recent years several attempts have been made to automatically induce semantic verb classes from (mainly) syntactic information in corpus data (joanis, 2002; merlo et al, 2002; <papid> P02-1027 </papid>schulte im walde and brew, 2002).</nextsent>
<nextsent>in this paper, we focus on the particular taskof classifying subcategorization frame (scf) distributions in semantically motivated manner.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4150">
<title id=" P03-1009.xml">clustering polysemic subcategorization frame distributions semantically </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>while such classifications may not provide means for full semantic inferencing, they can capture generalizations over range of linguistic properties, andcan therefore be used as means of reducing redundancy in the lexicon and for filling gaps in lexical knowledge.
</prevsent>
<prevsent>this work was partly supported by uk epsrc project gr/n36462/93: robust accurate statistical parsing (rasp)?.
</prevsent>
</prevsection>
<citsent citstr=" C96-1055 ">
verb classifications have, in fact, been used to support many natural language processing (nlp)tasks, such as language generation, machine translation (dorr, 1997), document classification (klavans and kan, 1998), <papid> P98-1112 </papid>word sense disambiguation (dorr and jones, 1996) <papid> C96-1055 </papid>and subcategorization acquisition (korhonen, 2002).</citsent>
<aftsection>
<nextsent>one attractive property of these classifications isthat they make it possible, to certain extent, to infer the semantics of verb on the basis of its syntactic behaviour.
</nextsent>
<nextsent>in recent years several attempts have been made to automatically induce semantic verb classes from (mainly) syntactic information in corpus data (joanis, 2002; merlo et al, 2002; <papid> P02-1027 </papid>schulte im walde and brew, 2002).</nextsent>
<nextsent>in this paper, we focus on the particular taskof classifying subcategorization frame (scf) distributions in semantically motivated manner.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4151">
<title id=" P03-1009.xml">clustering polysemic subcategorization frame distributions semantically </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>verb classifications have, in fact, been used to support many natural language processing (nlp)tasks, such as language generation, machine translation (dorr, 1997), document classification (klavans and kan, 1998), <papid> P98-1112 </papid>word sense disambiguation (dorr and jones, 1996) <papid> C96-1055 </papid>and subcategorization acquisition (korhonen, 2002).</prevsent>
<prevsent>one attractive property of these classifications isthat they make it possible, to certain extent, to infer the semantics of verb on the basis of its syntactic behaviour.</prevsent>
</prevsection>
<citsent citstr=" P02-1027 ">
in recent years several attempts have been made to automatically induce semantic verb classes from (mainly) syntactic information in corpus data (joanis, 2002; merlo et al, 2002; <papid> P02-1027 </papid>schulte im walde and brew, 2002).</citsent>
<aftsection>
<nextsent>in this paper, we focus on the particular taskof classifying subcategorization frame (scf) distributions in semantically motivated manner.
</nextsent>
<nextsent>previous research has demonstrated that clustering can be useful in inferring levin-style semantic classes (levin, 1993) from both english and german verb subcategorization information (brew and schulte im walde, 2002; schulte im walde, 2000; schulte im walde and brew, 2002).
</nextsent>
<nextsent>we propose novel approach, which involves: (i)obtaining scf frequency information from lexicon extracted automatically using the comprehensive system of briscoe and carroll (1997) <papid> A97-1052 </papid>and (ii)applying clustering mechanism to this informa tion.</nextsent>
<nextsent>we use clustering methods that process raw distributional data directly, avoiding complex preprocessing steps required by many advanced methods (e.g. brew and schulte im walde (2002)).<papid> W02-1016 </papid>in contrast to earlier work, we give special emphasis to polysemy.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4152">
<title id=" P03-1009.xml">clustering polysemic subcategorization frame distributions semantically </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we focus on the particular taskof classifying subcategorization frame (scf) distributions in semantically motivated manner.
</prevsent>
<prevsent>previous research has demonstrated that clustering can be useful in inferring levin-style semantic classes (levin, 1993) from both english and german verb subcategorization information (brew and schulte im walde, 2002; schulte im walde, 2000; schulte im walde and brew, 2002).
</prevsent>
</prevsection>
<citsent citstr=" A97-1052 ">
we propose novel approach, which involves: (i)obtaining scf frequency information from lexicon extracted automatically using the comprehensive system of briscoe and carroll (1997) <papid> A97-1052 </papid>and (ii)applying clustering mechanism to this informa tion.</citsent>
<aftsection>
<nextsent>we use clustering methods that process raw distributional data directly, avoiding complex preprocessing steps required by many advanced methods (e.g. brew and schulte im walde (2002)).<papid> W02-1016 </papid>in contrast to earlier work, we give special emphasis to polysemy.</nextsent>
<nextsent>earlier work has largely ignored this issue by assuming single gold standard class for each verb (whether polysemic or not).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4153">
<title id=" P03-1009.xml">clustering polysemic subcategorization frame distributions semantically </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>previous research has demonstrated that clustering can be useful in inferring levin-style semantic classes (levin, 1993) from both english and german verb subcategorization information (brew and schulte im walde, 2002; schulte im walde, 2000; schulte im walde and brew, 2002).
</prevsent>
<prevsent>we propose novel approach, which involves: (i)obtaining scf frequency information from lexicon extracted automatically using the comprehensive system of briscoe and carroll (1997) <papid> A97-1052 </papid>and (ii)applying clustering mechanism to this informa tion.</prevsent>
</prevsection>
<citsent citstr=" W02-1016 ">
we use clustering methods that process raw distributional data directly, avoiding complex preprocessing steps required by many advanced methods (e.g. brew and schulte im walde (2002)).<papid> W02-1016 </papid>in contrast to earlier work, we give special emphasis to polysemy.</citsent>
<aftsection>
<nextsent>earlier work has largely ignored this issue by assuming single gold standard class for each verb (whether polysemic or not).
</nextsent>
<nextsent>the relatively good clustering results obtained suggest that many polysemic verbs do have some predominating sense in corpus data.
</nextsent>
<nextsent>however, this sense can vary across corpora (roland et al, 2000), <papid> W00-0905 </papid>and assuming single sense is inadequate for an important group of medium and high frequency verbs whose distribution of senses in balanced corpus data is flat rather than zipfian (preiss and korhonen, 2002).<papid> W02-0815 </papid></nextsent>
<nextsent>to allow for sense variation, we introduce new evaluation scheme against polysemic gold stan dard.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4154">
<title id=" P03-1009.xml">clustering polysemic subcategorization frame distributions semantically </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>earlier work has largely ignored this issue by assuming single gold standard class for each verb (whether polysemic or not).
</prevsent>
<prevsent>the relatively good clustering results obtained suggest that many polysemic verbs do have some predominating sense in corpus data.
</prevsent>
</prevsection>
<citsent citstr=" W00-0905 ">
however, this sense can vary across corpora (roland et al, 2000), <papid> W00-0905 </papid>and assuming single sense is inadequate for an important group of medium and high frequency verbs whose distribution of senses in balanced corpus data is flat rather than zipfian (preiss and korhonen, 2002).<papid> W02-0815 </papid></citsent>
<aftsection>
<nextsent>to allow for sense variation, we introduce new evaluation scheme against polysemic gold standard.
</nextsent>
<nextsent>this helps to explain the results and offers better insight into the potential and limitations of clustering undisambiguated scf data semantically.
</nextsent>
<nextsent>we discuss our gold standards and the choice of test verbs in section 2.
</nextsent>
<nextsent>section 3 describes the method for subcategorization acquisition and section 4 presents the approach to clustering.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4155">
<title id=" P03-1009.xml">clustering polysemic subcategorization frame distributions semantically </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>earlier work has largely ignored this issue by assuming single gold standard class for each verb (whether polysemic or not).
</prevsent>
<prevsent>the relatively good clustering results obtained suggest that many polysemic verbs do have some predominating sense in corpus data.
</prevsent>
</prevsection>
<citsent citstr=" W02-0815 ">
however, this sense can vary across corpora (roland et al, 2000), <papid> W00-0905 </papid>and assuming single sense is inadequate for an important group of medium and high frequency verbs whose distribution of senses in balanced corpus data is flat rather than zipfian (preiss and korhonen, 2002).<papid> W02-0815 </papid></citsent>
<aftsection>
<nextsent>to allow for sense variation, we introduce new evaluation scheme against polysemic gold standard.
</nextsent>
<nextsent>this helps to explain the results and offers better insight into the potential and limitations of clustering undisambiguated scf data semantically.
</nextsent>
<nextsent>we discuss our gold standards and the choice of test verbs in section 2.
</nextsent>
<nextsent>section 3 describes the method for subcategorization acquisition and section 4 presents the approach to clustering.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4157">
<title id=" P03-1009.xml">clustering polysemic subcategorization frame distributions semantically </title>
<section> subcategorization information.  </section>
<citcontext>
<prevsection>
<prevsent>the test verbs and their classes are shown in table 1.
</prevsent>
<prevsent>the classes are indicated by number codes from the classifications of levin, dorr (the classes starting with 0) and korhonen (the classes starting with a).3 the predominant sense is indicated by bold font.
</prevsent>
</prevsection>
<citsent citstr=" P87-1027 ">
we obtain our scf data using the subcategorization acquisition system of briscoe and carroll (1997).<papid> A97-1052 </papid>we expect the use of this system to be benefi cial: it employs robust statistical parser (briscoe and carroll, 2002) which yields complete though shallow parses, and comprehensive scf classifier,which incorporates 163 scf distinctions, superset of those found in the anlt (boguraev et al,1987) <papid> P87-1027 </papid>and comlex (grishman et al, 1994) <papid> C94-1042 </papid>dictionaries.</citsent>
<aftsection>
<nextsent>the scfs abstract over specific lexically governed particles and prepositions and specific predicate selectional preferences but include some derived semi-predictable bounded dependency constructions, such as particle and dative movement.
</nextsent>
<nextsent>78 of these coarse-grained?
</nextsent>
<nextsent>scfs appeared in our data.
</nextsent>
<nextsent>in addition, set of 160 fine grained frames were employed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4158">
<title id=" P03-1009.xml">clustering polysemic subcategorization frame distributions semantically </title>
<section> subcategorization information.  </section>
<citcontext>
<prevsection>
<prevsent>the test verbs and their classes are shown in table 1.
</prevsent>
<prevsent>the classes are indicated by number codes from the classifications of levin, dorr (the classes starting with 0) and korhonen (the classes starting with a).3 the predominant sense is indicated by bold font.
</prevsent>
</prevsection>
<citsent citstr=" C94-1042 ">
we obtain our scf data using the subcategorization acquisition system of briscoe and carroll (1997).<papid> A97-1052 </papid>we expect the use of this system to be benefi cial: it employs robust statistical parser (briscoe and carroll, 2002) which yields complete though shallow parses, and comprehensive scf classifier,which incorporates 163 scf distinctions, superset of those found in the anlt (boguraev et al,1987) <papid> P87-1027 </papid>and comlex (grishman et al, 1994) <papid> C94-1042 </papid>dictionaries.</citsent>
<aftsection>
<nextsent>the scfs abstract over specific lexically governed particles and prepositions and specific predicate selectional preferences but include some derived semi-predictable bounded dependency constructions, such as particle and dative movement.
</nextsent>
<nextsent>78 of these coarse-grained?
</nextsent>
<nextsent>scfs appeared in our data.
</nextsent>
<nextsent>in addition, set of 160 fine grained frames were employed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4159">
<title id=" P03-1009.xml">clustering polysemic subcategorization frame distributions semantically </title>
<section> experimental evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>it is multiplied by factor that increases with cluster size.
</prevsent>
<prevsent>this factor compensates for bias towards small clusters.
</prevsent>
</prevsection>
<citsent citstr=" W03-0410 ">
our second measure is derived from purity, global measure which evaluates the mean precision of the clusters, weighted according to the cluster size (stevenson and joanis, 2003).<papid> W03-0410 </papid></citsent>
<aftsection>
<nextsent>we associate with each cluster its most prevalent semantic class, and denote the number of verbs in cluster that take its prevalent class by nprevalent(k).
</nextsent>
<nextsent>verbs that do not take this class are considered as errors.
</nextsent>
<nextsent>give nour task, we are only interested in classes which contain two or more verbs.
</nextsent>
<nextsent>we therefore disregard those clusters where nprevalent(k) = 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4163">
<title id=" P03-1071.xml">discourse segmentation of multiparty conversation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>existing approaches to textual segmentation can be broadly divided into two categories.
</prevsent>
<prevsent>on the one hand, many algorithms exploit the fact that topic segments tend to be lexically cohesive.
</prevsent>
</prevsection>
<citsent citstr=" J91-1002 ">
embodiments of this idea include semantic similarity (mor ris and hirst, 1991; <papid> J91-1002 </papid>kozima, 1993), <papid> P93-1041 </papid>cosine similarity in word vector space (hearst, 1994), <papid> P94-1002 </papid>inter-sentencesimilarity matrix (reynar, 1994; <papid> P94-1050 </papid>choi, 2000), <papid> A00-2004 </papid>entity repetition (kan et al, 1998), <papid> W98-1123 </papid>word frequency models (reynar, 1999), <papid> P99-1046 </papid>or adaptive language models (beeferman et al, 1999).</citsent>
<aftsection>
<nextsent>other algorithms exploit variety of linguistic features that may mark topic boundaries, such as referential noun phrases (pas sonneau and litman, 1997).<papid> J97-1005 </papid>in work on segmentation of spoken documents, into national, prosodic, and acoustic indicators are used to detect topic boundaries (grosz and hirschberg, 1992; nakatani et al, 1995; hirschberg and nakatani, 1996; <papid> P96-1038 </papid>passonneau and litman, 1997; <papid> J97-1005 </papid>hirschberg and nakatani, 1998; beeferman et al, 1999; tur et al, 2001).<papid> J01-1002 </papid></nextsent>
<nextsent>such indicators include long pauses, shifts in speaking rate, great range in f0 and intensity, and higher maximum accent peak.these approaches use different learning mechanisms to combine features, including decision trees(grosz and hirschberg, 1992; passonneau and litman, 1997; <papid> J97-1005 </papid>tur et al, 2001) <papid> J01-1002 </papid>exponential models(beeferman et al, 1999) or other probabilistic models (hajime et al, 1998; reynar, 1999).<papid> P99-1046 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4164">
<title id=" P03-1071.xml">discourse segmentation of multiparty conversation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>existing approaches to textual segmentation can be broadly divided into two categories.
</prevsent>
<prevsent>on the one hand, many algorithms exploit the fact that topic segments tend to be lexically cohesive.
</prevsent>
</prevsection>
<citsent citstr=" P93-1041 ">
embodiments of this idea include semantic similarity (mor ris and hirst, 1991; <papid> J91-1002 </papid>kozima, 1993), <papid> P93-1041 </papid>cosine similarity in word vector space (hearst, 1994), <papid> P94-1002 </papid>inter-sentencesimilarity matrix (reynar, 1994; <papid> P94-1050 </papid>choi, 2000), <papid> A00-2004 </papid>entity repetition (kan et al, 1998), <papid> W98-1123 </papid>word frequency models (reynar, 1999), <papid> P99-1046 </papid>or adaptive language models (beeferman et al, 1999).</citsent>
<aftsection>
<nextsent>other algorithms exploit variety of linguistic features that may mark topic boundaries, such as referential noun phrases (pas sonneau and litman, 1997).<papid> J97-1005 </papid>in work on segmentation of spoken documents, into national, prosodic, and acoustic indicators are used to detect topic boundaries (grosz and hirschberg, 1992; nakatani et al, 1995; hirschberg and nakatani, 1996; <papid> P96-1038 </papid>passonneau and litman, 1997; <papid> J97-1005 </papid>hirschberg and nakatani, 1998; beeferman et al, 1999; tur et al, 2001).<papid> J01-1002 </papid></nextsent>
<nextsent>such indicators include long pauses, shifts in speaking rate, great range in f0 and intensity, and higher maximum accent peak.these approaches use different learning mechanisms to combine features, including decision trees(grosz and hirschberg, 1992; passonneau and litman, 1997; <papid> J97-1005 </papid>tur et al, 2001) <papid> J01-1002 </papid>exponential models(beeferman et al, 1999) or other probabilistic models (hajime et al, 1998; reynar, 1999).<papid> P99-1046 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4165">
<title id=" P03-1071.xml">discourse segmentation of multiparty conversation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>existing approaches to textual segmentation can be broadly divided into two categories.
</prevsent>
<prevsent>on the one hand, many algorithms exploit the fact that topic segments tend to be lexically cohesive.
</prevsent>
</prevsection>
<citsent citstr=" P94-1002 ">
embodiments of this idea include semantic similarity (mor ris and hirst, 1991; <papid> J91-1002 </papid>kozima, 1993), <papid> P93-1041 </papid>cosine similarity in word vector space (hearst, 1994), <papid> P94-1002 </papid>inter-sentencesimilarity matrix (reynar, 1994; <papid> P94-1050 </papid>choi, 2000), <papid> A00-2004 </papid>entity repetition (kan et al, 1998), <papid> W98-1123 </papid>word frequency models (reynar, 1999), <papid> P99-1046 </papid>or adaptive language models (beeferman et al, 1999).</citsent>
<aftsection>
<nextsent>other algorithms exploit variety of linguistic features that may mark topic boundaries, such as referential noun phrases (pas sonneau and litman, 1997).<papid> J97-1005 </papid>in work on segmentation of spoken documents, into national, prosodic, and acoustic indicators are used to detect topic boundaries (grosz and hirschberg, 1992; nakatani et al, 1995; hirschberg and nakatani, 1996; <papid> P96-1038 </papid>passonneau and litman, 1997; <papid> J97-1005 </papid>hirschberg and nakatani, 1998; beeferman et al, 1999; tur et al, 2001).<papid> J01-1002 </papid></nextsent>
<nextsent>such indicators include long pauses, shifts in speaking rate, great range in f0 and intensity, and higher maximum accent peak.these approaches use different learning mechanisms to combine features, including decision trees(grosz and hirschberg, 1992; passonneau and litman, 1997; <papid> J97-1005 </papid>tur et al, 2001) <papid> J01-1002 </papid>exponential models(beeferman et al, 1999) or other probabilistic models (hajime et al, 1998; reynar, 1999).<papid> P99-1046 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4167">
<title id=" P03-1071.xml">discourse segmentation of multiparty conversation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>existing approaches to textual segmentation can be broadly divided into two categories.
</prevsent>
<prevsent>on the one hand, many algorithms exploit the fact that topic segments tend to be lexically cohesive.
</prevsent>
</prevsection>
<citsent citstr=" P94-1050 ">
embodiments of this idea include semantic similarity (mor ris and hirst, 1991; <papid> J91-1002 </papid>kozima, 1993), <papid> P93-1041 </papid>cosine similarity in word vector space (hearst, 1994), <papid> P94-1002 </papid>inter-sentencesimilarity matrix (reynar, 1994; <papid> P94-1050 </papid>choi, 2000), <papid> A00-2004 </papid>entity repetition (kan et al, 1998), <papid> W98-1123 </papid>word frequency models (reynar, 1999), <papid> P99-1046 </papid>or adaptive language models (beeferman et al, 1999).</citsent>
<aftsection>
<nextsent>other algorithms exploit variety of linguistic features that may mark topic boundaries, such as referential noun phrases (pas sonneau and litman, 1997).<papid> J97-1005 </papid>in work on segmentation of spoken documents, into national, prosodic, and acoustic indicators are used to detect topic boundaries (grosz and hirschberg, 1992; nakatani et al, 1995; hirschberg and nakatani, 1996; <papid> P96-1038 </papid>passonneau and litman, 1997; <papid> J97-1005 </papid>hirschberg and nakatani, 1998; beeferman et al, 1999; tur et al, 2001).<papid> J01-1002 </papid></nextsent>
<nextsent>such indicators include long pauses, shifts in speaking rate, great range in f0 and intensity, and higher maximum accent peak.these approaches use different learning mechanisms to combine features, including decision trees(grosz and hirschberg, 1992; passonneau and litman, 1997; <papid> J97-1005 </papid>tur et al, 2001) <papid> J01-1002 </papid>exponential models(beeferman et al, 1999) or other probabilistic models (hajime et al, 1998; reynar, 1999).<papid> P99-1046 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4168">
<title id=" P03-1071.xml">discourse segmentation of multiparty conversation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>existing approaches to textual segmentation can be broadly divided into two categories.
</prevsent>
<prevsent>on the one hand, many algorithms exploit the fact that topic segments tend to be lexically cohesive.
</prevsent>
</prevsection>
<citsent citstr=" A00-2004 ">
embodiments of this idea include semantic similarity (mor ris and hirst, 1991; <papid> J91-1002 </papid>kozima, 1993), <papid> P93-1041 </papid>cosine similarity in word vector space (hearst, 1994), <papid> P94-1002 </papid>inter-sentencesimilarity matrix (reynar, 1994; <papid> P94-1050 </papid>choi, 2000), <papid> A00-2004 </papid>entity repetition (kan et al, 1998), <papid> W98-1123 </papid>word frequency models (reynar, 1999), <papid> P99-1046 </papid>or adaptive language models (beeferman et al, 1999).</citsent>
<aftsection>
<nextsent>other algorithms exploit variety of linguistic features that may mark topic boundaries, such as referential noun phrases (pas sonneau and litman, 1997).<papid> J97-1005 </papid>in work on segmentation of spoken documents, into national, prosodic, and acoustic indicators are used to detect topic boundaries (grosz and hirschberg, 1992; nakatani et al, 1995; hirschberg and nakatani, 1996; <papid> P96-1038 </papid>passonneau and litman, 1997; <papid> J97-1005 </papid>hirschberg and nakatani, 1998; beeferman et al, 1999; tur et al, 2001).<papid> J01-1002 </papid></nextsent>
<nextsent>such indicators include long pauses, shifts in speaking rate, great range in f0 and intensity, and higher maximum accent peak.these approaches use different learning mechanisms to combine features, including decision trees(grosz and hirschberg, 1992; passonneau and litman, 1997; <papid> J97-1005 </papid>tur et al, 2001) <papid> J01-1002 </papid>exponential models(beeferman et al, 1999) or other probabilistic models (hajime et al, 1998; reynar, 1999).<papid> P99-1046 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4169">
<title id=" P03-1071.xml">discourse segmentation of multiparty conversation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>existing approaches to textual segmentation can be broadly divided into two categories.
</prevsent>
<prevsent>on the one hand, many algorithms exploit the fact that topic segments tend to be lexically cohesive.
</prevsent>
</prevsection>
<citsent citstr=" W98-1123 ">
embodiments of this idea include semantic similarity (mor ris and hirst, 1991; <papid> J91-1002 </papid>kozima, 1993), <papid> P93-1041 </papid>cosine similarity in word vector space (hearst, 1994), <papid> P94-1002 </papid>inter-sentencesimilarity matrix (reynar, 1994; <papid> P94-1050 </papid>choi, 2000), <papid> A00-2004 </papid>entity repetition (kan et al, 1998), <papid> W98-1123 </papid>word frequency models (reynar, 1999), <papid> P99-1046 </papid>or adaptive language models (beeferman et al, 1999).</citsent>
<aftsection>
<nextsent>other algorithms exploit variety of linguistic features that may mark topic boundaries, such as referential noun phrases (pas sonneau and litman, 1997).<papid> J97-1005 </papid>in work on segmentation of spoken documents, into national, prosodic, and acoustic indicators are used to detect topic boundaries (grosz and hirschberg, 1992; nakatani et al, 1995; hirschberg and nakatani, 1996; <papid> P96-1038 </papid>passonneau and litman, 1997; <papid> J97-1005 </papid>hirschberg and nakatani, 1998; beeferman et al, 1999; tur et al, 2001).<papid> J01-1002 </papid></nextsent>
<nextsent>such indicators include long pauses, shifts in speaking rate, great range in f0 and intensity, and higher maximum accent peak.these approaches use different learning mechanisms to combine features, including decision trees(grosz and hirschberg, 1992; passonneau and litman, 1997; <papid> J97-1005 </papid>tur et al, 2001) <papid> J01-1002 </papid>exponential models(beeferman et al, 1999) or other probabilistic models (hajime et al, 1998; reynar, 1999).<papid> P99-1046 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4170">
<title id=" P03-1071.xml">discourse segmentation of multiparty conversation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>existing approaches to textual segmentation can be broadly divided into two categories.
</prevsent>
<prevsent>on the one hand, many algorithms exploit the fact that topic segments tend to be lexically cohesive.
</prevsent>
</prevsection>
<citsent citstr=" P99-1046 ">
embodiments of this idea include semantic similarity (mor ris and hirst, 1991; <papid> J91-1002 </papid>kozima, 1993), <papid> P93-1041 </papid>cosine similarity in word vector space (hearst, 1994), <papid> P94-1002 </papid>inter-sentencesimilarity matrix (reynar, 1994; <papid> P94-1050 </papid>choi, 2000), <papid> A00-2004 </papid>entity repetition (kan et al, 1998), <papid> W98-1123 </papid>word frequency models (reynar, 1999), <papid> P99-1046 </papid>or adaptive language models (beeferman et al, 1999).</citsent>
<aftsection>
<nextsent>other algorithms exploit variety of linguistic features that may mark topic boundaries, such as referential noun phrases (pas sonneau and litman, 1997).<papid> J97-1005 </papid>in work on segmentation of spoken documents, into national, prosodic, and acoustic indicators are used to detect topic boundaries (grosz and hirschberg, 1992; nakatani et al, 1995; hirschberg and nakatani, 1996; <papid> P96-1038 </papid>passonneau and litman, 1997; <papid> J97-1005 </papid>hirschberg and nakatani, 1998; beeferman et al, 1999; tur et al, 2001).<papid> J01-1002 </papid></nextsent>
<nextsent>such indicators include long pauses, shifts in speaking rate, great range in f0 and intensity, and higher maximum accent peak.these approaches use different learning mechanisms to combine features, including decision trees(grosz and hirschberg, 1992; passonneau and litman, 1997; <papid> J97-1005 </papid>tur et al, 2001) <papid> J01-1002 </papid>exponential models(beeferman et al, 1999) or other probabilistic models (hajime et al, 1998; reynar, 1999).<papid> P99-1046 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4171">
<title id=" P03-1071.xml">discourse segmentation of multiparty conversation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>on the one hand, many algorithms exploit the fact that topic segments tend to be lexically cohesive.
</prevsent>
<prevsent>embodiments of this idea include semantic similarity (mor ris and hirst, 1991; <papid> J91-1002 </papid>kozima, 1993), <papid> P93-1041 </papid>cosine similarity in word vector space (hearst, 1994), <papid> P94-1002 </papid>inter-sentencesimilarity matrix (reynar, 1994; <papid> P94-1050 </papid>choi, 2000), <papid> A00-2004 </papid>entity repetition (kan et al, 1998), <papid> W98-1123 </papid>word frequency models (reynar, 1999), <papid> P99-1046 </papid>or adaptive language models (beeferman et al, 1999).</prevsent>
</prevsection>
<citsent citstr=" J97-1005 ">
other algorithms exploit variety of linguistic features that may mark topic boundaries, such as referential noun phrases (pas sonneau and litman, 1997).<papid> J97-1005 </papid>in work on segmentation of spoken documents, into national, prosodic, and acoustic indicators are used to detect topic boundaries (grosz and hirschberg, 1992; nakatani et al, 1995; hirschberg and nakatani, 1996; <papid> P96-1038 </papid>passonneau and litman, 1997; <papid> J97-1005 </papid>hirschberg and nakatani, 1998; beeferman et al, 1999; tur et al, 2001).<papid> J01-1002 </papid></citsent>
<aftsection>
<nextsent>such indicators include long pauses, shifts in speaking rate, great range in f0 and intensity, and higher maximum accent peak.these approaches use different learning mechanisms to combine features, including decision trees(grosz and hirschberg, 1992; passonneau and litman, 1997; <papid> J97-1005 </papid>tur et al, 2001) <papid> J01-1002 </papid>exponential models(beeferman et al, 1999) or other probabilistic models (hajime et al, 1998; reynar, 1999).<papid> P99-1046 </papid></nextsent>
<nextsent>we have evaluated our segmenter on the icsi meeting corpus (janin et al, 2003).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4172">
<title id=" P03-1071.xml">discourse segmentation of multiparty conversation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>on the one hand, many algorithms exploit the fact that topic segments tend to be lexically cohesive.
</prevsent>
<prevsent>embodiments of this idea include semantic similarity (mor ris and hirst, 1991; <papid> J91-1002 </papid>kozima, 1993), <papid> P93-1041 </papid>cosine similarity in word vector space (hearst, 1994), <papid> P94-1002 </papid>inter-sentencesimilarity matrix (reynar, 1994; <papid> P94-1050 </papid>choi, 2000), <papid> A00-2004 </papid>entity repetition (kan et al, 1998), <papid> W98-1123 </papid>word frequency models (reynar, 1999), <papid> P99-1046 </papid>or adaptive language models (beeferman et al, 1999).</prevsent>
</prevsection>
<citsent citstr=" P96-1038 ">
other algorithms exploit variety of linguistic features that may mark topic boundaries, such as referential noun phrases (pas sonneau and litman, 1997).<papid> J97-1005 </papid>in work on segmentation of spoken documents, into national, prosodic, and acoustic indicators are used to detect topic boundaries (grosz and hirschberg, 1992; nakatani et al, 1995; hirschberg and nakatani, 1996; <papid> P96-1038 </papid>passonneau and litman, 1997; <papid> J97-1005 </papid>hirschberg and nakatani, 1998; beeferman et al, 1999; tur et al, 2001).<papid> J01-1002 </papid></citsent>
<aftsection>
<nextsent>such indicators include long pauses, shifts in speaking rate, great range in f0 and intensity, and higher maximum accent peak.these approaches use different learning mechanisms to combine features, including decision trees(grosz and hirschberg, 1992; passonneau and litman, 1997; <papid> J97-1005 </papid>tur et al, 2001) <papid> J01-1002 </papid>exponential models(beeferman et al, 1999) or other probabilistic models (hajime et al, 1998; reynar, 1999).<papid> P99-1046 </papid></nextsent>
<nextsent>we have evaluated our segmenter on the icsi meeting corpus (janin et al, 2003).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4174">
<title id=" P03-1071.xml">discourse segmentation of multiparty conversation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>on the one hand, many algorithms exploit the fact that topic segments tend to be lexically cohesive.
</prevsent>
<prevsent>embodiments of this idea include semantic similarity (mor ris and hirst, 1991; <papid> J91-1002 </papid>kozima, 1993), <papid> P93-1041 </papid>cosine similarity in word vector space (hearst, 1994), <papid> P94-1002 </papid>inter-sentencesimilarity matrix (reynar, 1994; <papid> P94-1050 </papid>choi, 2000), <papid> A00-2004 </papid>entity repetition (kan et al, 1998), <papid> W98-1123 </papid>word frequency models (reynar, 1999), <papid> P99-1046 </papid>or adaptive language models (beeferman et al, 1999).</prevsent>
</prevsection>
<citsent citstr=" J01-1002 ">
other algorithms exploit variety of linguistic features that may mark topic boundaries, such as referential noun phrases (pas sonneau and litman, 1997).<papid> J97-1005 </papid>in work on segmentation of spoken documents, into national, prosodic, and acoustic indicators are used to detect topic boundaries (grosz and hirschberg, 1992; nakatani et al, 1995; hirschberg and nakatani, 1996; <papid> P96-1038 </papid>passonneau and litman, 1997; <papid> J97-1005 </papid>hirschberg and nakatani, 1998; beeferman et al, 1999; tur et al, 2001).<papid> J01-1002 </papid></citsent>
<aftsection>
<nextsent>such indicators include long pauses, shifts in speaking rate, great range in f0 and intensity, and higher maximum accent peak.these approaches use different learning mechanisms to combine features, including decision trees(grosz and hirschberg, 1992; passonneau and litman, 1997; <papid> J97-1005 </papid>tur et al, 2001) <papid> J01-1002 </papid>exponential models(beeferman et al, 1999) or other probabilistic models (hajime et al, 1998; reynar, 1999).<papid> P99-1046 </papid></nextsent>
<nextsent>we have evaluated our segmenter on the icsi meeting corpus (janin et al, 2003).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4179">
<title id=" P03-1071.xml">discourse segmentation of multiparty conversation </title>
<section> the icsi meeting corpus.  </section>
<citcontext>
<prevsection>
<prevsent>from the corpus, we selected 25 meetings to be segmented, each by at least three subjects.
</prevsent>
<prevsent>we opted for linear representation of discourse, since finer-grained discourse structures (e.g.
</prevsent>
</prevsection>
<citsent citstr=" J86-3001 ">
(grosz andsidner, 1986)) <papid> J86-3001 </papid>are generally considered to be difficult to mark reliably.</citsent>
<aftsection>
<nextsent>subjects were asked to mark each speaker change (potential boundary) as either boundary or non-boundary.
</nextsent>
<nextsent>in the resulting annotation, the agreed segmentation based on majority 1while it would be desirable to have broader variety of meetings, we hope that experiments on this corpus will still carry some generality.opinion contained 7.5 segments per meeting on average, while the average number of potential boundaries is 770.
</nextsent>
<nextsent>we used cochrans (1950) to evaluate the agreement among annotators.
</nextsent>
<nextsent>cochrans test evaluates the null hypothesis that the number of subjects assigning boundary at any position is randomly distributed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4183">
<title id=" P03-1071.xml">discourse segmentation of multiparty conversation </title>
<section> segmentation based on lexical cohesion.  </section>
<citcontext>
<prevsection>
<prevsent>lcseg computes lexical chains, which are thought to mirror the discourse structure of the underlying text (morris and hirst, 1991).<papid> J91-1002 </papid></prevsent>
<prevsent>we ignore synonymy and other semantic relations, building restricted model of lexical chains consisting of simple term repetitions, hypothesizing that major topic shifts are likely to occur where strong term repetitions start and end.</prevsent>
</prevsection>
<citsent citstr=" P01-1064 ">
while other relations between lexical items also work as cohesive factors (e.g. between term and its super-ordinate), the work on linear topic segmentation reporting the most promising results account for term repetitions alone (choi, 2000; <papid> A00-2004 </papid>utiyama and isahara, 2001).<papid> P01-1064 </papid></citsent>
<aftsection>
<nextsent>the preprocessing steps of lcseg are common to many segmentation algorithms.
</nextsent>
<nextsent>the input document is first tokenized, non-content words are removed, 2four other meetings failed short the significance test, while there was little agreement on the two last ones (p   0.1).and remaining words are stemmed using an extension of porters stemming algorithm (xu and croft, 1998) that conflates stems using corpus statistics.stemming will allow our algorithm to more accurately relate terms that are semantically close.
</nextsent>
<nextsent>the core algorithm of lcseg has two main parts:a method to identify and weight strong term repetitions using lexical chains, and method to hypothesize topic boundaries given the knowledge of multiple, simultaneous chains of term repetitions.
</nextsent>
<nextsent>a term is any stemmed content word within the text.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4192">
<title id=" P03-1071.xml">discourse segmentation of multiparty conversation </title>
<section> segmentation based on lexical cohesion.  </section>
<citcontext>
<prevsection>
<prevsent>we use the error metric pk proposed by beeferman et al(1999) to evaluate segmentation accuracy.
</prevsent>
<prevsent>it computes the probability that sentences units (e.g. sentences) apart are incorrectly determined as being either in different segments or in the same one.
</prevsent>
</prevsection>
<citsent citstr=" J02-1002 ">
since it has been argued in (pevzner and hearst, 2002) <papid> J02-1002 </papid>thatpk has some weaknesses, we also include results according to the window diff (wd) metric (which is described in the same work).</citsent>
<aftsection>
<nextsent>a test corpus of concatenated6 texts extracted from the brown corpus was built by choi (2000)<papid> A00-2004 </papid>to evaluate several domain-independent segmentation algorithms.</nextsent>
<nextsent>we reuse the same test corpus for our evaluation, in addition to two other test corpora we constructed to test how segment ers scale across genres and how they perform with texts with various6concatenated documents correspond to reference seg ments.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4198">
<title id=" P03-1071.xml">discourse segmentation of multiparty conversation </title>
<section> feature-based segmentation.  </section>
<citcontext>
<prevsection>
<prevsent>we selected terms whose 2 value rejected the hypothesis under 0.01-level confidence (the rejection criterion is 2 ? 6.635).
</prevsent>
<prevsent>finally, induced cue phrases whose usage has never been described in other work were removed (marked with ? in table 3).
</prevsent>
</prevsection>
<citsent citstr=" P95-1015 ">
indeed, there is risk that the automatically derived list of cue phrases could be too specific to the word usage in 9as in (litman and passonneau, 1995), <papid> P95-1015 </papid>we restrict ourselves to the first lexical item of any utterance, plus the second one if the first item is also cue word.</citsent>
<aftsection>
<nextsent>near boundary distant okay 64 740 other 657 25896 table 2: okay (2 = 89.11, df = 1,   0.01).
</nextsent>
<nextsent>okay 93.05 but 13.57 shall ? 27.34 so 11.65 anyway 23.95 and 10.99 were ? 17.67 should ? 10.21 alright 16.09 good ? 7.70 lets ? 14.54 table 3: automatically selected cue phrases.
</nextsent>
<nextsent>these meetings.silences: previous work has found that major shifts in topic typically show longer silences (passonneau and litman, 1993; <papid> P93-1020 </papid>hirschberg and nakatani, 1996).<papid> P96-1038 </papid></nextsent>
<nextsent>we investigated the presence of silences in meetings and their correlation with topic boundaries, and found it necessary to make distinction between pauses and gaps (levinson, 1983).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4199">
<title id=" P03-1071.xml">discourse segmentation of multiparty conversation </title>
<section> feature-based segmentation.  </section>
<citcontext>
<prevsection>
<prevsent>near boundary distant okay 64 740 other 657 25896 table 2: okay (2 = 89.11, df = 1,   0.01).
</prevsent>
<prevsent>okay 93.05 but 13.57 shall ? 27.34 so 11.65 anyway 23.95 and 10.99 were ? 17.67 should ? 10.21 alright 16.09 good ? 7.70 lets ? 14.54 table 3: automatically selected cue phrases.
</prevsent>
</prevsection>
<citsent citstr=" P93-1020 ">
these meetings.silences: previous work has found that major shifts in topic typically show longer silences (passonneau and litman, 1993; <papid> P93-1020 </papid>hirschberg and nakatani, 1996).<papid> P96-1038 </papid></citsent>
<aftsection>
<nextsent>we investigated the presence of silences in meetings and their correlation with topic boundaries, and found it necessary to make distinction between pauses and gaps (levinson, 1983).
</nextsent>
<nextsent>a pause is silence that is attributable to given party, for example in the middle of an adjacency pair, or when speaker pauses in the middle of her speech.
</nextsent>
<nextsent>gaps are silences not attributable to any party, and last until speaker takes the initiative of continuing the discussion.
</nextsent>
<nextsent>as an approximation of this distinction, we classified silence that follows question or in the middle of somebodys speech as pause, andany other silences as gap.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4203">
<title id=" P04-1016.xml">convolution kernels with feature selection for natural language processing tasks </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>over the past few years, many machine learning methods have been successfully applied totasks in natural language processing (nlp).
</prevsent>
<prevsent>especially, state-of-the-art performance can be achieved with kernel methods, such as support vector machine (cortes and vapnik, 1995).
</prevsent>
</prevsection>
<citsent citstr=" W02-2016 ">
examples include text categorization (joachims, 1998),chunking (kudo and matsumoto, 2002) <papid> W02-2016 </papid>and parsing (collins and duffy, 2001).</citsent>
<aftsection>
<nextsent>another feature of this kernel methodology is that it not only provides high accuracy but also allows us to design kernel function suited to modeling the task at hand.
</nextsent>
<nextsent>since natural language data take theform of sequences of words, and are generally analyzed using discrete structures, such as trees (parsedtrees) and graphs (relational graphs), discrete kernels, such as sequence kernels (lodhi et al, 2002), tree kernels (collins and duffy, 2001), and graph kernels (suzuki et al, 2003<papid> P03-1005 </papid>a), have been shown to offer excellent results.</nextsent>
<nextsent>these discrete kernels are related to convolution kernels (haussler, 1999), which provides the concept of kernels over discrete structures.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4204">
<title id=" P04-1016.xml">convolution kernels with feature selection for natural language processing tasks </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>examples include text categorization (joachims, 1998),chunking (kudo and matsumoto, 2002) <papid> W02-2016 </papid>and parsing (collins and duffy, 2001).</prevsent>
<prevsent>another feature of this kernel methodology is that it not only provides high accuracy but also allows us to design kernel function suited to modeling the task at hand.</prevsent>
</prevsection>
<citsent citstr=" P03-1005 ">
since natural language data take theform of sequences of words, and are generally analyzed using discrete structures, such as trees (parsedtrees) and graphs (relational graphs), discrete kernels, such as sequence kernels (lodhi et al, 2002), tree kernels (collins and duffy, 2001), and graph kernels (suzuki et al, 2003<papid> P03-1005 </papid>a), have been shown to offer excellent results.</citsent>
<aftsection>
<nextsent>these discrete kernels are related to convolution kernels (haussler, 1999), which provides the concept of kernels over discrete structures.
</nextsent>
<nextsent>convolution kernels allow us to treat structural features without explicitly representing the feature vectors from the input object.
</nextsent>
<nextsent>that is, convolution kernels are well suited to nlp tasks in terms of both accuracy and concept.
</nextsent>
<nextsent>unfortunately, experiments have shown that in some cases there is critical issue with convolution kernels, especially in nlp tasks (collins and duffy, 2001; cancedda et al, 2003; suzuki et al, 2003<papid> P03-1005 </papid>b).that is, the over-fitting problem arises if large sub structures?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4212">
<title id=" P04-1016.xml">convolution kernels with feature selection for natural language processing tasks </title>
<section> proposed feature selection method.  </section>
<citcontext>
<prevsection>
<prevsent>second, according to equations (10) to (18), the proposed method can be embedded in an original kernel calculation process, which allows us to use the same calculation procedure as the conventional methods.
</prevsent>
<prevsent>the only difference between the original sequence kernels and the proposed method is thatthe latter calculates statistical metric 2(u) by using sub-structure mining algorithm in the kernel calculation.third, although the kernel calculation, which unifies our proposed method, requires longer training time because of the feature selection, these lected sub-sequences have trie data structure.
</prevsent>
</prevsection>
<citsent citstr=" P03-1004 ">
this means fast calculation technique proposed in (kudo and matsumoto, 2003) <papid> P03-1004 </papid>can be simply applied to our method, which yields classification veryquickly.</citsent>
<aftsection>
<nextsent>in the classification part, the features (sub sequences) selected in the learning part must be known.
</nextsent>
<nextsent>therefore, we store the trie of selected sub-sequences and use them during classification.
</nextsent>
<nextsent>convolution kernels we have insufficient space to discuss this subject in detail in relation to other convolution kernels.
</nextsent>
<nextsent>however, our proposals can be easily applied to tree kernels (collins and duffy, 2001) by using string encoding for trees.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4217">
<title id=" P04-1016.xml">convolution kernels with feature selection for natural language processing tasks </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>6.1 question classification.
</prevsent>
<prevsent>question classification is defined as task similar to text categorization; it maps given question into question type.
</prevsent>
</prevsection>
<citsent citstr=" C02-1150 ">
we evaluated the performance by using data provided by (li and roth, 2002) <papid> C02-1150 </papid>for english and (suzuki et al, 2003<papid> P03-1005 </papid>b) for japanese question classification and followed the experimental setting used in these papers; namely we use four typical question types, location, numex, organization, and time top for jqa, and coarse?</citsent>
<aftsection>
<nextsent>and fine?
</nextsent>
<nextsent>classes for eqc.
</nextsent>
<nextsent>we used the one-vs-rest classifier of svm as the multi-class classification method for eqc.figure 4 shows examples of the question classification data used here.
</nextsent>
<nextsent>question types input object : word sequences ([ ]: information of chunk and ? ?: named entity) abbreviation what,[b-np] be,[b-vp] the,[b-np] abbreviation,[i-np] for,[b-pp] texas,[b-np],b-gpe?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4222">
<title id=" N12-1093.xml">unsupervised concepttotext generation with hypergraphs </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>traditionally, these components are hand-engineered in order to generate high quality text, however at the expense of portability and scalability.
</prevsent>
<prevsent>it is thus no surprise that recent years have witnessed growing interest in automatic methods for creating trainable generation components.
</prevsent>
</prevsection>
<citsent citstr=" H05-1042 ">
examples include learning which database records should be present in text (duboue and mckeown, 2002; barzilay and lapata, 2005) <papid> H05-1042 </papid>and how these should be verbalized (liang et al ,2009).</citsent>
<aftsection>
<nextsent>besides concentrating on isolated components, few approaches have emerged that tackle concept-to-text generation end-to-end.
</nextsent>
<nextsent>due to the complexity of the task, most models simplify the generation process, e.g., by creating output that consists of few sentences, thus obviating the need for document planning, or by treating sentence planning and surface realization as one component.
</nextsent>
<nextsent>a common modeling strategy is to break up the generation process into sequence of local decisions, each learned separately (reiter et al , 2005; belz, 2008; chen and mooney, 2008; angeli et al , 2010; <papid> D10-1049 </papid>kim and mooney, 2010).<papid> C10-2062 </papid>in this paper we describe an end-to-end generation model that performs content selection and surface realization jointly.</nextsent>
<nextsent>given corpus of database records and textual descriptions (for some of them), we define probabilistic context-free grammar (pcfg) that captures the structure of the database and how it can be rendered into natural 752 flight from to phoenix new york search type what query flight day day dep/ar sunday departure list flights from phoenix to new york on sunday temperature time min mean max 06:00-21:00 9 15 21 wind speed time min mean max 06:00-21:00 15 20 30 cloud sky cover time percent (%) 06:00-09:00 25-50 09:00-12:00 50-75 wind direction time mode 06:00-21:00 cloudy, with low around 10.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4223">
<title id=" N12-1093.xml">unsupervised concepttotext generation with hypergraphs </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>besides concentrating on isolated components, few approaches have emerged that tackle concept-to-text generation end-to-end.
</prevsent>
<prevsent>due to the complexity of the task, most models simplify the generation process, e.g., by creating output that consists of few sentences, thus obviating the need for document planning, or by treating sentence planning and surface realization as one component.
</prevsent>
</prevsection>
<citsent citstr=" D10-1049 ">
a common modeling strategy is to break up the generation process into sequence of local decisions, each learned separately (reiter et al , 2005; belz, 2008; chen and mooney, 2008; angeli et al , 2010; <papid> D10-1049 </papid>kim and mooney, 2010).<papid> C10-2062 </papid>in this paper we describe an end-to-end generation model that performs content selection and surface realization jointly.</citsent>
<aftsection>
<nextsent>given corpus of database records and textual descriptions (for some of them), we define probabilistic context-free grammar (pcfg) that captures the structure of the database and how it can be rendered into natural 752 flight from to phoenix new york search type what query flight day day dep/ar sunday departure list flights from phoenix to new york on sunday temperature time min mean max 06:00-21:00 9 15 21 wind speed time min mean max 06:00-21:00 15 20 30 cloud sky cover time percent (%) 06:00-09:00 25-50 09:00-12:00 50-75 wind direction time mode 06:00-21:00 cloudy, with low around 10.
</nextsent>
<nextsent>south wind around 20 mph.
</nextsent>
<nextsent>pass from to pink3 pink7 bad pass from to pink7 purple3 turn over from to pink7 purple3 pink3 passes the ball to pink7 (b)(a) (c) figure 1: input-output examples for (a) query generation in the air travel domain, (b) weather forecast generation, and (c) sportscasting.
</nextsent>
<nextsent>language.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4225">
<title id=" N12-1093.xml">unsupervised concepttotext generation with hypergraphs </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>besides concentrating on isolated components, few approaches have emerged that tackle concept-to-text generation end-to-end.
</prevsent>
<prevsent>due to the complexity of the task, most models simplify the generation process, e.g., by creating output that consists of few sentences, thus obviating the need for document planning, or by treating sentence planning and surface realization as one component.
</prevsent>
</prevsection>
<citsent citstr=" C10-2062 ">
a common modeling strategy is to break up the generation process into sequence of local decisions, each learned separately (reiter et al , 2005; belz, 2008; chen and mooney, 2008; angeli et al , 2010; <papid> D10-1049 </papid>kim and mooney, 2010).<papid> C10-2062 </papid>in this paper we describe an end-to-end generation model that performs content selection and surface realization jointly.</citsent>
<aftsection>
<nextsent>given corpus of database records and textual descriptions (for some of them), we define probabilistic context-free grammar (pcfg) that captures the structure of the database and how it can be rendered into natural 752 flight from to phoenix new york search type what query flight day day dep/ar sunday departure list flights from phoenix to new york on sunday temperature time min mean max 06:00-21:00 9 15 21 wind speed time min mean max 06:00-21:00 15 20 30 cloud sky cover time percent (%) 06:00-09:00 25-50 09:00-12:00 50-75 wind direction time mode 06:00-21:00 cloudy, with low around 10.
</nextsent>
<nextsent>south wind around 20 mph.
</nextsent>
<nextsent>pass from to pink3 pink7 bad pass from to pink7 purple3 turn over from to pink7 purple3 pink3 passes the ball to pink7 (b)(a) (c) figure 1: input-output examples for (a) query generation in the air travel domain, (b) weather forecast generation, and (c) sportscasting.
</nextsent>
<nextsent>language.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4227">
<title id=" N12-1093.xml">unsupervised concepttotext generation with hypergraphs </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this grammar represents set of trees which we encode compactly using weighted hypergraph (or packed forest), data structure that defines probability (or weight) for each tree.
</prevsent>
<prevsent>generation then boils down to finding the best derivation tree in the hypergraph which can be done efficiently using the viterbi algorithm.
</prevsent>
</prevsection>
<citsent citstr=" P07-1019 ">
in order to ensure that our generation output is fluent, we intersect our grammar with language model and perform decoding using dynamic programming algorithm (huang and chiang, 2007).<papid> P07-1019 </papid></citsent>
<aftsection>
<nextsent>our model is conceptually simpler than previous approaches and encodes information about the do main and its structure globally, by considering the input space simultaneously during generation.
</nextsent>
<nextsent>our only assumption is that the input must be set of records essentially corresponding to database-like tables whose columns describe fields of certaintype.
</nextsent>
<nextsent>experimental evaluation on three domains obtains results competitive to the state of the art with out using any domain specific constraints, explicit feature engineering or labeled data.
</nextsent>
<nextsent>our work is situated within the broader class ofdata-driven approaches to content selection and surface realization.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4237">
<title id=" N12-1093.xml">unsupervised concepttotext generation with hypergraphs </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>a few approaches have emerged more recently that combine content selection and surface realization.
</prevsent>
<prevsent>kim and mooney (2010) <papid> C10-2062 </papid>adopt two-stage ap proach: using generative model similar to liang etal.</prevsent>
</prevsection>
<citsent citstr=" N07-1022 ">
(2009), they first decide what to say and then verbalize the selected input with wasp1, an existing generation system (wong and mooney, 2007).<papid> N07-1022 </papid></citsent>
<aftsection>
<nextsent>in contrast, angeli et al  (2010) <papid> D10-1049 </papid>propose unified content selection and surface realization model which also operates over the alignment output produced by liang et al  (2009).</nextsent>
<nextsent>their model decomposes into sequence of discriminative local decisions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4242">
<title id=" N12-1093.xml">unsupervised concepttotext generation with hypergraphs </title>
<section> problem formulation.  </section>
<citcontext>
<prevsection>
<prevsent>our goal then is to reduce the tasks of content selection and surface realization into common probabilistic parsing problem.
</prevsent>
<prevsent>we do this by abstracting the structure of the database (and accompanying texts) intoa pcfg whose probabilities are learned from training data.1 specifically, we convert the database into rewrite rules and represent them as weighted directed hypergraph (gallo et al , 1993).
</prevsent>
</prevsection>
<citsent citstr=" D09-1005 ">
instead of learning the probabilities on the pcfg, we directly compute the weights on the hyper arcs using dynamic program similar to the inside-outside algorithm (li and eisner, 2009).<papid> D09-1005 </papid></citsent>
<aftsection>
<nextsent>during testing, we are given set of database records without the corresponding text.
</nextsent>
<nextsent>using the trained grammar we compile hypergraph specific to this test input and decode it approximately via cube pruning (chiang, 2007).<papid> J07-2003 </papid>the choice of the hypergraph framework is motivated by at least three reasons.</nextsent>
<nextsent>firstly, hypergraphs can be used to represent the search space of most parsers (klein and manning, 2001).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4244">
<title id=" N12-1093.xml">unsupervised concepttotext generation with hypergraphs </title>
<section> problem formulation.  </section>
<citcontext>
<prevsection>
<prevsent>instead of learning the probabilities on the pcfg, we directly compute the weights on the hyper arcs using dynamic program similar to the inside-outside algorithm (li and eisner, 2009).<papid> D09-1005 </papid></prevsent>
<prevsent>during testing, we are given set of database records without the corresponding text.</prevsent>
</prevsection>
<citsent citstr=" J07-2003 ">
using the trained grammar we compile hypergraph specific to this test input and decode it approximately via cube pruning (chiang, 2007).<papid> J07-2003 </papid>the choice of the hypergraph framework is motivated by at least three reasons.</citsent>
<aftsection>
<nextsent>firstly, hypergraphs can be used to represent the search space of most parsers (klein and manning, 2001).
</nextsent>
<nextsent>secondly, they are more efficient and faster than the common cyk parser-based representation for pcfgs by factor of more than ten (huang and chiang, 2007).<papid> P07-1019 </papid></nextsent>
<nextsent>and thirdly, the hypergraph representation allows us to integrate an n-gram language model and perform decoding efficiently using k-best viterbi search, optimizing what to say and how to say at the same time.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4254">
<title id=" N12-1093.xml">unsupervised concepttotext generation with hypergraphs </title>
<section> problem formulation.  </section>
<citcontext>
<prevsection>
<prevsent>theinside-outside algorithm is commonly used for estimating the weights of pcfg.
</prevsent>
<prevsent>however, we first transform the cyk parser and our grammar into hypergraph and then compute the weights using inside-outside.
</prevsent>
</prevsection>
<citsent citstr=" W05-1506 ">
huang and chiang (2005) <papid> W05-1506 </papid>define weighted directed hypergraph as follows: definition 1 an ordered hypergraph is tuple n,e, t,r?, where is finite set of nodes, is finite set of hyper arcs and is the set of weights.</citsent>
<aftsection>
<nextsent>each hyper arc ? is triple = (e),h(e), (e)?, where h(e) ? is its head node,t (e) ? n? is set of tail nodes and (e) is monotonic weight function r|t (e)| to and ? is target node.
</nextsent>
<nextsent>definition 2 we impose the arity of hyper arc to be |e| = |t (e)| = 2, in other words, each head node is connected with at most two tail nodes.
</nextsent>
<nextsent>given context-free grammar = n,t,p,s?(where is the set of variables, the set of terminals, the set of production rules, and ? the start symbol) and an input string w, we can map the standard weighted cyk algorithm to hypergraph as follows.
</nextsent>
<nextsent>each node [a, i, j] in the hypergraph corresponds to non-terminal spanning words wi to j of the input.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4270">
<title id=" N12-1093.xml">unsupervised concepttotext generation with hypergraphs </title>
<section> experimental design.  </section>
<citcontext>
<prevsection>
<prevsent>we used 25,000 scenarios from weather gov for training, 1,000 scenarios for development and 3,528 scenarios for testing.
</prevsent>
<prevsent>this is the same partition used in angeli et al  (2010).<papid> D10-1049 </papid></prevsent>
</prevsection>
<citsent citstr=" H94-1010 ">
for the air travel domain we used the atis dataset(dahl et al , 1994), <papid> H94-1010 </papid>consisting of 5,426 scenarios.</citsent>
<aftsection>
<nextsent>these are transcriptions of spontaneous utterances of users interacting with hypothetical on 757 weather gov atis robocup1 e t near 57.
</nextsent>
<nextsent>near 57.
</nextsent>
<nextsent>near 57.
</nextsent>
<nextsent>near 57.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4271">
<title id=" N12-1093.xml">unsupervised concepttotext generation with hypergraphs </title>
<section> experimental design.  </section>
<citcontext>
<prevsection>
<prevsent>list flights from denver to phoenix pink9 passes back to pink7 table 2: system output on weather gov, atis, and robocup (1-best, k-best, angeli) and corresponding human-authored text (human).
</prevsent>
<prevsent>line flight booking system.
</prevsent>
</prevsection>
<citsent citstr=" D07-1071 ">
we used the dataset introduced in zettlemoyer and collins (2007)<papid> D07-1071 </papid>4 and automatically converted their lambda-calculus expressions to attribute-value pairs following the conventions adopted by liang et al  (2009).</citsent>
<aftsection>
<nextsent>forex ample, the scenario in figure 1(a) was initially represented as: x. light(x) ? rom(x, phoenix) ? to(x,new york)day(x,sunday).5 in contrast to thetwo previous datasets, atis has much richer vocabulary (927 words); each scenario corresponds to single sentence (average length is 11.2 words)with 2.65 out of 19 record types mentioned on average.
</nextsent>
<nextsent>following zettlemoyer and collins (2007)<papid> D07-1071 </papid>, we trained on 4,962 scenarios and tested on atis nov93 which contains 448 examples.model parameters our model has two parameters, namely the number of grammar derivations considered by the decoder and the order of the language model.</nextsent>
<nextsent>we tuned experimentally on held-out data taken from weather gov, robocup, and atis, respectively.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4277">
<title id=" N12-1093.xml">unsupervised concepttotext generation with hypergraphs </title>
<section> experimental design.  </section>
<citcontext>
<prevsection>
<prevsent>for weather gov and atis, we used trigram language model.system comparison we evaluated two configurations of our system.
</prevsent>
<prevsent>a baseline that uses the top scoring derivation in each sub generation (1-best) and another version which makes better use of our decoding algorithm and considers the best derivations (i.e., 15 for weather gov, 40 for atis, and25 for robocup).
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
we compared our output to angeli et al  (2010) <papid> D10-1049 </papid>whose approach is closest to ours and state-of-the-art on the weather gov domain.for robocup, we also compare against the best published results (kim and mooney, 2010).<papid> C10-2062 </papid>evaluation we evaluated system output automatically, using the bleu modified precision score (papineni et al , 2002) <papid> P02-1040 </papid>with the human-written textas reference.</citsent>
<aftsection>
<nextsent>in addition, we evaluated the generated text by eliciting human judgments.
</nextsent>
<nextsent>participants were presented with scenario and its corresponding verbal ization and were asked to rate the latter along two dimensions: fluency (is the text grammatical and overall understandable?)
</nextsent>
<nextsent>and semantic correctness (does the meaning conveyed by the text correspond to the database input?).
</nextsent>
<nextsent>the subjects used five point rating scale where high number indicates better performance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4289">
<title id=" N12-1093.xml">unsupervised concepttotext generation with hypergraphs </title>
<section> conclusions.  </section>
<citcontext>
<prevsection>
<prevsent>we argue that our approach is computationally efficient and viable in practical applications.
</prevsent>
<prevsent>porting the system to different domain is straightforward, assuming database and corresponding (unaligned) text.as long as the database is compatible with the structure of the grammar in table 1, we need only retrain to obtain the weights on the hyper arcs and domain specific language model.our model takes into account the k-best derivations at decoding time, however inspection of these shows that it often fails to select the best one.
</prevsent>
</prevsection>
<citsent citstr=" P08-1067 ">
in the future, we plan to remedy this by using forest reranking, technique that approximately reranks packed forest of exponentially many derivations (huang, 2008).<papid> P08-1067 </papid></citsent>
<aftsection>
<nextsent>we would also like to scale our model to more challenging domains (e.g., product descriptions) and to enrich our generator with some notion of discourse planning.
</nextsent>
<nextsent>an interesting question is how to extend the pcfg-based approach advocated here so as to capture discourse-level document structure.
</nextsent>
<nextsent>acknowledgments we are grateful to percy liang and gabor angeli for providing us with their codeand data.
</nextsent>
<nextsent>we would also like to thank luke zettlemoyer and tom kwiatkowski for sharing their atis dataset with us and frank keller for his feedback on an earlier version of this paper.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4290">
<title id=" P01-1061.xml">computational properties of environment based disambiguation </title>
<section> sharing referents across.  </section>
<citcontext>
<prevsection>
<prevsent>these shared syntactic structures can further be associated with compositional semantic functions that correspond to the syntactic elements in the forest, to create shared forest of trees each representing complete expression in some logical form.
</prevsent>
<prevsent>this extended sharing is similar to the packing?
</prevsent>
</prevsection>
<citsent citstr=" C90-3045 ">
approach employed in the core language engine (alshawi, 1992), except thatthe cle relies on quasi-logical form to under specify semantic information such as quantifier scope (the calculation of which is deferred until syntactic ambiguities have been at least partially resolved by other means); whereas the approach described here extends structure sharing to incorporate certain amount of quantifier scope ambiguity in order to allow complete evaluation of all sub derivations in shared forest before making any disambiguation decisions in syntax.3 various synchronous formalisms have been introduced for associating syntactic representations with logical functions in isomorphicor locally non-isomorphic derivations, including categorial grammars (cgs) (wood, 1993), synchronous tree adjoining grammars (tags) (joshi, 1985; shieber and schabes, 1990; <papid> C90-3045 </papid>shieber,1994), and synchronous description tree grammars (dtgs) (rambow et al, 1995; <papid> P95-1021 </papid>rambow ands atta, 1996).<papid> P96-1016 </papid></citsent>
<aftsection>
<nextsent>most of these formalisms can be extended to define semantic associations over entire shared forests, rather than merely over individual parse trees, in straightforward manner, preserving the ambiguity of the syntactic forest without exceeding its polynomial size, or the polynomial time complexity of creating or traversing it.
</nextsent>
<nextsent>since one of the goals of this architecture isto use the systems representation of its environment to resolve ambiguity in its instructions, space-efficient shared forest of logical functions will not be enough.
</nextsent>
<nextsent>the system must also be ableto efficiently calculate the sets of potential referents in the environment for every sub expression in this forest.
</nextsent>
<nextsent>fortunately, since the logical function forest shares structure between alternative analyses, many of the sets of potential referents can be shared between analyses during evaluation as well.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4291">
<title id=" P01-1061.xml">computational properties of environment based disambiguation </title>
<section> sharing referents across.  </section>
<citcontext>
<prevsection>
<prevsent>these shared syntactic structures can further be associated with compositional semantic functions that correspond to the syntactic elements in the forest, to create shared forest of trees each representing complete expression in some logical form.
</prevsent>
<prevsent>this extended sharing is similar to the packing?
</prevsent>
</prevsection>
<citsent citstr=" P95-1021 ">
approach employed in the core language engine (alshawi, 1992), except thatthe cle relies on quasi-logical form to under specify semantic information such as quantifier scope (the calculation of which is deferred until syntactic ambiguities have been at least partially resolved by other means); whereas the approach described here extends structure sharing to incorporate certain amount of quantifier scope ambiguity in order to allow complete evaluation of all sub derivations in shared forest before making any disambiguation decisions in syntax.3 various synchronous formalisms have been introduced for associating syntactic representations with logical functions in isomorphicor locally non-isomorphic derivations, including categorial grammars (cgs) (wood, 1993), synchronous tree adjoining grammars (tags) (joshi, 1985; shieber and schabes, 1990; <papid> C90-3045 </papid>shieber,1994), and synchronous description tree grammars (dtgs) (rambow et al, 1995; <papid> P95-1021 </papid>rambow ands atta, 1996).<papid> P96-1016 </papid></citsent>
<aftsection>
<nextsent>most of these formalisms can be extended to define semantic associations over entire shared forests, rather than merely over individual parse trees, in straightforward manner, preserving the ambiguity of the syntactic forest without exceeding its polynomial size, or the polynomial time complexity of creating or traversing it.
</nextsent>
<nextsent>since one of the goals of this architecture isto use the systems representation of its environment to resolve ambiguity in its instructions, space-efficient shared forest of logical functions will not be enough.
</nextsent>
<nextsent>the system must also be ableto efficiently calculate the sets of potential referents in the environment for every sub expression in this forest.
</nextsent>
<nextsent>fortunately, since the logical function forest shares structure between alternative analyses, many of the sets of potential referents can be shared between analyses during evaluation as well.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4292">
<title id=" P01-1061.xml">computational properties of environment based disambiguation </title>
<section> sharing referents across.  </section>
<citcontext>
<prevsection>
<prevsent>these shared syntactic structures can further be associated with compositional semantic functions that correspond to the syntactic elements in the forest, to create shared forest of trees each representing complete expression in some logical form.
</prevsent>
<prevsent>this extended sharing is similar to the packing?
</prevsent>
</prevsection>
<citsent citstr=" P96-1016 ">
approach employed in the core language engine (alshawi, 1992), except thatthe cle relies on quasi-logical form to under specify semantic information such as quantifier scope (the calculation of which is deferred until syntactic ambiguities have been at least partially resolved by other means); whereas the approach described here extends structure sharing to incorporate certain amount of quantifier scope ambiguity in order to allow complete evaluation of all sub derivations in shared forest before making any disambiguation decisions in syntax.3 various synchronous formalisms have been introduced for associating syntactic representations with logical functions in isomorphicor locally non-isomorphic derivations, including categorial grammars (cgs) (wood, 1993), synchronous tree adjoining grammars (tags) (joshi, 1985; shieber and schabes, 1990; <papid> C90-3045 </papid>shieber,1994), and synchronous description tree grammars (dtgs) (rambow et al, 1995; <papid> P95-1021 </papid>rambow ands atta, 1996).<papid> P96-1016 </papid></citsent>
<aftsection>
<nextsent>most of these formalisms can be extended to define semantic associations over entire shared forests, rather than merely over individual parse trees, in straightforward manner, preserving the ambiguity of the syntactic forest without exceeding its polynomial size, or the polynomial time complexity of creating or traversing it.
</nextsent>
<nextsent>since one of the goals of this architecture isto use the systems representation of its environment to resolve ambiguity in its instructions, space-efficient shared forest of logical functions will not be enough.
</nextsent>
<nextsent>the system must also be ableto efficiently calculate the sets of potential referents in the environment for every sub expression in this forest.
</nextsent>
<nextsent>fortunately, since the logical function forest shares structure between alternative analyses, many of the sets of potential referents can be shared between analyses during evaluation as well.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4293">
<title id=" P03-2017.xml">towards interactive text understanding </title>
<section> mda: semantics-based document au-.  </section>
<citcontext>
<prevsection>
<prevsent>in section 4, we present current work on using mda for legacy-document normalization and show that this work can provide first approach to an itu implementation.
</prevsent>
<prevsent>in section 5, we indicate some links between these ideas and current work on interactive statistical mt (transtype), showing directions towards more efficient implementations of itu.
</prevsent>
</prevsection>
<citsent citstr=" W00-1404 ">
thoring system the mda (multilingual document authoring) system [brun et al 2000] <papid> W00-1404 </papid>is an instance (de scended from rantas grammatical framework [ranta 2002]) of text-mediated interactive natural language generation system, notion introduced by [power and scott 1998] <papid> P98-2173 </papid>under the name of wysiwym.</citsent>
<aftsection>
<nextsent>in such systems, an author gradually constructs semantic representation, but rather than accessing the evolving representation directly, she actually interacts with natural language text generated from the representation; some regions of the text are active, and correspond to still unspecified parts of the representa tion; they are associated with menus presenting collections of choices for extending the semantic representation; the choices are semantically explicit and the resulting representation contains no ambiguities.
</nextsent>
<nextsent>the author thus has the feeling of only interacting with text, while in fact she is building formal semantic object.
</nextsent>
<nextsent>one application of this approach is in multilingual authoring: the author interacts with text in her own language, but the internal representation can be used to generate reliable translations in other languages.
</nextsent>
<nextsent>fig.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4294">
<title id=" P03-2017.xml">towards interactive text understanding </title>
<section> mda: semantics-based document au-.  </section>
<citcontext>
<prevsection>
<prevsent>in section 4, we present current work on using mda for legacy-document normalization and show that this work can provide first approach to an itu implementation.
</prevsent>
<prevsent>in section 5, we indicate some links between these ideas and current work on interactive statistical mt (transtype), showing directions towards more efficient implementations of itu.
</prevsent>
</prevsection>
<citsent citstr=" P98-2173 ">
thoring system the mda (multilingual document authoring) system [brun et al 2000] <papid> W00-1404 </papid>is an instance (de scended from rantas grammatical framework [ranta 2002]) of text-mediated interactive natural language generation system, notion introduced by [power and scott 1998] <papid> P98-2173 </papid>under the name of wysiwym.</citsent>
<aftsection>
<nextsent>in such systems, an author gradually constructs semantic representation, but rather than accessing the evolving representation directly, she actually interacts with natural language text generated from the representation; some regions of the text are active, and correspond to still unspecified parts of the representa tion; they are associated with menus presenting collections of choices for extending the semantic representation; the choices are semantically explicit and the resulting representation contains no ambiguities.
</nextsent>
<nextsent>the author thus has the feeling of only interacting with text, while in fact she is building formal semantic object.
</nextsent>
<nextsent>one application of this approach is in multilingual authoring: the author interacts with text in her own language, but the internal representation can be used to generate reliable translations in other languages.
</nextsent>
<nextsent>fig.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4295">
<title id=" P03-2017.xml">towards interactive text understanding </title>
<section> towards statistical itu.  </section>
<citcontext>
<prevsection>
<prevsent>a way of solving these problems is to move towards more probabilistic approach that combines advantages of being built on accepted principles and of having well-developed learning theory.
</prevsent>
<prevsent>we finally turn our attention to existing work in this area that holds promise for improving itu.
</prevsent>
</prevsection>
<citsent citstr=" W02-1020 ">
recent research on the interactive statistical machine translation system trans type [foster et al  1997; foster et al  2002] <papid> W02-1020 </papid>holds special interest in relation to itu.</citsent>
<aftsection>
<nextsent>this system, outlined in fig.
</nextsent>
<nextsent>4, aims at helping translator type her (unconstrained) translation of source text by predicting sequences of characters that are likely to follow already typed characters in the target text; this prediction is done on the basis of information present in the source text.
</nextsent>
<nextsent>the approach is similar to standard statistical mt4, but instead of producing one single best translation, the system ranks several completion proposals according to probabilistic confidence measure and uses this measure to optimize the length of completions proposed to the translator for validation.
</nextsent>
<nextsent>evaluations of the first version of trans type have already shown significant gains in terms of the number of keystrokes needed for producing translation, and work is continuing for making the approach effective in real translation environments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4296">
<title id=" P03-2017.xml">towards interactive text understanding </title>
<section> towards statistical itu.  </section>
<citcontext>
<prevsection>
<prevsent>if we now compare fig.
</prevsent>
<prevsent>3 and fig.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
4, we see strong parallels between trans type and itu: language model enumerating word sequences vs 4 initially statistical mt used noisy-channel approach [brown et al  1993]; <papid> J93-2003 </papid>but recently [och and ney 2002] <papid> P02-1038 </papid>have introduced more general framework based on the maxi mum-entropy principle, which shows nice prospects in terms of flexibility and learnability.</citsent>
<aftsection>
<nextsent>an interesting research thread is to use more linguistic structure in statistical translation model [yamada and knight 2001], <papid> P01-1067 </papid>which has some relevance to itu since we need to handle structured semantic data.</nextsent>
<nextsent>grammar enumerating semantic structures, source text vs input text as information sources, match between source text and target text vs match between input text and semantic structure.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4297">
<title id=" P03-2017.xml">towards interactive text understanding </title>
<section> towards statistical itu.  </section>
<citcontext>
<prevsection>
<prevsent>if we now compare fig.
</prevsent>
<prevsent>3 and fig.
</prevsent>
</prevsection>
<citsent citstr=" P02-1038 ">
4, we see strong parallels between trans type and itu: language model enumerating word sequences vs 4 initially statistical mt used noisy-channel approach [brown et al  1993]; <papid> J93-2003 </papid>but recently [och and ney 2002] <papid> P02-1038 </papid>have introduced more general framework based on the maxi mum-entropy principle, which shows nice prospects in terms of flexibility and learnability.</citsent>
<aftsection>
<nextsent>an interesting research thread is to use more linguistic structure in statistical translation model [yamada and knight 2001], <papid> P01-1067 </papid>which has some relevance to itu since we need to handle structured semantic data.</nextsent>
<nextsent>grammar enumerating semantic structures, source text vs input text as information sources, match between source text and target text vs match between input text and semantic structure.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4298">
<title id=" P03-2017.xml">towards interactive text understanding </title>
<section> towards statistical itu.  </section>
<citcontext>
<prevsection>
<prevsent>3 and fig.
</prevsent>
<prevsent>4, we see strong parallels between trans type and itu: language model enumerating word sequences vs 4 initially statistical mt used noisy-channel approach [brown et al  1993]; <papid> J93-2003 </papid>but recently [och and ney 2002] <papid> P02-1038 </papid>have introduced more general framework based on the maxi mum-entropy principle, which shows nice prospects in terms of flexibility and learnability.</prevsent>
</prevsection>
<citsent citstr=" P01-1067 ">
an interesting research thread is to use more linguistic structure in statistical translation model [yamada and knight 2001], <papid> P01-1067 </papid>which has some relevance to itu since we need to handle structured semantic data.</citsent>
<aftsection>
<nextsent>grammar enumerating semantic structures, source text vs input text as information sources, match between source text and target text vs match between input text and semantic structure.
</nextsent>
<nextsent>in trans type the interaction is directly with the target text, while in itu the interaction with the semantic structure is mediated through an output text realization of that structure.
</nextsent>
<nextsent>we can thus hope to bring some of the techniques developed for trans type to itu, but let us note that some of the challenges are different: for instance training the semantic grammars in itu cannot be done on directly observable corpus of texts.5 fig.
</nextsent>
<nextsent>4: transtype.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4300">
<title id=" P03-2025.xml">bilingual terminology acquisition from comparable corpora and phrasal translation to cross language information retrieval </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>although, corpora have been an object of study ofsome decades, recent years saw an increased interest in their use and construction.
</prevsent>
<prevsent>with this increased interest and awareness has come an expansion in the application to knowledge acquisition, such as bilingual terminology.
</prevsent>
</prevsection>
<citsent citstr=" C02-1166 ">
in addition, non-aligned comparable corpora have been given special interest in bilingual terminology acquisition and lexical resources enrichment (dejean et al, 2002; <papid> C02-1166 </papid>fung, 2000; koehn and knight, 2002; <papid> W02-0902 </papid>rapp, 1999).<papid> P99-1067 </papid>this paper presents novel approach to bilingual terminology acquisition and disambiguation from scarce resources such as comparable corpora, phrasal translation through re-scoring techniques as well as evaluations on cross-language information retrieval (clir).</citsent>
<aftsection>
<nextsent>clir consists of retrieving documents written in one language using queries written in another language.
</nextsent>
<nextsent>an application is completed ona large-scale test collection, ntcir for japanese english language pair.
</nextsent>
<nextsent>clir figure 1 shows the overall design of the proposed translation model in clir consisting of three main parts as follows: - bilingual terminology acquisition from bi-directional comparable corpora, completed through two-stages term-by-term translation model.
</nextsent>
<nextsent>- linguistic-based pruning, which is applied on the extracted translation alternatives in order to filter and detect terms and their translations that are morphologically close enough, i.e., with close or similar part-of-speech tags.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4301">
<title id=" P03-2025.xml">bilingual terminology acquisition from comparable corpora and phrasal translation to cross language information retrieval </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>although, corpora have been an object of study ofsome decades, recent years saw an increased interest in their use and construction.
</prevsent>
<prevsent>with this increased interest and awareness has come an expansion in the application to knowledge acquisition, such as bilingual terminology.
</prevsent>
</prevsection>
<citsent citstr=" W02-0902 ">
in addition, non-aligned comparable corpora have been given special interest in bilingual terminology acquisition and lexical resources enrichment (dejean et al, 2002; <papid> C02-1166 </papid>fung, 2000; koehn and knight, 2002; <papid> W02-0902 </papid>rapp, 1999).<papid> P99-1067 </papid>this paper presents novel approach to bilingual terminology acquisition and disambiguation from scarce resources such as comparable corpora, phrasal translation through re-scoring techniques as well as evaluations on cross-language information retrieval (clir).</citsent>
<aftsection>
<nextsent>clir consists of retrieving documents written in one language using queries written in another language.
</nextsent>
<nextsent>an application is completed ona large-scale test collection, ntcir for japanese english language pair.
</nextsent>
<nextsent>clir figure 1 shows the overall design of the proposed translation model in clir consisting of three main parts as follows: - bilingual terminology acquisition from bi-directional comparable corpora, completed through two-stages term-by-term translation model.
</nextsent>
<nextsent>- linguistic-based pruning, which is applied on the extracted translation alternatives in order to filter and detect terms and their translations that are morphologically close enough, i.e., with close or similar part-of-speech tags.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4302">
<title id=" P03-2025.xml">bilingual terminology acquisition from comparable corpora and phrasal translation to cross language information retrieval </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>although, corpora have been an object of study ofsome decades, recent years saw an increased interest in their use and construction.
</prevsent>
<prevsent>with this increased interest and awareness has come an expansion in the application to knowledge acquisition, such as bilingual terminology.
</prevsent>
</prevsection>
<citsent citstr=" P99-1067 ">
in addition, non-aligned comparable corpora have been given special interest in bilingual terminology acquisition and lexical resources enrichment (dejean et al, 2002; <papid> C02-1166 </papid>fung, 2000; koehn and knight, 2002; <papid> W02-0902 </papid>rapp, 1999).<papid> P99-1067 </papid>this paper presents novel approach to bilingual terminology acquisition and disambiguation from scarce resources such as comparable corpora, phrasal translation through re-scoring techniques as well as evaluations on cross-language information retrieval (clir).</citsent>
<aftsection>
<nextsent>clir consists of retrieving documents written in one language using queries written in another language.
</nextsent>
<nextsent>an application is completed ona large-scale test collection, ntcir for japanese english language pair.
</nextsent>
<nextsent>clir figure 1 shows the overall design of the proposed translation model in clir consisting of three main parts as follows: - bilingual terminology acquisition from bi-directional comparable corpora, completed through two-stages term-by-term translation model.
</nextsent>
<nextsent>- linguistic-based pruning, which is applied on the extracted translation alternatives in order to filter and detect terms and their translations that are morphologically close enough, i.e., with close or similar part-of-speech tags.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4303">
<title id=" P03-2025.xml">bilingual terminology acquisition from comparable corpora and phrasal translation to cross language information retrieval </title>
<section> the proposed translation model in.  </section>
<citcontext>
<prevsection>
<prevsent>the proposed rescoring techniques are based on the world wide web (www), large-scale test collection such asntcir, the comparable corpora or possible interaction with the user, among others.finally, linear combination to bilingual dictionaries, bilingual thesauri and transliteration for th especial phonetic alphabet of foreign words and loan words, would be possible depending on the cost and availability of linguistic resources.
</prevsent>
<prevsent>2.1 two-stages comparable corpora-based.
</prevsent>
</prevsection>
<citsent citstr=" W03-1108 ">
approach the proposed two-stages approach on bilingual terminology acquisition and disambiguation from comparable corpora (sadat et al, 2003) <papid> W03-1108 </papid>is described as follows: - bilingual terminology acquisition from source language to target language to yield first translation model, represented by similarity vectors simst . - bilingual terminology acquisition from target language to source language to yield second translation model, represented by similarity vectors simts .- merge the first and second models to yield two stages translation model, based on bi-directional comparable corpora and represented by similarity vectors sim(st .we follow strategies of previous researches (de jean et al, 2002; <papid> C02-1166 </papid>fung, 2000; rapp, 1999) <papid> P99-1067 </papid>for the first and second models and propose merging and disambiguation process for the two-stages translation model.</citsent>
<aftsection>
<nextsent>therefore, context vectors of each termin source and target languages are constructed following statistics-based metric.
</nextsent>
<nextsent>next, context vectors related to source words are translated using apreliminary bilingual seed lexicon.
</nextsent>
<nextsent>similarity vectors simst and simts related to the first and second models respectively, are constructed for each pair of source term and target translation using the cosine metric.
</nextsent>
<nextsent>the merging process will keep common pairs of source term and target translation (s,t) which appear in simst as (s,t) but also in simts as (t,s), to result in combined similarity vectors simst for each pair (s,t).the product of similarity values in vectors simst and sim(ts will yield similarity values in simst for each pair (s,t) of source term and target translation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4308">
<title id=" N12-1070.xml">multimodal grammar implementation </title>
<section> implementation.  </section>
<citcontext>
<prevsection>
<prevsent>this is essential for our grammar since the multimodal integration is constrained by temporal overlap between speech and gesture (recall 2.1).
</prevsent>
<prevsent>to solve this, we pre-processed the xml-based fs input so that overlapping time start and time end values were translated?
</prevsent>
</prevsection>
<citsent citstr=" L08-1024 ">
into identical start and end edges of the speech token and the gesture token as follows:  edge source= v0  target= v1    fs type= speech_token    edge source= v0  target= v1    fs type= gesture_token   this robust pre-processing step is sufficient since the only temporal relation required by the grammar is overlap, an abstraction over more fined-grained relations between speech (s) and gesture (g) such as (precedence(start(s), start(g)) ? identity (end(s), end(g))).the linking of gesture to its temporally overlapping speech segment happens prior to parsing via chart-mapping rules (adolphs et al, 2008) <papid> L08-1024 </papid>which involve re-writing chart items into fss.</citsent>
<aftsection>
<nextsent>thegesture-unary-rule (see fig.1) rewrites an in put (i) speech token in the context (c) of gesture token into combined speech+gesture token where the +gest and +pros values of the speech and gesture tokens are copied onto the output (o).
</nextsent>
<nextsent>gesture-unary-rule := cm_rule &amp; [+context  gesture_token &amp; [+gest #gest] , +input  speech_token &amp; [+pros #pros] , +output  speech+gesture_token &amp; [+gest #gest, +pros #pros] , +position  o1@i1, i1@c1  ].
</nextsent>
<nextsent>figure 1: definition of gesture-unary-rulethe +pros attribute contains prosodic information and the +gest attribute is feature-structurerepresentation as shown in (3).
</nextsent>
<nextsent>the +position constraint restricts the position of the i, and items to an overlap (@), i.e., the edge markers of the gesture token should be identical to those of the speech token, and also identical to the speech+gesture token.this chart-mapping rule recognises the gesture token overlapping the speech token and it records this by augmenting?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4309">
<title id=" N12-1070.xml">multimodal grammar implementation </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>in the real implementation, the number of these labels corresponds to the number of features.
</prevsent>
<prevsent>they are designed in the same way and we thus forego any details about the rest.
</prevsent>
</prevsection>
<citsent citstr=" C96-2120 ">
the evaluation was performed against test suite designed in analogy to the traditional phenomenon based test-suites (lehmann et al, 1996): <papid> C96-2120 </papid>manually crafted to ensure coverage of well-formed and illformed data, but inspired by an examination of natural data.</citsent>
<aftsection>
<nextsent>we systematically tested syntactic phenomena (intransitivity, transit ivity, complex nps, coordination, negation and modification) over well-formed and ill-formed examples where the ill-formed items were derived by means of the following operations:prosodic permutation (varying the prosodic marked ness, e.g., from (4a) we derive (4b) to reflect intuitions of native speakers); gesture variation (test ing distinct gesture types) and temporal permutation (moving the gestural performance over the distinct speech items).
</nextsent>
<nextsent>(4) a. anna ate . . .
</nextsent>
<nextsent>depicting gesture along with anna?.
</nextsent>
<nextsent>b. *anna ate . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4310">
<title id=" N12-1076.xml">a comparison of models of word meaning in context </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>several proposals have been made in the recent literature to address this problem.
</prevsent>
<prevsent>type-based methods combine the (type) vector of the target with the vectors of the surrounding context words to obtain disambiguated representation.
</prevsent>
</prevsection>
<citsent citstr=" P08-1028 ">
in recent work, this has been proposed by mitchell and lapata (2008), <papid> P08-1028 </papid>erk and pad?</citsent>
<aftsection>
<nextsent>(2008) and thater et al (2010), <papid> P10-1097 </papid>thater et al (2011),which differ in the choice of input vector representation and in the combination operation they propose.</nextsent>
<nextsent>a different approach has been taken by erk and pad?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4311">
<title id=" N12-1076.xml">a comparison of models of word meaning in context </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>type-based methods combine the (type) vector of the target with the vectors of the surrounding context words to obtain disambiguated representation.
</prevsent>
<prevsent>in recent work, this has been proposed by mitchell and lapata (2008), <papid> P08-1028 </papid>erk and pad?</prevsent>
</prevsection>
<citsent citstr=" P10-1097 ">
(2008) and thater et al (2010), <papid> P10-1097 </papid>thater et al (2011),which differ in the choice of input vector representation and in the combination operation they propose.</citsent>
<aftsection>
<nextsent>a different approach has been taken by erk and pad?
</nextsent>
<nextsent>(2010), reisinger and mooney (2010) <papid> N10-1013 </papid>and reddy et al (2011), who make use of token vectors for individual occurrences of word, rather than using the already mixed type vectors.</nextsent>
<nextsent>generally speaking, these methods select?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4312">
<title id=" N12-1076.xml">a comparison of models of word meaning in context </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(2008) and thater et al (2010), <papid> P10-1097 </papid>thater et al (2011),which differ in the choice of input vector representation and in the combination operation they propose.</prevsent>
<prevsent>a different approach has been taken by erk and pad?</prevsent>
</prevsection>
<citsent citstr=" N10-1013 ">
(2010), reisinger and mooney (2010) <papid> N10-1013 </papid>and reddy et al (2011), who make use of token vectors for individual occurrences of word, rather than using the already mixed type vectors.</citsent>
<aftsection>
<nextsent>generally speaking, these methods select?
</nextsent>
<nextsent>a set of token vectors of the target, which are similar to the current context, and use only these to obtain disambiguated representation.
</nextsent>
<nextsent>yet another approach has been taken by dinu and lapata (2010), ? <papid> D10-1113 </papid>saghdha and korhonen (2011) and van de cruys et al (2011), who propose to use latent variable models.</nextsent>
<nextsent>conceptually, this comes close to token-based models, however their approach is more unitary as they attempt to recover hidden layer which best explains the observation data.in this paper, we focus on the first group of approaches and investigate the precise differences between the three models of erk and pad?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4313">
<title id=" N12-1076.xml">a comparison of models of word meaning in context </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>generally speaking, these methods select?
</prevsent>
<prevsent>a set of token vectors of the target, which are similar to the current context, and use only these to obtain disambiguated representation.
</prevsent>
</prevsection>
<citsent citstr=" D10-1113 ">
yet another approach has been taken by dinu and lapata (2010), ? <papid> D10-1113 </papid>saghdha and korhonen (2011) and van de cruys et al (2011), who propose to use latent variable models.</citsent>
<aftsection>
<nextsent>conceptually, this comes close to token-based models, however their approach is more unitary as they attempt to recover hidden layer which best explains the observation data.in this paper, we focus on the first group of approaches and investigate the precise differences between the three models of erk and pad?
</nextsent>
<nextsent>and thater et al., out of which (thater et al, 2011) achieves state of the art results on standard dataset.
</nextsent>
<nextsent>despite the fact that these models exploit similar intuitions, both their formal presentations and the results obtained vary toa great extent.
</nextsent>
<nextsent>the answer given in this paper is sur prising: the three models are essentially equivalent if syntactic information is ignored; in syntactic space the three methods implement only slightly different 611 intuitions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4316">
<title id=" N12-1060.xml">improved reordering for shall own grammar based hierarchical phrase based translation </title>
<section> abstract </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" J10-3008 ">
shallow-n grammars (de gispert et al, 2010) <papid> J10-3008 </papid>were introduced to reduce over-generation inthe hiero translation model (chiang, 2005) <papid> P05-1033 </papid>resulting in much faster decoding and restricting reordering to desired level for specific language pairs.</citsent>
<aftsection>
<nextsent>however, shallow-n grammars require parameters which cannot be directly optimized using minimum error-rate tuning by the decoder.
</nextsent>
<nextsent>this paper introduces some novel improvements to the translation model for shallow-n grammars.
</nextsent>
<nextsent>we introduce two rules: bitg-style reordering glue rule and simpler monotonic concatenation rule.
</nextsent>
<nextsent>we use separate features for the new rules in our loglinear model allowing the decoder to directly optimize the feature weights.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4319">
<title id=" N12-1060.xml">improved reordering for shall own grammar based hierarchical phrase based translation </title>
<section> abstract </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" P05-1033 ">
shallow-n grammars (de gispert et al, 2010) <papid> J10-3008 </papid>were introduced to reduce over-generation inthe hiero translation model (chiang, 2005) <papid> P05-1033 </papid>resulting in much faster decoding and restricting reordering to desired level for specific language pairs.</citsent>
<aftsection>
<nextsent>however, shallow-n grammars require parameters which cannot be directly optimized using minimum error-rate tuning by the decoder.
</nextsent>
<nextsent>this paper introduces some novel improvements to the translation model for shallow-n grammars.
</nextsent>
<nextsent>we introduce two rules: bitg-style reordering glue rule and simpler monotonic concatenation rule.
</nextsent>
<nextsent>we use separate features for the new rules in our loglinear model allowing the decoder to directly optimize the feature weights.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4321">
<title id=" N12-1060.xml">improved reordering for shall own grammar based hierarchical phrase based translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we use separate features for the new rules in our loglinear model allowing the decoder to directly optimize the feature weights.
</prevsent>
<prevsent>we show this formulation of shallow-n hierarchical phrase based translation is comparable in translation quality to full hiero-style decoding (without shallow rules) while at the same time being considerably faster.
</prevsent>
</prevsection>
<citsent citstr=" J07-2003 ">
hierarchical phrase-based translation (chiang, 2005; <papid> P05-1033 </papid>chiang, 2007) <papid> J07-2003 </papid>extends the highly lexicalized models from phrase-based translation systems inorder to model lexicalized reordering and discon tiguous phrases.</citsent>
<aftsection>
<nextsent>however, major drawback in this approach, when compared to phrase-based systems, is the total number of rules that are learnt are several orders of magnitude larger than standard phrase tables, which leads to over-generation and search errors and contribute to much longer decoding times.
</nextsent>
<nextsent>several approaches have been proposed to address these issues: from filtering the extracted synchronous grammar (zollmann et al, 2008; <papid> C08-1144 </papid>he et al, 2009; iglesias et al, 2009) <papid> E09-1044 </papid>to alternative bayesian approaches for learning minimal grammars (blunsom et al, 2008; blunsom et al, 2009;<papid> P09-1088 </papid>sankaran et al, 2011).<papid> W11-2167 </papid></nextsent>
<nextsent>the idea of shallow-n grammars (de gispert et al, 2010) <papid> J10-3008 </papid>takes an orthogonal direction for controlling the over-generation and search space in hiero decoder by restricting the degree of nesting allowed for hierarchical rules.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4322">
<title id=" N12-1060.xml">improved reordering for shall own grammar based hierarchical phrase based translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>hierarchical phrase-based translation (chiang, 2005; <papid> P05-1033 </papid>chiang, 2007) <papid> J07-2003 </papid>extends the highly lexicalized models from phrase-based translation systems inorder to model lexicalized reordering and discon tiguous phrases.</prevsent>
<prevsent>however, major drawback in this approach, when compared to phrase-based systems, is the total number of rules that are learnt are several orders of magnitude larger than standard phrase tables, which leads to over-generation and search errors and contribute to much longer decoding times.</prevsent>
</prevsection>
<citsent citstr=" C08-1144 ">
several approaches have been proposed to address these issues: from filtering the extracted synchronous grammar (zollmann et al, 2008; <papid> C08-1144 </papid>he et al, 2009; iglesias et al, 2009) <papid> E09-1044 </papid>to alternative bayesian approaches for learning minimal grammars (blunsom et al, 2008; blunsom et al, 2009;<papid> P09-1088 </papid>sankaran et al, 2011).<papid> W11-2167 </papid></citsent>
<aftsection>
<nextsent>the idea of shallow-n grammars (de gispert et al, 2010) <papid> J10-3008 </papid>takes an orthogonal direction for controlling the over-generation and search space in hiero decoder by restricting the degree of nesting allowed for hierarchical rules.</nextsent>
<nextsent>we propose an novel statistical model forshallow-n grammars which does not require additional non-terminals for monotonic re-ordering and also eliminates hand-tuned parameters and instead introduces an automatically tunable alternative.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4323">
<title id=" N12-1060.xml">improved reordering for shall own grammar based hierarchical phrase based translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>hierarchical phrase-based translation (chiang, 2005; <papid> P05-1033 </papid>chiang, 2007) <papid> J07-2003 </papid>extends the highly lexicalized models from phrase-based translation systems inorder to model lexicalized reordering and discon tiguous phrases.</prevsent>
<prevsent>however, major drawback in this approach, when compared to phrase-based systems, is the total number of rules that are learnt are several orders of magnitude larger than standard phrase tables, which leads to over-generation and search errors and contribute to much longer decoding times.</prevsent>
</prevsection>
<citsent citstr=" E09-1044 ">
several approaches have been proposed to address these issues: from filtering the extracted synchronous grammar (zollmann et al, 2008; <papid> C08-1144 </papid>he et al, 2009; iglesias et al, 2009) <papid> E09-1044 </papid>to alternative bayesian approaches for learning minimal grammars (blunsom et al, 2008; blunsom et al, 2009;<papid> P09-1088 </papid>sankaran et al, 2011).<papid> W11-2167 </papid></citsent>
<aftsection>
<nextsent>the idea of shallow-n grammars (de gispert et al, 2010) <papid> J10-3008 </papid>takes an orthogonal direction for controlling the over-generation and search space in hiero decoder by restricting the degree of nesting allowed for hierarchical rules.</nextsent>
<nextsent>we propose an novel statistical model forshallow-n grammars which does not require additional non-terminals for monotonic re-ordering and also eliminates hand-tuned parameters and instead introduces an automatically tunable alternative.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4325">
<title id=" N12-1060.xml">improved reordering for shall own grammar based hierarchical phrase based translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>hierarchical phrase-based translation (chiang, 2005; <papid> P05-1033 </papid>chiang, 2007) <papid> J07-2003 </papid>extends the highly lexicalized models from phrase-based translation systems inorder to model lexicalized reordering and discon tiguous phrases.</prevsent>
<prevsent>however, major drawback in this approach, when compared to phrase-based systems, is the total number of rules that are learnt are several orders of magnitude larger than standard phrase tables, which leads to over-generation and search errors and contribute to much longer decoding times.</prevsent>
</prevsection>
<citsent citstr=" P09-1088 ">
several approaches have been proposed to address these issues: from filtering the extracted synchronous grammar (zollmann et al, 2008; <papid> C08-1144 </papid>he et al, 2009; iglesias et al, 2009) <papid> E09-1044 </papid>to alternative bayesian approaches for learning minimal grammars (blunsom et al, 2008; blunsom et al, 2009;<papid> P09-1088 </papid>sankaran et al, 2011).<papid> W11-2167 </papid></citsent>
<aftsection>
<nextsent>the idea of shallow-n grammars (de gispert et al, 2010) <papid> J10-3008 </papid>takes an orthogonal direction for controlling the over-generation and search space in hiero decoder by restricting the degree of nesting allowed for hierarchical rules.</nextsent>
<nextsent>we propose an novel statistical model forshallow-n grammars which does not require additional non-terminals for monotonic re-ordering and also eliminates hand-tuned parameters and instead introduces an automatically tunable alternative.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4326">
<title id=" N12-1060.xml">improved reordering for shall own grammar based hierarchical phrase based translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>hierarchical phrase-based translation (chiang, 2005; <papid> P05-1033 </papid>chiang, 2007) <papid> J07-2003 </papid>extends the highly lexicalized models from phrase-based translation systems inorder to model lexicalized reordering and discon tiguous phrases.</prevsent>
<prevsent>however, major drawback in this approach, when compared to phrase-based systems, is the total number of rules that are learnt are several orders of magnitude larger than standard phrase tables, which leads to over-generation and search errors and contribute to much longer decoding times.</prevsent>
</prevsection>
<citsent citstr=" W11-2167 ">
several approaches have been proposed to address these issues: from filtering the extracted synchronous grammar (zollmann et al, 2008; <papid> C08-1144 </papid>he et al, 2009; iglesias et al, 2009) <papid> E09-1044 </papid>to alternative bayesian approaches for learning minimal grammars (blunsom et al, 2008; blunsom et al, 2009;<papid> P09-1088 </papid>sankaran et al, 2011).<papid> W11-2167 </papid></citsent>
<aftsection>
<nextsent>the idea of shallow-n grammars (de gispert et al, 2010) <papid> J10-3008 </papid>takes an orthogonal direction for controlling the over-generation and search space in hiero decoder by restricting the degree of nesting allowed for hierarchical rules.</nextsent>
<nextsent>we propose an novel statistical model forshallow-n grammars which does not require additional non-terminals for monotonic re-ordering and also eliminates hand-tuned parameters and instead introduces an automatically tunable alternative.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4330">
<title id=" N12-1060.xml">improved reordering for shall own grammar based hierarchical phrase based translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the idea of shallow-n grammars (de gispert et al, 2010) <papid> J10-3008 </papid>takes an orthogonal direction for controlling the over-generation and search space in hiero decoder by restricting the degree of nesting allowed for hierarchical rules.</prevsent>
<prevsent>we propose an novel statistical model forshallow-n grammars which does not require additional non-terminals for monotonic re-ordering and also eliminates hand-tuned parameters and instead introduces an automatically tunable alternative.</prevsent>
</prevsection>
<citsent citstr=" W09-3804 ">
we introduce bitg-style (saers et al, 2009) <papid> W09-3804 </papid>reordering glue rule (?</citsent>
<aftsection>
<nextsent>3) and monotonic x-glue rule (?
</nextsent>
<nextsent>4).
</nextsent>
<nextsent>our experiments show the resulting shallow-n decoding is comparable in translation quality to full hiero-style decoding while at the same time being considerably faster.
</nextsent>
<nextsent>all the experiments in this paper were done usingkriya (sankaran et al, 2012) hierarchical phrase based system which also supports decoding withshallow-n grammars.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4341">
<title id=" N12-1060.xml">improved reordering for shall own grammar based hierarchical phrase based translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>our log-linear model uses the standard features conditional (p(e|f) and p(f |e)) and lexical (pl(e|f) and pl(f |e)) probabilities, phrase (pp) and word (wp) penalties, language model and regular glue penalty (mg) apart from two additional features for rglue (rg) and xglue (xg).
</prevsent>
<prevsent>table 2 shows the bleu scores and decoding time for the mtc test-set.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
we provide the ibmbleu (papineni et al, 2002) <papid> P02-1040 </papid>scores for the shallow grammars for order: = 1, 2, 3 and compare it to the full-hiero baseline.</citsent>
<aftsection>
<nextsent>finally, we experiment withtwo variants of the glue rules, i) restricted version where the glue rules combine only at leveln , (column glue: xn ? in table), ii) more free variant where they are allowed to use any freely (col umn glue: x?
</nextsent>
<nextsent>in table).as it can be seen, the unrestricted glue rules variant (column glue: x?)
</nextsent>
<nextsent>consistently outperforms the glue rules restricted to the top-level non-terminal xn , achieving maximum bleu score of 26.24,which is about 1.4 bleu points higher than the latter and is also marginally higher than full hiero.
</nextsent>
<nextsent>the decoding speeds for free-glue and restricted-gluevariants were mostly identical and so we only provide the decoding time for the latter.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4342">
<title id=" P03-1008.xml">syntactic features and word similarity for supervised metonymy resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in (1),1 seat 19?
</prevsent>
<prevsent>refers to the person occupying seat 19.
</prevsent>
</prevsection>
<citsent citstr=" P92-1047 ">
(1) ask seat 19 whether he wants to swap the importance of resolving metonymies hasbeen shown for variety of nlp tasks, e.g., machine translation (kamei and wakao, 1992), <papid> P92-1047 </papid>question answering (stallard, 1993) <papid> P93-1012 </papid>and anaphora resolution (harabagiu, 1998; <papid> W98-0720 </papid>markert and hahn, 2002).</citsent>
<aftsection>
<nextsent>1(1) was actually uttered by flight attendant on plane.
</nextsent>
<nextsent>in order to recognise and interpret the metonymy in (1), large amount of knowledge and contextual inference is necessary (e.g. seats cannot be questioned, people occupy seats, people can be ques tioned).
</nextsent>
<nextsent>metonymic readings are also potentially open-ended (nunberg, 1978), so that developing ama chine learning algorithm based on previous examples does not seem feasible.
</nextsent>
<nextsent>however, it has long been recognised that many metonymic readings are actually quite regular (lakoff and johnson, 1980; nunberg, 1995).2 in (2), pakistan?, the name of location, refers to one of its national sports teams.3 (2) pakistan had won the world cup similar examples can be regularly found for many other location names (see (3) and (4)).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4343">
<title id=" P03-1008.xml">syntactic features and word similarity for supervised metonymy resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in (1),1 seat 19?
</prevsent>
<prevsent>refers to the person occupying seat 19.
</prevsent>
</prevsection>
<citsent citstr=" P93-1012 ">
(1) ask seat 19 whether he wants to swap the importance of resolving metonymies hasbeen shown for variety of nlp tasks, e.g., machine translation (kamei and wakao, 1992), <papid> P92-1047 </papid>question answering (stallard, 1993) <papid> P93-1012 </papid>and anaphora resolution (harabagiu, 1998; <papid> W98-0720 </papid>markert and hahn, 2002).</citsent>
<aftsection>
<nextsent>1(1) was actually uttered by flight attendant on plane.
</nextsent>
<nextsent>in order to recognise and interpret the metonymy in (1), large amount of knowledge and contextual inference is necessary (e.g. seats cannot be questioned, people occupy seats, people can be ques tioned).
</nextsent>
<nextsent>metonymic readings are also potentially open-ended (nunberg, 1978), so that developing ama chine learning algorithm based on previous examples does not seem feasible.
</nextsent>
<nextsent>however, it has long been recognised that many metonymic readings are actually quite regular (lakoff and johnson, 1980; nunberg, 1995).2 in (2), pakistan?, the name of location, refers to one of its national sports teams.3 (2) pakistan had won the world cup similar examples can be regularly found for many other location names (see (3) and (4)).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4344">
<title id=" P03-1008.xml">syntactic features and word similarity for supervised metonymy resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in (1),1 seat 19?
</prevsent>
<prevsent>refers to the person occupying seat 19.
</prevsent>
</prevsection>
<citsent citstr=" W98-0720 ">
(1) ask seat 19 whether he wants to swap the importance of resolving metonymies hasbeen shown for variety of nlp tasks, e.g., machine translation (kamei and wakao, 1992), <papid> P92-1047 </papid>question answering (stallard, 1993) <papid> P93-1012 </papid>and anaphora resolution (harabagiu, 1998; <papid> W98-0720 </papid>markert and hahn, 2002).</citsent>
<aftsection>
<nextsent>1(1) was actually uttered by flight attendant on plane.
</nextsent>
<nextsent>in order to recognise and interpret the metonymy in (1), large amount of knowledge and contextual inference is necessary (e.g. seats cannot be questioned, people occupy seats, people can be ques tioned).
</nextsent>
<nextsent>metonymic readings are also potentially open-ended (nunberg, 1978), so that developing ama chine learning algorithm based on previous examples does not seem feasible.
</nextsent>
<nextsent>however, it has long been recognised that many metonymic readings are actually quite regular (lakoff and johnson, 1980; nunberg, 1995).2 in (2), pakistan?, the name of location, refers to one of its national sports teams.3 (2) pakistan had won the world cup similar examples can be regularly found for many other location names (see (3) and (4)).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4346">
<title id=" P03-1008.xml">syntactic features and word similarity for supervised metonymy resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>metonymic readings are also potentially open-ended (nunberg, 1978), so that developing ama chine learning algorithm based on previous examples does not seem feasible.
</prevsent>
<prevsent>however, it has long been recognised that many metonymic readings are actually quite regular (lakoff and johnson, 1980; nunberg, 1995).2 in (2), pakistan?, the name of location, refers to one of its national sports teams.3 (2) pakistan had won the world cup similar examples can be regularly found for many other location names (see (3) and (4)).
</prevsent>
</prevsection>
<citsent citstr=" W02-1027 ">
(3) england won the world cup (4) scotland lost in the semi-finalin contrast to (1), the regularity of these examples can be exploited by supervised machine learning algorithm, although this method is not pursued in standard approaches to regular polysemy and metonymy (with the exception of our own previous work in (markert and nissim, 2002<papid> W02-1027 </papid>a)).</citsent>
<aftsection>
<nextsent>such an algorithm needs to infer from examples like (2) (whenlabelled as metonymy) that england?
</nextsent>
<nextsent>and scot land?
</nextsent>
<nextsent>in (3) and (4) are also metonymic.
</nextsent>
<nextsent>in order to 2due to its regularity, conventional metonymy is also known as regular polysemy (copestake and briscoe, 1995).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4378">
<title id=" P03-1008.xml">syntactic features and word similarity for supervised metonymy resolution </title>
<section> corpus study.  </section>
<citcontext>
<prevsection>
<prevsent>5http://www.cia.gov/cia/publications/ factbook/ 1998) to occur.
</prevsent>
<prevsent>each country name is surrounded by three sentences of context.the 1000 examples of our corpus have been independently annotated by two computational linguists, who are the authors of this paper.
</prevsent>
</prevsection>
<citsent citstr=" J96-2004 ">
the annotation can be considered reliable (krippendorff, 1980) with 95% agreement and kappa (carletta, 1996) <papid> J96-2004 </papid>of .88.</citsent>
<aftsection>
<nextsent>our corpus for testing and training the algorithm includes only the examples which both annotators could agree on and which were not marked as noise (e.g. homonyms, as professor greenland?), for total of 925.
</nextsent>
<nextsent>table 1 reports the reading distribution.
</nextsent>
<nextsent>table 1: distribution of readings in our corpus reading freq % literal 737 79.7 place-for-people 161 17.4 place-for-event 3 .3 place-for-product 0 .0 mixed 15 1.6 other met 9 1.0 total non-literal 188 20.3 total 925 100.0
</nextsent>
<nextsent>task the corpus distribution confirms that metonymies that do not follow established metonymic patterns (othermet) are very rare.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4379">
<title id=" P03-1008.xml">syntactic features and word similarity for supervised metonymy resolution </title>
<section> metonymy resolution as classification.  </section>
<citcontext>
<prevsection>
<prevsent>this class-basedapproach enables one to, for example, infer the reading of (3) from that of (2).
</prevsent>
<prevsent>we use decision list (dl) classifier.
</prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
all features encountered in the training data are ranked in the dl(best evidence first) according to the following log likelihood ratio (yarowsky, 1995): <papid> P95-1026 </papid>log ( pr(reading |feature ) ? 6=i pr(reading |feature ) )we estimated probabilities via maximum likelihood, adopting simple smoothing method (martinez and agirre, 2000): <papid> W00-1326 </papid>0.1 is added to both the denominator and numerator.</citsent>
<aftsection>
<nextsent>the target readings to be distinguished are literal, place-for-people,place-for event, place-for-product, other met andmixed.
</nextsent>
<nextsent>all our algorithms are tested on our annotated corpus, employing 10-fold cross-validation.
</nextsent>
<nextsent>we evaluate accuracy and coverage: acc = # correct decisions made # decisions made cov = # decisions made # test datawe also use backing-off strategy to the most frequent reading (literal) for the cases where no decision can be made.
</nextsent>
<nextsent>we report the results as accuracy backoff (acc ); coverage backoff is always 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4380">
<title id=" P03-1008.xml">syntactic features and word similarity for supervised metonymy resolution </title>
<section> metonymy resolution as classification.  </section>
<citcontext>
<prevsection>
<prevsent>this class-basedapproach enables one to, for example, infer the reading of (3) from that of (2).
</prevsent>
<prevsent>we use decision list (dl) classifier.
</prevsent>
</prevsection>
<citsent citstr=" W00-1326 ">
all features encountered in the training data are ranked in the dl(best evidence first) according to the following log likelihood ratio (yarowsky, 1995): <papid> P95-1026 </papid>log ( pr(reading |feature ) ? 6=i pr(reading |feature ) )we estimated probabilities via maximum likelihood, adopting simple smoothing method (martinez and agirre, 2000): <papid> W00-1326 </papid>0.1 is added to both the denominator and numerator.</citsent>
<aftsection>
<nextsent>the target readings to be distinguished are literal, place-for-people,place-for event, place-for-product, other met andmixed.
</nextsent>
<nextsent>all our algorithms are tested on our annotated corpus, employing 10-fold cross-validation.
</nextsent>
<nextsent>we evaluate accuracy and coverage: acc = # correct decisions made # decisions made cov = # decisions made # test datawe also use backing-off strategy to the most frequent reading (literal) for the cases where no decision can be made.
</nextsent>
<nextsent>we report the results as accuracy backoff (acc ); coverage backoff is always 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4389">
<title id=" P03-1008.xml">syntactic features and word similarity for supervised metonymy resolution </title>
<section> influence of parsing.  </section>
<citcontext>
<prevsection>
<prevsent>for pmw direct objects, precision is 60% and recall 86%.10we reproduced all experiments using the automatically extracted relations.
</prevsent>
<prevsent>although the relative performance of the algorithms remains mostly unchanged, most of the resulting f-measures are more than 10% lower than for hand annotated roles (ta ble 6).
</prevsent>
</prevsection>
<citsent citstr=" P02-1031 ">
this is in line with results in (gildea and palmer, 2002), <papid> P02-1031 </papid>who compare the effect of manual and automatic parsing on semantic predicate argument recognition.</citsent>
<aftsection>
<nextsent>previous approaches to metonymy recognition.
</nextsent>
<nextsent>our approach is the first machine learning algorithm to metonymy recognition, building on our previous 10we did not evaluate rasps performance on relations that do not involve the pmw.table 6: results summary for the different algorithms using rasp.
</nextsent>
<nextsent>for relax and combination we report best results (50 thesaurus iterations).
</nextsent>
<nextsent>algorithm acc cov acc p f hmr .884 .514 .812 .674 .154 .251 relax .841 .666 .821 .619 .319 .421 relax ii .820 .769 .823 .621 .340 .439 combination .850 .672 .830 .640 .388 .483 baseline .797 1.00 .797 n/a .000 n/awork (markert and nissim, 2002<papid> W02-1027 </papid>a).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4411">
<title id=" P03-1008.xml">syntactic features and word similarity for supervised metonymy resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>an empirical comparison between our approach in (markert and nissim, 2002<papid> W02-1027 </papid>a)12 and an srs violation approach showed that our approach performed better.</prevsent>
<prevsent>in contrast to previous approaches (fass, 1997; hobbs et al , 1993; copestake and briscoe, 1995; pustejovsky, 1995; verspoor, 1996; markert and hahn, 2002; harabagiu, 1998; <papid> W98-0720 </papid>stallard, 1993), <papid> P93-1012 </papid>we use corpus reliably annotated for metonymy for evaluation, moving the field towards more objective11(markert and hahn, 2002) and (harabagiu, 1998) <papid> W98-0720 </papid>enhance this with anaphoric information.</prevsent>
</prevsection>
<citsent citstr=" J99-4002 ">
(briscoe and copestake, 1999) <papid> J99-4002 </papid>propose using frequency information besides syntactic/semantic restrictions, but use only priori sense frequencies without contextual features.</citsent>
<aftsection>
<nextsent>12note that our current approach even outperforms (markert and nissim, 2002<papid> W02-1027 </papid>a).</nextsent>
<nextsent>evaluation procedures.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4420">
<title id=" P03-1008.xml">syntactic features and word similarity for supervised metonymy resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>this allows for level of abstraction not present in standard supervised wsd.
</prevsent>
<prevsent>we can infer readings for words that have not been seen in the training data before, allow an easy treatment of rare words that undergo regular sense alternations and do not have to annotate and train separately for every individual word to treat regular sense distinctions.13by exploiting additional similarity levels and integrating thesaurus we further generalise the kind of inferences we can make and limit the size of annotated training data: as our sampling frame contains 553 different names, an annotated dataset of 925 samples is quite small.
</prevsent>
</prevsection>
<citsent citstr=" C02-1112 ">
these generalisations over context and collocates are also applicable to standard wsd and can supplement those achieved e.g., by subcategorisation frames (martinez et al , 2002).<papid> C02-1112 </papid></citsent>
<aftsection>
<nextsent>our approach to word similarity to overcome data sparseness is perhaps most similar to (karov and edelman, 1998).<papid> J98-1002 </papid></nextsent>
<nextsent>however, they mainly focus on the computation of similarity measures from the training data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4421">
<title id=" P03-1008.xml">syntactic features and word similarity for supervised metonymy resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>we can infer readings for words that have not been seen in the training data before, allow an easy treatment of rare words that undergo regular sense alternations and do not have to annotate and train separately for every individual word to treat regular sense distinctions.13by exploiting additional similarity levels and integrating thesaurus we further generalise the kind of inferences we can make and limit the size of annotated training data: as our sampling frame contains 553 different names, an annotated dataset of 925 samples is quite small.
</prevsent>
<prevsent>these generalisations over context and collocates are also applicable to standard wsd and can supplement those achieved e.g., by subcategorisation frames (martinez et al , 2002).<papid> C02-1112 </papid></prevsent>
</prevsection>
<citsent citstr=" J98-1002 ">
our approach to word similarity to overcome data sparseness is perhaps most similar to (karov and edelman, 1998).<papid> J98-1002 </papid></citsent>
<aftsection>
<nextsent>however, they mainly focus on the computation of similarity measures from the training data.
</nextsent>
<nextsent>we instead use an off-the-shelf resource without adding much computational complexity and achieve considerable improvement in our results.
</nextsent>
<nextsent>we presented supervised classification algorithm for metonymy recognition, which exploits the similarity between examples of conventional metonymy, operates on semantic classes and thereby enables complex inferences from training to test examples.
</nextsent>
<nextsent>we showed that syntactic head-modifier relations are high precision feature for metonymy recognition.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4422">
<title id=" P04-2011.xml">beyond n in ngram tagging </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the hidden markov model (hmm) used for part of-speech (pos) tagging is usually second-order model, using tag trigrams, implementing the idea that limited number of preceding tags provide aconsiderable amount of information on the identity of the current tag.
</prevsent>
<prevsent>this approach leads to good results.
</prevsent>
</prevsection>
<citsent citstr=" A00-1031 ">
for example, the tnt trigram hmm tagger achieves state-of-the-art tagging accuracies on english and german (brants, 2000).<papid> A00-1031 </papid></citsent>
<aftsection>
<nextsent>in general, however, as the model does not consider global context, mistakes are made that concern long-distance syntactic relations.
</nextsent>
<nextsent>the simplifying assumption, which is the basis for hmm tagging, that the context of given tag can be fully represented by just the previous two tags, leads to tagging errors where syntactic features that fall outside of this range, and that are needed for determining the identity of the tag at hand, are ignored.
</nextsent>
<nextsent>one such error in tagging dutch is related to finite ness of verbs.
</nextsent>
<nextsent>this is discussed in the next paragraph and will be used in explaining the proposed approach.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4424">
<title id=" P02-1016.xml">active learning for statistical natural language parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>based on this distance, the active learning process analyzes the sample distribution by clustering and calculates the density of each sample to quantify its representativeness.
</prevsent>
<prevsent>further more, sentence is deemed as useful if the existing model is highly uncertain about its parses, where uncertainty is measured by various entropy-based scores.experiments are carried out in the shallow semantic parser of an air travel dialog system.our result shows that for about the same parsing accuracy, we only need to annotate third of the samples as compared to the usual random selection method.
</prevsent>
</prevsection>
<citsent citstr=" H94-1052 ">
a prerequisite for building statistical parsers (jelinek et al., 1994; <papid> H94-1052 </papid>collins, 1996; <papid> P96-1025 </papid>ratnaparkhi, 1997; <papid> W97-0301 </papid>charniak,1997) is the availability of (large) corpus of parsed sentences.</citsent>
<aftsection>
<nextsent>acquiring such corpus is expensive and time consuming and is often the bottleneck to build parser for new application or domain.
</nextsent>
<nextsent>the goal of this study is to reduce the amount of annotated sentences (and hence the development time) required for statistical parser to achieve satisfactory performance using active learning.
</nextsent>
<nextsent>active learning has been studied in the context of many natural language processing (nlp) applications such as information extraction(thompson et al, 1999), text classication(mccallum and nigam, 1998) and natural language parsing(thompson et al, 1999; hwa, 2000), <papid> W00-1306 </papid>toname few.</nextsent>
<nextsent>the basic idea is to couple tightly knowledge acquisition, e.g., annotating sentences for parsing,with model-training, as opposed to treating them sepa rately.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4426">
<title id=" P02-1016.xml">active learning for statistical natural language parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>based on this distance, the active learning process analyzes the sample distribution by clustering and calculates the density of each sample to quantify its representativeness.
</prevsent>
<prevsent>further more, sentence is deemed as useful if the existing model is highly uncertain about its parses, where uncertainty is measured by various entropy-based scores.experiments are carried out in the shallow semantic parser of an air travel dialog system.our result shows that for about the same parsing accuracy, we only need to annotate third of the samples as compared to the usual random selection method.
</prevsent>
</prevsection>
<citsent citstr=" P96-1025 ">
a prerequisite for building statistical parsers (jelinek et al., 1994; <papid> H94-1052 </papid>collins, 1996; <papid> P96-1025 </papid>ratnaparkhi, 1997; <papid> W97-0301 </papid>charniak,1997) is the availability of (large) corpus of parsed sentences.</citsent>
<aftsection>
<nextsent>acquiring such corpus is expensive and time consuming and is often the bottleneck to build parser for new application or domain.
</nextsent>
<nextsent>the goal of this study is to reduce the amount of annotated sentences (and hence the development time) required for statistical parser to achieve satisfactory performance using active learning.
</nextsent>
<nextsent>active learning has been studied in the context of many natural language processing (nlp) applications such as information extraction(thompson et al, 1999), text classication(mccallum and nigam, 1998) and natural language parsing(thompson et al, 1999; hwa, 2000), <papid> W00-1306 </papid>toname few.</nextsent>
<nextsent>the basic idea is to couple tightly knowledge acquisition, e.g., annotating sentences for parsing,with model-training, as opposed to treating them sepa rately.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4427">
<title id=" P02-1016.xml">active learning for statistical natural language parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>based on this distance, the active learning process analyzes the sample distribution by clustering and calculates the density of each sample to quantify its representativeness.
</prevsent>
<prevsent>further more, sentence is deemed as useful if the existing model is highly uncertain about its parses, where uncertainty is measured by various entropy-based scores.experiments are carried out in the shallow semantic parser of an air travel dialog system.our result shows that for about the same parsing accuracy, we only need to annotate third of the samples as compared to the usual random selection method.
</prevsent>
</prevsection>
<citsent citstr=" W97-0301 ">
a prerequisite for building statistical parsers (jelinek et al., 1994; <papid> H94-1052 </papid>collins, 1996; <papid> P96-1025 </papid>ratnaparkhi, 1997; <papid> W97-0301 </papid>charniak,1997) is the availability of (large) corpus of parsed sentences.</citsent>
<aftsection>
<nextsent>acquiring such corpus is expensive and time consuming and is often the bottleneck to build parser for new application or domain.
</nextsent>
<nextsent>the goal of this study is to reduce the amount of annotated sentences (and hence the development time) required for statistical parser to achieve satisfactory performance using active learning.
</nextsent>
<nextsent>active learning has been studied in the context of many natural language processing (nlp) applications such as information extraction(thompson et al, 1999), text classication(mccallum and nigam, 1998) and natural language parsing(thompson et al, 1999; hwa, 2000), <papid> W00-1306 </papid>toname few.</nextsent>
<nextsent>the basic idea is to couple tightly knowledge acquisition, e.g., annotating sentences for parsing,with model-training, as opposed to treating them sepa rately.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4428">
<title id=" P02-1016.xml">active learning for statistical natural language parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>acquiring such corpus is expensive and time consuming and is often the bottleneck to build parser for new application or domain.
</prevsent>
<prevsent>the goal of this study is to reduce the amount of annotated sentences (and hence the development time) required for statistical parser to achieve satisfactory performance using active learning.
</prevsent>
</prevsection>
<citsent citstr=" W00-1306 ">
active learning has been studied in the context of many natural language processing (nlp) applications such as information extraction(thompson et al, 1999), text classication(mccallum and nigam, 1998) and natural language parsing(thompson et al, 1999; hwa, 2000), <papid> W00-1306 </papid>toname few.</citsent>
<aftsection>
<nextsent>the basic idea is to couple tightly knowledge acquisition, e.g., annotating sentences for parsing,with model-training, as opposed to treating them separately.
</nextsent>
<nextsent>in our setup, we assume that small amount of annotated sentences is initially available, which is used to build statistical parser.
</nextsent>
<nextsent>we also assume that there is large corpus of unannotated sentences at our disposal this corpus is called active training set.
</nextsent>
<nextsent>a batch of sam ples1 is selected using algorithms developed here, and are annotated by human beings and are then added to training data to rebuild the model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4432">
<title id=" P02-1016.xml">active learning for statistical natural language parsing </title>
<section> sentence distance and clustering.  </section>
<citcontext>
<prevsection>
<prevsent>answers of each question are represented as bitstrings.
</prevsent>
<prevsent>to support questions like what is the previous word (or tag, label, extension)??,word, tag, label and extension vocabularies are all encoded as bitstrings.
</prevsent>
</prevsection>
<citsent citstr=" J92-4003 ">
words are encoded through an automatic clustering algorithm (brown et al, 1992) <papid> J92-4003 </papid>while tags, labels and extensions are normally encoded using diagonal bits.</citsent>
<aftsection>
<nextsent>an example can be found in (luo et al, 2002).
</nextsent>
<nextsent>in summary, parse tree can be represented uniquely by sequence of events, while each event can in turn be represented as bitstring.
</nextsent>
<nextsent>with this in mind, we are now ready to dene structural distance for two sentences given an existing model.
</nextsent>
<nextsent>2.2 sentence distance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4435">
<title id=" P02-1016.xml">active learning for statistical natural language parsing </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>and after only about 2800 sentences are selected, the active learning result becomes very close to the best possible accuracy.
</prevsent>
<prevsent>while active learning has been studied extensively in the context of machine learning (cohn et al, 1996; freund 500 1000 1500 2000 2500 60 65 70 75 80 85 90 effect of clustering number of sentences selected ac cu ra cy (% ) word entropy(hw) use sentence entropy only figure 7: effect of clustering: entropy-based learning curve (in plus) vs. sample selection with clustering and uncertainty score(in triangle).
</prevsent>
</prevsection>
<citsent citstr=" W01-0710 ">
500 1000 1500 2000 2500 3000 3500 4000 60 65 70 75 80 85 90 active learning vs. random selection number of sentences selected ac cu ra cy (% ) word entropy(hw), weighted by density random selection use 20k samples figure 8: active learner uses one-third (about 1300 sen tences) of training data to achieve similar performance to random selection (about 4000 sentence).et al, 1997), and has been applied to text classica tion (mccallum and nigam, 1998) and part-of-speech tagging (dagan and engelson, 1995), there are only handful studies on natural language parsing (thompson et al, 1999) and (hwa, 2000; <papid> W00-1306 </papid>hwa, 2001).<papid> W01-0710 </papid></citsent>
<aftsection>
<nextsent>(thompson et al, 1999) uses active learning to acquire shift-reduce parser, and the uncertainty of an unparseable sentence is dened as the number of operators applied successfully divided by the number of words.
</nextsent>
<nextsent>it is more natural to dene uncertainty scores in our study because of the avail bility of parse scores.
</nextsent>
<nextsent>(hwa, 2000; <papid> W00-1306 </papid>hwa, 2001) <papid> W01-0710 </papid>is related closely to our work in that both use entropy-based uncertainty scores, but hwa does not characterize the distribution of sample space.</nextsent>
<nextsent>knowing the distribution of sample space is important since uncertainty measure, if used alone for sample selection, will be likely to select outliers.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4439">
<title id=" P02-1016.xml">active learning for statistical natural language parsing </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>similar idea is also exploited in (mccallum and nigam, 1998) where authors use the divergence between the unigram word distributions of two documents to measure their difference.
</prevsent>
<prevsent>this distance enables us to cluster the active training set and sample is then selected and weighted based on both its uncertainty score and its density.
</prevsent>
</prevsection>
<citsent citstr=" N01-1023 ">
(sarkar, 2001) <papid> N01-1023 </papid>applied co-training to statistical parsing, where two component models are trained and the most condent parsing outputs of the existing model are incorporated into the next training.</citsent>
<aftsection>
<nextsent>this is different venue for reducing annotation work in that the current model output is directly used and no human annotation is assumed.
</nextsent>
<nextsent>(luoet al, 1999; luo, 2000) also aimed to making use of unlabeled data to improve statistical parsers by transforming model parameters.
</nextsent>
<nextsent>we have examined three entropy-based uncertainty scores to measure the usefulness?
</nextsent>
<nextsent>of sample to improving statistical model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4440">
<title id=" P04-1049.xml">paragraph word and coherence based approaches to sentence ranking a comparison of algorithm and human performance </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>most approaches also outperformed the commercially available msword summarizer.
</prevsent>
<prevsent>automatic generation of text summaries is natural language engineering application that has received considerable interest, particularly due to the ever-increasing volume of text information available through the internet.
</prevsent>
</prevsection>
<citsent citstr=" W97-0707 ">
the task of human generating summary generally involves three subtasks (brandow et al (1995); mitra et al (1997)): (<papid> W97-0707 </papid>1) understanding text; (2) ranking text pieces (sentences, paragraphs, phrases, etc.) for importance; (3) generating new text (the summary).</citsent>
<aftsection>
<nextsent>like most approaches to summarization, we are concerned with the second subtask (e.g. carlson et al (2001); goldstein et al (1999); gong &amp; liu (2001); jing et al (1998); luhn (1958); mitra et al (1997); <papid> W97-0707 </papid>sparck-jones &amp; sakai (2001); zechner (1996)).<papid> C96-2166 </papid></nextsent>
<nextsent>furthermore, we are concerned with obtaining generic rather than query-relevant importance rankings (cf.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4442">
<title id=" P04-1049.xml">paragraph word and coherence based approaches to sentence ranking a comparison of algorithm and human performance </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>automatic generation of text summaries is natural language engineering application that has received considerable interest, particularly due to the ever-increasing volume of text information available through the internet.
</prevsent>
<prevsent>the task of human generating summary generally involves three subtasks (brandow et al (1995); mitra et al (1997)): (<papid> W97-0707 </papid>1) understanding text; (2) ranking text pieces (sentences, paragraphs, phrases, etc.) for importance; (3) generating new text (the summary).</prevsent>
</prevsection>
<citsent citstr=" C96-2166 ">
like most approaches to summarization, we are concerned with the second subtask (e.g. carlson et al (2001); goldstein et al (1999); gong &amp; liu (2001); jing et al (1998); luhn (1958); mitra et al (1997); <papid> W97-0707 </papid>sparck-jones &amp; sakai (2001); zechner (1996)).<papid> C96-2166 </papid></citsent>
<aftsection>
<nextsent>furthermore, we are concerned with obtaining generic rather than query-relevant importance rankings (cf.
</nextsent>
<nextsent>goldstein et al (1999), radev et al (2002) <papid> J02-4001 </papid>for that distinction).</nextsent>
<nextsent>we evaluated different approaches to sentence ranking against human sentence rankings.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4444">
<title id=" P04-1049.xml">paragraph word and coherence based approaches to sentence ranking a comparison of algorithm and human performance </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>like most approaches to summarization, we are concerned with the second subtask (e.g. carlson et al (2001); goldstein et al (1999); gong &amp; liu (2001); jing et al (1998); luhn (1958); mitra et al (1997); <papid> W97-0707 </papid>sparck-jones &amp; sakai (2001); zechner (1996)).<papid> C96-2166 </papid></prevsent>
<prevsent>furthermore, we are concerned with obtaining generic rather than query-relevant importance rankings (cf.</prevsent>
</prevsection>
<citsent citstr=" J02-4001 ">
goldstein et al (1999), radev et al (2002) <papid> J02-4001 </papid>for that distinction).</citsent>
<aftsection>
<nextsent>we evaluated different approaches to sentence ranking against human sentence rankings.
</nextsent>
<nextsent>to obtain human sentence rankings, we asked people to read 15 texts from the wall street journal on wide variety of topics (e.g. economics, foreign and domestic affairs, political commentaries).
</nextsent>
<nextsent>for each of the sentences in the text, they provided ranking of how important that sentence is with respect to the content of the text, on an integer scale from 1 (not important) to 7 (very important).
</nextsent>
<nextsent>the approaches we evaluated are simple paragraph-based approach that serves as baseline, two word-based algorithms, and two coherence based approaches1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4447">
<title id=" P04-1049.xml">paragraph word and coherence based approaches to sentence ranking a comparison of algorithm and human performance </title>
<section> approaches to sentence ranking.  </section>
<citcontext>
<prevsection>
<prevsent>this set can be represented in graph, where the nodes represent sentences, and labeled directed arcs represent informational relations that hold between the sentences (cf.
</prevsent>
<prevsent>hobbs (1985)).
</prevsent>
</prevsection>
<citsent citstr=" C94-1056 ">
often, informational structures of texts have been represented as trees (e.g. carlson et al (2001), corston-oliver (1998), mann &amp; thompson (1988), ono et al (1994)).<papid> C94-1056 </papid></citsent>
<aftsection>
<nextsent>we will present one coherence-based approach that assumes trees as data structure for representing discourse structure, and one approach that assumes less constrained graphs.
</nextsent>
<nextsent>as we will show, the approach based on less constrained graphs performs better than the tree-based approach when compared to human sentence rankings.
</nextsent>
<nextsent>this section will discuss in more detail the data structures we used to represent discourse structure, as well as the algorithms used to calculate sentence importance, based on discourse structures.
</nextsent>
<nextsent>3.1 representing coherence structures.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4449">
<title id=" P04-1049.xml">paragraph word and coherence based approaches to sentence ranking a comparison of algorithm and human performance </title>
<section> coherence-based summarization revisited.  </section>
<citcontext>
<prevsection>
<prevsent>this section will discuss in more detail the data structures we used to represent discourse structure, as well as the algorithms used to calculate sentence importance, based on discourse structures.
</prevsent>
<prevsent>3.1 representing coherence structures.
</prevsent>
</prevsection>
<citsent citstr=" P96-1038 ">
3.1.1 discourse segments discourse segments can be defined as nonoverlapping spans of prosodic units (hirschberg &amp; nakatani (1996)), <papid> P96-1038 </papid>intentional units (grosz &amp; sidner (1986)), <papid> J86-3001 </papid>phrasal units (lascarides &amp; asher (1993)), or sentences (hobbs (1985)).</citsent>
<aftsection>
<nextsent>we adopted sentence unit-based definition of discourse segments for the coherence-based approach that assumes non-tree graphs.
</nextsent>
<nextsent>for the coherence-based approach that assumes trees, we used marcu (2000)s more fine-grained definition of discourse segments because we used the discourse trees from carlson et al (2002)s database of coherence annotated texts.
</nextsent>
<nextsent>3.1.2 kinds of coherence relations we assume set of coherence relations that is similar to that of hobbs (1985).
</nextsent>
<nextsent>below are examples of each coherence relation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4450">
<title id=" P04-1049.xml">paragraph word and coherence based approaches to sentence ranking a comparison of algorithm and human performance </title>
<section> coherence-based summarization revisited.  </section>
<citcontext>
<prevsection>
<prevsent>this section will discuss in more detail the data structures we used to represent discourse structure, as well as the algorithms used to calculate sentence importance, based on discourse structures.
</prevsent>
<prevsent>3.1 representing coherence structures.
</prevsent>
</prevsection>
<citsent citstr=" J86-3001 ">
3.1.1 discourse segments discourse segments can be defined as nonoverlapping spans of prosodic units (hirschberg &amp; nakatani (1996)), <papid> P96-1038 </papid>intentional units (grosz &amp; sidner (1986)), <papid> J86-3001 </papid>phrasal units (lascarides &amp; asher (1993)), or sentences (hobbs (1985)).</citsent>
<aftsection>
<nextsent>we adopted sentence unit-based definition of discourse segments for the coherence-based approach that assumes non-tree graphs.
</nextsent>
<nextsent>for the coherence-based approach that assumes trees, we used marcu (2000)s more fine-grained definition of discourse segments because we used the discourse trees from carlson et al (2002)s database of coherence annotated texts.
</nextsent>
<nextsent>3.1.2 kinds of coherence relations we assume set of coherence relations that is similar to that of hobbs (1985).
</nextsent>
<nextsent>below are examples of each coherence relation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4451">
<title id=" P04-1049.xml">paragraph word and coherence based approaches to sentence ranking a comparison of algorithm and human performance </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>approaches in order to test the tree-based approach, we took coherence trees for 15 texts from database of 385 texts from the wall street journal that were annotated for coherence (carlson et al (2002)).
</prevsent>
<prevsent>the database was independently annotated by six annotators.
</prevsent>
</prevsection>
<citsent citstr=" J96-2004 ">
inter-annotator agreement was determined for six pairs of two annotators each, resulting in kappa values (carletta (1996)) <papid> J96-2004 </papid>ranging from 0.62 to 0.82 for the whole database (carlson et al (2003)).</citsent>
<aftsection>
<nextsent>no kappa values for just the 15 texts we used were available.
</nextsent>
<nextsent>for the non-tree based approach, we used coherence graphs from database of 135 texts from the wall street journal and the ap newswire, annotated for coherence.
</nextsent>
<nextsent>each text was independently annotated by two annotators.
</nextsent>
<nextsent>for the 15 texts we used, kappa was 0.78, for the whole database, kappa was 0.84.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4454">
<title id=" P02-1034.xml">new ranking algorithms for parsing and tagging kernels over discrete structures and the voted perceptron </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>crucially, the algorithm scan be efficiently applied to exponential sized representations of parse trees, such as the all subtrees?
</prevsent>
<prevsent>(dop) representation described by (bod 1998), or representation tracking all sub-fragments of taggedsentence.
</prevsent>
</prevsection>
<citsent citstr=" W96-0214 ">
it might seem paradoxical to be able to efficiently learn and apply model with an exponential number of features.1 the key to our algorithms is the 1although see (goodman 1996) <papid> W96-0214 </papid>for an efficient algorithm for the dop model, which we discuss in section 7 of this paper.</citsent>
<aftsection>
<nextsent>kernel?
</nextsent>
<nextsent>trick ((cristianini and shawe-taylor 2000) discuss kernel methods at length).
</nextsent>
<nextsent>we describe how the inner product between feature vectors in these representations can be calculated efficiently using dynamic programming algorithms.
</nextsent>
<nextsent>this leads topolynomial time2 algorithms for training and applying the perceptron.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4456">
<title id=" P02-1034.xml">new ranking algorithms for parsing and tagging kernels over discrete structures and the voted perceptron </title>
<section> algorithms.  </section>
<citcontext>
<prevsection>
<prevsent>3.1 notation.
</prevsent>
<prevsent>this section formalizes the idea of linear models for parsing or tagging.
</prevsent>
</prevsection>
<citsent citstr=" P99-1069 ">
the method is related to the boosting approach to ranking problems (freund et al. 1998), the markov random field methods of (johnson et al 1999), <papid> P99-1069 </papid>and the boosting approaches for parsing in (collins 2000).</citsent>
<aftsection>
<nextsent>the set-up is as fol lows: training data is set of example input/output pairs.
</nextsent>
<nextsent>in parsing the training examples are !
</nextsent>
<nextsent> ffi#  %$ where each !  is sentence and each    is the correct tree for that sentence. we assume some way of enumerating set of candidates for particular sentence.
</nextsent>
<nextsent>we use   &amp; to denote the ( th candidate for the ) th sentence in training data, and *  !  +    ffi# -, .ff.ff.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4458">
<title id=" P02-1034.xml">new ranking algorithms for parsing and tagging kernels over discrete structures and the voted perceptron </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>6.1 parsing wall street journal text.
</prevsent>
<prevsent>we used the same dataset as that described in(collins 2000).
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
the penn wall street journal tree bank (marcus et al 1993) <papid> J93-2004 </papid>was used as training and test data.</citsent>
<aftsection>
<nextsent>sections 2-21 inclusive (around 40,000 sentences) were used as training data, section 23was used as the final test set.
</nextsent>
<nextsent>of the 40,000 training sentences, the first 36,000 were used to train the perceptron.
</nextsent>
<nextsent>the remaining 4,000 sentences we reused as development data, and for tuning parameters of the algorithm.
</nextsent>
<nextsent>model 2 of (collins 1999) wasused to parse both the training and test data, producing multiple hypotheses for each sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4459">
<title id=" P02-1034.xml">new ranking algorithms for parsing and tagging kernels over discrete structures and the voted perceptron </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the method shows u.c? absolute improvement in average precision and recall (from 88.2% to 88.8% on sentences ? wffu8uwords), 5.1% relative reduction in error.
</prevsent>
<prevsent>the boosting method of (collins 2000) showed89.6%/89.9% recall and precision on reranking approaches for the same datasets (sentences less than 100 words in length).
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
(charniak 2000) <papid> A00-2018 </papid>describes adifferent method which achieves very similar performance to (collins 2000).</citsent>
<aftsection>
<nextsent>(bod 2001) <papid> P01-1010 </papid>describes experiments giving 90.6%/90.8% recall and precision for sentences of less than 40 words in length, using the all-subtrees representation, but using very different algorithms and parameter estimation methods from the perceptron algorithms in this paper (see section 7 for more discussion).</nextsent>
<nextsent>6.2 named entity extraction.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4460">
<title id=" P02-1034.xml">new ranking algorithms for parsing and tagging kernels over discrete structures and the voted perceptron </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the boosting method of (collins 2000) showed89.6%/89.9% recall and precision on reranking approaches for the same datasets (sentences less than 100 words in length).
</prevsent>
<prevsent>(charniak 2000) <papid> A00-2018 </papid>describes adifferent method which achieves very similar performance to (collins 2000).</prevsent>
</prevsection>
<citsent citstr=" P01-1010 ">
(bod 2001) <papid> P01-1010 </papid>describes experiments giving 90.6%/90.8% recall and precision for sentences of less than 40 words in length, using the all-subtrees representation, but using very different algorithms and parameter estimation methods from the perceptron algorithms in this paper (see section 7 for more discussion).</citsent>
<aftsection>
<nextsent>6.2 named entity extraction.
</nextsent>
<nextsent>over period of year or so we have had over one million words of named-entity data annotated.
</nextsent>
<nextsent>thedata is drawn from web pages, the aim being to support question-answering system over web data.
</nextsent>
<nextsent>anumber of categories are annotated: the usual people, organization and location categories, as well asless frequent categories such as brand-names, scientific terms, event titles (such as concerts) and so on.as result, we created training set of 53,609 sentences (1,047,491 words), and test set of 14,717 sentences (291,898 words).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4463">
<title id=" P02-1034.xml">new ranking algorithms for parsing and tagging kernels over discrete structures and the voted perceptron </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we leave the recovery of the categories of entities to separate stage of processing.
</prevsent>
<prevsent>we evaluate different methods on the task through precision and recall.7 the problem can be framed as tagging task ? to tag each word as being either the start of an entity, continuation of an entity, or not to be part of an entity at all.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
as baseline model we used maximum entropy tagger, very similar to theone described in (ratnaparkhi 1996).<papid> W96-0213 </papid></citsent>
<aftsection>
<nextsent>maximum entropy taggers have been shown to be highly competitive on number of tagging tasks, such as partof-speech tagging (ratnaparkhi 1996), <papid> W96-0213 </papid>and named entity recognition (borthwick et. al 1998).<papid> W98-1118 </papid></nextsent>
<nextsent>thus the maximum-entropy tagger we used represents serious baseline for the task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4465">
<title id=" P02-1034.xml">new ranking algorithms for parsing and tagging kernels over discrete structures and the voted perceptron </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we evaluate different methods on the task through precision and recall.7 the problem can be framed as tagging task ? to tag each word as being either the start of an entity, continuation of an entity, or not to be part of an entity at all.
</prevsent>
<prevsent>as baseline model we used maximum entropy tagger, very similar to theone described in (ratnaparkhi 1996).<papid> W96-0213 </papid></prevsent>
</prevsection>
<citsent citstr=" W98-1118 ">
maximum entropy taggers have been shown to be highly competitive on number of tagging tasks, such as partof-speech tagging (ratnaparkhi 1996), <papid> W96-0213 </papid>and named entity recognition (borthwick et. al 1998).<papid> W98-1118 </papid></citsent>
<aftsection>
<nextsent>thus the maximum-entropy tagger we used represents serious baseline for the task.
</nextsent>
<nextsent>we used feature set which included the current, next, and previous word; the previous two tags; various capitalization and other features of the word being tagged (the full feature set is described in (collins 2002<papid> W02-1001 </papid>a)).</nextsent>
<nextsent>as baseline we trained model on the full 53,609 sentences of training data, and decoded the 14,717 sentences of test data using beam search 7if method proposes ? entities on the test set, and ? of these are correct then the precision of method is l?#f? . similarly, if ? is the number of entities in the human annotated version of the test set, then the recall is ?#6?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4466">
<title id=" P02-1034.xml">new ranking algorithms for parsing and tagging kernels over discrete structures and the voted perceptron </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>maximum entropy taggers have been shown to be highly competitive on number of tagging tasks, such as partof-speech tagging (ratnaparkhi 1996), <papid> W96-0213 </papid>and named entity recognition (borthwick et. al 1998).<papid> W98-1118 </papid></prevsent>
<prevsent>thus the maximum-entropy tagger we used represents serious baseline for the task.</prevsent>
</prevsection>
<citsent citstr=" W02-1001 ">
we used feature set which included the current, next, and previous word; the previous two tags; various capitalization and other features of the word being tagged (the full feature set is described in (collins 2002<papid> W02-1001 </papid>a)).</citsent>
<aftsection>
<nextsent>as baseline we trained model on the full 53,609 sentences of training data, and decoded the 14,717 sentences of test data using beam search 7if method proposes ? entities on the test set, and ? of these are correct then the precision of method is l?#f? . similarly, if ? is the number of entities in the human annotated version of the test set, then the recall is ?#6?
</nextsent>
<nextsent>. r max-ent 84.4% 86.3% 85.3% perc.
</nextsent>
<nextsent>86.1% 89.1% 87.6% imp.
</nextsent>
<nextsent>10.9% 20.4% 15.6%figure 5: results for the max-ent and voted perceptron methods.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4484">
<title id=" P02-1034.xml">new ranking algorithms for parsing and tagging kernels over discrete structures and the voted perceptron </title>
<section> relationship to previous work.  </section>
<citcontext>
<prevsection>
<prevsent>the method uses similar recur sion to the commonsub-trees recur sion described in this paper.
</prevsent>
<prevsent>goodmans method still leaves exact parsing under the model intractable (because of the need to sum over multiple derivations underlying the same tree), buthe gives an approximation to finding the most probable tree, which can be computed efficiently.
</prevsent>
</prevsection>
<citsent citstr=" J02-1005 ">
from theoretical point of view, it is difficult tofind motivation for the parameter estimation methods used by (bod 1998) ? see (johnson 2002) <papid> J02-1005 </papid>for discussion.</citsent>
<aftsection>
<nextsent>in contrast, the parameter estimation methods in this paper have strong theoretical basis (see (cristianini and shawe-taylor 2000) chapter 2 and (freund &amp; schapire 1999) for statistical theory underlying the perceptron).for related work on the voted perceptron algorithm applied to nlp problems, see (collins 2002<papid> W02-1001 </papid>a)and (collins 2002<papid> W02-1001 </papid>b).</nextsent>
<nextsent>(collins 2002<papid> W02-1001 </papid>a) describes experiments on the same named-entity dataset as inthis paper, but using explicit features rather than kernels.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4525">
<title id=" P04-1022.xml">collocation translation acquisition using monolingual corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a collocation is an arbitrary and recurrent word combination (benson, 1990).
</prevsent>
<prevsent>previous work in collocation acquisition varies in the kinds of collocations they detect.
</prevsent>
</prevsection>
<citsent citstr=" J93-1007 ">
these range from two word to multi-word, with or without syntactic structure (smadja 1993; <papid> J93-1007 </papid>lin, 1998; pearce, 2001; seretan et al 2003).</citsent>
<aftsection>
<nextsent>in this paper, collocation refers to recurrent word pair linked with certain syntactic relation.
</nextsent>
<nextsent>for instance,  solve, verb-object, problem  is collocation with syntactic relation verb-object.
</nextsent>
<nextsent>translation of collocations is difficult for nonnative speakers.
</nextsent>
<nextsent>many collocation translations are idiosyncratic in the sense that they are unpredictable by syntactic or semantic features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4526">
<title id=" P04-1022.xml">collocation translation acquisition using monolingual corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>or resolve ~problem?.
</prevsent>
<prevsent>automatically acquiring these collocation translations will be very useful for machine translation, cross language information retrieval, second language learning and many other nlp applications.
</prevsent>
</prevsection>
<citsent citstr=" J96-1001 ">
(smadja et al, 1996; <papid> J96-1001 </papid>gao et al, 2002; wu and zhou, 2003).<papid> P03-1016 </papid></citsent>
<aftsection>
<nextsent>some studies have been done for acquiring collocation translations using parallel corpora (smadja et al 1996; <papid> J96-1001 </papid>kupiec, 1993; <papid> P93-1003 </papid>echizen-ya et al., 2003).</nextsent>
<nextsent>these works implicitly assume that bilingual corpus on large scale can be obtained easily.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4527">
<title id=" P04-1022.xml">collocation translation acquisition using monolingual corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>or resolve ~problem?.
</prevsent>
<prevsent>automatically acquiring these collocation translations will be very useful for machine translation, cross language information retrieval, second language learning and many other nlp applications.
</prevsent>
</prevsection>
<citsent citstr=" P03-1016 ">
(smadja et al, 1996; <papid> J96-1001 </papid>gao et al, 2002; wu and zhou, 2003).<papid> P03-1016 </papid></citsent>
<aftsection>
<nextsent>some studies have been done for acquiring collocation translations using parallel corpora (smadja et al 1996; <papid> J96-1001 </papid>kupiec, 1993; <papid> P93-1003 </papid>echizen-ya et al., 2003).</nextsent>
<nextsent>these works implicitly assume that bilingual corpus on large scale can be obtained easily.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4529">
<title id=" P04-1022.xml">collocation translation acquisition using monolingual corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>automatically acquiring these collocation translations will be very useful for machine translation, cross language information retrieval, second language learning and many other nlp applications.
</prevsent>
<prevsent>(smadja et al, 1996; <papid> J96-1001 </papid>gao et al, 2002; wu and zhou, 2003).<papid> P03-1016 </papid></prevsent>
</prevsection>
<citsent citstr=" P93-1003 ">
some studies have been done for acquiring collocation translations using parallel corpora (smadja et al 1996; <papid> J96-1001 </papid>kupiec, 1993; <papid> P93-1003 </papid>echizen-ya et al., 2003).</citsent>
<aftsection>
<nextsent>these works implicitly assume that bilingual corpus on large scale can be obtained easily.
</nextsent>
<nextsent>however, despite efforts in compiling parallel corpora, sufficient amounts of such corpora are still unavailable.
</nextsent>
<nextsent>instead of heavily relying on bilingual corpora, this paper aims to solve the bottleneck in different way: to mine bilingual knowledge from structured monolingual corpora, which can be more easily obtained in large volume.
</nextsent>
<nextsent>our method is based on the observation that despite the great differences between chinese and english, the main dependency relations tend to have strong direct correspondence (zhou et al, 2001).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4531">
<title id=" P04-1022.xml">collocation translation acquisition using monolingual corpora </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>there has been much previous work done on monolingual collocation extraction.
</prevsent>
<prevsent>they can in general be classified into two types: window-based and syntax-based methods.
</prevsent>
</prevsection>
<citsent citstr=" J90-1003 ">
the former extracts collocations within fixed window (church and hanks 1990; <papid> J90-1003 </papid>smadja, 1993).<papid> J93-1007 </papid></citsent>
<aftsection>
<nextsent>the latter extracts collocations which have syntactic relationship (lin, 1998; seretan et al, 2003).
</nextsent>
<nextsent>the syntax-based method becomes more favorable with recent significant increases in parsing efficiency and accuracy.
</nextsent>
<nextsent>several metrics have been adopted to measure the association strength in collocation extraction.
</nextsent>
<nextsent>thanopoulos et al (2002) give comparative evaluations on these metrics.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4533">
<title id=" P04-1022.xml">collocation translation acquisition using monolingual corpora </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>several metrics have been adopted to measure the association strength in collocation extraction.
</prevsent>
<prevsent>thanopoulos et al (2002) give comparative evaluations on these metrics.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
most previous research in translation knowledge acquisition is based on parallel corpora (brown et al., 1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>as for collocation translation, smadja et al.
</nextsent>
<nextsent>(1996) implement system to extract collocation translations from parallel english french corpus.
</nextsent>
<nextsent>english collocations are first extracted using the xtract system, then corresponding french translations are sought based on the dice coefficient.
</nextsent>
<nextsent>echizen-ya et al (2003) propose method to extract bilingual collocations using recursive chain-link-type learning.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4536">
<title id=" P04-1022.xml">collocation translation acquisition using monolingual corpora </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>english collocations are first extracted using the xtract system, then corresponding french translations are sought based on the dice coefficient.
</prevsent>
<prevsent>echizen-ya et al (2003) propose method to extract bilingual collocations using recursive chain-link-type learning.
</prevsent>
</prevsection>
<citsent citstr=" C00-2135 ">
in addition to collocation translation, there is also some related work in acquiring phrase or term translations from parallel corpus (kupiec, 1993; <papid> P93-1003 </papid>yamamoto and matsumoto 2000).<papid> C00-2135 </papid></citsent>
<aftsection>
<nextsent>since large aligned bilingual corpora are hard to obtain, some research has been conducted to exploit translation knowledge from non-parallel corpora.
</nextsent>
<nextsent>their work is mainly on word level.
</nextsent>
<nextsent>koehn and knight (2000) presents an approach to estimating word translation probabilities using unrelated monolingual corpora with the em algorithm.
</nextsent>
<nextsent>the method exhibits promising results in selecting the right translation among several options provided by bilingual dictionary.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4537">
<title id=" P04-1022.xml">collocation translation acquisition using monolingual corpora </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>zhou et al.(2001) proposes method to simulate translation probability with cross language similarity score, which is estimated from monolingual corpora based on mutual information.
</prevsent>
<prevsent>the method achieves good results in word translation selection.
</prevsent>
</prevsection>
<citsent citstr=" J94-4003 ">
in addition, (dagan and itai, 1994) <papid> J94-4003 </papid>and (li, 2002) propose using two monolingual corpora for word sense disambiguation.</citsent>
<aftsection>
<nextsent>(fung, 1998) uses an ir approach to induce new word translations from comparable corpora.
</nextsent>
<nextsent>(rapp, 1999) <papid> P99-1067 </papid>and (koehn and knight, 2002) <papid> W02-0902 </papid>extract new word translations from non-parallel corpus.</nextsent>
<nextsent>(cao and li, 2002) <papid> C02-1011 </papid>acquire noun phrase translations by making use of web data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4538">
<title id=" P04-1022.xml">collocation translation acquisition using monolingual corpora </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in addition, (dagan and itai, 1994) <papid> J94-4003 </papid>and (li, 2002) propose using two monolingual corpora for word sense disambiguation.</prevsent>
<prevsent>(fung, 1998) uses an ir approach to induce new word translations from comparable corpora.</prevsent>
</prevsection>
<citsent citstr=" P99-1067 ">
(rapp, 1999) <papid> P99-1067 </papid>and (koehn and knight, 2002) <papid> W02-0902 </papid>extract new word translations from non-parallel corpus.</citsent>
<aftsection>
<nextsent>(cao and li, 2002) <papid> C02-1011 </papid>acquire noun phrase translations by making use of web data.</nextsent>
<nextsent>(wu and zhou, 2003) <papid> P03-1016 </papid>also make full use of large scale monolingual corpora and limited bilingual corpora for synonymous collocation extraction.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4539">
<title id=" P04-1022.xml">collocation translation acquisition using monolingual corpora </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in addition, (dagan and itai, 1994) <papid> J94-4003 </papid>and (li, 2002) propose using two monolingual corpora for word sense disambiguation.</prevsent>
<prevsent>(fung, 1998) uses an ir approach to induce new word translations from comparable corpora.</prevsent>
</prevsection>
<citsent citstr=" W02-0902 ">
(rapp, 1999) <papid> P99-1067 </papid>and (koehn and knight, 2002) <papid> W02-0902 </papid>extract new word translations from non-parallel corpus.</citsent>
<aftsection>
<nextsent>(cao and li, 2002) <papid> C02-1011 </papid>acquire noun phrase translations by making use of web data.</nextsent>
<nextsent>(wu and zhou, 2003) <papid> P03-1016 </papid>also make full use of large scale monolingual corpora and limited bilingual corpora for synonymous collocation extraction.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4540">
<title id=" P04-1022.xml">collocation translation acquisition using monolingual corpora </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>(fung, 1998) uses an ir approach to induce new word translations from comparable corpora.
</prevsent>
<prevsent>(rapp, 1999) <papid> P99-1067 </papid>and (koehn and knight, 2002) <papid> W02-0902 </papid>extract new word translations from non-parallel corpus.</prevsent>
</prevsection>
<citsent citstr=" C02-1011 ">
(cao and li, 2002) <papid> C02-1011 </papid>acquire noun phrase translations by making use of web data.</citsent>
<aftsection>
<nextsent>(wu and zhou, 2003) <papid> P03-1016 </papid>also make full use of large scale monolingual corpora and limited bilingual corpora for synonymous collocation extraction.</nextsent>
<nextsent>monolingual corpora in this section, we first describe the dependency correspondence assumption underlying our approach.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4544">
<title id=" P04-1022.xml">collocation translation acquisition using monolingual corpora </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the two words in triple cannot be translated separately.
</prevsent>
<prevsent>our current model cannot deal with this kind of non-compositional collocation translation.
</prevsent>
</prevsection>
<citsent citstr=" W97-0311 ">
melamed (1997) <papid> W97-0311 </papid>and lin (1999) <papid> P99-1041 </papid>have done some research on non compositional phrases discovery.</citsent>
<aftsection>
<nextsent>we will consider taking their work as complement to our model.
</nextsent>
<nextsent>6 conclusion and future work.
</nextsent>
<nextsent>this paper proposes novel method to train triple translation model and extract collocation translations from two independent monolingual corpora.
</nextsent>
<nextsent>evaluation results show that it outperforms the existing monolingual corpus based methods in triple translation, mainly due to the employment of em algorithm in cross language translation probability estimation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4545">
<title id=" P04-1022.xml">collocation translation acquisition using monolingual corpora </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the two words in triple cannot be translated separately.
</prevsent>
<prevsent>our current model cannot deal with this kind of non-compositional collocation translation.
</prevsent>
</prevsection>
<citsent citstr=" P99-1041 ">
melamed (1997) <papid> W97-0311 </papid>and lin (1999) <papid> P99-1041 </papid>have done some research on non compositional phrases discovery.</citsent>
<aftsection>
<nextsent>we will consider taking their work as complement to our model.
</nextsent>
<nextsent>6 conclusion and future work.
</nextsent>
<nextsent>this paper proposes novel method to train triple translation model and extract collocation translations from two independent monolingual corpora.
</nextsent>
<nextsent>evaluation results show that it outperforms the existing monolingual corpus based methods in triple translation, mainly due to the employment of em algorithm in cross language translation probability estimation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4546">
<title id=" P00-1070.xml">importance of pronominal anaphora resolution in question answering systems </title>
<section> our approach.  </section>
<citcontext>
<prevsection>
<prevsent>the lat corpus has been selected as test collection due to his high level of pronominal references.
</prevsent>
<prevsent>4.1 solving pronominal anaphora.
</prevsent>
</prevsection>
<citsent citstr=" P98-1064 ">
in this section, the nlp slot uni cation parser for anaphora resolution (supar) is brie described (ferrandez et al, 1999;ferrandez et al, 1998).<papid> P98-1064 </papid></citsent>
<aftsection>
<nextsent>supar architecture consists of three independent modules that interact with one other.
</nextsent>
<nextsent>these modules are lexical analysis, syntactic analysis, and are solution module for natural language processing problems.
</nextsent>
<nextsent>lexical analysis module.
</nextsent>
<nextsent>this module takes each sentence to parse as input, along with tool that provides the system with all the lexical information for each word of thesentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4547">
<title id=" P03-1066.xml">unsupervised learning of dependency structure for language modeling </title>
<section> dependency language model.  </section>
<citcontext>
<prevsection>
<prevsent>between wi and wj.
</prevsent>
<prevsent>the maximum likelihood estimation (mle) of p(dij) is given by ),( ),,()( ji ji ij wwc rwwc dp = (4) where c(wi, wj, r) is the number of times wi and wj have dependency relation in sentence in training data, and c(wi, wj) is the number of times wi and wj are seen in the same sentence.
</prevsent>
</prevsection>
<citsent citstr=" P96-1025 ">
to deal with the data sparseness problem of mle, we used the backoff estimation strategy similar to the one proposed in collins (1996), <papid> P96-1025 </papid>which backs off to estimates that use less conditioning context.</citsent>
<aftsection>
<nextsent>more specifically, we used the following three estimates: 4 4 4 32 32 23 1 1 1 ? ?
</nextsent>
<nextsent>= + + == eee , (5) where ),,(1 rwwc ji=?
</nextsent>
<nextsent>, ),(1 ji wwc=?
</nextsent>
<nextsent>, ),*,(2 rwc i=?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4548">
<title id=" P03-1066.xml">unsupervised learning of dependency structure for language modeling </title>
<section> dependency language model.  </section>
<citcontext>
<prevsection>
<prevsent>in our experiments, we found that the algorithm performs reasonably well on average, and its speed and simplicity make it better choice in dlm training where we need to parse large amount of training data iteratively, as described in section 3.3.
</prevsent>
<prevsent>the parsing algorithm is slightly modified version of that proposed in yuret (1998).
</prevsent>
</prevsection>
<citsent citstr=" P99-1059 ">
it reads sentence left to right; after reading each new word 2 for parsers that use bigram lexical dependencies, eisner and satta (1999) <papid> P99-1059 </papid>presents parsing algorithms that are o(n4) or o(n3).</citsent>
<aftsection>
<nextsent>we thank joshua goodman for pointing this out.
</nextsent>
<nextsent>wj, it tries to link wj to each of its previous words wi, and push the generated dependency dij into stack.
</nextsent>
<nextsent>when dependency crossing or cycle is detected in the stack, the dependency with the lowest dependency probability in conflict is eliminated.
</nextsent>
<nextsent>the algorithm is outlined in figures 2 and 3.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4549">
<title id=" P03-1066.xml">unsupervised learning of dependency structure for language modeling </title>
<section> dependency language model.  </section>
<citcontext>
<prevsection>
<prevsent>here p(wj|wj-2, wj-1, hj) is the word trigram probability given that wj is headword, p(wj|hj-1, hj) is the headword bigram probability, and 1, 2 ? [0,1] are the interpolation weights optimized on held-out data.
</prevsent>
<prevsent>we now come back to the estimate of the other three probabilities in equation (9).
</prevsent>
</prevsection>
<citsent citstr=" W02-1032 ">
following the work in gao et al (2002<papid> W02-1032 </papid>b), we used the unigram estimate for word category probabilities, (i.e., p(hj|?(wj-1, dj-1)) ? p(hj) and p(fj | ?(wj-1, dj-1)) ? p(fj)), and the standard trigram estimate for function word probability (i.e., p(wj |?(wj-1,dj-1),fj) ? p(wj | wj-2, wj-1, fj)).</citsent>
<aftsection>
<nextsent>let cj be the category of wj; we approximated p(cj)?
</nextsent>
<nextsent>p(wj|wj-2, wj-1, cj) by p(wj | wj-2, wj-1).
</nextsent>
<nextsent>by separating the estimates for the probabilities of headwords and function words, the final estimate is given below: p(wj | ?(wj-1, dj-1))= (13) )|()((( 121 jjj hwphp ??
</nextsent>
<nextsent>)),|()1( 2 rwwp ij??+ ),|()1( 121 ???+ jjj wwwp?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4553">
<title id=" P03-1066.xml">unsupervised learning of dependency structure for language modeling </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>the discussion includes: (1) the use of dlm as parser, (2) the definition of the mapping function ?, and (3) the method of unsupervised dependency structure acquisition.
</prevsent>
<prevsent>one basic approach to using linguistic structure for language modeling is to extend the conventional language model p(w) to p(w, t), where is parse tree of w. the extended model can then be used as parser to select the most likely parse by t* = arg maxt p(w, t).
</prevsent>
</prevsection>
<citsent citstr=" P01-1017 ">
many recent studies (e.g., chelba and jelinek, 2000; charniak, 2001; <papid> P01-1017 </papid>roark, 2001) <papid> J01-2004 </papid>adopt this approach.</citsent>
<aftsection>
<nextsent>similarly, dependency-based models (e.g., collins, 1996; <papid> P96-1025 </papid>chelba et al, 1997) use dependency structure of instead of parse tree t, where is extracted from syntactic trees.</nextsent>
<nextsent>both of these models can be called grammar-based models, in that they capture the syntactic structure of sentence, and the model parameters are estimated from syntactically annotated corpora such as the penn treebank.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4554">
<title id=" P03-1066.xml">unsupervised learning of dependency structure for language modeling </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>the discussion includes: (1) the use of dlm as parser, (2) the definition of the mapping function ?, and (3) the method of unsupervised dependency structure acquisition.
</prevsent>
<prevsent>one basic approach to using linguistic structure for language modeling is to extend the conventional language model p(w) to p(w, t), where is parse tree of w. the extended model can then be used as parser to select the most likely parse by t* = arg maxt p(w, t).
</prevsent>
</prevsection>
<citsent citstr=" J01-2004 ">
many recent studies (e.g., chelba and jelinek, 2000; charniak, 2001; <papid> P01-1017 </papid>roark, 2001) <papid> J01-2004 </papid>adopt this approach.</citsent>
<aftsection>
<nextsent>similarly, dependency-based models (e.g., collins, 1996; <papid> P96-1025 </papid>chelba et al, 1997) use dependency structure of instead of parse tree t, where is extracted from syntactic trees.</nextsent>
<nextsent>both of these models can be called grammar-based models, in that they capture the syntactic structure of sentence, and the model parameters are estimated from syntactically annotated corpora such as the penn treebank.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4557">
<title id=" P02-1018.xml">a simple pattern matching algorithm for recovering empty nodes and their antecedents </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>the patterns are minimal connected tree fragments containing an empty node and all other nodes co-indexed with it.
</prevsent>
<prevsent>this paper also proposes an evaluation procedure for empty node recovery procedures which is independent of most of the details of phrase structure, which makes it possible to compare the performance of empty node recovery on parser output with the empty node annotations in gold standard corpus.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
evaluating the algorithm on the output of charniaks parser (charniak, 2000) <papid> A00-2018 </papid>and the penn treebank (marcus et al, 1993) <papid> J93-2004 </papid>shows that the pattern matching algorithm does surprisingly well on the most frequently occuring types of empty nodes given its simplicity.</citsent>
<aftsection>
<nextsent>one of the main motivations for research on parsing is that syntactic structure provides important information for semantic interpretation; hence syntactic parsing is an important rst step in variety of?
</nextsent>
<nextsent>i would like to thank my colle ages in the brown laboratory for linguistic information processing (bllip) as well as michael collins for their advice.
</nextsent>
<nextsent>this research was supported by nsf awards dms 0074276 and itr iis 0085940.
</nextsent>
<nextsent>useful tasks.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4558">
<title id=" P02-1018.xml">a simple pattern matching algorithm for recovering empty nodes and their antecedents </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>the patterns are minimal connected tree fragments containing an empty node and all other nodes co-indexed with it.
</prevsent>
<prevsent>this paper also proposes an evaluation procedure for empty node recovery procedures which is independent of most of the details of phrase structure, which makes it possible to compare the performance of empty node recovery on parser output with the empty node annotations in gold standard corpus.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
evaluating the algorithm on the output of charniaks parser (charniak, 2000) <papid> A00-2018 </papid>and the penn treebank (marcus et al, 1993) <papid> J93-2004 </papid>shows that the pattern matching algorithm does surprisingly well on the most frequently occuring types of empty nodes given its simplicity.</citsent>
<aftsection>
<nextsent>one of the main motivations for research on parsing is that syntactic structure provides important information for semantic interpretation; hence syntactic parsing is an important rst step in variety of?
</nextsent>
<nextsent>i would like to thank my colle ages in the brown laboratory for linguistic information processing (bllip) as well as michael collins for their advice.
</nextsent>
<nextsent>this research was supported by nsf awards dms 0074276 and itr iis 0085940.
</nextsent>
<nextsent>useful tasks.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4560">
<title id=" P02-1018.xml">a simple pattern matching algorithm for recovering empty nodes and their antecedents </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>useful tasks.
</prevsent>
<prevsent>broad coverage syntactic parsers with good performance have recently become available (charniak, 2000; <papid> A00-2018 </papid>collins, 2000), but these typically produce as output parse tree that only encodes local syntactic information, i.e., tree that does not include any empty nodes?.</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
(collins (1997) <papid> P97-1003 </papid>discusses the recovery of one kind of empty node, viz.,wh-traces).</citsent>
<aftsection>
<nextsent>this paper describes simple pattern matching algorithm for post-processing the output of such parsers to add wide variety of empty nodes to its parse trees.
</nextsent>
<nextsent>empty nodes encode additional information about non-local dependencies between words and phrases which is important for the interpretation of constructions such as wh-questions, relative clauses, etc.1 for example, in the noun phrase the man sam likes the fact the man is interpreted as the direct object of the verb likes is indicated in penn treebank notation by empty nodes and co indexation as shown in figure 1 (see the next section for an explanation of why likes is tagged vbz rather than the standard vbz).the broad-coverage statistical parsers just mentioned produce simpler tree structure for such relative clause that contains neither of the empty nodes just indicated.
</nextsent>
<nextsent>rather, they produce trees of the kind shown in figure 2.
</nextsent>
<nextsent>unlike the tree depicted in figure 1, this type of tree does not explicitly represent the relationship between likes and the man. this paper presents an algorithm that takes as its input tree without empty nodes of the kind shown 1there are other ways to represent this information that do not require empty nodes; however, information about non-local dependencies must be represented somehow in order to interpret these constructions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4561">
<title id=" P02-1018.xml">a simple pattern matching algorithm for recovering empty nodes and their antecedents </title>
<section> a pattern-matching algorithm </section>
<citcontext>
<prevsection>
<prevsent>be regarded as an instance of the memory-basedlearning approach, where both the pattern extraction and pattern matching involve recursively visiting all of the subtrees of the tree concerned.
</prevsent>
<prevsent>it can also be regarded as kind of tree transformation, so the overall system architecture (including the parser)is an instance of the transform-detransform?
</prevsent>
</prevsection>
<citsent citstr=" J98-4004 ">
approach advocated by johnson (1998).<papid> J98-4004 </papid></citsent>
<aftsection>
<nextsent>the algorithm has two phases.
</nextsent>
<nextsent>the rst phase of the algorithm extracts the patterns from the trees in the training corpus.
</nextsent>
<nextsent>the second phase of the algorithm uses these extracted patterns to insert empty nodes and index their antecedents in trees that do not contain empty nodes.
</nextsent>
<nextsent>before the trees are used in the training and insertion phases they are passed through acommon preproccessing step, which re labels pre terminal nodes dominating auxiliary verbs and transitive verbs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4566">
<title id=" P04-2006.xml">istart paraphrase recognition </title>
<section> partial paraphrase with extra info..  </section>
<citcontext>
<prevsection>
<prevsent>a number of people have worked on paraphrasing such as the multilingual-translation recognition by smith (2003), the multilingual sentence generation by stede (1996), universal model paraphrasing using transformation by murata and isahara (2001), dirt ? using inference rules in question answering and information retrieval by lin and pantel (2001).
</prevsent>
<prevsent>due to the space limitation we will mention only few related works.
</prevsent>
</prevsection>
<citsent citstr=" W03-1604 ">
extrans (extracting answers from technical texts) by (molla et al 2003) and (rinaldi et al 2003) <papid> W03-1604 </papid>uses minimal logical forms (mlf) to represent both texts and questions.</citsent>
<aftsection>
<nextsent>they identify terminological paraphrases by using term-based hierarchy with their synonyms and variations; and syntactic paraphrases by constructing common representation for different types of syntactic variation via meaning postulates.
</nextsent>
<nextsent>absent paraphrase, they loosen the criteria by using hy ponyms, finding highest overlap of predicates, and simple keyword matching.
</nextsent>
<nextsent>barzilay &amp; lee (2003) <papid> N03-1003 </papid>also identify paraphrases in their paraphrased sentence generation system.</nextsent>
<nextsent>they first find different paraphrasing rules by clustering sentences incomparable corpora using n-gram word-overlap.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4567">
<title id=" P04-2006.xml">istart paraphrase recognition </title>
<section> partial paraphrase with extra info..  </section>
<citcontext>
<prevsection>
<prevsent>they identify terminological paraphrases by using term-based hierarchy with their synonyms and variations; and syntactic paraphrases by constructing common representation for different types of syntactic variation via meaning postulates.
</prevsent>
<prevsent>absent paraphrase, they loosen the criteria by using hy ponyms, finding highest overlap of predicates, and simple keyword matching.
</prevsent>
</prevsection>
<citsent citstr=" N03-1003 ">
barzilay &amp; lee (2003) <papid> N03-1003 </papid>also identify paraphrases in their paraphrased sentence generation system.</citsent>
<aftsection>
<nextsent>they first find different paraphrasing rules by clustering sentences incomparable corpora using n-gram word-overlap.
</nextsent>
<nextsent>then for each cluster, they use multi-sequence alignment to find intra-cluster paraphrasing rules: either morphosyntactic or lexical patterns.
</nextsent>
<nextsent>to identify inter cluster paraphrasing, they compare the slot values without considering word ordering.
</nextsent>
<nextsent>in our system sentences are represented by conceptual graphs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4568">
<title id=" P04-3006.xml">an automatic filter for non parallel texts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there is abundant literature on aligning parallel texts at the sentence level.
</prevsent>
<prevsent>to the best of our knowledge, all published methods happily mis align non parallel inputs, without so much as warning.
</prevsent>
</prevsection>
<citsent citstr=" J03-3002 ">
thereis also some recent work on distinguishing parallel texts from pairs of unrelated texts (resnik and smith, 2003).<papid> J03-3002 </papid></citsent>
<aftsection>
<nextsent>in this paper, we propose solution to the more difficult problem of distinguishing parallel texts from texts that are comparable but not parallel.definitions of comparable texts?
</nextsent>
<nextsent>vary in the literature.
</nextsent>
<nextsent>here we adopt definition that is most suitable for filtering smt training data: two texts are comparable?
</nextsent>
<nextsent>if they are not alignable at approximately the sentence level.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4572">
<title id=" P04-3006.xml">an automatic filter for non parallel texts </title>
<section> a modification to simr </section>
<citcontext>
<prevsection>
<prevsent>it then computes similarity score based on the maximum cardinality bipartite matching between the two halves.
</prevsent>
<prevsent>we chose to compare our method with tsim because we were interested in an approach that works with both marked up and plain text documents.
</prevsent>
</prevsection>
<citsent citstr=" J99-1003 ">
our work is based on modification of the simr bitext mapping algorithm (melamed, 1999).<papid> J99-1003 </papid></citsent>
<aftsection>
<nextsent>the simr algorithm attempts to construct piece wise linear approximation to the true bitext map (tbm) of bitext by greedily searching for small chains of points of correspondence.
</nextsent>
<nextsent>each chain forms one section of the approximation.
</nextsent>
<nextsent>simr uses two phase approach to generating chains.
</nextsent>
<nextsent>first, it generates set of potential points of correspondence within search rectangle.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4573">
<title id=" P04-3006.xml">an automatic filter for non parallel texts </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we performed line search for the best possible threshold for each parameter set.
</prevsent>
<prevsent>in our first two experiments we limited the points of correspondence to orthographic cognates.
</prevsent>
</prevsection>
<citsent citstr=" W95-0115 ">
we used the longest common sub sequence ratio (lcsr) to measure similarity (melamed, 1995).<papid> W95-0115 </papid></citsent>
<aftsection>
<nextsent>the lcsrratio is the length of the longest common subse quence of two tokens, divided by the length of the longer token.
</nextsent>
<nextsent>in our english-hindi experiments weused an english-hindi dictionary because the languages are written in different character sets, limiting the effectiveness of orthographic cognates.
</nextsent>
<nextsent>4.1 strand data.
</nextsent>
<nextsent>before evaluating our approach on the more difficult task of discriminating parallel texts from comparable texts, we compared it to previous approaches on the easier task of discriminating parallel texts from unrelated texts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4578">
<title id=" P04-3006.xml">an automatic filter for non parallel texts </title>
<section> conclusions.  </section>
<citcontext>
<prevsection>
<prevsent>we have demonstrated that simr-cl is effective on three language pairs, including two where no bilingual dictionary was available.
</prevsent>
<prevsent>in addition, wehave presented tentative evidence that the parameters of simr-cl are not very sensitive to particular language pairs or text genres on this task.our results suggest several new avenues for future research.
</prevsent>
</prevsection>
<citsent citstr=" C96-2129 ">
first, it would be useful to combine our method for filtering out non-parallel texts with methods for detecting omissions in translations (melamed, 1996).<papid> C96-2129 </papid></citsent>
<aftsection>
<nextsent>some of the translations found on the web today might be made more literal by deleting the untranslated parts.
</nextsent>
<nextsent>second, we seem to have discovered the existence of training data for ama chine learning approach to translation with summarization.
</nextsent>
<nextsent>third, our results suggest that the density of bitext map is highly correlated with its accuracy, and that this correlation is largely in variant across language pairs and text genres.
</nextsent>
<nextsent>if this is true,then it should be possible to train bitext mapping algorithms without any hand-aligned training data, by using map density as the objective function instead of rms error.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4579">
<title id=" P04-1078.xml">a unified framework for automatic evaluation using ngram cooccurrence statistics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the automatic evaluation metrics proposed to date for machine translation and automatic summarization are particular instances from the family of metrics we propose.
</prevsent>
<prevsent>we show that different members of the same family of metrics explain best the variations obtained with human evaluations, according to the application being evaluated (machine translation, automatic summarization, and automatic question answering) and the evaluation guidelines used by humans for evaluating such applications.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
with the introduction of the bleu metric for machine translation evaluation (papineni et al 2002), <papid> P02-1040 </papid>the advantages of doing automatic evaluation for various nlp applications have become increasingly appreciated: they allow for faster implement-evaluate cycles (by by-passing the human evaluation bottleneck), less variation in evaluation performance due to errors in human assessor judgment, and, not least, the possibility of hill-climbing on such metrics in order to improve system performance (och 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>recently, second proposal for automatic evaluation has come from the automatic summarization community (lin and hovy, 2003), <papid> N03-1020 </papid>with an automatic evaluation metric called rouge, inspired by bleu but twisted towards the specifics of the summarization task.</nextsent>
<nextsent>an automatic evaluation metric is said to be successful if it is shown to have high agreement with human-performed evaluations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4580">
<title id=" P04-1078.xml">a unified framework for automatic evaluation using ngram cooccurrence statistics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the automatic evaluation metrics proposed to date for machine translation and automatic summarization are particular instances from the family of metrics we propose.
</prevsent>
<prevsent>we show that different members of the same family of metrics explain best the variations obtained with human evaluations, according to the application being evaluated (machine translation, automatic summarization, and automatic question answering) and the evaluation guidelines used by humans for evaluating such applications.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
with the introduction of the bleu metric for machine translation evaluation (papineni et al 2002), <papid> P02-1040 </papid>the advantages of doing automatic evaluation for various nlp applications have become increasingly appreciated: they allow for faster implement-evaluate cycles (by by-passing the human evaluation bottleneck), less variation in evaluation performance due to errors in human assessor judgment, and, not least, the possibility of hill-climbing on such metrics in order to improve system performance (och 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>recently, second proposal for automatic evaluation has come from the automatic summarization community (lin and hovy, 2003), <papid> N03-1020 </papid>with an automatic evaluation metric called rouge, inspired by bleu but twisted towards the specifics of the summarization task.</nextsent>
<nextsent>an automatic evaluation metric is said to be successful if it is shown to have high agreement with human-performed evaluations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4581">
<title id=" P04-1078.xml">a unified framework for automatic evaluation using ngram cooccurrence statistics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we show that different members of the same family of metrics explain best the variations obtained with human evaluations, according to the application being evaluated (machine translation, automatic summarization, and automatic question answering) and the evaluation guidelines used by humans for evaluating such applications.
</prevsent>
<prevsent>with the introduction of the bleu metric for machine translation evaluation (papineni et al 2002), <papid> P02-1040 </papid>the advantages of doing automatic evaluation for various nlp applications have become increasingly appreciated: they allow for faster implement-evaluate cycles (by by-passing the human evaluation bottleneck), less variation in evaluation performance due to errors in human assessor judgment, and, not least, the possibility of hill-climbing on such metrics in order to improve system performance (och 2003).<papid> P03-1021 </papid></prevsent>
</prevsection>
<citsent citstr=" N03-1020 ">
recently, second proposal for automatic evaluation has come from the automatic summarization community (lin and hovy, 2003), <papid> N03-1020 </papid>with an automatic evaluation metric called rouge, inspired by bleu but twisted towards the specifics of the summarization task.</citsent>
<aftsection>
<nextsent>an automatic evaluation metric is said to be successful if it is shown to have high agreement with human-performed evaluations.
</nextsent>
<nextsent>human evaluations, however, are subject to specific guidelines given to the human assessors when performing the evaluation task; the variation in human judgment is therefore highly influenced by these guidelines.
</nextsent>
<nextsent>it follows that, in order for an automatic evaluation to agree with human performed evaluation, the evaluation metric used by the automatic method must be able to account, at least to some degree, for the bias induced by the human evaluation guidelines.
</nextsent>
<nextsent>none of the automatic evaluation methods proposed to date, however, explicitly accounts for the different criteria followed by the human assessors, as they are defined independently of the guidelines used in the human evaluations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4595">
<title id=" P04-1078.xml">a unified framework for automatic evaluation using ngram cooccurrence statistics </title>
<section> evaluating the evaluation framework.  </section>
<citcontext>
<prevsection>
<prevsent>automatic evaluation of factoid qa is often straightforward, as the number of correct answers is most of the time limited, and exhaustive lists of correct answers are available.
</prevsent>
<prevsent>when removing the factoid constraint, however, the set of possible answer to (complex, beyond factoid) question becomes un feasibly large, and consequently automatic evaluation becomes challenge.
</prevsent>
</prevsection>
<citsent citstr=" N04-1008 ">
in this section, we focus on an evaluation carried out in order to assess the performance of qa system for answering questions from the frequently-asked-question (faq) domain (soricut and brill, 2004).<papid> N04-1008 </papid></citsent>
<aftsection>
<nextsent>these are generally questions requiring more elaborated answer than simple factoid (e.g., questions such as: how does film qualify for an academy award??).
</nextsent>
<nextsent>in order to evaluate such system human performed evaluation was performed, in which 11 versions of the qa system (various modules were implemented using various algorithms) were separately evaluated.
</nextsent>
<nextsent>each version was evaluated by human evaluator, with no reference answer available.
</nextsent>
<nextsent>for this evaluation 115 test questions were used, and the human evaluator was asked to assess whether the proposed answer was correct, somehow related, or wrong.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4599">
<title id=" P03-1051.xml">language model based arabic word segmentation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we believe this is state-of-the-art performance and the algorithm can be used for many highly inflected languages provided that one can create small manually segmented corpus of the language of interest.
</prevsent>
<prevsent>morphologically rich languages like arabic present significant challenges to many natural language processing applications because word often conveys complex meanings decomposable into several morphemes (i.e. prefix, stem, suffix).
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
by segmenting words into morphemes, we can improve the performance of natural language systems including machine translation (brown et al 1993) <papid> J93-2003 </papid>and information retrieval (franz, m. and mccarley, s. 2002).</citsent>
<aftsection>
<nextsent>in this paper, we present general word segmentation algorithm for handling inflectional morphology capable of segmenting word into prefix*-stem suffix* sequence, using small manually segmented corpus and table of prefixes/suffixes of the language.
</nextsent>
<nextsent>we do not address arabic infix morphology where many stems correspond to the same root with various infix variations; we treat all the stems of common root as separate atomic units.
</nextsent>
<nextsent>the use of stem as morpheme (unit of meaning) is better suited than the use of root for the applications we are considering in information retrieval and machine translation (e.g. different stems of the same root translate into different english words.)
</nextsent>
<nextsent>examples of arabic words and their segmentation into prefix*-stem-suffix* are given in table 1, where  #  indicates morpheme being prefix, and  +  suffix.1 as 1 arabic is presented in both native and buckwalter.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4600">
<title id=" P03-1051.xml">language model based arabic word segmentation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in section 5, we present experimental results.
</prevsent>
<prevsent>in section 6, we summarize the paper.
</prevsent>
</prevsection>
<citsent citstr=" P96-1019 ">
our work adopts major components of the algorithm from (luo &amp; roukos 1996): <papid> P96-1019 </papid>language model (lm) parameter estimation from segmented corpus and input segmentation on the basis of lm probabilities.</citsent>
<aftsection>
<nextsent>however, our work diverges from their work in two crucial respects: (i) new technique of computing all possible segment ations of word into prefix*-stem-suffix* for decoding, and (ii) unsupervised algorithm for new stem acquisition based on stem candidate similarity to stems occurring in the training corpus.
</nextsent>
<nextsent>(darwish 2002) <papid> W02-0506 </papid>presents supervised technique which identifies the root of an arabic word by stripping away the prefix and the suffix of the word on the basis of manually acquired dictionary of word-root pairs and the likelihood that prefix and suffix would occur with the template from which the root is derived.</nextsent>
<nextsent>he reports 92.7% segmentation accuracy on 9,606 word evaluation corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4601">
<title id=" P03-1051.xml">language model based arabic word segmentation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>our work adopts major components of the algorithm from (luo &amp; roukos 1996): <papid> P96-1019 </papid>language model (lm) parameter estimation from segmented corpus and input segmentation on the basis of lm probabilities.</prevsent>
<prevsent>however, our work diverges from their work in two crucial respects: (i) new technique of computing all possible segment ations of word into prefix*-stem-suffix* for decoding, and (ii) unsupervised algorithm for new stem acquisition based on stem candidate similarity to stems occurring in the training corpus.</prevsent>
</prevsection>
<citsent citstr=" W02-0506 ">
(darwish 2002) <papid> W02-0506 </papid>presents supervised technique which identifies the root of an arabic word by stripping away the prefix and the suffix of the word on the basis of manually acquired dictionary of word-root pairs and the likelihood that prefix and suffix would occur with the template from which the root is derived.</citsent>
<aftsection>
<nextsent>he reports 92.7% segmentation accuracy on 9,606 word evaluation corpus.
</nextsent>
<nextsent>his technique pre-supposes at most one prefix and one suffix per stem regardless of the actual number and meanings of prefixes/suffixes associated with the stem.
</nextsent>
<nextsent>(beesley 1996) <papid> C96-1017 </papid>presents finite-state morphological analyzer for arabic, which displays the root, pattern, and prefixes/suffixes.</nextsent>
<nextsent>the analyses are based on manually acquired lexicons and rules.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4602">
<title id=" P03-1051.xml">language model based arabic word segmentation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>he reports 92.7% segmentation accuracy on 9,606 word evaluation corpus.
</prevsent>
<prevsent>his technique pre-supposes at most one prefix and one suffix per stem regardless of the actual number and meanings of prefixes/suffixes associated with the stem.
</prevsent>
</prevsection>
<citsent citstr=" C96-1017 ">
(beesley 1996) <papid> C96-1017 </papid>presents finite-state morphological analyzer for arabic, which displays the root, pattern, and prefixes/suffixes.</citsent>
<aftsection>
<nextsent>the analyses are based on manually acquired lexicons and rules.
</nextsent>
<nextsent>although his analyzer is comprehensive in the types of knowledge it presents, it has been criticized for their extensive development time and lack of robustness, cf.
</nextsent>
<nextsent>(darwish 2002).<papid> W02-0506 </papid></nextsent>
<nextsent>marking prefix with  #  and suffix with  +  will be adopted throughout the paper.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4604">
<title id=" P03-1051.xml">language model based arabic word segmentation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>(darwish 2002).<papid> W02-0506 </papid></prevsent>
<prevsent>marking prefix with  #  and suffix with  +  will be adopted throughout the paper.</prevsent>
</prevsection>
<citsent citstr=" P00-1027 ">
(yarowsky and wicentowsky 2000) <papid> P00-1027 </papid>presents minimally supervised morphological analysis with performance of over 99.2% accuracy for the 3,888 past-tense test cases in english.</citsent>
<aftsection>
<nextsent>the core algorithm lies in the estimation of probabilistic alignment between inflected forms and root forms.
</nextsent>
<nextsent>the probability estimation is based on the lemma alignment by frequency ratio similarity among different inflectional forms derived from the same lemma, given table of inflectional parts-of-speech, list of the canonical suffixes for each part of speech, and list of the candidate noun, verb and adjective roots of the language.
</nextsent>
<nextsent>their algorithm does not handle multiple affixes per word.
</nextsent>
<nextsent>(goldsmith 2000) presents an unsupervised technique based on the expectation maximization algorithm and minimum description length to segment exactly one suffix per word, resulting in an f-score of 81.8 for suffix identification in english according to (schone and jurafsky 2001).<papid> N01-1024 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4605">
<title id=" P03-1051.xml">language model based arabic word segmentation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the probability estimation is based on the lemma alignment by frequency ratio similarity among different inflectional forms derived from the same lemma, given table of inflectional parts-of-speech, list of the canonical suffixes for each part of speech, and list of the candidate noun, verb and adjective roots of the language.
</prevsent>
<prevsent>their algorithm does not handle multiple affixes per word.
</prevsent>
</prevsection>
<citsent citstr=" N01-1024 ">
(goldsmith 2000) presents an unsupervised technique based on the expectation maximization algorithm and minimum description length to segment exactly one suffix per word, resulting in an f-score of 81.8 for suffix identification in english according to (schone and jurafsky 2001).<papid> N01-1024 </papid></citsent>
<aftsection>
<nextsent>(schone and jurafsky 2001) <papid> N01-1024 </papid>proposes an unsupervised algorithm capable of automatically inducing the morphology of inflectional languages using only text corpora.</nextsent>
<nextsent>their algorithm combines cues from orthography, semantics, and contextual information to induce morphological relationships in german, dutch, and english, among others.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4609">
<title id=" P03-1068.xml">towards a resource for lexical semantics a large german corpus with extensive semantic annotation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>on this basis, we discuss the problems of vagueness and ambiguity in semantic annotation.
</prevsent>
<prevsent>corpus-based methods for syntactic learning and processing are well-established in computational linguistics.
</prevsent>
</prevsection>
<citsent citstr=" H94-1020 ">
there are comprehensive and carefullyworked-out corpus resources available for number of languages, e.g. the penn treebank (marcus et al., 1994) <papid> H94-1020 </papid>for english or the negra corpus (skutet al, 1998) for german.</citsent>
<aftsection>
<nextsent>in semantics, the situation is different: semantic corpus annotation is only in its initial stages, and currently only few,mostly small, corpora are available.
</nextsent>
<nextsent>semantic annotation has predominantly concentrated on word senses, e.g. in the senseval initiative (kilgarriff,2001), notable exception being the prague tree bank (hajicova?, 1998) . as consequence, most recent work in corpus-based semantics has taken an unsupervised approach, relying on statistical methods to extract semantic regularities from raw corpora, often using information from ontologies like wordnet (miller et al, 1990).meanwhile, the lack of large, domain independent lexica providing word-semantic information is one of the most serious bottlenecks for language technology.
</nextsent>
<nextsent>to train tools for the acquisition of semantic information for such lexica, large, extensively annotated resources are necessary.
</nextsent>
<nextsent>in this paper, we present current work of the salsa (saarbrucken lexical semantics annotation and analysis) project, whose aim is to provide such resource and to investigate efficient methods for its utilisation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4610">
<title id=" P03-1068.xml">towards a resource for lexical semantics a large german corpus with extensive semantic annotation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we present current work of the salsa (saarbrucken lexical semantics annotation and analysis) project, whose aim is to provide such resource and to investigate efficient methods for its utilisation.
</prevsent>
<prevsent>in the current project phase, the focus of our research and the backbone of the annotation are semantic role relations.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
more specifically, our role annotation is based on the berkeley framenet project (baker et al, 1998; <papid> P98-1013 </papid>johnson et al, 2002).</citsent>
<aftsection>
<nextsent>in addition, we selectively annotate word senses and anaphoric links.
</nextsent>
<nextsent>the tiger corpus(brants et al, 2002), 1.5m word german newspaper corpus, serves as sound syntactic basis.besides the sparse data problem, the most serious problem for corpus-based lexical semantics is the lack of specificity of the data: word meaning is notoriously ambiguous, vague, and subject to contextual variance.
</nextsent>
<nextsent>the problem has been recognised and discussed in connection with the senseval task (kilgarriff and rosenzweig, 2000).
</nextsent>
<nextsent>annotation of frame semantic roles compounds the problem asit combines word sense assignment with the assignment of semantic roles, task that introduces vagueness and ambiguity problems of its own.the problem can be alleviated by choosing suit able resource as annotation basis.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4611">
<title id=" P04-1023.xml">statistical machine translation with word and sentence aligned parallel corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>on the verb mobil dataset, we attain 38% reduction in the alignment error rate and higher bleu score with half as many training examples.
</prevsent>
<prevsent>we discus show varying the ratio of word-aligned to sentence aligned data affects the expected performance gain.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
machine translation systems based on probabilistic translation models (brown et al, 1993) <papid> J93-2003 </papid>are generally trained using sentence-aligned parallel corpora.</citsent>
<aftsection>
<nextsent>for many language pairs these exist in abundant quantities.
</nextsent>
<nextsent>however for new domains or uncommon language pairs extensive parallel corpora are often hard to come by.
</nextsent>
<nextsent>two factors could increase the performance of statistical machine translation for new language pairs and domains: reduction in the cost of creating new training data, and the development ofmore efficient methods for exploiting existing training data.
</nextsent>
<nextsent>approaches such as harvesting parallel corpora from the web (resnik and smith, 2003) <papid> J03-3002 </papid>address the creation of data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4612">
<title id=" P04-1023.xml">statistical machine translation with word and sentence aligned parallel corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however for new domains or uncommon language pairs extensive parallel corpora are often hard to come by.
</prevsent>
<prevsent>two factors could increase the performance of statistical machine translation for new language pairs and domains: reduction in the cost of creating new training data, and the development ofmore efficient methods for exploiting existing training data.
</prevsent>
</prevsection>
<citsent citstr=" J03-3002 ">
approaches such as harvesting parallel corpora from the web (resnik and smith, 2003) <papid> J03-3002 </papid>address the creation of data.</citsent>
<aftsection>
<nextsent>we take the second,complementary approach.
</nextsent>
<nextsent>we address the problem of efficiently exploiting existing parallel corpora by adding explicit word-level alignments between number of the sentence pairs in the training corpus.
</nextsent>
<nextsent>we modify the standard parameter estimation procedure for ibm models and hmm variants so that they can exploit these additional word level alignments.
</nextsent>
<nextsent>our approach uses both word- and sentence-level alignments for training material.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4618">
<title id=" P04-1023.xml">statistical machine translation with word and sentence aligned parallel corpora </title>
<section> experimental design.  </section>
<citcontext>
<prevsection>
<prevsent>this means that can be maximized while essentially ignoring the likelihood of the word-aligned data.
</prevsent>
<prevsent>since we believe that the explicit word-alignment information will be highly effective in distinguishing plausible alignments in the corpus as whole, we expect to see benefits by setting ? to amplify the contribution of the word aligned dataset particularly when this is relatively small portion of the corpus.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
to perform our experiments with word-level aligne ments we modified giza++, an existing and freely available implementation of the ibm models andhmm variants (och and ney, 2003).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>our modifications involved circumventing the e-step for sentences which had word-level alignments and incorporating these observed alignment statistics in the m-step.
</nextsent>
<nextsent>the observed and expected statistics were weighted accordingly by ? and (1?
</nextsent>
<nextsent>?) respectively as were their contributions to the mixed log likeli hood.in order to measure the accuracy of the predictions that the statistical translation models make under our various experimental settings, we choose the alignment error rate (aer) metric, which is defined in och and ney (2003).<papid> J03-1002 </papid></nextsent>
<nextsent>we also investigated whether improved aer leads to improved translation quality.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4621">
<title id=" P04-1023.xml">statistical machine translation with word and sentence aligned parallel corpora </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>a more significant result is whether it leads to improved translation quality.
</prevsent>
<prevsent>in order to test that our improved parameter estimates lead to better translation quality, we used state-of-the-art phrase-based decoder to translate held out set of german sentences into english.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>we trained language model aer when when ratio ? = standard mle ? = .9 0.1 11.73 9.40 0.2 10.89 8.66 0.3 10.23 8.13 0.5 8.65 8.19 0.7 8.29 8.03 0.9 7.78 7.78 table 5: the effect of weighting word-aligned data more heavily that its proportion in the training data (corpus size 16000 sentence pairs)using the 34,000 english sentences from the training set.
</nextsent>
<nextsent>table 4 shows that using word-aligned data leadsto better translation quality than using sentence aligned data.
</nextsent>
<nextsent>particularly, significantly less data is needed to achieve high bleu score when using word alignments.
</nextsent>
<nextsent>training on corpus of 8,000 sentence pairs with word alignments results in higher bleu score than when training on corpus of 16,000 sentence pairs without word alignments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4623">
<title id=" P04-1023.xml">statistical machine translation with word and sentence aligned parallel corpora </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>och and ney (2003) <papid> J03-1002 </papid>is the most extensive analysis to date of how many different factors contribute towards improved alignments error rates, but the inclusion of word-alignments is not considered.</prevsent>
<prevsent>och and ney do not give any direct analysis of how improved word alignments accuracy contributes toward better translation quality as we do here.</prevsent>
</prevsection>
<citsent citstr=" W03-0301 ">
mihalcea and pedersen (2003) <papid> W03-0301 </papid>described shared task where the goal was to achieve the best aer.</citsent>
<aftsection>
<nextsent>a number of different methods were tried, but none of them used word-level alignments.
</nextsent>
<nextsent>since the best performing system used an unmodified version ofgiza++, we would expected that our modifed version would show enhanced performance.
</nextsent>
<nextsent>naturally this would need to be tested in future work.melamed (1998) describes the process of manually creating large set of word-level alignments of sentences in parallel text.
</nextsent>
<nextsent>nigam et al (2000) described the use of weight to balance the respective contributions of labeled and unlabeled data to mixed likelihood function.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4624">
<title id=" P04-1023.xml">statistical machine translation with word and sentence aligned parallel corpora </title>
<section> discussion and future work.  </section>
<citcontext>
<prevsection>
<prevsent>this holds even when using noisy word alignments such as our automatically created set.
</prevsent>
<prevsent>one should take our research into account when trying to efficiently create statistical machine translation system for language pair for which parallel corpus is not available.
</prevsent>
</prevsection>
<citsent citstr=" W01-1409 ">
germann (2001)<papid> W01-1409 </papid>describes the cost of building tamil-english parallel corpus from scratch, and finds that using professional translations is prohibitively high.</citsent>
<aftsection>
<nextsent>in our experience it is quicker to manually word-align translated sentence pairs than to translate sentence, and word-level alignment can be done by someone who might not be fluent enough to produce translations.
</nextsent>
<nextsent>it might therefore be possible to achieve higher performance at fraction of the cost by hiring nonprofessional produce word-alignments after limited set of sentences have been translated.
</nextsent>
<nextsent>we plan to investigate whether it is feasible to use active learning to select which examples willbe most useful when aligned at the word-level.
</nextsent>
<nextsent>section 5.4 shows that word-aligning fraction of sentence pairs in training corpus, rather than the entire training corpus can still yield most of the benefits described in this paper.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4625">
<title id=" N12-1086.xml">graph based lexicon expansion with sparsityinducing penalties </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>compared to standard graph-based learning methods, for two lexicon expansion problems, our approach produces significantly smaller lexicons and obtains better predictive performance.
</prevsent>
<prevsent>semi-supervised learning (ssl) is attractive for the learning of complex phenomena, for example, linguistic structure, where data annotation is expensive.
</prevsent>
</prevsection>
<citsent citstr=" P09-1056 ">
natural language processing applications have benefited from various ssl techniques, such as distributional word representations (huang and yates, 2009; <papid> P09-1056 </papid>turian et al, 2010; <papid> P10-1040 </papid>dhillon et al, 2011), self-training (mcclosky et al, 2006), <papid> N06-1020 </papid>and entropy regularization (jiao et al, 2006; <papid> P06-1027 </papid>smith and eisner, 2007).<papid> D07-1070 </papid></citsent>
<aftsection>
<nextsent>in this paper, we focus on semi-supervised learning that uses graph constructed from labeled and unlabeled data.
</nextsent>
<nextsent>this framework, graph-based sslsee bengio et al (2006) and zhu (2008) for introductory material on this topic has been widely used and has been shown to perform better than several other semi-supervised algorithms on benchmark datasets (chapelle et al, 2006, ch.
</nextsent>
<nextsent>21).
</nextsent>
<nextsent>the method constructs graph where small portion of vertices correspond to labeled instances, and the rest are unlabeled.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4626">
<title id=" N12-1086.xml">graph based lexicon expansion with sparsityinducing penalties </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>compared to standard graph-based learning methods, for two lexicon expansion problems, our approach produces significantly smaller lexicons and obtains better predictive performance.
</prevsent>
<prevsent>semi-supervised learning (ssl) is attractive for the learning of complex phenomena, for example, linguistic structure, where data annotation is expensive.
</prevsent>
</prevsection>
<citsent citstr=" P10-1040 ">
natural language processing applications have benefited from various ssl techniques, such as distributional word representations (huang and yates, 2009; <papid> P09-1056 </papid>turian et al, 2010; <papid> P10-1040 </papid>dhillon et al, 2011), self-training (mcclosky et al, 2006), <papid> N06-1020 </papid>and entropy regularization (jiao et al, 2006; <papid> P06-1027 </papid>smith and eisner, 2007).<papid> D07-1070 </papid></citsent>
<aftsection>
<nextsent>in this paper, we focus on semi-supervised learning that uses graph constructed from labeled and unlabeled data.
</nextsent>
<nextsent>this framework, graph-based sslsee bengio et al (2006) and zhu (2008) for introductory material on this topic has been widely used and has been shown to perform better than several other semi-supervised algorithms on benchmark datasets (chapelle et al, 2006, ch.
</nextsent>
<nextsent>21).
</nextsent>
<nextsent>the method constructs graph where small portion of vertices correspond to labeled instances, and the rest are unlabeled.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4627">
<title id=" N12-1086.xml">graph based lexicon expansion with sparsityinducing penalties </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>compared to standard graph-based learning methods, for two lexicon expansion problems, our approach produces significantly smaller lexicons and obtains better predictive performance.
</prevsent>
<prevsent>semi-supervised learning (ssl) is attractive for the learning of complex phenomena, for example, linguistic structure, where data annotation is expensive.
</prevsent>
</prevsection>
<citsent citstr=" N06-1020 ">
natural language processing applications have benefited from various ssl techniques, such as distributional word representations (huang and yates, 2009; <papid> P09-1056 </papid>turian et al, 2010; <papid> P10-1040 </papid>dhillon et al, 2011), self-training (mcclosky et al, 2006), <papid> N06-1020 </papid>and entropy regularization (jiao et al, 2006; <papid> P06-1027 </papid>smith and eisner, 2007).<papid> D07-1070 </papid></citsent>
<aftsection>
<nextsent>in this paper, we focus on semi-supervised learning that uses graph constructed from labeled and unlabeled data.
</nextsent>
<nextsent>this framework, graph-based sslsee bengio et al (2006) and zhu (2008) for introductory material on this topic has been widely used and has been shown to perform better than several other semi-supervised algorithms on benchmark datasets (chapelle et al, 2006, ch.
</nextsent>
<nextsent>21).
</nextsent>
<nextsent>the method constructs graph where small portion of vertices correspond to labeled instances, and the rest are unlabeled.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4628">
<title id=" N12-1086.xml">graph based lexicon expansion with sparsityinducing penalties </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>compared to standard graph-based learning methods, for two lexicon expansion problems, our approach produces significantly smaller lexicons and obtains better predictive performance.
</prevsent>
<prevsent>semi-supervised learning (ssl) is attractive for the learning of complex phenomena, for example, linguistic structure, where data annotation is expensive.
</prevsent>
</prevsection>
<citsent citstr=" P06-1027 ">
natural language processing applications have benefited from various ssl techniques, such as distributional word representations (huang and yates, 2009; <papid> P09-1056 </papid>turian et al, 2010; <papid> P10-1040 </papid>dhillon et al, 2011), self-training (mcclosky et al, 2006), <papid> N06-1020 </papid>and entropy regularization (jiao et al, 2006; <papid> P06-1027 </papid>smith and eisner, 2007).<papid> D07-1070 </papid></citsent>
<aftsection>
<nextsent>in this paper, we focus on semi-supervised learning that uses graph constructed from labeled and unlabeled data.
</nextsent>
<nextsent>this framework, graph-based sslsee bengio et al (2006) and zhu (2008) for introductory material on this topic has been widely used and has been shown to perform better than several other semi-supervised algorithms on benchmark datasets (chapelle et al, 2006, ch.
</nextsent>
<nextsent>21).
</nextsent>
<nextsent>the method constructs graph where small portion of vertices correspond to labeled instances, and the rest are unlabeled.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4629">
<title id=" N12-1086.xml">graph based lexicon expansion with sparsityinducing penalties </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>compared to standard graph-based learning methods, for two lexicon expansion problems, our approach produces significantly smaller lexicons and obtains better predictive performance.
</prevsent>
<prevsent>semi-supervised learning (ssl) is attractive for the learning of complex phenomena, for example, linguistic structure, where data annotation is expensive.
</prevsent>
</prevsection>
<citsent citstr=" D07-1070 ">
natural language processing applications have benefited from various ssl techniques, such as distributional word representations (huang and yates, 2009; <papid> P09-1056 </papid>turian et al, 2010; <papid> P10-1040 </papid>dhillon et al, 2011), self-training (mcclosky et al, 2006), <papid> N06-1020 </papid>and entropy regularization (jiao et al, 2006; <papid> P06-1027 </papid>smith and eisner, 2007).<papid> D07-1070 </papid></citsent>
<aftsection>
<nextsent>in this paper, we focus on semi-supervised learning that uses graph constructed from labeled and unlabeled data.
</nextsent>
<nextsent>this framework, graph-based sslsee bengio et al (2006) and zhu (2008) for introductory material on this topic has been widely used and has been shown to perform better than several other semi-supervised algorithms on benchmark datasets (chapelle et al, 2006, ch.
</nextsent>
<nextsent>21).
</nextsent>
<nextsent>the method constructs graph where small portion of vertices correspond to labeled instances, and the rest are unlabeled.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4630">
<title id=" N12-1086.xml">graph based lexicon expansion with sparsityinducing penalties </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the method constructs graph where small portion of vertices correspond to labeled instances, and the rest are unlabeled.
</prevsent>
<prevsent>pairs of vertices are connected by weighted edges denoting the similarity between thepair.
</prevsent>
</prevsection>
<citsent citstr=" D08-1114 ">
traditionally, markov random walks (szummer and jaakkola, 2001; baluja et al, 2008) or optimization of loss function based on smoothness properties of the graph (corduneanu and jaakkola, 2003; zhu et al, 2003; subramanya and bilmes, 2008, <papid> D08-1114 </papid>inter alia) are performed to propagate labels from the labeled vertices to the unlabeled ones.in this work, we are interested in multi-class generalizations of graph-propagation algorithms suitable for nlp applications, where each graph vertex can assume one or more out of many possible labels (talukdar and crammer, 2009; subramanya and bilmes, 2008, <papid> D08-1114 </papid>2009).</citsent>
<aftsection>
<nextsent>for us, graph vertices correspond to natural language types (not tokens) and undirected edges between them are weighted using similarity metric.
</nextsent>
<nextsent>recently, this setup has been used to learn soft labels on natural language types (say,word n-grams or syntactically disambiguated pred icates) from seed data, resulting in large but noisy lexicons, which are used to constrain structured prediction models.
</nextsent>
<nextsent>applications have ranged from domain adaptation of part-of-speech (pos) taggers (subramanya et al, 2010), <papid> D10-1017 </papid>unsupervised learning ofpos taggers by using bilingual graph-based projections (das and petrov, 2011), <papid> P11-1061 </papid>and shallow semantic parsing for unknown predicates (das and smith,2011).<papid> P11-1144 </papid></nextsent>
<nextsent>however, none of the above captured the empirical fact that only few categories typically associate with given type (vertex).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4635">
<title id=" N12-1086.xml">graph based lexicon expansion with sparsityinducing penalties </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for us, graph vertices correspond to natural language types (not tokens) and undirected edges between them are weighted using similarity metric.
</prevsent>
<prevsent>recently, this setup has been used to learn soft labels on natural language types (say,word n-grams or syntactically disambiguated pred icates) from seed data, resulting in large but noisy lexicons, which are used to constrain structured prediction models.
</prevsent>
</prevsection>
<citsent citstr=" D10-1017 ">
applications have ranged from domain adaptation of part-of-speech (pos) taggers (subramanya et al, 2010), <papid> D10-1017 </papid>unsupervised learning ofpos taggers by using bilingual graph-based projections (das and petrov, 2011), <papid> P11-1061 </papid>and shallow semantic parsing for unknown predicates (das and smith,2011).<papid> P11-1144 </papid></citsent>
<aftsection>
<nextsent>however, none of the above captured the empirical fact that only few categories typically associate with given type (vertex).
</nextsent>
<nextsent>take the case of pos tagging: subramanya et al (2010) <papid> D10-1017 </papid>construct agraph over trigram types as vertices, with 45 possible tags for the middle word of trigram as the 677 label set for each vertex.</nextsent>
<nextsent>it is empirically observed that contextual ized word types can assume very few (most often, one) pos tags.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4636">
<title id=" N12-1086.xml">graph based lexicon expansion with sparsityinducing penalties </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for us, graph vertices correspond to natural language types (not tokens) and undirected edges between them are weighted using similarity metric.
</prevsent>
<prevsent>recently, this setup has been used to learn soft labels on natural language types (say,word n-grams or syntactically disambiguated pred icates) from seed data, resulting in large but noisy lexicons, which are used to constrain structured prediction models.
</prevsent>
</prevsection>
<citsent citstr=" P11-1061 ">
applications have ranged from domain adaptation of part-of-speech (pos) taggers (subramanya et al, 2010), <papid> D10-1017 </papid>unsupervised learning ofpos taggers by using bilingual graph-based projections (das and petrov, 2011), <papid> P11-1061 </papid>and shallow semantic parsing for unknown predicates (das and smith,2011).<papid> P11-1144 </papid></citsent>
<aftsection>
<nextsent>however, none of the above captured the empirical fact that only few categories typically associate with given type (vertex).
</nextsent>
<nextsent>take the case of pos tagging: subramanya et al (2010) <papid> D10-1017 </papid>construct agraph over trigram types as vertices, with 45 possible tags for the middle word of trigram as the 677 label set for each vertex.</nextsent>
<nextsent>it is empirically observed that contextual ized word types can assume very few (most often, one) pos tags.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4637">
<title id=" N12-1086.xml">graph based lexicon expansion with sparsityinducing penalties </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for us, graph vertices correspond to natural language types (not tokens) and undirected edges between them are weighted using similarity metric.
</prevsent>
<prevsent>recently, this setup has been used to learn soft labels on natural language types (say,word n-grams or syntactically disambiguated pred icates) from seed data, resulting in large but noisy lexicons, which are used to constrain structured prediction models.
</prevsent>
</prevsection>
<citsent citstr=" P11-1144 ">
applications have ranged from domain adaptation of part-of-speech (pos) taggers (subramanya et al, 2010), <papid> D10-1017 </papid>unsupervised learning ofpos taggers by using bilingual graph-based projections (das and petrov, 2011), <papid> P11-1061 </papid>and shallow semantic parsing for unknown predicates (das and smith,2011).<papid> P11-1144 </papid></citsent>
<aftsection>
<nextsent>however, none of the above captured the empirical fact that only few categories typically associate with given type (vertex).
</nextsent>
<nextsent>take the case of pos tagging: subramanya et al (2010) <papid> D10-1017 </papid>construct agraph over trigram types as vertices, with 45 possible tags for the middle word of trigram as the 677 label set for each vertex.</nextsent>
<nextsent>it is empirically observed that contextual ized word types can assume very few (most often, one) pos tags.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4648">
<title id=" N12-1086.xml">graph based lexicon expansion with sparsityinducing penalties </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we achieve this by penalizing the graph propagation objective with the `1 norm or the mixed `1,2 norm (kowalski and torre sani, 2009) of the measures at each vertex, aiming for global and vertex-level sparsity, respectively.
</prevsent>
<prevsent>importantly, the proposed graph objective functions are convex, so we avoid degenerate solutions and local minima.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
we present experiments on two natural language lexicon expansion problems in semi-supervised setting: (i) inducing distributions of pos tags over n-gram types in the wall street journal section of the penn treebank corpus (marcus et al, 1993) <papid> J93-2004 </papid>and (ii) inducing distributions of semantic frames(fillmore, 1982) over predicates unseen in anno 1moreover, we also assume the edge weights in given graph are unconstrained, consistent with prior work on graph based ssl (das and petrov, 2011; <papid> P11-1061 </papid>das and smith, 2011; <papid> P11-1144 </papid>subramanya and bilmes, 2008; <papid> D08-1114 </papid>subramanya and bilmes, 2009; subramanya et al, 2010; <papid> D10-1017 </papid>zhu and ghahramani, 2002).</citsent>
<aftsection>
<nextsent>tated data.
</nextsent>
<nextsent>our methods produce sparse measures at graph vertices resulting in compact lexicons, andalso result in better performance with respect to label propagation using gaussian penalties (zhu and ghahramani, 2002) and entropic measure propagation (subramanya and bilmes, 2009), two state-of the-art graph propagation algorithms.
</nextsent>
<nextsent>2.1 graph-based ssl as map inference.
</nextsent>
<nextsent>let dl = {(xj , rj)}lj=1 denote annotated data types;2 xjs empirical label distribution is rj . let the unlabeled data types be denoted by du = {xi}mi=l+1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4697">
<title id=" N12-1086.xml">graph based lexicon expansion with sparsityinducing penalties </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we fixed k, the number of nearest neighbors for each vertex, to be 10.
</prevsent>
<prevsent>for each graph objective, ?, ? and were chosen by five-fold cross-validation.
</prevsent>
</prevsection>
<citsent citstr=" W07-2018 ">
thecross-validation sets were the same as the ones described in 6.3 of d&amp;s11.9results; and discussion: table 3 shows frame identification accuracy, both using exact match as wellas partial match that assigns partial credit when related frame is predicted (baker et al, 2007).<papid> W07-2018 </papid></citsent>
<aftsection>
<nextsent>the final column presents lexicon size in terms of the set of truncated frame distributions (filtered according to the top frames in qi) for all the targets in graph.
</nextsent>
<nextsent>all the graph-based models are better than the supervised baseline; for our objectives using pairwise gaussian fields with sparse unary penalties, the accuracies are equal or better with respect to ngf-`2; however, the lexicon sizes are reduced by few hundred to few thousand entries.
</nextsent>
<nextsent>massive reduction in lexicon sizes (as in the pos problem in 4.1) is not visible for these objectives because we throw out most of the components of the entire set of distributions and keep only at most the top m(which is automatically chosen to be 2 for all ob jectives) frames per target.
</nextsent>
<nextsent>although significant number of components in the whole distribution qin the sparse objectives get zero mass, the components for target tend to be non-zero for majority of the targets.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4698">
<title id=" P01-1003.xml">improvement of a whole sentence maximum entropy language model using grammatical features </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>language modeling is an important component in computational applications such as speech recognition, automatic translation, optical character recognition, information retrieval etc.
</prevsent>
<prevsent>(jelinek, 1997; borthwick, 1997).
</prevsent>
</prevsection>
<citsent citstr=" H91-1057 ">
statistical language models have gained considerable acceptance due to the efficiency demonstrated in the fields in which they have been applied (bahal et al, 1983;jelinek et al, 1991; <papid> H91-1057 </papid>ratnapharkhi, 1998; borthwick, 1999).traditional statistical language models calculate the probability of sentence  using the chain rule:           fiff   fl ffi  (1) this work has been partially supported by the spanish cycit under contract (tic98/0423-c06).</citsent>
<aftsection>
<nextsent>!granted by universidad del cauca, popayan (colom bia) where ffi  #  $  , which is usually known as the history of  . the effort in the language modeling techniques is usually directed to the estimation of  fl ffi   . the language model defined by the expression  fl ffi   is named the conditional language model.
</nextsent>
<nextsent>in principle, the determination of the conditional probability in (1) is expensive, because the possible number of word sequences is very great.
</nextsent>
<nextsent>traditional conditional language models assume that the probability of the word  does not depend on the entire history,and the history is limited by an equivalence relation % , and (1) is rewritten as:   &amp;      &amp;    (ff    fl %  ffi   (2) the most commonly used conditional language model is the n-gram model.
</nextsent>
<nextsent>in the n-gram model,the history is reduced (by the equivalence rela tion) to the last )+*-, words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4699">
<title id=" P01-1003.xml">improvement of a whole sentence maximum entropy language model using grammatical features </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>and sanchez, 2000).
</prevsent>
<prevsent>a formal framework to include long-distance and local information in the same language model is based on the maximum entropy principle (me).
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
using the me principle, we can combine information from variety of sources into thesame language model (berger et al, 1996; <papid> J96-1002 </papid>rosenfeld, 1996).</citsent>
<aftsection>
<nextsent>the goal of the me principle is that,given set of features (pieces of desired information contained in the sentence), set of functions 5 6 5 7 (measuring the contribution of each feature to the model) and set of constraints1 , wehave to find the probability distribution that satisfies the constraints and minimizes the relative entropy (divergence of kullback-leibler) 8 9 fl(fl ;:  , with respect to the distribution ;: .the general maximum entropy probability distribution relative to prior distribution  : is given by the expression:   &amp; , = ;:   @badce9fhg ekjlenm(oqp (3) where = is the normalization constant and  are parameters to be found.
</nextsent>
<nextsent>the  represent the contribution of each feature to the distribution.
</nextsent>
<nextsent>from (3) it is easy to derive the maximum entropy conditional language model (rosenfeld, 1996): if is the context space and is the vocabulary, then x is the states space, and if  uv6w yxzs t then:  fl [ , =   badce9f gbi ekjlenm]\ ^ _`p (4) and =   : ab [ 2c _ badde9f gbi jqeem9\ ^ _`p (5)where ab  is the normalization constant depending on the context . although the conditional me language model is more flexible than n-grammodels, there is an important obstacle to its general use: conditional me language models have ahigh computational cost (rosenfeld, 1996), specially the evaluation of the normalization constant (5).
</nextsent>
<nextsent>1the constraints usually involve the equality between theoretical expectation and the empirical expectation over the training corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4700">
<title id=" P01-1003.xml">improvement of a whole sentence maximum entropy language model using grammatical features </title>
<section> the grammatical features.  </section>
<citcontext>
<prevsection>
<prevsent>each word in the training sample has part-of-speech tag (postag) associated to it.
</prevsent>
<prevsent>these postags are considered as word categories and are the terminal symbols of our scfg.
</prevsent>
</prevsection>
<citsent citstr=" P92-1017 ">
given category, the probability distribution ofa word is estimated by means of the relative frequency of the word in the category, i.e. the relative frequency which the word has been labeled with postag (a word may belong to different categories).to estimate the scfg parameters, several algorithms have been presented (k. and s.j., 1991; pereira and shabes, 1992; <papid> P92-1017 </papid>amaya et al, 1999; sanchez and bened??, 1999).</citsent>
<aftsection>
<nextsent>taking into account the good results achieved on real tasks (sanchez and bened??, 1999), we used them to learn our category-based scfg.
</nextsent>
<nextsent>to solve the integration problem, we used an algorithm that computes the probability of the best derivation that generates sentence, given the category-based grammar and the model of word distribution into categories (bened??
</nextsent>
<nextsent>and sanchez, 2000).
</nextsent>
<nextsent>this algorithm is based on the well-known viterbi-like scheme for scfgs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4701">
<title id=" P01-1003.xml">improvement of a whole sentence maximum entropy language model using grammatical features </title>
<section> experimental work.  </section>
<citcontext>
<prevsection>
<prevsent> doesnot contribute to the sentence probability.
</prevsent>
<prevsent>therefore, sentence may be grammatically incorrect sentence (relative to the scfg used), if derivations with low frequency appears.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
a part of the wall street journal (wsj) which had been processed in the penn treebanck project (marcus et al, 1993) <papid> J93-2004 </papid>was used in the experiments.this corpus was automatically labelled and manually checked.</citsent>
<aftsection>
<nextsent>there were two kinds of labelling: postag labelling and syntactic labelling.
</nextsent>
<nextsent>the postag vocabulary was composed of 45 labels.the syntactic labels are 14.
</nextsent>
<nextsent>the corpus was divided into sentences according to the bracketing.we selected 12 sections of the corpus at random.
</nextsent>
<nextsent>six were used as training corpus, three as test set and the other three sections were used as held-out for tuning the smoothing wsme model.the sets are described as follow: the training corpus has 11,201 sentences; the test set has 6,350sentences and the held-out set has 5,796 sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4702">
<title id=" P01-1053.xml">automatic detection of syllable boundaries combining the advantages of treebank and bracketed corpora training </title>
<section> treebank training (tt) and.  </section>
<citcontext>
<prevsection>
<prevsent>the advantages of treebank training are the simple procedure, and the good results which are due to the fact that for each word that appears in the training corpus there is only one possible analysis.
</prevsent>
<prevsent>the disadvantage is that grammars which are read off treebank are dependent on the quality of the treebank.
</prevsent>
</prevsection>
<citsent citstr=" P92-1017 ">
there is no freedom of putting more information into the grammar. bracketed corpora training introduced by pereira and schabes (1992) <papid> P92-1017 </papid>employs context free grammar and training corpus, which is partially tagged with brackets.</citsent>
<aftsection>
<nextsent>the probability of rule is inferred by an iterative training procedure with an extended version of the inside-outside algorithm.
</nextsent>
<nextsent>however, only those analyses are considered that meet the tagged brackets (here syllable brackets).
</nextsent>
<nextsent>usually the context-free grammars generate more than one analysis.
</nextsent>
<nextsent>bct reduces the large number of analyses.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4703">
<title id=" P01-1027.xml">refined lexicon models for statistical machine translation using a maximum entropy approach </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>to include this additional information within the statistical framework we use the maximum entropy approach.
</prevsent>
<prevsent>this approach has been applied in natural language processing to variety of tasks.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
(berger et al, 1996) <papid> J96-1002 </papid>applies this approach to the so-called ibm candide system to build context dependent models, compute automatic sentence splitting and to improve word reordering intranslation.</citsent>
<aftsection>
<nextsent>similar techniques are used in (papineni et al, 1996; papineni et al, 1998) for so called direct translation models instead of those proposed in (brown et al, 1993).<papid> J93-2003 </papid></nextsent>
<nextsent>(foster, 2000)<papid> W00-0707 </papid>describes two methods for incorporating information about the relative position of bilingual word pairs into maximum entropy translation model.other authors have applied this approach to language modeling (rosenfeld, 1996; martinet al, 1999; peters and klakow, 1999).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4705">
<title id=" P01-1027.xml">refined lexicon models for statistical machine translation using a maximum entropy approach </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this approach has been applied in natural language processing to variety of tasks.
</prevsent>
<prevsent>(berger et al, 1996) <papid> J96-1002 </papid>applies this approach to the so-called ibm candide system to build context dependent models, compute automatic sentence splitting and to improve word reordering intranslation.</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
similar techniques are used in (papineni et al, 1996; papineni et al, 1998) for so called direct translation models instead of those proposed in (brown et al, 1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>(foster, 2000)<papid> W00-0707 </papid>describes two methods for incorporating information about the relative position of bilingual word pairs into maximum entropy translation model.other authors have applied this approach to language modeling (rosenfeld, 1996; martinet al, 1999; peters and klakow, 1999).</nextsent>
<nextsent>a short review of the maximum entropy approach is outlined in section 3.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4706">
<title id=" P01-1027.xml">refined lexicon models for statistical machine translation using a maximum entropy approach </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(berger et al, 1996) <papid> J96-1002 </papid>applies this approach to the so-called ibm candide system to build context dependent models, compute automatic sentence splitting and to improve word reordering intranslation.</prevsent>
<prevsent>similar techniques are used in (papineni et al, 1996; papineni et al, 1998) for so called direct translation models instead of those proposed in (brown et al, 1993).<papid> J93-2003 </papid></prevsent>
</prevsection>
<citsent citstr=" W00-0707 ">
(foster, 2000)<papid> W00-0707 </papid>describes two methods for incorporating information about the relative position of bilingual word pairs into maximum entropy translation model.other authors have applied this approach to language modeling (rosenfeld, 1996; martinet al, 1999; peters and klakow, 1999).</citsent>
<aftsection>
<nextsent>a short review of the maximum entropy approach is outlined in section 3.
</nextsent>
<nextsent>the goal of the translation process in statistical machine translation can be formulated as fol lows: source language string         is to be translated into target language string       . in the experiments reported in.
</nextsent>
<nextsent>this paper, the source language is german and the target language is english.
</nextsent>
<nextsent>every target string is considered as possible translation for the input.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4707">
<title id=" P01-1027.xml">refined lexicon models for statistical machine translation using a maximum entropy approach </title>
<section> statistical machine translation.  </section>
<citcontext>
<prevsection>
<prevsent>every target string is considered as possible translation for the input.
</prevsent>
<prevsent>if we assign probability    to each pairof strings       , then according to bayes?
</prevsent>
</prevsection>
<citsent citstr=" H94-1028 ">
decision rule, we have to choose the target string that maximizes the product of the target language model     and the string translation model      . many existing systems for statistical machine translation (berger et al, 1994; <papid> H94-1028 </papid>wang and waibel, 1997; <papid> P97-1047 </papid>tillmann et al, 1997; <papid> P97-1037 </papid>nieen et al, 1998) make use of special way of structuring the string translation model like proposed by (brown et al, 1993): <papid> J93-2003 </papid>the correspondence between the words in the source and the target string is described by alignments that assign one target word position to each source word position.</citsent>
<aftsection>
<nextsent>the lexicon probability fffi   of certain target word to occur in the target string is assumed to depend basically only on the source word  aligned to it.these alignment models are similar to the concept of hidden markov models (hmm) in speech recognition.
</nextsent>
<nextsent>the alignment mapping is flffi  !# from source position fl to target position $!%# . the alignment !   may contain align-.
</nextsent>
<nextsent>ments !%#&amp;(  with the empty?
</nextsent>
<nextsent>word ) to account for source words that are not aligned to any target word.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4708">
<title id=" P01-1027.xml">refined lexicon models for statistical machine translation using a maximum entropy approach </title>
<section> statistical machine translation.  </section>
<citcontext>
<prevsection>
<prevsent>every target string is considered as possible translation for the input.
</prevsent>
<prevsent>if we assign probability    to each pairof strings       , then according to bayes?
</prevsent>
</prevsection>
<citsent citstr=" P97-1047 ">
decision rule, we have to choose the target string that maximizes the product of the target language model     and the string translation model      . many existing systems for statistical machine translation (berger et al, 1994; <papid> H94-1028 </papid>wang and waibel, 1997; <papid> P97-1047 </papid>tillmann et al, 1997; <papid> P97-1037 </papid>nieen et al, 1998) make use of special way of structuring the string translation model like proposed by (brown et al, 1993): <papid> J93-2003 </papid>the correspondence between the words in the source and the target string is described by alignments that assign one target word position to each source word position.</citsent>
<aftsection>
<nextsent>the lexicon probability fffi   of certain target word to occur in the target string is assumed to depend basically only on the source word  aligned to it.these alignment models are similar to the concept of hidden markov models (hmm) in speech recognition.
</nextsent>
<nextsent>the alignment mapping is flffi  !# from source position fl to target position $!%# . the alignment !   may contain align-.
</nextsent>
<nextsent>ments !%#&amp;(  with the empty?
</nextsent>
<nextsent>word ) to account for source words that are not aligned to any target word.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4709">
<title id=" P01-1027.xml">refined lexicon models for statistical machine translation using a maximum entropy approach </title>
<section> statistical machine translation.  </section>
<citcontext>
<prevsection>
<prevsent>every target string is considered as possible translation for the input.
</prevsent>
<prevsent>if we assign probability    to each pairof strings       , then according to bayes?
</prevsent>
</prevsection>
<citsent citstr=" P97-1037 ">
decision rule, we have to choose the target string that maximizes the product of the target language model     and the string translation model      . many existing systems for statistical machine translation (berger et al, 1994; <papid> H94-1028 </papid>wang and waibel, 1997; <papid> P97-1047 </papid>tillmann et al, 1997; <papid> P97-1037 </papid>nieen et al, 1998) make use of special way of structuring the string translation model like proposed by (brown et al, 1993): <papid> J93-2003 </papid>the correspondence between the words in the source and the target string is described by alignments that assign one target word position to each source word position.</citsent>
<aftsection>
<nextsent>the lexicon probability fffi   of certain target word to occur in the target string is assumed to depend basically only on the source word  aligned to it.these alignment models are similar to the concept of hidden markov models (hmm) in speech recognition.
</nextsent>
<nextsent>the alignment mapping is flffi  !# from source position fl to target position $!%# . the alignment !   may contain align-.
</nextsent>
<nextsent>ments !%#&amp;(  with the empty?
</nextsent>
<nextsent>word ) to account for source words that are not aligned to any target word.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4713">
<title id=" P01-1027.xml">refined lexicon models for statistical machine translation using a maximum entropy approach </title>
<section> contextual information and training.  </section>
<citcontext>
<prevsection>
<prevsent>that is obtained using the viterbi alignment provided by translation model as described in (brown etal., 1993).<papid> J93-2003 </papid></prevsent>
<prevsent>specifically, we use the viterbi alignment that was produced by model 5.</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
we use the program giza++ (och and ney, 2000<papid> P00-1056 </papid>b; och and ney, 2000<papid> P00-1056 </papid>a), which is an extension of the training program available in egypt (al-onaizan et al, 1999).berger et al (1996) <papid> J96-1002 </papid>use the words that surround specific word pair     as contextual in formation.</citsent>
<aftsection>
<nextsent>the authors propose as context the 3 words to the left and the 3 words to the right of the target word.
</nextsent>
<nextsent>in this work we use the following contextual information:  target context: as in (berger et al, 1996) <papid> J96-1002 </papid>we consider window of 3 words to the left and to the right of the target word considered.</nextsent>
<nextsent> source context: in addition, we consider window of 3 words to the left of the source word  which is connected to according to the viterbi alignment.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4720">
<title id=" P01-1027.xml">refined lexicon models for statistical machine translation using a maximum entropy approach </title>
<section> contextual information and training.  </section>
<citcontext>
<prevsection>
<prevsent> word classes: instead of using dependency on the word identity we include also dependency on word classes.
</prevsent>
<prevsent>by doing this, we improve the generalization of the models and include some semantic and syntactic information with.
</prevsent>
</prevsection>
<citsent citstr=" E99-1010 ">
the word classes are computed automatically using another statistical training procedure (och, 1999) <papid> E99-1010 </papid>which often produces word classes including words with the same semantic meaning in the same class.</citsent>
<aftsection>
<nextsent>a training event, for specific target word , is composed by three items:  the source word  aligned to .  the context in which the aligned pair     appears.
</nextsent>
<nextsent> the number of occurrences of the event in the training corpus.
</nextsent>
<nextsent>table 1 shows some examples of training events for the target word which?.
</nextsent>
<nextsent>once we have set of training events for each target word we need to describe our feature functions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4722">
<title id=" P01-1027.xml">refined lexicon models for statistical machine translation using a maximum entropy approach </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>depending on whether the translated sentence is longer or shorter than the target translation, the remaining words result in either insertion or deletion errors in addition to substitution errors.
</prevsent>
<prevsent>the per is guaranteed to be less than or equal to the wer.
</prevsent>
</prevsection>
<citsent citstr=" C00-2123 ">
we use the top-10 list of hypothesis provided by the translation system described in (tillmannand ney, 2000) <papid> C00-2123 </papid>for rescoring the hypothesis using the me models and sort them according to thenew maximum entropy score.</citsent>
<aftsection>
<nextsent>the translation results in terms of error rates are shown in table 8.we use model 4 in order to perform the translation experiments because model 4 typically gives better translation results than model 5.
</nextsent>
<nextsent>we see that the translation quality improves slightly with respect to the wer and per.
</nextsent>
<nextsent>the translation quality improvements so far are quite small compared to the perplexity measure improvements.
</nextsent>
<nextsent>we attribute this to the fact that the algorithm for computing the  -best lists is sub optimal.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4723">
<title id=" P02-1024.xml">exploring asymmetric clustering for statistical language modeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>experimental results show substantial improvements of the acm in comparison with classical cluster models and word n-gram models at the same model size.
</prevsent>
<prevsent>our analysis shows that the high-performance of the acm lies in the asymmetry of the model.
</prevsent>
</prevsection>
<citsent citstr=" J90-2002 ">
the n-gram model has been widely applied in many applications such as speech recognition, machine translation, and asian language text input [jelinek, 1990; brown et al, 1990; <papid> J90-2002 </papid>gao et al, 2002].</citsent>
<aftsection>
<nextsent>it is stochastic model, which predicts the next word (predicted word) given the previous n-1 words (conditional words) in word sequence.
</nextsent>
<nextsent>the cluster n-gram model is variant of the word n-gram model in which similar words are classified in the same cluster.
</nextsent>
<nextsent>this has been demonstrated as an effective way to deal with the data sparseness problem and to reduce the memory sizes for realistic applications.
</nextsent>
<nextsent>recent research [yamamoto et al, 2001] <papid> P01-1068 </papid>shows that using different clusters for predicted and conditional words can lead to cluster models that are superior to classical cluster models, which use the same clusters for both words [brown et al, 1992].<papid> J92-4003 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4724">
<title id=" P02-1024.xml">exploring asymmetric clustering for statistical language modeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the cluster n-gram model is variant of the word n-gram model in which similar words are classified in the same cluster.
</prevsent>
<prevsent>this has been demonstrated as an effective way to deal with the data sparseness problem and to reduce the memory sizes for realistic applications.
</prevsent>
</prevsection>
<citsent citstr=" P01-1068 ">
recent research [yamamoto et al, 2001] <papid> P01-1068 </papid>shows that using different clusters for predicted and conditional words can lead to cluster models that are superior to classical cluster models, which use the same clusters for both words [brown et al, 1992].<papid> J92-4003 </papid></citsent>
<aftsection>
<nextsent>this is the basis of the asymmetric cluster model (acm), which will be formally defined and empirically studied in this paper.
</nextsent>
<nextsent>although similar models have been used in previous studies [goodman and gao, 2000; yamamoto et al, 2001], <papid> P01-1068 </papid>several issues have not been completely investigated.</nextsent>
<nextsent>these include: (1) an effective methodology for constructing the acm, (2) thorough comparative study of the acm with classical cluster models and word models when they are applied to realistic application, and (3) an analysis of the reason why the acm is superior.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4725">
<title id=" P02-1024.xml">exploring asymmetric clustering for statistical language modeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the cluster n-gram model is variant of the word n-gram model in which similar words are classified in the same cluster.
</prevsent>
<prevsent>this has been demonstrated as an effective way to deal with the data sparseness problem and to reduce the memory sizes for realistic applications.
</prevsent>
</prevsection>
<citsent citstr=" J92-4003 ">
recent research [yamamoto et al, 2001] <papid> P01-1068 </papid>shows that using different clusters for predicted and conditional words can lead to cluster models that are superior to classical cluster models, which use the same clusters for both words [brown et al, 1992].<papid> J92-4003 </papid></citsent>
<aftsection>
<nextsent>this is the basis of the asymmetric cluster model (acm), which will be formally defined and empirically studied in this paper.
</nextsent>
<nextsent>although similar models have been used in previous studies [goodman and gao, 2000; yamamoto et al, 2001], <papid> P01-1068 </papid>several issues have not been completely investigated.</nextsent>
<nextsent>these include: (1) an effective methodology for constructing the acm, (2) thorough comparative study of the acm with classical cluster models and word models when they are applied to realistic application, and (3) an analysis of the reason why the acm is superior.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4728">
<title id=" P02-1024.xml">exploring asymmetric clustering for statistical language modeling </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>section 4 first introduces the japanese kana-kanji conversion task; it then presents our main experiments and discussion of our findings.
</prevsent>
<prevsent>finally, conclusions are presented in section 5.
</prevsent>
</prevsection>
<citsent citstr=" P93-1024 ">
a large amount of previous research on clustering has been focused on how to find the best clusters [brown et al, 1992; <papid> J92-4003 </papid>kneser and ney, 1993; yamamoto and sagisaka, 1999; ueberla, 1996; pereira et al, 1993; <papid> P93-1024 </papid>bellegarda et al, 1996; bai et al., 1998].</citsent>
<aftsection>
<nextsent>only small differences have been observed, however, in the performance of the different techniques for constructing clusters.
</nextsent>
<nextsent>in this study, we focused our research on novel techniques for using clusters ? the acm, in which different clusters are used for predicted and conditional words respectively.
</nextsent>
<nextsent>the discussion of the acm in this paper is an extension of several studies below.
</nextsent>
<nextsent>the first similar cluster model was presented by goodman and gao [2000] in which the clustering techniques were combined with stolckes [1998] pruning to reduce the language model (lm) size effectively.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4731">
<title id=" P02-1024.xml">exploring asymmetric clustering for statistical language modeling </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>all cluster models discussed in this paper are based on hard clustering, meaning that each word belongs to only one cluster.
</prevsent>
<prevsent>one area we have not explored is the use of soft clustering, where word can be assigned to multiple clusters with probability p(w|w) [pereira et al, 1993].<papid> P93-1024 </papid></prevsent>
</prevsection>
<citsent citstr=" W97-0309 ">
saul and pereira [1997] <papid> W97-0309 </papid>demonstrated the utility of soft clustering and concluded that any method that assigns each word to single cluster would lose information.</citsent>
<aftsection>
<nextsent>it is an interesting question whether our techniques for hard clustering can be extended to soft clustering.
</nextsent>
<nextsent>on the other hand, soft clustering models tend to be larger than hard clustering models because given word can belong to multiple clusters, and thus training instance p(wi|wi-2wi-1) can lead to multiple counts instead of just 1.
</nextsent>


</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4732">
<title id=" P01-1051.xml">error profiling toward a model of english acquisition for deaf learners </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this work, we explore how our second language instruction system, icicle, has generated the need for modeling such an account, and we discuss the results of corpus analysis we have undertaken to fulfill that need.
</prevsent>
<prevsent>1.1 icicle: an overview.
</prevsent>
</prevsection>
<citsent citstr=" W99-0408 ">
icicle (interactive computer identification and correction of language errors) is an intelligent tutoring system currently underdevelopment (michaud and mccoy, 1999; <papid> W99-0408 </papid>michaud et al, 2000; michaud et al, 2001).</citsent>
<aftsection>
<nextsent>its primary function is to tutor deaf students on their written english.
</nextsent>
<nextsent>essential to performing that function is the ability to correctly analyze user-generated language errors and produce tutorial feedback to student performance which is both correct and tailored to the students language competence.
</nextsent>
<nextsent>our target learners are native or near-native users of american sign language (asl), distinct language from english (cf.
</nextsent>
<nextsent>(baker and cokely, 1980)), so we view the acquisition of skills in written english asthe acquisition of second language for this population (michaud et al, 2000).our system uses cycle of user input and system response, beginning when user submits piece of writing to be reviewed by the system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4733">
<title id=" P01-1051.xml">error profiling toward a model of english acquisition for deaf learners </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one- or two-sentence explanations of each error on request.
</prevsent>
<prevsent>the user can then make changes and resubmit the piece for additional analysis.
</prevsent>
</prevsection>
<citsent citstr=" P98-2196 ">
we have discussed in (schneider and mccoy,1998) <papid> P98-2196 </papid>the performance of our parser and mal-rule augmented grammar and the unique challenges she is teach piano on tuesdays.?</citsent>
<aftsection>
<nextsent>beginner: inappropriate use of auxiliary and verb morphology problems.
</nextsent>
<nextsent>she teaches piano on tuesdays.?
</nextsent>
<nextsent>intermediate: missing appropriate +ing morphology.
</nextsent>
<nextsent>she is teaching piano on tuesdays.?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4734">
<title id=" P01-1051.xml">error profiling toward a model of english acquisition for deaf learners </title>
<section> profiling language errors.  </section>
<citcontext>
<prevsection>
<prevsent>level and compare to the magnitude of occurrence at other levels 5.
</prevsent>
<prevsent>analyze resulting findings to determine.
</prevsent>
</prevsection>
<citsent citstr=" J96-2004 ">
a progression of competence in (michaud et al, 2001) we discuss the initial steps we took in this process, including the development of list of error codes documented by coding manual, the verification of our manu aland coding scheme by testing inter-coder reliability in subset of the corpus (where we achieved kappa agreement score (carletta, 1996) <papid> J96-2004 </papid>of </citsent>
<aftsection>
<nextsent> )2, and the subsequent tagging of the entire corpus.
</nextsent>
<nextsent>once the corpus was annotated with the errors each sentence contained, we obtained expert evaluations of overall proficiency levels performed by esl instructors using the national test of written english (twe) ratings3 . the initial analysis we go on to describe in (michaud et al, 2001) confirmed that clustering algorithms looking at the relative magnitude of different errors grouped the samples in manner which corresponded to where they appeared in the spectrum of proficiency represented by the corpus.
</nextsent>
<nextsent>the next step, the results of which we discuss here, was to look at each error we tagged and the ability of the level of the writers proficiency to predict which errors he or she would commit.
</nextsent>
<nextsent>if we found significant differences in the errors committed by writers of different twe scores, then we could use the errors to help organize the slalom elements, and through that obtain data on which errors to expect given users level of proficiency.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4735">
<title id=" P04-1029.xml">optimizing typed feature structure grammar parsing through non statistical indexing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>thus, failing unifications must be avoided during retrieval from the chart.
</prevsent>
<prevsent>to our knowledge, there have been only four methods proposed for improving the retrieval component of tfsg parsing.
</prevsent>
</prevsection>
<citsent citstr=" P03-1026 ">
one (penn and munteanu,2003) <papid> P03-1026 </papid>addresses only the cost of copying large categories, and was found to reduce parsing times by an average of 25% on large-scale tfsg (merge).the second, statistical method known as quick check (malouf et al, 2000), determines the paths that are likely to cause unification failure by profiling large sequence of parses over representative input, and then filters unifications at run-time by first testing these paths for type consistency.this was measured as providing up to 50% improvement in parse times on the english resource grammar (flickinger, 1999, erg).</citsent>
<aftsection>
<nextsent>the third (penn, 1999b) is similar but more conservative approach that uses the profile to re-order sister feature value sin the internal data structure.
</nextsent>
<nextsent>this was found to im prove parse times on the ale hpsg by up to 33%.
</nextsent>
<nextsent>the problem with these statistical methods is thatthe improvements in parsing times may not justify the time spent on profiling, particularly during grammar development.
</nextsent>
<nextsent>the static analysis method introduced here does not use profiling, although it does not preclude it either.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4736">
<title id=" P04-1029.xml">optimizing typed feature structure grammar parsing through non statistical indexing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>indeed, an evaluation of statistical methods would be more relevant if measured on top of an adequate extent of non-statistical optimizations.
</prevsent>
<prevsent>although quick-check is thought to produce parsing time improvements, its evaluation used parser with only superficial static analysis of chart indexing.
</prevsent>
</prevsection>
<citsent citstr=" P99-1061 ">
that analysis, rule filtering (kiefer et al, 1999), <papid> P99-1061 </papid>reduces parse times by filtering out mother-daughter unifications that can be determined to fail at compile-time.</citsent>
<aftsection>
<nextsent>true indexing organizes the data(in this case, chart edges) to avoid unnecessary re trievals altogether, does not require the operations that it performs to be repeated once full unification is deemed necessary, and offers the support for easily adding information extracted from further static analysis of the grammar rules, while maintaining the same indexing strategy.
</nextsent>
<nextsent>flexibility is one of the reasons for the successful employment of indexing in databases (elmasri and navathe, 2000) and automated reasoning (ramakrishnan et al, 2001).in this paper, we present general scheme for indexing tfs categories during parsing (section 3).we then present specific method for static ally analyzing tfsgs based on the type signature and the structure of category descriptions in the grammar rules, and prove its soundness and completeness (section 4.2.1).
</nextsent>
<nextsent>we describe specific indexing strategy based on this analysis (section 4), and evaluate it on two large-scale tfsgs (section 5).
</nextsent>
<nextsent>the result is purely non-statistical method that is competitive with the improvements gained by statistical optimizations, and is still compatible with further statistical improvements.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4738">
<title id=" P03-2039.xml">chinese unknown word identification using character based tagging and chunking </title>
<section> proposed method.  </section>
<citcontext>
<prevsection>
<prevsent>the set of characters used for transliteration may also be useful for retrieving transliterated names.
</prevsent>
<prevsent>2.3 chunking with support vector machine.
</prevsent>
</prevsection>
<citsent citstr=" N01-1025 ">
we use support vector machines-based chunker, yamcha (kudo and matsumoto, 2001), <papid> N01-1025 </papid>to extract unknown words from the output of the morphological analysis.</citsent>
<aftsection>
<nextsent>the chunker uses polynomial kernel of degree 2.
</nextsent>
<nextsent>please refer to the paper cited forde tails.
</nextsent>
<nextsent>basically we would like to classify the characters into 3 categories, (beginning of chunk), (insidea chunk) and (outside chunk).
</nextsent>
<nextsent>a chunk is considered as an unknown word in this case.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4739">
<title id=" P03-2039.xml">chinese unknown word identification using character based tagging and chunking </title>
<section> comparison with other works.  </section>
<citcontext>
<prevsection>
<prevsent>the f-measure ( word based vs character based ) for person name extraction is (81.28 vs 84.69), for organization name is (67.88 vs 70.40), and for general unknown word is (56.96 vs 61.00) respectively.
</prevsent>
<prevsent>there are basically two methods to extract unknown words, statistical and rule based approaches.
</prevsent>
</prevsection>
<citsent citstr=" C02-1049 ">
in this section, we compare our results with previous reported work.(chen and ma, 2002) <papid> C02-1049 </papid>present an approach that automatically generates morphological rules and statistical rules from training corpus.</citsent>
<aftsection>
<nextsent>they use very large corpus to generate the rules, therefore the rules generated can represent patterns of unknwon words as well.
</nextsent>
<nextsent>while we use different corpus for the experiment, it is difficult to perform comparison.
</nextsent>
<nextsent>they report precision of 89% and recall of 68% for all unknown word types.
</nextsent>
<nextsent>this is better than our system which achieves only 65% for precision and 58% for recall.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4740">
<title id=" P03-2039.xml">chinese unknown word identification using character based tagging and chunking </title>
<section> comparison with other works.  </section>
<citcontext>
<prevsection>
<prevsent>they report that the larger the cache, the higher the recall, but not the case for precision.
</prevsent>
<prevsent>they report recall of 54.9%, less than the 58.43% we achieved.
</prevsent>
</prevsection>
<citsent citstr=" W02-1817 ">
(zhang et al, 2002) <papid> W02-1817 </papid>suggest method that isbased on role tagging for unknown words recognition.</citsent>
<aftsection>
<nextsent>their method is also based on markov models.
</nextsent>
<nextsent>our method is closest to the role tagging idea as this latter is also sort of character based tagging.the extension in our method is that we first do morphological analysis and then use chunking based on svm for unknown word extraction.
</nextsent>
<nextsent>in their paper,they report an f-measure of 79.30% in open test environment for person name extraction.
</nextsent>
<nextsent>our method seems better with an f-measure of 86.78% for person name extraction (for both chinese and foreign names).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4741">
<title id=" P02-1019.xml">pronunciation modeling for improved spelling correction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>many of the early algorithms for spelling correction are based on the assumption that the correct word differs from the misspelling by exactly one of these operations (m. d. kernigan and gale,1990; church and gale, 1991; mayes and f. damerau, 1991).
</prevsent>
<prevsent>by estimating probabilities or weights for the different edit operations and conditioning on the left and right context for insertions and deletions and allowing multiple edit operations, high spelling correction accuracy has been achieved.
</prevsent>
</prevsection>
<citsent citstr=" P00-1037 ">
at acl 2000, brill and moore (2000) <papid> P00-1037 </papid>introduced new error model, allowing generic string-to-string edits.</citsent>
<aftsection>
<nextsent>this model reduced the error rate of the best previous model by nearly 50%.
</nextsent>
<nextsent>it proved advantageous to model substitutions of up to 5-letter sequences (e.g ent being mis typed as ant, ph as f, al as le, etc.) this model deals with phonetic errors significantly better than previous models since it allows much larger context size.
</nextsent>
<nextsent>however this model makes residual errors, many of which have to do with word pronunciation.
</nextsent>
<nextsent>for example, the following are triples of misspelling, correct word and (incorrect) guess that the brill and moore model made: edelvise edelweiss advise bouncie bouncy bounce latecks latex lacks in this work we take the approach of modeling phonetic errors explicitly by building separate error model for phonetic errors.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4747">
<title id=" P04-1076.xml">weakly supervised learning for cross document person name disambiguation supported by information extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as far as names are concerned, co-reference consists of two sub-tasks: (i) name disambiguation to handle the problem of different entities happening to use the same name; (ii) alias association to handle the problem of the same entity using multiple names (aliases).
</prevsent>
<prevsent>message understanding conference (muc) community has established within-document coreference standards [muc-7 1998].
</prevsent>
</prevsection>
<citsent citstr=" H92-1045 ">
compared with within-document name disambiguation which can leverage highly reliable discourse heuristics such as one sense per discourse [gale et al 1992], <papid> H92-1045 </papid>cross-document name disambiguation is much harder problem.</citsent>
<aftsection>
<nextsent>among major categories of named entities (nes, which in this paper refer to entity names, excluding the muc time and numerical nes), company and product names are often trademarked or uniquely registered, and hence less subject to name ambiguity.
</nextsent>
<nextsent>this paper focuses on cross-document disambiguation of person names.
</nextsent>
<nextsent>previous research for cross-document name disambiguation applies vector space model (vsm) for context similarity, only using co-occurring words [bagga &amp; baldwin 1998].<papid> P98-1012 </papid></nextsent>
<nextsent>a pre-defined threshold decides whether two context vectors are different enough to represent two different entities.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4748">
<title id=" P04-1076.xml">weakly supervised learning for cross document person name disambiguation supported by information extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>among major categories of named entities (nes, which in this paper refer to entity names, excluding the muc time and numerical nes), company and product names are often trademarked or uniquely registered, and hence less subject to name ambiguity.
</prevsent>
<prevsent>this paper focuses on cross-document disambiguation of person names.
</prevsent>
</prevsection>
<citsent citstr=" P98-1012 ">
previous research for cross-document name disambiguation applies vector space model (vsm) for context similarity, only using co-occurring words [bagga &amp; baldwin 1998].<papid> P98-1012 </papid></citsent>
<aftsection>
<nextsent>a pre-defined threshold decides whether two context vectors are different enough to represent two different entities.
</nextsent>
<nextsent>this approach faces two challenges: i) it is difficult to incorporate natural language processing (nlp) results in the vsm framework; 1 ii) the algorithm focuses on the local pairwise context similarity, and neglects the global correlation in the data: this may cause inconsistent results, and hurts the performance.
</nextsent>
<nextsent>this paper presents new algorithm that addresses these problems.
</nextsent>
<nextsent>a learning scheme with minimal supervision is developed within the bayesian framework.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4751">
<title id=" P00-1066.xml">feature logic for dotted types a formalism for complex word meanings </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we use higher order feature logic based on ohori srecord -calculus to model the semantics of words like book and library, in particular their behavior in the context of quanti cation and cardinality statements.
</prevsent>
<prevsent>the treatment of lexical ambiguity is one of the main problems in lexical semantics and inthe modeling of natural language understanding.
</prevsent>
</prevsection>
<citsent citstr=" J91-4003 ">
pustejovsky framework of the \gen erative lexicon  made contribution to the discussion by employing the concept of type coercion, thus replacing the enumeration of readings by the systematic context-dependent generation of suitable interpretations, in the case of systematic polysemies (pustejovsky, 1991; <papid> J91-4003 </papid>pustejovsky, 1995).</citsent>
<aftsection>
<nextsent>also, pustejovsky pointed to frequent and important phenomenon in lexical semantics, which at rst sight looks as another case of polysemy, but is signi cantly dierent in nature.
</nextsent>
<nextsent>(1) the book is blue/on the shelf.
</nextsent>
<nextsent>(2) mary burned the book.
</nextsent>
<nextsent>(3) the book is amusing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4752">
<title id=" N12-2010.xml">automatic metrics for genre specific text quality </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these metrics typically classify texts as suitable for adultor child, or into more fine-grained set of 12 educational grade levels.
</prevsent>
<prevsent>the second line of workare recent computational metrics to predict coherence.
</prevsent>
</prevsection>
<citsent citstr=" N04-1015 ">
these methods identify regularities in words(barzilay and lee, 2004), <papid> N04-1015 </papid>entity coreference (barzi lay and lapata, 2008) <papid> J08-1001 </papid>and discourse relations (pitlerand nenkova, 2008) <papid> D08-1020 </papid>from large collection of articles and use these patterns to predict the coher ence.</citsent>
<aftsection>
<nextsent>they assume particular competency level(adult educated readers) and also fix the text (typi cally news articles, which are appropriate for adult readers).
</nextsent>
<nextsent>by removing the focus on age/educationlevel, these methods compute textual differences between good and poorly written texts as perceived by single audience level.
</nextsent>
<nextsent>in my thesis, propose new definition ? text quality: the overall well-written characteristic of an article.
</nextsent>
<nextsent>it differs from prior work in three respects: 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4754">
<title id=" N12-2010.xml">automatic metrics for genre specific text quality </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these metrics typically classify texts as suitable for adultor child, or into more fine-grained set of 12 educational grade levels.
</prevsent>
<prevsent>the second line of workare recent computational metrics to predict coherence.
</prevsent>
</prevsection>
<citsent citstr=" J08-1001 ">
these methods identify regularities in words(barzilay and lee, 2004), <papid> N04-1015 </papid>entity coreference (barzi lay and lapata, 2008) <papid> J08-1001 </papid>and discourse relations (pitlerand nenkova, 2008) <papid> D08-1020 </papid>from large collection of articles and use these patterns to predict the coher ence.</citsent>
<aftsection>
<nextsent>they assume particular competency level(adult educated readers) and also fix the text (typi cally news articles, which are appropriate for adult readers).
</nextsent>
<nextsent>by removing the focus on age/educationlevel, these methods compute textual differences between good and poorly written texts as perceived by single audience level.
</nextsent>
<nextsent>in my thesis, propose new definition ? text quality: the overall well-written characteristic of an article.
</nextsent>
<nextsent>it differs from prior work in three respects: 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4755">
<title id=" N12-2010.xml">automatic metrics for genre specific text quality </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these metrics typically classify texts as suitable for adultor child, or into more fine-grained set of 12 educational grade levels.
</prevsent>
<prevsent>the second line of workare recent computational metrics to predict coherence.
</prevsent>
</prevsection>
<citsent citstr=" D08-1020 ">
these methods identify regularities in words(barzilay and lee, 2004), <papid> N04-1015 </papid>entity coreference (barzi lay and lapata, 2008) <papid> J08-1001 </papid>and discourse relations (pitlerand nenkova, 2008) <papid> D08-1020 </papid>from large collection of articles and use these patterns to predict the coher ence.</citsent>
<aftsection>
<nextsent>they assume particular competency level(adult educated readers) and also fix the text (typi cally news articles, which are appropriate for adult readers).
</nextsent>
<nextsent>by removing the focus on age/educationlevel, these methods compute textual differences between good and poorly written texts as perceived by single audience level.
</nextsent>
<nextsent>in my thesis, propose new definition ? text quality: the overall well-written characteristic of an article.
</nextsent>
<nextsent>it differs from prior work in three respects: 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4756">
<title id=" N12-2010.xml">automatic metrics for genre specific text quality </title>
<section> thesis summary and contributions.  </section>
<citcontext>
<prevsection>
<prevsent>automatic evaluation of content and linguistic quality is therefore necessary for system development in this genre.
</prevsent>
<prevsent>for this thesis, we only consider the discourse and style components of text quality, aspects that have received less focus in prior work.
</prevsent>
</prevsection>
<citsent citstr=" W10-4236 ">
sentence-level problems have been widely explored and recently, even specifically for academic writing (dale and kilgarriff, 2010).<papid> W10-4236 </papid></citsent>
<aftsection>
<nextsent>we also do not consider content in our work, for example, academic writing quality also depends on the ideas and arguments presented but these aspects are outside the scope of this thesis.
</nextsent>
<nextsent>as defined previously, we focus on fixed audience level.
</nextsent>
<nextsent>we assume reader at the top level of the competency spectrum: an adult educated reader for science news and automatic summaries, and for academic articles, an expert on the topic.
</nextsent>
<nextsent>this definition has minimal focus on reader abilities and allows us to analyze textual differences exclusively.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4757">
<title id=" N12-2010.xml">automatic metrics for genre specific text quality </title>
<section> proposing new discourse-level features: in.  </section>
<citcontext>
<prevsection>
<prevsent>3 related work.
</prevsent>
<prevsent>early readability metrics used sentence length, number of syllables in words and number of easy words to distinguish texts from different grade levels (flesch, 1948; gunning, 1952; dale and chall, 1948).
</prevsent>
</prevsection>
<citsent citstr=" P05-1065 ">
other measures are based on word familiarity (collins-thompson and callan, 2004; si and callan, 2001), difficulty of concepts (zhao and kan, 2010)and features of sentence syntax (schwarm and ostendorf, 2005).<papid> P05-1065 </papid></citsent>
<aftsection>
<nextsent>there are also readability studies for audience distinctions other than grade levels.
</nextsent>
<nextsent>feng et al (2009) <papid> E09-1027 </papid>consider adult readers with intellectual disability and therefore introduce features such asthe number of entities person should keep in working memory for that text and how far entity linksstretch.</nextsent>
<nextsent>heilman et al (2007) <papid> N07-1058 </papid>show that grammatical features make bigger impact while predicting readability for second language learners in contrast to native speakers.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4758">
<title id=" N12-2010.xml">automatic metrics for genre specific text quality </title>
<section> proposing new discourse-level features: in.  </section>
<citcontext>
<prevsection>
<prevsent>other measures are based on word familiarity (collins-thompson and callan, 2004; si and callan, 2001), difficulty of concepts (zhao and kan, 2010)and features of sentence syntax (schwarm and ostendorf, 2005).<papid> P05-1065 </papid></prevsent>
<prevsent>there are also readability studies for audience distinctions other than grade levels.</prevsent>
</prevsection>
<citsent citstr=" E09-1027 ">
feng et al (2009) <papid> E09-1027 </papid>consider adult readers with intellectual disability and therefore introduce features such asthe number of entities person should keep in working memory for that text and how far entity linksstretch.</citsent>
<aftsection>
<nextsent>heilman et al (2007) <papid> N07-1058 </papid>show that grammatical features make bigger impact while predicting readability for second language learners in contrast to native speakers.</nextsent>
<nextsent>newer coherence measures do not focus on reader abilities.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4759">
<title id=" N12-2010.xml">automatic metrics for genre specific text quality </title>
<section> proposing new discourse-level features: in.  </section>
<citcontext>
<prevsection>
<prevsent>there are also readability studies for audience distinctions other than grade levels.
</prevsent>
<prevsent>feng et al (2009) <papid> E09-1027 </papid>consider adult readers with intellectual disability and therefore introduce features such asthe number of entities person should keep in working memory for that text and how far entity linksstretch.</prevsent>
</prevsection>
<citsent citstr=" N07-1058 ">
heilman et al (2007) <papid> N07-1058 </papid>show that grammatical features make bigger impact while predicting readability for second language learners in contrast to native speakers.</citsent>
<aftsection>
<nextsent>newer coherence measures do not focus on reader abilities.
</nextsent>
<nextsent>they are typically run on news articles and assume an adult audience.
</nextsent>
<nextsent>they show that word co-occurrence (soricut and marcu, 2006), <papid> P06-2103 </papid>sub topic structure (barzilay and lee, 2004), <papid> N04-1015 </papid>discourse relations (pitler and nenkova, 2008; <papid> D08-1020 </papid>lin et al,2011) <papid> P11-1100 </papid>and coreference patterns (barzilay and lap ata, 2008) <papid> J08-1001 </papid>learn from large corpora can be used to predict coherence.</nextsent>
<nextsent>but prior metrics are not proposed as unique to any genre.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4760">
<title id=" N12-2010.xml">automatic metrics for genre specific text quality </title>
<section> proposing new discourse-level features: in.  </section>
<citcontext>
<prevsection>
<prevsent>newer coherence measures do not focus on reader abilities.
</prevsent>
<prevsent>they are typically run on news articles and assume an adult audience.
</prevsent>
</prevsection>
<citsent citstr=" P06-2103 ">
they show that word co-occurrence (soricut and marcu, 2006), <papid> P06-2103 </papid>sub topic structure (barzilay and lee, 2004), <papid> N04-1015 </papid>discourse relations (pitler and nenkova, 2008; <papid> D08-1020 </papid>lin et al,2011) <papid> P11-1100 </papid>and coreference patterns (barzilay and lap ata, 2008) <papid> J08-1001 </papid>learn from large corpora can be used to predict coherence.</citsent>
<aftsection>
<nextsent>but prior metrics are not proposed as unique to any genre.
</nextsent>
<nextsent>some metrics using word patterns (si and callan, 2001; barzilay and lee, 2004) <papid> N04-1015 </papid>are domain dependent in that they require documents from the target domain for training.</nextsent>
<nextsent>but they can be trained for any domain in this manner.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4764">
<title id=" N12-2010.xml">automatic metrics for genre specific text quality </title>
<section> proposing new discourse-level features: in.  </section>
<citcontext>
<prevsection>
<prevsent>newer coherence measures do not focus on reader abilities.
</prevsent>
<prevsent>they are typically run on news articles and assume an adult audience.
</prevsent>
</prevsection>
<citsent citstr=" P11-1100 ">
they show that word co-occurrence (soricut and marcu, 2006), <papid> P06-2103 </papid>sub topic structure (barzilay and lee, 2004), <papid> N04-1015 </papid>discourse relations (pitler and nenkova, 2008; <papid> D08-1020 </papid>lin et al,2011) <papid> P11-1100 </papid>and coreference patterns (barzilay and lap ata, 2008) <papid> J08-1001 </papid>learn from large corpora can be used to predict coherence.</citsent>
<aftsection>
<nextsent>but prior metrics are not proposed as unique to any genre.
</nextsent>
<nextsent>some metrics using word patterns (si and callan, 2001; barzilay and lee, 2004) <papid> N04-1015 </papid>are domain dependent in that they require documents from the target domain for training.</nextsent>
<nextsent>but they can be trained for any domain in this manner.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4767">
<title id=" N12-2010.xml">automatic metrics for genre specific text quality </title>
<section> proposing new discourse-level features: in.  </section>
<citcontext>
<prevsection>
<prevsent>but they can be trained for any domain in this manner.
</prevsent>
<prevsent>however recent work show that genre-specific indicators could be quite useful for applications.
</prevsent>
</prevsection>
<citsent citstr=" P09-1025 ">
mcintyre and lapata (2009) <papid> P09-1025 </papid>automatically generate short childrens stories using patterns of event and entity co-occurrences.</citsent>
<aftsection>
<nextsent>they find that people judge their stories as better when the text is optimized not only for coherence and but also its interesting nature.they use supervised approach to predict the interest value for story during the generation process.burstein et al (2010) <papid> N10-1099 </papid>find that for predicting the coherence of student essays, better accuracies can be obtained by augmenting generic coherence metrics with features related to student writing such as word variety and spelling errors.in my own work on automatic evaluation of summaries (pitler et al, 2010), <papid> P10-1056 </papid>have observed the impact of genre.</nextsent>
<nextsent>we consider corpus of summaries written by people and those produced by automaticsystems.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4768">
<title id=" N12-2010.xml">automatic metrics for genre specific text quality </title>
<section> proposing new discourse-level features: in.  </section>
<citcontext>
<prevsection>
<prevsent>however recent work show that genre-specific indicators could be quite useful for applications.
</prevsent>
<prevsent>mcintyre and lapata (2009) <papid> P09-1025 </papid>automatically generate short childrens stories using patterns of event and entity co-occurrences.</prevsent>
</prevsection>
<citsent citstr=" N10-1099 ">
they find that people judge their stories as better when the text is optimized not only for coherence and but also its interesting nature.they use supervised approach to predict the interest value for story during the generation process.burstein et al (2010) <papid> N10-1099 </papid>find that for predicting the coherence of student essays, better accuracies can be obtained by augmenting generic coherence metrics with features related to student writing such as word variety and spelling errors.in my own work on automatic evaluation of summaries (pitler et al, 2010), <papid> P10-1056 </papid>have observed the impact of genre.</citsent>
<aftsection>
<nextsent>we consider corpus of summaries written by people and those produced by automaticsystems.
</nextsent>
<nextsent>psycho linguistic metrics previously proposed for analyzing coherence of human texts work successfully on human summaries but are less accurate for system summaries.
</nextsent>
<nextsent>similarly, metrics which predict the fluency of machine translations accurately, work barely above baseline for judging the grammaticality of sentences from human sum 56 maries.
</nextsent>
<nextsent>but they give high accuracies on machine summary sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4769">
<title id=" N12-2010.xml">automatic metrics for genre specific text quality </title>
<section> proposing new discourse-level features: in.  </section>
<citcontext>
<prevsection>
<prevsent>however recent work show that genre-specific indicators could be quite useful for applications.
</prevsent>
<prevsent>mcintyre and lapata (2009) <papid> P09-1025 </papid>automatically generate short childrens stories using patterns of event and entity co-occurrences.</prevsent>
</prevsection>
<citsent citstr=" P10-1056 ">
they find that people judge their stories as better when the text is optimized not only for coherence and but also its interesting nature.they use supervised approach to predict the interest value for story during the generation process.burstein et al (2010) <papid> N10-1099 </papid>find that for predicting the coherence of student essays, better accuracies can be obtained by augmenting generic coherence metrics with features related to student writing such as word variety and spelling errors.in my own work on automatic evaluation of summaries (pitler et al, 2010), <papid> P10-1056 </papid>have observed the impact of genre.</citsent>
<aftsection>
<nextsent>we consider corpus of summaries written by people and those produced by automaticsystems.
</nextsent>
<nextsent>psycho linguistic metrics previously proposed for analyzing coherence of human texts work successfully on human summaries but are less accurate for system summaries.
</nextsent>
<nextsent>similarly, metrics which predict the fluency of machine translations accurately, work barely above baseline for judging the grammaticality of sentences from human sum 56 maries.
</nextsent>
<nextsent>but they give high accuracies on machine summary sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4773">
<title id=" N12-2010.xml">automatic metrics for genre specific text quality </title>
<section> patterns in communicative goals.  </section>
<citcontext>
<prevsection>
<prevsent>in fact, this intuition of seeing texts as sequence of semantic zones is well-understood for the academic writing genre.
</prevsent>
<prevsent>prior research has identified that small set of argumentative zones exist in academic articles such as motivation, results, prior work, speculations and descriptions.
</prevsent>
</prevsection>
<citsent citstr=" W00-1302 ">
they also 1http://www.nist.gov/tac/ found that sentences could be manually annotated into zones with high agreement and automatically predicting the zone for sentence can also be done with high accuracy (teufel and moens, 2000; <papid> W00-1302 </papid>liakata et al, 2010).</citsent>
<aftsection>
<nextsent>we hypothesize that these zones would also have certain distribution and sequence in well-written articles versus others and propose metric based on this aspect for the academic writing and science journalism genres.rather than using predefined set of communicative goals, we develop an unsupervised technique to identify analogs to semantic zones and use the patterns in zones to predict coherence (louis and nenkova, 2012a).
</nextsent>
<nextsent>our key idea is that the syntax of sentence can be useful proxy for its communicative goal.
</nextsent>
<nextsent>for example, questions and definition sentences have unique syntax.
</nextsent>
<nextsent>we extend this ideato large scale analysis.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4774">
<title id=" N12-2010.xml">automatic metrics for genre specific text quality </title>
<section> general-specific nature of sentences.  </section>
<citcontext>
<prevsection>
<prevsent>some details have to be omitted and others made more general.
</prevsent>
<prevsent>so we explore the preferred degree of general-specific content and its relationship to text quality for summaries.
</prevsent>
</prevsection>
<citsent citstr=" W11-1605 ">
57 we developed classifier to distinguish between general and specific sentences from news articles (louis and nenkova, 2011<papid> W11-1605 </papid>a; louis and nenkova, 2012b).</citsent>
<aftsection>
<nextsent>the classifier uses features such as the word specificity, presence of named entities, word polarity, counts of different phrase types, sentence length, likelihood under language models and the identities of the words themselves.
</nextsent>
<nextsent>for example, sentences with named entities tended to be specific whereas sentences with shorter verb phrases and more polarity words were general.
</nextsent>
<nextsent>this classifier was trained on sentences multiply annotated by people as general or specific and produces an accuracy of about 79%.
</nextsent>
<nextsent>further the classifier confidence was found tobe indicative of the annotator agreement on the sentences; when there was high agreement that sentence was either general or specific, the classifier also made very confident prediction for the correct class.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4778">
<title id=" N12-2010.xml">automatic metrics for genre specific text quality </title>
<section> information cohesiveness.  </section>
<citcontext>
<prevsection>
<prevsent>aspect.
</prevsent>
<prevsent>for this purpose, we want to identify metrics which can indicate cohesiveness and focus of an article.
</prevsent>
</prevsection>
<citsent citstr=" E09-1062 ">
in our studies so far, we have have developed cohesiveness metrics for clusters of articles (nenkova and louis, 2008; louis and nenkova, 2009).<papid> E09-1062 </papid></citsent>
<aftsection>
<nextsent>in future work, we will explore how these metrics work for individual articles.
</nextsent>
<nextsent>information quality also arises in the context of source documents given for automatic summarization.
</nextsent>
<nextsent>particularly for systems which summarize on line news, the input is created by clustering together news on the same topic from different sources.
</nextsent>
<nextsent>for example, cluster may be created for the japanese earthquake and aftermath.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4779">
<title id=" N12-1085.xml">grammatical structures for word level sentiment detection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>sentiment analysis plays large role in business, politics, and is itself vibrant research area (bollen et al , 2010).
</prevsent>
<prevsent>effective sentiment analysis for texts such as newswire depends on the ability to extract who(source) is saying what (target).
</prevsent>
</prevsection>
<citsent citstr=" L08-1087 ">
fine-grained sentiment analysis requires identifying the sources and targets directly relevant to sentiment bearing expressions (ruppenhofer et al , 2008).<papid> L08-1087 </papid></citsent>
<aftsection>
<nextsent>for example, consider the following sentence from major information technology (it) business journal: lloyd hession, chief security officer at btradianz in new york, said that virtual ization also opens up slew of potential network access control issues.
</nextsent>
<nextsent>there are three entities in the sentence that have the capacity to express an opinion: lloyd hession, bt radianz, and new york.
</nextsent>
<nextsent>these are potential opinionsources.
</nextsent>
<nextsent>there are also number of mentioned concepts that could serve as the topic of an opinion in the sentence, or target.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4780">
<title id=" N12-1085.xml">grammatical structures for word level sentiment detection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the challenging task is to discriminate between these mentions and choose the ones that are relevant to the user.
</prevsent>
<prevsent>furthermore, such system must also indicate the content of the opinion itself.
</prevsent>
</prevsection>
<citsent citstr=" W06-0301 ">
this means that we are actually searching for all triples {source, target, opinion} in this sentence (kim and hovy, 2006) <papid> W06-0301 </papid>and throughout each document in the corpus.</citsent>
<aftsection>
<nextsent>in this case, we want to identify that lloyd hession is the source of an opinion, slew of network issues,?
</nextsent>
<nextsent>about target, virtualization.
</nextsent>
<nextsent>providing such fine-grained annotations would enrich information extraction, question answering, and corpus exploration applications by letting users see who is saying what with what opinion (wilson et al , 2005; <papid> H05-1044 </papid>stoyanov and cardie, 2006).<papid> W06-1640 </papid></nextsent>
<nextsent>we motivate the need for grammatically-focused approach to fine-grained opinion mining and situate it 667 within the context of existing work in section 2.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4781">
<title id=" N12-1085.xml">grammatical structures for word level sentiment detection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this case, we want to identify that lloyd hession is the source of an opinion, slew of network issues,?
</prevsent>
<prevsent>about target, virtualization.
</prevsent>
</prevsection>
<citsent citstr=" H05-1044 ">
providing such fine-grained annotations would enrich information extraction, question answering, and corpus exploration applications by letting users see who is saying what with what opinion (wilson et al , 2005; <papid> H05-1044 </papid>stoyanov and cardie, 2006).<papid> W06-1640 </papid></citsent>
<aftsection>
<nextsent>we motivate the need for grammatically-focused approach to fine-grained opinion mining and situate it 667 within the context of existing work in section 2.
</nextsent>
<nextsent>we propose supervised technique for learning opinion target relations from dependency graphs in way that preserves syntactic coherence and semantic compo sitionality.
</nextsent>
<nextsent>in addition to being theoretically sound ? lacuna identified in many sentiment systems1 ? such approaches improve downstream sentiment tasks (moilanen and pulman, 2007).
</nextsent>
<nextsent>there are multiple types of downstream tasks that potentially require the retrieval of {source, target, opinion} relations on sentence-by-sentence basis.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4782">
<title id=" N12-1085.xml">grammatical structures for word level sentiment detection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this case, we want to identify that lloyd hession is the source of an opinion, slew of network issues,?
</prevsent>
<prevsent>about target, virtualization.
</prevsent>
</prevsection>
<citsent citstr=" W06-1640 ">
providing such fine-grained annotations would enrich information extraction, question answering, and corpus exploration applications by letting users see who is saying what with what opinion (wilson et al , 2005; <papid> H05-1044 </papid>stoyanov and cardie, 2006).<papid> W06-1640 </papid></citsent>
<aftsection>
<nextsent>we motivate the need for grammatically-focused approach to fine-grained opinion mining and situate it 667 within the context of existing work in section 2.
</nextsent>
<nextsent>we propose supervised technique for learning opinion target relations from dependency graphs in way that preserves syntactic coherence and semantic compo sitionality.
</nextsent>
<nextsent>in addition to being theoretically sound ? lacuna identified in many sentiment systems1 ? such approaches improve downstream sentiment tasks (moilanen and pulman, 2007).
</nextsent>
<nextsent>there are multiple types of downstream tasks that potentially require the retrieval of {source, target, opinion} relations on sentence-by-sentence basis.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4783">
<title id=" N12-1085.xml">grammatical structures for word level sentiment detection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>an increasingly significant application area is in the use of large corpora in social science.
</prevsent>
<prevsent>this area of research requires the exploration and aggregation ofdata about the relationships between discourses, organizations, and people.
</prevsent>
</prevsection>
<citsent citstr=" C10-2126 ">
for example, the it business press data that we use in this work belongs to larger research program (tsui et al , 2009; sayeed et al , 2010) <papid> C10-2126 </papid>of exploring industry opinion leadership.</citsent>
<aftsection>
<nextsent>it business press text is one type of text in which many entities and opinions can appear intermingled with one another in small amount of text.another application for fine-grained sentiment relation retrieval of this type is paraphrasing, where attribution of which opinion belongs to which entities may be important for producing useful and accurate output, since source and target identification errors can change the entire meaning of an output text.
</nextsent>
<nextsent>unlike previous approaches that ignore syntax, weuse sentences syntactic structure to build probabilistic model that encodes whether word is opinion bearing as latent variable.
</nextsent>
<nextsent>we build data structure we call syntactic relatedness trie?
</nextsent>
<nextsent>(section 3) that serves as the skeleton for graphical model over the sentiment relevance of words (section 4).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4784">
<title id=" N12-1085.xml">grammatical structures for word level sentiment detection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(section 3) that serves as the skeleton for graphical model over the sentiment relevance of words (section 4).
</prevsent>
<prevsent>this approach allows us to learn features that predict opinion bearing constructions from grammatical structures.
</prevsent>
</prevsection>
<citsent citstr=" P11-2019 ">
because of dearth of resources for this fine-grained task, we also develop new crowdsourcing techniques for labeling word-level, syntactically informed sen1alm (2011) <papid> P11-2019 </papid>recently argued that work on sentiment analysis needs to de-emphasize the goal of building systems that are high-performing?</citsent>
<aftsection>
<nextsent>by traditional measures, because the field risks sacrificing opportunities that may lead to more thorough understanding of language uses and users?
</nextsent>
<nextsent>in relation to subjective phenomena.
</nextsent>
<nextsent>the work we present in this paper therefore focuses on extracting meaningful features as an investment in future work that directly improves retrieval performance.
</nextsent>
<nextsent>timent (section 5).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4785">
<title id=" N12-1085.xml">grammatical structures for word level sentiment detection </title>
<section> background and existing work.  </section>
<citcontext>
<prevsection>
<prevsent>however, it is much harder to find obvious features that tell us whether virtual ization?
</prevsent>
<prevsent>is the target of an opinion.
</prevsent>
</prevsection>
<citsent citstr=" D10-1101 ">
the most recent target identification techniques use machine learning to determine the presence of target from known opinionated language (jakob and gurevych, 2010).<papid> D10-1101 </papid></citsent>
<aftsection>
<nextsent>even when targets are identified we must decide if an opinion is expressed, since not all target mention swill necessarily be accompanied by opinion expressions.
</nextsent>
<nextsent>returning to the first example sentence, wecould say that the negative opinion about virtualiza tion is expressed by the words slew?
</nextsent>
<nextsent>and issues?.a system that could automatically make this discovery must draw on grammatical relationships between targets and the opinion bearing words.
</nextsent>
<nextsent>parsers reveal these relationships, but the relationships are often indirect.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4787">
<title id=" N12-1085.xml">grammatical structures for word level sentiment detection </title>
<section> background and existing work.  </section>
<citcontext>
<prevsection>
<prevsent>the variability of language prevents complete enumeration of all intervening items that make the relationships indirect, but examples include negation and intensifiers, which change opinion, andsentiment-neutral words, which fill syntactic or stylistic needs.
</prevsent>
<prevsent>in this paper, we cope with the variability of expression by using supervised machine learning to generalize across observations and learn which features best enable us to identify opinionated language.
</prevsent>
</prevsection>
<citsent citstr=" W06-1651 ">
existing work in this area often uses semantic frames and role labeling (kim and hovy, 2006; <papid> W06-0301 </papid>choi et al , 2006), <papid> W06-1651 </papid>but resources typically used in these tasks (e.g. framenet) are not exhaustive.</citsent>
<aftsection>
<nextsent>more general approaches (ruppenhofer et al , 2008) <papid> L08-1087 </papid>describe semantic and discourse contexts of opinion sources and targets cannot recognize them.</nextsent>
<nextsent>when techniques do identify targets via syntax,they often only use grammar as feature in an otherwise syntax-agnostic model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4790">
<title id=" N12-1085.xml">grammatical structures for word level sentiment detection </title>
<section> background and existing work.  </section>
<citcontext>
<prevsection>
<prevsent>when techniques do identify targets via syntax,they often only use grammar as feature in an otherwise syntax-agnostic model.
</prevsent>
<prevsent>some work of this 668 nature merely identifies targets without providing the syntactic evidence necessary to find domain-relevant opinionated language (jakob and gurevych, 2010), <papid> D10-1101 </papid>relying on lists of opinion keywords.</prevsent>
</prevsection>
<citsent citstr=" J11-1002 ">
there is also work (qiu et al , 2011) <papid> J11-1002 </papid>that uses predefined heuristics over dependency parses to identify both targets and opinion keywords but does not acquire new syntacticheuristics.</citsent>
<aftsection>
<nextsent>other work (nakagawa et al , 2010) <papid> N10-1120 </papid>is similar to ours in that it uses factor graph modeling over dependency parse formalism, but it assumes that opinionated language is known priori and focuses on polarity classification, while our work tackles themore fundamental problem of identifying the opinionated language itself.</nextsent>
<nextsent>little work has been done to perform target and opinion-expression extraction jointly, especially in way that extracts features for downstream processing.this dearth persists despite evidence that such information improves sentiment analysis (moilanen and pulman, 2007).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4791">
<title id=" N12-1085.xml">grammatical structures for word level sentiment detection </title>
<section> background and existing work.  </section>
<citcontext>
<prevsection>
<prevsent>some work of this 668 nature merely identifies targets without providing the syntactic evidence necessary to find domain-relevant opinionated language (jakob and gurevych, 2010), <papid> D10-1101 </papid>relying on lists of opinion keywords.</prevsent>
<prevsent>there is also work (qiu et al , 2011) <papid> J11-1002 </papid>that uses predefined heuristics over dependency parses to identify both targets and opinion keywords but does not acquire new syntacticheuristics.</prevsent>
</prevsection>
<citsent citstr=" N10-1120 ">
other work (nakagawa et al , 2010) <papid> N10-1120 </papid>is similar to ours in that it uses factor graph modeling over dependency parse formalism, but it assumes that opinionated language is known priori and focuses on polarity classification, while our work tackles themore fundamental problem of identifying the opinionated language itself.</citsent>
<aftsection>
<nextsent>little work has been done to perform target and opinion-expression extraction jointly, especially in way that extracts features for downstream processing.this dearth persists despite evidence that such information improves sentiment analysis (moilanen and pulman, 2007).
</nextsent>
<nextsent>an advantage of our proposed approach is that wecan use dependency paths in order to capture situations where the relations are non-compositional or semantically motivated.
</nextsent>
<nextsent>in section 5, we describe dataset that has the additional property that opinion is expressed in ways that require external pragmatic knowledge of the domain.
</nextsent>
<nextsent>an advantage of arbitrary, non-local dependencies is that we can treat this knowledge as part of the model we learn via long distance chains, which can capture pragmatics.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4792">
<title id=" N12-1085.xml">grammatical structures for word level sentiment detection </title>
<section> encoding srts as factor graph.  </section>
<citcontext>
<prevsection>
<prevsent>factors are functions that represent relationships, i.e. probabilistic dependencies, among the variables; the product of all factors gives the complete joint distribution p. each factor fi can take as input some corresponding subset of variables yi from z. we can then write the relationship as follows: p(z) ? k=1 fk(yk) our goal is to discover the values for the variables that best explain dataset.
</prevsent>
<prevsent>while there are many approaches for inference in statistical models, we turn to mcmc methods (neal, 1993) to discover the underlying structure of the model.
</prevsent>
</prevsection>
<citsent citstr=" P05-1045 ">
more specifically, we seek posterior distribution over latent variables parent node child 1 child 2 child 3 g figure 3: graphical model of srt factors that partition words in sentence into flow and inert groups; we estimate this posterior using gibbs sampling (finkel et al , 2005).<papid> P05-1045 </papid></citsent>
<aftsection>
<nextsent>the sampler requires an initial state that respects the invariant.
</nextsent>
<nextsent>our initial setting is produced by iterat ing through all labels in the srt forest and randomly setting them as either flow or inert with uniform probability.a gibbs sampler samples new variable assignments from the conditional distribution, treating the variable assignments for all other variables fixed.
</nextsent>
<nextsent>however, the assignment of single node is highly coupled with its neighbors, so block sampler is used to propose changes to groups nodes that respect the flow labeling of the overall assignments.
</nextsent>
<nextsent>this was implemented by changing the proposal distribution used by the facto rie framework (mccallum et al , 2009).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4793">
<title id=" N12-1085.xml">grammatical structures for word level sentiment detection </title>
<section> data source.  </section>
<citcontext>
<prevsection>
<prevsent>within phrase,however, some words may contribute more than others to the statement of an opinion.
</prevsent>
<prevsent>we developed our own annotations to discover such distinctions3.
</prevsent>
</prevsection>
<citsent citstr=" W11-1510 ">
we describe these briefly here; more information about the development of the data source can be found in sayeed et al  (2011).<papid> W11-1510 </papid></citsent>
<aftsection>
<nextsent>5.1 information technology business press.
</nextsent>
<nextsent>our work is part of larger collaboration with social scientists to study the diffusion of information technology (it) innovations through society by identifying opinion leaders and it-relevant opinionated language rogers (2003).
</nextsent>
<nextsent>thus, we focus on collection of articles from the it professional magazine, information week, from the years 1991 to 2008.
</nextsent>
<nextsent>3to download the corpus, visit http://www.umiacs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4794">
<title id=" N12-1085.xml">grammatical structures for word level sentiment detection </title>
<section> data source.  </section>
<citcontext>
<prevsection>
<prevsent>we consider this list of target termsto be complete, which allows us to focus on discovering opinion-bearing text associated with these targets.
</prevsent>
<prevsent>5.2 crowd sourced annotation process.
</prevsent>
</prevsection>
<citsent citstr=" W09-1904 ">
our process for obtaining gold standard data involves multiple levels of human annotation including on crowdsourcing platforms hsueh et al  (2009).<papid> W09-1904 </papid></citsent>
<aftsection>
<nextsent>there are 75k sentences with it concept mentions, only minority of which express relevant opinions.hired undergraduate students searched random selection of these sentences and found 219 that contain these opinions.
</nextsent>
<nextsent>we used cosine-similarity to rank the remaining sentences against the 219.
</nextsent>
<nextsent>we then needed to identify which of the words contained an opinion.
</nextsent>
<nextsent>we excluded all words that were common function words (e.g.,the?, in?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4795">
<title id=" P03-1027.xml">recognizing expressions of commonsense psychology in english text </title>
<section> commonsense psychology in language.  </section>
<citcontext>
<prevsection>
<prevsent>commonsense psychology has been studied in many fields, sometimes using the terms folk psychology or theory of mind, as both set of beliefs that people have about the mind and as set of everyday reasoning abilities.
</prevsent>
<prevsent>within the field of computational linguistics,the study of commonsense psychology has notre ceived special attention, and is generally viewed as just one of the many conceptual areas that must be addressed in building large-scale lexical-semantic resources for language processing.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
although there have been number of projects that have included concepts of commonsense psychology as part of larger lexical-semantic resource, e.g. the berkeley framenet project (baker et al, 1998), <papid> P98-1013 </papid>none have attempted to achieve high degree of breadth or depth over the sorts of expressions that people use to refer to mental states and processes.the lack of large-scale resource for the analysis of language for commonsense psychological concepts is seen as barrier to the development ofa range of potential computer applications that involve text analysis, including the following: ? natural language interfaces to mixed-initiative planning systems (ferguson &amp; allen, 1993;traum, 1993) require the ability to map expressions of users?</citsent>
<aftsection>
<nextsent>beliefs, goals, and plans(among other commonsense psychology concepts) onto formalizations that can be manipulated by automated planning algorithms.
</nextsent>
<nextsent>automated question answering systems(voorhees &amp; buckland, 2002) require the ability to tag and index text corpora with the relevant commonsense psychology concepts inorder to handle questions concerning the beliefs, expectations, and intentions of people.
</nextsent>
<nextsent>research efforts within the field of psychology that employ automated corpus analysis techniques to investigate developmental and mental illness impacts on language production, e.g.reboul &amp; saba tiers (2001) study of the discourse of schizophrenic patients, require the ability to identify all references to certain psychological concepts in order to draw statistical comparisons.in order to enable future applications, we undertook new effort to meet this need for linguistic resource.
</nextsent>
<nextsent>this paper describes our efforts in building large-scale lexical-semantic resource for automated processing of natural language text about mental states and processes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4799">
<title id=" P04-1043.xml">a study on convolution kernels for shallow statistic parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>0 arg.
</prevsent>
<prevsent>m n np n vp paulin gives lecture pp in rome arg.
</prevsent>
</prevsection>
<citsent citstr=" P02-1031 ">
1 figure 1: predicate argument structure in parse-tree representation.several machine learning approaches for argument identification and classification have been developed (gildea and jurasfky, 2002; gildeaand palmer, 2002; <papid> P02-1031 </papid>surdeanu et al , 2003; <papid> P03-1002 </papid>hacioglu et al , 2003).</citsent>
<aftsection>
<nextsent>their common characteristic is the adoption of feature spaces that modelpredicate-argument structures in flat representation.
</nextsent>
<nextsent>on the contrary, convolution kernels aim to capture structural information in term of sub-structures, providing viable alternative to flat features.
</nextsent>
<nextsent>in this paper, we select portions of syntactic trees, which include predicate/argument salient sub-structures, to define convolution kernels for the task of predicate argument classification.
</nextsent>
<nextsent>in particular, our kernels aim to (a) represent the relation between predicate and one of its arguments and (b) to capture the overall argument structure of the target predicate.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4800">
<title id=" P04-1043.xml">a study on convolution kernels for shallow statistic parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>0 arg.
</prevsent>
<prevsent>m n np n vp paulin gives lecture pp in rome arg.
</prevsent>
</prevsection>
<citsent citstr=" P03-1002 ">
1 figure 1: predicate argument structure in parse-tree representation.several machine learning approaches for argument identification and classification have been developed (gildea and jurasfky, 2002; gildeaand palmer, 2002; <papid> P02-1031 </papid>surdeanu et al , 2003; <papid> P03-1002 </papid>hacioglu et al , 2003).</citsent>
<aftsection>
<nextsent>their common characteristic is the adoption of feature spaces that modelpredicate-argument structures in flat representation.
</nextsent>
<nextsent>on the contrary, convolution kernels aim to capture structural information in term of sub-structures, providing viable alternative to flat features.
</nextsent>
<nextsent>in this paper, we select portions of syntactic trees, which include predicate/argument salient sub-structures, to define convolution kernels for the task of predicate argument classification.
</nextsent>
<nextsent>in particular, our kernels aim to (a) represent the relation between predicate and one of its arguments and (b) to capture the overall argument structure of the target predicate.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4802">
<title id=" P04-1043.xml">a study on convolution kernels for shallow statistic parsing </title>
<section> convolution kernels for semantic.  </section>
<citcontext>
<prevsection>
<prevsent>as suggested in section 2 we can map them into vectors in  and evaluate implicitly the scalar product among them.
</prevsent>
<prevsent>3.3 predicate/argument structure.
</prevsent>
</prevsection>
<citsent citstr=" P02-1034 ">
kernel (pak)given the semantic objects defined in the previous section, we design convolution kernel in way similar to the parse-tree kernel proposed in (collins and duffy, 2002).<papid> P02-1034 </papid></citsent>
<aftsection>
<nextsent>we divide our mapping ? in two steps: (1) from the semantic structure space (i.e. paf or scf objects) to the set of all their possible sub-structures element in fp,a with an abuse of notation we use it to indicate the objects themselves.
</nextsent>
<nextsent>np n talk np n np n d a talk np n np n vp delivers talk delivers np n vp a talk np n vp np n vp a np vp talk a np n vp delivers talk np n vp delivers np n vp delivers np vp np vp delivers talk figure 4: all 17 valid fragments of the semantic structure associated with arg 1 of figure 2.
</nextsent>
<nextsent>f ? = {f 1, .., ? |f ?|} and (2) from ? to  |f ?|.
</nextsent>
<nextsent>an example of features in ? is givenin figure 4 where the whole set of fragments, deliver,arg1, of the argument structure fdeliver,arg1, is shown (see also figure 2).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4805">
<title id=" P04-1043.xml">a study on convolution kernels for shallow statistic parsing </title>
<section> convolution kernels for semantic.  </section>
<citcontext>
<prevsection>
<prevsent>in (collins and duffy, 2002), <papid> P02-1034 </papid>it has been shown that ii(nx)ii(nz) = ?(nx, nz)can be computed in o(|nx| ? |nz|) by the following recursive relation: (1) if the productions at nx and nz are different then ?(nx, nz) = 0; 2a fragment can appear several times in parse-tree, thus each fragment occurrence is considered as different element in p,a.</prevsent>
<prevsent>(2) if the productions at nx and nz are the same, and nx and nz are pre-terminals then ?(nx, nz) = 1; (3) if the productions at nx and nz are the same, and nx and nz are not pre-terminals then ?(nx, nz) = nc(nx) ? j=1 (1 + ?(ch(nx, j), ch(nz , j))), where nc(nx) is the number of the children of nx and ch(n, i) is the i-th child of the node n. note that as the productions are the same ch(nx, i) = ch(nz, i).</prevsent>
</prevsection>
<citsent citstr=" W04-2403 ">
this kind of kernel has the drawback of assigning more weight to larger structures while the argument type does not strictly depend on the size of the argument (moschittiand bejan, 2004).<papid> W04-2403 </papid></citsent>
<aftsection>
<nextsent>to overcome this problem we can scale the relative importance of the tree fragments using parameter ? for the cases (2) and (3), i.e. ?(nx, nz) = ? and ?(nx, nz) = ? nc(nx) j=1 (1 + ?(ch(nx, j), ch(nz , j))) respectively.it is worth noting that even if the above equations define kernel function similar to the one proposed in (collins and duffy, 2002), <papid> P02-1034 </papid>the substructures on which it operates are different from the parse-tree kernel.</nextsent>
<nextsent>for example, figure 4 shows that structures such as [vp [v] [np]], [vp [v delivers ] [np]] and [vp [v] [np [dt] [n]]] are valid features, but these fragments (and manyothers) are not generated by complete production, i.e. vp ? np pp.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4808">
<title id=" P04-1043.xml">a study on convolution kernels for shallow statistic parsing </title>
<section> the experiments.  </section>
<citcontext>
<prevsection>
<prevsent>kscf = kscf kpd |kscf |?|kpd |, i.e. the normalized product between scf-based kernel and the polynomial kernel.
</prevsent>
<prevsent>4.1 corpora set-up.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
the above kernels were experimented over two corpora: propbank (www.cis.upenn.edu/ace) along with penn treebank5 2 (marcus et al , 1993) <papid> J93-2004 </papid>and framenet.</citsent>
<aftsection>
<nextsent>propbank contains about 53,700 sentence sand fixed split between training and testing which has been used in other researches e.g., (gildea and palmer, 2002; <papid> P02-1031 </papid>surdeanu et al ,2003; <papid> P03-1002 </papid>hacioglu et al , 2003).</nextsent>
<nextsent>in this split, sections from 02 to 21 are used for training, section23 for testing and sections 1 and 22 as developing set.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4811">
<title id=" P04-1043.xml">a study on convolution kernels for shallow statistic parsing </title>
<section> the experiments.  </section>
<citcontext>
<prevsection>
<prevsent>additionally, 30% of training was used as avalidation-set.
</prevsent>
<prevsent>the sentences were processed using collins?
</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
parser (collins, 1997) <papid> P97-1003 </papid>to generate parse-trees automatically.</citsent>
<aftsection>
<nextsent>4.2 classification set-up.
</nextsent>
<nextsent>the classifier evaluations were carried out using the svm-light software (joachims, 1999) available at svmlight.joachims.org with the defaultpolynomial kernel for standard feature evaluations.
</nextsent>
<nextsent>to process paf and scf, we implemented our own kernels and we used them in side svm-light.the classification performances were evaluated using the f1 measure7 for single argument sand the accuracy for the final multi-class classifier.
</nextsent>
<nextsent>this latter choice allows us to compare the results with previous literature works, e.g.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4815">
<title id=" P01-1025.xml">methods for the qualitative evaluation of lexical association measures </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>finally, methods and strategies for handling low-frequency data are suggested.
</prevsent>
<prevsent>the measures2 ? mutual information (
</prevsent>
</prevsection>
<citsent citstr=" P89-1010 ">
) (church and hanks, 1989), <papid> P89-1010 </papid>the log-likelihood ratio test (dunning, 1993), <papid> J93-1003 </papid>two statistical tests: t-test and  -test, and co-occurrence frequency ? are applied to two sets of data: adjective-noun (adjn) pairs and preposition-noun-verb (pnv) triples, where the ams are applied to (pn,v) pairs.</citsent>
<aftsection>
<nextsent>see section 3 for description of the base data.
</nextsent>
<nextsent>for evaluation of the association measures,  -best strategies (section 4.1) are supplemented with precision and recall graphs (section 4.2) overthe complete datasets.
</nextsent>
<nextsent>samples comprising particular frequency strata (high versus low frequen cies) are examined (section 4.3).
</nextsent>
<nextsent>in section 5, methods for the treatment of low-frequency data, single (hapaxlegomena) and double occurrences are discussed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4816">
<title id=" P01-1025.xml">methods for the qualitative evaluation of lexical association measures </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>finally, methods and strategies for handling low-frequency data are suggested.
</prevsent>
<prevsent>the measures2 ? mutual information (
</prevsent>
</prevsection>
<citsent citstr=" J93-1003 ">
) (church and hanks, 1989), <papid> P89-1010 </papid>the log-likelihood ratio test (dunning, 1993), <papid> J93-1003 </papid>two statistical tests: t-test and  -test, and co-occurrence frequency ? are applied to two sets of data: adjective-noun (adjn) pairs and preposition-noun-verb (pnv) triples, where the ams are applied to (pn,v) pairs.</citsent>
<aftsection>
<nextsent>see section 3 for description of the base data.
</nextsent>
<nextsent>for evaluation of the association measures,  -best strategies (section 4.1) are supplemented with precision and recall graphs (section 4.2) overthe complete datasets.
</nextsent>
<nextsent>samples comprising particular frequency strata (high versus low frequen cies) are examined (section 4.3).
</nextsent>
<nextsent>in section 5, methods for the treatment of low-frequency data, single (hapaxlegomena) and double occurrences are discussed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4818">
<title id=" P01-1025.xml">methods for the qualitative evaluation of lexical association measures </title>
<section> hapaxlegomena and double.  </section>
<citcontext>
<prevsection>
<prevsent>one way to deal with low frequency candidates is the introduction of cut off thresholds.
</prevsent>
<prevsent>this is widely used strategy,and it is motivated by the fact that it is in general highly problematic to draw conclusions from low-frequency data with statistical methods (cf.
</prevsent>
</prevsection>
<citsent citstr=" J00-3001 ">
weeber et al (2000) <papid> J00-3001 </papid>and figure 8).</citsent>
<aftsection>
<nextsent>a practical reason for cutting off low-frequency data is the need to reduce the amount of manual work when the complete dataset has to be evaluated, which is precondition for the exact calculation of recall and for plotting precision curves.
</nextsent>
<nextsent>the major drawback of an approach where all low-frequency candidates are excluded is that alarge part of the data is lost for collocation extraction.
</nextsent>
<nextsent>in our data, for instance, 80% of the full setof pnv data and 58% of the adjn data are ha paxes.
</nextsent>
<nextsent>thus it is important to know how many (and which) true collocations there are among the excluded low-frequency candidates.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4819">
<title id=" P00-1017.xml">using existing systems to supplement small amounts of annotated grammatical relations training data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>grs are often stored in structures similar to the fstructures of lexical-functional grammar (ka plan, 1994).
</prevsent>
<prevsent>a complication is that dierent sets of grsare useful for dierent purposes.
</prevsent>
</prevsection>
<citsent citstr=" W99-0706 ">
for example, ferro et al  (1999) <papid> W99-0706 </papid>is interested in semantic interpretation, and needs to dierentiate between time, location and other modiers.</citsent>
<aftsection>
<nextsent>the sparkle project (carroll et al , 1997),on the other hand, does not dierentiate between these types of modiers.
</nextsent>
<nextsent>as has been mentioned by john carroll (personal commu nication), combining modier types together is ne for information retrieval.
</nextsent>
<nextsent>also, having less dierentiation of the modiers can make it easier to nd them (ferro et al , 1999).<papid> W99-0706 </papid></nextsent>
<nextsent>furthermore, unless the desired set of grs matches the set al eady annotated in some large training corpus, 1 one will have to either manually write rules to nd the grs, as donein at-mokhtar and chanod (1997), or annotate new training corpus for the desired set.manually writing rules is expensive, as is annotating large corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4829">
<title id=" P00-1017.xml">using existing systems to supplement small amounts of annotated grammatical relations training data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>also, having less dierentiation of the modiers can make it easier to nd them (ferro et al , 1999).<papid> W99-0706 </papid></prevsent>
<prevsent>furthermore, unless the desired set of grs matches the set al eady annotated in some large training corpus, 1 one will have to either manually write rules to nd the grs, as donein at-mokhtar and chanod (1997), or annotate new training corpus for the desired set.manually writing rules is expensive, as is annotating large corpus.</prevsent>
</prevsection>
<citsent citstr=" W99-0629 ">
often, one may only have the resources to produce small annotated training set, and many of the less common features of the set 1one example is memory-based gr nder (buch holz et al , 1999) <papid> W99-0629 </papid>that uses the grs annotated in the penn treebank (marcus et al , 1993).<papid> J93-2004 </papid></citsent>
<aftsection>
<nextsent>domain may not appear at all in that set.
</nextsent>
<nextsent>in contrast are existing systems that perform well (probably due to large annotated training set or set of carefully hand-crafted rules)on related (but dierent) annotation standards.
</nextsent>
<nextsent>such systems will cover many more domain features, but because the annotation standards are slightly dierent, some of those features will be annotated in dierent way than in the small training and test set.a way to try to combine the dierent advantages of these small training datasets and existing systems which produce related annotations is to use sequence of two systems.
</nextsent>
<nextsent>we rst use an existing annotation system which can handle many of the less common features, i.e., those which do not appear in the small training set.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4830">
<title id=" P00-1017.xml">using existing systems to supplement small amounts of annotated grammatical relations training data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>also, having less dierentiation of the modiers can make it easier to nd them (ferro et al , 1999).<papid> W99-0706 </papid></prevsent>
<prevsent>furthermore, unless the desired set of grs matches the set al eady annotated in some large training corpus, 1 one will have to either manually write rules to nd the grs, as donein at-mokhtar and chanod (1997), or annotate new training corpus for the desired set.manually writing rules is expensive, as is annotating large corpus.</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
often, one may only have the resources to produce small annotated training set, and many of the less common features of the set 1one example is memory-based gr nder (buch holz et al , 1999) <papid> W99-0629 </papid>that uses the grs annotated in the penn treebank (marcus et al , 1993).<papid> J93-2004 </papid></citsent>
<aftsection>
<nextsent>domain may not appear at all in that set.
</nextsent>
<nextsent>in contrast are existing systems that perform well (probably due to large annotated training set or set of carefully hand-crafted rules)on related (but dierent) annotation standards.
</nextsent>
<nextsent>such systems will cover many more domain features, but because the annotation standards are slightly dierent, some of those features will be annotated in dierent way than in the small training and test set.a way to try to combine the dierent advantages of these small training datasets and existing systems which produce related annotations is to use sequence of two systems.
</nextsent>
<nextsent>we rst use an existing annotation system which can handle many of the less common features, i.e., those which do not appear in the small training set.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4831">
<title id=" P00-1017.xml">using existing systems to supplement small amounts of annotated grammatical relations training data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we rst use an existing annotation system which can handle many of the less common features, i.e., those which do not appear in the small training set.
</prevsent>
<prevsent>we then train second system with that same small training set to take the output of the rst system and correct for the dierences in annotations.
</prevsent>
</prevsection>
<citsent citstr=" P97-1041 ">
this approach was used by palmer (1997) <papid> P97-1041 </papid>for word segmentation.hwa (1999) <papid> P99-1010 </papid>describes somewhat similar approach for nding parse brackets which combines fully annotated related training dataset and large but incompletely annotated  nal training data set.</citsent>
<aftsection>
<nextsent>both these works deal with just one (word boundary) or two (start and end parse bracket) annotation label types and the same label types are used in both the existing annotation system/training set andthe nal (small) training set.
</nextsent>
<nextsent>in comparison, our work handles many annotation label types, and the translation from the types used in the existing annotation system to the types in the small training set tends to be both more complicated and most easily determined by empirical means.
</nextsent>
<nextsent>also, the type of baseline score being improved upon is dierent.
</nextsent>
<nextsent>our work adds an existing system to improve the rules learned, while palmer (1997) <papid> P97-1041 </papid>adds rules to improve an existing system performance.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4834">
<title id=" P00-1017.xml">using existing systems to supplement small amounts of annotated grammatical relations training data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we rst use an existing annotation system which can handle many of the less common features, i.e., those which do not appear in the small training set.
</prevsent>
<prevsent>we then train second system with that same small training set to take the output of the rst system and correct for the dierences in annotations.
</prevsent>
</prevsection>
<citsent citstr=" P99-1010 ">
this approach was used by palmer (1997) <papid> P97-1041 </papid>for word segmentation.hwa (1999) <papid> P99-1010 </papid>describes somewhat similar approach for nding parse brackets which combines fully annotated related training dataset and large but incompletely annotated  nal training data set.</citsent>
<aftsection>
<nextsent>both these works deal with just one (word boundary) or two (start and end parse bracket) annotation label types and the same label types are used in both the existing annotation system/training set andthe nal (small) training set.
</nextsent>
<nextsent>in comparison, our work handles many annotation label types, and the translation from the types used in the existing annotation system to the types in the small training set tends to be both more complicated and most easily determined by empirical means.
</nextsent>
<nextsent>also, the type of baseline score being improved upon is dierent.
</nextsent>
<nextsent>our work adds an existing system to improve the rules learned, while palmer (1997) <papid> P97-1041 </papid>adds rules to improve an existing system performance.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4921">
<title id=" P00-1017.xml">using existing systems to supplement small amounts of annotated grammatical relations training data </title>
<section> the experiment.  </section>
<citcontext>
<prevsection>
<prevsent>after the learned rules were applied, those f-scores increased to about 70%.
</prevsent>
<prevsent>an alternative to performing translations is to use the untranslated initial annotations asan additional type of input to the rule system.
</prevsent>
</prevsection>
<citsent citstr=" C94-2195 ">
this alternative, which we have yet to try, has the advantage of tting into the transformation-based error-driven paradigm (brill and resnik, 1994) <papid> C94-2195 </papid>more cleanly than having translation stage.</citsent>
<aftsection>
<nextsent>however, this additional type of input will also further slow down an already slow rule-learning module.
</nextsent>
<nextsent>2.2 overall results.
</nextsent>
<nextsent>for our experiment, we use the same 1151 word (748 gr) test set used in ferro et al  (1999), <papid> W99-0706 </papid>but for training set, we use only subset of the 3299 word training setused in ferro et al  (1999).<papid> W99-0706 </papid></nextsent>
<nextsent>this subset contains 1391 (71%) of the 1963 gr instances in the original training set.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4965">
<title id=" P00-1017.xml">using existing systems to supplement small amounts of annotated grammatical relations training data </title>
<section> the experiment.  </section>
<citcontext>
<prevsection>
<prevsent>annotations so the initial annotations from dierent existing systems tend to each concentrate on improving the performance of dierent gr types.
</prevsent>
<prevsent>from this observation, one may wonder about combining the annotations from thesedierent systems in order to increase the performance on all the gr types aected by those dierent existing systems.
</prevsent>
</prevsection>
<citsent citstr=" W99-0623 ">
various works (van halteren et al , 1998; henderson and brill, 1999; <papid> W99-0623 </papid>wilkes and stevenson, 1998) on combining dierent systems exist.</citsent>
<aftsection>
<nextsent>these works use one or both of two types of schemes.
</nextsent>
<nextsent>one is to have the dierent systems simply vote.
</nextsent>
<nextsent>however, this does not really make use of the fact that different systems are better at handling dier ent gr types.
</nextsent>
<nextsent>the other approach uses combi ner that takes the systems  output asinput and may perform such actions as determining which system to use under which circumstance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4989">
<title id=" P00-1017.xml">using existing systems to supplement small amounts of annotated grammatical relations training data </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>we leverage this tendency to make further modest improvement in the overall results by providing the rule learner with the merged output of these existing systems.
</prevsent>
<prevsent>we have yet to try other ways of combining the output of existing systems that do not require extra training data.
</prevsent>
</prevsection>
<citsent citstr=" P98-1029 ">
one possibility is the example-based combi ner in brill and wu (1998, <papid> P98-1029 </papid>sec.</citsent>
<aftsection>
<nextsent>3.2).
</nextsent>
<nextsent>6 furthermore, nding additional existing systems to add tothe combination may further improve there sults.
</nextsent>


</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4990">
<title id=" P01-1010.xml">what is the minimal set of fragments that achieves maximal parse accuracy </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we isolate some dependency relations which previous models neglect but which contribute to higher parse accuracy.
</prevsent>
<prevsent>one of the goals in statistical natural language parsing is to find the minimal set of statistical dependencies (between words and syntactic structures) that achieves maximal parse accuracy.
</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
many stochastic parsing models use linguistic intuitions to find this minimal set, for example by restricting the statistical dependencies to the locality of headwords of constituents (collins 1997, <papid> P97-1003 </papid>1999; eisner 1997), leaving it as an open question whether there exist important statistical dependencies that go beyond linguistically motivated dependencies.</citsent>
<aftsection>
<nextsent>the data oriented parsing (dop) model, on the other hand, takes rather extreme view on this issue: given an annotated corpus, all fragments (i.e. subtrees) seen in that corpus, regardless of size and lexicalization, are in principle taken to form grammar (see bod 1993, 1998; goodman 1998; sima an 1999).
</nextsent>
<nextsent>the set of subtrees that is used is thus very large and extremely redundant.
</nextsent>
<nextsent>both from theoretical and from computational perspective we may wonder whether it is possible to impose constraints on the subtrees that are used, in such way that the accuracy of the model does not deteriorate or perhaps even improves.
</nextsent>
<nextsent>that is the main question addressed in this paper.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4995">
<title id=" P01-1010.xml">what is the minimal set of fragments that achieves maximal parse accuracy </title>
<section> the dop1 model.  </section>
<citcontext>
<prevsection>
<prevsent>we found that the only constraints that do not decrease the parse accuracy consist in an upper bound of the number of words in the subtree frontiers and an upper bound on the depth of un lexicalized subtrees.
</prevsent>
<prevsent>we also found that counts of subtrees with several non headwords are important, resulting in improved parse accuracy over previous parsers tested on the wsj.
</prevsent>
</prevsection>
<citsent citstr=" P98-1022 ">
to-date, the data oriented parsing model has mainly been applied to corpora of trees whose labels consist of primitive symbols (but see bod&amp; kaplan 1998; <papid> P98-1022 </papid>bod 2000<papid> P00-1009 </papid>c, 2001).</citsent>
<aftsection>
<nextsent>let us illustrate the original dop model presented in bod (1993), called dop1, with simple example.
</nextsent>
<nextsent>assume corpus consisting of only two trees: np vp np mary likes john np vp npv peter hates susan figure 1.
</nextsent>
<nextsent>a corpus of two trees new sentences may be derived by combining fragments, i.e. subtrees, from this corpus, by means of node-substitution operation indicated as ?.
</nextsent>
<nextsent>node-substitution identifies the left most nonterminal frontier node of one subtree with the root node of second subtree (i.e., the second subtree is substituted on the left most nonterminal frontier node of the first subtree).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q4996">
<title id=" P01-1010.xml">what is the minimal set of fragments that achieves maximal parse accuracy </title>
<section> the dop1 model.  </section>
<citcontext>
<prevsection>
<prevsent>we found that the only constraints that do not decrease the parse accuracy consist in an upper bound of the number of words in the subtree frontiers and an upper bound on the depth of un lexicalized subtrees.
</prevsent>
<prevsent>we also found that counts of subtrees with several non headwords are important, resulting in improved parse accuracy over previous parsers tested on the wsj.
</prevsent>
</prevsection>
<citsent citstr=" P00-1009 ">
to-date, the data oriented parsing model has mainly been applied to corpora of trees whose labels consist of primitive symbols (but see bod&amp; kaplan 1998; <papid> P98-1022 </papid>bod 2000<papid> P00-1009 </papid>c, 2001).</citsent>
<aftsection>
<nextsent>let us illustrate the original dop model presented in bod (1993), called dop1, with simple example.
</nextsent>
<nextsent>assume corpus consisting of only two trees: np vp np mary likes john np vp npv peter hates susan figure 1.
</nextsent>
<nextsent>a corpus of two trees new sentences may be derived by combining fragments, i.e. subtrees, from this corpus, by means of node-substitution operation indicated as ?.
</nextsent>
<nextsent>node-substitution identifies the left most nonterminal frontier node of one subtree with the root node of second subtree (i.e., the second subtree is substituted on the left most nonterminal frontier node of the first subtree).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5000">
<title id=" P01-1010.xml">what is the minimal set of fragments that achieves maximal parse accuracy </title>
<section> the dop1 model.  </section>
<citcontext>
<prevsection>
<prevsent>a derivation for mary likes susan other derivations may yield the same tree, e.g.: np vp npv np mary np vp npmary likes susan = susan likes ? ?
</prevsent>
<prevsent>figure 3.
</prevsent>
</prevsection>
<citsent citstr=" W96-0111 ">
another derivation yielding same tree dop1 computes the probability of subtree as the probability of selecting among all corpus subtrees that can be substituted on the same node as t. this probability is equal to the number of occurrences of , | |, divided by the total number of occurrences of all subtrees  with the same root label as t. let r(t) return the root label of t. then we may write: p(t) = | | ? : r(t )= r(t) |  | in most applications of dop1, the subtree probabilities are smoothed by the technique described in bod (1996) <papid> W96-0111 </papid>which is based on good-turing.</citsent>
<aftsection>
<nextsent>(the subtree probabilities are not smoothed by backing off to smaller subtrees, since these are taken into account by the parse tree probability, as we will see.)
</nextsent>
<nextsent>the probability of derivation t1?...tn is computed by the product of the probabilities of its subtrees ti: p(t1?...tn) = p(ti) as we have seen, there may be several distinct derivations that generate the same parse tree.
</nextsent>
<nextsent>the probability of parse tree is thus the sum of the probabilities of its distinct derivations.
</nextsent>
<nextsent>let tid be the i-th subtree in the derivation that produces tree t, then the probability of is given by p(t) = di p(tid) thus the dop1 model considers counts of subtrees of wide range of sizes in computing the probability of tree: everything from counts of single-level rules to counts of entire trees.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5006">
<title id=" P01-1010.xml">what is the minimal set of fragments that achieves maximal parse accuracy </title>
<section> computational issues.  </section>
<citcontext>
<prevsection>
<prevsent>each corpus subtree is converted into context-free rule where the left hand side of corresponds to the root label of and the right hand side of corresponds to the frontier labels of t. indices link the rules to the original subtrees so as to maintain the subtree internal structure and probability.
</prevsent>
<prevsent>these rules are used to create derivation forest for sentence (using cky parser), and the most probable parse is computed by sampling sufficiently large number of random derivations from the forest ( monte carlo disambiguation , see bod 1998).
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
while this technique has been successfully applied to parsing the atis portion in the penn treebank (marcus et al 1993), <papid> J93-2004 </papid>it is extremely time consuming.</citsent>
<aftsection>
<nextsent>this is mainly because the number of random derivations that should be sampled to reliably estimate the most probable parse increases exponentially with the sentence length (see goodman 1998).
</nextsent>
<nextsent>it is therefore questionable whether bod sampling technique can be scaled to larger domains such as the wsj portion in the penn treebank.
</nextsent>
<nextsent>goodman (1996), <papid> W96-0214 </papid>goodman (1998) showed how dop1can be reduced to compact stochastic context free grammar (scfg) which contains exactly eight scfg rules for each node in the training set trees.</nextsent>
<nextsent>although goodman method does still not allow for an efficient computation of the most probable parse (in fact, the problem of computing the most probable parse in dop1 is np-hard - see sima an 1999), his method does allow for an efficient computation of the  maximum constituents parse , i.e. the parse tree that is most likely to have the largest number of correct constituents.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5007">
<title id=" P01-1010.xml">what is the minimal set of fragments that achieves maximal parse accuracy </title>
<section> computational issues.  </section>
<citcontext>
<prevsection>
<prevsent>this is mainly because the number of random derivations that should be sampled to reliably estimate the most probable parse increases exponentially with the sentence length (see goodman 1998).
</prevsent>
<prevsent>it is therefore questionable whether bod sampling technique can be scaled to larger domains such as the wsj portion in the penn treebank.
</prevsent>
</prevsection>
<citsent citstr=" W96-0214 ">
goodman (1996), <papid> W96-0214 </papid>goodman (1998) showed how dop1can be reduced to compact stochastic context free grammar (scfg) which contains exactly eight scfg rules for each node in the training set trees.</citsent>
<aftsection>
<nextsent>although goodman method does still not allow for an efficient computation of the most probable parse (in fact, the problem of computing the most probable parse in dop1 is np-hard - see sima an 1999), his method does allow for an efficient computation of the  maximum constituents parse , i.e. the parse tree that is most likely to have the largest number of correct constituents.
</nextsent>
<nextsent>goodman has shown on the atis corpus that the maximum constituents parse performs at least as well as the most probable parse if all subtrees are used.
</nextsent>
<nextsent>unfortunately, goodman reduction method is only beneficial if indeed all subtrees are used.
</nextsent>
<nextsent>sima an (1999: 108) argues that there may still be an isomorphic scfg for dop1 if the corpus-subtrees are restricted in size or lexicalization, but that the number of the rules explodes in that case.in this paper we will use bod subtree-to rule conversion method for studying the impact of various subtree restrictions on the wsj corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5010">
<title id=" P01-1010.xml">what is the minimal set of fragments that achieves maximal parse accuracy </title>
<section> computational issues.  </section>
<citcontext>
<prevsection>
<prevsent>although this heuristic does not guarantee that the most probable parse is actually found, it is shown in bod (2000<papid> P00-1009 </papid>a) to perform at least as well as the estimation of the most probable parse with monte carlo techniques.</prevsent>
<prevsent>however, in computing the 1,000 most probable derivations by means of viterbi it is prohibitive to keep track of all sub derivations at each edge in the chart (at least for such large corpus as the wsj).</prevsent>
</prevsection>
<citsent citstr=" W97-0302 ">
as in most other statistical parsing systems we therefore use the pruning technique described in goodman (1997) <papid> W97-0302 </papid>and collins (1999: 263-264) which assigns score to each item in the chart equal to the product of the inside probability of the item and its prior probability.</citsent>
<aftsection>
<nextsent>any item with scoreless than 105 times of that of the best item is pruned from the chart.
</nextsent>
<nextsent>achieves maximal parse accuracy?
</nextsent>
<nextsent>4.1 the base line.
</nextsent>
<nextsent>for our base line parse accuracy, we used the now standard division of the wsj (see collins 1997, <papid> P97-1003 </papid>1999; charniak 1997, 2000; ratnaparkhi 1999) with sections 2 through 21 for training (approx.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5018">
<title id=" P01-1010.xml">what is the minimal set of fragments that achieves maximal parse accuracy </title>
<section> what is the minimal subtree set that.  </section>
<citcontext>
<prevsection>
<prevsent>this resulted in base line subtree set of 5,217,529 subtrees which were smoothed by the technique described in bod (1996) <papid> W96-0111 </papid>based on good-turing.</prevsent>
<prevsent>since our subtrees are allowed to be lexicalized (at theirfrontiers), we did not use separate part-of speech tagger: the test sentences were directly parsed by the training set subtrees.</prevsent>
</prevsection>
<citsent citstr=" J93-2006 ">
for words that were unknown in our subtree set, we guessed their categories by means of the method described in weischedel et al (1993) <papid> J93-2006 </papid>which uses statistics on word-endings, hyphenation and capitalization.</citsent>
<aftsection>
<nextsent>the guessed category for each unknown word was converted into depth-1 subtree and assigned probability by means of simple good-turing estimation (see bod 1998).
</nextsent>
<nextsent>the most probable parse for each test sentence was estimated from the 1,000 most probable derivations of that sentence, as described in section 3.
</nextsent>
<nextsent>we used  evalb 1 to compute the standard parseval scores for our parse results.
</nextsent>
<nextsent>we focus on the labeled precision (lp) and labeled recall (lr) scores only in this paper, as these are commonly used to rank parsing systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5019">
<title id=" P01-1010.xml">what is the minimal set of fragments that achieves maximal parse accuracy </title>
<section> what is the minimal subtree set that.  </section>
<citcontext>
<prevsection>
<prevsent>we used  evalb 1 to compute the standard parseval scores for our parse results.
</prevsent>
<prevsent>we focus on the labeled precision (lp) and labeled recall (lr) scores only in this paper, as these are commonly used to rank parsing systems.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
table 1 shows the lp and lr scores obtained with our base line subtree set, and compares these scores with those of previous stochastic parsers tested on the wsj (respectively charniak 1997, collins 1999, ratnaparkhi 1999, and charniak 2000).<papid> A00-2018 </papid></citsent>
<aftsection>
<nextsent>the table shows that by using the base line subtree set, our parser outperforms most previous parsers but it performs worse than the parser in charniak (2000).<papid> A00-2018 </papid></nextsent>
<nextsent>we will use our scores of 89.5% lp and 89.3% lr (for test sentences ? 40 words) as the base line result against which the effect of various subtree restrictions is investigated.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5031">
<title id=" P01-1010.xml">what is the minimal set of fragments that achieves maximal parse accuracy </title>
<section> what is the minimal subtree set that.  </section>
<citcontext>
<prevsection>
<prevsent>the highest scores obtained are: 90.8% labeled precision and 90.6% labeled recall.
</prevsent>
<prevsent>we thus conclude that pure structural context without any lexical information contributes to higher parse accuracy (even if there exists an upper bound for the size of structural context).
</prevsent>
</prevsection>
<citsent citstr=" J98-4004 ">
the importance of structural context is consonant with johnson (1998) <papid> J98-4004 </papid>who showed that structural context from higher nodes in the tree (i.e. grandparent nodes) contributes to higher parse accuracy.</citsent>
<aftsection>
<nextsent>this mirrors our result of the importance of un lexicalized subtrees of depth 2.
</nextsent>
<nextsent>but our results show that larger structural context (up to depth 6) also contributes to the accuracy.
</nextsent>
<nextsent>4.5 the impact of non headword dependencies.
</nextsent>
<nextsent>we may also raise the question as to whether we need almost arbitrarily large lexicalized subtrees (up to 12 words) to obtain our best results.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5037">
<title id=" P01-1010.xml">what is the minimal set of fragments that achieves maximal parse accuracy </title>
<section> what is the minimal subtree set that.  </section>
<citcontext>
<prevsection>
<prevsent>it could be the case that dop gain in parse accuracy with increasing subtree depth is due to the model becoming sensitive to the influence of lexical heads higher in the tree, and that this gain could also be achieved by more compact model which associates each nonterminal with its headword, such as head-lexicalized scfg.
</prevsent>
<prevsent>head-lexicalized stochastic grammars have recently become increasingly popular (see collins 1997, <papid> P97-1003 </papid>1999; charniak 1997, 2000).</prevsent>
</prevsection>
<citsent citstr=" P95-1037 ">
these grammars are based on magerman head percolation scheme to determine the headword ofeach nonterminal (magerman 1995).<papid> P95-1037 </papid></citsent>
<aftsection>
<nextsent>unfortunately this means that head-lexicalized stochastic grammars are not able to capture dependency relations between words that according to magerman head-percolation scheme are  non headwords  -- e.g. between more and than in the wsj construction carry more people than cargo where neither more nor than are headwords of the np constituent more people than cargo . frontier-lexicalized dop model, on the other hand, captures these dependencies since it includes subtrees in which more and than are the only frontier words.
</nextsent>
<nextsent>one may object that this example is somewhat far-fetched, but chiang (2000) <papid> P00-1058 </papid>notes that head-lexicalized stochastic grammars fall short in encoding even simple dependency relations such as between left and john in the sentence john should have left . this is because magerman head-percolation scheme makes should and have the heads of their respective vps so that there is no dependency relation between the verb left and its subject john.</nextsent>
<nextsent>chiang observes that almost quarter of all non empty subjects in the wsj appear in such configuration.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5038">
<title id=" P01-1010.xml">what is the minimal set of fragments that achieves maximal parse accuracy </title>
<section> what is the minimal subtree set that.  </section>
<citcontext>
<prevsection>
<prevsent>these grammars are based on magerman head percolation scheme to determine the headword ofeach nonterminal (magerman 1995).<papid> P95-1037 </papid></prevsent>
<prevsent>unfortunately this means that head-lexicalized stochastic grammars are not able to capture dependency relations between words that according to magerman head-percolation scheme are  non headwords  -- e.g. between more and than in the wsj construction carry more people than cargo where neither more nor than are headwords of the np constituent more people than cargo . frontier-lexicalized dop model, on the other hand, captures these dependencies since it includes subtrees in which more and than are the only frontier words.</prevsent>
</prevsection>
<citsent citstr=" P00-1058 ">
one may object that this example is somewhat far-fetched, but chiang (2000) <papid> P00-1058 </papid>notes that head-lexicalized stochastic grammars fall short in encoding even simple dependency relations such as between left and john in the sentence john should have left . this is because magerman head-percolation scheme makes should and have the heads of their respective vps so that there is no dependency relation between the verb left and its subject john.</citsent>
<aftsection>
<nextsent>chiang observes that almost quarter of all non empty subjects in the wsj appear in such configuration.
</nextsent>
<nextsent>in order to isolate the contribution of non headword dependencies to the parse accuracy, we eliminated all subtrees containing certain maximum number of non headwords, where non headword of subtree is word which according to magerman scheme is not headword of the subtree root nonterminal (although such non headword may of course be headword of one of the subtree internal nodes).
</nextsent>
<nextsent>in the following experiments we used the subtree set for which maximum accuracy was obtained in our previous experiments, i.e. containing all lexicalized subtrees with maximally 12 frontier words and all un lexicalized subtrees up to depth 6.
</nextsent>
<nextsent># non headwords in subtrees lp lr 0 89.6 89.6 1 90.2 90.1 2 90.4 90.2 3 90.3 90.2 4 90.6 90.4 5 90.6 90.6 6 90.6 90.5 7 90.7 90.7 8 90.8 90.6 unrestricted 90.8 90.6 table 5.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5046">
<title id=" P01-1010.xml">what is the minimal set of fragments that achieves maximal parse accuracy </title>
<section> discussion: converging approaches.  </section>
<citcontext>
<prevsection>
<prevsent>in previous experiments with dop1 on smaller and more restricted domains we found that the parse accuracy decreases also after certain maximum subtree depth (see bod 1998; sima an 1999).
</prevsent>
<prevsent>we expect that also for the wsj the parse accuracy will decrease after certain depth, although we have not been able to find this depth so far.
</prevsent>
</prevsection>
<citsent citstr=" P96-1025 ">
a major difference between our approach and most other models tested on the wsj is that the dop model uses frontier lexicalization while most other models use constituent lexicalization(in that they associate each constituent nonterminal with its lexical head -- see collins 1996, <papid> P96-1025 </papid>1999; charniak 1997; eisner 1997).</citsent>
<aftsection>
<nextsent>the results in this paper indicate that frontier lexicalization isa promising alternative to constituent lexicalization.
</nextsent>
<nextsent>our results also show that the linguistically motivated constraint which limits the statistical dependencies to the locality of headwords of constituents is too narrow.
</nextsent>
<nextsent>not only are counts of subtrees with non headwords important, also counts of un lexicalized subtrees up to depth 6 increase the parse accuracy.
</nextsent>
<nextsent>the only other model that uses frontier lexicalization and that was tested on the standard wsj split is chiang (2000) <papid> P00-1058 </papid>who extracts stochastic tree-insertion grammar or stig (schabes &amp; waters 1996) from the wsj, obtaining 86.6% lp and 86.9% lr for sentences ? 40 words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5052">
<title id=" P01-1010.xml">what is the minimal set of fragments that achieves maximal parse accuracy </title>
<section> discussion: converging approaches.  </section>
<citcontext>
<prevsection>
<prevsent>the history of stochastic parsing models shows consistent increase in the scope of statistical dependencies that are captured by these models.
</prevsent>
<prevsent>figure 4 gives (very) schematic overview of this increase (see carroll &amp; weir 2000, for more detailed account of subsumption lattice where scfg is at the bottom and dop at the top).
</prevsent>
</prevsection>
<citsent citstr=" C96-1058 ">
context-free rules charniak (1996) collins (1996), <papid> P96-1025 </papid>eisner (1996) <papid> C96-1058 </papid>context-free rules, headwords charniak (1997) context-free rules, headwords, grandparent nodes collins (2000) context-free rules, headwords, grandparent nodes/rules, bigrams, two-level rules, two-level bigrams, non headwords bod (1992) all fragments within parse trees scope of statistical dependencies model figure 4.</citsent>
<aftsection>
<nextsent>schematic overview of the increase of statistical dependencies by stochastic parsers thus there seems to be convergence towards maximalist model which  takes all fragments [...]
</nextsent>
<nextsent>and lets the statistics decide  (bod 1998: 5).
</nextsent>
<nextsent>while early head-lexicalized grammars restricted the fragments to the locality of headwords (e.g. collins 1996; <papid> P96-1025 </papid>eisner 1996), <papid> C96-1058 </papid>later models showed the importance of including context from higher nodes in the tree (charniak 1997; johnson 1998).<papid> J98-4004 </papid></nextsent>
<nextsent>this mirrors our result of the utility of (unlexicalized) fragments of depth 2 and larger.the importance of including single nonhead words is now also uncontroversial (e.g. collins 1997, <papid> P97-1003 </papid>1999; charniak 2000), <papid> A00-2018 </papid>and the current paper has shown the importance of including two and more nonheadwords.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5062">
<title id=" P04-1005.xml">a tag based noisy channel model of speech repairs </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>probabilistic models have the advantage over other kinds of models that they can in principle be integrated with other probabilistic models to produce combined model that uses all available evidence to select the globally optimal analysis.
</prevsent>
<prevsent>shriberg and stolcke (1998) studied the location and distribution of repairs in the switchboard corpus, but did not propose an actual model of repairs.
</prevsent>
</prevsection>
<citsent citstr=" J99-4003 ">
heeman and allen (1999) <papid> J99-4003 </papid>describe noisy channel model of speech repairs, but leave extending the model to incorporate higher level syntactic . . .</citsent>
<aftsection>
<nextsent>processing?
</nextsent>
<nextsent>to future work.
</nextsent>
<nextsent>the previous work most closely related to the current work is charniak and johnson(2001), <papid> N01-1016 </papid>who used boosted decision stub classifier to classify words as edited or not on word by word basis, but do not identify or assign probability to repair as whole.</nextsent>
<nextsent>there are two innovations in this paper.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5063">
<title id=" P04-1005.xml">a tag based noisy channel model of speech repairs </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>processing?
</prevsent>
<prevsent>to future work.
</prevsent>
</prevsection>
<citsent citstr=" N01-1016 ">
the previous work most closely related to the current work is charniak and johnson(2001), <papid> N01-1016 </papid>who used boosted decision stub classifier to classify words as edited or not on word by word basis, but do not identify or assign probability to repair as whole.</citsent>
<aftsection>
<nextsent>there are two innovations in this paper.
</nextsent>
<nextsent>first, we demonstrate that using syntactic parser-based language model charniak (2001)<papid> P01-1017 </papid>instead of bi/trigram language models significantly improves the accuracy of repair detection and correction.</nextsent>
<nextsent>second, we show how tree adjoining grammars (tags) can be used to provide precise formal description and probabilistic model of the crossed dependencies occurring in speech repairs.the rest of this paper is structured as follows.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5064">
<title id=" P04-1005.xml">a tag based noisy channel model of speech repairs </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the previous work most closely related to the current work is charniak and johnson(2001), <papid> N01-1016 </papid>who used boosted decision stub classifier to classify words as edited or not on word by word basis, but do not identify or assign probability to repair as whole.</prevsent>
<prevsent>there are two innovations in this paper.</prevsent>
</prevsection>
<citsent citstr=" P01-1017 ">
first, we demonstrate that using syntactic parser-based language model charniak (2001)<papid> P01-1017 </papid>instead of bi/trigram language models significantly improves the accuracy of repair detection and correction.</citsent>
<aftsection>
<nextsent>second, we show how tree adjoining grammars (tags) can be used to provide precise formal description and probabilistic model of the crossed dependencies occurring in speech repairs.the rest of this paper is structured as follows.
</nextsent>
<nextsent>the next section describes the noisy channel model of speech repairs and the section after that explains how it can be applied to detect and repair speech repairs.
</nextsent>
<nextsent>section 4 evaluates this model on the penn 3 disfluency-tagged switchboard corpus, and section 5 concludes and discusses future work.
</nextsent>
<nextsent>we follow shriberg (1994) and most other work on speech repairs by dividing repair into three parts: the reparandum (the material repaired), the interregnum that is typically either empty or consists of filler, and the repair.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5066">
<title id=" P04-1005.xml">a tag based noisy channel model of speech repairs </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>on the other hand, it seems desirable to use language model that is sensitive to more global properties of the sentence, and we do this by reranking the initial analysis, replacing the bigram language model with syntactic parser based model.
</prevsent>
<prevsent>we do not need to intersect this parser based language model with our tag channel model since we evaluate each analysis separately.
</prevsent>
</prevsection>
<citsent citstr=" C90-3045 ">
the tag channel model defines stochastic mapping of source sentences into observed sentences . there are several ways to define transducers using tags such as shieber and schabes (1990), <papid> C90-3045 </papid>but the following simple method, inspired by finite-state transducers,suffices for the application here.</citsent>
<aftsection>
<nextsent>the tag defines language whose vocabulary is the set ofpairs (??{?})?(??{?}), where ? is the vocabulary of the observed sentences . string in this language can be interpreted as pairof strings (y,x), where is the concatenation of the projection of the first components of and is the concatenation of the projection of the second components.
</nextsent>
<nextsent>for example, the string = a:a flight:flight to:?
</nextsent>
<nextsent>boston:uh:?
</nextsent>
<nextsent>i:?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5074">
<title id=" P03-2019.xml">integrating information extraction and automatic hyper linking </title>
<section> the sprout system.  </section>
<citcontext>
<prevsection>
<prevsent>the morphology unit provides lexical resources for english, german (equipped with online shallow compound recognition), french, italian, and spanish, which were compiled from the full form lexica of mmorph (petitpierre and russell, 1995).
</prevsent>
<prevsent>considering slavic languages, component for czech presented in (haji?, 2001), and morfeusz (przepirkowski and wolinski, 2003) for polish.
</prevsent>
</prevsection>
<citsent citstr=" C00-1004 ">
for asian languages, we integrated chasen (asahara and matsumoto, 2000) <papid> C00-1004 </papid>for japanese and shanxi (liu, 2000) for chinese.</citsent>
<aftsection>
<nextsent>the xtdl-based grammar engineering platform has been used to define grammars for english, german, french, spanish, chinese and japanese allowing for named entity recognition and extraction.
</nextsent>
<nextsent>to guarantee comparable coverage, and to ease evaluation, an extension of the muc-7 standard for entities has been adopted.
</nextsent>
<nextsent>ne-person := enamex &amp; [ title list-of-strings, given_name list-of-strings, surname list-of-strings, p-position list-of-strings, name-suffix string, descriptor string ].
</nextsent>
<nextsent>given the expressiveness of xtdl expressions, muc-7/met-2 named entity types can be enhanced with more complex internal structures.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5075">
<title id=" P02-1043.xml">generative models for statistical parsing with combinatory categorial grammar </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>these models are trained and tested on corpus obtained by translating the penn treebank trees into ccg normal-form derivations.
</prevsent>
<prevsent>according to an evaluation of unlabeled word-word dependencies, our best model achieves performance of 89.9%, comparable to the figures given by collins (1999) for linguistically less expressive grammar.
</prevsent>
</prevsection>
<citsent citstr=" W01-0521 ">
in contrast to gildea (2001), <papid> W01-0521 </papid>we find significant improvement from modeling word word dependencies.</citsent>
<aftsection>
<nextsent>the currently best single-model statistical parser (charniak, 1999) achieves parseval scores of over 89% on the penn treebank.
</nextsent>
<nextsent>however, the grammar underlying the penn treebank is very permissive, and parser can do well on the standard parseval measures without committing itself on certain semantically significant decisions, such as predicting null elements arising from deletion or movement.
</nextsent>
<nextsent>the potential benefit of wide-coverage parsing with ccg lies in its more constrained grammar and its simple and semantically transparent capture of extraction and coordination.we present number of models over syntactic derivations of combinatory categorial grammar (ccg, see steedman (2000) and clark et al  (2002), <papid> P02-1042 </papid>this conference, for introduction), estimated from and tested on translation of the penn treebank to corpus of ccg normal-form derivations.</nextsent>
<nextsent>ccg grammars are characterized by much larger category sets than standard penn treebank grammars, distinguishing for example between many classes of verbs with different subcategorization frames.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5076">
<title id=" P02-1043.xml">generative models for statistical parsing with combinatory categorial grammar </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the currently best single-model statistical parser (charniak, 1999) achieves parseval scores of over 89% on the penn treebank.
</prevsent>
<prevsent>however, the grammar underlying the penn treebank is very permissive, and parser can do well on the standard parseval measures without committing itself on certain semantically significant decisions, such as predicting null elements arising from deletion or movement.
</prevsent>
</prevsection>
<citsent citstr=" P02-1042 ">
the potential benefit of wide-coverage parsing with ccg lies in its more constrained grammar and its simple and semantically transparent capture of extraction and coordination.we present number of models over syntactic derivations of combinatory categorial grammar (ccg, see steedman (2000) and clark et al  (2002), <papid> P02-1042 </papid>this conference, for introduction), estimated from and tested on translation of the penn treebank to corpus of ccg normal-form derivations.</citsent>
<aftsection>
<nextsent>ccg grammars are characterized by much larger category sets than standard penn treebank grammars, distinguishing for example between many classes of verbs with different subcategorization frames.
</nextsent>
<nextsent>as result, the categorial lexicon extracted for this purpose from the training corpus has 1207 categories, compared with the 48 pos-tags of the penn treebank.on the other hand, grammar rules in ccg are limited to small number of simple unary and binary combinatory schemata such as function application and composition.
</nextsent>
<nextsent>this results in smaller and less over generating grammar than standard pcfgs (ca.3,000 rules when instantiated with the above categories in sections 02-21, instead of  12,400 in the original treebank representation (collins, 1999)).
</nextsent>
<nextsent>since ccg produces unary and binary branching trees with very fine-grained category set, ccg parseval scores cannot be compared with scores of standard treebank parsers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5082">
<title id=" P02-1043.xml">generative models for statistical parsing with combinatory categorial grammar </title>
<section> extending the baseline model.  </section>
<citcontext>
<prevsection>
<prevsent>state-of-the-art statistical parsers use many other features, or conditioning variables, such as headwords, subcategorization frames, distance measures and grandparent nodes.
</prevsent>
<prevsent>we too can extend the baseline model described in the previous section by including more features.
</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
like the models of goodman (1997), the additional features in our model are generated probabilistically, whereas in the parser of collins (1997) <papid> P97-1003 </papid>distance measures are assumed to be function of the already generated structure and are not generated explicitly.</citsent>
<aftsection>
<nextsent>in order to estimate the conditional probabilities of our model, we recursively smooth empirical estimates ei of specific conditional distributions with(possible smoothed) estimates of less specific distributions ei 1, using linear interpolation: ei = ei +(1 ?)ei 1?
</nextsent>
<nextsent>is smoothing weight which depends on the particular distribution.2when defining models, we will indicate backoff level with # sign between conditioning variables, eg.
</nextsent>
<nextsent>a;b # # means that we interpolatep(::: a;b;c;d) with p(::: a;b;c), which is an interpolation of p(::: a;b;c) and p(::: a;b).
</nextsent>
<nextsent>1we conjecture that the minor variations in coverage among the other models (except grandparent) are artefacts of the beam.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5083">
<title id=" P02-1043.xml">generative models for statistical parsing with combinatory categorial grammar </title>
<section> extending the baseline model.  </section>
<citcontext>
<prevsection>
<prevsent>table 1 shows how conj is used as conditioning variable.
</prevsent>
<prevsent>this is intended to allow the model to capture the fact that, for sentence without extraction, ccg derivation where the subject is type-raised and composed with the verb is much more likely in right node raising constructions like the above.
</prevsent>
</prevsection>
<citsent citstr=" J98-4004 ">
the impact of the grandparent feature johnson (1998) <papid> J98-4004 </papid>showed that pcfg estimated from version of the penn treebank in which the label of nodes parent is attached to the nodes own label yields substantial improvement (lp/lr: from 73.5%/69.7% to 80.0%/79.2%).</citsent>
<aftsection>
<nextsent>the inclusion of an additional grandparent feature gives charniak (1999) slight improvement in the maximum entropy inspired model, but slight decrease in performance for an mle model.
</nextsent>
<nextsent>table3 (grandparent) shows that grammar transformation like johnsons does yield an improvement, but not as dramatic as in the treebank-cfg case.
</nextsent>
<nextsent>at the same time coverage is reduced (which might not be the case if this was an additional feature in the model rather than change in the representation of the categories).
</nextsent>
<nextsent>both of these results are to be expectedccg categories encode more contextual information than treebank labels, in particular about parents and grandparents; therefore the history feature might be expected to have less impact.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5087">
<title id=" P02-1043.xml">generative models for statistical parsing with combinatory categorial grammar </title>
<section> extending the baseline model.  </section>
<citcontext>
<prevsection>
<prevsent>all of the experiments described above use the pos tags as given by ccgbank (which are the treebank tags, with some corrections necessary to acquire correct features on categories).
</prevsent>
<prevsent>it is reasonable to assume that this input is of higher quality than can be produced by pos-tagger.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
we therefore ran the dependency model on test corpus tagged with the pos-tagger of ratnaparkhi (1996), <papid> W96-0213 </papid>which is trained on the original penn treebank (see hwdep (+ tag ger) in table 3).</citsent>
<aftsection>
<nextsent>performance degrades slightly, which is to be expected, since our approach makesso much use of the pos-tag information for unknown words.
</nextsent>
<nextsent>however, pos-tagger trained on ccgbank might yield slightly better results.
</nextsent>
<nextsent>5.5 limitations of the current model.
</nextsent>
<nextsent>unlike clark et al  (2002), <papid> P02-1042 </papid>our parser does not always model the dependencies in the logical form.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5091">
<title id=" P02-1043.xml">generative models for statistical parsing with combinatory categorial grammar </title>
<section> extending the baseline model.  </section>
<citcontext>
<prevsection>
<prevsent>for example, in the interpretation of coordinate structure like buy and sell shares?, shares will head an object of both buy and sell.
</prevsent>
<prevsent>similarly, in examples like buy the company that wins?, the relative construction makes company depend upon both buy as object and wins as subject.
</prevsent>
</prevsection>
<citsent citstr=" J97-4005 ">
as is well known (abney, 1997), <papid> J97-4005 </papid>dag-like dependencies cannot in general be modeled with generative approach of the kind taken here3.</citsent>
<aftsection>
<nextsent>5.6 comparison with clark et al  (2002).<papid> P02-1042 </papid></nextsent>
<nextsent>clark et al  (2002) <papid> P02-1042 </papid>presents another statistical ccg parser, which is based on conditional (ratherthan generative) model of the derived dependency structure, including non-surface dependen cies.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5100">
<title id=" P00-1045.xml">memory efficient and thread safe quasi destructive graph unification </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>redundant.
</prevsent>
<prevsent>as copying is the most expensive part of unification, great deal of research has gone in eliminating superfluous copying.
</prevsent>
</prevsection>
<citsent citstr=" P91-1041 ">
examples of these approaches are given in (tomabechi, 1991) <papid> P91-1041 </papid>and (wroblewski, 1987).</citsent>
<aftsection>
<nextsent>in order to avoid superfluous copying, these algorithms incorporate control data in the graphs.
</nextsent>
<nextsent>this has several drawbacks, as we will discuss next.
</nextsent>
<nextsent>memory consumption to achieve the goal of eliminating superfluous copying, the aforementioned algorithms include administrative fields which we will call scratch field sin the node structure.
</nextsent>
<nextsent>these fields do not attribute to the definition of the graph,but are used to efficiently guide the unification and copying process.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5103">
<title id=" P00-1045.xml">memory efficient and thread safe quasi destructive graph unification </title>
<section> enhancements.  </section>
<citcontext>
<prevsection>
<prevsent>some of these abilities will be used in the enhancements of the algorithm we will discuss next.
</prevsent>
<prevsent>structure sharing structure sharing is an important technique to reduce memory us age.
</prevsent>
</prevsection>
<citsent citstr=" C92-2068 ">
we will adopt the same terminology as tomabechi in (tomabechi, 1992).<papid> C92-2068 </papid></citsent>
<aftsection>
<nextsent>that is, we will use the term feature-structure sharing when two arcs in one graph converge to the same node in that graph (also refered to as reentrancy) and data-structure sharing when arcs from two different graphs converge to the same node.
</nextsent>
<nextsent>the conditions for sharing mentioned in (tomabechi, 1992) <papid> C92-2068 </papid>are: (1) bottom and atomic nodes can be shared; (2) complex nodes can be shared unless they are modified.</nextsent>
<nextsent>we need to add the following condition: (3) all arcs in the shared subgraph must have the same offsets as the subgraph that would have resulted from copying.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5109">
<title id=" P00-1045.xml">memory efficient and thread safe quasi destructive graph unification </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>running the same tests on machines with less memory showed clear performance advantage for the algorithms using less memory, because paging could be avoided.
</prevsent>
<prevsent>we reduce memory consumption of graph unification as presented in (tomabechi, 1991) <papid> P91-1041 </papid>(or (wroblewski, 1987)) by separating scratch fields from node structures.</prevsent>
</prevsection>
<citsent citstr=" P85-1017 ">
pere iras (pereira, 1985) <papid> P85-1017 </papid>algorithm also stores changes to nodes separate from the graph.</citsent>
<aftsection>
<nextsent>however, pere iras mechanism incurs log(n) overhead for accessing the changes (where is the number of nodes in graph), resulting in an o(n logn) time algorithm.
</nextsent>
<nextsent>our algorithm runs in o(n) time.
</nextsent>
<nextsent>6the results do not include the space consumed by the scratch tables.
</nextsent>
<nextsent>however, these tables do not consume more than 10 kb in total, and hence have no significant impact on the results.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5112">
<title id=" P02-1010.xml">ellipsis resolution with underspecified scope </title>
<section> abstract </section>
<citcontext>
<prevsection>

<prevsent>the paper presents an approach to ellipsis resolution in framework of scope under specification (underspecified discourse representation theory).
</prevsent>
</prevsection>
<citsent citstr=" E95-1032 ">
it is argued thatthe approach improves on previous proposals to integrate ellipsis resolution and scope under specification (crouch, 1995;<papid> E95-1032 </papid>egg et al, 2001) in that application processes like anaphora resolution do notre quire full disambiguation but can work directly on the underspecified representation.</citsent>
<aftsection>
<nextsent>furthermore it is shown that the approach presented can cope with the examples discussed by dalrymple et al (1991) as well as problem noted recently by erk and koller (2001).
</nextsent>
<nextsent>explicit computation of all scope configurations is apt to slow down an nlp system considerably.
</nextsent>
<nextsent>therefore, under specification of scope ambiguities is an important prerequisite for efficient processing.many tasks, like ellipsis resolution or anaphora resolution, are arguably best performed on representation with fixed scope order.
</nextsent>
<nextsent>an under specification formalism should support execution of these tasks.this paper aims to upgrade an existing under specification formalism for scope ambiguities, underspecified discourse representation theory (udrt)(reyle, 1993), so that both ellipsis and anaphora resolution can work on the underspecified structures.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5121">
<title id=" P02-1010.xml">ellipsis resolution with underspecified scope </title>
<section> scope parallelism.  </section>
<citcontext>
<prevsection>
<prevsent>we talk about sequence here, because, as sentence (7) shows, ellipses may be nested.
</prevsent>
<prevsent>(7) john arrived before the teacher did (1 arrive), and bill did too (2 arrive before the teacher did (1 arrive)).
</prevsent>
</prevsection>
<citsent citstr=" E95-1025 ">
for the implementation of classes, we take our cues from prolog (erbach, 1995; <papid> E95-1025 </papid>mellish, 1988).<papid> J88-1004 </papid></citsent>
<aftsection>
<nextsent>in pro log, class membership is most efficiently tested viaunification.
</nextsent>
<nextsent>for unification to work, the class members must be represented as instances of the representation of the class.
</nextsent>
<nextsent>if class members are mutually exclusive, their representations must have different constants at some argument position.
</nextsent>
<nextsent>in this vein,we can think of label as prolog term whose functor denotes the equivalence class and whose argument describes the sequence of ellipsis resolutions that generated the label.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5122">
<title id=" P02-1010.xml">ellipsis resolution with underspecified scope </title>
<section> scope parallelism.  </section>
<citcontext>
<prevsection>
<prevsent>we talk about sequence here, because, as sentence (7) shows, ellipses may be nested.
</prevsent>
<prevsent>(7) john arrived before the teacher did (1 arrive), and bill did too (2 arrive before the teacher did (1 arrive)).
</prevsent>
</prevsection>
<citsent citstr=" J88-1004 ">
for the implementation of classes, we take our cues from prolog (erbach, 1995; <papid> E95-1025 </papid>mellish, 1988).<papid> J88-1004 </papid></citsent>
<aftsection>
<nextsent>in pro log, class membership is most efficiently tested viaunification.
</nextsent>
<nextsent>for unification to work, the class members must be represented as instances of the representation of the class.
</nextsent>
<nextsent>if class members are mutually exclusive, their representations must have different constants at some argument position.
</nextsent>
<nextsent>in this vein,we can think of label as prolog term whose functor denotes the equivalence class and whose argument describes the sequence of ellipsis resolutions that generated the label.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5127">
<title id=" P03-2012.xml">high precision identification of discourse new and unique noun phrases </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as the final step, the pairs are ranked using scoring algorithm in order to find an appropriate partition of all the markables into coreference classes.
</prevsent>
<prevsent>those approaches require substantial processing:in the worst case one has to check )+*,)+-.0/1 candidate pairs, where  is the total number of mark ables found by the system.
</prevsent>
</prevsection>
<citsent citstr=" J00-4003 ">
however, r. vieira and m. poesio have recently shown in (vieira and poesio, 2000) <papid> J00-4003 </papid>that such an exhaustive search is not needed, because many noun phrases are not anaphoric at all ? about 24365 of definite nps in their corpus have no prior referents.</citsent>
<aftsection>
<nextsent>obviously, this number is even higher if one takes into account all the other types of nps ? for example, indefinites are almost always non-anaphoric.we can conclude that coreference resolution engine might benefit lot from pre-filtering algorithm for identifying non-anaphoric entities.
</nextsent>
<nextsent>first, we save much processing time by discarding at least half of the markables.
</nextsent>
<nextsent>second, we can hope to reduce the number of mistakes: without pre-filtering, our coreference resolution system might misclassifya discourse new entity as co referent to some previous one.
</nextsent>
<nextsent>however, such pre-filtering can also decrease the systems performance if too many anaphoric nps are classified as discourse new: as those nps are not processed by the main coreference resolution module at all, we cannot find correct antecedents for them.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5128">
<title id=" P03-2012.xml">high precision identification of discourse new and unique noun phrases </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, such pre-filtering can also decrease the systems performance if too many anaphoric nps are classified as discourse new: as those nps are not processed by the main coreference resolution module at all, we cannot find correct antecedents for them.
</prevsent>
<prevsent>therefore, we are interested in an algorithm with good precision, possibly sacrificing its recall to reasonable extent.
</prevsent>
</prevsection>
<citsent citstr=" C02-1139 ">
v. ng and c. cardie analysed in (ng and cardie, 2002) <papid> C02-1139 </papid>the impact of such pre filtering on their coreference resolution engine.</citsent>
<aftsection>
<nextsent>it turned out that an automatically induced
</nextsent>
<nextsent>60     classifier did not help to improve the overall performance and even decreased it.
</nextsent>
<nextsent>how ever, when more nps were considered anaphoric (that is, the precision for the 7
</nextsent>
<nextsent>60     class increased and the recall decreased), the pre filtering resulted in improving the coreference resolution.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5129">
<title id=" P03-2012.xml">high precision identification of discourse new and unique noun phrases </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>60(   ffi   , because it contains the restrictive post modification of the current landownership system?.
</prevsent>
<prevsent>this approach leads to 72% precision and 69% recall for definite discourse new nps.
</prevsent>
</prevsection>
<citsent citstr=" P99-1048 ">
the system described in (bean and riloff, 1999)<papid> P99-1048 </papid>also makes use of syntactic heuristics.</citsent>
<aftsection>
<nextsent>but in addition the authors mine discourse new entities from the corpus.
</nextsent>
<nextsent>four types of entities can be classified as non-anaphoric: 1.
</nextsent>
<nextsent>having specific syntactic structure, 2.
</nextsent>
<nextsent>appearing in the first sentence of some text in the training corpus,3.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5130">
<title id=" P03-2012.xml">high precision identification of discourse new and unique noun phrases </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>unlike bean and riloff, we model definite probability using the internet instead of the training corpus it self.
</prevsent>
<prevsent>this helps us to overcome the data sparseness problem to large extent.
</prevsent>
</prevsection>
<citsent citstr=" W02-1030 ">
as it has been shown recently in (keller et al, 2002), <papid> W02-1030 </papid>internet counts produce reliable data for linguistic analysis, correlating well with corpus counts and plausibility judgements.</citsent>
<aftsection>
<nextsent>the rest of the paper is organised as follows: first we discuss our nps classification.
</nextsent>
<nextsent>in section 3, we describe briefly various data sources we used.
</nextsent>
<nextsent>section 4 provides an explanation of our learning strategy and evaluation results.
</nextsent>
<nextsent>the approach is summarised in section 5.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5131">
<title id=" P03-2012.xml">high precision identification of discourse new and unique noun phrases </title>
<section> data.  </section>
<citcontext>
<prevsection>
<prevsent>are classified as     .
</prevsent>
<prevsent>in our research we use 20 texts from the muc 7 corpus (hirschman and chinchor, 1997).
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
the texts were parsed by e. charniaks parser (charniak, 2000).<papid> A00-2018 </papid></citsent>
<aftsection>
<nextsent>parsing errors were not corrected manually.
</nextsent>
<nextsent>after this preprocessing step we have 20 lists of noun phrases.
</nextsent>
<nextsent>there are discrepancies between our lists and the muc-7 annotations.
</nextsent>
<nextsent>first, we consider only noun phrases, whereas muc-7 takes into account more types of entities (for example, his?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5132">
<title id=" N12-1082.xml">on the feasibility of open domain referring expression generation using large scale folksonomies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we found that roughly half of the entities annotated in the documents we represent in the folksonomy, which speaks of the feasibility of using folksonomy for od reg, given the fact that wikipedia has strict not ability requirements for adding information.
</prevsent>
<prevsent>in the second experiment, we obtained sets of dis tractors from wikinews,7 aservice where volunteers submit news articles interspersed with wikipedia links.
</prevsent>
</prevsection>
<citsent citstr=" P02-1013 ">
we leveraged said links to assemble 40k referring expression tasks.for algorithms, we employed dale andre iter (1995), gardent (2002) <papid> P02-1013 </papid>and full brevity (fb) (bohnet, 2007).</citsent>
<aftsection>
<nextsent>our results show that the first two algorithms produce results in majority of there ferring expression tasks, with the dale and reiter algorithm being the most efficient and resilient of the three.
</nextsent>
<nextsent>the results, however, are of mixed quality and more research is needed to overcome two problems we have identified in our experiments: dealing with undefined information in the folksonomy and the need to incorporate rough user model in the form of information salience.
</nextsent>
<nextsent>in the next section we briefly summarize the three algorithms we employed in our experiments.
</nextsent>
<nextsent>in section 3, we describe the data employed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5134">
<title id=" P00-1038.xml">query relevant summarization using faqs </title>
<section> a probabilistic model of </section>
<citcontext>
<prevsection>
<prevsent>we now describe the parametric form of these models, and how one can determine optimal values for these parameters using maximum likelihood estimation.
</prevsent>
<prevsent>2.1 language modeling.
</prevsent>
</prevsection>
<citsent citstr=" H94-1028 ">
the type of statistical model we employ for both`py[-bc.?\ and `py[.pbi,?\ is unigram probability distribution over words; in other words, language model.stochastic models of language have been used extensively in speech recognition, optical character recognition, and machine translation (jelinek, 1997; berger et al ., 1994).<papid> H94-1028 </papid></citsent>
<aftsection>
<nextsent>language models have also started to find their way into document retrieval (ponte and croft, 1998; ponte, 1998).
</nextsent>
<nextsent>the fidelity model `y[.pbi,?\ one simple statistical characterization of an ? -word document , 0r???
</nextsent>
<nextsent>1 ???
</nextsent>
<nextsent>1??????
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5135">
<title id=" P00-1038.xml">query relevant summarization using faqs </title>
<section> summary.  </section>
<citcontext>
<prevsection>
<prevsent>a human perform it many times.
</prevsent>
<prevsent>this is the strategy we have pursued here.there has been some work on learning probabilistic model of summarization from text; some of the earliest work on this was due to kupiec et al  (1995), who used collection of manually-summarized text to learn the weights for set of features used in generic summarization system.
</prevsent>
</prevsection>
<citsent citstr=" W97-0704 ">
hovy and lin (1997) <papid> W97-0704 </papid>present another system that learned how the position of sentence affects its suitability for inclusion in summary of the document.</citsent>
<aftsection>
<nextsent>more recently, there has been work on building more complex, structuredmodelsprobabilistic syntax treesto compress single sentences (knight and marcu, 2000).
</nextsent>
<nextsent>mani and bloedorn (1998) have recently proposed method for automatically constructing decision trees to predict whether sentence should or should not be included in documents summary.
</nextsent>
<nextsent>these previous approaches focus mainly on the generic summarization task, not query relevant summarization.
</nextsent>
<nextsent>the language modelling approach described here does suffer from common flaw within text processingsystems: the problem of synonymy.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5136">
<title id=" P00-1063.xml">term recognition using technical dictionary hierarchy </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper focuses on method for extracting terms using dictionary hierarchy.
</prevsent>
<prevsent>our method produces relatively good results for this task.
</prevsent>
</prevsection>
<citsent citstr=" C92-3150 ">
in recent years, statistical approaches on atr (automatic term recognition) (bourigault, 1992; <papid> C92-3150 </papid>dagan et al 1994; justeson and katz, 1995; frantzi, 1999) have achieved good results.</citsent>
<aftsection>
<nextsent>however, there are scopes to improve the performance in extracting terms still further.
</nextsent>
<nextsent>for example, the additional technical dictionaries can be used for improving the accuracy in extracting terms.
</nextsent>
<nextsent>although, the hardship on constructing an electronic dictionary was major obstacles for using an electronic technical dictionary in term recognition, the increasing development of tools for building electronic lexical resources makes new chance to use them in the field of terminology.
</nextsent>
<nextsent>from these endeavour, number of electronic technical dictionaries (domain dictionaries) have been acquired.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5137">
<title id=" P00-1063.xml">term recognition using technical dictionary hierarchy </title>
<section> experiment.  </section>
<citcontext>
<prevsection>
<prevsent>although the method targets korean, it can be applicable to english by slight change on the tweight (wtrl).
</prevsent>
<prevsent>however, there are many scopes for further extensions of this research.
</prevsent>
</prevsection>
<citsent citstr=" P98-1112 ">
the problems of non-nominal terms (klavans and kan, 1998), <papid> P98-1112 </papid>term variation (jacquemin et al, 1997), <papid> P97-1004 </papid>and relevant contexts (maynard and ananiadou, 1998), can be considered for improving the performance.</citsent>
<aftsection>
<nextsent>moreover, it is necessary to apply our method to practical nlp systems, such as an information retrieval system and morphological analyser.
</nextsent>
<nextsent>acknowledgements korterm is sponsored by the ministry of culture and tourism under the program of king sejong project.
</nextsent>
<nextsent>many fundamental researches are supported by the fund of ministry of science and technology under project of plan step2000.
</nextsent>
<nextsent>and this work was partially supported by the kosef through the multilingual information retrieval?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5138">
<title id=" P00-1063.xml">term recognition using technical dictionary hierarchy </title>
<section> experiment.  </section>
<citcontext>
<prevsection>
<prevsent>although the method targets korean, it can be applicable to english by slight change on the tweight (wtrl).
</prevsent>
<prevsent>however, there are many scopes for further extensions of this research.
</prevsent>
</prevsection>
<citsent citstr=" P97-1004 ">
the problems of non-nominal terms (klavans and kan, 1998), <papid> P98-1112 </papid>term variation (jacquemin et al, 1997), <papid> P97-1004 </papid>and relevant contexts (maynard and ananiadou, 1998), can be considered for improving the performance.</citsent>
<aftsection>
<nextsent>moreover, it is necessary to apply our method to practical nlp systems, such as an information retrieval system and morphological analyser.
</nextsent>
<nextsent>acknowledgements korterm is sponsored by the ministry of culture and tourism under the program of king sejong project.
</nextsent>
<nextsent>many fundamental researches are supported by the fund of ministry of science and technology under project of plan step2000.
</nextsent>
<nextsent>and this work was partially supported by the kosef through the multilingual information retrieval?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5139">
<title id=" P04-1059.xml">adaptive chinese word segmentation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we explore several features and describe how to create training data by sampling.
</prevsent>
<prevsent>we evaluate the performance of our segmentation system using an annotated test set, where new words are simulated by sampling.
</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
we then describe transformation-based learning (tbl, brill, 1995) <papid> J95-4004 </papid>method that is used to adapt our system to different segmentation standards.</citsent>
<aftsection>
<nextsent>we compare the adaptive system to other state-of-the-art systems using four test sets in the sighans first international chinese word segmentation bakeoff, each of which is constructed according to different segmentation standard.
</nextsent>
<nextsent>the performance of our system is comparable to the best systems reported on all four test sets.
</nextsent>
<nextsent>it demonstrates the possibility of having single adaptive chinese word segmenter that is capable of supporting multiple user applications.
</nextsent>
<nextsent>word class2 model feature functions, f(s,w) context model word class based trigram, p(w).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5140">
<title id=" P04-1059.xml">adaptive chinese word segmentation </title>
<section> chinese word segmentation with.  </section>
<citcontext>
<prevsection>
<prevsent>in this study we use linear models.
</prevsent>
<prevsent>the method is derived from linear discriminant functions widely used for pattern classification (duda et al, 2001), and has been recently introduced into nlp tasks by collins and duffy (2001).
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
it is also related to log-linear models for machine translation (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>in this framework, we have set of m+1 feature functions fi(s,w), = 0,?,m. they are derived from the context model (i.e. f0(w)) and class models, each for one word class, as shown in figure 1: for probabilistic models such as the context model or person name model, the feature functions are defined as the negative logarithm of the corresponding probabilistic models.
</nextsent>
<nextsent>for each feature function, there is model parameter i. the best word segmentation w* is determined by the decision rule as ? = == i ii m wsfwsscorew 0 0 * ),(maxarg),,(maxarg ??
</nextsent>
<nextsent>(2) below we describe how to optimize s. our method is discriminative approach inspired by the minimum error rate training method proposed in och (2003).<papid> P03-1021 </papid></nextsent>
<nextsent>assume that we can measure the number of segmentation errors in by comparing it with reference segmentation using function er(r,w).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5143">
<title id=" P04-1059.xml">adaptive chinese word segmentation </title>
<section> chinese word segmentation with.  </section>
<citcontext>
<prevsection>
<prevsent>most previous works treat oov word detection as separate step after word segmentation.
</prevsent>
<prevsent>compared to these approaches, our method avoids the error propagation problem and can incorporate variety of knowledge to achieve globally optimal solution.
</prevsent>
</prevsection>
<citsent citstr=" P03-1035 ">
the superiority of the unified approach has been demonstrated empirically in gao et al (2003), <papid> P03-1035 </papid>and will also be discussed in section 5.</citsent>
<aftsection>
<nextsent>new words in this section refer to oov words that are neither recognized as named entities or facto ids nor derived by morphological rules.
</nextsent>
<nextsent>these words are mostly domain specific and/or time-sensitive.
</nextsent>
<nextsent>the identification of such new words has not been studied extensively before.
</nextsent>
<nextsent>it is an important issue that would have substantial impact on the performance of word segmentation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5144">
<title id=" P04-1059.xml">adaptive chinese word segmentation </title>
<section> new word identification.  </section>
<citcontext>
<prevsection>
<prevsent>iwp is real valued feature.
</prevsent>
<prevsent>most chinese characters can be used either as independent words or component parts of multi-character words, or both.
</prevsent>
</prevsection>
<citsent citstr=" W00-1207 ">
the iwp of single character is the likelihood for this character to appear as an independent word in texts (wu and jiang, 2000): )( ) ,()( <papid> W00-1207 </papid>xc wxc xiwp = .</citsent>
<aftsection>
<nextsent>(4) where c(x, w) is the number of occurrences of the character as an independent word in training data, and c(x) is the total number of in training data.
</nextsent>
<nextsent>we assume that the iwp of character string is the product of the iwps of the component characters.
</nextsent>
<nextsent>intuitively, the lower the iwp value, the more likely the character string forms new word.
</nextsent>
<nextsent>in our implementation, the training data is word-segmented.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5145">
<title id=" P04-1059.xml">adaptive chinese word segmentation </title>
<section> new word identification.  </section>
<citcontext>
<prevsection>
<prevsent>= ? 1 0 )()|( k ii kpwnwp , (5) where the constant is dependent on the size of the document: the larger the document, the larger the value.
</prevsent>
<prevsent>pi(k) can be estimated using several term distribution models (see chapter 15.3 in manning and schtze, 1999).
</prevsent>
</prevsection>
<citsent citstr=" P00-1073 ">
following the empirical study in (gao and lee, 2000), <papid> P00-1073 </papid>we use k-mixture (katz, 1996) which estimate pi(k) as ki kp )1(1)1()( 0, +++?= ? ?</citsent>
<aftsection>
<nextsent>, (6) where k,0=1 if k=0, 0 otherwise.
</nextsent>
<nextsent>and ? are parameters that can be fit using the observed mean ? and the observed inverse document frequency idf as follow: cf =?
</nextsent>
<nextsent>, df nidf log= , df dfcfidf ? =??= 12??
</nextsent>
<nextsent>, and ? ?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5147">
<title id=" P04-1059.xml">adaptive chinese word segmentation </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>standards
</prevsent>
<prevsent>we evaluated the proposed adaptive word segmentation system (henceforth aws) using five different standards.
</prevsent>
</prevsection>
<citsent citstr=" W03-1719 ">
the training and test corpora of these standards are detailed in table 1, where msr is defined by ourselves, and the other four are standards used in sighans first international chinese word segmentation bakeoff (bakeoff test sets for brevity, see sproat and emperson (2003) <papid> W03-1719 </papid>for details).</citsent>
<aftsection>
<nextsent>corpus abbrev.
</nextsent>
<nextsent># tr.
</nextsent>
<nextsent>word # te.
</nextsent>
<nextsent>word general?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5153">
<title id=" P04-1059.xml">adaptive chinese word segmentation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the features for nwi were studied in wu &amp; jiang (2000) <papid> W00-1207 </papid>and li et al (2004).</prevsent>
<prevsent>the use of sampling was proposed in della pietra et al (1997) and rosenfeld et al (2001).</prevsent>
</prevsection>
<citsent citstr=" W01-0512 ">
there is also related work on this line in japanese (uchimoto et al, 2001).<papid> W01-0512 </papid></citsent>
<aftsection>
<nextsent>a detailed discussion on differences among the four bakeoff standards is presented in wu (2003), which also proposes an adaptive system where the display of the output can be customized by users.
</nextsent>
<nextsent>the method described in section 4 can be viewed as an improved version in that the transformations are learnt automatically from adaptation data.
</nextsent>
<nextsent>the use of tbl for chinese word segmentation was first suggested in palmer (1997).<papid> P97-1041 </papid></nextsent>
<nextsent>this paper presents statistical approach to adaptive chinese word segmentation based on linear models and tbl.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5154">
<title id=" P04-1059.xml">adaptive chinese word segmentation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>a detailed discussion on differences among the four bakeoff standards is presented in wu (2003), which also proposes an adaptive system where the display of the output can be customized by users.
</prevsent>
<prevsent>the method described in section 4 can be viewed as an improved version in that the transformations are learnt automatically from adaptation data.
</prevsent>
</prevsection>
<citsent citstr=" P97-1041 ">
the use of tbl for chinese word segmentation was first suggested in palmer (1997).<papid> P97-1041 </papid></citsent>
<aftsection>
<nextsent>this paper presents statistical approach to adaptive chinese word segmentation based on linear models and tbl.
</nextsent>
<nextsent>the system has two components: generic segmenter that can adapt to the vocabularies of different domains, and set of output adaptors, learned from application data, for adapting to different application-specific?
</nextsent>
<nextsent>standards.
</nextsent>
<nextsent>we evaluate our system on five test sets, each corresponding to different standard.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5155">
<title id=" P04-2008.xml">improving the accuracy of subcategorizations acquired from corpora </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>grammarsi start by acquiring scfs for lexicalized grammar from corpora by the method described in (car roll and fang, 2004).
</prevsent>
<prevsent>#s(epattern :target |yield| :subcat (vsubcat np) :classes ((24 51 161) 5293) :reliability 0 :freqscore 0.26861903 :freqcnt 1 :tltl (vv0) :sltl ((|route| nn1)) :olt1l ((|result| nn2)) :olt2l nil :olt3l nil :lrl 0)) figure 1: an acquired scf for verb yield?
</prevsent>
</prevsection>
<citsent citstr=" A97-1052 ">
in their study, they first acquire fine-grained scfs using the unsupervised method proposed by briscoe and carroll (1997) <papid> A97-1052 </papid>and korhonen (2002).</citsent>
<aftsection>
<nextsent>figure 1 shows an example of one acquired scf entry for verb yield.?
</nextsent>
<nextsent>each scf entry has several fields about the observed scf.
</nextsent>
<nextsent>i explain here only its portion related to this study.
</nextsent>
<nextsent>the target field is word stem, the first number in the classes field indicates an scf type, and the freqcnt field shows how often words derivable from the word stem appeared with the scf type in the training corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5156">
<title id=" P04-2008.xml">improving the accuracy of subcategorizations acquired from corpora </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>i explain here only its portion related to this study.
</prevsent>
<prevsent>the target field is word stem, the first number in the classes field indicates an scf type, and the freqcnt field shows how often words derivable from the word stem appeared with the scf type in the training corpus.
</prevsent>
</prevsection>
<citsent citstr=" J87-3002 ">
the obtained scfs comprise the total 163 scf types which are originally based on the scfs in the anlt (boguraev and briscoe,1987) <papid> J87-3002 </papid>and comlex (grishman et al, 1994) <papid> C94-1042 </papid>dictionaries.</citsent>
<aftsection>
<nextsent>in this example, the scf type 24 corresponds to an scf of transitive verb.
</nextsent>
<nextsent>they then obtain scfs for the target lexicalized grammar (the lingo erg (copestake, 2002) in their study) using handcrafted translation map from these 163 types to the scf types in the target grammar.
</nextsent>
<nextsent>they reported that they could achievea coverage improvement of 4.5% but that average parse time was doubled.
</nextsent>
<nextsent>this is because they did not use any filtering method for the acquiredscfs to suppress an increase of the lexical ambiguity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5157">
<title id=" P04-2008.xml">improving the accuracy of subcategorizations acquired from corpora </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>i explain here only its portion related to this study.
</prevsent>
<prevsent>the target field is word stem, the first number in the classes field indicates an scf type, and the freqcnt field shows how often words derivable from the word stem appeared with the scf type in the training corpus.
</prevsent>
</prevsection>
<citsent citstr=" C94-1042 ">
the obtained scfs comprise the total 163 scf types which are originally based on the scfs in the anlt (boguraev and briscoe,1987) <papid> J87-3002 </papid>and comlex (grishman et al, 1994) <papid> C94-1042 </papid>dictionaries.</citsent>
<aftsection>
<nextsent>in this example, the scf type 24 corresponds to an scf of transitive verb.
</nextsent>
<nextsent>they then obtain scfs for the target lexicalized grammar (the lingo erg (copestake, 2002) in their study) using handcrafted translation map from these 163 types to the scf types in the target grammar.
</nextsent>
<nextsent>they reported that they could achievea coverage improvement of 4.5% but that average parse time was doubled.
</nextsent>
<nextsent>this is because they did not use any filtering method for the acquiredscfs to suppress an increase of the lexical ambiguity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5158">
<title id=" P04-2008.xml">improving the accuracy of subcategorizations acquired from corpora </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>their method is extendable to any lexicalized grammars, if we could have translation map from these 163 types to the scf types in the grammar.
</prevsent>
<prevsent>2.2 clustering of verb scf distributions.
</prevsent>
</prevsection>
<citsent citstr=" P03-1009 ">
there is some related work on clustering ofverbs according to their scf probability distributions (schulte im walde and brew, 2002; korhonen et al, 2003).<papid> P03-1009 </papid></citsent>
<aftsection>
<nextsent>schulte im walde and (true) probability distribution 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 np none np_to-pp np_pp pp subcategorization frame pr ba bi lit apply recognition threshold figure 2: scf probability distributions for apply brew (2002) used the k-means (forgy, 1965) algorithm to cluster scf distributions for monose mous verbs while korhonen et al (2003) <papid> P03-1009 </papid>applied other clustering methods to cluster polysemic scfdata.</nextsent>
<nextsent>these studies aim at obtaining verb semantic classes, which are closely related to syntactic behavior of argument selection (levin, 1993).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5160">
<title id=" N12-1064.xml">how text segmentation algorithms gain from topic models </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>tt using tms and our own algorithm improve on the state-ofthe-art for standard dataset, while being conceptually simpler and computationally more efficient than other topic-based segmentation algorithms.
</prevsent>
<prevsent>based on the observation of halliday and hasan (1976) that the density of coherence relations is higher within segments than between segments,most algorithms compute coherence score to measure the difference of textual units for informing segmentation decision.
</prevsent>
</prevsection>
<citsent citstr=" P94-1002 ">
text tiling (tt) (hearst, 1994) <papid> P94-1002 </papid>relies on the simplest coherence relation ? word repetition ? and computes similarities between textual units based on the similarities of word space vectors.</citsent>
<aftsection>
<nextsent>with c99 (choi, 2000) <papid> A00-2004 </papid>an algorithm was introduced that uses matrix-based ranking and aclustering approach in order to relate the most similar textual units and to cluster groups of consecutive units into segments.</nextsent>
<nextsent>both tt and c99 characterize textual units by the words they contain.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5162">
<title id=" N12-1064.xml">how text segmentation algorithms gain from topic models </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>based on the observation of halliday and hasan (1976) that the density of coherence relations is higher within segments than between segments,most algorithms compute coherence score to measure the difference of textual units for informing segmentation decision.
</prevsent>
<prevsent>text tiling (tt) (hearst, 1994) <papid> P94-1002 </papid>relies on the simplest coherence relation ? word repetition ? and computes similarities between textual units based on the similarities of word space vectors.</prevsent>
</prevsection>
<citsent citstr=" A00-2004 ">
with c99 (choi, 2000) <papid> A00-2004 </papid>an algorithm was introduced that uses matrix-based ranking and aclustering approach in order to relate the most similar textual units and to cluster groups of consecutive units into segments.</citsent>
<aftsection>
<nextsent>both tt and c99 characterize textual units by the words they contain.
</nextsent>
<nextsent>galley et al  (2003) <papid> P03-1071 </papid>showed that using tf-idf term weights in the term vector improves the performance of tt.</nextsent>
<nextsent>proposals using dynamic programming (dp) are given in (utiyama and isahara, 2001; <papid> P01-1064 </papid>fragkou et al ., 2004).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5163">
<title id=" N12-1064.xml">how text segmentation algorithms gain from topic models </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>with c99 (choi, 2000) <papid> A00-2004 </papid>an algorithm was introduced that uses matrix-based ranking and aclustering approach in order to relate the most similar textual units and to cluster groups of consecutive units into segments.</prevsent>
<prevsent>both tt and c99 characterize textual units by the words they contain.</prevsent>
</prevsection>
<citsent citstr=" P03-1071 ">
galley et al  (2003) <papid> P03-1071 </papid>showed that using tf-idf term weights in the term vector improves the performance of tt.</citsent>
<aftsection>
<nextsent>proposals using dynamic programming (dp) are given in (utiyama and isahara, 2001; <papid> P01-1064 </papid>fragkou et al ., 2004).</nextsent>
<nextsent>related to our work are the approaches described in (misra et al , 2009; sun et al , 2008): <papid> P08-2068 </papid>here, tms are also used to alleviate the sparsity of word vectors.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5164">
<title id=" N12-1064.xml">how text segmentation algorithms gain from topic models </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>both tt and c99 characterize textual units by the words they contain.
</prevsent>
<prevsent>galley et al  (2003) <papid> P03-1071 </papid>showed that using tf-idf term weights in the term vector improves the performance of tt.</prevsent>
</prevsection>
<citsent citstr=" P01-1064 ">
proposals using dynamic programming (dp) are given in (utiyama and isahara, 2001; <papid> P01-1064 </papid>fragkou et al ., 2004).</citsent>
<aftsection>
<nextsent>related to our work are the approaches described in (misra et al , 2009; sun et al , 2008): <papid> P08-2068 </papid>here, tms are also used to alleviate the sparsity of word vectors.</nextsent>
<nextsent>misra et al  (2009) extended the dpalgorithm u00 from utiyama and isahara (2001) <papid> P01-1064 </papid>us 553 ing tms.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5165">
<title id=" N12-1064.xml">how text segmentation algorithms gain from topic models </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>galley et al  (2003) <papid> P03-1071 </papid>showed that using tf-idf term weights in the term vector improves the performance of tt.</prevsent>
<prevsent>proposals using dynamic programming (dp) are given in (utiyama and isahara, 2001; <papid> P01-1064 </papid>fragkou et al ., 2004).</prevsent>
</prevsection>
<citsent citstr=" P08-2068 ">
related to our work are the approaches described in (misra et al , 2009; sun et al , 2008): <papid> P08-2068 </papid>here, tms are also used to alleviate the sparsity of word vectors.</citsent>
<aftsection>
<nextsent>misra et al  (2009) extended the dpalgorithm u00 from utiyama and isahara (2001) <papid> P01-1064 </papid>us 553 ing tms.</nextsent>
<nextsent>at this, the topic assignments have to be inferred for each possible segment, resulting in high computational cost.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5167">
<title id=" N12-1064.xml">how text segmentation algorithms gain from topic models </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>misra et al  (2009) extended the dpalgorithm u00 from utiyama and isahara (2001) <papid> P01-1064 </papid>us 553 ing tms.</prevsent>
<prevsent>at this, the topic assignments have to be inferred for each possible segment, resulting in high computational cost.</prevsent>
</prevsection>
<citsent citstr=" E06-1035 ">
in addition to these linear topic segmentation algorithms, there are hierarchical segmentation algorithms, see (yaari, 1997; hsueh et al , 2006; <papid> E06-1035 </papid>eisenstein, 2009).<papid> N09-1040 </papid></citsent>
<aftsection>
<nextsent>for topic modeling, we use the widely applied lda (blei et al , 2003).
</nextsent>
<nextsent>this generative probabilistic model uses training corpus of documents to create document-topic and topic-word distributions and is parameterized by the number of topics as well as by two hyperparameters.
</nextsent>
<nextsent>to generate document the topic proportions are drawn using dirichlet distribution with hyperparameter ?.
</nextsent>
<nextsent>adjacent for each word a topic zdi is chosen according to multinomial distribution using hyperparameter zdi . unseen documents can be annotated with an existing tm using bayesian inference methods (here: gibbs sampling).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5168">
<title id=" N12-1064.xml">how text segmentation algorithms gain from topic models </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>misra et al  (2009) extended the dpalgorithm u00 from utiyama and isahara (2001) <papid> P01-1064 </papid>us 553 ing tms.</prevsent>
<prevsent>at this, the topic assignments have to be inferred for each possible segment, resulting in high computational cost.</prevsent>
</prevsection>
<citsent citstr=" N09-1040 ">
in addition to these linear topic segmentation algorithms, there are hierarchical segmentation algorithms, see (yaari, 1997; hsueh et al , 2006; <papid> E06-1035 </papid>eisenstein, 2009).<papid> N09-1040 </papid></citsent>
<aftsection>
<nextsent>for topic modeling, we use the widely applied lda (blei et al , 2003).
</nextsent>
<nextsent>this generative probabilistic model uses training corpus of documents to create document-topic and topic-word distributions and is parameterized by the number of topics as well as by two hyperparameters.
</nextsent>
<nextsent>to generate document the topic proportions are drawn using dirichlet distribution with hyperparameter ?.
</nextsent>
<nextsent>adjacent for each word a topic zdi is chosen according to multinomial distribution using hyperparameter zdi . unseen documents can be annotated with an existing tm using bayesian inference methods (here: gibbs sampling).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5172">
<title id=" N12-1064.xml">how text segmentation algorithms gain from topic models </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>to reduce the variance of the shown results, derived by the random nature of sampling and inference, the results for each fold are calculated 30 times using different lda models.the lda model is trained with n=100 topics, 500 sampling iterations and symmetric hy per parameters as recommended by griffiths and steyvers (2004)(?=50/n and ?=0.01), using jgibbslda (phan and nguyen, 2007).
</prevsent>
<prevsent>for the annotation of unseen data with topic information, we use lda inference, sampling 100 iterations.
</prevsent>
</prevsection>
<citsent citstr=" J02-1002 ">
inference is executed sentence-wise, since sentences form the minimal unit of our segmentation algorithms and we cannot use document information in the test setting.the performance of the algorithms is measured using pk and window diff (wd) metrics (beefermanet al , 1999; pevzner and hearst, 2002).<papid> J02-1002 </papid></citsent>
<aftsection>
<nextsent>the c99 algorithm is initial ized with 1111 ranking mask, as recommended in choi (2000).<papid> A00-2004 </papid></nextsent>
<nextsent>tt is configured according to choi (2000) <papid> A00-2004 </papid>with sequence length w=20 and block size k=6.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5178">
<title id=" P03-2009.xml">discourse chunking a tool in dialogue act tagging </title>
<section> dialogue act tagging.  </section>
<citcontext>
<prevsection>
<prevsent>da tagging has application in nlp work, including speech recognition and language understanding.
</prevsent>
<prevsent>the verbmobil-2 corpus was used for this study, with its accompanying tagset, shown in table 1.1.
</prevsent>
</prevsection>
<citsent citstr=" J00-3003 ">
much of the work in da tagging (reithinger, 1997; samuel, 2000; stolcke et al 2000; <papid> J00-3003 </papid>wright,1998) uses lexical information (the words or grams in an utterance), and to lesser extent syntactic and phonological information (as with prosody).</citsent>
<aftsection>
<nextsent>however, there has traditionally been lack of true discourse-level information in tasks involving dialogue acts.
</nextsent>
<nextsent>discourse information is typically limited to looking at surrounding da tags (reithinger, 1997; samuel, 2000).
</nextsent>
<nextsent>unfortunately, knowledge of prior da tags does not always translate to an accurate guess of whats coming next, especially when this information is imperfect.
</nextsent>
<nextsent>theories about the structure of dialogue (for example, centering [grosz, joshi, &amp; weinstein 1995], and more recently dialogue macro game theory [mann 2002]) <papid> W02-0218 </papid>have not generally been applied to theda tagging task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5179">
<title id=" P03-2009.xml">discourse chunking a tool in dialogue act tagging </title>
<section> dialogue act tagging.  </section>
<citcontext>
<prevsection>
<prevsent>discourse information is typically limited to looking at surrounding da tags (reithinger, 1997; samuel, 2000).
</prevsent>
<prevsent>unfortunately, knowledge of prior da tags does not always translate to an accurate guess of whats coming next, especially when this information is imperfect.
</prevsent>
</prevsection>
<citsent citstr=" W02-0218 ">
theories about the structure of dialogue (for example, centering [grosz, joshi, &amp; weinstein 1995], and more recently dialogue macro game theory [mann 2002]) <papid> W02-0218 </papid>have not generally been applied to theda tagging task.</citsent>
<aftsection>
<nextsent>their use amounts to separate tagging task of its own, with the concomitant time-consuming corpus annotation.
</nextsent>
<nextsent>in this work, present the results from da tagging project that uses case-based reasoning system (after kolodner 1993).
</nextsent>
<nextsent>i show how the results from this da tagger are improved by the use of concept call discourse chunking.?
</nextsent>
<nextsent>discourse chunking gives information about the patterns of topic raising and negotiation india tag example accept sounds good to me back channel mhm bye see you clarify said the third close okay  uhm  so guess that is it commit will get that arranged then confirm well will see you  uhm  at the airport on the third defer and will get back to you on that deliberate so let us see deviate_scenario oh have tickets for the opera on friday exclude january is basically shot for me explained_reject am on vacation then feedback gosh feedback_negative not really feedback_positive okay give_reason because that is when the express flights are greet hello miriam inform  uhm  i have list of hotels here init so we need to schedule trip to hanover introduce natalie this is scott not_classifiable and  uh  offer  uhm  would you like me to call politeness_formula good of you to stop by refer_to_setting want to step into your office since we are standing right outside of it reject no that is bad for me unfortunately request you think so?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5180">
<title id=" N12-1068.xml">are you sure confidence in prediction of dependency tree edges </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we evaluate our methods on parsing text in 14 languages.
</prevsent>
<prevsent>dependency parsers construct directed edges between words of given sentence to their arguments according to syntactic or semantic rules.
</prevsent>
</prevsection>
<citsent citstr=" H05-1066 ">
we use mst parser of mcdonald et al (2005) <papid> H05-1066 </papid>and focuson non-projective dependency parse trees with non typed (unlabeled) edges.</citsent>
<aftsection>
<nextsent>mst parser produces aparse tree for sentence by constructing full, directed and weighted graph over the words of the sentence, and then out putting the maximal spanning tree (mst) of the graph.
</nextsent>
<nextsent>a linear model is employed for computing the weights of the edges using features depending on the two words the edge connects.
</nextsent>
<nextsent>example features are the distance between the two words, words identity and words part-of-speech.
</nextsent>
<nextsent>mst parser is training model using online learning and specifically the mira algorithm (crammer et al., 2006).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5181">
<title id=" N12-1068.xml">are you sure confidence in prediction of dependency tree edges </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this information can be used in several ways.
</prevsent>
<prevsent>for example, when using parse treesas input to another system such as machine translation, the confidence information can be used to correct inputs with low confidence.
</prevsent>
</prevsection>
<citsent citstr=" D10-1095 ">
another example is to guide manual validation to outputs which are more likely to be erroneous, saving human labor.we adapt methods proposed by mejer and crammer (2010) <papid> D10-1095 </papid>in order to produce per-edge confidence estimations in the prediction.</citsent>
<aftsection>
<nextsent>specifically, one approach is based on sampling, and another on generalization of the concept of margin.
</nextsent>
<nextsent>additionally, we propose new method based on combining both approaches, and show that is outperforms both.
</nextsent>
<nextsent>mst parser produces the highest scoring parse trees using the trained linear model with no additional information about the confidence in the predicted tree.
</nextsent>
<nextsent>in this work we compute per-edge confidence scores, that is, numeric confidence value, for all edges predicted by the parser.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5183">
<title id=" N12-1068.xml">are you sure confidence in prediction of dependency tree edges </title>
<section> confidence estimation in prediction.  </section>
<citcontext>
<prevsection>
<prevsent>delta method does not require parameter tuning.
</prevsent>
<prevsent>the second method, named weighted k-best(wkb), is deterministic method building on properties of the inference algorithm.
</prevsent>
</prevsection>
<citsent citstr=" P07-1050 ">
specifically, we use k-best maximum spanning tree algorithm (hall, 2007) <papid> P07-1050 </papid>to produce the parse trees with the highest score.</citsent>
<aftsection>
<nextsent>this collection of k-trees is used to compute the confidence in predicted edge.
</nextsent>
<nextsent>the confidence score is defined to be the weighted fraction of parse trees that contain the edge.
</nextsent>
<nextsent>the contribution of different trees to compute this fraction is proportional to their absolute score, where thetree with the highest score has the largest contribution.
</nextsent>
<nextsent>only trees with positive scores are included.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5186">
<title id=" P01-1006.xml">evaluation tool for rule based anaphora resolution methods </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the evaluation of any nlp algorithm or system should indicate not only its efficiency or performance, but should also help us discover what new approach brings to the current state of play in the field.
</prevsent>
<prevsent>to this end, comparative evaluation with other well-known or similar approaches would be highly desirable.
</prevsent>
</prevsection>
<citsent citstr=" P98-2143 ">
we have already voiced concern (mitkov, 1998<papid> P98-2143 </papid>a), (mitkov, 2000b) that the evaluation of anaphora resolution algorithms and systems is bereft of any common ground for comparison due not only to the difference of the evaluation data, but also due to the diversity of pre-processing tools employed by each anaphora resolution system.</citsent>
<aftsection>
<nextsent>the evaluation picture would not be accurate even if we compared anaphora resolution systems on the basis of the same data since the pre-processing errors which would be carried over to the systems?
</nextsent>
<nextsent>outputs might vary.
</nextsent>
<nextsent>as way forward we have proposed the idea of the evaluation workbench (mitkov, 2000b) - an open-ended architecture which allows the incorporation of different algorithms and their comparison on the basis of the same pre-processing tools and the same data.
</nextsent>
<nextsent>our paper discusses particular configuration of this new evaluation environment incorporating three approaches sharing common knowledge-poor philosophy?: kennedy and boguraevs (1996) <papid> C96-1021 </papid>parser-free algorithm, baldwins (1997) cogniac and mitkovs (1998b) knowledge-poor approach.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5190">
<title id=" P01-1006.xml">evaluation tool for rule based anaphora resolution methods </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>outputs might vary.
</prevsent>
<prevsent>as way forward we have proposed the idea of the evaluation workbench (mitkov, 2000b) - an open-ended architecture which allows the incorporation of different algorithms and their comparison on the basis of the same pre-processing tools and the same data.
</prevsent>
</prevsection>
<citsent citstr=" C96-1021 ">
our paper discusses particular configuration of this new evaluation environment incorporating three approaches sharing common knowledge-poor philosophy?: kennedy and boguraevs (1996) <papid> C96-1021 </papid>parser-free algorithm, baldwins (1997) cogniac and mitkovs (1998b) knowledge-poor approach.</citsent>
<aftsection>
<nextsent>anaphora resolution in order to secure fair?, consistent and accurate evaluation environment, and to address the problems identified above, we have developed an evaluation workbench for anaphora resolution which allows the comparison of anaphora resolution approaches sharing common principles (e.g. similar pre-processing or resolution strategy).
</nextsent>
<nextsent>the workbench enables the plugging in?
</nextsent>
<nextsent>and testing of anaphora resolution algorithms on the basis of the same pre-processing tools and data.
</nextsent>
<nextsent>this development is time-consuming task, given that we have to re-implement most of the algorithms, but it is expected to achieve clearer assessment of the advantages and disadvantages of the different approaches.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5191">
<title id=" P01-1006.xml">evaluation tool for rule based anaphora resolution methods </title>
<section> the evaluation workbench for.  </section>
<citcontext>
<prevsection>
<prevsent>by way of illustration, hobbs?
</prevsent>
<prevsent>naive approach (1976), naive approach (1978) was not implemented in its original version.
</prevsent>
</prevsection>
<citsent citstr=" C90-3063 ">
in (dagan and itai, 1990; <papid> C90-3063 </papid>dagan and itai, 1991; aone and bennett, 1995; kennedy and boguraev, 1996) <papid> C96-1021 </papid>pleonastic pronouns are removed manually2 , whereas in (mitkov, 1998<papid> P98-2143 </papid>b;ferrandez et al, 1997) the outputs of the part-of speech tagger and the np extractor/ partial parser are post-edited similarly to lappin and leass (1994) <papid> J94-4002 </papid>where the output of the slot unification grammar parser is corrected manually.</citsent>
<aftsection>
<nextsent>finally, ge at als (1998) and tetraults systems (1999) 1for instance, the accuracy of tasks such as robust parsing and identification of pleonastic pronouns is far below 100% see (mitkov, 2001) for detailed discussion.
</nextsent>
<nextsent>2in addition, dagan and itai (1991) undertook additional pre-editing such as the removal of sentences for which the parser failed to produce reasonable parse, cases where the antecedent was not an np etc.; kennedy and boguraev (1996) <papid> C96-1021 </papid>manually removed 30 occurrences of pleonastic pronouns (which could not be recognised by their pleonastic recogniser) as well as 6 occurrences of it which referred to vp or prepositional constituent.</nextsent>
<nextsent>make use of annotated corpora and thus do not perform any pre-processing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5197">
<title id=" P01-1006.xml">evaluation tool for rule based anaphora resolution methods </title>
<section> the evaluation workbench for.  </section>
<citcontext>
<prevsection>
<prevsent>by way of illustration, hobbs?
</prevsent>
<prevsent>naive approach (1976), naive approach (1978) was not implemented in its original version.
</prevsent>
</prevsection>
<citsent citstr=" J94-4002 ">
in (dagan and itai, 1990; <papid> C90-3063 </papid>dagan and itai, 1991; aone and bennett, 1995; kennedy and boguraev, 1996) <papid> C96-1021 </papid>pleonastic pronouns are removed manually2 , whereas in (mitkov, 1998<papid> P98-2143 </papid>b;ferrandez et al, 1997) the outputs of the part-of speech tagger and the np extractor/ partial parser are post-edited similarly to lappin and leass (1994) <papid> J94-4002 </papid>where the output of the slot unification grammar parser is corrected manually.</citsent>
<aftsection>
<nextsent>finally, ge at als (1998) and tetraults systems (1999) 1for instance, the accuracy of tasks such as robust parsing and identification of pleonastic pronouns is far below 100% see (mitkov, 2001) for detailed discussion.
</nextsent>
<nextsent>2in addition, dagan and itai (1991) undertook additional pre-editing such as the removal of sentences for which the parser failed to produce reasonable parse, cases where the antecedent was not an np etc.; kennedy and boguraev (1996) <papid> C96-1021 </papid>manually removed 30 occurrences of pleonastic pronouns (which could not be recognised by their pleonastic recogniser) as well as 6 occurrences of it which referred to vp or prepositional constituent.</nextsent>
<nextsent>make use of annotated corpora and thus do not perform any pre-processing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5199">
<title id=" P01-1006.xml">evaluation tool for rule based anaphora resolution methods </title>
<section> the evaluation workbench for.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 pre-processing tools.
</prevsent>
<prevsent>parser the current version of the evaluation workbench employs one of the high performance super-taggers?
</prevsent>
</prevsection>
<citsent citstr=" A97-1011 ">
for english - con exors fdg parser (tapanainen and jarvinen, 1997).<papid> A97-1011 </papid></citsent>
<aftsection>
<nextsent>this super-tagger gives morphological information and the syntactic roles of words (in most of the cases).
</nextsent>
<nextsent>it also performs surface syntactic parsing of the text using dependency links that show the head-modifier relations between words.
</nextsent>
<nextsent>this kind of information is used for extracting complex nps.
</nextsent>
<nextsent>in the table below the output of the fdg parser run over the sentence: this is an input file.?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5203">
<title id=" P01-1006.xml">evaluation tool for rule based anaphora resolution methods </title>
<section> comparative evaluation of.  </section>
<citcontext>
<prevsection>
<prevsent>knowledge-poor anaphora resolution approaches the first phase of our project included comparison of knowledge-poorer approaches which share common pre-processing philosophy.
</prevsent>
<prevsent>we selected for comparative evaluation three approaches extensively cited inthe literature: kennedy and boguraevs parser free version of lappin and leass?
</prevsent>
</prevsection>
<citsent citstr=" W97-1306 ">
rap (kennedy and boguraev, 1996), <papid> C96-1021 </papid>baldwins pronoun resolution method (baldwin, 1997) <papid> W97-1306 </papid>and mitkovs knowledge-poor pronoun resolution approach (mitkov, 1998<papid> P98-2143 </papid>b).</citsent>
<aftsection>
<nextsent>all three of these algorithms share similar pre-processing methodology: they do not relyon parser to process the input and instead use pos taggers and np extractors; nor do any of the methods make use of semantic or real-world knowledge.
</nextsent>
<nextsent>we re-implemented all three algorithms based on their original description and personal consultation with the authors to avoid misinterpretations.
</nextsent>
<nextsent>since the original version of cogniac is non-robust and resolves only anaphors that obey certain rules, for fairer and comparable results we implemented the resolve-all?
</nextsent>
<nextsent>version as described in (baldwin, 1997).<papid> W97-1306 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5226">
<title id=" P00-1026.xml">a morphologically sensitive clustering algorithm for identifying arabic roots </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, arabic morphology is excruciatingly complex (the appendix attempts brief introduction), and root identification on scale useful for ir remains problematic.
</prevsent>
<prevsent>research on arabic ir tends to treat automatic indexing and stemming separately.
</prevsent>
</prevsection>
<citsent citstr=" W98-1009 ">
al-shalabi and evans (1998) <papid> W98-1009 </papid>and el-sadany and hashish (1989) developed stemming algorithms.</citsent>
<aftsection>
<nextsent>hmeidi et al (1997) developed an information retrieval system with an index, but does not explain the underlying stemming algorithm.
</nextsent>
<nextsent>in al-kharashi and evans (1994), stemming is done manually and their index is built by manual insertion of roots, stems and words.
</nextsent>
<nextsent>typically, arabic stemming algorithms operate by trial and error?.
</nextsent>
<nextsent>affixes are stripped away, and stems undone?, according to patterns and rules, and with reference to dictionaries.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5227">
<title id=" P00-1026.xml">a morphologically sensitive clustering algorithm for identifying arabic roots </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>some work builds on established formalisms such datr (al-najem 1998), or kimmo.
</prevsent>
<prevsent>this latter strand produced extensive deep analyses.
</prevsent>
</prevsection>
<citsent citstr=" C94-1029 ">
kiraz (1994) <papid> C94-1029 </papid>extended the architecture with multi-level tape, to deal with the typical interruption of root letter sequences caused by broken plural and weak root letter change.</citsent>
<aftsection>
<nextsent>beesley (1996) <papid> C96-1017 </papid>describes the re-implementation of earlier work as single finite state transducer between surface and lexical (root and tag) strings.</nextsent>
<nextsent>this was refined (beesley 1998) to the current on-line system capable of analysing over 70 million words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5228">
<title id=" P00-1026.xml">a morphologically sensitive clustering algorithm for identifying arabic roots </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this latter strand produced extensive deep analyses.
</prevsent>
<prevsent>kiraz (1994) <papid> C94-1029 </papid>extended the architecture with multi-level tape, to deal with the typical interruption of root letter sequences caused by broken plural and weak root letter change.</prevsent>
</prevsection>
<citsent citstr=" C96-1017 ">
beesley (1996) <papid> C96-1017 </papid>describes the re-implementation of earlier work as single finite state transducer between surface and lexical (root and tag) strings.</citsent>
<aftsection>
<nextsent>this was refined (beesley 1998) to the current on-line system capable of analysing over 70 million words.
</nextsent>
<nextsent>so far, these approaches have limited scope for deployment in ir.
</nextsent>
<nextsent>even if substantial, their morpho-syntactic coverage remains limited and processing efficiency implications are often unclear.
</nextsent>
<nextsent>in addition, modern written arabic presents unique range of orthographic problems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5229">
<title id=" P03-1055.xml">deep syntactic processing by combining shallow methods </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we explore novel approach for finding long-distance dependencies.
</prevsent>
<prevsent>in particular, we detect such dependencies, or discontinuities, in atwo-step process: (i) conceptually simple shallow tagger looks for sites of discontinuties as preprocessing step, before parsing; (ii) the parser then finds the dependent constituent (antecedent).clearly, information about long-distance relationships is vital for semantic interpretation.
</prevsent>
</prevsection>
<citsent citstr=" P99-1065 ">
however,such constructions prove to be difficult for stochastic parsers (collins et al, 1999) <papid> P99-1065 </papid>and they either avoid tackling the problem (charniak, 2000; <papid> A00-2018 </papid>bod, 2003) <papid> E03-1005 </papid>or only deal with subset of the problematic cases (collins, 1997).<papid> P97-1003 </papid></citsent>
<aftsection>
<nextsent>johnson (2002)<papid> P02-1018 </papid>proposes an algorithm that isable to find long-distance dependencies, as postprocessing step, after parsing.</nextsent>
<nextsent>although this algorithm fares well, it faces the problem that stochastic parsers not designed to capture non-local dependencies may get confused when parsing sentence with discontinuities.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5230">
<title id=" P03-1055.xml">deep syntactic processing by combining shallow methods </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we explore novel approach for finding long-distance dependencies.
</prevsent>
<prevsent>in particular, we detect such dependencies, or discontinuities, in atwo-step process: (i) conceptually simple shallow tagger looks for sites of discontinuties as preprocessing step, before parsing; (ii) the parser then finds the dependent constituent (antecedent).clearly, information about long-distance relationships is vital for semantic interpretation.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
however,such constructions prove to be difficult for stochastic parsers (collins et al, 1999) <papid> P99-1065 </papid>and they either avoid tackling the problem (charniak, 2000; <papid> A00-2018 </papid>bod, 2003) <papid> E03-1005 </papid>or only deal with subset of the problematic cases (collins, 1997).<papid> P97-1003 </papid></citsent>
<aftsection>
<nextsent>johnson (2002)<papid> P02-1018 </papid>proposes an algorithm that isable to find long-distance dependencies, as postprocessing step, after parsing.</nextsent>
<nextsent>although this algorithm fares well, it faces the problem that stochastic parsers not designed to capture non-local dependencies may get confused when parsing sentence with discontinuities.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5231">
<title id=" P03-1055.xml">deep syntactic processing by combining shallow methods </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we explore novel approach for finding long-distance dependencies.
</prevsent>
<prevsent>in particular, we detect such dependencies, or discontinuities, in atwo-step process: (i) conceptually simple shallow tagger looks for sites of discontinuties as preprocessing step, before parsing; (ii) the parser then finds the dependent constituent (antecedent).clearly, information about long-distance relationships is vital for semantic interpretation.
</prevsent>
</prevsection>
<citsent citstr=" E03-1005 ">
however,such constructions prove to be difficult for stochastic parsers (collins et al, 1999) <papid> P99-1065 </papid>and they either avoid tackling the problem (charniak, 2000; <papid> A00-2018 </papid>bod, 2003) <papid> E03-1005 </papid>or only deal with subset of the problematic cases (collins, 1997).<papid> P97-1003 </papid></citsent>
<aftsection>
<nextsent>johnson (2002)<papid> P02-1018 </papid>proposes an algorithm that isable to find long-distance dependencies, as postprocessing step, after parsing.</nextsent>
<nextsent>although this algorithm fares well, it faces the problem that stochastic parsers not designed to capture non-local dependencies may get confused when parsing sentence with discontinuities.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5232">
<title id=" P03-1055.xml">deep syntactic processing by combining shallow methods </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we explore novel approach for finding long-distance dependencies.
</prevsent>
<prevsent>in particular, we detect such dependencies, or discontinuities, in atwo-step process: (i) conceptually simple shallow tagger looks for sites of discontinuties as preprocessing step, before parsing; (ii) the parser then finds the dependent constituent (antecedent).clearly, information about long-distance relationships is vital for semantic interpretation.
</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
however,such constructions prove to be difficult for stochastic parsers (collins et al, 1999) <papid> P99-1065 </papid>and they either avoid tackling the problem (charniak, 2000; <papid> A00-2018 </papid>bod, 2003) <papid> E03-1005 </papid>or only deal with subset of the problematic cases (collins, 1997).<papid> P97-1003 </papid></citsent>
<aftsection>
<nextsent>johnson (2002)<papid> P02-1018 </papid>proposes an algorithm that isable to find long-distance dependencies, as postprocessing step, after parsing.</nextsent>
<nextsent>although this algorithm fares well, it faces the problem that stochastic parsers not designed to capture non-local dependencies may get confused when parsing sentence with discontinuities.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5235">
<title id=" P03-1055.xml">deep syntactic processing by combining shallow methods </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in particular, we detect such dependencies, or discontinuities, in atwo-step process: (i) conceptually simple shallow tagger looks for sites of discontinuties as preprocessing step, before parsing; (ii) the parser then finds the dependent constituent (antecedent).clearly, information about long-distance relationships is vital for semantic interpretation.
</prevsent>
<prevsent>however,such constructions prove to be difficult for stochastic parsers (collins et al, 1999) <papid> P99-1065 </papid>and they either avoid tackling the problem (charniak, 2000; <papid> A00-2018 </papid>bod, 2003) <papid> E03-1005 </papid>or only deal with subset of the problematic cases (collins, 1997).<papid> P97-1003 </papid></prevsent>
</prevsection>
<citsent citstr=" P02-1018 ">
johnson (2002)<papid> P02-1018 </papid>proposes an algorithm that isable to find long-distance dependencies, as postprocessing step, after parsing.</citsent>
<aftsection>
<nextsent>although this algorithm fares well, it faces the problem that stochastic parsers not designed to capture non-local dependencies may get confused when parsing sentence with discontinuities.
</nextsent>
<nextsent>however, the approach presented here is not susceptible to this shortcoming as it finds discontinuties before parsing.
</nextsent>
<nextsent>overall, we present three primary contributions.first, we extend the mechanism of adding gap variables for nodes dominating site of discontinuity (collins, 1997).<papid> P97-1003 </papid></nextsent>
<nextsent>this approach allows even context-free parser to reliably recover antecedents, given prior information about where discontinuities occur.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5240">
<title id=" P03-1055.xml">deep syntactic processing by combining shallow methods </title>
<section> annotation of empty elements.  </section>
<citcontext>
<prevsection>
<prevsent>example npnp 987 sam was seen * whnp 438 the woman who you saw *t* pronp 426 * to sleep is nice comps bar 338 sam said 0 sasha snores unit 332 $ 25 *u* whs 228 sam had to go, sasha said *t* whadvp 120 sam told us how he did it *t* clause 118 sam had to go, sasha said 0 compwhnp 98 the woman 0 we saw *t* all 3310 table 1: most frequent types of ees in section 0.
</prevsent>
<prevsent>ling constituent.the experiments reported here relyon training corpus annotated with non-local dependencies as well as phrase-structure information.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
we usedthe wall street journal (wsj) part of the penn treebank (marcus et al, 1993), <papid> J93-2004 </papid>where extraction is represented by co-indexing an empty terminal element(henceforth ee) to its antecedent.</citsent>
<aftsection>
<nextsent>without committing ourselves to any syntactic theory, we adopt this representation.
</nextsent>
<nextsent>following the annotation guidelines (bies et al., 1995), we distinguish seven basic types of ees: controlled np-traces (np), pros (pro), traces of   -movement (mostly wh-movement: wh), empty complementizers (comp), empty units (unit), and traces representing pseudo-attachments (shared constituents, discontinuous dependencies,etc.: pseudo) and ellipsis (ellipsis ).
</nextsent>
<nextsent>these labels, however, do not identify the ees uniquely: for instance, the label wh may represent an extracted np object as well as an adverb moved out of theverb phrase.
</nextsent>
<nextsent>in order to facilitate antecedent recovery and to disambiguate the ees, we also annotate them with their parent nodes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5250">
<title id=" P03-1055.xml">deep syntactic processing by combining shallow methods </title>
<section> parsing with empty elements.  </section>
<citcontext>
<prevsection>
<prevsent>knowing this node is not enough, though.
</prevsent>
<prevsent>since the penn treebank grammar is not binary-branching, the final task is to decide which child of this node is the actual antecedent.the first two modifications are not difficult conceptually.
</prevsent>
</prevsection>
<citsent citstr=" W03-1005 ">
a bottom-up parser can be easily modified to insert empty elements (c.f. dienes and dubey (2003)).<papid> W03-1005 </papid></citsent>
<aftsection>
<nextsent>likewise, the changes required to include gap+ categories are not complicated: we simply add the gap+ features to the nonterminal category labels.
</nextsent>
<nextsent>the final and perhaps most important concern with developing gap-threading parser is to ensure it is possible to choose the correct child as the antecedent of an ee.
</nextsent>
<nextsent>to achieve this task, we employ the algorithm presented in figure 2.
</nextsent>
<nextsent>at any node in the tree where the children, all together,have more gap+ features activated than the parent, the algorithm deduces that gap+ must havean antecedent.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5256">
<title id=" P03-1055.xml">deep syntactic processing by combining shallow methods </title>
<section> detecting empty elements.  </section>
<citcontext>
<prevsection>
<prevsent>rb* to rb* vb to-infinitive [,:] rb* vbg gerund comps bar (v  ,) !that* (md  v) look ahead for that whnp !in    wp wdt compwhnp    !whnp* look back for pending whnps whadvp wrb !whadvp* !whadvp* [.,:] look back for pending whadvp before verb unit $ cd* $ sign before numbers table 4: non-local binary feature templates; the ee-site is indicated by although this approach is closely related to pos tagging, there are certain differences which make this task more difficult.
</prevsent>
<prevsent>despite the smaller tagset, the data exhibits extreme sparseness: even though more than 50% of the sentences in the penn tree bank contain some ees, the actual number of ees is very small.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
in section 0 of the wsj corpus, out of the 46451 tokens only 3056 are preceded by one or more ees, that is, approximately 93.5% of the words are tagged with the ee=* tag.the other main difference is the apparently non local nature of the problem, which motivates our choice of maximum entropy (me) model for the tagging task (berger et al, 1996).<papid> J96-1002 </papid></citsent>
<aftsection>
<nextsent>me allows the flexible combination of different sources of information, i.e., local and long-distance cues characterizing possible sites for ees.
</nextsent>
<nextsent>in the me framework, linguistic cues are represented by (binary-valued) features ( fi), the relative importance (weight, i) of which is determined by an iterative training algorithm.
</nextsent>
<nextsent>the weighted linear combination of the features amount to the log-probability of the label (l) given the context (c):  c  1  exp  i fi  c  (1) where  is context-dependent normalizing factor to ensure that  c be proper probability distribution.
</nextsent>
<nextsent>we determine weights for the features with modified version of the generative iterative scaling algorithm (curran and clark, 2003).<papid> E03-1071 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5257">
<title id=" P03-1055.xml">deep syntactic processing by combining shallow methods </title>
<section> detecting empty elements.  </section>
<citcontext>
<prevsection>
<prevsent>in the me framework, linguistic cues are represented by (binary-valued) features ( fi), the relative importance (weight, i) of which is determined by an iterative training algorithm.
</prevsent>
<prevsent>the weighted linear combination of the features amount to the log-probability of the label (l) given the context (c):  c  1  exp  i fi  c  (1) where  is context-dependent normalizing factor to ensure that  c be proper probability distribution.
</prevsent>
</prevsection>
<citsent citstr=" E03-1071 ">
we determine weights for the features with modified version of the generative iterative scaling algorithm (curran and clark, 2003).<papid> E03-1071 </papid></citsent>
<aftsection>
<nextsent>templates for local features are similar to the ones employed by ratnaparkhi (1996) <papid> W96-0213 </papid>for pos-tagging(table 3), though as our input already includes pos tags, we can make use of part-of-speech information as well.</nextsent>
<nextsent>long-distance features are simple hand written regular expressions matching possible sites for ees (table 4).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5258">
<title id=" P03-1055.xml">deep syntactic processing by combining shallow methods </title>
<section> detecting empty elements.  </section>
<citcontext>
<prevsection>
<prevsent>the weighted linear combination of the features amount to the log-probability of the label (l) given the context (c):  c  1  exp  i fi  c  (1) where  is context-dependent normalizing factor to ensure that  c be proper probability distribution.
</prevsent>
<prevsent>we determine weights for the features with modified version of the generative iterative scaling algorithm (curran and clark, 2003).<papid> E03-1071 </papid></prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
templates for local features are similar to the ones employed by ratnaparkhi (1996) <papid> W96-0213 </papid>for pos-tagging(table 3), though as our input already includes pos tags, we can make use of part-of-speech information as well.</citsent>
<aftsection>
<nextsent>long-distance features are simple hand written regular expressions matching possible sites for ees (table 4).
</nextsent>
<nextsent>features and labels occurring less than 10 times in the training corpus are ignored.
</nextsent>
<nextsent>since our main aim is to show that finding empty elements can be done fairly accurately without using parser, the input to the tagger is pos-tagged corpus, containing no syntactic information.
</nextsent>
<nextsent>the best label-sequence is approximated by bigram viterbi-search algorithm, augmented with variable width beam-search.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5266">
<title id=" P03-1055.xml">deep syntactic processing by combining shallow methods </title>
<section> combining the models.  </section>
<citcontext>
<prevsection>
<prevsent>most of the tags emitted by the eetagger are just ee=*, which would defeat generative models by making the hidden?
</prevsent>
<prevsent>state uninformative.
</prevsent>
</prevsection>
<citsent citstr=" P01-1042 ">
conditional parsing algorithms do exist, butthey are difficult to train using large corpora (johnson, 2001).<papid> P01-1042 </papid></citsent>
<aftsection>
<nextsent>however, we show that it is quite effective if the parser simply treats the output of the tagger as certainty.
</nextsent>
<nextsent>given this combination method, there still are two interesting variations: we may use only the ees proposed by the tagger (henceforth the no insert model), or we may allow the parser to insert even more ees (henceforth the insert model).
</nextsent>
<nextsent>in both cases, ees out putted by the tagger are treated as separate words, as in the perfect model of section 3.
</nextsent>
<nextsent>5.2 results.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5275">
<title id=" P03-1055.xml">deep syntactic processing by combining shallow methods </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>while the insert model here did have wider coverage than the parser in section 3, it seems the real benefit of using the combined approach is to let the simple model reduce the search space of the more complicated parsing model.
</prevsent>
<prevsent>this search space reduction works because the shallow finite state method takes information about adjacent words into account, whereas the context-free parser does not, since phrase boundary might separate them.
</prevsent>
</prevsection>
<citsent citstr=" P02-1042 ">
excluding johnson (2002)<papid> P02-1018 </papid>s pattern-matching algorithm, most recent work on finding head dependencies with statistical parser has used statistical versions of deep grammar formalisms, such as ccg (clark et al, 2002) <papid> P02-1042 </papid>or lfg (riezler et al, 2002).<papid> P02-1035 </papid></citsent>
<aftsection>
<nextsent>while these systems should, in theory, be able to handle discontinuities accurately, there has not yet been study on how these systems handle such phenomena overall.
</nextsent>
<nextsent>the tagger presented here is not the first one proposed to recover syntactic information deeper than part-of-speech tags.
</nextsent>
<nextsent>for example, super tag ging (joshi and bangalore, 1994) also aims to do more meaningful syntactic pre-processing.
</nextsent>
<nextsent>unlikesupertagging, our approach only focuses on detecting ees.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5276">
<title id=" P03-1055.xml">deep syntactic processing by combining shallow methods </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>while the insert model here did have wider coverage than the parser in section 3, it seems the real benefit of using the combined approach is to let the simple model reduce the search space of the more complicated parsing model.
</prevsent>
<prevsent>this search space reduction works because the shallow finite state method takes information about adjacent words into account, whereas the context-free parser does not, since phrase boundary might separate them.
</prevsent>
</prevsection>
<citsent citstr=" P02-1035 ">
excluding johnson (2002)<papid> P02-1018 </papid>s pattern-matching algorithm, most recent work on finding head dependencies with statistical parser has used statistical versions of deep grammar formalisms, such as ccg (clark et al, 2002) <papid> P02-1042 </papid>or lfg (riezler et al, 2002).<papid> P02-1035 </papid></citsent>
<aftsection>
<nextsent>while these systems should, in theory, be able to handle discontinuities accurately, there has not yet been study on how these systems handle such phenomena overall.
</nextsent>
<nextsent>the tagger presented here is not the first one proposed to recover syntactic information deeper than part-of-speech tags.
</nextsent>
<nextsent>for example, super tag ging (joshi and bangalore, 1994) also aims to do more meaningful syntactic pre-processing.
</nextsent>
<nextsent>unlikesupertagging, our approach only focuses on detecting ees.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5278">
<title id=" P03-2037.xml">automatic detection of grammar elements that decrease readability </title>
<section> 97 </section>
<citcontext>
<prevsection>
<prevsent>}) ) ); 3.2 the architecture of the detector.
</prevsent>
<prevsent>the architecture of the detector is shown in figure 1.
</prevsent>
</prevsection>
<citsent citstr=" J94-4001 ">
the detector uses morphological analyzer, juman,and syntactic analyzer, knp (kurohashi and na gao, 1994).<papid> J94-4001 </papid></citsent>
<aftsection>
<nextsent>the rule set is converted into the format that knp can read and it is added to the standard ruleset of knp.
</nextsent>
<nextsent>this addition enables knp to detect candidates of grammar elements.
</nextsent>
<nextsent>the detection?
</nextsent>
<nextsent>part selects final results from these candidates based on preference information given by the rule set.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5279">
<title id=" P00-1069.xml">word sense disambiguation by learning from unlabeled data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the objective of word sense disambiguation (wsd) is to identify the correct sense of word in context.
</prevsent>
<prevsent>it is one of the most critical tasks in most natural language applications, including information retrieval, information extraction, and machine translation.
</prevsent>
</prevsection>
<citsent citstr=" P98-2228 ">
the availability of large-scale corpus and various machine learning algorithms enabled corpus based approach to wsd (cho and kim, 1995; hwee and lee, 1996; wilks and stevenson, 1998),<papid> P98-2228 </papid>but large scale sense-tagged corpus or aligned bilingual corpus is needed for corpus-based approach.</citsent>
<aftsection>
<nextsent>however, most languages except english do not have large-scale sense-tagged corpus.
</nextsent>
<nextsent>therefore, any corpus-based approach to wsd for such languages should consider the following problems: there no reliable and available sense tagged corpus.
</nextsent>
<nextsent> most words are sense ambiguous.
</nextsent>
<nextsent> annotating the large corpora require shuman experts, so that it is too expen sive.because it is expensive to construct sense tagged corpus or bilingual corpus, many researchers tried to reduce the number of examples needed to learn wsd (atsushi et al, 1998; pedersen and bruce, 1997).<papid> W97-0322 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5280">
<title id=" P00-1069.xml">word sense disambiguation by learning from unlabeled data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>therefore, any corpus-based approach to wsd for such languages should consider the following problems: there no reliable and available sense tagged corpus.
</prevsent>
<prevsent> most words are sense ambiguous.
</prevsent>
</prevsection>
<citsent citstr=" W97-0322 ">
annotating the large corpora require shuman experts, so that it is too expen sive.because it is expensive to construct sense tagged corpus or bilingual corpus, many researchers tried to reduce the number of examples needed to learn wsd (atsushi et al, 1998; pedersen and bruce, 1997).<papid> W97-0322 </papid></citsent>
<aftsection>
<nextsent>atsushi etal.
</nextsent>
<nextsent>(atsushi et al, 1998) adopted selective sampling method to use small number of examples in training.
</nextsent>
<nextsent>they de ned training utility function to select examples with minimum certainty, and at each training iteration the examples with less certainty were saved in the example database.
</nextsent>
<nextsent>however, at each iteration of training the similarity among word property vectors must be calculated due to their k-nn like implementation of training utility.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5281">
<title id=" P00-1069.xml">word sense disambiguation by learning from unlabeled data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, at each iteration of training the similarity among word property vectors must be calculated due to their k-nn like implementation of training utility.
</prevsent>
<prevsent>while labeled examples obtained from asense-tagged corpus is expensive and time consuming, it is signi cantly easier to obtain the unlabeled examples.
</prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
yarowsky (yarowsky, 1995)<papid> P95-1026 </papid>presented, for the rst time, the possibility that unlabeled examples canbe used for wsd.</citsent>
<aftsection>
<nextsent>he used learning algorithm based on the local context under the assumption that all instances of word have the same intended meaning within any xed document and achieved good results with only few labeled examples and many unlabeled ones.
</nextsent>
<nextsent>nigam et al (nigam et al, 2000) also showed the unlabeled examples can enhance the accuracy of text categorization.
</nextsent>
<nextsent>attribute substance gfunc the grammatical function of parent the word of the node modi ed by subject whether or not parent of has subject object whether or not parent of has an object nmodword the word of the noun modi er of adnword the head word of the adnominal phrase of adnsubj whether or not the adnominal phrase of has subject adnobj whether or not the adnominal phrase of has an object table 1: the properties used to distinguish the sense of an ambiguous korean noun w. in this paper, we present new approach to word sense disambiguation that is basedon selective sampling algorithm with committees.
</nextsent>
<nextsent>in this approach, the number of training examples is reduced, by determining by weighted majority voting of multiple classi ers, whether given training example should be learned or not.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5287">
<title id=" P01-1020.xml">a machine learning approach to the automatic evaluation of machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it focuses on evaluating the wellformedness of output and does not address issues of evaluating content transfer.
</prevsent>
<prevsent>researchers are now applying automated evaluation in mt and natural language generation tasks, both as system-internal goodness metrics and for the assessment of output.
</prevsent>
</prevsection>
<citsent citstr=" P98-1116 ">
langkilde and knight (1998), <papid> P98-1116 </papid>for example, employ n-gram metrics to select among candidate outputs in natural language generation, while ringger et al (2001) use gram perplexity to compare the output of mt systems.</citsent>
<aftsection>
<nextsent>su et al (1992), <papid> C92-2067 </papid>alshawi et al (1998) <papid> P98-1006 </papid>and bangalore et al (2000) <papid> W00-1401 </papid>employ string edit distance between reference and output sentences to gauge output quality for mt and generation.</nextsent>
<nextsent>to be useful to researchers, however, assessment must provide linguistic information that can guide in identifying areas where work is required.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5288">
<title id=" P01-1020.xml">a machine learning approach to the automatic evaluation of machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>researchers are now applying automated evaluation in mt and natural language generation tasks, both as system-internal goodness metrics and for the assessment of output.
</prevsent>
<prevsent>langkilde and knight (1998), <papid> P98-1116 </papid>for example, employ n-gram metrics to select among candidate outputs in natural language generation, while ringger et al (2001) use gram perplexity to compare the output of mt systems.</prevsent>
</prevsection>
<citsent citstr=" C92-2067 ">
su et al (1992), <papid> C92-2067 </papid>alshawi et al (1998) <papid> P98-1006 </papid>and bangalore et al (2000) <papid> W00-1401 </papid>employ string edit distance between reference and output sentences to gauge output quality for mt and generation.</citsent>
<aftsection>
<nextsent>to be useful to researchers, however, assessment must provide linguistic information that can guide in identifying areas where work is required.
</nextsent>
<nextsent>(see nyberg et al, 1994 <papid> C94-1013 </papid>for useful discussion of this issue.)</nextsent>
<nextsent>the better the mt system, the more its output will resemble human-generated text.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5289">
<title id=" P01-1020.xml">a machine learning approach to the automatic evaluation of machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>researchers are now applying automated evaluation in mt and natural language generation tasks, both as system-internal goodness metrics and for the assessment of output.
</prevsent>
<prevsent>langkilde and knight (1998), <papid> P98-1116 </papid>for example, employ n-gram metrics to select among candidate outputs in natural language generation, while ringger et al (2001) use gram perplexity to compare the output of mt systems.</prevsent>
</prevsection>
<citsent citstr=" P98-1006 ">
su et al (1992), <papid> C92-2067 </papid>alshawi et al (1998) <papid> P98-1006 </papid>and bangalore et al (2000) <papid> W00-1401 </papid>employ string edit distance between reference and output sentences to gauge output quality for mt and generation.</citsent>
<aftsection>
<nextsent>to be useful to researchers, however, assessment must provide linguistic information that can guide in identifying areas where work is required.
</nextsent>
<nextsent>(see nyberg et al, 1994 <papid> C94-1013 </papid>for useful discussion of this issue.)</nextsent>
<nextsent>the better the mt system, the more its output will resemble human-generated text.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5290">
<title id=" P01-1020.xml">a machine learning approach to the automatic evaluation of machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>researchers are now applying automated evaluation in mt and natural language generation tasks, both as system-internal goodness metrics and for the assessment of output.
</prevsent>
<prevsent>langkilde and knight (1998), <papid> P98-1116 </papid>for example, employ n-gram metrics to select among candidate outputs in natural language generation, while ringger et al (2001) use gram perplexity to compare the output of mt systems.</prevsent>
</prevsection>
<citsent citstr=" W00-1401 ">
su et al (1992), <papid> C92-2067 </papid>alshawi et al (1998) <papid> P98-1006 </papid>and bangalore et al (2000) <papid> W00-1401 </papid>employ string edit distance between reference and output sentences to gauge output quality for mt and generation.</citsent>
<aftsection>
<nextsent>to be useful to researchers, however, assessment must provide linguistic information that can guide in identifying areas where work is required.
</nextsent>
<nextsent>(see nyberg et al, 1994 <papid> C94-1013 </papid>for useful discussion of this issue.)</nextsent>
<nextsent>the better the mt system, the more its output will resemble human-generated text.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5291">
<title id=" P01-1020.xml">a machine learning approach to the automatic evaluation of machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>su et al (1992), <papid> C92-2067 </papid>alshawi et al (1998) <papid> P98-1006 </papid>and bangalore et al (2000) <papid> W00-1401 </papid>employ string edit distance between reference and output sentences to gauge output quality for mt and generation.</prevsent>
<prevsent>to be useful to researchers, however, assessment must provide linguistic information that can guide in identifying areas where work is required.</prevsent>
</prevsection>
<citsent citstr=" C94-1013 ">
(see nyberg et al, 1994 <papid> C94-1013 </papid>for useful discussion of this issue.)</citsent>
<aftsection>
<nextsent>the better the mt system, the more its output will resemble human-generated text.
</nextsent>
<nextsent>indeed, mt might be considered solved problem should it ever become impossible to distinguish automated output from human translation.
</nextsent>
<nextsent>we have observed that in general humans can easily and reliably categorize sentence as either machine- or human-generated.
</nextsent>
<nextsent>moreover, they can usually justify their decision.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5292">
<title id=" P04-1015.xml">incremental parsing with the perceptron algorithm </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>this paper describes an incremental parsing approach where parameters are estimated using variant of the perceptron algorithm.
</prevsent>
<prevsent>a beam-search algorithm is used during both training and decoding phases of the method.
</prevsent>
</prevsection>
<citsent citstr=" J01-2004 ">
the perceptron approach was implemented with the same feature set as that of an existing generative model (roark, 2001<papid> J01-2004 </papid>a), and experimental results show that it gives competitive performance to the generative modelon parsing the penn treebank.</citsent>
<aftsection>
<nextsent>we demonstrate that training perceptron model to combine with the generative model during search provides 2.1 percent f-measure improvement over the generative model alone, to 88.8 percent.
</nextsent>
<nextsent>in statistical approaches to nlp problems such as tagging or parsing, it seems clear that the representation used as input to learning algorithm is central to the accuracy of an approach.
</nextsent>
<nextsent>in an ideal world, the designer of parser or tagger would be free to choose any features which might be useful in discriminating good from bad structures, without concerns about how the features interact with the problems of training (parameter estima tion) or decoding (search for the most plausible candidate under the model).
</nextsent>
<nextsent>to this end, number of recently proposed methods allow model to incorporate arbitrary global features of candidate analyses or parses.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5294">
<title id=" P04-1015.xml">incremental parsing with the perceptron algorithm </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in an ideal world, the designer of parser or tagger would be free to choose any features which might be useful in discriminating good from bad structures, without concerns about how the features interact with the problems of training (parameter estima tion) or decoding (search for the most plausible candidate under the model).
</prevsent>
<prevsent>to this end, number of recently proposed methods allow model to incorporate arbitrary global features of candidate analyses or parses.
</prevsent>
</prevsection>
<citsent citstr=" J97-4005 ">
examples of such techniques are markov random fields (rat naparkhi et al, 1994; abney, 1997; <papid> J97-4005 </papid>della pietra et al, 1997; johnson et al, 1999), <papid> P99-1069 </papid>and boosting or perceptron approaches to reranking (freund et al, 1998; collins, 2000; collins and duffy, 2002).<papid> P02-1034 </papid></citsent>
<aftsection>
<nextsent>a drawback of these approaches is that in the general case, they can require exhaustive enumeration of the setof candidates for each input sentence in both the training and decoding phases1.
</nextsent>
<nextsent>for example, johnson et al (1999) <papid> P99-1069 </papid>and riezler et al (2002) <papid> P02-1035 </papid>use all parses generated by an lfg parser as input to an mrf approach ? given the level of ambiguity in natural language, this set can presumably become extremely large.</nextsent>
<nextsent>collins (2000) and collins and duffy (2002) <papid> P02-1034 </papid>rerank the top parses from an existing generative parser, but this kind of approach1dynamic programming methods (geman and johnson, 2002; <papid> P02-1036 </papid>lafferty et al, 2001) can sometimes be used for both training and decoding, but this requires fairly strong restrictions on the features in the model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5295">
<title id=" P04-1015.xml">incremental parsing with the perceptron algorithm </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in an ideal world, the designer of parser or tagger would be free to choose any features which might be useful in discriminating good from bad structures, without concerns about how the features interact with the problems of training (parameter estima tion) or decoding (search for the most plausible candidate under the model).
</prevsent>
<prevsent>to this end, number of recently proposed methods allow model to incorporate arbitrary global features of candidate analyses or parses.
</prevsent>
</prevsection>
<citsent citstr=" P99-1069 ">
examples of such techniques are markov random fields (rat naparkhi et al, 1994; abney, 1997; <papid> J97-4005 </papid>della pietra et al, 1997; johnson et al, 1999), <papid> P99-1069 </papid>and boosting or perceptron approaches to reranking (freund et al, 1998; collins, 2000; collins and duffy, 2002).<papid> P02-1034 </papid></citsent>
<aftsection>
<nextsent>a drawback of these approaches is that in the general case, they can require exhaustive enumeration of the setof candidates for each input sentence in both the training and decoding phases1.
</nextsent>
<nextsent>for example, johnson et al (1999) <papid> P99-1069 </papid>and riezler et al (2002) <papid> P02-1035 </papid>use all parses generated by an lfg parser as input to an mrf approach ? given the level of ambiguity in natural language, this set can presumably become extremely large.</nextsent>
<nextsent>collins (2000) and collins and duffy (2002) <papid> P02-1034 </papid>rerank the top parses from an existing generative parser, but this kind of approach1dynamic programming methods (geman and johnson, 2002; <papid> P02-1036 </papid>lafferty et al, 2001) can sometimes be used for both training and decoding, but this requires fairly strong restrictions on the features in the model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5296">
<title id=" P04-1015.xml">incremental parsing with the perceptron algorithm </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in an ideal world, the designer of parser or tagger would be free to choose any features which might be useful in discriminating good from bad structures, without concerns about how the features interact with the problems of training (parameter estima tion) or decoding (search for the most plausible candidate under the model).
</prevsent>
<prevsent>to this end, number of recently proposed methods allow model to incorporate arbitrary global features of candidate analyses or parses.
</prevsent>
</prevsection>
<citsent citstr=" P02-1034 ">
examples of such techniques are markov random fields (rat naparkhi et al, 1994; abney, 1997; <papid> J97-4005 </papid>della pietra et al, 1997; johnson et al, 1999), <papid> P99-1069 </papid>and boosting or perceptron approaches to reranking (freund et al, 1998; collins, 2000; collins and duffy, 2002).<papid> P02-1034 </papid></citsent>
<aftsection>
<nextsent>a drawback of these approaches is that in the general case, they can require exhaustive enumeration of the setof candidates for each input sentence in both the training and decoding phases1.
</nextsent>
<nextsent>for example, johnson et al (1999) <papid> P99-1069 </papid>and riezler et al (2002) <papid> P02-1035 </papid>use all parses generated by an lfg parser as input to an mrf approach ? given the level of ambiguity in natural language, this set can presumably become extremely large.</nextsent>
<nextsent>collins (2000) and collins and duffy (2002) <papid> P02-1034 </papid>rerank the top parses from an existing generative parser, but this kind of approach1dynamic programming methods (geman and johnson, 2002; <papid> P02-1036 </papid>lafferty et al, 2001) can sometimes be used for both training and decoding, but this requires fairly strong restrictions on the features in the model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5298">
<title id=" P04-1015.xml">incremental parsing with the perceptron algorithm </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>examples of such techniques are markov random fields (rat naparkhi et al, 1994; abney, 1997; <papid> J97-4005 </papid>della pietra et al, 1997; johnson et al, 1999), <papid> P99-1069 </papid>and boosting or perceptron approaches to reranking (freund et al, 1998; collins, 2000; collins and duffy, 2002).<papid> P02-1034 </papid></prevsent>
<prevsent>a drawback of these approaches is that in the general case, they can require exhaustive enumeration of the setof candidates for each input sentence in both the training and decoding phases1.</prevsent>
</prevsection>
<citsent citstr=" P02-1035 ">
for example, johnson et al (1999) <papid> P99-1069 </papid>and riezler et al (2002) <papid> P02-1035 </papid>use all parses generated by an lfg parser as input to an mrf approach ? given the level of ambiguity in natural language, this set can presumably become extremely large.</citsent>
<aftsection>
<nextsent>collins (2000) and collins and duffy (2002) <papid> P02-1034 </papid>rerank the top parses from an existing generative parser, but this kind of approach1dynamic programming methods (geman and johnson, 2002; <papid> P02-1036 </papid>lafferty et al, 2001) can sometimes be used for both training and decoding, but this requires fairly strong restrictions on the features in the model.</nextsent>
<nextsent>presupposes that there is an existing baseline model with reasonable performance.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5300">
<title id=" P04-1015.xml">incremental parsing with the perceptron algorithm </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a drawback of these approaches is that in the general case, they can require exhaustive enumeration of the setof candidates for each input sentence in both the training and decoding phases1.
</prevsent>
<prevsent>for example, johnson et al (1999) <papid> P99-1069 </papid>and riezler et al (2002) <papid> P02-1035 </papid>use all parses generated by an lfg parser as input to an mrf approach ? given the level of ambiguity in natural language, this set can presumably become extremely large.</prevsent>
</prevsection>
<citsent citstr=" P02-1036 ">
collins (2000) and collins and duffy (2002) <papid> P02-1034 </papid>rerank the top parses from an existing generative parser, but this kind of approach1dynamic programming methods (geman and johnson, 2002; <papid> P02-1036 </papid>lafferty et al, 2001) can sometimes be used for both training and decoding, but this requires fairly strong restrictions on the features in the model.</citsent>
<aftsection>
<nextsent>presupposes that there is an existing baseline model with reasonable performance.
</nextsent>
<nextsent>many of these baseline models are themselves used with heuristic search techniques, so that the potential gain through the use of discriminative re-ranking techniques is further dependent on effective search.this paper explores an alternative approach to parsing, based on the perceptron training algorithm introduced in collins (2002).<papid> W02-1001 </papid></nextsent>
<nextsent>in this approach the training and decoding problems are very closely related ? the training method decodes training examples in sequence, and makes simple corrective updates to the parameters when errors are made.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5301">
<title id=" P04-1015.xml">incremental parsing with the perceptron algorithm </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>collins (2000) and collins and duffy (2002) <papid> P02-1034 </papid>rerank the top parses from an existing generative parser, but this kind of approach1dynamic programming methods (geman and johnson, 2002; <papid> P02-1036 </papid>lafferty et al, 2001) can sometimes be used for both training and decoding, but this requires fairly strong restrictions on the features in the model.</prevsent>
<prevsent>presupposes that there is an existing baseline model with reasonable performance.</prevsent>
</prevsection>
<citsent citstr=" W02-1001 ">
many of these baseline models are themselves used with heuristic search techniques, so that the potential gain through the use of discriminative re-ranking techniques is further dependent on effective search.this paper explores an alternative approach to parsing, based on the perceptron training algorithm introduced in collins (2002).<papid> W02-1001 </papid></citsent>
<aftsection>
<nextsent>in this approach the training and decoding problems are very closely related ? the training method decodes training examples in sequence, and makes simple corrective updates to the parameters when errors are made.
</nextsent>
<nextsent>thus the main complexity of the method is isolated to the decoding problem.
</nextsent>
<nextsent>we describe an approach that uses an incremental, left-to-right parser,with beam search, to find the highest scoring analysis under the model.
</nextsent>
<nextsent>the same search method is used in both training and decoding.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5331">
<title id=" P04-1015.xml">incremental parsing with the perceptron algorithm </title>
<section> the general framework.  </section>
<citcontext>
<prevsection>
<prevsent>we use two techniques to reduce the number of left-childchains: first, we remove some (but not all) of the recur sion from the grammar through tree transform; next, we limit the left-child chains consisting of more than two non-terminal categories to those actually observed in the training data more than once.
</prevsent>
<prevsent>left-child chains of length less than or equal to two are all those observed in training data.
</prevsent>
</prevsection>
<citsent citstr=" C00-1052 ">
as practical matter, the set of left child chains for terminal is taken to be the union ofthe sets of left-child chains for all pre-terminal part-of speech (pos) tags for x. before inducing the left-child chains and allowable triples from the treebank, the trees are transformed with selective left-corner transformation (johnson and roark, 2000) <papid> C00-1052 </papid>that has been flattened as presented in roark (2001<papid> J01-2004 </papid>b).</citsent>
<aftsection>
<nextsent>this transform is only applied to left-recursive productions, i.e. productions of the form ? a?.
</nextsent>
<nextsent>the transformed trees look as in figure 3.
</nextsent>
<nextsent>the transform has the benefit of dramatically reducing the number ofleft-child chains, without unduly disrupting the immediate dominance relationships that provide features for the model.
</nextsent>
<nextsent>the parse trees that are returned by the parser are then de-transformed to the original form of the grammar for evaluation2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5336">
<title id=" P04-1015.xml">incremental parsing with the perceptron algorithm </title>
<section> the general framework.  </section>
<citcontext>
<prevsection>
<prevsent>the parse trees that are returned by the parser are then de-transformed to the original form of the grammar for evaluation2.
</prevsent>
<prevsent>table 1 presents the number of left-child chains of length greater than 2 in sections 2-21 and 24 of the penn wall st. journal treebank, both with and without the flattened selective left-corner transformation (fslc), forgold-standard part-of-speech (pos) tags and automatically tagged pos tags.
</prevsent>
</prevsection>
<citsent citstr=" J98-4004 ">
when the fslc has been applied and the set is restricted to those occurring more than once2see johnson (1998) <papid> J98-4004 </papid>for presentation of the transform/de transform paradigm in parsing.</citsent>
<aftsection>
<nextsent>(a) np  np  np  nnp jim bb pos hhh nn dog pppp pp , in with . . .
</nextsent>
<nextsent>l np (b) np  nnp jim pos xxxxx np/np  nn dog hhh np/np pp  in with . . .
</nextsent>
<nextsent>l np (c) np nnp jim !!!
</nextsent>
<nextsent>pos l np/np nn dog `````` np/np pp , in with . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5344">
<title id=" P02-1002.xml">sequential conditional generalized iterative scaling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>rather than attempting to train all model parameters simultaneously, the algorithm trains them sequentially.
</prevsent>
<prevsent>the algorithm is easy to implement, typically uses only slightly more memory, and will lead to improvements for most maximum entropy problems.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
conditional maximum entropy models have been used for variety of natural language tasks, including language modeling (rosenfeld, 1994), part of-speech tagging, prepositional phrase attachment, and parsing (ratnaparkhi, 1998), word selection for machine translation (berger et al, 1996), <papid> J96-1002 </papid>and finding sentence boundaries (reynar and ratnaparkhi, 1997).<papid> A97-1004 </papid></citsent>
<aftsection>
<nextsent>unfortunately, although maximum entropy (maxent) models can be applied very generally, the typical training algorithm for maxent, generalized iterative scaling (gis) (darroch and rat cliff, 1972), can be extremely slow.
</nextsent>
<nextsent>we have personally used up to month of computer time to train single model.there have been several attempts to speed up maxent training (della pietra et al, 1997; wu and khudanpur, 2000; goodman, 2001).
</nextsent>
<nextsent>however, as we describe later, each of these has suffered from applicability to limited number of applications.
</nextsent>
<nextsent>darrochand rat cliff (1972) describe gis for joint probabilities, and mention fast variation, which appears tohave been missed by the conditional maxent community.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5345">
<title id=" P02-1002.xml">sequential conditional generalized iterative scaling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>rather than attempting to train all model parameters simultaneously, the algorithm trains them sequentially.
</prevsent>
<prevsent>the algorithm is easy to implement, typically uses only slightly more memory, and will lead to improvements for most maximum entropy problems.
</prevsent>
</prevsection>
<citsent citstr=" A97-1004 ">
conditional maximum entropy models have been used for variety of natural language tasks, including language modeling (rosenfeld, 1994), part of-speech tagging, prepositional phrase attachment, and parsing (ratnaparkhi, 1998), word selection for machine translation (berger et al, 1996), <papid> J96-1002 </papid>and finding sentence boundaries (reynar and ratnaparkhi, 1997).<papid> A97-1004 </papid></citsent>
<aftsection>
<nextsent>unfortunately, although maximum entropy (maxent) models can be applied very generally, the typical training algorithm for maxent, generalized iterative scaling (gis) (darroch and rat cliff, 1972), can be extremely slow.
</nextsent>
<nextsent>we have personally used up to month of computer time to train single model.there have been several attempts to speed up maxent training (della pietra et al, 1997; wu and khudanpur, 2000; goodman, 2001).
</nextsent>
<nextsent>however, as we describe later, each of these has suffered from applicability to limited number of applications.
</nextsent>
<nextsent>darrochand rat cliff (1972) describe gis for joint probabilities, and mention fast variation, which appears tohave been missed by the conditional maxent community.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5347">
<title id=" P02-1002.xml">sequential conditional generalized iterative scaling </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>the objective function for both scgis andgis when smoothing is equation 3: the probability of the training data times the probability of the model.
</prevsent>
<prevsent>the most interesting measure, the percent correct on test data, tends to be noisy.
</prevsent>
</prevsection>
<citsent citstr=" H01-1052 ">
for test corpus, we chose to use exactly the same training, test, problems, and feature sets used by banko and brill (2001).<papid> H01-1052 </papid></citsent>
<aftsection>
<nextsent>these problems consisted of trying to guess which of two conf usable words, e.g. their?
</nextsent>
<nextsent>or there?, user intended.
</nextsent>
<nextsent>banko and brill chose this data to be representative of typical machine learning problems, and, by trying it across data sizes and different pairs of words, it exhibits good deal of different behaviors.
</nextsent>
<nextsent>banko and brill used standard set of features, including words within window of 2, part-of-speech tags within window of 2, pairs of word or tag features, and whether or nota given word occurred within window of 9.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5348">
<title id=" P02-1048.xml">match an architecture for multimodal dialogue systems </title>
<section> multimodal application architecture.  </section>
<citcontext>
<prevsection>
<prevsent>number and type indicate the number of entities in selection (1,2,3, many) and their type (rest(aurant), the atre).
</prevsent>
<prevsent>semis place holder for the specific content of the gesture, such as the points that make up an area or the identifiers of objects in selection.
</prevsent>
</prevsection>
<citsent citstr=" C00-1053 ">
when multiple selection gestures are present an aggregation technique (johnston and bangalore, 2001) is employed to overcome the problems withdeictic plurals and numerals described in johnston (2000).<papid> C00-1053 </papid></citsent>
<aftsection>
<nextsent>aggregation augments the ink meaning lattice with aggregate gestures that result from combining adjacent selection gestures.
</nextsent>
<nextsent>this allows deictic expression like these three restaurants to combine with two area gestures, one which selects one restaurant and the other two, as long as their sum isthree.
</nextsent>
<nextsent>for example, if the user makes two area gestures, one around single restaurant and the other around two restaurants (figure 3), the resulting ink meaning lattice will be as in figure 8.
</nextsent>
<nextsent>the first gesture (node numbers 0-7) is either reference to location (loc.)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5349">
<title id=" P02-1048.xml">match an architecture for multimodal dialogue systems </title>
<section> multimodal application architecture.  </section>
<citcontext>
<prevsection>
<prevsent>and treats the speech as unimodal.
</prevsent>
<prevsent>when an ink meaning lattice arrives, if the user has tapped click-to-speakmmfst waits for the speech lattice to arrive, otherwise it applies short timeout (1 sec.)
</prevsent>
</prevsection>
<citsent citstr=" C00-1054 ">
and treats the ink as unimodal.mmfst uses the finite-state approach to multimodal integration and understanding proposed by johnston and bangalore (2000).<papid> C00-1054 </papid></citsent>
<aftsection>
<nextsent>possibilities for multimodal integration and understanding are captured in three tape device in which the first tape represents the speech stream (words), the second theink stream (gesture symbols) and the third their combined meaning (meaning symbols).
</nextsent>
<nextsent>in essence, this device takes the speech and ink meaning lattices as inputs, consumes them using the first two tapes, and writes out multimodal meaning lattice using the third tape.
</nextsent>
<nextsent>the three tape finite-state device is simulated using two transducers: g:w which is used toalign speech and ink and w:m which takes composite alphabet of speech and gesture symbols as in put and outputs meaning.
</nextsent>
<nextsent>the ink meaning lattice and speech lattice are composed with g:w andthe result is factored into an fsa w which is composed with w:m to derive the meaning lattice m. in order to capture multimodal integration using finite-state methods, it is necessary to abstract over specific aspects of gestural content (johnston and bangalore, 2000).<papid> C00-1054 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5351">
<title id=" P02-1048.xml">match an architecture for multimodal dialogue systems </title>
<section> multimodal application architecture.  </section>
<citcontext>
<prevsection>
<prevsent>this is passed to the multimodal dialog manager (mdm) and from there to the multimodal ui resulting in display like figure 4 with coordinated tts output.
</prevsent>
<prevsent>since the speech input is lattice and there is also potential for ambiguity in the multimodal grammar, the output from mmfst to mdm is an n-best list of potential multimodal interpretations.
</prevsent>
</prevsection>
<citsent citstr=" P99-1024 ">
multimodal dialog manager (mdm) the mdmis based on previous work on speech-act based models of dialog (stent et al, 1999; <papid> P99-1024 </papid>rich and sidner, 1998).</citsent>
<aftsection>
<nextsent>it uses java-based toolkit for writing dialog managers that is similar in philosophy to trindikit (larsson et al, 1999).
</nextsent>
<nextsent>it includes several rule-based ! eps:eps: cmd  cmd eps:eps: /cmd  cmd ! phone:eps: phone  numbers:eps:eps for:eps:eps deicticnp eps:eps: /phone  deicticnp ! ddetpl eps:area:eps eps:selection:eps num restpl eps:eps: restaurant  eps:sem:sem eps:eps: /restaurant  ddetpl ! these:g:eps restpl ! restaurants:restaurant:eps num ! three:3:eps figure 9: multimodal grammar fragment processes that operate on shared state.
</nextsent>
<nextsent>the state includes system and user intentions and beliefs, dialog history and focus space, and information about the speaker, the domain and the available modalities.the processes include interpretation, update, selection and generation processes.
</nextsent>
<nextsent>the interpretation process takes as input an n-best list of possible multimodal interpretations for user input from mmfst.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5352">
<title id=" P01-1056.xml">evaluating a trainable sentence planner for a spoken dialogue system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>most current research systems usetemplate-based generation because it is conceptually straightforward.
</prevsent>
<prevsent>however, while little or no linguistic training is needed to write templates, it is tedious and time-consuming task: one ormore templates must be written for each combination of goals and discourse contexts, and linguistic issues such as subject-verb agreement and determiner-noun agreement must be repeatedly encoded for each template.
</prevsent>
</prevsection>
<citsent citstr=" A92-1006 ">
furthermore, maintenance of the collection of templates becomes software engineering problem as the complexity of the dialog system increases.1the second approach is natural language generation (nlg), which customarily divides the generation process into three modules (rambowand korelsky, 1992): (<papid> A92-1006 </papid>1) text planning, (2) sentence planning, and (3) surface realization.</citsent>
<aftsection>
<nextsent>in this paper, we discuss only sentence planning; the role of the sentence planner is to choose abstract lexico-structural resources for text plan, where text plan encodes the communicative goals for an utterance (and, sometimes, their rhetorical structure).
</nextsent>
<nextsent>in general, nlg promises portability across application domains and dialog situations by focusing on the development of rules for each generation module that are general and domain 1although we are not aware of any software engineering studies of template development and maintenance, this claim is supported by abundant anecdotal evidence.
</nextsent>
<nextsent>independent.
</nextsent>
<nextsent>however, the quality of the output for particular domain, or particular situation in dialog, may be inferior to that of template based system without considerable investment indomain-specific rules or domain-tuning of general rules.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5353">
<title id=" P01-1056.xml">evaluating a trainable sentence planner for a spoken dialogue system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, the quality of the output for particular domain, or particular situation in dialog, may be inferior to that of template based system without considerable investment indomain-specific rules or domain-tuning of general rules.
</prevsent>
<prevsent>furthermore, since rule-based systems use sophisticated linguistic representations, this hand crafting requires linguistic knowledge.
</prevsent>
</prevsection>
<citsent citstr=" P98-1116 ">
recently, several approaches for automatically training modules of an nlg system have been proposed (langkilde and knight, 1998; <papid> P98-1116 </papid>mellish et al, 1998; <papid> W98-1411 </papid>walker, 2000).</citsent>
<aftsection>
<nextsent>these holdthe promise that the complex step of customizing nlg systems by hand can be automated, while avoiding the need for tedious hand-crafting of templates.
</nextsent>
<nextsent>while the engineering benefits of trainable approaches appear obvious, it is unclear whether the utterance quality is high enough.
</nextsent>
<nextsent>in (walker et al, 2001) <papid> N01-1003 </papid>we propose new model of sentence planning called spot.</nextsent>
<nextsent>in spot, the sentence planner is automatically trained, using feedback from two human judges, to choose the best from among different options for realizing set of communicative goals.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5355">
<title id=" P01-1056.xml">evaluating a trainable sentence planner for a spoken dialogue system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, the quality of the output for particular domain, or particular situation in dialog, may be inferior to that of template based system without considerable investment indomain-specific rules or domain-tuning of general rules.
</prevsent>
<prevsent>furthermore, since rule-based systems use sophisticated linguistic representations, this hand crafting requires linguistic knowledge.
</prevsent>
</prevsection>
<citsent citstr=" W98-1411 ">
recently, several approaches for automatically training modules of an nlg system have been proposed (langkilde and knight, 1998; <papid> P98-1116 </papid>mellish et al, 1998; <papid> W98-1411 </papid>walker, 2000).</citsent>
<aftsection>
<nextsent>these holdthe promise that the complex step of customizing nlg systems by hand can be automated, while avoiding the need for tedious hand-crafting of templates.
</nextsent>
<nextsent>while the engineering benefits of trainable approaches appear obvious, it is unclear whether the utterance quality is high enough.
</nextsent>
<nextsent>in (walker et al, 2001) <papid> N01-1003 </papid>we propose new model of sentence planning called spot.</nextsent>
<nextsent>in spot, the sentence planner is automatically trained, using feedback from two human judges, to choose the best from among different options for realizing set of communicative goals.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5356">
<title id=" P01-1056.xml">evaluating a trainable sentence planner for a spoken dialogue system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these holdthe promise that the complex step of customizing nlg systems by hand can be automated, while avoiding the need for tedious hand-crafting of templates.
</prevsent>
<prevsent>while the engineering benefits of trainable approaches appear obvious, it is unclear whether the utterance quality is high enough.
</prevsent>
</prevsection>
<citsent citstr=" N01-1003 ">
in (walker et al, 2001) <papid> N01-1003 </papid>we propose new model of sentence planning called spot.</citsent>
<aftsection>
<nextsent>in spot, the sentence planner is automatically trained, using feedback from two human judges, to choose the best from among different options for realizing set of communicative goals.
</nextsent>
<nextsent>in(walker et al, 2001), <papid> N01-1003 </papid>we evaluate the performance of the learning component of spot, and show that spot learns to select sentence plans that are highly rated by the two human judges.while this evaluation shows that spot has indeed learned from the human judges, it does not show that using only two human judgments is sufficient to produce more broadly acceptable results, nor does it show that spot performs as well as optimized hand-crafted template or rule-based systems.</nextsent>
<nextsent>in this paper we address these questions.because spot is trained on data from working system, we can directly compare spot to thehand-crafted, template-based generation component of the current system.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5359">
<title id=" P01-1056.xml">evaluating a trainable sentence planner for a spoken dialogue system </title>
<section> sentence planning systems.  </section>
<citcontext>
<prevsection>
<prevsent>you are going to dallas random cue word what time would yo like to leave?
</prevsent>
<prevsent>n/a now, what time would you like to leave?
</prevsent>
</prevsection>
<citsent citstr=" A97-1039 ">
figure 4: list of clause combining operations with examples sentence planners (lavoie and rambow, 1997).<papid> A97-1039 </papid>dsyntss are combined using the operations exemplified in figure 4.</citsent>
<aftsection>
<nextsent>the result of applying the operations is sentence plan tree (or sp-treefor short), which is binary tree with leaves labeled by all the elementary speech acts from the input text plan, and with its interior nodes labeled with clause-combining operations.
</nextsent>
<nextsent>as an example, figure 5 shows the sp-tree for utterance system5 in figure 1.
</nextsent>
<nextsent>node soft-merge-general  merges an implicit-confirmation of the destination city and the origin city.
</nextsent>
<nextsent>the row labelled soft-merge in figure 4 shows the result whenargs 1 and 2 are implicit confirmations of the origin and destination.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5366">
<title id=" P01-1056.xml">evaluating a trainable sentence planner for a spoken dialogue system </title>
<section> discussion and future work.  </section>
<citcontext>
<prevsection>
<prevsent>other work has also explored automatically training modules of generator (langkilde and knight, 1998; <papid> P98-1116 </papid>mellish et al, 1998; <papid> W98-1411 </papid>walker, 2000).however, to our knowledge, this is the first reported experimental comparison of trainable technique that shows that the quality of system utterances produced with trainable component scan compete with hand-crafted or rule-based tech niques.</prevsent>
<prevsent>the results validate our methodology; spot outperforms two representative rule-based sentence planners, and performs as well as thehand-crafted template system, but is more easily and quickly tuned to new domain: the training materials for the spot sentence planner can be collected from subjective judgements from small number of judges with little or no linguistic knowledge.previous work on evaluation of natural language generation has utilized three different approaches to evaluation (mellish and dale, 1998).</prevsent>
</prevsection>
<citsent citstr=" J97-1004 ">
the first approach is subjective evaluation methodology such as we use here, where human subjects rate nlg outputs produced by different sources (lester and porter, 1997).<papid> J97-1004 </papid></citsent>
<aftsection>
<nextsent>other work has evaluated template-based spoken dialog generation with task-based approach, i.e. the generator is evaluated with metric such as task completion or user satisfaction after dialog completion (walker, 2000).
</nextsent>
<nextsent>this approach can work well when the task only involves one or two exchanges, when the choices have large effects overthe whole dialog, or the choices vary the content of the utterance.
</nextsent>
<nextsent>because sentence planning choices realize the same content and only affect the current utterance, we believed it important to get local feedback.
</nextsent>
<nextsent>a final approach focuses on sub problems of natural language generation such as the generation of referring expressions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5367">
<title id=" P01-1056.xml">evaluating a trainable sentence planner for a spoken dialogue system </title>
<section> discussion and future work.  </section>
<citcontext>
<prevsection>
<prevsent>because sentence planning choices realize the same content and only affect the current utterance, we believed it important to get local feedback.
</prevsent>
<prevsent>a final approach focuses on sub problems of natural language generation such as the generation of referring expressions.
</prevsent>
</prevsection>
<citsent citstr=" J97-1007 ">
for this type of problem it is possible to evaluate the generator by the degree to which it matches human performance (yeh and mellish, 1997).<papid> J97-1007 </papid></citsent>
<aftsection>
<nextsent>when evaluating sentence planning, this approach doesnt make sense because many different realizations may be equally good.
</nextsent>
<nextsent>however, this experiment did not show that trainable sentence planners produce, in general,better-quality output than template-based or rule based sentence planners.
</nextsent>
<nextsent>that would be impossible: given the nature of template and rule based systems, any quality standard for the output can be met given sufficient person-hours, elapsed time, and software engineering acumen.
</nextsent>
<nextsent>our principal goal, rather, is to show that the quality of the template output, for currently operational dialog system whose template-based output component was developed, expanded, and refined over about 18 months, can be achieved using train able system, for which the necessary training data was collected in three person-days.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5368">
<title id=" P02-1051.xml">translating named entities using monolingual and bilingual resources </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also compare our results with the results obtained from human translations and commercial system for the same task.
</prevsent>
<prevsent>named entity phrases are being introduced in news stories on daily basis in the form of personal names, organizations, locations, temporal phrases,and monetary expressions.
</prevsent>
</prevsection>
<citsent citstr=" E99-1001 ">
while the identification of named entities in text has received significant attention (e.g., mikheev et al (1999) <papid> E99-1001 </papid>and bikel et al (1999)), translation of named entities has not.</citsent>
<aftsection>
<nextsent>this translation problem is especially challenging because new phrases can appear from nowhere, and because many named-entities are domain specific, not to be found in bilingual dictionar ies.a system that specializes in translating named entities such as the one we describe here would be an important tool for many nlp applications.
</nextsent>
<nextsent>statistical machine translation systems can use such system as component to handle phrase translation inorder to improve overall translation quality.
</nextsent>
<nextsent>cross lingual information retrieval (clir) systems could identify relevant documents based on translationsof named entity phrases provided by such system.
</nextsent>
<nextsent>question answering (qa) systems could benefit substantially from such tool since the answer to many factoid questions involve named entities(e.g., answers to who questions usually involve persons/organizations, where questions involve locations, and when questions involve temporal ex pressions).in this paper, we describe system for arabic english named entity translation, though the technique is applicable to any language pair and does not require especially difficult-to-obtain resources.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5369">
<title id=" P02-1051.xml">translating named entities using monolingual and bilingual resources </title>
<section> producing translation candidates.  </section>
<citcontext>
<prevsection>
<prevsent>this regular expression is then matched against large english news corpus.
</prevsent>
<prevsent>all matches are then scored according to their individual word translation/transliteration scores.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
the score forgiven candidate is given by modified ibm model 1 probability (brown et al., 1993) <papid> J93-2003 </papid>as follows:           (4)     </citsent>
<aftsection>
<nextsent>fffifffiff   ffifl
</nextsent>
<nextsent>  ! # %$ &amp; !    (5) where ( is the length of , ) is the length of ,  is scaling factor based on the number of matches of found, and  ! is the index of the english word aligned with ! according to alignment  . the probability $    !  is linear combination of the transliteration and translation score, where the translation score is uniform probability over all dictionary entries for ! .
</nextsent>
<nextsent>the scored matches form the list of translation candidates.
</nextsent>
<nextsent>for example, the candidate list for ?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5370">
<title id=" P01-1024.xml">topological dependency trees a constraint based account of linear precedence </title>
<section> formal framework.  </section>
<citcontext>
<prevsection>
<prevsent>an id/ lp analysis is tuple (v, eid, elp, lex, cat, valencyid, valencylp, field ext, fieldint) such that (v,eid, lex, cat, valencyid) is an id tree and (v,elp, lex, valencylp, fieldext,fieldint) is an lp tree and all principles are satisfied.
</prevsent>
<prevsent>our approach has points of similarity with(broker, 1999) but eschews modal logic in favor of simpler and arguably more perspicuous constraint-based formulation.
</prevsent>
</prevsection>
<citsent citstr=" P98-1106 ">
it is also related to the lifting rules of (kahane et al, 1998), <papid> P98-1106 </papid>but where they choose to stipulate rules that license liftings, we opt instead for placing constraints on otherwise unrestricted climbing.</citsent>
<aftsection>
<nextsent>we now illustrate our theory by applying it to the treatment of word order phenomena in the verbal complex of german verb final sentences.
</nextsent>
<nextsent>we assume the grammar and lexicon shown in figure 1.
</nextsent>
<nextsent>these are intended purely for didactic purpose sand we extend for them no claim of linguistic adequacy.
</nextsent>
<nextsent>5.1 vp extraposition.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5371">
<title id=" P04-3002.xml">improving domain specific word alignment for computer assisted translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>experimental results show significant improvement in terms of both alignment precision and recall.
</prevsent>
<prevsent>and the alignment results are applied in computer assisted translation system to improve human translation efficiency.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
bilingual word alignment is first introduced as an intermediate result in statistical machine translation (smt) (brown et al, 1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>in previous alignment methods, some researchers modeled the alignments with different statistical models (wu, 1997; <papid> J97-3002 </papid>och and ney, 2000; <papid> P00-1056 </papid>cherry and lin, 2003).<papid> P03-1012 </papid></nextsent>
<nextsent>some researchers use similarity and association measures to build alignment links (ahrenberg et al, 1998; <papid> P98-1004 </papid>tufis and barbu, 2002).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5372">
<title id=" P04-3002.xml">improving domain specific word alignment for computer assisted translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>and the alignment results are applied in computer assisted translation system to improve human translation efficiency.
</prevsent>
<prevsent>bilingual word alignment is first introduced as an intermediate result in statistical machine translation (smt) (brown et al, 1993).<papid> J93-2003 </papid></prevsent>
</prevsection>
<citsent citstr=" J97-3002 ">
in previous alignment methods, some researchers modeled the alignments with different statistical models (wu, 1997; <papid> J97-3002 </papid>och and ney, 2000; <papid> P00-1056 </papid>cherry and lin, 2003).<papid> P03-1012 </papid></citsent>
<aftsection>
<nextsent>some researchers use similarity and association measures to build alignment links (ahrenberg et al, 1998; <papid> P98-1004 </papid>tufis and barbu, 2002).</nextsent>
<nextsent>however, all of these methods require large-scale bilingual corpus for training.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5373">
<title id=" P04-3002.xml">improving domain specific word alignment for computer assisted translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>and the alignment results are applied in computer assisted translation system to improve human translation efficiency.
</prevsent>
<prevsent>bilingual word alignment is first introduced as an intermediate result in statistical machine translation (smt) (brown et al, 1993).<papid> J93-2003 </papid></prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
in previous alignment methods, some researchers modeled the alignments with different statistical models (wu, 1997; <papid> J97-3002 </papid>och and ney, 2000; <papid> P00-1056 </papid>cherry and lin, 2003).<papid> P03-1012 </papid></citsent>
<aftsection>
<nextsent>some researchers use similarity and association measures to build alignment links (ahrenberg et al, 1998; <papid> P98-1004 </papid>tufis and barbu, 2002).</nextsent>
<nextsent>however, all of these methods require large-scale bilingual corpus for training.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5374">
<title id=" P04-3002.xml">improving domain specific word alignment for computer assisted translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>and the alignment results are applied in computer assisted translation system to improve human translation efficiency.
</prevsent>
<prevsent>bilingual word alignment is first introduced as an intermediate result in statistical machine translation (smt) (brown et al, 1993).<papid> J93-2003 </papid></prevsent>
</prevsection>
<citsent citstr=" P03-1012 ">
in previous alignment methods, some researchers modeled the alignments with different statistical models (wu, 1997; <papid> J97-3002 </papid>och and ney, 2000; <papid> P00-1056 </papid>cherry and lin, 2003).<papid> P03-1012 </papid></citsent>
<aftsection>
<nextsent>some researchers use similarity and association measures to build alignment links (ahrenberg et al, 1998; <papid> P98-1004 </papid>tufis and barbu, 2002).</nextsent>
<nextsent>however, all of these methods require large-scale bilingual corpus for training.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5375">
<title id=" P04-3002.xml">improving domain specific word alignment for computer assisted translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>bilingual word alignment is first introduced as an intermediate result in statistical machine translation (smt) (brown et al, 1993).<papid> J93-2003 </papid></prevsent>
<prevsent>in previous alignment methods, some researchers modeled the alignments with different statistical models (wu, 1997; <papid> J97-3002 </papid>och and ney, 2000; <papid> P00-1056 </papid>cherry and lin, 2003).<papid> P03-1012 </papid></prevsent>
</prevsection>
<citsent citstr=" P98-1004 ">
some researchers use similarity and association measures to build alignment links (ahrenberg et al, 1998; <papid> P98-1004 </papid>tufis and barbu, 2002).</citsent>
<aftsection>
<nextsent>however, all of these methods require large-scale bilingual corpus for training.
</nextsent>
<nextsent>when the large-scale bilingual corpus is not available, some researchers use existing dictionaries to improve word alignment (ker and chang, 1997).<papid> J97-2004 </papid></nextsent>
<nextsent>however, few works address the problem of domain-specific word alignment when neither the large-scale domain-specific bilingual corpus nor the domain-specific translation dictionary is available.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5376">
<title id=" P04-3002.xml">improving domain specific word alignment for computer assisted translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>some researchers use similarity and association measures to build alignment links (ahrenberg et al, 1998; <papid> P98-1004 </papid>tufis and barbu, 2002).</prevsent>
<prevsent>however, all of these methods require large-scale bilingual corpus for training.</prevsent>
</prevsection>
<citsent citstr=" J97-2004 ">
when the large-scale bilingual corpus is not available, some researchers use existing dictionaries to improve word alignment (ker and chang, 1997).<papid> J97-2004 </papid></citsent>
<aftsection>
<nextsent>however, few works address the problem of domain-specific word alignment when neither the large-scale domain-specific bilingual corpus nor the domain-specific translation dictionary is available.
</nextsent>
<nextsent>this paper addresses the problem of word alignment in specific domain, where only small domain-specific corpus is available.
</nextsent>
<nextsent>in the domain-specific corpus, there are two kinds of words.
</nextsent>
<nextsent>some are general words, which are also frequently used in the general domain.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5384">
<title id=" P04-3002.xml">improving domain specific word alignment for computer assisted translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in order to filter some noise caused by the error alignment links, we only retain those translation pairs whose translation probabilities are above threshold 1d 1?
</prevsent>
<prevsent>or co-occurring frequencies are above threshold 2?
</prevsent>
</prevsection>
<citsent citstr=" J93-1003 ">
when we train the ibm statistical word alignment model with limited bilingual corpus in the specific domain, we build another translation dictionary with the same method as for the dictionary . but we adopt different filtering strategy for the translation dictionary . we use log-likelihood ratio to estimate the association strength of each translation pair because dunning (1993) <papid> J93-1003 </papid>proved that log-likelihood ratio performed very well on small-scale data.</citsent>
<aftsection>
<nextsent>thus, we get the translation dictionary by keeping those entries whose log-likelihood ratio scores are greater than threshold 2d 1d 3 2d 2d ? .
</nextsent>
<nextsent>based on the bi-directional word alignment, we define as si sfsgsi ?= and as ug sipfpgug ??= . the word alignment links in the set si are very reliable.
</nextsent>
<nextsent>thus, we directly accept them as correct links and add them into the final alignment set . wa input: alignment set and si ug (1) for alignment links in , we directly add them into the final alignment set . si wa (2) for each english word in the , we first find its different alignment links, and then do the following: ug a) if there are alignment links found in dictionary , add the link with the largest probability to . 1d wa b) otherwise, if there are alignment links found in dictionary , add the link with the largest log-likelihood ratio score to . 2d wa c) if both a) and b) fail, but three links select the same target words for the english word i, we add this link into . wa d) otherwise, if there are two different links for this word: one target is single word, and the other target is multi-word unit and the words in the multi-word unit have no link in , add this multi-word alignment link to . wa wa output: updated alignment set wa figure 1.
</nextsent>
<nextsent>word alignment adaptation algorithm for each source word in the set , there are two to four different alignment links.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5389">
<title id=" N12-2004.xml">indexing google 1t for low turnaround wild carded frequency queries </title>
<section> background and motivation.  </section>
<citcontext>
<prevsection>
<prevsent>the google 1t?
</prevsent>
<prevsent>dataset (ldc #2006t13) is acollection of 2-, 3-, 4-, and 5-gram frequencies extracted at google from around 1012 tokens of rawweb text.
</prevsent>
</prevsection>
<citsent citstr=" P11-1070 ">
wide access to web-scale data being relative novelty, there has been considerable interest in the research community in how this resource can be put to use (bansal and klein, 2011; <papid> P11-1070 </papid>hawker et al, 2007; lin et al, 2010, among others).</citsent>
<aftsection>
<nextsent>we are concerned with facilitating approaches where large number of frequency queries (op tion ally with token-by-token wildcarding) are made automatically in the context of larger natural language-based system.
</nextsent>
<nextsent>our motivating example is bansal and klein (2011) <papid> P11-1070 </papid>who substantially improve statistical parsing by integrating frequency based features from google 1t, taken as indicative of associations between words.</nextsent>
<nextsent>in this work, however, parser test data is preprocessed off-line?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5392">
<title id=" N12-2004.xml">indexing google 1t for low turnaround wild carded frequency queries </title>
<section> prior work.  </section>
<citcontext>
<prevsection>
<prevsent>although they obtain very fast queries, in our estimation the error introduced by this method would be problematic forour desired use.
</prevsent>
<prevsent>furthermore, the authors do not address wild carding for this strategy.
</prevsent>
</prevsection>
<citsent citstr=" P07-1065 ">
talbot and osborne (2007<papid> P07-1065 </papid>b), talbot and osborne (2007<papid> P07-1065 </papid>a) have explored applications of bloom filters to making comparatively small probabilistic models of large n-gram data sets.</citsent>
<aftsection>
<nextsent>though their method too is randomized and subject to false positives, they discuss ways of controlling the error rate.
</nextsent>
<nextsent>finally, several researchers including bansal and klein (2011) <papid> P11-1070 </papid>and hawker, gardiner and bennetts (2007) describe ways of working off-line?,without low-turnaround querying.</nextsent>
<nextsent>however, systems built along these lines will be unable to efficiently solve single small problems as they arise.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5404">
<title id=" P03-1037.xml">parametric models of linguistic count data </title>
<section> word frequency in fixed-length texts.  </section>
<citcontext>
<prevsection>
<prevsent>if we apply this to word frequency in documents, what this is saying is, informally: whether given word appears at all in document is one thing; how often it appears, if it does, is another thing.
</prevsent>
<prevsent>this is reminiscent of churchs statement that ?[t]he first mention of word obviously depends on frequency, but surprisingly, the second doesnot.?
</prevsent>
</prevsection>
<citsent citstr=" C00-1027 ">
(church, 2000) <papid> C00-1027 </papid>however, church was concerned with language modeling, and in particularcache-based models that overcome some of the limitations introduced by markov assumption.</citsent>
<aftsection>
<nextsent>in such setting it is natural to make distinction between the first occurrence of word and subsequent occurrences, which according to church are influenced by adaptation (church and gale, 1995), referring to an increase in words chance of re-occurrence after it has been spotted for the first time.
</nextsent>
<nextsent>for empirically demonstrating the effects of adaptation, church (2000) <papid> C00-1027 </papid>worked with non parametric methods.</nextsent>
<nextsent>by contrast, our focus is on parametric methods, and unlike in language modeling, we are also interested in words that fail to occur in document, so it is natural for us to distinguish between zero and nonzero occurrences.in table 1, zinb refers to the zero-inflated negative binomial distribution, which takes parameter in addition to the two parameters of its negative binomial component.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5410">
<title id=" P02-1029.xml">inducing german semantic verb classes from purely syntactic subcategorisation information </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a long-standing linguistic hypothesis asserts tight connection between the meaning components of averb and its syntactic behaviour: to certain extent, the lexical meaning of verb determines its behaviour, particularly with respect to the choice of itsarguments.
</prevsent>
<prevsent>the theoretical foundation has been established in extensive work on semantic verb classes such as (levin, 1993) for english and (vzquez et al , 2000) for spanish: each verb class contains verbs which are similar in their meaning and in their syntactic properties.from practical point of view, verb classification supports natural language processing tasks, since it provides principled basis for filling gaps in available lexical knowledge.
</prevsent>
</prevsection>
<citsent citstr=" C96-1055 ">
for example, the english verb classification has been used for applications such as machine translation (dorr, 1997), word sense disambiguation (dorr and jones, 1996), <papid> C96-1055 </papid>and document classification (klavans and kan, 1998).<papid> P98-1112 </papid>various attempts have been made to infer conveniently observable morpho-syntactic and semantic properties for english verb classes (dorr and jones, 1996; <papid> C96-1055 </papid>lapata, 1999; <papid> P99-1051 </papid>stevenson and merlo, 1999; <papid> E99-1007 </papid>schulte im walde, 2000; mccarthy, 2001).to our knowledge this is the first work to obtain german verb classes automatically.</citsent>
<aftsection>
<nextsent>we useda robust statistical parser (schmid, 2000) to acquire purely syntactic subcategorisation information for verbs.
</nextsent>
<nextsent>the information was provided in form of probability distributions over verb frames for each verb.
</nextsent>
<nextsent>there were two conditions: the first with relatively coarse syntactic verb subcategorisation frames, the second more delicate classification subdividing the verb frames of the first condition using prepositional phrase information (case plus preposition).
</nextsent>
<nextsent>in both conditions verbs were clustered using k-means, an iterative, unsupervised, hard clustering method with well-known properties, cf.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5411">
<title id=" P02-1029.xml">inducing german semantic verb classes from purely syntactic subcategorisation information </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a long-standing linguistic hypothesis asserts tight connection between the meaning components of averb and its syntactic behaviour: to certain extent, the lexical meaning of verb determines its behaviour, particularly with respect to the choice of itsarguments.
</prevsent>
<prevsent>the theoretical foundation has been established in extensive work on semantic verb classes such as (levin, 1993) for english and (vzquez et al , 2000) for spanish: each verb class contains verbs which are similar in their meaning and in their syntactic properties.from practical point of view, verb classification supports natural language processing tasks, since it provides principled basis for filling gaps in available lexical knowledge.
</prevsent>
</prevsection>
<citsent citstr=" P98-1112 ">
for example, the english verb classification has been used for applications such as machine translation (dorr, 1997), word sense disambiguation (dorr and jones, 1996), <papid> C96-1055 </papid>and document classification (klavans and kan, 1998).<papid> P98-1112 </papid>various attempts have been made to infer conveniently observable morpho-syntactic and semantic properties for english verb classes (dorr and jones, 1996; <papid> C96-1055 </papid>lapata, 1999; <papid> P99-1051 </papid>stevenson and merlo, 1999; <papid> E99-1007 </papid>schulte im walde, 2000; mccarthy, 2001).to our knowledge this is the first work to obtain german verb classes automatically.</citsent>
<aftsection>
<nextsent>we useda robust statistical parser (schmid, 2000) to acquire purely syntactic subcategorisation information for verbs.
</nextsent>
<nextsent>the information was provided in form of probability distributions over verb frames for each verb.
</nextsent>
<nextsent>there were two conditions: the first with relatively coarse syntactic verb subcategorisation frames, the second more delicate classification subdividing the verb frames of the first condition using prepositional phrase information (case plus preposition).
</nextsent>
<nextsent>in both conditions verbs were clustered using k-means, an iterative, unsupervised, hard clustering method with well-known properties, cf.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5413">
<title id=" P02-1029.xml">inducing german semantic verb classes from purely syntactic subcategorisation information </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a long-standing linguistic hypothesis asserts tight connection between the meaning components of averb and its syntactic behaviour: to certain extent, the lexical meaning of verb determines its behaviour, particularly with respect to the choice of itsarguments.
</prevsent>
<prevsent>the theoretical foundation has been established in extensive work on semantic verb classes such as (levin, 1993) for english and (vzquez et al , 2000) for spanish: each verb class contains verbs which are similar in their meaning and in their syntactic properties.from practical point of view, verb classification supports natural language processing tasks, since it provides principled basis for filling gaps in available lexical knowledge.
</prevsent>
</prevsection>
<citsent citstr=" P99-1051 ">
for example, the english verb classification has been used for applications such as machine translation (dorr, 1997), word sense disambiguation (dorr and jones, 1996), <papid> C96-1055 </papid>and document classification (klavans and kan, 1998).<papid> P98-1112 </papid>various attempts have been made to infer conveniently observable morpho-syntactic and semantic properties for english verb classes (dorr and jones, 1996; <papid> C96-1055 </papid>lapata, 1999; <papid> P99-1051 </papid>stevenson and merlo, 1999; <papid> E99-1007 </papid>schulte im walde, 2000; mccarthy, 2001).to our knowledge this is the first work to obtain german verb classes automatically.</citsent>
<aftsection>
<nextsent>we useda robust statistical parser (schmid, 2000) to acquire purely syntactic subcategorisation information for verbs.
</nextsent>
<nextsent>the information was provided in form of probability distributions over verb frames for each verb.
</nextsent>
<nextsent>there were two conditions: the first with relatively coarse syntactic verb subcategorisation frames, the second more delicate classification subdividing the verb frames of the first condition using prepositional phrase information (case plus preposition).
</nextsent>
<nextsent>in both conditions verbs were clustered using k-means, an iterative, unsupervised, hard clustering method with well-known properties, cf.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5414">
<title id=" P02-1029.xml">inducing german semantic verb classes from purely syntactic subcategorisation information </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a long-standing linguistic hypothesis asserts tight connection between the meaning components of averb and its syntactic behaviour: to certain extent, the lexical meaning of verb determines its behaviour, particularly with respect to the choice of itsarguments.
</prevsent>
<prevsent>the theoretical foundation has been established in extensive work on semantic verb classes such as (levin, 1993) for english and (vzquez et al , 2000) for spanish: each verb class contains verbs which are similar in their meaning and in their syntactic properties.from practical point of view, verb classification supports natural language processing tasks, since it provides principled basis for filling gaps in available lexical knowledge.
</prevsent>
</prevsection>
<citsent citstr=" E99-1007 ">
for example, the english verb classification has been used for applications such as machine translation (dorr, 1997), word sense disambiguation (dorr and jones, 1996), <papid> C96-1055 </papid>and document classification (klavans and kan, 1998).<papid> P98-1112 </papid>various attempts have been made to infer conveniently observable morpho-syntactic and semantic properties for english verb classes (dorr and jones, 1996; <papid> C96-1055 </papid>lapata, 1999; <papid> P99-1051 </papid>stevenson and merlo, 1999; <papid> E99-1007 </papid>schulte im walde, 2000; mccarthy, 2001).to our knowledge this is the first work to obtain german verb classes automatically.</citsent>
<aftsection>
<nextsent>we useda robust statistical parser (schmid, 2000) to acquire purely syntactic subcategorisation information for verbs.
</nextsent>
<nextsent>the information was provided in form of probability distributions over verb frames for each verb.
</nextsent>
<nextsent>there were two conditions: the first with relatively coarse syntactic verb subcategorisation frames, the second more delicate classification subdividing the verb frames of the first condition using prepositional phrase information (case plus preposition).
</nextsent>
<nextsent>in both conditions verbs were clustered using k-means, an iterative, unsupervised, hard clustering method with well-known properties, cf.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5417">
<title id=" P02-1029.xml">inducing german semantic verb classes from purely syntactic subcategorisation information </title>
<section> emotion: rgern, freuen.  </section>
<citcontext>
<prevsection>
<prevsent>it is designed to uncover an inherent natural structure of the data objects, and the equivalence classes induced by the clusters provide means for generalising over these objects.
</prevsent>
<prevsent>in our case, clustering is realised on verbs: the data objects are represented by verbs, and the data features for describing the objects are realised by probability distribution over syntactic verb frame descriptions.
</prevsent>
</prevsection>
<citsent citstr=" C00-2094 ">
clustering is applicable to variety of areas in natural language processing, e.g. by utilising class type descriptions such as in machine translation (dorr, 1997), word sense disambiguation (dorrand jones, 1996), <papid> C96-1055 </papid>and document classification (kla vans and kan, 1998), <papid> P98-1112 </papid>or by applying clusters for smoothing such as in machine translation (prescher et al , 2000), <papid> C00-2094 </papid>or probabilistic grammars (riezler et al ., 2000).<papid> P00-1061 </papid>we performed clustering by the k-means algorithm as proposed by (forgy, 1965), which is an unsupervised hard clustering method assigning   data objects to exactly</citsent>
<aftsection>
<nextsent>clusters.
</nextsent>
<nextsent>initial verb clusters are iteratively re-organised by assigning each verb to its closest cluster (centroid) and re-calculating cluster centro ids until no further changes take place.
</nextsent>
<nextsent>one parameter of the clustering process is the distance measure used.
</nextsent>
<nextsent>standard choices include the cosine, euclidean distance, manhattan metric,and variants of the kullback-leibler (kl) divergence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5418">
<title id=" P02-1029.xml">inducing german semantic verb classes from purely syntactic subcategorisation information </title>
<section> emotion: rgern, freuen.  </section>
<citcontext>
<prevsection>
<prevsent>it is designed to uncover an inherent natural structure of the data objects, and the equivalence classes induced by the clusters provide means for generalising over these objects.
</prevsent>
<prevsent>in our case, clustering is realised on verbs: the data objects are represented by verbs, and the data features for describing the objects are realised by probability distribution over syntactic verb frame descriptions.
</prevsent>
</prevsection>
<citsent citstr=" P00-1061 ">
clustering is applicable to variety of areas in natural language processing, e.g. by utilising class type descriptions such as in machine translation (dorr, 1997), word sense disambiguation (dorrand jones, 1996), <papid> C96-1055 </papid>and document classification (kla vans and kan, 1998), <papid> P98-1112 </papid>or by applying clusters for smoothing such as in machine translation (prescher et al , 2000), <papid> C00-2094 </papid>or probabilistic grammars (riezler et al ., 2000).<papid> P00-1061 </papid>we performed clustering by the k-means algorithm as proposed by (forgy, 1965), which is an unsupervised hard clustering method assigning   data objects to exactly</citsent>
<aftsection>
<nextsent>clusters.
</nextsent>
<nextsent>initial verb clusters are iteratively re-organised by assigning each verb to its closest cluster (centroid) and re-calculating cluster centro ids until no further changes take place.
</nextsent>
<nextsent>one parameter of the clustering process is the distance measure used.
</nextsent>
<nextsent>standard choices include the cosine, euclidean distance, manhattan metric,and variants of the kullback-leibler (kl) divergence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5420">
<title id=" P02-1029.xml">inducing german semantic verb classes from purely syntactic subcategorisation information </title>
<section> emotion: rgern, freuen.  </section>
<citcontext>
<prevsection>
<prevsent>the task of evaluating the result of cluster analysis against the known gold standard of hand-constructedverb classes requires us to assess the similarity between two sets of equivalence relations.
</prevsent>
<prevsent>as noted by (strehl et al , 2000), it is useful to have an evaluation measure that does not depend on the choice of similarity measure or on the original dimensionality ofthe input data, since that allows meaningful comparison of results for which these parameters vary.
</prevsent>
</prevsection>
<citsent citstr=" M95-1005 ">
this is similar to the perspective of (vilain et al , 1995), <papid> M95-1005 </papid>who present, in the context of the muc co-reference evaluation scheme, model-theoretic measure of the similarity between equivalence classes.</citsent>
<aftsection>
<nextsent>strehl et al  consider clustering   that partitions   objects (
</nextsent>
<nextsent> ) into
</nextsent>
<nextsent>clusters; the clusters   ffi of   are the sets for which   ffi
</nextsent>
<nextsent>  . 1we also tried various transformations and variations of the probabilities, such as frequencies and binarisation, but none proved as effective as the probabilities.we call the cluster result  and the desired gold standard  . for measuring the quality of an individual cluster, the cluster purity of each cluster  ffi is defined by its largest  ffi , the number of members  ffi that are projected into the same class   . the measure is biased towards small clusters, with the extreme case of singleton clusters, which is an undesired property for our (linguistic) needs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5421">
<title id=" P04-3001.xml">transtype2  an innovative computer assisted translation system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the tt2 system consists of two major subsystems that interact closely: user interface (ui), written in java, provides the typing and pointing modalities; second ui supplements those with speech for operating the prototype via short commands uttered by the user . the user interface also produces trace of all user actions that can later be replayed by special program or analyzed in order to evaluate the effectiveness of transtype2 both in terms of number of keystrokes needed for typing translation and the various patterns of use.
</prevsent>
<prevsent>prediction engine (pe), written in c/c++, of which there are multiple realizations available, several per language pair and specific domain (either technical documentation, ec official documents or hansards).
</prevsent>
</prevsection>
<citsent citstr=" P00-1006 ">
the translation engines developed by research partners are: rali (frenchenglish) is maximum-entropy minimum-divergence translation model (foster 2000) <papid> P00-1006 </papid>that proposes multiple completions for the next few words.</citsent>
<aftsection>
<nextsent>iti (frenchenglish, spanishenglish) are based on finite-state techniques (cubel et al 2003) and suggest single completion of whole sentence.
</nextsent>
<nextsent>rwth (frenchenglish, spanish english, germanenglish) are statistical based (och et al 2003) and suggest single completion of whole sentence.
</nextsent>
<nextsent>the main communications between the ui and the pe are the following: 1.
</nextsent>
<nextsent>to initialize the pe, the ui calls generic create.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5422">
<title id=" P00-1053.xml">a hierarchical account of referential accessibility </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also show that vt provides better model for determining domains of referential accessibility, and discuss how vt can be used to address various issues of structural ambiguity.
</prevsent>
<prevsent>in this paper, we outline theory of referential accessibility called veins theory (vt).
</prevsent>
</prevsection>
<citsent citstr=" J86-3001 ">
we compare vt to stack-based models based on grosz and sidner (1986) <papid> J86-3001 </papid>focus spaces, and show how vt addresses the problem of  left satellites , i.e., subordinate discourse segments that appear prior to their nuclei (dominating segments) in the linear text.</citsent>
<aftsection>
<nextsent>left-satellites pose problem for stack-based models, which remove subordinate segments from the stack before pushing nuclear or dominating segment, thus rendering them inaccessible.
</nextsent>
<nextsent>the percentage of such cases is typically small, which may account for the fact that their treatment has been largely overlooked in the literature, but the phenomenon nonetheless persists in most texts.
</nextsent>
<nextsent>we also show how vt can be used to address various issues of structural ambiguity.
</nextsent>
<nextsent>1 veins theory.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5423">
<title id=" P00-1053.xml">a hierarchical account of referential accessibility </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>when hierarchical adjacency is considered, an anaphor may be resolved to referent that is not the closest in linear interpretation of text.
</prevsent>
<prevsent>however, because referential expressions are organized in equivalence classes, it is sufficient that an anaphor is resolved to some member of the set.
</prevsent>
</prevsection>
<citsent citstr=" P98-1044 ">
this is consistent with the distinction between  direct  and  indirect  references discussed in (cristea, et al, 1998).<papid> P98-1044 </papid></citsent>
<aftsection>
<nextsent>1 2 3 4 5 6 7 8 9 10 11 12 13-?
</nextsent>
<nextsent>h = 1 9 * = 1 9 * = 1 = 1 9 * = 9 = 1 9 * = 1 = 1 9 * = 5 = 1 5 9 * = 1 = 1 9 * = 3 = 1 3 5 9 * = 6 7 = 1 5 6 7 9 * = 9 = 1 9 * = 9 = 1 9 * = 9 = 1 (8) 9 * = 10 = 1 9 10 * = 11 = 1 9 10 11 *h = 3 = 1 3 5 9 dra = 1 3 = 9 = 1 (8) 9 dra = 1 8 9 figure 2: rst analysis of the text in figure 1
</nextsent>
<nextsent>veins theory claims that references from given unit are possible only in its dra, i.e., that discourse structure constrains the areas of the text over which references can be resolved.
</nextsent>
<nextsent>in previous work, we compared the potential of hierarchical and linear models of discourse--i.e., approaches that enumerate potential antecedents in an undifferentiated window of text linearly preceding the anaphor under scrutiny--to correctly establish co-referential links in texts, and hence, their potential to correctly resolve anaphors (cristea, et al, 2000).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5425">
<title id=" P00-1053.xml">a hierarchical account of referential accessibility </title>
<section> vt and stack-based models.  </section>
<citcontext>
<prevsection>
<prevsent>in general, the potential to correctly determine coreferential links was greater for vt than for linear models when one looks back 4 elementary discourse units.
</prevsent>
<prevsent>when looking back more than four units, the linear model was equally effective.
</prevsent>
</prevsection>
<citsent citstr=" P98-1011 ">
here, we compare vt to stack-based models of discourse structure based on grosz and sidner (1986) <papid> J86-3001 </papid>(g&s;) focus spaces (e.g., hahn and strbe, 1997; azzam, et al, 1998).<papid> P98-1011 </papid></citsent>
<aftsection>
<nextsent>in these approaches, discourse segments are pushed on the stack as they are encountered in linear traversal of the text.
</nextsent>
<nextsent>before dominating segment is pushed, subordinate segments that precede it are popped from the stack.
</nextsent>
<nextsent>antecedents for res appearing in the segment on the top of the stack are sought in discourse segments in the stack below it.
</nextsent>
<nextsent>therefore, in cases where subordinate segment precedes dominating segment b, reference to an entity in by an re in is not resolvable.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5426">
<title id=" P00-1053.xml">a hierarchical account of referential accessibility </title>
<section> vt and stack-based models.  </section>
<citcontext>
<prevsection>
<prevsent>special provision could be made in order to handle such casese.g., subsequently pushing on top of bbut this would violate the overall strategy of resolving res appearing in segments currently on the top of the stack.
</prevsent>
<prevsent>the special status given to left satellites in vt addresses this problem.
</prevsent>
</prevsection>
<citsent citstr=" J96-3006 ">
for example, one rst analysis of (1) proposed by moser and moore (1996) <papid> J96-3006 </papid>is given in figure 3.</citsent>
<aftsection>
<nextsent>moser and moore note that the relation of an rst nucleus to its satellite is analogous to the dominates relation proposed by g&s; (see also marcu, 2000).<papid> C00-1076 </papid></nextsent>
<nextsent>as subordinate segment preceding the segment that dominates it, the satellite is popped from the stack before the dominant segment (the nucleus) is pushed in the stack-based model, and therefore it is not included among the discourse segments that are searched to resolve co-references.3 similarly, the text in (2), taken from the muc annotated corpus (marcu, et al, 1999), <papid> W99-0307 </papid>was assigned the rst structure in figure 4, which presents the same problem for the stack-based approach: the referent for this in c2 is to the clinton program in a2, but because it is subordinate segment, it is no longer on the stack when c2 is processed.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5428">
<title id=" P00-1053.xml">a hierarchical account of referential accessibility </title>
<section> vt and stack-based models.  </section>
<citcontext>
<prevsection>
<prevsent>the special status given to left satellites in vt addresses this problem.
</prevsent>
<prevsent>for example, one rst analysis of (1) proposed by moser and moore (1996) <papid> J96-3006 </papid>is given in figure 3.</prevsent>
</prevsection>
<citsent citstr=" C00-1076 ">
moser and moore note that the relation of an rst nucleus to its satellite is analogous to the dominates relation proposed by g&s; (see also marcu, 2000).<papid> C00-1076 </papid></citsent>
<aftsection>
<nextsent>as subordinate segment preceding the segment that dominates it, the satellite is popped from the stack before the dominant segment (the nucleus) is pushed in the stack-based model, and therefore it is not included among the discourse segments that are searched to resolve co-references.3 similarly, the text in (2), taken from the muc annotated corpus (marcu, et al, 1999), <papid> W99-0307 </papid>was assigned the rst structure in figure 4, which presents the same problem for the stack-based approach: the referent for this in c2 is to the clinton program in a2, but because it is subordinate segment, it is no longer on the stack when c2 is processed.</nextsent>
<nextsent>(1) a1.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5429">
<title id=" P00-1053.xml">a hierarchical account of referential accessibility </title>
<section> vt and stack-based models.  </section>
<citcontext>
<prevsection>
<prevsent>for example, one rst analysis of (1) proposed by moser and moore (1996) <papid> J96-3006 </papid>is given in figure 3.</prevsent>
<prevsent>moser and moore note that the relation of an rst nucleus to its satellite is analogous to the dominates relation proposed by g&s; (see also marcu, 2000).<papid> C00-1076 </papid></prevsent>
</prevsection>
<citsent citstr=" W99-0307 ">
as subordinate segment preceding the segment that dominates it, the satellite is popped from the stack before the dominant segment (the nucleus) is pushed in the stack-based model, and therefore it is not included among the discourse segments that are searched to resolve co-references.3 similarly, the text in (2), taken from the muc annotated corpus (marcu, et al, 1999), <papid> W99-0307 </papid>was assigned the rst structure in figure 4, which presents the same problem for the stack-based approach: the referent for this in c2 is to the clinton program in a2, but because it is subordinate segment, it is no longer on the stack when c2 is processed.</citsent>
<aftsection>
<nextsent>(1) a1.
</nextsent>
<nextsent>george bush supports big business.
</nextsent>
<nextsent>b1.
</nextsent>
<nextsent>he sure to veto house bill 1711.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5434">
<title id=" P02-1064.xml">an empirical study of active learning with support vector machines for japanese word segmentation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>even if we have good supervised-learning method,we cannot get high-performance without an annotated corpus.
</prevsent>
<prevsent>the problem is that corpus annotation is labour intensive and very expensive.
</prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
in order to overcome this, some unsupervised learning methods and minimally-supervised methods, e.g., (yarowsky, 1995; <papid> P95-1026 </papid>yarowsky and wicentowski, 2000), <papid> P00-1027 </papid>have been proposed.</citsent>
<aftsection>
<nextsent>however, such methods usually depend on tasks or domains and their performance of ten does not match one with supervised learning method.
</nextsent>
<nextsent>another promising approach is active learning, in which classifier selects examples to be labeled, andthen requests teacher to label them.
</nextsent>
<nextsent>it is very different from passive learning, in which classifier gets labeled examples randomly.
</nextsent>
<nextsent>active learning is general framework and does not depend on tasks or domains.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5435">
<title id=" P02-1064.xml">an empirical study of active learning with support vector machines for japanese word segmentation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>even if we have good supervised-learning method,we cannot get high-performance without an annotated corpus.
</prevsent>
<prevsent>the problem is that corpus annotation is labour intensive and very expensive.
</prevsent>
</prevsection>
<citsent citstr=" P00-1027 ">
in order to overcome this, some unsupervised learning methods and minimally-supervised methods, e.g., (yarowsky, 1995; <papid> P95-1026 </papid>yarowsky and wicentowski, 2000), <papid> P00-1027 </papid>have been proposed.</citsent>
<aftsection>
<nextsent>however, such methods usually depend on tasks or domains and their performance of ten does not match one with supervised learning method.
</nextsent>
<nextsent>another promising approach is active learning, in which classifier selects examples to be labeled, andthen requests teacher to label them.
</nextsent>
<nextsent>it is very different from passive learning, in which classifier gets labeled examples randomly.
</nextsent>
<nextsent>active learning is general framework and does not depend on tasks or domains.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5436">
<title id=" P02-1064.xml">an empirical study of active learning with support vector machines for japanese word segmentation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>active learning is general framework and does not depend on tasks or domains.
</prevsent>
<prevsent>it is expected that active learning will reduce considerably manual annotation cost while keeping performance.
</prevsent>
</prevsection>
<citsent citstr=" P00-1016 ">
however, few papers in the field of computational linguistics have focused onthis approach (dagan and engelson, 1995; thompson et al, 1999; ngai and yarowsky, 2000; <papid> P00-1016 </papid>hwa, 2000; <papid> W00-1306 </papid>banko and brill, 2001).<papid> P01-1005 </papid></citsent>
<aftsection>
<nextsent>although there aremany active learning methods with various classifiers such as probabilistic classifier (mccallum and nigam, 1998), we focus on active learning with support vector machines (svms) because of their performance.
</nextsent>
<nextsent>the support vector machine, which is introduced by vapnik (1995), is powerful new statistical learning method.
</nextsent>
<nextsent>excellent performance is reported in hand-written character recognition, face detection, image classification, and so forth.
</nextsent>
<nextsent>svms have been recently applied to several natural language tasks, including text classification (joachims, 1998;dumais et al, 1998), chunking (kudo and matsumoto, 2000<papid> W00-1303 </papid>b; kudo and matsumoto, 2001), <papid> N01-1025 </papid>and dependency analysis (kudo and matsumoto, 2000<papid> W00-1303 </papid>a).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5437">
<title id=" P02-1064.xml">an empirical study of active learning with support vector machines for japanese word segmentation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>active learning is general framework and does not depend on tasks or domains.
</prevsent>
<prevsent>it is expected that active learning will reduce considerably manual annotation cost while keeping performance.
</prevsent>
</prevsection>
<citsent citstr=" W00-1306 ">
however, few papers in the field of computational linguistics have focused onthis approach (dagan and engelson, 1995; thompson et al, 1999; ngai and yarowsky, 2000; <papid> P00-1016 </papid>hwa, 2000; <papid> W00-1306 </papid>banko and brill, 2001).<papid> P01-1005 </papid></citsent>
<aftsection>
<nextsent>although there aremany active learning methods with various classifiers such as probabilistic classifier (mccallum and nigam, 1998), we focus on active learning with support vector machines (svms) because of their performance.
</nextsent>
<nextsent>the support vector machine, which is introduced by vapnik (1995), is powerful new statistical learning method.
</nextsent>
<nextsent>excellent performance is reported in hand-written character recognition, face detection, image classification, and so forth.
</nextsent>
<nextsent>svms have been recently applied to several natural language tasks, including text classification (joachims, 1998;dumais et al, 1998), chunking (kudo and matsumoto, 2000<papid> W00-1303 </papid>b; kudo and matsumoto, 2001), <papid> N01-1025 </papid>and dependency analysis (kudo and matsumoto, 2000<papid> W00-1303 </papid>a).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5438">
<title id=" P02-1064.xml">an empirical study of active learning with support vector machines for japanese word segmentation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>active learning is general framework and does not depend on tasks or domains.
</prevsent>
<prevsent>it is expected that active learning will reduce considerably manual annotation cost while keeping performance.
</prevsent>
</prevsection>
<citsent citstr=" P01-1005 ">
however, few papers in the field of computational linguistics have focused onthis approach (dagan and engelson, 1995; thompson et al, 1999; ngai and yarowsky, 2000; <papid> P00-1016 </papid>hwa, 2000; <papid> W00-1306 </papid>banko and brill, 2001).<papid> P01-1005 </papid></citsent>
<aftsection>
<nextsent>although there aremany active learning methods with various classifiers such as probabilistic classifier (mccallum and nigam, 1998), we focus on active learning with support vector machines (svms) because of their performance.
</nextsent>
<nextsent>the support vector machine, which is introduced by vapnik (1995), is powerful new statistical learning method.
</nextsent>
<nextsent>excellent performance is reported in hand-written character recognition, face detection, image classification, and so forth.
</nextsent>
<nextsent>svms have been recently applied to several natural language tasks, including text classification (joachims, 1998;dumais et al, 1998), chunking (kudo and matsumoto, 2000<papid> W00-1303 </papid>b; kudo and matsumoto, 2001), <papid> N01-1025 </papid>and dependency analysis (kudo and matsumoto, 2000<papid> W00-1303 </papid>a).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5439">
<title id=" P02-1064.xml">an empirical study of active learning with support vector machines for japanese word segmentation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the support vector machine, which is introduced by vapnik (1995), is powerful new statistical learning method.
</prevsent>
<prevsent>excellent performance is reported in hand-written character recognition, face detection, image classification, and so forth.
</prevsent>
</prevsection>
<citsent citstr=" W00-1303 ">
svms have been recently applied to several natural language tasks, including text classification (joachims, 1998;dumais et al, 1998), chunking (kudo and matsumoto, 2000<papid> W00-1303 </papid>b; kudo and matsumoto, 2001), <papid> N01-1025 </papid>and dependency analysis (kudo and matsumoto, 2000<papid> W00-1303 </papid>a).</citsent>
<aftsection>
<nextsent>svms have been greatly successful in such tasks.
</nextsent>
<nextsent>computational linguistics (acl), philadelphia, july 2002, pp.
</nextsent>
<nextsent>505-512.
</nextsent>
<nextsent>proceedings of the 40th annual meeting of the association for additionally, svms as well as boosting have good theoretical background.the objective of our research is to develop an effective way to build corpus and to create high performance nl systems with minimal cost.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5441">
<title id=" P02-1064.xml">an empirical study of active learning with support vector machines for japanese word segmentation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the support vector machine, which is introduced by vapnik (1995), is powerful new statistical learning method.
</prevsent>
<prevsent>excellent performance is reported in hand-written character recognition, face detection, image classification, and so forth.
</prevsent>
</prevsection>
<citsent citstr=" N01-1025 ">
svms have been recently applied to several natural language tasks, including text classification (joachims, 1998;dumais et al, 1998), chunking (kudo and matsumoto, 2000<papid> W00-1303 </papid>b; kudo and matsumoto, 2001), <papid> N01-1025 </papid>and dependency analysis (kudo and matsumoto, 2000<papid> W00-1303 </papid>a).</citsent>
<aftsection>
<nextsent>svms have been greatly successful in such tasks.
</nextsent>
<nextsent>computational linguistics (acl), philadelphia, july 2002, pp.
</nextsent>
<nextsent>505-512.
</nextsent>
<nextsent>proceedings of the 40th annual meeting of the association for additionally, svms as well as boosting have good theoretical background.the objective of our research is to develop an effective way to build corpus and to create high performance nl systems with minimal cost.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5444">
<title id=" P04-1067.xml">a geometric view on bilingual lexicon extraction from comparable corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we will explain in this paper the motivations behind the use of such methods for bilingual lexicon extraction from comparable corpora, and show how to apply them.
</prevsent>
<prevsent>section 2 is devoted tothe presentation of the standard approach, ie the approach adopted by most researchers so far, its geometric interpretation, and the unresolved synonymy 1http://clef.iei.pi.cnr.it:2002/and polysemy problems.
</prevsent>
</prevsection>
<citsent citstr=" C02-1166 ">
sections 3 to 4 then describe three new methods aiming at addressing the issues raised by synonymy and polysemy: in section 3 we introduce an extension of the standard approach, and show in appendix how this approach relates to the probabilistic method proposed in (dejean et al, 2002); <papid> C02-1166 </papid>in section 4, we present bilingual extension to lsa, namely canonical correlation analysis and its kernel version; lastly, in section 5, we formulate the problem in terms of probabilistic lsa and review different associated simi larities.</citsent>
<aftsection>
<nextsent>section 6 is then devoted to large-scale evaluation of the different methods proposed.
</nextsent>
<nextsent>open issues are then discussed in section 7.
</nextsent>
<nextsent>bilingual lexicon extraction from comparable corpora has been studied by number of researchers, (rapp, 1995; <papid> P95-1050 </papid>peters and picchi, 1995; tanaka and iwasaki, 1996; <papid> C96-2098 </papid>shahzad et al, 1999; fung, 2000,among others).</nextsent>
<nextsent>their work relies on the assumption that if two words are mutual translations, then their more frequent collocates (taken here in very broad sense) are likely to be mutual translations aswell.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5445">
<title id=" P04-1067.xml">a geometric view on bilingual lexicon extraction from comparable corpora </title>
<section> standard approach.  </section>
<citcontext>
<prevsection>
<prevsent>section 6 is then devoted to large-scale evaluation of the different methods proposed.
</prevsent>
<prevsent>open issues are then discussed in section 7.
</prevsent>
</prevsection>
<citsent citstr=" P95-1050 ">
bilingual lexicon extraction from comparable corpora has been studied by number of researchers, (rapp, 1995; <papid> P95-1050 </papid>peters and picchi, 1995; tanaka and iwasaki, 1996; <papid> C96-2098 </papid>shahzad et al, 1999; fung, 2000,among others).</citsent>
<aftsection>
<nextsent>their work relies on the assumption that if two words are mutual translations, then their more frequent collocates (taken here in very broad sense) are likely to be mutual translations aswell.
</nextsent>
<nextsent>based on this assumption, the standard approach builds context vectors for each source and target word, translates the target context vectors using general bilingual dictionary, and compares the translation with the source context vector: 1.
</nextsent>
<nextsent>for each source word (resp.
</nextsent>
<nextsent>target word w),.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5446">
<title id=" P04-1067.xml">a geometric view on bilingual lexicon extraction from comparable corpora </title>
<section> standard approach.  </section>
<citcontext>
<prevsection>
<prevsent>section 6 is then devoted to large-scale evaluation of the different methods proposed.
</prevsent>
<prevsent>open issues are then discussed in section 7.
</prevsent>
</prevsection>
<citsent citstr=" C96-2098 ">
bilingual lexicon extraction from comparable corpora has been studied by number of researchers, (rapp, 1995; <papid> P95-1050 </papid>peters and picchi, 1995; tanaka and iwasaki, 1996; <papid> C96-2098 </papid>shahzad et al, 1999; fung, 2000,among others).</citsent>
<aftsection>
<nextsent>their work relies on the assumption that if two words are mutual translations, then their more frequent collocates (taken here in very broad sense) are likely to be mutual translations aswell.
</nextsent>
<nextsent>based on this assumption, the standard approach builds context vectors for each source and target word, translates the target context vectors using general bilingual dictionary, and compares the translation with the source context vector: 1.
</nextsent>
<nextsent>for each source word (resp.
</nextsent>
<nextsent>target word w),.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5447">
<title id=" P04-1067.xml">a geometric view on bilingual lexicon extraction from comparable corpora </title>
<section> standard approach.  </section>
<citcontext>
<prevsection>
<prevsent>(e,f)d a(v, e) a(w, f) (1) because of the translation step, only the pairs (e, f) that are present in the dictionary contribute to the dot-product.
</prevsent>
<prevsent>note that this approach requires some general bilingual dictionary as initial seed.
</prevsent>
</prevsection>
<citsent citstr=" W02-0902 ">
one way to circumvent this requirement consists in automatically building seed lexicon based on spelling and cognates clues (koehn and knight, 2002).<papid> W02-0902 </papid></citsent>
<aftsection>
<nextsent>another approach directly tackles the problem from scratch by searching for translation mapping which optimally preserves the intra lingual association measure between words (diab and finch, 2000): the under lying assumption is that pairs of words which are highly associated in one language should have translations that are highly associated in the other language.
</nextsent>
<nextsent>in this latter case, the association measure is defined as the spearman rank order correlation between their context vectors restricted to peripheral tokens?
</nextsent>
<nextsent>(highly frequent words).
</nextsent>
<nextsent>the search method is based on gradient descent algorithm, by iteratively changing the mapping of single word until (locally) minimizing the sum of squared differences between the association measure of all pairsof words in one language and the association measure of the pairs of translated words obtained by the current mapping.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5449">
<title id=" P02-1001.xml">parameter estimation for probabilistic finite state transducers </title>
<section> transducers and parameters.  </section>
<citcontext>
<prevsection>
<prevsent>{}, ? ??
</prevsent>
<prevsent>{}) using concatenation, probabilistic union +p, and probabilistic closure p. for defining conditional relations, good regexp language is unknown to us, but they can be defined in several other ways: (1) via fsts as in fig.
</prevsent>
</prevsection>
<citsent citstr=" P96-1031 ">
1c, (2) by compilation of weighted rewrite rules (mohri and sproat, 1996), (<papid> P96-1031 </papid>3) by compilation of decision trees(sproat and riley, 1996), (<papid> P96-1029 </papid>4) as relation that performs contextual left-to-right replacement of inputsubstrings by smaller conditional relation (gerdemann and van noord, 1999),<papid> E99-1017 </papid>5 (5) by conditionaliza tion of joint relation as discussed below.</citsent>
<aftsection>
<nextsent>a central technique is to define joint relation as noisy-channel model, by composing joint relation with cascade of one or more conditional relations as in fig.
</nextsent>
<nextsent>1 (pereira and riley, 1997; knight and graehl, 1998).<papid> J98-4003 </papid></nextsent>
<nextsent>the general form is illustrated by 3conceptually, the parameters represent the probabilities of reading another (?); reading another (?); transducing to rather than (?); starting to trans duce to  rather than (?).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5450">
<title id=" P02-1001.xml">parameter estimation for probabilistic finite state transducers </title>
<section> transducers and parameters.  </section>
<citcontext>
<prevsection>
<prevsent>{}, ? ??
</prevsent>
<prevsent>{}) using concatenation, probabilistic union +p, and probabilistic closure p. for defining conditional relations, good regexp language is unknown to us, but they can be defined in several other ways: (1) via fsts as in fig.
</prevsent>
</prevsection>
<citsent citstr=" P96-1029 ">
1c, (2) by compilation of weighted rewrite rules (mohri and sproat, 1996), (<papid> P96-1031 </papid>3) by compilation of decision trees(sproat and riley, 1996), (<papid> P96-1029 </papid>4) as relation that performs contextual left-to-right replacement of inputsubstrings by smaller conditional relation (gerdemann and van noord, 1999),<papid> E99-1017 </papid>5 (5) by conditionaliza tion of joint relation as discussed below.</citsent>
<aftsection>
<nextsent>a central technique is to define joint relation as noisy-channel model, by composing joint relation with cascade of one or more conditional relations as in fig.
</nextsent>
<nextsent>1 (pereira and riley, 1997; knight and graehl, 1998).<papid> J98-4003 </papid></nextsent>
<nextsent>the general form is illustrated by 3conceptually, the parameters represent the probabilities of reading another (?); reading another (?); transducing to rather than (?); starting to trans duce to  rather than (?).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5451">
<title id=" P02-1001.xml">parameter estimation for probabilistic finite state transducers </title>
<section> transducers and parameters.  </section>
<citcontext>
<prevsection>
<prevsent>{}, ? ??
</prevsent>
<prevsent>{}) using concatenation, probabilistic union +p, and probabilistic closure p. for defining conditional relations, good regexp language is unknown to us, but they can be defined in several other ways: (1) via fsts as in fig.
</prevsent>
</prevsection>
<citsent citstr=" E99-1017 ">
1c, (2) by compilation of weighted rewrite rules (mohri and sproat, 1996), (<papid> P96-1031 </papid>3) by compilation of decision trees(sproat and riley, 1996), (<papid> P96-1029 </papid>4) as relation that performs contextual left-to-right replacement of inputsubstrings by smaller conditional relation (gerdemann and van noord, 1999),<papid> E99-1017 </papid>5 (5) by conditionaliza tion of joint relation as discussed below.</citsent>
<aftsection>
<nextsent>a central technique is to define joint relation as noisy-channel model, by composing joint relation with cascade of one or more conditional relations as in fig.
</nextsent>
<nextsent>1 (pereira and riley, 1997; knight and graehl, 1998).<papid> J98-4003 </papid></nextsent>
<nextsent>the general form is illustrated by 3conceptually, the parameters represent the probabilities of reading another (?); reading another (?); transducing to rather than (?); starting to trans duce to  rather than (?).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5452">
<title id=" P02-1001.xml">parameter estimation for probabilistic finite state transducers </title>
<section> transducers and parameters.  </section>
<citcontext>
<prevsection>
<prevsent>1c, (2) by compilation of weighted rewrite rules (mohri and sproat, 1996), (<papid> P96-1031 </papid>3) by compilation of decision trees(sproat and riley, 1996), (<papid> P96-1029 </papid>4) as relation that performs contextual left-to-right replacement of inputsubstrings by smaller conditional relation (gerdemann and van noord, 1999),<papid> E99-1017 </papid>5 (5) by conditionaliza tion of joint relation as discussed below.</prevsent>
<prevsent>a central technique is to define joint relation as noisy-channel model, by composing joint relation with cascade of one or more conditional relations as in fig.</prevsent>
</prevsection>
<citsent citstr=" J98-4003 ">
1 (pereira and riley, 1997; knight and graehl, 1998).<papid> J98-4003 </papid></citsent>
<aftsection>
<nextsent>the general form is illustrated by 3conceptually, the parameters represent the probabilities of reading another (?); reading another (?); transducing to rather than (?); starting to trans duce to  rather than (?).
</nextsent>
<nextsent>4to prove (1)?(3), express as an fst and apply the well-known kleene-schutzenberger construction (berstel andreutenauer, 1988), taking care to write each regexp in the construction as constant times probabilistic regexp.
</nextsent>
<nextsent>a full proof is straightforward, as are proofs of (3)?(2), (2)?(1).
</nextsent>
<nextsent>5in (4), the randomness is in the smaller relations choice of how to replace match.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5453">
<title id=" P02-1001.xml">parameter estimation for probabilistic finite state transducers </title>
<section> transducers and parameters.  </section>
<citcontext>
<prevsection>
<prevsent>arbitrary weights such as 2.7may be assigned to arcs or sprinkled through reg exp (to be compiled into :/2.7??
</prevsent>
<prevsent>arcs).
</prevsent>
</prevsection>
<citsent citstr=" J00-1003 ">
a more subtle example is weighted fsas that approximate pcfgs (nederhof, 2000; <papid> J00-1003 </papid>mohri and nederhof, 2001), or to extend the idea, weighted fsts that approximate joint or conditional synchronous pcfgs built for translation.</citsent>
<aftsection>
<nextsent>these are parameterized by the pcfgs parameters, but add or remove strings of the pcfg to leave an improper probability distribution.
</nextsent>
<nextsent>fortunately for those techniques, an fst with positive arc weights can be normalized to make it jointly or conditionally probabilistic: ? an easy approach is to normalize the options ateach state to make the fst markovian.
</nextsent>
<nextsent>unfortunately, the result may differ for equivalent fsts that express the same weighted relation.
</nextsent>
<nextsent>undesirable consequences of this fact have been termed label bias?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5454">
<title id=" P00-1058.xml">statistical parsing with an automatically extracted tree adjoining grammar </title>
<section> abstract </section>
<citcontext>
<prevsection>

<prevsent>we discuss the advantages of lexicalized tree-adjoining grammar as an alternative to lexicalized pcfg forsta tistical parsing, describing the induction of probabilistic ltag model from thepenn treebank and evaluating its parsing performance.
</prevsent>
</prevsection>
<citsent citstr=" P98-1091 ">
we nd that this induction method is an improvement over the em-based method of (hwa, 1998),<papid> P98-1091 </papid>and that the induced model yields results comparable to lexicalized pcfg.</citsent>
<aftsection>
<nextsent>why use tree-adjoining grammar for statistical parsing?
</nextsent>
<nextsent>given that statistical natural language processing is concerned with the probable rather than the possible, it is not because tag can describe constructions like arbitrarily large dutch verb clusters.
</nextsent>
<nextsent>rather, what makes tag useful for statistical parsing arethe structural descriptions it assigns to bread and-butter sentences.
</nextsent>
<nextsent>the approach of chelba and jelinek (1998) <papid> P98-1035 </papid>to language modeling is illustrative: even though the probability estimate of appearing as the kth word can be conditioned on the entire history 1 ; : : : ; k 1 , the quantity of available training data limits the usable context to about two words|but which two?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5455">
<title id=" P00-1058.xml">statistical parsing with an automatically extracted tree adjoining grammar </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>given that statistical natural language processing is concerned with the probable rather than the possible, it is not because tag can describe constructions like arbitrarily large dutch verb clusters.
</prevsent>
<prevsent>rather, what makes tag useful for statistical parsing arethe structural descriptions it assigns to bread and-butter sentences.
</prevsent>
</prevsection>
<citsent citstr=" P98-1035 ">
the approach of chelba and jelinek (1998) <papid> P98-1035 </papid>to language modeling is illustrative: even though the probability estimate of appearing as the kth word can be conditioned on the entire history 1 ; : : : ; k 1 , the quantity of available training data limits the usable context to about two words|but which two?</citsent>
<aftsection>
<nextsent>a trigram model chooses k 1 and k 2 and works quite well; model which chose k 7 and k 11 would probably work less well.
</nextsent>
<nextsent>but (chelba and jelinek, 1998) <papid> P98-1035 </papid>chooses the lexical heads of the two previous constituents as determined by shift-reduce parser, and works better than trigram model.</nextsent>
<nextsent>thus the (vir tual) grammar serves to structure the history so that the two most useful words can be chosen, even though the structure of the problem itself is entirely linear.similarly, nothing about the parsing problem requires that we construct any structure other than phrase structure.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5458">
<title id=" P00-1058.xml">statistical parsing with an automatically extracted tree adjoining grammar </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>but (chelba and jelinek, 1998) <papid> P98-1035 </papid>chooses the lexical heads of the two previous constituents as determined by shift-reduce parser, and works better than trigram model.</prevsent>
<prevsent>thus the (vir tual) grammar serves to structure the history so that the two most useful words can be chosen, even though the structure of the problem itself is entirely linear.similarly, nothing about the parsing problem requires that we construct any structure other than phrase structure.</prevsent>
</prevsection>
<citsent citstr=" P95-1037 ">
but beginning with (magerman, 1995) <papid> P95-1037 </papid>statistical parsers have used bilexical dependencies with great success.</citsent>
<aftsection>
<nextsent>since these dependencies are not encoded in plain phrase-structure trees,the standard approach has been to let the lexical heads percolate up the tree, so that when one lexical head is immediately dominated by another, it is understood to be dependent on it.
</nextsent>
<nextsent>eectively, dependency structure is made parasitic on the phrase structure so that they can be generated together by context-free model.
</nextsent>
<nextsent>however, this solution is not ideal.
</nextsent>
<nextsent>aside from cases where context-free derivations are incapable of encoding both constituency and dependency (which are somewhat isolated and not of great interest for statistical parsing) there are common cases where percolation of single heads is not sucient to encode dependencies correctly|for example, relative clause attachment or raising/auxiliary verbs (see section 3).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5461">
<title id=" P00-1058.xml">statistical parsing with an automatically extracted tree adjoining grammar </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a more suitable approach is to employa grammar formalism which produces structural descriptions that can encode both constituency and dependency.
</prevsent>
<prevsent>lexicalized tag is such formalism, because it assigns to each sentence not only parse tree, whichis built out of elementary trees and is interpreted as encoding constituency, but derivation tree, which records how the various elementary trees were combined together andis commonly intepreted as encoding dependency.
</prevsent>
</prevsection>
<citsent citstr=" C92-2065 ">
the ability of probabilistic ltag to np nnp john np# vp vb leave vp md should vp np nn tomorrow ( 1 ) ( 2 ) ( ) ( ) )  2  1 1 2 2,1 np nnp john vp md should vp vb leave np nn tomorrow figure 1: grammar and derivation for \john should leave tomorrow.  model bilexical dependencies was noted early on by (resnik, 1992).<papid> C92-2065 </papid></citsent>
<aftsection>
<nextsent>it turns out that there are other pieces of contextual information that need to be explicitly accounted for in cfg by grammar transformations but come for free in atag.
</nextsent>
<nextsent>we discuss few such cases in section 3.
</nextsent>
<nextsent>in sections 4 and 5 we describe an experiment to test the parsing accuracy of probabilistic tag extracted automatically from the penn treebank.
</nextsent>
<nextsent>we nd that the automatically-extracted grammar gives an improvement over the em-based induction method of (hwa, 1998),<papid> P98-1091 </papid> and that the parser performs comparably to lexicalized pcfg parsers, though certainly with room for im provement.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5465">
<title id=" P00-1058.xml">statistical parsing with an automatically extracted tree adjoining grammar </title>
<section> the formalism.  </section>
<citcontext>
<prevsection>
<prevsent>(this is where the analogy with (chelba and jelinek, 1998) <papid> P98-1035 </papid>breaks down.)</prevsent>
<prevsent>thus certain possibilities which werenot apparent in pcfg framework or prohibitively complicated might become simple to implement in ptag framework; we conclude by oering two such possibilities.</prevsent>
</prevsection>
<citsent citstr=" J95-4002 ">
the formalism we use is variant of lexicalized tree-insertion grammar (ltig), which is in turn restriction of ltag (schabes and waters, 1995).<papid> J95-4002 </papid></citsent>
<aftsection>
<nextsent>in this variant there are three kinds of elementary tree: initial, (predicative)auxiliary, and modi er, and three composition operations: substitution, adjunction, and sister-adjunction.auxiliary trees and adjunction are restricted as in tig: essentially, no wrapping adjunction or anything equivalent to wrapping adjunction is allowed.
</nextsent>
<nextsent>sister-adjunctionis not an operation found in standard de ni tions of tag, but is borrowed from d-treegrammar (rambow et al, 1995).<papid> P95-1021 </papid></nextsent>
<nextsent>in sister adjunction the root of modi er tree is added as new daughter to any other node.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5466">
<title id=" P00-1058.xml">statistical parsing with an automatically extracted tree adjoining grammar </title>
<section> the formalism.  </section>
<citcontext>
<prevsection>
<prevsent>the formalism we use is variant of lexicalized tree-insertion grammar (ltig), which is in turn restriction of ltag (schabes and waters, 1995).<papid> J95-4002 </papid></prevsent>
<prevsent>in this variant there are three kinds of elementary tree: initial, (predicative)auxiliary, and modi er, and three composition operations: substitution, adjunction, and sister-adjunction.auxiliary trees and adjunction are restricted as in tig: essentially, no wrapping adjunction or anything equivalent to wrapping adjunction is allowed.</prevsent>
</prevsection>
<citsent citstr=" P95-1021 ">
sister-adjunctionis not an operation found in standard de ni tions of tag, but is borrowed from d-treegrammar (rambow et al, 1995).<papid> P95-1021 </papid></citsent>
<aftsection>
<nextsent>in sister adjunction the root of modi er tree is added as new daughter to any other node.
</nextsent>
<nextsent>(notethat as it stands sister-adjunction is completely unconstrained; it will be constrained by the probability model.)
</nextsent>
<nextsent>we introduce this operation simply so we can derive the at structures found in the penn treebank.
</nextsent>
<nextsent>following (schabes and shieber, 1994), <papid> J94-1004 </papid>multiple modi er trees can be sister-adjoined at single site, but only one auxiliary tree may be adjoined at single node.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5467">
<title id=" P00-1058.xml">statistical parsing with an automatically extracted tree adjoining grammar </title>
<section> the formalism.  </section>
<citcontext>
<prevsection>
<prevsent>(notethat as it stands sister-adjunction is completely unconstrained; it will be constrained by the probability model.)
</prevsent>
<prevsent>we introduce this operation simply so we can derive the at structures found in the penn treebank.
</prevsent>
</prevsection>
<citsent citstr=" J94-1004 ">
following (schabes and shieber, 1994), <papid> J94-1004 </papid>multiple modi er trees can be sister-adjoined at single site, but only one auxiliary tree may be adjoined at single node.</citsent>
<aftsection>
<nextsent>figure 1 shows an example grammar and the derivation of the sentence \john should leave tomorrow.
</nextsent>
<nextsent>the derivation tree encodes this process, with each arc corresponding to composition operation.
</nextsent>
<nextsent>arcs corresponding to substitution and adjunction are labeled with the gorn address 1of the substitution or ad 1 gorn address is list of integers: the root of tree has address , and the jth child of the node with junction site.
</nextsent>
<nextsent>an arc corresponding to the sister-adjunction of tree between the ith andi + 1th children of  (allowing for two imaginary children beyond the left most and right most children) is labeled ; i. this grammar, as well as the grammar used by the parser, is lexicalized in the sense that every elementary tree has exactly one terminal node, its lexical anchor.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5469">
<title id=" P00-1058.xml">statistical parsing with an automatically extracted tree adjoining grammar </title>
<section> the formalism.  </section>
<citcontext>
<prevsection>
<prevsent>since sister-adjunction can be simulated by ordinary adjunction, this variant is, like tig (and cfg), weakly context-free and o(n 3 )-time parsable.
</prevsent>
<prevsent>rather than coin new acronym for this particular variant, we will simply refer to it as \tag  and trust that no confusion will arise.
</prevsent>
</prevsection>
<citsent citstr=" C92-2066 ">
the parameters of probabilistic tag (resnik, 1992; <papid> C92-2065 </papid>schabes, 1992) <papid> C92-2066 </papid>are:  i () = 1  s ( ) = 1 p ( ) + a (none ) = 1where  ranges over initial trees, over auxiliary trees, over modi er trees, and  over nodes.</citsent>
<aftsection>
<nextsent>p () is the probability of beginning derivation with ; s( ) is the probability of substituting  at ; a ( ) is the probability of adjoining at ; nally, a (none ) is the probability of nothing adjoining at .
</nextsent>
<nextsent>(carroll and weir, 1997) suggest other parameterizations worth exploring as well.
</nextsent>
<nextsent>our variant adds another set of parameters: p sa ( ; i; f) + sa (stop ; i; f) = 1 this is the probability of sister-adjoining between the ith and + 1th children of  (as before, allowing for two imaginary children beyond the left most and rightmost children).
</nextsent>
<nextsent>since multiple modi er trees can adjoin at the same location, sa ( ) is also conditioned on ag which indicates whether is the rst modi er tree (i.e., the one closest to the head) to adjoin at that location.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5474">
<title id=" P00-1058.xml">statistical parsing with an automatically extracted tree adjoining grammar </title>
<section> some properties of probabilistic.  </section>
<citcontext>
<prevsection>
<prevsent>a more complex lexicalization scheme for cfg could as well (one which kept track of two heads at time, for example), but the tag account is simpler and cleaner.
</prevsent>
<prevsent>bilexical dependencies are not the only non local dependencies that can be used to improve parsing accuracy.
</prevsent>
</prevsection>
<citsent citstr=" J98-4004 ">
for example, the attachment of an depends on the presence or absence of the embedded subject (collins,1999); treebank-style two-level nps are mis modeled by pcfg (collins, 1999; johnson, 1998); <papid> J98-4004 </papid>the generation of node depends on the label of its grandparent (charniak, 2000; <papid> A00-2018 </papid>johnson, 1998).<papid> J98-4004 </papid></citsent>
<aftsection>
<nextsent>in order to capture such dependencies in pcfg-based model, they must be localized either by transforming the data or modifying the parser.
</nextsent>
<nextsent>such changes are not always obvious priori and often must be devised anew for each language or each corpus.
</nextsent>
<nextsent>but none of these cases really requires special treatment in ptag model, be cause each composition probability involve snot only bilexical dependency but \biarbo real  (tree-tree) dependency.
</nextsent>
<nextsent>that is, ptag generates an entire elementary tree at once,conditioned on the entire elementary tree being modi ed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5475">
<title id=" P00-1058.xml">statistical parsing with an automatically extracted tree adjoining grammar </title>
<section> some properties of probabilistic.  </section>
<citcontext>
<prevsection>
<prevsent>a more complex lexicalization scheme for cfg could as well (one which kept track of two heads at time, for example), but the tag account is simpler and cleaner.
</prevsent>
<prevsent>bilexical dependencies are not the only non local dependencies that can be used to improve parsing accuracy.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
for example, the attachment of an depends on the presence or absence of the embedded subject (collins,1999); treebank-style two-level nps are mis modeled by pcfg (collins, 1999; johnson, 1998); <papid> J98-4004 </papid>the generation of node depends on the label of its grandparent (charniak, 2000; <papid> A00-2018 </papid>johnson, 1998).<papid> J98-4004 </papid></citsent>
<aftsection>
<nextsent>in order to capture such dependencies in pcfg-based model, they must be localized either by transforming the data or modifying the parser.
</nextsent>
<nextsent>such changes are not always obvious priori and often must be devised anew for each language or each corpus.
</nextsent>
<nextsent>but none of these cases really requires special treatment in ptag model, be cause each composition probability involve snot only bilexical dependency but \biarbo real  (tree-tree) dependency.
</nextsent>
<nextsent>that is, ptag generates an entire elementary tree at once,conditioned on the entire elementary tree being modi ed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5478">
<title id=" P00-1058.xml">statistical parsing with an automatically extracted tree adjoining grammar </title>
<section> inducing stochastic grammar.  </section>
<citcontext>
<prevsection>
<prevsent>of course, the price that the ptag model pays is sparser data; the backo model must therefore be chosen carefully.
</prevsent>
<prevsent>from the treebank 4.1 reconstructing derivations.
</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
we want to extract from the penn tree bank an ltag whose derivations mirror the dependency analysis implicit in the head-percolation rules of (magerman, 1995; <papid> P95-1037 </papid>collins, 1997).<papid> P97-1003 </papid></citsent>
<aftsection>
<nextsent>for each node , these rules classify exactly one child of  as head andthe rest as either arguments or adjuncts.
</nextsent>
<nextsent>using this classi cation we can construct tag derivation (including elementary trees) from derived tree as follows: 1.
</nextsent>
<nextsent>if  is an adjunct, excise the subtree.
</nextsent>
<nextsent>rooted at  to form modi er tree.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5479">
<title id=" P00-1058.xml">statistical parsing with an automatically extracted tree adjoining grammar </title>
<section> inducing stochastic grammar.  </section>
<citcontext>
<prevsection>
<prevsent>the generation of the tree template has two backo levels: at the rst level, the anchor of  is ignored, and at the second level, the pos tag of the anchor as well as the ag are ignored.
</prevsent>
<prevsent>the generation of the anchor has three backo levels: the rst two are as before, and the third just conditions the anchor on its pos tag.
</prevsent>
</prevsection>
<citsent citstr=" A97-1029 ">
the backed-o models are combined by linear interpolation, with the weights chosen as in (bikel et al, 1997).<papid> A97-1029 </papid></citsent>
<aftsection>
<nextsent>5.1 extracting the grammar.
</nextsent>
<nextsent>we ran the algorithm given in section 4.1 on sections 02{21 of the penn treebank.
</nextsent>
<nextsent>the extracted grammar is large (about 73,000 trees,with words seen fewer than four times replaced with the symbol *unknown*), but if we 1 10 100 1000 10000 100000 1 10 100 1000 10000 fr eq ue nc rank figure 4: frequency of tree templates versus rank (log-log)consider elementary tree templates, the grammar is quite manageable: 3626 tree templates,of which 2039 occur more than once (see figure 4).
</nextsent>
<nextsent>the 616 most frequent tree-template types account for 99% of tree-template tokens in the training data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5480">
<title id=" P00-1058.xml">statistical parsing with an automatically extracted tree adjoining grammar </title>
<section> the experiment.  </section>
<citcontext>
<prevsection>
<prevsent>we used cky-style parser similar to the one described in (schabes and waters, 1996), witha modi cation to ensure completeness (be cause foot nodes are treated as empty, which cky prohibits) and another to reduce useless substitutions.
</prevsent>
<prevsent>we also extended the parser to simulate sister-adjunction as regular adjunction and compute the ag which distinguishes the rst modi er from subsequent modi ers.
</prevsent>
</prevsection>
<citsent citstr=" W97-0302 ">
we use beam search, computing the score of an item [; i; j] by multiplying it by the prior probability () (goodman, 1997); <papid> W97-0302 </papid>any item with scoreless than 10  5 times that of the best item in cell is pruned.following (collins, 1997), <papid> P97-1003 </papid>words occur ring fewer than four times in training were replaced with the symbol *unknown* and tagged with the output of the part-of-speech tagger described in (ratnaparkhi, 1996).<papid> W96-0213 </papid></citsent>
<aftsection>
<nextsent>tree templates occurring only once in training were ignored entirely.
</nextsent>
<nextsent>we rst compared the parser with (hwa, 1998): <papid> P98-1091 </papid>we trained the model on sentences of length 40 or less in sections 02{09 of the penn treebank, down to parts of speech only, and then tested on sentences of length 40 or less in section 23, parsing from part-of-speech tag sequences to fully bracketed parses.</nextsent>
<nextsent>the metric used was the percentage of guessed brackets which did not cross any correct brackets.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5482">
<title id=" P00-1058.xml">statistical parsing with an automatically extracted tree adjoining grammar </title>
<section> the experiment.  </section>
<citcontext>
<prevsection>
<prevsent>we used cky-style parser similar to the one described in (schabes and waters, 1996), witha modi cation to ensure completeness (be cause foot nodes are treated as empty, which cky prohibits) and another to reduce useless substitutions.
</prevsent>
<prevsent>we also extended the parser to simulate sister-adjunction as regular adjunction and compute the ag which distinguishes the rst modi er from subsequent modi ers.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
we use beam search, computing the score of an item [; i; j] by multiplying it by the prior probability () (goodman, 1997); <papid> W97-0302 </papid>any item with scoreless than 10  5 times that of the best item in cell is pruned.following (collins, 1997), <papid> P97-1003 </papid>words occur ring fewer than four times in training were replaced with the symbol *unknown* and tagged with the output of the part-of-speech tagger described in (ratnaparkhi, 1996).<papid> W96-0213 </papid></citsent>
<aftsection>
<nextsent>tree templates occurring only once in training were ignored entirely.
</nextsent>
<nextsent>we rst compared the parser with (hwa, 1998): <papid> P98-1091 </papid>we trained the model on sentences of length 40 or less in sections 02{09 of the penn treebank, down to parts of speech only, and then tested on sentences of length 40 or less in section 23, parsing from part-of-speech tag sequences to fully bracketed parses.</nextsent>
<nextsent>the metric used was the percentage of guessed brackets which did not cross any correct brackets.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5488">
<title id=" P00-1058.xml">statistical parsing with an automatically extracted tree adjoining grammar </title>
<section> the experiment.  </section>
<citcontext>
<prevsection>
<prevsent>these results place our parser roughly in the middle of the lexicalized pcfg parsers.
</prevsent>
<prevsent>while the results are not state-of-the-art, they do demonstrate the viability of tag as framework for statistical parsing.
</prevsent>
</prevsection>
<citsent citstr=" P96-1025 ">
with  40 words  100 words lr lp cb 0 cb  2 cb lr lp cb 0 cb  2 cb (magerman, 1995) <papid> P95-1037 </papid>84.6 84.9 1.26 56.6 81.4 84.0 84.3 1.46 54.0 78.8 (collins, 1996) <papid> P96-1025 </papid>85.8 86.3 1.14 59.9 83.6 85.3 85.7 1.32 57.2 80.8 present model 86.9 86.6 1.09 63.2 84.3 86.2 85.8 1.29 60.4 81.8 (collins, 1997) <papid> P97-1003 </papid>88.1 88.6 0.91 66.5 86.9 87.5 88.1 1.07 63.9 84.6 (charniak, 2000) <papid> A00-2018 </papid>90.1 90.1 0.74 70.1 89.6 89.6 89.5 0.88 67.6 87.7 figure 6: parsing results.</citsent>
<aftsection>
<nextsent>lr = labeled recall, lp = labeled precision; cb = average crossing brackets, 0 cb = no crossing brackets,  2 cb = two or fewer crossing brackets.
</nextsent>
<nextsent>all gures except cb are percentages.improvements in smoothing and cleaner handling of punctuation and coordination, perhaps these results can be brought more up to-date.
</nextsent>
<nextsent>work (neumann, 1998) describes an experiment similar to ours, although the grammar he extracts only arrives at complete parse for 10% of unseen sentences.
</nextsent>
<nextsent>(xia, 1999) describes grammar extraction process similar to ours,and describes some techniques for automatically ltering out invalid elementary trees.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5491">
<title id=" P04-1083.xml">statistical machine translation by parsing </title>
<section> multi text grammars and multi trees.  </section>
<citcontext>
<prevsection>
<prevsent>it culminates with recipe for using these algorithms to train and apply syntax-aware statistical machine translation (smt) system.
</prevsent>
<prevsent>the algorithms in this paper can be adapted for any synchronous grammar formalism.
</prevsent>
</prevsection>
<citsent citstr=" N03-1021 ">
the vehicle for the present guided tour shall be multi text grammar (mtg), which is generalization of context-free grammar to the synchronous case (melamed, 2003).<papid> N03-1021 </papid></citsent>
<aftsection>
<nextsent>we shall limit our attention to mtgs in generalized chomsky normal form (gcnf) (melamed et al, 2004).<papid> P04-1084 </papid></nextsent>
<nextsent>this normal form allows simpler algorithm descriptions than the normal forms used by wu (1997) <papid> J97-3002 </papid>and melamed (2003)<papid> N03-1021 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5492">
<title id=" P04-1083.xml">statistical machine translation by parsing </title>
<section> multi text grammars and multi trees.  </section>
<citcontext>
<prevsection>
<prevsent>the algorithms in this paper can be adapted for any synchronous grammar formalism.
</prevsent>
<prevsent>the vehicle for the present guided tour shall be multi text grammar (mtg), which is generalization of context-free grammar to the synchronous case (melamed, 2003).<papid> N03-1021 </papid></prevsent>
</prevsection>
<citsent citstr=" P04-1084 ">
we shall limit our attention to mtgs in generalized chomsky normal form (gcnf) (melamed et al, 2004).<papid> P04-1084 </papid></citsent>
<aftsection>
<nextsent>this normal form allows simpler algorithm descriptions than the normal forms used by wu (1997) <papid> J97-3002 </papid>and melamed (2003)<papid> N03-1021 </papid></nextsent>
<nextsent>in gcnf, every production is either terminal production or nonterminal production.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5493">
<title id=" P04-1083.xml">statistical machine translation by parsing </title>
<section> multi text grammars and multi trees.  </section>
<citcontext>
<prevsection>
<prevsent>the vehicle for the present guided tour shall be multi text grammar (mtg), which is generalization of context-free grammar to the synchronous case (melamed, 2003).<papid> N03-1021 </papid></prevsent>
<prevsent>we shall limit our attention to mtgs in generalized chomsky normal form (gcnf) (melamed et al, 2004).<papid> P04-1084 </papid></prevsent>
</prevsection>
<citsent citstr=" J97-3002 ">
this normal form allows simpler algorithm descriptions than the normal forms used by wu (1997) <papid> J97-3002 </papid>and melamed (2003)<papid> N03-1021 </papid></citsent>
<aftsection>
<nextsent>in gcnf, every production is either terminal production or nonterminal production.
</nextsent>
<nextsent>a nonterminal production might look like this:             a d(2)  fffi (1) there are nonterminals on the left-hand side (lhs) and in parentheses on the right-hand side (rhs).
</nextsent>
<nextsent>each row of the production describes rewriting in different component text of multitext.
</nextsent>
<nextsent>in each row, role template describes the relative order and contiguity of the rhs nonterminals.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5497">
<title id=" P04-1083.xml">statistical machine translation by parsing </title>
<section> multi text grammars and multi trees.  </section>
<citcontext>
<prevsection>
<prevsent>dishes the wash moy pasudu np nv wash dish pas mit nnp ministic: they do not indicate the order in which parser should attempt inferences.
</prevsent>
<prevsent>a deterministic parsing strategy can always be chosen later, to suitthe application.
</prevsent>
</prevsection>
<citsent citstr=" J99-4004 ">
we presume that readers are familiar with declarative descriptions of inference algorithms, as well as with semi ring parsing (goodman, 1999).<papid> J99-4004 </papid></citsent>
<aftsection>
<nextsent>figure 3 shows logic c. parser is any parser based on logic c. as in melamed (2003)<papid> N03-1021 </papid>s parser a, parser cs items consist of   -dimensional label vector 213 and  -dimensional d-span vector 4 13 .2 the items contain d-spans, rather than ordinary spans, because2superscripts and sub scripts indicate the range of dimensions of vector.</nextsent>
<nextsent>e.g., 5-67 is vector spanning dimensions 1 through 8 . see melamed (2003)<papid> N03-1021 </papid> for definitions of cardinality, d-span, and the operators 9 and : . parser needs to know all the boundaries of each item, not just the outermost boundaries.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5503">
<title id=" P04-1083.xml">statistical machine translation by parsing </title>
<section> a synchronous cky parser </section>
<citcontext>
<prevsection>
<prevsent>1 +    10 1 3 34 4 5 67 7 8  1 /.
</prevsent>
<prevsent>1   10 1 3 2  1 /.
</prevsent>
</prevsection>
<citsent citstr=" J00-1004 ">
1  9    10 1 3 : ; ;   compose: =? a@ bdc @ bgf =#h%@ bdc @ bgf$jlk nm @ blc @ bpoqi @   r@  h%@ ! @ c @ b%s @  figure 3: logic (c? for cky)these constraints are enforced by the d-span operators and .parser is conceptually simpler than the synchronous parsers of wu (1997), <papid> J97-3002 </papid>alshawi et al (2000), <papid> J00-1004 </papid>and melamed (2003)<papid> N03-1021 </papid>, because it uses only one kind of item, and it never composes terminals.the inference rules of logic are the multidimensional generalizations of inference rules with thesame names in ordinary cky parsers.</citsent>
<aftsection>
<nextsent>for example, given suitable grammar and the input (imper ative) sentence pair wash the dishes / pasudu moy, parser might make the 9 inferences in figure 4 to infer the multi tree in figure 2.
</nextsent>
<nextsent>note that there is one inference per internal node of the multitree.
</nextsent>
<nextsent>goodman (1999) <papid> J99-4004 </papid>shows how parsing logic canbe combined with various semi rings to compute different kinds of information about the input.</nextsent>
<nextsent>depending on the chosen semi ring, parsing logic can compute the single most probable derivation and/or its probability, the most probable derivations and/or their total probability, all possible derivationsand/or their total probability, the number of possible derivations, etc. all the parsing semi rings catalogued by goodman apply the same way to synchronous parsing, and to all the other classes of algorithms discussed in this paper.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5509">
<title id=" P04-1083.xml">statistical machine translation by parsing </title>
<section> a synchronous cky parser </section>
<citcontext>
<prevsection>
<prevsent>under such an mtg, the logic of word alignment is the one in melamed (2003)<papid> N03-1021 </papid>s parser a, but without compose inferences.</prevsent>
<prevsent>the only other difference is that, instead of single item, the goal of word alignment is any set of items that covers all dimensions of the input.</prevsent>
</prevsection>
<citsent citstr=" P02-1001 ">
this logic can be used with the expectation semi ring (eisner, 2002) <papid> P02-1001 </papid>to find the maximum likelihood estimates of the parameters of word-to-word translation model.</citsent>
<aftsection>
<nextsent>an important application of parser is parameter estimation for probabilistic mtgs (pmtgs).
</nextsent>
<nextsent>eisner (2002) <papid> P02-1001 </papid>has claimed that parsing under an expectation semi ring is equivalent to the inside-outsidealgorithm for pcfgs.</nextsent>
<nextsent>if so, then there is straightforward generalization for pmtgs.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5513">
<title id=" P04-1083.xml">statistical machine translation by parsing </title>
<section> synchronization.  </section>
<citcontext>
<prevsection>
<prevsent>only one synchronous dependency structure (dashed arrows) is compatible with the monolingual structure (solid arrows) and word alignment (shaded cells).
</prevsent>
<prevsent>if we have no suitable pmtg, then we can use other criteria to search for trees that have high probability.we shall consider the common synchronization scenario where lexicalized monolingual grammar is available for at least one component.5 also, given tokenized set of -tuples of parallel sentences, it is always possible to estimate word-to-word translation model
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
3 1  ) 3 0 1  (e.g., och &amp; ney, 2003).<papid> J03-1002 </papid>6a word-to-word translation model and lexicalized monolingual grammar are sufficient to drive asynchronizer.</citsent>
<aftsection>
<nextsent>for example, in figure 6 monolingual grammar has allowed only one dependency structure on the english side, and word-to-wordtranslation model has allowed only one word alignment.
</nextsent>
<nextsent>the syntactic structures of all dimensions of multi tree are isomorphic up to reordering of sibling nodes and deletion.
</nextsent>
<nextsent>so, given fixed correspondence between the tree leaves (i.e. words) across components, choosing the optimal structure for one component is tantamount to choosing the optimal synchronous structure for all components.7ignoring the nonterminal labels, only one dependency structure is compatible with these constraints?
</nextsent>
<nextsent>the one indicated by dashed arrows.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5514">
<title id=" P04-1083.xml">statistical machine translation by parsing </title>
<section> synchronization.  </section>
<citcontext>
<prevsection>
<prevsent>so, given fixed correspondence between the tree leaves (i.e. words) across components, choosing the optimal structure for one component is tantamount to choosing the optimal synchronous structure for all components.7ignoring the nonterminal labels, only one dependency structure is compatible with these constraints?
</prevsent>
<prevsent>the one indicated by dashed arrows.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
bootstrapping pmtg from lower-dimensional pmtg and word-to-word translation model is similar in spirit to the way that regular grammars can help to estimate cfgs (lari &amp; young, 1990), and the way that simple translation models can help to bootstrap more sophisticated ones (brown et al, 1993).<papid> J93-2003 </papid>5such grammar can be induced from treebank, for exam ple.</citsent>
<aftsection>
<nextsent>we are currently aware of treebanks for english, spanish, german, chinese, czech, arabic, and korean.6although most of the literature discusses word translation models between only two languages, it is possible to combine several 2d models into higher-dimensional model (mann &amp; yarowsky, 2001).<papid> N01-1020 </papid></nextsent>
<nextsent>7except where the unstructured components have words that are linked to nothing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5515">
<title id=" P04-1083.xml">statistical machine translation by parsing </title>
<section> synchronization.  </section>
<citcontext>
<prevsection>
<prevsent>the one indicated by dashed arrows.
</prevsent>
<prevsent>bootstrapping pmtg from lower-dimensional pmtg and word-to-word translation model is similar in spirit to the way that regular grammars can help to estimate cfgs (lari &amp; young, 1990), and the way that simple translation models can help to bootstrap more sophisticated ones (brown et al, 1993).<papid> J93-2003 </papid>5such grammar can be induced from treebank, for exam ple.</prevsent>
</prevsection>
<citsent citstr=" N01-1020 ">
we are currently aware of treebanks for english, spanish, german, chinese, czech, arabic, and korean.6although most of the literature discusses word translation models between only two languages, it is possible to combine several 2d models into higher-dimensional model (mann &amp; yarowsky, 2001).<papid> N01-1020 </papid></citsent>
<aftsection>
<nextsent>7except where the unstructured components have words that are linked to nothing.
</nextsent>
<nextsent>we need only redefine the terms in way that does not relyon an -pmtg.
</nextsent>
<nextsent>without loss of generality, we shall assume   -pmtg that ranges over the first   components, where   w . we shall then refer to the   structured components and the    unstructured components.
</nextsent>
<nextsent>we begin with a . for the structured components       , we retain the grammar based definition:
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5516">
<title id=" P04-1083.xml">statistical machine translation by parsing </title>
<section> synchronization.  </section>
<citcontext>
<prevsection>
<prevsent>we can use these definitions of the grammar terms in the inference rules of logic to synchronize multi texts into multitreebanks.
</prevsent>
<prevsent>more sophisticated synchronization methods are certainly possible.
</prevsent>
</prevsection>
<citsent citstr=" N01-1026 ">
for example, we could project part-of-speech tagger (yarowsky &amp; ngai, 2001)<papid> N01-1026 </papid>to improve our estimates in equation 6.</citsent>
<aftsection>
<nextsent>yet, despite their relative simplicity, the above methods for estimating production rule probabilities use allof the available information inconsistent manner, without double-counting.
</nextsent>
<nextsent>this kind of synchro nizer stands in contrast to more ad-hoc approaches (e.g., matsumoto, 1993; meyers, 1996; wu, 1998; hwa et al, 2002).<papid> P02-1050 </papid></nextsent>
<nextsent>some of these previous works fix the word alignments first, and then infer compatible parse structures.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5517">
<title id=" P04-1083.xml">statistical machine translation by parsing </title>
<section> synchronization.  </section>
<citcontext>
<prevsection>
<prevsent>for example, we could project part-of-speech tagger (yarowsky &amp; ngai, 2001)<papid> N01-1026 </papid>to improve our estimates in equation 6.</prevsent>
<prevsent>yet, despite their relative simplicity, the above methods for estimating production rule probabilities use allof the available information inconsistent manner, without double-counting.</prevsent>
</prevsection>
<citsent citstr=" P02-1050 ">
this kind of synchro nizer stands in contrast to more ad-hoc approaches (e.g., matsumoto, 1993; meyers, 1996; wu, 1998; hwa et al, 2002).<papid> P02-1050 </papid></citsent>
<aftsection>
<nextsent>some of these previous works fix the word alignments first, and then infer compatible parse structures.
</nextsent>
<nextsent>others do the opposite.
</nextsent>
<nextsent>information about syntactic structure can be inferred more accurately given information about translational equivalence, and vice versa.
</nextsent>
<nextsent>commitment to either kind of information without consideration ofthe other increases the potential for compounded errors.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5520">
<title id=" P04-1052.xml">generating referring expressions in open domains </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>entities in the real world are logically represented; for example (ignoring quantifiers), big brown dog might be represented as big1(x) ? brown1(x) ? dog1(x), where the predicates big1, brown1 and dog1 represent different attributes of the variable (entity) x. the task of referring expression generation has traditionally been framed as the identification of the shortest logical description for the referent entity that differentiates it from all other entities in the discourse do main.
</prevsent>
<prevsent>for example, if there were small brown dog (small1(x) ? brown1(x) ? dog1(x)) in context, the minimal description for the big brown dog would be big1(x) ? dog1(x)1.this semantic framework makes it difficult to apply existing referring expression generation algorithms to the many regeneration tasks that are important today; for example, summarisation, open ended question answering and text simplification.
</prevsent>
</prevsection>
<citsent citstr=" C92-1038 ">
unlike in traditional generation, the starting point in1the predicate dog1 is selected because it has distinguished status, referred to as type in reiter and dale (1992).<papid> C92-1038 </papid></citsent>
<aftsection>
<nextsent>one such predicate has to to be present in the description.these tasks is unrestricted text, rather than semantic representation of small domain.
</nextsent>
<nextsent>it is difficult to extract the required semantics from unrestricted text (this task would require sense disambiguation, among other issues) and even harder to construct classification for the extracted predicates in the manner that existing approaches require (cf., 2).in this paper, we present an algorithm for generating referring expressions in open domains.
</nextsent>
<nextsent>we discuss the literature and detail the problems in applying existing approaches to reference generation to open domains in 2.
</nextsent>
<nextsent>we then present our approach in 3, contrasting it with existing approaches.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5522">
<title id=" P04-1052.xml">generating referring expressions in open domains </title>
<section> overview of prior approaches.  </section>
<citcontext>
<prevsection>
<prevsent>type dog size large colour brown ? ?
</prevsent>
<prevsent>type dog size large colour black ? ?
</prevsent>
</prevsection>
<citsent citstr=" E03-1017 ">
assuming that the *preferred-attributes* list is[size, colour, ...], the algorithm would first compare the values of the size attribute (both large), disregard that attribute as not being discriminating,compare the values of the colour attribute andre turn the brown dog.subsequent work on referring expression generation has expanded the logical framework to allow reference by negation (the dog that is not black) and references to multiple entities (the brown or black dogs) (van deemter, 2002), explored different search algorithms for finding the minimal description (e.g., horacek (2003)) <papid> E03-1017 </papid>and offered different representation frameworks like graph theory (krah mer et al, 2003) <papid> J03-1003 </papid>as alternatives to avms.</citsent>
<aftsection>
<nextsent>however,all these approaches are based on very similar formalisations of the problem, and all make the following assumptions: 1.
</nextsent>
<nextsent>a semantic representation exists.
</nextsent>
<nextsent>2.
</nextsent>
<nextsent>a classification scheme for attributes exists.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5523">
<title id=" P04-1052.xml">generating referring expressions in open domains </title>
<section> overview of prior approaches.  </section>
<citcontext>
<prevsection>
<prevsent>type dog size large colour brown ? ?
</prevsent>
<prevsent>type dog size large colour black ? ?
</prevsent>
</prevsection>
<citsent citstr=" J03-1003 ">
assuming that the *preferred-attributes* list is[size, colour, ...], the algorithm would first compare the values of the size attribute (both large), disregard that attribute as not being discriminating,compare the values of the colour attribute andre turn the brown dog.subsequent work on referring expression generation has expanded the logical framework to allow reference by negation (the dog that is not black) and references to multiple entities (the brown or black dogs) (van deemter, 2002), explored different search algorithms for finding the minimal description (e.g., horacek (2003)) <papid> E03-1017 </papid>and offered different representation frameworks like graph theory (krah mer et al, 2003) <papid> J03-1003 </papid>as alternatives to avms.</citsent>
<aftsection>
<nextsent>however,all these approaches are based on very similar formalisations of the problem, and all make the following assumptions: 1.
</nextsent>
<nextsent>a semantic representation exists.
</nextsent>
<nextsent>2.
</nextsent>
<nextsent>a classification scheme for attributes exists.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5524">
<title id=" P04-1052.xml">generating referring expressions in open domains </title>
<section> the linguistic realisations are unambiguous..  </section>
<citcontext>
<prevsection>
<prevsent>in given context.
</prevsent>
<prevsent>let be the maximum number of entities in the contrast set and be the maximum number of attributes per entity.
</prevsent>
</prevsection>
<citsent citstr=" P90-1013 ">
the table below compares the computational complexity of an optimal algorithm (such as reiter (1990)), <papid> P90-1013 </papid>our algorithm and the ia. incremental algo our algorithm optimal algo o(nn) o(n2n) o(n2n ) both the ia and our algorithm are linear in the number of entities . this is because neither algorithm allows backtracking; an attribute, once selected, cannot be discarded.</citsent>
<aftsection>
<nextsent>in contrast, an optimal search requires o(2n ) comparisons.
</nextsent>
<nextsent>as our algorithm compares each attribute of the discourse referent to every attribute of every dis tractor, it is quadratic in n. the ia compares each attribute ofthe discourse referent to only one attribute per dis tractor and is linear in n. note, however, that values for of over 4 are rare.
</nextsent>
<nextsent>3.3 relations.
</nextsent>
<nextsent>semantically, attributes describe an entity (e.g., the small grey dog) and relations relate an entity to other entities (e.g., the dog in the bin).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5525">
<title id=" P04-1052.xml">generating referring expressions in open domains </title>
<section> the linguistic realisations are unambiguous..  </section>
<citcontext>
<prevsection>
<prevsent>relations are troublesome because in relating an entity eo toe1, we need to recursively generate referring expression for e1.
</prevsent>
<prevsent>the ia does not consider relation sand the referring expression is constructed out of attributes alone.
</prevsent>
</prevsection>
<citsent citstr=" E91-1028 ">
the dale and haddock (1991) <papid> E91-1028 </papid>algorithm allows for relational descriptions but involves exponential global search, or greedy search ap proximation.</citsent>
<aftsection>
<nextsent>to incorporate relational description sin the incremental framework would require classification system which somehow takes into account the relations themselves and the secondary entitiese1 etc. this again suggests that the existing algorithms force the incrementality at the wrong stage in the generation process.
</nextsent>
<nextsent>our approach computes the order in which attributes are incorporated after observing the context, by quantifying their utility through the quotient dq.
</nextsent>
<nextsent>this makes it easy forus to extend our algorithm to handle relations, be cause we can compute dq for relations in much the same way as we did for attributes.we illustrate this for prepositions.
</nextsent>
<nextsent>3.4 calculating dq for relations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5526">
<title id=" P04-1052.xml">generating referring expressions in open domains </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>to generate referring expression for e1 (full purchasing agents report) when the dis tractor iseo(report by chicago purchasing agents), our algorithm again flattens eo to obtain: dqagents = 4, dqpurchasing = 4 dqfull = 4 the generated referring expression is the full report.
</prevsent>
<prevsent>this is identical to the referring expression used in the original text.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
as our algorithm works in open domains, we were able to perform corpus-based evaluation using thepenn wsj treebank (marcus et al, 1993).<papid> J93-2004 </papid></citsent>
<aftsection>
<nextsent>our evaluation aimed to reproduce existing referring expressions (nps with definite determiner) in the penn treebank by providing our algorithm as input: 1.
</nextsent>
<nextsent>the first mention np for that reference..
</nextsent>
<nextsent>2.
</nextsent>
<nextsent>the contrast set of dis tractor nps.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5527">
<title id=" P02-1047.xml">an unsupervised approach to recognizing discourse relations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(2) in these examples, the discourse markers but and because help us figure out that contrast relation holds between the text spans in (1) and an explanation-evidence relation holds between the spans in (2).
</prevsent>
<prevsent>unfortunately, cue phrases do not signal all relations in text.
</prevsent>
</prevsection>
<citsent citstr=" W01-1605 ">
in the corpus of rhetorical structure trees (www.isi.edu/ marcu/discourse/) built by carlson et al  (2001), <papid> W01-1605 </papid>for example, we have observed that only 61 of 238 contrast relation sand 79 out of 307 explanation-evidence relations that hold between two adjacent clauses were marked by cue phrase.</citsent>
<aftsection>
<nextsent>so what shall we do when no discourse markers are used?
</nextsent>
<nextsent>if we had access to robust semantic interpreters, we could, for example, infer from sentence 1.a that cannot buy arms legally(libya)?, infer from sentence 1.b that can buy arms legally(rwanda)?, use our background knowledge in order to infer that similar(libya,rwanda)?, and apply hobbss (1990) definitions of discourse relations to arrive at the conclusion that contrast relation holds between the sentences in (1).
</nextsent>
<nextsent>unfortunately, the state of the art in nlp does not provide us access to semantic interpreters and general purpose knowledge bases that would support these kinds of inferences.
</nextsent>
<nextsent>the discourse relation definitions proposed by computational linguistics (acl), philadelphia, july 2002, pp.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5529">
<title id=" P02-1047.xml">an unsupervised approach to recognizing discourse relations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>or what contradicts y??, which are beyond the state of the art of current systems (trec, 2001).
</prevsent>
<prevsent>in this paper, we describe experiments aimed at building robust discourse-relation classification systems.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
to build such systems, we train family of naive bayes classifiers on large set of examples that are generated automatically from two corpora: corpus of 41,147,805 english sentences that have no annotations, and blipp, corpus of 1,796,386 automatically parsed english sentences (charniak, 2000), <papid> A00-2018 </papid>which is available from the linguistic data consortium (www.ldc.upenn.edu).</citsent>
<aftsection>
<nextsent>we study empirically the adequacy of various features for the task of discourse relation classification and we show that some discourse relations can be correctly recognized with accuracies as high as 93%.
</nextsent>
<nextsent>generation of training data 2.1 background.
</nextsent>
<nextsent>in order to build discourse relation classifier, one first needs to decide what relation definitions one is going to use.
</nextsent>
<nextsent>in section 1, we simply relied onthe readers intuition when we claimed that contrast relation holds between the sentences in (1).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5540">
<title id=" P02-1047.xml">an unsupervised approach to recognizing discourse relations </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>when we run our causeexplanation-evidence vs. elaboration classifier on these examples, we labeled correctly 73 of the 79 cue-phrase-marked relations and 102 of the 228 unmarked relations.
</prevsent>
<prevsent>this corresponds to an increase inaccuracy from eeg?]e_ec+eha ^@[b to  ee_uav\ c?^ffi]e_ec+eiakje@b .
</prevsent>
</prevsection>
<citsent citstr=" P01-1005 ">
in seminal paper, banko and brill (2001) <papid> P01-1005 </papid>have recently shown that massive amounts of data can be used to significantly increase the performance of confusion set disambiguators.</citsent>
<aftsection>
<nextsent>in our paper, weshow that massive amounts of data can have major impact on discourse processing research as well.our experiments show that discourse relation classifiers that use very simple features achieve unexpectedly high levels of performance when trained on extremely large datasets.
</nextsent>
<nextsent>developing lower-noise methods for automatically collecting training data and discovering features of higher predictive power for discourse relation classification than the features presented in this paper appear to be research avenues that are worthwhile to pursue.
</nextsent>
<nextsent>over the last thirty years, the nature, number, and taxonomy of discourse relations have been among the most controversial issues in text/discourse linguistics.
</nextsent>
<nextsent>this paper does not settle the controversy.rather, it raises some new, interesting questions be cause the lexical patterns learned by our algorithms can be interpreted as empirical proof of existence for discourse relations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5541">
<title id=" N12-1057.xml">predicting overt display of power in written dialogs </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in the computational field, several studies have used social network analysis(e.g., (diesner and carley, 2005)) for extracting social relations from online communication.
</prevsent>
<prevsent>only recently have researchers started using nlp to analyze the content of messages to deduce social relations (e.g., (diehl et al, 2007)).
</prevsent>
</prevsection>
<citsent citstr=" P11-1078 ">
bramsen et al (2011) <papid> P11-1078 </papid>use knowledge of the actual organizational structure to create two sets of messages: messages sent from superior to subordinate, and vice versa.</citsent>
<aftsection>
<nextsent>their task is to determine the direction of power (since all their data, by construction of the corpus, has power re lationship).
</nextsent>
<nextsent>their reported results cannot be directly compared with ours since their results are on classifying aggregations of messages as being to superior or to subordinate, whereas our results are on predicting whether single utterance has an odp or not.
</nextsent>
<nextsent>518
</nextsent>
<nextsent>dialog is successful when all discourse participants show cooperative dialog behavior.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5542">
<title id=" N12-1057.xml">predicting overt display of power in written dialogs </title>
<section> data and annotations.  </section>
<citcontext>
<prevsection>
<prevsent>which makes it an instance of odp, while s6 is merely an inquiry and s7 is rhetorical question.
</prevsent>
<prevsent>this makes the problem of finding odp in utterances non-trivial one.
</prevsent>
</prevsection>
<citsent citstr=" W09-3953 ">
for our study, we use small corpus of enron email threads which has been previously annotated with dialog acts (hu et al, 2009).<papid> W09-3953 </papid></citsent>
<aftsection>
<nextsent>the corpus contains122 email threads with 360 messages, 1734 utterances and 20,740 word tokens.
</nextsent>
<nextsent>we trained an annotator using the definition for odp given in section 3.
</nextsent>
<nextsent>she was given full email threads whose messages.
</nextsent>
<nextsent>were already segmented into utterances.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5545">
<title id=" N12-1072.xml">stance classification using dia logic properties of persuasion </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the topic was evolution?, with sides yes, believe?
</prevsent>
<prevsent>vs. no, dont believe?.
</prevsent>
</prevsection>
<citsent citstr=" W06-1639 ">
bates (thomas et al, 2006; <papid> W06-1639 </papid>bansal et al, 2008;<papid> C08-2004 </papid>yessenalina et al, 2010; <papid> D10-1102 </papid>balahur et al, 2009; burfoot et al, 2011); (<papid> P11-1151 </papid>2) company-internal discussion sites (murakami and raymond, 2010; <papid> C10-2100 </papid>agrawal et al., 2003); and (3) online social and political public forums (somasundaran and wiebe, 2009; <papid> P09-1026 </papid>somasundaran and wiebe, 2010; <papid> W10-0214 </papid>wang and rose?, 2010; biran and rambow, 2011).</citsent>
<aftsection>
<nextsent>debates in online public forums (e.g. fig.
</nextsent>
<nextsent>1) differ from debates in congress and on company discussion sites in two ways.
</nextsent>
<nextsent>first, the language is different.
</nextsent>
<nextsent>online debaters are highly involved, often using emotional and colorful language to make their points.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5547">
<title id=" N12-1072.xml">stance classification using dia logic properties of persuasion </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the topic was evolution?, with sides yes, believe?
</prevsent>
<prevsent>vs. no, dont believe?.
</prevsent>
</prevsection>
<citsent citstr=" C08-2004 ">
bates (thomas et al, 2006; <papid> W06-1639 </papid>bansal et al, 2008;<papid> C08-2004 </papid>yessenalina et al, 2010; <papid> D10-1102 </papid>balahur et al, 2009; burfoot et al, 2011); (<papid> P11-1151 </papid>2) company-internal discussion sites (murakami and raymond, 2010; <papid> C10-2100 </papid>agrawal et al., 2003); and (3) online social and political public forums (somasundaran and wiebe, 2009; <papid> P09-1026 </papid>somasundaran and wiebe, 2010; <papid> W10-0214 </papid>wang and rose?, 2010; biran and rambow, 2011).</citsent>
<aftsection>
<nextsent>debates in online public forums (e.g. fig.
</nextsent>
<nextsent>1) differ from debates in congress and on company discussion sites in two ways.
</nextsent>
<nextsent>first, the language is different.
</nextsent>
<nextsent>online debaters are highly involved, often using emotional and colorful language to make their points.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5548">
<title id=" N12-1072.xml">stance classification using dia logic properties of persuasion </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the topic was evolution?, with sides yes, believe?
</prevsent>
<prevsent>vs. no, dont believe?.
</prevsent>
</prevsection>
<citsent citstr=" D10-1102 ">
bates (thomas et al, 2006; <papid> W06-1639 </papid>bansal et al, 2008;<papid> C08-2004 </papid>yessenalina et al, 2010; <papid> D10-1102 </papid>balahur et al, 2009; burfoot et al, 2011); (<papid> P11-1151 </papid>2) company-internal discussion sites (murakami and raymond, 2010; <papid> C10-2100 </papid>agrawal et al., 2003); and (3) online social and political public forums (somasundaran and wiebe, 2009; <papid> P09-1026 </papid>somasundaran and wiebe, 2010; <papid> W10-0214 </papid>wang and rose?, 2010; biran and rambow, 2011).</citsent>
<aftsection>
<nextsent>debates in online public forums (e.g. fig.
</nextsent>
<nextsent>1) differ from debates in congress and on company discussion sites in two ways.
</nextsent>
<nextsent>first, the language is different.
</nextsent>
<nextsent>online debaters are highly involved, often using emotional and colorful language to make their points.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5549">
<title id=" N12-1072.xml">stance classification using dia logic properties of persuasion </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the topic was evolution?, with sides yes, believe?
</prevsent>
<prevsent>vs. no, dont believe?.
</prevsent>
</prevsection>
<citsent citstr=" P11-1151 ">
bates (thomas et al, 2006; <papid> W06-1639 </papid>bansal et al, 2008;<papid> C08-2004 </papid>yessenalina et al, 2010; <papid> D10-1102 </papid>balahur et al, 2009; burfoot et al, 2011); (<papid> P11-1151 </papid>2) company-internal discussion sites (murakami and raymond, 2010; <papid> C10-2100 </papid>agrawal et al., 2003); and (3) online social and political public forums (somasundaran and wiebe, 2009; <papid> P09-1026 </papid>somasundaran and wiebe, 2010; <papid> W10-0214 </papid>wang and rose?, 2010; biran and rambow, 2011).</citsent>
<aftsection>
<nextsent>debates in online public forums (e.g. fig.
</nextsent>
<nextsent>1) differ from debates in congress and on company discussion sites in two ways.
</nextsent>
<nextsent>first, the language is different.
</nextsent>
<nextsent>online debaters are highly involved, often using emotional and colorful language to make their points.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5550">
<title id=" N12-1072.xml">stance classification using dia logic properties of persuasion </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the topic was evolution?, with sides yes, believe?
</prevsent>
<prevsent>vs. no, dont believe?.
</prevsent>
</prevsection>
<citsent citstr=" C10-2100 ">
bates (thomas et al, 2006; <papid> W06-1639 </papid>bansal et al, 2008;<papid> C08-2004 </papid>yessenalina et al, 2010; <papid> D10-1102 </papid>balahur et al, 2009; burfoot et al, 2011); (<papid> P11-1151 </papid>2) company-internal discussion sites (murakami and raymond, 2010; <papid> C10-2100 </papid>agrawal et al., 2003); and (3) online social and political public forums (somasundaran and wiebe, 2009; <papid> P09-1026 </papid>somasundaran and wiebe, 2010; <papid> W10-0214 </papid>wang and rose?, 2010; biran and rambow, 2011).</citsent>
<aftsection>
<nextsent>debates in online public forums (e.g. fig.
</nextsent>
<nextsent>1) differ from debates in congress and on company discussion sites in two ways.
</nextsent>
<nextsent>first, the language is different.
</nextsent>
<nextsent>online debaters are highly involved, often using emotional and colorful language to make their points.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5551">
<title id=" N12-1072.xml">stance classification using dia logic properties of persuasion </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the topic was evolution?, with sides yes, believe?
</prevsent>
<prevsent>vs. no, dont believe?.
</prevsent>
</prevsection>
<citsent citstr=" P09-1026 ">
bates (thomas et al, 2006; <papid> W06-1639 </papid>bansal et al, 2008;<papid> C08-2004 </papid>yessenalina et al, 2010; <papid> D10-1102 </papid>balahur et al, 2009; burfoot et al, 2011); (<papid> P11-1151 </papid>2) company-internal discussion sites (murakami and raymond, 2010; <papid> C10-2100 </papid>agrawal et al., 2003); and (3) online social and political public forums (somasundaran and wiebe, 2009; <papid> P09-1026 </papid>somasundaran and wiebe, 2010; <papid> W10-0214 </papid>wang and rose?, 2010; biran and rambow, 2011).</citsent>
<aftsection>
<nextsent>debates in online public forums (e.g. fig.
</nextsent>
<nextsent>1) differ from debates in congress and on company discussion sites in two ways.
</nextsent>
<nextsent>first, the language is different.
</nextsent>
<nextsent>online debaters are highly involved, often using emotional and colorful language to make their points.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5552">
<title id=" N12-1072.xml">stance classification using dia logic properties of persuasion </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the topic was evolution?, with sides yes, believe?
</prevsent>
<prevsent>vs. no, dont believe?.
</prevsent>
</prevsection>
<citsent citstr=" W10-0214 ">
bates (thomas et al, 2006; <papid> W06-1639 </papid>bansal et al, 2008;<papid> C08-2004 </papid>yessenalina et al, 2010; <papid> D10-1102 </papid>balahur et al, 2009; burfoot et al, 2011); (<papid> P11-1151 </papid>2) company-internal discussion sites (murakami and raymond, 2010; <papid> C10-2100 </papid>agrawal et al., 2003); and (3) online social and political public forums (somasundaran and wiebe, 2009; <papid> P09-1026 </papid>somasundaran and wiebe, 2010; <papid> W10-0214 </papid>wang and rose?, 2010; biran and rambow, 2011).</citsent>
<aftsection>
<nextsent>debates in online public forums (e.g. fig.
</nextsent>
<nextsent>1) differ from debates in congress and on company discussion sites in two ways.
</nextsent>
<nextsent>first, the language is different.
</nextsent>
<nextsent>online debaters are highly involved, often using emotional and colorful language to make their points.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5563">
<title id=" P03-1041.xml">effective phrase translation extraction from alignment models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>statistical machine translation defines the task of translating source language sentence
</prevsent>
<prevsent>into target language sentence        . the traditional framework presented in.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
(brown et al, 1993) <papid> J93-2003 </papid>assumes generative process where the source sentence is passed through noisy stochastic process to produce the target sentence.</citsent>
<aftsection>
<nextsent>the task can be formally stated as finding the   s.t   = fiffflffi    !
</nextsent>
<nextsent>  where the search component is commonly referred to as the decoding step (wang and waibel, 1998).
</nextsent>
<nextsent>within the generative model, the bayes reformulation is used to estimate   #!
</nextsent>
<nextsent>  where     is considered the language model, and
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5567">
<title id=" P03-1041.xml">effective phrase translation extraction from alignment models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>  where     is considered the language model, and
</prevsent>
<prevsent> is the translation model; the ibm (brown et al, 1993) <papid> J93-2003 </papid>models being the defacto standard.</prevsent>
</prevsection>
<citsent citstr=" P00-1006 ">
direct translation approaches (fos ter, 2000) <papid> P00-1006 </papid>consider estimating    !</citsent>
<aftsection>
<nextsent>  directly, and work by (och and ney, 2002) <papid> P02-1038 </papid>show that similar or improved results are achieved by replacing   </nextsent>
<nextsent>  in the optimization with   #!</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5568">
<title id=" P03-1041.xml">effective phrase translation extraction from alignment models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent> is the translation model; the ibm (brown et al, 1993) <papid> J93-2003 </papid>models being the defacto standard.</prevsent>
<prevsent>direct translation approaches (fos ter, 2000) <papid> P00-1006 </papid>consider estimating    !</prevsent>
</prevsection>
<citsent citstr=" P02-1038 ">
directly, and work by (och and ney, 2002) <papid> P02-1038 </papid>show that similar or improved results are achieved by replacing   </citsent>
<aftsection>
<nextsent>  in the optimization with   #!
</nextsent>
<nextsent> , at the cost of deviating from the bayesian framework.
</nextsent>
<nextsent>regardless of the approach, the question of accurately estimatinga model of translation from large parallel or comparable corpus is one of the defining components within statistical machine translation.
</nextsent>
<nextsent>re-ordering effects across languages have been modeled in several ways, including word-based (brown et al, 1993), <papid> J93-2003 </papid>template-based (och et al, 1999) <papid> W99-0604 </papid>and syntax-based (yamada, knight, 2001).analyzing these models from generative mindset, they all assume that the atomic unit of lexical content is the word, and re-ordering effects are applied above that level.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5570">
<title id=" P03-1041.xml">effective phrase translation extraction from alignment models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent> , at the cost of deviating from the bayesian framework.
</prevsent>
<prevsent>regardless of the approach, the question of accurately estimatinga model of translation from large parallel or comparable corpus is one of the defining components within statistical machine translation.
</prevsent>
</prevsection>
<citsent citstr=" W99-0604 ">
re-ordering effects across languages have been modeled in several ways, including word-based (brown et al, 1993), <papid> J93-2003 </papid>template-based (och et al, 1999) <papid> W99-0604 </papid>and syntax-based (yamada, knight, 2001).analyzing these models from generative mindset, they all assume that the atomic unit of lexical content is the word, and re-ordering effects are applied above that level.</citsent>
<aftsection>
<nextsent>(marcu, wong, 2002) illustrate the effects of assuming that lexical correspondence can only be modeled at the word level,and motivate joint probability model that explicitly generates phrase level lexical content across both languages.
</nextsent>
<nextsent>(wu, 1995) presents bracketing method that models re-ordering at the sentence level.both (marcu, wong, 2002; wu, 1995) model there ordering phenomenon effectively, but at significant computational expense, and tend to be difficult to scale to long sentences.
</nextsent>
<nextsent>reasons to introduce phrase level translation knowledge sources have been adequately shown and confirmed by (och, ney, 2000), and we focus on methods to build these sources from existing, mature components within the translation process.
</nextsent>
<nextsent>this paper presents method of phrase extraction from alignment data generated by ibm models.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5571">
<title id=" P03-1041.xml">effective phrase translation extraction from alignment models </title>
<section> motivation.  </section>
<citcontext>
<prevsection>
<prevsent>alignment models associate words and their translations at the sentence level creating translation lexicon across the language pair.
</prevsent>
<prevsent>for each sentence pair,the model also presents the maximally likely association between each source and target word across the sentence pair, forming an alignment map for each sentence pair in the training corpus.
</prevsent>
</prevsection>
<citsent citstr=" C96-2141 ">
the most likely alignment pattern between source and target sentence under the trained alignment model will be referred to as the maximum approximation, which under hmm alignment (vogel et al, 1996) <papid> C96-2141 </papid>model corresponds to the viterbi path.</citsent>
<aftsection>
<nextsent>a set of words in the source sentence associated with set of words in the target sentence is considered phrasal pair and forms partition within the alignment map.
</nextsent>
<nextsent>figure ( . shows source and target sentence pair with points indicating alignment points.
</nextsent>
<nextsent>a phrasal translation pair within sentence pair can be represented as the 4-tuple hypothesis )+*  , - ./#-10- .324 representing an index  , -10 and length  5.6/#- .327 within the source and the target sentence pair  , respectively.
</nextsent>
<nextsent>the phrasal extraction task involves selecting phrasal hypotheses based on the alignment figure 1: sample source 8:9 and target ;9 aligment map.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5575">
<title id=" P04-1053.xml">discovering relations among named entities from large corpora </title>
<section> prior work.  </section>
<citcontext>
<prevsection>
<prevsent>following muc, the automatic content extraction (ace) meetings (national institute of standards and technology, 2000) are pursuing informa1gpe is an acronym introduced by the ace program to represent geo-political entity ? an entity with land and gov ernment.tion extraction.
</prevsent>
<prevsent>in the ace program2, relation detection and characterization (rdc) was introduced as task in 2002.
</prevsent>
</prevsection>
<citsent citstr=" W02-1010 ">
most of approaches to the acerdc task involved supervised learning such as kernel methods (zelenko et al, 2002) <papid> W02-1010 </papid>and need richly annotated corpora which are tagged with relation in stances.</citsent>
<aftsection>
<nextsent>the biggest problem with this approach is that it takes great deal of time and effort to prepare annotated corpora large enough to apply supervised learning.
</nextsent>
<nextsent>in addition, the varieties of relations were limited to those defined by the ace rdc task.
</nextsent>
<nextsent>in order to discover knowledge from diverse corpora, broader range of relations would be necessary.some previous work adopted weakly supervised learning approach.
</nextsent>
<nextsent>this approach has the advantage of not needing large tagged corpora.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5576">
<title id=" P04-1053.xml">discovering relations among named entities from large corpora </title>
<section> prior work.  </section>
<citcontext>
<prevsection>
<prevsent>brinused few samples of book titles and authors, collected common patterns from context including the samples and finally found new examples of book title and authors whose context matched the common patterns.
</prevsent>
<prevsent>agichtein improved brins method by adopting the constraint of using named entity tagger (agichtein and gravano, 2000).
</prevsent>
</prevsection>
<citsent citstr=" P02-1006 ">
ravichandran also explored similar method for question answering (ravichandran and hovy, 2002).<papid> P02-1006 </papid></citsent>
<aftsection>
<nextsent>these approaches, however, need small set of initial seeds.
</nextsent>
<nextsent>it is also unclear how initial seeds should be selected and how many seeds are required.
</nextsent>
<nextsent>also their methods were only tried on functional relations, and this was an important constraint on their bootstrapping.the variety of expressions conveying the same relation can be considered an example of paraphrases,and so some of the prior work on paraphrase acquisition is pertinent to relation discovery.
</nextsent>
<nextsent>lin proposed another weakly supervised approach for discovering paraphrase (lin and pantel, 2001).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5577">
<title id=" P04-2007.xml">towards a semantic classification of spanish verbs based on subcategorisation information </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>lexical semantic classes group together words that have similar meaning.
</prevsent>
<prevsent>knowledge about verbs is especially important, since verbs are the primary means of structuring and conveying meaning in sentences.
</prevsent>
</prevsection>
<citsent citstr=" W02-0907 ">
manually built semantic classifications of english verbs have been used for different applications such as machine translation (dorr, 1997), verb subcategorisation acquisition (korhonen, 2002<papid> W02-0907 </papid>a) or parsing (schneider, 2003).<papid> N03-3006 </papid></citsent>
<aftsection>
<nextsent>(levin, 1993) has established large-scale classification of english verbs based on the hypothesis that the meaning of verband its syntactic behaviour are related, and therefore semantic information can be induced from the syntactic behaviour of the verb.
</nextsent>
<nextsent>a classification of spanish verbs based on the same hypothesis hasbeen developed by (vazquez et al, 2000).
</nextsent>
<nextsent>but manually constructing large-scale verb classifications is labour-intensive task.
</nextsent>
<nextsent>for this reason, various methods for automatically classifying verbs using machine learning techniques have been attempted((merlo and stevenson, 2001), (<papid> J01-3003 </papid>stevenson and joa nis, 2003), (<papid> W03-0410 </papid>schulte im walde, 2003)).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5580">
<title id=" P04-2007.xml">towards a semantic classification of spanish verbs based on subcategorisation information </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>lexical semantic classes group together words that have similar meaning.
</prevsent>
<prevsent>knowledge about verbs is especially important, since verbs are the primary means of structuring and conveying meaning in sentences.
</prevsent>
</prevsection>
<citsent citstr=" N03-3006 ">
manually built semantic classifications of english verbs have been used for different applications such as machine translation (dorr, 1997), verb subcategorisation acquisition (korhonen, 2002<papid> W02-0907 </papid>a) or parsing (schneider, 2003).<papid> N03-3006 </papid></citsent>
<aftsection>
<nextsent>(levin, 1993) has established large-scale classification of english verbs based on the hypothesis that the meaning of verband its syntactic behaviour are related, and therefore semantic information can be induced from the syntactic behaviour of the verb.
</nextsent>
<nextsent>a classification of spanish verbs based on the same hypothesis hasbeen developed by (vazquez et al, 2000).
</nextsent>
<nextsent>but manually constructing large-scale verb classifications is labour-intensive task.
</nextsent>
<nextsent>for this reason, various methods for automatically classifying verbs using machine learning techniques have been attempted((merlo and stevenson, 2001), (<papid> J01-3003 </papid>stevenson and joa nis, 2003), (<papid> W03-0410 </papid>schulte im walde, 2003)).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5581">
<title id=" P04-2007.xml">towards a semantic classification of spanish verbs based on subcategorisation information </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a classification of spanish verbs based on the same hypothesis hasbeen developed by (vazquez et al, 2000).
</prevsent>
<prevsent>but manually constructing large-scale verb classifications is labour-intensive task.
</prevsent>
</prevsection>
<citsent citstr=" J01-3003 ">
for this reason, various methods for automatically classifying verbs using machine learning techniques have been attempted((merlo and stevenson, 2001), (<papid> J01-3003 </papid>stevenson and joa nis, 2003), (<papid> W03-0410 </papid>schulte im walde, 2003)).</citsent>
<aftsection>
<nextsent>in this article we present experiments aiming at automatically classifying spanish verbs into lexical semantic classes based on their subcategorisation frames.
</nextsent>
<nextsent>we adopt the idea that description of verbs in terms of their syntactic behaviour is useful for acquiring their semantic properties.
</nextsent>
<nextsent>the classification task at hand is achieved through process that requires different steps: we first extract from apartially parsed corpus the probabilities of the subcategorisation frames for each verb.
</nextsent>
<nextsent>then, the acquired probabilities are used as features describing the verbs and given as input to an unsupervised classification algorithm that clusters together the verbs according to the similarity of their descriptions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5582">
<title id=" P04-2007.xml">towards a semantic classification of spanish verbs based on subcategorisation information </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a classification of spanish verbs based on the same hypothesis hasbeen developed by (vazquez et al, 2000).
</prevsent>
<prevsent>but manually constructing large-scale verb classifications is labour-intensive task.
</prevsent>
</prevsection>
<citsent citstr=" W03-0410 ">
for this reason, various methods for automatically classifying verbs using machine learning techniques have been attempted((merlo and stevenson, 2001), (<papid> J01-3003 </papid>stevenson and joa nis, 2003), (<papid> W03-0410 </papid>schulte im walde, 2003)).</citsent>
<aftsection>
<nextsent>in this article we present experiments aiming at automatically classifying spanish verbs into lexical semantic classes based on their subcategorisation frames.
</nextsent>
<nextsent>we adopt the idea that description of verbs in terms of their syntactic behaviour is useful for acquiring their semantic properties.
</nextsent>
<nextsent>the classification task at hand is achieved through process that requires different steps: we first extract from apartially parsed corpus the probabilities of the subcategorisation frames for each verb.
</nextsent>
<nextsent>then, the acquired probabilities are used as features describing the verbs and given as input to an unsupervised classification algorithm that clusters together the verbs according to the similarity of their descriptions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5585">
<title id=" P04-2007.xml">towards a semantic classification of spanish verbs based on subcategorisation information </title>
<section> acquisition of spanish.  </section>
<citcontext>
<prevsection>
<prevsent>we experiment our methodology on two corpora of different sizes, both consisting of spanish newswire text: 3 million word corpus, hereafter called small corpus, and 50 million word corpus, hereafter called large corpus.
</prevsent>
<prevsent>they are both pos tagged and partially parsed using the ms-analyzer, partial parser for spanish that includes named entities recognition (atserias et al, 1998).
</prevsent>
</prevsection>
<citsent citstr=" J93-2002 ">
in order to collect the frequency distributions of spanish subcategorisation frames, we adapt methodology that has been developed for english to the specificities of the spanish language ((brent, 1993), (<papid> J93-2002 </papid>manning, 1993), (<papid> P93-1032 </papid>korhonen, 2002<papid> W02-0907 </papid>b)).</citsent>
<aftsection>
<nextsent>it consists in extracting from the corpus pairs made of verb and its co-occurring constituents that are possible pattern of frame, and then filtering outthe patterns that do not have probability of cooccurrence with the verb high enough to be considered its arguments.we establish set of 11 possible spanish subcategorisation frames.
</nextsent>
<nextsent>these are the plausible combinations of maximum of 2 of the following con stituents: nominal phrases, prepositional phrases, temporal sentential clauses, gerundive sentential clauses, infiniti val sentential clauses, and infiniti val sentential clauses introduced by preposition.
</nextsent>
<nextsent>the individual prepositions are also taken into account as part of the subcategorisation frame types.
</nextsent>
<nextsent>adapting methodology that has been thought for english presents few problems, because english is language with strong word order constraint, while in spanish the order of constituents is freer.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5586">
<title id=" P04-2007.xml">towards a semantic classification of spanish verbs based on subcategorisation information </title>
<section> acquisition of spanish.  </section>
<citcontext>
<prevsection>
<prevsent>we experiment our methodology on two corpora of different sizes, both consisting of spanish newswire text: 3 million word corpus, hereafter called small corpus, and 50 million word corpus, hereafter called large corpus.
</prevsent>
<prevsent>they are both pos tagged and partially parsed using the ms-analyzer, partial parser for spanish that includes named entities recognition (atserias et al, 1998).
</prevsent>
</prevsection>
<citsent citstr=" P93-1032 ">
in order to collect the frequency distributions of spanish subcategorisation frames, we adapt methodology that has been developed for english to the specificities of the spanish language ((brent, 1993), (<papid> J93-2002 </papid>manning, 1993), (<papid> P93-1032 </papid>korhonen, 2002<papid> W02-0907 </papid>b)).</citsent>
<aftsection>
<nextsent>it consists in extracting from the corpus pairs made of verb and its co-occurring constituents that are possible pattern of frame, and then filtering outthe patterns that do not have probability of cooccurrence with the verb high enough to be considered its arguments.we establish set of 11 possible spanish subcategorisation frames.
</nextsent>
<nextsent>these are the plausible combinations of maximum of 2 of the following con stituents: nominal phrases, prepositional phrases, temporal sentential clauses, gerundive sentential clauses, infiniti val sentential clauses, and infiniti val sentential clauses introduced by preposition.
</nextsent>
<nextsent>the individual prepositions are also taken into account as part of the subcategorisation frame types.
</nextsent>
<nextsent>adapting methodology that has been thought for english presents few problems, because english is language with strong word order constraint, while in spanish the order of constituents is freer.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5597">
<title id=" P04-2007.xml">towards a semantic classification of spanish verbs based on subcategorisation information </title>
<section> conclusions and future work.  </section>
<citcontext>
<prevsection>
<prevsent>for the purposes of possible applications, hard clustering of verbs does notseem to be necessary, especially when even manually constructed classifications adopt arbitrary decisions and do not agree with each other: knowing which verbs are semantically similar to each other in more fuzzy?
</prevsent>
<prevsent>way might be even more useful.
</prevsent>
</prevsection>
<citsent citstr=" W03-1011 ">
for this reason, new approach could be envisaged for this task, in the direction of the work by (weeds and weir, 2003), <papid> W03-1011 </papid>by building rankings of similarity for each verb.</citsent>
<aftsection>
<nextsent>for the purpose of evaluation, the gold standard classification could also be organised in the form of similarity rankings, based on the distance between the verbs in the hierarchy.
</nextsent>
<nextsent>then, the rankings for each verb could be evaluated.
</nextsent>
<nextsent>the two directions appointed here, enriching the verb descriptions with new features that grasp other properties of the verbs, and envisaging similarity ranking of verbs instead of hard clustering, are the next steps to be taken for this work.
</nextsent>
<nextsent>acknowledgements the realisation of this work was possible thanks tothe funding of the swiss fnrs project number 11 65328.01.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5598">
<title id=" P04-1012.xml">user expertise modeling and adapt ivity in a speech based email system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the system monitors the users competence with the help of parameters that describe e.g. the success of the users interaction with the system.
</prevsent>
<prevsent>the model consists of an online and an offline version, the former taking care of the expertise level changes during the same session, the latter modelling the overall user expertise as function of time and repeated interactions.
</prevsent>
</prevsection>
<citsent citstr=" A00-2028 ">
adaptive functionality in spoken dialogue systems is usually geared towards dealing with communication disfluencies and facilitating more natural interaction (e.g. danieli and gerbino, 1995; litman and pan, 1999; krahmer et al 1999; walker et al 2000).<papid> A00-2028 </papid></citsent>
<aftsection>
<nextsent>in the athosmail system (turunen et al, 2004), the focus has been on adapt ivity that addresses the users expertise levels with respect to dialogue systems functionality, and allows adaptation to take place both online and between the sessions.
</nextsent>
<nextsent>the main idea is that while novice users need guidance, it would be inefficient and annoying for experienced users to be forced to listen to the same instructions every time they use the system.
</nextsent>
<nextsent>for instance, already (smith, 1993) observed that it is safer for beginners to be closely guided by the system, while experienced users like to take the initiative which results in more efficient dialogues in terms of decreased average completion time and decreased average number of utterances.
</nextsent>
<nextsent>however, being able to decide when to switch from guiding novice to facilitating an expert requires the system to be able to keep track of the user expertise level.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5599">
<title id=" N12-1094.xml">detecting visual text </title>
<section> data analysis.  </section>
<citcontext>
<prevsection>
<prevsent>visual or notone of the challenges in arriving at such definition is that the description of an image in flickr is almost always written by the photographer of thatimage.
</prevsent>
<prevsent>this means the descriptions often contain information that is not actually pictured in the image, or contain references that are only relevant to the photographer (referring to person/pet by name).one might think that this is an artifact of this particular dataset, but it appears to be generic to all captions, even those written by viewer (rather than the photographer).
</prevsent>
</prevsection>
<citsent citstr=" W10-0721 ">
figure 2 shows an image from the pascal dataset (everingham et al, 2010), together with captions written by random people collected via crowd-sourcing (rashtchian et al, 2010).<papid> W10-0721 </papid></citsent>
<aftsection>
<nextsent>there is much in this caption that is clearly made-up by the author, presumably to make the caption more interesting (e.g., meta-references like the camera?
</nextsent>
<nextsent>or photo?
</nextsent>
<nextsent>as well as guesses?
</nextsent>
<nextsent>about the image, such as garage?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5600">
<title id=" N12-1094.xml">detecting visual text </title>
<section> visual features from raw text.  </section>
<citcontext>
<prevsection>
<prevsent>for example, in small red apple,?
</prevsent>
<prevsent>we consider onlyred as modifier for noun.
</prevsent>
</prevsection>
<citsent citstr=" P89-1010 ">
we use pointwise mutual information (pmi) (church and hanks, 1989) <papid> P89-1010 </papid>to weight the contexts, and select the top 1000 pmi contexts for each adjective.3 next, we apply cosine similarity to find the top 10 distributionally similar adjectives with respect toeach target adjective based on our large generic corpus (large-data from section 2.1).</citsent>
<aftsection>
<nextsent>this creates graph with adjectives as nodes and cosine similarity as weight on the edges.
</nextsent>
<nextsent>analogously, we construct graph with nouns as nodes (here, adjectives are used as contexts for nouns).
</nextsent>
<nextsent>we then apply bootstrapping (kozareva et al,2008) <papid> P08-1119 </papid>on the noun and adjective graphs by selecting 10 seeds for visual and non-visual nouns and adjectives (see table 1).</nextsent>
<nextsent>we use in-degree (sum of weights of incoming edges) to compute the score for3we are interested in descriptive adjectives, which typically ascribe to noun value of an attribute?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5601">
<title id=" N12-1094.xml">detecting visual text </title>
<section> visual features from raw text.  </section>
<citcontext>
<prevsection>
<prevsent>this creates graph with adjectives as nodes and cosine similarity as weight on the edges.
</prevsent>
<prevsent>analogously, we construct graph with nouns as nodes (here, adjectives are used as contexts for nouns).
</prevsent>
</prevsection>
<citsent citstr=" P08-1119 ">
we then apply bootstrapping (kozareva et al,2008) <papid> P08-1119 </papid>on the noun and adjective graphs by selecting 10 seeds for visual and non-visual nouns and adjectives (see table 1).</citsent>
<aftsection>
<nextsent>we use in-degree (sum of weights of incoming edges) to compute the score for3we are interested in descriptive adjectives, which typically ascribe to noun value of an attribute?
</nextsent>
<nextsent>(miller, 1998).
</nextsent>
<nextsent>765 visual car house tree horse animal nouns man table bottle seeds woman computer non-visual idea bravery deceit trust nouns dedication anger humour luck seeds inflation honesty visual brown green wooden striped adjectives orange rectangular furry seeds shiny rusty feathered non-visual public original whole righteous adjectives political personal intrinsic seeds individual initial total table 1: example seeds for bootstrapping.
</nextsent>
<nextsent>each node that has connections with known (seeds) or automatically labeled nodes, previously exploited to learn hyponymy relations from the web (kozarevaet al, 2008).<papid> P08-1119 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5603">
<title id=" N12-1094.xml">detecting visual text </title>
<section> visual features from raw text.  </section>
<citcontext>
<prevsection>
<prevsent>each node that has connections with known (seeds) or automatically labeled nodes, previously exploited to learn hyponymy relations from the web (kozarevaet al, 2008).<papid> P08-1119 </papid></prevsent>
<prevsent>intuitively, in-degree captures the popularity of new instances among instances that have already been identified as good instances.</prevsent>
</prevsection>
<citsent citstr=" W02-1028 ">
we learn visual and non-visual words together (known as the mutual exclusion principle in bootstrapping (the len and riloff, 2002; <papid> W02-1028 </papid>mcintosh and curran, 2008)): each word (node) is assigned to only one class.moreover, after each iteration, we harmonically decrease the weight of the in-degree associated with instances learned in later iterations.</citsent>
<aftsection>
<nextsent>we added 25 new instances at each iteration and ran 500 iterations of bootstrapping, yielding 11955 visual and 11978non-visual nouns, and 7746 visual and 7464 non visual adjectives.
</nextsent>
<nextsent>based on manual inspection, the learned visual and non-visual lists look great.
</nextsent>
<nextsent>in the future, we would like to do mechanical turk evaluation to directly evaluate the visual and non-visual nouns and adjectives.
</nextsent>
<nextsent>for now, we show the coverage of these classes in the flickr data-set: visual nouns:53.71%; non-visual nouns: 14.25%; visual ad jectives: 51.79%; non-visual adjectives: 14.40%.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5604">
<title id=" N12-1094.xml">detecting visual text </title>
<section> visual features from raw text.  </section>
<citcontext>
<prevsection>
<prevsent>to learn the visually descriptive words, we set vp to 20 visually descriptive predicates shown in the top of table 2, and vato all nouns that appear in the object argument position with respect to the seed predicates.
</prevsent>
<prevsent>we approximate this by taking nouns on the right hand side of the predicates within window of 4 words using the web 1t google n-gram data (brants and franz.,2006).
</prevsent>
</prevsection>
<citsent citstr=" N10-1119 ">
for edge weights, we use conditional probabilities between predicates and arguments so that w(p? a) := pr(a|p) and w(a? p) := pr(p|a).in order to collectively induce the visually descriptive words from this graph, we apply the graph propagation algorithm of velikovich et al (2010), <papid> N10-1119 </papid>variant of label propagation algorithms (zhu and ghahramani, 2002) that has been shown to be effective for inducing web-scale polarity lexicon based on word co-occurrence statistics.</citsent>
<aftsection>
<nextsent>this algo 766 color purple blue maroon beige green material plastic cotton wooden metallic silver shape circular square round rectangular triangular size small big tiny tall huge surface coarse smooth furry fluffy rough direction sideways north upward left down pattern striped dotted checked plaid quilted quality shiny rusty dirty burned glittery beauty beautiful cute pretty gorgeous lovely age young mature immature older senior ethnicity french asian american greek hispanic table 4: attribute classes with their seed valuesrithm iteratively updates the semantic distance between each pair of nodes in the graph, then produces score for each node that represents how visually descriptive each word is. to learn the words that are not visually descriptive, we use the predicates shown in the bottom of table 2 as vp instead.
</nextsent>
<nextsent>table 3 shows the top ranked nouns that are visually descriptive and not visually descriptive.
</nextsent>
<nextsent>3.3 bootstrapping visual adjectives.
</nextsent>
<nextsent>our goal in this section is to automatically generate comprehensive lists of adjectives for different attributes, such as color, material, shape, etc. to our knowledge, this is the first significant effort of this type for adjectives: most bootstrapping techniques focus exclusively on nouns, although almuhareb and poesio (2005) populated lists of attributes using web-based similarity measures.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5605">
<title id=" N12-1094.xml">detecting visual text </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>beginning with the system that contains all features (small=73.9, large=76.8), we first remove the bootstrap-based features (small71.8,large75.5) or remove the label-propagation based features (small71.2, large74.9) or remove both (small70.7, large74.2).
</prevsent>
<prevsent>from these results, we can see that these techniques are useful, but somewhat redundant: if you had to choose one, you should choose label-propagation.
</prevsent>
</prevsection>
<citsent citstr=" P10-1126 ">
as connections between language and vision become stronger, for instance in the contexts of object detection (hou and zhang, 2007; kim and tor ralba, 2009; sivic et al, 2008; alexe et al, 2010;gu et al, 2009), attribute detection (ferrari and zis serman, 2007; farhadi et al, 2009; kumar et al, 2009; berg et al, 2010), visual phrases (farhadi and sadeghi, 2011), and automatic caption generation(farhadi et al, 2010; feng and lapata, 2010; <papid> P10-1126 </papid>ordonez et al, 2011; kulkarni et al, 2011; yang et al., 2011; <papid> D11-1041 </papid>li et al, 2011; <papid> W11-0326 </papid>mitchell et al, 2012), <papid> E12-1076 </papid>it becomes increasingly important to understand, andto be able to detect, text that actually refers to observed phenomena.</citsent>
<aftsection>
<nextsent>our results suggest that while this is hard problem, it is possible to leverage large text resources and state-of-the-art computervision algorithms to address it with high accuracy.
</nextsent>
<nextsent>acknowledgments t.l. berg and k. yamaguchi were supported in partby nsf faculty early career development (ca reer) award #1054133; a.c. berg and y. choi were partially supported by the stony brook university office of the vice president for research; h. daume?
</nextsent>
<nextsent>iii and a. goyal were partially supported by nsf award iis-1139909; all authors were partially supported by 2011 jhu summer workshop.
</nextsent>

</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5606">
<title id=" N12-1094.xml">detecting visual text </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>beginning with the system that contains all features (small=73.9, large=76.8), we first remove the bootstrap-based features (small71.8,large75.5) or remove the label-propagation based features (small71.2, large74.9) or remove both (small70.7, large74.2).
</prevsent>
<prevsent>from these results, we can see that these techniques are useful, but somewhat redundant: if you had to choose one, you should choose label-propagation.
</prevsent>
</prevsection>
<citsent citstr=" D11-1041 ">
as connections between language and vision become stronger, for instance in the contexts of object detection (hou and zhang, 2007; kim and tor ralba, 2009; sivic et al, 2008; alexe et al, 2010;gu et al, 2009), attribute detection (ferrari and zis serman, 2007; farhadi et al, 2009; kumar et al, 2009; berg et al, 2010), visual phrases (farhadi and sadeghi, 2011), and automatic caption generation(farhadi et al, 2010; feng and lapata, 2010; <papid> P10-1126 </papid>ordonez et al, 2011; kulkarni et al, 2011; yang et al., 2011; <papid> D11-1041 </papid>li et al, 2011; <papid> W11-0326 </papid>mitchell et al, 2012), <papid> E12-1076 </papid>it becomes increasingly important to understand, andto be able to detect, text that actually refers to observed phenomena.</citsent>
<aftsection>
<nextsent>our results suggest that while this is hard problem, it is possible to leverage large text resources and state-of-the-art computervision algorithms to address it with high accuracy.
</nextsent>
<nextsent>acknowledgments t.l. berg and k. yamaguchi were supported in partby nsf faculty early career development (ca reer) award #1054133; a.c. berg and y. choi were partially supported by the stony brook university office of the vice president for research; h. daume?
</nextsent>
<nextsent>iii and a. goyal were partially supported by nsf award iis-1139909; all authors were partially supported by 2011 jhu summer workshop.
</nextsent>

</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5607">
<title id=" N12-1094.xml">detecting visual text </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>beginning with the system that contains all features (small=73.9, large=76.8), we first remove the bootstrap-based features (small71.8,large75.5) or remove the label-propagation based features (small71.2, large74.9) or remove both (small70.7, large74.2).
</prevsent>
<prevsent>from these results, we can see that these techniques are useful, but somewhat redundant: if you had to choose one, you should choose label-propagation.
</prevsent>
</prevsection>
<citsent citstr=" W11-0326 ">
as connections between language and vision become stronger, for instance in the contexts of object detection (hou and zhang, 2007; kim and tor ralba, 2009; sivic et al, 2008; alexe et al, 2010;gu et al, 2009), attribute detection (ferrari and zis serman, 2007; farhadi et al, 2009; kumar et al, 2009; berg et al, 2010), visual phrases (farhadi and sadeghi, 2011), and automatic caption generation(farhadi et al, 2010; feng and lapata, 2010; <papid> P10-1126 </papid>ordonez et al, 2011; kulkarni et al, 2011; yang et al., 2011; <papid> D11-1041 </papid>li et al, 2011; <papid> W11-0326 </papid>mitchell et al, 2012), <papid> E12-1076 </papid>it becomes increasingly important to understand, andto be able to detect, text that actually refers to observed phenomena.</citsent>
<aftsection>
<nextsent>our results suggest that while this is hard problem, it is possible to leverage large text resources and state-of-the-art computervision algorithms to address it with high accuracy.
</nextsent>
<nextsent>acknowledgments t.l. berg and k. yamaguchi were supported in partby nsf faculty early career development (ca reer) award #1054133; a.c. berg and y. choi were partially supported by the stony brook university office of the vice president for research; h. daume?
</nextsent>
<nextsent>iii and a. goyal were partially supported by nsf award iis-1139909; all authors were partially supported by 2011 jhu summer workshop.
</nextsent>

</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5608">
<title id=" N12-1094.xml">detecting visual text </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>beginning with the system that contains all features (small=73.9, large=76.8), we first remove the bootstrap-based features (small71.8,large75.5) or remove the label-propagation based features (small71.2, large74.9) or remove both (small70.7, large74.2).
</prevsent>
<prevsent>from these results, we can see that these techniques are useful, but somewhat redundant: if you had to choose one, you should choose label-propagation.
</prevsent>
</prevsection>
<citsent citstr=" E12-1076 ">
as connections between language and vision become stronger, for instance in the contexts of object detection (hou and zhang, 2007; kim and tor ralba, 2009; sivic et al, 2008; alexe et al, 2010;gu et al, 2009), attribute detection (ferrari and zis serman, 2007; farhadi et al, 2009; kumar et al, 2009; berg et al, 2010), visual phrases (farhadi and sadeghi, 2011), and automatic caption generation(farhadi et al, 2010; feng and lapata, 2010; <papid> P10-1126 </papid>ordonez et al, 2011; kulkarni et al, 2011; yang et al., 2011; <papid> D11-1041 </papid>li et al, 2011; <papid> W11-0326 </papid>mitchell et al, 2012), <papid> E12-1076 </papid>it becomes increasingly important to understand, andto be able to detect, text that actually refers to observed phenomena.</citsent>
<aftsection>
<nextsent>our results suggest that while this is hard problem, it is possible to leverage large text resources and state-of-the-art computervision algorithms to address it with high accuracy.
</nextsent>
<nextsent>acknowledgments t.l. berg and k. yamaguchi were supported in partby nsf faculty early career development (ca reer) award #1054133; a.c. berg and y. choi were partially supported by the stony brook university office of the vice president for research; h. daume?
</nextsent>
<nextsent>iii and a. goyal were partially supported by nsf award iis-1139909; all authors were partially supported by 2011 jhu summer workshop.
</nextsent>

</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5609">
<title id=" P00-1054.xml">lexical transfer using a vector space model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>typically, the developer of machine translation system has to spend several years building general-purpose bilingual dictionary.
</prevsent>
<prevsent>unfortunately, such general-purpose dictionary is not almighty, in that (1) when faced with new domain, unknown source words may emerge and/or some domain-specific usages of known words may appear and (2) the accuracy of the target word selection may be insufficient due to the handling of many target words simultaneously.
</prevsent>
</prevsection>
<citsent citstr=" P98-2139 ">
recently, to overcome these bottlenecks in knowledge building and/or tuning, the automation of lexicography has been studied by many researchers: (1) approaches using decision tree: the id3 learning algorithm is applied to obtain transfer rules from case-frame representations of simple sentences with thesaurus for generalization (akiba et. al., 1996 and tanaka, 1995); (2) approaches using structural matching: to obtain transfer rules, several search methods have been proposed for maximal structural matching between trees obtained by parsing bilingual sentences (kitamura and matsumoto, 1996; meyers et. al., 1998; <papid> P98-2139 </papid>and kaji et. al.,1992).<papid> C92-2101 </papid></citsent>
<aftsection>
<nextsent>1 our proposal.
</nextsent>
<nextsent>1.1 our problem and approach.
</nextsent>
<nextsent>in this paper, we concentrate on lexical transfer, i.e., target word selection.
</nextsent>
<nextsent>in other words, the mapping of structures between source and target expressions is not dealt with here.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5610">
<title id=" P00-1054.xml">lexical transfer using a vector space model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>typically, the developer of machine translation system has to spend several years building general-purpose bilingual dictionary.
</prevsent>
<prevsent>unfortunately, such general-purpose dictionary is not almighty, in that (1) when faced with new domain, unknown source words may emerge and/or some domain-specific usages of known words may appear and (2) the accuracy of the target word selection may be insufficient due to the handling of many target words simultaneously.
</prevsent>
</prevsection>
<citsent citstr=" C92-2101 ">
recently, to overcome these bottlenecks in knowledge building and/or tuning, the automation of lexicography has been studied by many researchers: (1) approaches using decision tree: the id3 learning algorithm is applied to obtain transfer rules from case-frame representations of simple sentences with thesaurus for generalization (akiba et. al., 1996 and tanaka, 1995); (2) approaches using structural matching: to obtain transfer rules, several search methods have been proposed for maximal structural matching between trees obtained by parsing bilingual sentences (kitamura and matsumoto, 1996; meyers et. al., 1998; <papid> P98-2139 </papid>and kaji et. al.,1992).<papid> C92-2101 </papid></citsent>
<aftsection>
<nextsent>1 our proposal.
</nextsent>
<nextsent>1.1 our problem and approach.
</nextsent>
<nextsent>in this paper, we concentrate on lexical transfer, i.e., target word selection.
</nextsent>
<nextsent>in other words, the mapping of structures between source and target expressions is not dealt with here.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5611">
<title id=" P00-1054.xml">lexical transfer using a vector space model </title>
<section> vector-space model.  </section>
<citcontext>
<prevsection>
<prevsent>suppose that we have translation examples including the concerned source word and we know in advance which target word corresponds to the source word.
</prevsent>
<prevsent>by measuring the similarity between (1) an unknown sentence that includes the concerned source word and (2) known sentences that include the concerned source word, we can select the target word which is included in the most similar sentence.
</prevsent>
</prevsection>
<citsent citstr=" C90-3044 ">
this is the same idea as example-based machine translation (sato and nagao, 1990 <papid> C90-3044 </papid>and furuse et. al., 1994).</citsent>
<aftsection>
<nextsent>group1: ??
</nextsent>
<nextsent>(not sweet) source sentence 1: this beer is drier and full-bodied.
</nextsent>
<nextsent>target sentence 1: ??????????????????
</nextsent>
<nextsent>source sentence 2: would you like dry or sweet sherry?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5612">
<title id=" P00-1054.xml">lexical transfer using a vector space model </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>5.1 accuracy.
</prevsent>
<prevsent>an experiment was done for restricted problem, i.e., select the appropriate one cluster (target word) from two major clusters (target words), and the result was encouraging for the automation of the lexicography for transfer.
</prevsent>
</prevsection>
<citsent citstr=" A00-1006 ">
we plan to improve the accuracy obtained so far by exploring elementary techniques: (1) adding new features including extra linguistic information such as the role of the speaker of the sentence (yamada et al, 2000) (<papid> A00-1006 </papid>also, the topic that sentences are referring to) may be effective; and (2) considering the physical distance from the concerned input word, which may improve the accuracy.</citsent>
<aftsection>
<nextsent>a kind of window function might also be useful; (3) improving the word alignment, which may contribute to the overall accuracy.
</nextsent>
<nextsent>5.2 data sparseness.
</nextsent>
<nextsent>in our proposal, deficiencies in the nave implementation of vsm are compensated in several ways by using thesaurus, grouping, and clustering, as explained in subsections 2.3 and 3.2.
</nextsent>
<nextsent>5.3 future work.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5613">
<title id=" P02-1023.xml">improving language model size reduction using better pruning criteria </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>4.
</prevsent>
<prevsent>re-compute backoff weights..
</prevsent>
</prevsection>
<citsent citstr=" P00-1073 ">
figure 1: thresholding algorithm for bigram pruning the algorithm in figure 1 together with several pruning criteria has been studied previously (seymore and rosenfeld, 1996; stolcke, 1998; gao and lee, 2000; <papid> P00-1073 </papid>etc).</citsent>
<aftsection>
<nextsent>a comparative study of these techniques is presented in (goodman and gao, 2000).
</nextsent>
<nextsent>in this paper, three pruning criteria will be studied: probability, rank, and entropy.
</nextsent>
<nextsent>probability serves as the baseline pruning criterion.
</nextsent>
<nextsent>it is derived from perplexity which has been widely used as lm evaluation measure.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5614">
<title id=" P03-1004.xml">fast methods for kernel based text analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>kernel methods (e.g., support vector machines(vapnik, 1995)) attract great deal of attention recently.
</prevsent>
<prevsent>in the field of natural language processing, many successes have been reported.
</prevsent>
</prevsection>
<citsent citstr=" P02-1063 ">
examples include part-of-speech tagging (nakagawa et al, 2002) <papid> P02-1063 </papid>text chunking (kudo and matsumoto, 2001), <papid> N01-1025 </papid>named entity recognition (isozaki and kazawa, 2002), <papid> C02-1054 </papid>and japanese dependency parsing (kudo and matsumoto, 2000; <papid> W00-1303 </papid>kudo and matsumoto, 2002).<papid> W02-2016 </papid></citsent>
<aftsection>
<nextsent>it is known in nlp that combination of features contributes to significant improvement inaccuracy.
</nextsent>
<nextsent>for instance, in the task of dependency parsing, itwould be hard to confirm correct dependency relation with only single set of features from either head or its modifier.
</nextsent>
<nextsent>rather, dependency relations should be determined by at least information from both of two phrases.
</nextsent>
<nextsent>in previous research, feature combination has been selected manually, and the performance significantly depended on these selections.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5615">
<title id=" P03-1004.xml">fast methods for kernel based text analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>kernel methods (e.g., support vector machines(vapnik, 1995)) attract great deal of attention recently.
</prevsent>
<prevsent>in the field of natural language processing, many successes have been reported.
</prevsent>
</prevsection>
<citsent citstr=" N01-1025 ">
examples include part-of-speech tagging (nakagawa et al, 2002) <papid> P02-1063 </papid>text chunking (kudo and matsumoto, 2001), <papid> N01-1025 </papid>named entity recognition (isozaki and kazawa, 2002), <papid> C02-1054 </papid>and japanese dependency parsing (kudo and matsumoto, 2000; <papid> W00-1303 </papid>kudo and matsumoto, 2002).<papid> W02-2016 </papid></citsent>
<aftsection>
<nextsent>it is known in nlp that combination of features contributes to significant improvement inaccuracy.
</nextsent>
<nextsent>for instance, in the task of dependency parsing, itwould be hard to confirm correct dependency relation with only single set of features from either head or its modifier.
</nextsent>
<nextsent>rather, dependency relations should be determined by at least information from both of two phrases.
</nextsent>
<nextsent>in previous research, feature combination has been selected manually, and the performance significantly depended on these selections.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5616">
<title id=" P03-1004.xml">fast methods for kernel based text analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>kernel methods (e.g., support vector machines(vapnik, 1995)) attract great deal of attention recently.
</prevsent>
<prevsent>in the field of natural language processing, many successes have been reported.
</prevsent>
</prevsection>
<citsent citstr=" C02-1054 ">
examples include part-of-speech tagging (nakagawa et al, 2002) <papid> P02-1063 </papid>text chunking (kudo and matsumoto, 2001), <papid> N01-1025 </papid>named entity recognition (isozaki and kazawa, 2002), <papid> C02-1054 </papid>and japanese dependency parsing (kudo and matsumoto, 2000; <papid> W00-1303 </papid>kudo and matsumoto, 2002).<papid> W02-2016 </papid></citsent>
<aftsection>
<nextsent>it is known in nlp that combination of features contributes to significant improvement inaccuracy.
</nextsent>
<nextsent>for instance, in the task of dependency parsing, itwould be hard to confirm correct dependency relation with only single set of features from either head or its modifier.
</nextsent>
<nextsent>rather, dependency relations should be determined by at least information from both of two phrases.
</nextsent>
<nextsent>in previous research, feature combination has been selected manually, and the performance significantly depended on these selections.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5617">
<title id=" P03-1004.xml">fast methods for kernel based text analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>kernel methods (e.g., support vector machines(vapnik, 1995)) attract great deal of attention recently.
</prevsent>
<prevsent>in the field of natural language processing, many successes have been reported.
</prevsent>
</prevsection>
<citsent citstr=" W00-1303 ">
examples include part-of-speech tagging (nakagawa et al, 2002) <papid> P02-1063 </papid>text chunking (kudo and matsumoto, 2001), <papid> N01-1025 </papid>named entity recognition (isozaki and kazawa, 2002), <papid> C02-1054 </papid>and japanese dependency parsing (kudo and matsumoto, 2000; <papid> W00-1303 </papid>kudo and matsumoto, 2002).<papid> W02-2016 </papid></citsent>
<aftsection>
<nextsent>it is known in nlp that combination of features contributes to significant improvement inaccuracy.
</nextsent>
<nextsent>for instance, in the task of dependency parsing, itwould be hard to confirm correct dependency relation with only single set of features from either head or its modifier.
</nextsent>
<nextsent>rather, dependency relations should be determined by at least information from both of two phrases.
</nextsent>
<nextsent>in previous research, feature combination has been selected manually, and the performance significantly depended on these selections.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5619">
<title id=" P03-1004.xml">fast methods for kernel based text analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>kernel methods (e.g., support vector machines(vapnik, 1995)) attract great deal of attention recently.
</prevsent>
<prevsent>in the field of natural language processing, many successes have been reported.
</prevsent>
</prevsection>
<citsent citstr=" W02-2016 ">
examples include part-of-speech tagging (nakagawa et al, 2002) <papid> P02-1063 </papid>text chunking (kudo and matsumoto, 2001), <papid> N01-1025 </papid>named entity recognition (isozaki and kazawa, 2002), <papid> C02-1054 </papid>and japanese dependency parsing (kudo and matsumoto, 2000; <papid> W00-1303 </papid>kudo and matsumoto, 2002).<papid> W02-2016 </papid></citsent>
<aftsection>
<nextsent>it is known in nlp that combination of features contributes to significant improvement inaccuracy.
</nextsent>
<nextsent>for instance, in the task of dependency parsing, itwould be hard to confirm correct dependency relation with only single set of features from either head or its modifier.
</nextsent>
<nextsent>rather, dependency relations should be determined by at least information from both of two phrases.
</nextsent>
<nextsent>in previous research, feature combination has been selected manually, and the performance significantly depended on these selections.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5633">
<title id=" P03-1004.xml">fast methods for kernel based text analysis </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>o: outside of the chunk.
</prevsent>
<prevsent>in our experiments, we used the same settings as (kudo and matsumoto, 2002).<papid> W02-2016 </papid></prevsent>
</prevsection>
<citsent citstr=" W95-0107 ">
we use standard dataset (ramshaw and marcus,1995) <papid> W95-0107 </papid>consisting of sections 15-19 of the wsj corpus as training and section 20 as testing.</citsent>
<aftsection>
<nextsent>5.2 japanese word segmentation (jws).
</nextsent>
<nextsent>since there are no explicit spaces between words in japanese sentences, we must first identify the word boundaries before analyzing deep structure of sentence.
</nextsent>
<nextsent>japanese word segmentation is formalized as simple classification task.
</nextsent>
<nextsent>let = c1c2 ? ?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5640">
<title id=" P03-2006.xml">finding non local dependencies beyond pattern matching </title>
<section> abstract </section>
<citcontext>
<prevsection>

<prevsent>we describe an algorithm for recovering non-local dependencies in syntactic dependency structures.
</prevsent>
</prevsection>
<citsent citstr=" P02-1018 ">
the pattern matching approach proposed by johnson (2002) <papid> P02-1018 </papid>for similar task for phrase structure trees is extended with machine learning techniques.</citsent>
<aftsection>
<nextsent>the algorithm is essentially classifier that predicts non local dependency given connected fragment of dependency structure and aset of structural features for this fragment.
</nextsent>
<nextsent>evaluating the algorithm on the penn treebank shows an improvement of both precision and recall, compared to the results presented in (johnson, 2002).<papid> P02-1018 </papid></nextsent>
<nextsent>non-local dependencies (also called long-distance,long-range or unbounded) appear in many frequent linguistic phenomena, such as passive, wh movement, control and raising etc. although much current research in natural language parsing focuses on extracting local syntactic relations from text, non local dependencies have recently started to attract more attention.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5647">
<title id=" P03-2006.xml">finding non local dependencies beyond pattern matching </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>evaluating the algorithm on the penn treebank shows an improvement of both precision and recall, compared to the results presented in (johnson, 2002).<papid> P02-1018 </papid></prevsent>
<prevsent>non-local dependencies (also called long-distance,long-range or unbounded) appear in many frequent linguistic phenomena, such as passive, wh movement, control and raising etc. although much current research in natural language parsing focuses on extracting local syntactic relations from text, non local dependencies have recently started to attract more attention.</prevsent>
</prevsection>
<citsent citstr=" P02-1042 ">
in (clark et al, 2002) <papid> P02-1042 </papid>long-range dependencies are included in parsers probabilistic model, while johnson (2002) <papid> P02-1018 </papid>presents method for recovering non-local dependencies after parsing has been performed.</citsent>
<aftsection>
<nextsent>more specifically, johnson (2002) <papid> P02-1018 </papid>describes pattern-matching algorithm for inserting empty nodes and identifying their antecedents in phrase structure trees or, to put it differently, for recovering non-local dependencies.</nextsent>
<nextsent>from training corpus with annotated empty nodes johnsons algorithm first extracts those local fragments of phrase trees which connect empty nodes with their antecedents,thus licensing?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5662">
<title id=" P03-2006.xml">finding non local dependencies beyond pattern matching </title>
<section> from the penn treebank to a.  </section>
<citcontext>
<prevsection>
<prevsent>however, additional work remains to be done for our algorithm to perform well on the output of parser.
</prevsent>
<prevsent>dependency treebank this section describes the corpus of dependency structures that we used to evaluate our algorithm.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
the corpus was automatically derived from the penn treebank ii corpus (marcus et al, 1993), <papid> J93-2004 </papid>by means of the script chunklink.pl (buchholz, 2002) that we modified to fit our purposes.</citsent>
<aftsection>
<nextsent>the script uses sort of head percolation table to identify heads of constituents, and then converts the result to dependency format.
</nextsent>
<nextsent>we refer to (buchholz, 2002) for thorough description of the conversion algorithm, and will only emphasize the two most important modifications that we made.
</nextsent>
<nextsent>one modification of the conversion algorithm concerns participles and reduced relative clauses modifying nps.
</nextsent>
<nextsent>regular participles in the penn treebank ii are simply annotated as vps adjoinedto the modified nps (see figure 1(a)).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5663">
<title id=" P03-2006.xml">finding non local dependencies beyond pattern matching </title>
<section> from the penn treebank to a.  </section>
<citcontext>
<prevsection>
<prevsent>script concerns the structure of vps.
</prevsent>
<prevsent>for every verb cluster, we choose the main verb as the head of the cluster, and leave modal and auxiliary verbs as dependents of the main verb.
</prevsent>
</prevsection>
<citsent citstr=" C96-1058 ">
a similar modification was used by eisner (1996) <papid> C96-1058 </papid>for the study of dependency parsing models.</citsent>
<aftsection>
<nextsent>as will be described below, this allows us to factor out?
</nextsent>
<nextsent>tense and modality of finite clauses from our patterns, making the patterns more general.
</nextsent>
<nextsent>after converting the penn treebank to dependency treebank, we first extracted non-local dependency patterns.
</nextsent>
<nextsent>as in (johnson, 2002), <papid> P02-1018 </papid>our patterns are minimal connected fragments containing both nodes involved in non-local dependency.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5710">
<title id=" P01-1018.xml">constraints on strong generative power </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>how much strong generative power can be squeezed out of formal system without increasing its weak generative power??
</prevsent>
<prevsent>this question,posed by joshi (2000), is important for both linguistic description and natural language processing.
</prevsent>
</prevsection>
<citsent citstr=" P93-1017 ">
the extension of tree adjoining grammar (tag) to tree-local multicomponent tag (joshi,1987), or the extension of context free grammar (cfg) to tree insertion grammar (schabes and waters, 1993) <papid> P93-1017 </papid>or regular form tag (rogers, 1994) <papid> P94-1022 </papid>can be seen as steps toward answering this question.</citsent>
<aftsection>
<nextsent>but this question is difficult to answer with much finality unless we pin its terms down more precisely.
</nextsent>
<nextsent>first, what is meant by strong generative power?
</nextsent>
<nextsent>in the standard definition (chomsky, 1965) grammar weakly generates set of sentences l(g) and strongly generates set of structural descriptions ?(g); the strong generative capacity of formalism is then f?(g) f provides gg.
</nextsent>
<nextsent>there is some vagueness in the literature, however, over what structural descriptions are and how they can reasonably be compared across theories (miller (1999) gives good synopsis).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5711">
<title id=" P01-1018.xml">constraints on strong generative power </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>how much strong generative power can be squeezed out of formal system without increasing its weak generative power??
</prevsent>
<prevsent>this question,posed by joshi (2000), is important for both linguistic description and natural language processing.
</prevsent>
</prevsection>
<citsent citstr=" P94-1022 ">
the extension of tree adjoining grammar (tag) to tree-local multicomponent tag (joshi,1987), or the extension of context free grammar (cfg) to tree insertion grammar (schabes and waters, 1993) <papid> P93-1017 </papid>or regular form tag (rogers, 1994) <papid> P94-1022 </papid>can be seen as steps toward answering this question.</citsent>
<aftsection>
<nextsent>but this question is difficult to answer with much finality unless we pin its terms down more precisely.
</nextsent>
<nextsent>first, what is meant by strong generative power?
</nextsent>
<nextsent>in the standard definition (chomsky, 1965) grammar weakly generates set of sentences l(g) and strongly generates set of structural descriptions ?(g); the strong generative capacity of formalism is then f?(g) f provides gg.
</nextsent>
<nextsent>there is some vagueness in the literature, however, over what structural descriptions are and how they can reasonably be compared across theories (miller (1999) gives good synopsis).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5712">
<title id=" P01-1018.xml">constraints on strong generative power </title>
<section> simulating structural descriptions.  </section>
<citcontext>
<prevsection>
<prevsent>the only if?
</prevsent>
<prevsent>direction ()) shows that, in the sense we have defined, rf-mmtag is the most powerful such formalism.
</prevsent>
</prevsection>
<citsent citstr=" P99-1011 ">
we can generalize this result using the notion of meta-level grammar (dras, 1999).<papid> P99-1011 </papid></citsent>
<aftsection>
<nextsent>definition 7 if f1 and f2 are two cfrss, f2  f1 is the cfrs characterized by the interpretation function ~
</nextsent>
<nextsent>f2f1 = ~
</nextsent>
<nextsent>f2  ~
</nextsent>
<nextsent>f1 . f1 is the meta-level formalism, which generates derivations for f2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5713">
<title id=" P01-1018.xml">constraints on strong generative power </title>
<section> multicomponent multi foot tag.  </section>
<citcontext>
<prevsection>
<prevsent>direction (() is little trickier because the constructed cfg inserts and re labels nodes.
</prevsent>
<prevsent>4.1 definitions.
</prevsent>
</prevsection>
<citsent citstr=" C88-1001 ">
mmtag resembles cross between set-local multicomponent tag (joshi, 1987) and ranked node rewriting grammar (abe, 1988), <papid> C88-1001 </papid>variant of tag in which auxiliary trees may have multiple foot nodes.</citsent>
<aftsection>
<nextsent>it also has much in common with tree substitution grammar (rambow et al, 1995).<papid> P95-1021 </papid></nextsent>
<nextsent>definition 8 an elementary tree set ~?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5714">
<title id=" P01-1018.xml">constraints on strong generative power </title>
<section> multicomponent multi foot tag.  </section>
<citcontext>
<prevsection>
<prevsent>4.1 definitions.
</prevsent>
<prevsent>mmtag resembles cross between set-local multicomponent tag (joshi, 1987) and ranked node rewriting grammar (abe, 1988), <papid> C88-1001 </papid>variant of tag in which auxiliary trees may have multiple foot nodes.</prevsent>
</prevsection>
<citsent citstr=" P95-1021 ">
it also has much in common with tree substitution grammar (rambow et al, 1995).<papid> P95-1021 </papid></citsent>
<aftsection>
<nextsent>definition 8 an elementary tree set ~?
</nextsent>
<nextsent>is finite set of trees (called the components of ~?)
</nextsent>
<nextsent>with the following properties: 1.
</nextsent>
<nextsent>zero or more frontier nodes are designated.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5715">
<title id=" P03-1058.xml">exploiting parallel texts for word sense disambiguation an empirical study </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>corpus obtained via parallel text alignment, compared with training on manually sense-tagged corpus?
</prevsent>
<prevsent>much research remains to be done to investigate all of the above issues.
</prevsent>
</prevsection>
<citsent citstr=" P99-1068 ">
the lack of large-scale parallel corpora no doubt has impeded progress in this direction, although attempts have been made to mine parallel corpora from the web (resnik, 1999).<papid> P99-1068 </papid></citsent>
<aftsection>
<nextsent>however, large-scale, good-quality parallel corpora have recently become available.
</nextsent>
<nextsent>forex ample, six english-chinese parallel corpora are now available from linguistic data consortium.
</nextsent>
<nextsent>these parallel corpora are listed in table 2, with combined size of 280 mb.
</nextsent>
<nextsent>in this paper, we address the above issues and report our findings, exploiting the english-chinese parallel corpora in table 2 for word sense disambiguation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5716">
<title id=" P03-1058.xml">exploiting parallel texts for word sense disambiguation an empirical study </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>2 2.1 2.2 2.3 2.4 approach our approach of exploiting parallel texts for word sense disambiguation consists of four steps: (1) parallel text alignment (2) manual selection of target translations (3) training of wsd classifier (4) wsd of words in new contexts.
</prevsent>
<prevsent>parallel text alignment in this step, parallel texts are first sentence-aligned and then word-aligned.
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
various alignment algorithms (melamed 2001; och and ney 2000) <papid> P00-1056 </papid>have been developed in the past.</citsent>
<aftsection>
<nextsent>for the six bilingual corpora that we used, they already come with sentences pre-aligned, either manually when the corpora were prepared or automatically by sentence alignment programs.
</nextsent>
<nextsent>after sentence alignment, the english texts are tokenized so that punctuation symbol is separated from its preceding word.
</nextsent>
<nextsent>for the chinese texts, we performed word segmentation, so that chinese characters are segmented into words.
</nextsent>
<nextsent>the resulting parallel texts are then input to the giza++ software (och and ney 2000) <papid> P00-1056 </papid>for word alignment.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5720">
<title id=" P03-1058.xml">exploiting parallel texts for word sense disambiguation an empirical study </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this is relatively short time, especially when compared to the effort that we would otherwise need to spend to perform manual sense-tagging of training examples.
</prevsent>
<prevsent>this step could also be potentially automated if we have suitable bilingual translation lexicon.
</prevsent>
</prevsection>
<citsent citstr=" W02-1004 ">
training of wsd classifier much research has been done on the best supervised learning approach for wsd (florian and yarowsky, 2002; <papid> W02-1004 </papid>lee and ng, 2002; mihalcea and moldovan, 2001; yarowsky et al, 2001).</citsent>
<aftsection>
<nextsent>in this paper, we used the wsd program reported in (lee and ng, 2002).
</nextsent>
<nextsent>in particular, our method made use of the knowledge sources of part-of-speech, surrounding words, and local collocations.
</nextsent>
<nextsent>we used nave bayes as the learning algorithm.
</nextsent>
<nextsent>our previous research demonstrated that such an approach leads to state-of-the-art wsd program with good performance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5721">
<title id=" P03-1058.xml">exploiting parallel texts for word sense disambiguation an empirical study </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>on average, about 9.8 training examples and 6.2 test examples contain this collocation.
</prevsent>
<prevsent>this alone would have accounted for 0.088 of the accuracy difference between the two approaches.
</prevsent>
</prevsection>
<citsent citstr=" W00-1322 ">
that domain dependence is an important issue affecting the performance of wsd programs has been pointed out by (escudero et al, 2000).<papid> W00-1322 </papid></citsent>
<aftsection>
<nextsent>our work confirms the importance of domain dependence in wsd.
</nextsent>
<nextsent>as to the problem of insufficient sense cover age, with the steady increase and availability of parallel corpora, we believe that getting sufficient sense coverage from larger parallel corpora should not be problem in the near future for most of the commonly occurring words in language.
</nextsent>
<nextsent>related work brown et al (1991) <papid> P91-1034 </papid>is the first to have explored statistical methods in word sense disambiguation in the context of machine translation.</nextsent>
<nextsent>however, they only looked at assigning at most two senses to word, and their method only asked single question about single word of context.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5722">
<title id=" P03-1058.xml">exploiting parallel texts for word sense disambiguation an empirical study </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our work confirms the importance of domain dependence in wsd.
</prevsent>
<prevsent>as to the problem of insufficient sense cover age, with the steady increase and availability of parallel corpora, we believe that getting sufficient sense coverage from larger parallel corpora should not be problem in the near future for most of the commonly occurring words in language.
</prevsent>
</prevsection>
<citsent citstr=" P91-1034 ">
related work brown et al (1991) <papid> P91-1034 </papid>is the first to have explored statistical methods in word sense disambiguation in the context of machine translation.</citsent>
<aftsection>
<nextsent>however, they only looked at assigning at most two senses to word, and their method only asked single question about single word of context.
</nextsent>
<nextsent>li and li (2002) <papid> P02-1044 </papid>investigated bilingual bootstrapping technique, which differs from the method we implemented here.</nextsent>
<nextsent>their method also does not require parallel corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5723">
<title id=" P03-1058.xml">exploiting parallel texts for word sense disambiguation an empirical study </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>related work brown et al (1991) <papid> P91-1034 </papid>is the first to have explored statistical methods in word sense disambiguation in the context of machine translation.</prevsent>
<prevsent>however, they only looked at assigning at most two senses to word, and their method only asked single question about single word of context.</prevsent>
</prevsection>
<citsent citstr=" P02-1044 ">
li and li (2002) <papid> P02-1044 </papid>investigated bilingual bootstrapping technique, which differs from the method we implemented here.</citsent>
<aftsection>
<nextsent>their method also does not require parallel corpus.
</nextsent>
<nextsent>the research of (chugur et al, 2002) <papid> W02-0805 </papid>dealt with sense distinctions across multiple languages.</nextsent>
<nextsent>ide et al.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5724">
<title id=" P03-1058.xml">exploiting parallel texts for word sense disambiguation an empirical study </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>li and li (2002) <papid> P02-1044 </papid>investigated bilingual bootstrapping technique, which differs from the method we implemented here.</prevsent>
<prevsent>their method also does not require parallel corpus.</prevsent>
</prevsection>
<citsent citstr=" W02-0805 ">
the research of (chugur et al, 2002) <papid> W02-0805 </papid>dealt with sense distinctions across multiple languages.</citsent>
<aftsection>
<nextsent>ide et al.
</nextsent>
<nextsent>(2002) investigated word sense distinctions using parallel corpora.
</nextsent>
<nextsent>resnik and yarowsky (2000) considered word sense disambiguation using multiple languages.
</nextsent>
<nextsent>our present work can be similarly extended beyond bilingual corpora to multilingual corpora.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5725">
<title id=" P03-1058.xml">exploiting parallel texts for word sense disambiguation an empirical study </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>resnik and yarowsky (2000) considered word sense disambiguation using multiple languages.
</prevsent>
<prevsent>our present work can be similarly extended beyond bilingual corpora to multilingual corpora.
</prevsent>
</prevsection>
<citsent citstr=" P02-1033 ">
the research most similar to ours is the work of diab and resnik (2002).<papid> P02-1033 </papid></citsent>
<aftsection>
<nextsent>however, they used machine translated parallel corpus instead of human translated parallel corpus.
</nextsent>
<nextsent>in addition, they used an unsupervised method of noun group disambiguation, and evaluated on the english all-words task.
</nextsent>
<nextsent>conclusion in this paper, we reported an empirical study to evaluate an approach of automatically acquiring sense-tagged training data from english-chinese parallel corpora, which were then used for disam biguating the nouns in the senseval-2 english lexical sample task.
</nextsent>
<nextsent>our investigation reveals that this method of acquiring sense-tagged data is promising and provides an alternative to manual sense tagging.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5726">
<title id=" P04-1088.xml">flsa extending latent semantic analysis with features for dialogue act classification </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>surprisingly, one dialogue related feature that does not help is the dialogue act history.we applied lsa / flsa to dialogue act classification.
</prevsent>
<prevsent>dialogue systems need to perform dialogue act classification, in order to understand the role the users utterance plays in the dialogue (e.g., question for information or request to per forman action).
</prevsent>
</prevsection>
<citsent citstr=" P98-2188 ">
in recent years, variety of empirical techniques have been used to train the dialogue act classifier (samuel et al, 1998; <papid> P98-2188 </papid>stolcke et al, 2000).<papid> J00-3003 </papid></citsent>
<aftsection>
<nextsent>a second contribution of our work is toshow that flsa is successful at dialogue act classification, reaching comparable or better results than other published methods.
</nextsent>
<nextsent>with respect to baseline of choosing the most frequent dialogue act (da), lsa reduces error rates between 33% and 52%, and flsa reduces error rates between 60% and 78%.
</nextsent>
<nextsent>lsa is an attractive method for this task because it is straightforward to train and use.
</nextsent>
<nextsent>more importantly, although it is statistical theory, it has been shown to mimic many aspects of human competence / performance (landauer and dumais, 1997).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5727">
<title id=" P04-1088.xml">flsa extending latent semantic analysis with features for dialogue act classification </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>surprisingly, one dialogue related feature that does not help is the dialogue act history.we applied lsa / flsa to dialogue act classification.
</prevsent>
<prevsent>dialogue systems need to perform dialogue act classification, in order to understand the role the users utterance plays in the dialogue (e.g., question for information or request to per forman action).
</prevsent>
</prevsection>
<citsent citstr=" J00-3003 ">
in recent years, variety of empirical techniques have been used to train the dialogue act classifier (samuel et al, 1998; <papid> P98-2188 </papid>stolcke et al, 2000).<papid> J00-3003 </papid></citsent>
<aftsection>
<nextsent>a second contribution of our work is toshow that flsa is successful at dialogue act classification, reaching comparable or better results than other published methods.
</nextsent>
<nextsent>with respect to baseline of choosing the most frequent dialogue act (da), lsa reduces error rates between 33% and 52%, and flsa reduces error rates between 60% and 78%.
</nextsent>
<nextsent>lsa is an attractive method for this task because it is straightforward to train and use.
</nextsent>
<nextsent>more importantly, although it is statistical theory, it has been shown to mimic many aspects of human competence / performance (landauer and dumais, 1997).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5731">
<title id=" P04-1088.xml">flsa extending latent semantic analysis with features for dialogue act classification </title>
<section> corpora.  </section>
<citcontext>
<prevsection>
<prevsent>for noise.
</prevsent>
<prevsent>call home spanish is further annotated for dialogue games and activities.
</prevsent>
</prevsection>
<citsent citstr=" J97-1002 ">
dialogue game annotation is based on the maptask notion of dialogue game, set of utterances starting with an initiation and encompassing all utterances up until the purpose ofthe game has been fulfilled (e.g., the requested information has been transferred) or abandoned (car letta et al, 1997).<papid> J97-1002 </papid></citsent>
<aftsection>
<nextsent>moves are the components of games, they correspond to single or more das,and each is tagged as initiative, response or feed back.
</nextsent>
<nextsent>each game is also given label, such asinfo(rmation) or direct(ive).
</nextsent>
<nextsent>finally, activities pertain to the main goal of certain discourse stretch, such as gossip or argue.the hcrc maptask corpus is collection of dialogues regarding map task?
</nextsent>
<nextsent>experiment.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5735">
<title id=" P04-1088.xml">flsa extending latent semantic analysis with features for dialogue act classification </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>in maptask srule indicates the main structure of the utterance, such as declarative or wh-question.
</prevsent>
<prevsent>it is not surprising thats rule did not help, since it is well known that syntactic form is not predictive of das, especially those of indirect speech act flavor (searle, 1975).
</prevsent>
</prevsection>
<citsent citstr=" W03-0208 ">
postags dont help lsa either, as has already been observed by (wiemer-hastings, 2001; kanejiya et al, 2003) <papid> W03-0208 </papid>for other tasks.</citsent>
<aftsection>
<nextsent>the likely reason is that it is necessary to add different word?
</nextsent>
<nextsent>for each distinct pair word-pos, e.g., route becomes split as route nn and route-vb.
</nextsent>
<nextsent>this makes the word-document matrix much sparser: for maptask, the number of rows increases from 1,835 for plain lsa to 2,324 for flsa.these negative results on adding syntactic information to lsa may just reinforce one of the claims of the lsa proponents, that structural information is irrelevant for determining meaning (landauer and dumais, 1997).
</nextsent>
<nextsent>alternatively, syntactic information may need to be added to lsa in different ways.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5736">
<title id=" P04-1088.xml">flsa extending latent semantic analysis with features for dialogue act classification </title>
<section> discussion and future work.  </section>
<citcontext>
<prevsection>
<prevsent>further, if the system can reliably recognize the end of game, the method just described needs to be used only for the first da of each game.
</prevsent>
<prevsent>then, the game label that gives the best result becomes the game label used for the next few das, until the end of the current game is detected.
</prevsent>
</prevsection>
<citsent citstr=" J96-2004 ">
another reason why we advocate flsa ove rother approaches is that it appears to be close to human performance for da classification, in the same way that lsa approximates well many aspects of human competence / performance (landauer and dumais, 1997).to support this claim, first, we used the ? coefficient (krippendorff, 1980; carletta, 1996) <papid> J96-2004 </papid>to assess the agreement between the classification made by flsa and the classification from the corpora ? see table 8.</citsent>
<aftsection>
<nextsent>a general rule of thumb on how to interpret the values of ?
</nextsent>
<nextsent>(krippendorff, 1980) is to require value of ? ?
</nextsent>
<nextsent>0.8, with 0.67   ?   0.8 allowing tentative conclusions to be drawn.
</nextsent>
<nextsent>as awhole, table 8 shows that flsa achieves satisfying level of agreement with human coders.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5739">
<title id=" P04-1088.xml">flsa extending latent semantic analysis with features for dialogue act classification </title>
<section> discussion and future work.  </section>
<citcontext>
<prevsection>
<prevsent>thus, most of the sources of confusion for humans are the same as for flsa.
</prevsent>
<prevsent>future work includes further investigating how to select promising feature combinations, e.g. by using logical regression.
</prevsent>
</prevsection>
<citsent citstr=" W02-0205 ">
we are also exploring whether flsa can be usedas the basis for semi-automatic annotation of dialogue acts, to be incorporated into mup, an annotation tool we have developed (glass and di eugenio,2002).<papid> W02-0205 </papid></citsent>
<aftsection>
<nextsent>the problem is that large corpora are necessary to train methods based on lsa.
</nextsent>
<nextsent>this would seem to defeat the purpose of using flsa as the basis for semi-automatic dialogue annotation, since, to train flsa in new domain, we would need large hand annotated corpus to start with.
</nextsent>
<nextsent>co-training (blum and mitchell, 1998) may offer solution tothis problem.
</nextsent>
<nextsent>in co-training, two different classifiers are initially trained on small set of annotated data, by using different features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5740">
<title id=" P04-1070.xml">an alternative method of training probabilistic lr parsers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we present an alternative way of training that is prov ably optimal, and that allows all probability distributions expressible in the context-free grammar to be carried over to the lr parser.
</prevsent>
<prevsent>we also demonstrate empirically that this kind of training can be effectively applied on large treebank.
</prevsent>
</prevsection>
<citsent citstr=" J93-1002 ">
the lr parsing strategy was originally devised for programming languages (sippu and soi salon soininen, 1990), but has been used in wide range of other areas as well, such as for natural language processing (lavie and tomita, 1993; briscoe and carroll, 1993; <papid> J93-1002 </papid>ruland, 2000).<papid> C00-2098 </papid></citsent>
<aftsection>
<nextsent>the main difference between the application to programming languages and the application to natural languages is that inthe latter case the parsers should be nondetermin istic, in order to deal with ambiguous context-freegrammars (cfgs).
</nextsent>
<nextsent>non determinism can be handled in number of ways, but the most efficient is tabulation, which allows processing in polyno mial time.
</nextsent>
<nextsent>tabular lr parsing is known from the work by (tomita, 1986), but can also be achieved by the generic tabulation technique due to (lang,1974; billot and lang, 1989), which assumes an in put push down transducer (pdt).
</nextsent>
<nextsent>in this context, thelr parsing strategy can be seen as particular mapping from context-free grammars to pdts.the acronym lr?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5741">
<title id=" P04-1070.xml">an alternative method of training probabilistic lr parsers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we present an alternative way of training that is prov ably optimal, and that allows all probability distributions expressible in the context-free grammar to be carried over to the lr parser.
</prevsent>
<prevsent>we also demonstrate empirically that this kind of training can be effectively applied on large treebank.
</prevsent>
</prevsection>
<citsent citstr=" C00-2098 ">
the lr parsing strategy was originally devised for programming languages (sippu and soi salon soininen, 1990), but has been used in wide range of other areas as well, such as for natural language processing (lavie and tomita, 1993; briscoe and carroll, 1993; <papid> J93-1002 </papid>ruland, 2000).<papid> C00-2098 </papid></citsent>
<aftsection>
<nextsent>the main difference between the application to programming languages and the application to natural languages is that inthe latter case the parsers should be nondetermin istic, in order to deal with ambiguous context-freegrammars (cfgs).
</nextsent>
<nextsent>non determinism can be handled in number of ways, but the most efficient is tabulation, which allows processing in polyno mial time.
</nextsent>
<nextsent>tabular lr parsing is known from the work by (tomita, 1986), but can also be achieved by the generic tabulation technique due to (lang,1974; billot and lang, 1989), which assumes an in put push down transducer (pdt).
</nextsent>
<nextsent>in this context, thelr parsing strategy can be seen as particular mapping from context-free grammars to pdts.the acronym lr?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5747">
<title id=" P04-1070.xml">an alternative method of training probabilistic lr parsers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in other words, the resulting probability function pa on transitions of the pdt allows better disambiguation than the corresponding function pg on rules of the original grammar.a plausible explanation of this is that stack symbols of an lr parser encode some amount of left context, i.e. information on rules applied earlier, sothat the probability function on transitions may encode dependencies between rules that cannot be encoded in terms of the original cfg extended with rule probabilities.
</prevsent>
<prevsent>the explicit use of left context in probabilistic context-free models was investigated by e.g.
</prevsent>
</prevsection>
<citsent citstr=" J98-4004 ">
(chitrao and grishman, 1990; johnson, 1998), <papid> J98-4004 </papid>who also demonstrated that this may significantly improve accuracy.</citsent>
<aftsection>
<nextsent>note that the probability distributions of language may be beyond the reach of given context-free grammar, as pointed out by e.g.
</nextsent>
<nextsent>(collins, 2001).
</nextsent>
<nextsent>therefore, the use of left context, and the resulting increase in the number of parameters of the model, may narrow the gap between the given grammar and ill-understood mechanisms underlying actual language.
</nextsent>
<nextsent>one important assumption that is made by (briscoe and carroll, 1993) <papid> J93-1002 </papid>and (inui et al, 2000) is that trained probabilistic lr parsers should be proper, i.e. if several transitions are applicable fora given stack, then the sum of probabilities assigned to those transitions by probability functionpa should be 1.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5750">
<title id=" P04-1070.xml">an alternative method of training probabilistic lr parsers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this respect, lr parsing differs from at least one otherwell-known parsing strategy, viz.
</prevsent>
<prevsent>left-corner parsing.
</prevsent>
</prevsection>
<citsent citstr=" P04-1069 ">
see (nederhof and satta, 2004) <papid> P04-1069 </papid>for discussion of property that is shared by left-corner parsing but not by lr parsing, and which explains the above difference.</citsent>
<aftsection>
<nextsent>as main contribution of this paper we establish that this restriction on expressible probability distributions can be dispensed with, without losing the ability to perform training by relative frequency estimation.
</nextsent>
<nextsent>what comes in place of properness isreverse-properness, which can be seen as properness of the reversed push down automaton that processes input from right to left instead of from left to right, interpreting the transitions of backwards.as we will show, reverse-properness does not restrict the space of probability distributions express ible by an lr automaton.
</nextsent>
<nextsent>more precisely, assume some probability distribution on the set of derivations is specified by probability function pa on transitions of pdt that realizes the lr strategy forgiven grammar g. then the same probability distribution can be specified by an alternative such function pa that is reverse-proper.
</nextsent>
<nextsent>in addition, for each probability distribution on derivations expressible by probability function pg for g, there is reverse-proper probability function pa for that expresses the same probability distribution.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5751">
<title id=" P04-1070.xml">an alternative method of training probabilistic lr parsers </title>
<section> lr parsing.  </section>
<citcontext>
<prevsection>
<prevsent>otherwise, the time complexity would be o(nm+1), where is the length of the longest right-hand side of rule in the cfg.
</prevsent>
<prevsent>this observation was made before by (kipps, 1991), who proposed solution similar to ours, albeit formulated differently.
</prevsent>
</prevsection>
<citsent citstr=" P96-1032 ">
see also related formulation of tabular lr parsing by (nederhof and satta, 1996).<papid> P96-1032 </papid></citsent>
<aftsection>
<nextsent>to be more specific, instead of one step of the pdt taking stack: p0p1 ? ?
</nextsent>
<nextsent>pm immediately to stack: p0q where (a ? x1 ? ?
</nextsent>
<nextsent>xm ?) ?
</nextsent>
<nextsent>pm, ? is string of stack symbols and goto(p0, a) = q, we have number of smaller steps leading to series of stacks: p0p1 ? ?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5753">
<title id=" P04-1070.xml">an alternative method of training probabilistic lr parsers </title>
<section> properness and reverse-properness.  </section>
<citcontext>
<prevsection>
<prevsent>in other words, if probability distribution can be defined by attaching probabilities to rules, then we may reassign the probabilities such that that pcfg becomes proper, while preserving the probability distribution.
</prevsent>
<prevsent>this even holds if the input grammar is non-tight, meaning that probability mass is lost in infinite derivations?
</prevsent>
</prevsection>
<citsent citstr=" J98-2005 ">
(sanchez and bened??, 1997; chi and geman, 1998; <papid> J98-2005 </papid>chi, 1999; <papid> J99-1004 </papid>nederhof and satta, 2003).although cfgs and pdts are weakly equivalent, they behave very differently when they are extended with probabilities.</citsent>
<aftsection>
<nextsent>in particular, there seems to be no notion similar to pcfg properness thatcan be imposed on all types of pdts without losing generality.
</nextsent>
<nextsent>below we will discuss two constraints, which we will call properness and reverse properness.
</nextsent>
<nextsent>neither of these is suitable for all types of pdts, but as we will show, the second is more suitable for probabilistic lr parsing than the first.this is surprising, as only properness has been described in existing literature on probabilistic pdts (ppdts).
</nextsent>
<nextsent>in particular, all existing approaches to probabilistic lr parsing have assumed properness rather than anything related to reverse-properness.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5754">
<title id=" P04-1070.xml">an alternative method of training probabilistic lr parsers </title>
<section> properness and reverse-properness.  </section>
<citcontext>
<prevsection>
<prevsent>in other words, if probability distribution can be defined by attaching probabilities to rules, then we may reassign the probabilities such that that pcfg becomes proper, while preserving the probability distribution.
</prevsent>
<prevsent>this even holds if the input grammar is non-tight, meaning that probability mass is lost in infinite derivations?
</prevsent>
</prevsection>
<citsent citstr=" J99-1004 ">
(sanchez and bened??, 1997; chi and geman, 1998; <papid> J98-2005 </papid>chi, 1999; <papid> J99-1004 </papid>nederhof and satta, 2003).although cfgs and pdts are weakly equivalent, they behave very differently when they are extended with probabilities.</citsent>
<aftsection>
<nextsent>in particular, there seems to be no notion similar to pcfg properness thatcan be imposed on all types of pdts without losing generality.
</nextsent>
<nextsent>below we will discuss two constraints, which we will call properness and reverse properness.
</nextsent>
<nextsent>neither of these is suitable for all types of pdts, but as we will show, the second is more suitable for probabilistic lr parsing than the first.this is surprising, as only properness has been described in existing literature on probabilistic pdts (ppdts).
</nextsent>
<nextsent>in particular, all existing approaches to probabilistic lr parsing have assumed properness rather than anything related to reverse-properness.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5762">
<title id=" N12-2002.xml">automatic animacy classification </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this information is of interest within lexical semantics and has potential value as feature in several nlp tasks.we train discriminative classifier on an annotated corpus of spoken english, with features capturing each noun phrases constituent words, its internal structure, and its syntactic relations with other keywords in the sentence.
</prevsent>
<prevsent>only the first two of these three feature sets have substantial impact on performance, but the resulting model is able to fairly accurately classify new data from that corpus, and shows promise for binary animacy classification and for use on automatically parsed text.
</prevsent>
</prevsection>
<citsent citstr=" W04-0216 ">
an animacy hierarchy, in the sense of zaenen et al (2004), <papid> W04-0216 </papid>is set of mutually exclusive categories describing noun phrases (nps) in natural language sen tences.</citsent>
<aftsection>
<nextsent>these classes capture the degree to which the entity described by an np is capable of human like volition: key lexical semantic property which has been shown to trigger number of morphological and syntactic phenomena across languages.
</nextsent>
<nextsent>annotating corpus with this information can facilitate statistical semantic work, as well as providing potentially valuable feature discussed in zaenen et al .for tasks like relation extraction, parsing1, and 1using our model in parsing would require bootstrapping from oarser parses, as our model makes use of some syntactic features.
</nextsent>
<nextsent>machine translation.
</nextsent>
<nextsent>the handful of papers that we have found on animacy annotation centrally ji and lin (2009), vrelid (2005), and orasan and evans (2001)classify only the basic animate/inanimate contrast, but show some promise in doing so.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5764">
<title id=" N12-2002.xml">automatic animacy classification </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>this annotated section consists of about 110,000 sentences with about 300,000 nps.
</prevsent>
<prevsent>we divide these sentences into training set (80%), development set (10%),and test set (10%).2 every np in this section is either assigned class or marked as problematic, andwe train and test on all the nps for which the annotators were able to agree (after discussion) on an assignment.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
we use standard maximum entropy classifier (berger et al , 1996) <papid> J96-1002 </papid>to classify constituents: for each labeled np in the corpus, the model selects the locally most probable class.</citsent>
<aftsection>
<nextsent>our features are described in this section.we considered features that required dependencies between consecutively assigned classes, allowing large nps to depend on smaller nps contained within them, as in conjoined structures.
</nextsent>
<nextsent>these achieved somewhat better coverage of the rare mix class, but did not yield any gains in overall performance, and are not included in our results.
</nextsent>
<nextsent>2.1 bag-of-words features.
</nextsent>
<nextsent>our simplest feature set, hasword-(tag-)word, simply captures each word in the np, both with and without its accompanying part-of-speech (pos) tag.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5765">
<title id=" N12-2002.xml">automatic animacy classification </title>
<section> conclusion and future work.  </section>
<citcontext>
<prevsection>
<prevsent>this signals one possible site for further development.should this model be used in setting where external knowledge sources are available, two seem especially promising.
</prevsent>
<prevsent>synonyms and hypernymsfrom wordnet (fellbaum, 2010) or similar lexicon could be used to improve the models handling of unknown words demonstrated successfully with the aid of word sense disambiguation system in orasan and evans (2001) for binary animacy classification on single words.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
a lexical-semantic database like framenet (baker et al , 1998) <papid> P98-1013 </papid>could also be used to introduce semantic role labels (whichare tied to animacy restrictions) as features, potentially rescuing the intuition that governing verbs and prepositions carry animacy information.</citsent>
<aftsection>
<nextsent>acknowledgments we are indebted to marie-catherine de marneffe and jason graf miller, who first suggested we model this corpus, and to chris manning and our reviewers for valuable advice.
</nextsent>



</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5766">
<title id=" P04-1080.xml">learning word sense with feature selection and order identification capabilities </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>gaussian mixture model and minimum description length criterion are used to estimate cluster structure and cluster number.
</prevsent>
<prevsent>experimental results show that our algorithm canfind important feature subset, estimate model order (cluster number) and achieve better performance than another algorithm which requires cluster number to be provided.
</prevsent>
</prevsection>
<citsent citstr=" J98-1001 ">
sense disambiguation is essential for many language applications such as machine translation, information retrieval, and speech processing (ide and veronis, 1998).<papid> J98-1001 </papid></citsent>
<aftsection>
<nextsent>almost all of sense disambiguation methods are heavily dependant on manually compiled lexical resources.
</nextsent>
<nextsent>however these lexical resources often miss domain specific word senses, even many new words are not included inside.
</nextsent>
<nextsent>learning word senses from free text will help us dispense of outside knowledge source for defining sense by only discriminating senses of words.
</nextsent>
<nextsent>an other application of word sense learning is to help enriching or even constructing semantic lexicons (widdows, 2003).<papid> N03-1036 </papid>the solution of word sense learning is closely related to the interpretation of word senses.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5767">
<title id=" P04-1080.xml">learning word sense with feature selection and order identification capabilities </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however these lexical resources often miss domain specific word senses, even many new words are not included inside.
</prevsent>
<prevsent>learning word senses from free text will help us dispense of outside knowledge source for defining sense by only discriminating senses of words.
</prevsent>
</prevsection>
<citsent citstr=" N03-1036 ">
an other application of word sense learning is to help enriching or even constructing semantic lexicons (widdows, 2003).<papid> N03-1036 </papid>the solution of word sense learning is closely related to the interpretation of word senses.</citsent>
<aftsection>
<nextsent>different interpretations of word senses result in different solutions to word sense learning.
</nextsent>
<nextsent>one interpretation strategy is to treat word sense as set of synonyms like synset in wordnet.
</nextsent>
<nextsent>the committee based word sense discovery algorithm (pantel and lin, 2002) followed this strategy, which treated senses as clusters of words occurring in similar contexts.
</nextsent>
<nextsent>their algorithm initially discovered tight clusters called committees by grouping topn words similar with target word using average link clustering.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5769">
<title id=" P04-1080.xml">learning word sense with feature selection and order identification capabilities </title>
<section> experiments and evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>for line?, accuracy dropped when increas-.
</prevsent>
<prevsent>ing window size and the best accuracy(50.2%) was achieved at window size 1.
</prevsent>
</prevsection>
<citsent citstr=" J98-1006 ">
for serve?, the performance benefitted from large window size and the best accuracy(46.8%) was achieved at window size 15.in (leacock et al, 1998), <papid> J98-1006 </papid>they used bayesian approach for sense disambiguation of three ambiguous words, hard?, line?, and serve?, based on cues from topical and local context.</citsent>
<aftsection>
<nextsent>they observed that local context was more reliable than topical context as an indicator of senses for this verb and adjective, but slightly less reliable for this noun.
</nextsent>
<nextsent>compared with their conclusion, we can find that our result is consistent with it for hard?.
</nextsent>
<nextsent>but there is some differences for verb serve?
</nextsent>
<nextsent>and noun line?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5772">
<title id=" P04-1080.xml">learning word sense with feature selection and order identification capabilities </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>algorithm feature feature average ranking weighting accuracy method method fsgmm 2 binary 0.554 cgdterm 2 binary 0.404 cgdterm 2 idf 0.407 cgdterm 2 tf ? idf 0.409 cgdsvd 2 binary 0.513 cgdsvd 2 idf 0.512 cgdsvd 2 tf ? idf 0.508 fsgmm freq binary 0.512 cgdterm freq binary 0.451 cgdterm freq idf 0.437 cgdterm freq tf ? idf 0.447 cgdsvd freq binary 0.502 cgdsvd freq idf 0.498 cgdsvd freq tf ? idf 0.485table 6: automatically determined mixture component number.
</prevsent>
<prevsent>word context model model window order order size with 2 with freq hard 1 3 4 5 2 2 15 2 3 25 2 3 all 2 3 interest 1 5 4 5 3 4 15 4 6 25 4 6 all 3 4 line 1 5 6 5 4 3 15 5 4 25 5 4 all 3 4 serve 1 3 3 5 3 4 15 3 3 25 3 3 all 2 4 context window size is no less than 5.
</prevsent>
</prevsection>
<citsent citstr=" E99-1028 ">
besides the two works (pantel and lin, 2002; schutze, 1998), there are other related efforts on word sense discrimination (dorow and widdows, 2003; <papid> N03-1036 </papid>fukumoto and suzuki, 1999; <papid> E99-1028 </papid>pedersen and bruce, 1997).<papid> W97-0322 </papid></citsent>
<aftsection>
<nextsent>in (pedersen and bruce, 1997), <papid> W97-0322 </papid>they described an experimental comparison of three clustering algorithms for word sense discrimination.</nextsent>
<nextsent>their feature sets included morphology of target word, part of speech of contextual words, absence or presence of particular contextual words, and collocation of fre 0 1 5 15 25 all0.4 0.5 0.6 0.7 0.8 0.9 hard dataset acc ura cy 0 1 5 15 25 all0.2 0.3 0.4 0.5 0.6 acc ura cy interest dataset 0 1 5 15 25 all0.2 0.3 0.4 0.5 0.6 0.7 line dataset acc ura cy 0 1 5 15 25 all0.3 0.35 0.4 0.45 0.5 0.55 0.6 serve dataset acc ura cy figure 1: results for three procedures over 4 datases.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5773">
<title id=" P04-1080.xml">learning word sense with feature selection and order identification capabilities </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>algorithm feature feature average ranking weighting accuracy method method fsgmm 2 binary 0.554 cgdterm 2 binary 0.404 cgdterm 2 idf 0.407 cgdterm 2 tf ? idf 0.409 cgdsvd 2 binary 0.513 cgdsvd 2 idf 0.512 cgdsvd 2 tf ? idf 0.508 fsgmm freq binary 0.512 cgdterm freq binary 0.451 cgdterm freq idf 0.437 cgdterm freq tf ? idf 0.447 cgdsvd freq binary 0.502 cgdsvd freq idf 0.498 cgdsvd freq tf ? idf 0.485table 6: automatically determined mixture component number.
</prevsent>
<prevsent>word context model model window order order size with 2 with freq hard 1 3 4 5 2 2 15 2 3 25 2 3 all 2 3 interest 1 5 4 5 3 4 15 4 6 25 4 6 all 3 4 line 1 5 6 5 4 3 15 5 4 25 5 4 all 3 4 serve 1 3 3 5 3 4 15 3 3 25 3 3 all 2 4 context window size is no less than 5.
</prevsent>
</prevsection>
<citsent citstr=" W97-0322 ">
besides the two works (pantel and lin, 2002; schutze, 1998), there are other related efforts on word sense discrimination (dorow and widdows, 2003; <papid> N03-1036 </papid>fukumoto and suzuki, 1999; <papid> E99-1028 </papid>pedersen and bruce, 1997).<papid> W97-0322 </papid></citsent>
<aftsection>
<nextsent>in (pedersen and bruce, 1997), <papid> W97-0322 </papid>they described an experimental comparison of three clustering algorithms for word sense discrimination.</nextsent>
<nextsent>their feature sets included morphology of target word, part of speech of contextual words, absence or presence of particular contextual words, and collocation of fre 0 1 5 15 25 all0.4 0.5 0.6 0.7 0.8 0.9 hard dataset acc ura cy 0 1 5 15 25 all0.2 0.3 0.4 0.5 0.6 acc ura cy interest dataset 0 1 5 15 25 all0.2 0.3 0.4 0.5 0.6 0.7 line dataset acc ura cy 0 1 5 15 25 all0.3 0.35 0.4 0.45 0.5 0.55 0.6 serve dataset acc ura cy figure 1: results for three procedures over 4 datases.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5781">
<title id=" P01-1046.xml">evaluating smoothing algorithms against plausibility judgements </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>on the other hand, powerful car is highly plausible, whereas strong car is less plausible.
</prevsent>
<prevsent>it has been argued in the theoretical literature that the plausibility of an adjective-noun pair is largely collocational (i.e., idiosyncratic) property, in contrast to verb-object or noun-noun plausibility, which is more predictable (cruse, 1986; smadja, 1991).
</prevsent>
</prevsection>
<citsent citstr=" E99-1005 ">
the collocational hypothesis has recently been investigated in corpus study by lapata et al  (1999).<papid> E99-1005 </papid></citsent>
<aftsection>
<nextsent>this study investigated potential statistical predictors of adjective-nounplausibility by using correlation analysis to compare judgements elicited from human subjects with five corpus-derived measures: co-occurrence frequency of the adjective-noun pair, noun frequency, conditional probability of the noun given the adjective, the log-likelihood ratio, and resniks (1993) selectional association measure.
</nextsent>
<nextsent>all predictors but one were positively correlated with plausibility; the highest correlation was obtained with co-occurrence frequency.
</nextsent>
<nextsent>resniks selectional association measure surprisingly yielded significant negative correlation with judged plausibility.
</nextsent>
<nextsent>these results suggest that the best predictor of whether an adjective-noun combination is plausible or not is simply how often the adjective and the noun col locate in record of language experience.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5786">
<title id=" P01-1046.xml">evaluating smoothing algorithms against plausibility judgements </title>
<section> smoothing methods.  </section>
<citcontext>
<prevsection>
<prevsent>smoothing techniques have been used in variety of statistical natural language processing applications as means to address data sparseness, an inherent problem for statistical methods which relyon the relative frequencies of word combinations.
</prevsent>
<prevsent>the problem arises when the probability of word combinations that do not occur in the training data needs to be estimated.
</prevsent>
</prevsection>
<citsent citstr=" P99-1004 ">
the smoothing methods proposed in the literature (overviews are provided by dagan et al  (1999) and lee (1999)) <papid> P99-1004 </papid>canbe generally divided into three types: discounting (katz, 1987), class-based smoothing (resnik, 1993; brown et al , 1992; <papid> J92-4003 </papid>pereira et al , 1993), <papid> P93-1024 </papid>and distance-weighted averaging (grishman and sterling, 1994; <papid> C94-2119 </papid>dagan et al , 1999).</citsent>
<aftsection>
<nextsent>discounting methods decrease the probability of previously seen events so that the total probability of observed word co-occurrences is less than one, leaving some probability mass to be redistributed among unseen co-occurrences.
</nextsent>
<nextsent>class-based smoothing and distance-weighted averaging both relyon an intuitively simple idea: inter-word dependencies are modelled by relying on the corpus evidence available for words thatare similar to the words of interest.
</nextsent>
<nextsent>the two approaches differ in the way they measure word similarity.
</nextsent>
<nextsent>distance-weighted averaging estimate sword similarity from lexical co-occurrence information, viz., it finds similar words by taking into account the linguistic contexts in which they occur: two words are similar if they occur in similar contexts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5787">
<title id=" P01-1046.xml">evaluating smoothing algorithms against plausibility judgements </title>
<section> smoothing methods.  </section>
<citcontext>
<prevsection>
<prevsent>smoothing techniques have been used in variety of statistical natural language processing applications as means to address data sparseness, an inherent problem for statistical methods which relyon the relative frequencies of word combinations.
</prevsent>
<prevsent>the problem arises when the probability of word combinations that do not occur in the training data needs to be estimated.
</prevsent>
</prevsection>
<citsent citstr=" J92-4003 ">
the smoothing methods proposed in the literature (overviews are provided by dagan et al  (1999) and lee (1999)) <papid> P99-1004 </papid>canbe generally divided into three types: discounting (katz, 1987), class-based smoothing (resnik, 1993; brown et al , 1992; <papid> J92-4003 </papid>pereira et al , 1993), <papid> P93-1024 </papid>and distance-weighted averaging (grishman and sterling, 1994; <papid> C94-2119 </papid>dagan et al , 1999).</citsent>
<aftsection>
<nextsent>discounting methods decrease the probability of previously seen events so that the total probability of observed word co-occurrences is less than one, leaving some probability mass to be redistributed among unseen co-occurrences.
</nextsent>
<nextsent>class-based smoothing and distance-weighted averaging both relyon an intuitively simple idea: inter-word dependencies are modelled by relying on the corpus evidence available for words thatare similar to the words of interest.
</nextsent>
<nextsent>the two approaches differ in the way they measure word similarity.
</nextsent>
<nextsent>distance-weighted averaging estimate sword similarity from lexical co-occurrence information, viz., it finds similar words by taking into account the linguistic contexts in which they occur: two words are similar if they occur in similar contexts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5788">
<title id=" P01-1046.xml">evaluating smoothing algorithms against plausibility judgements </title>
<section> smoothing methods.  </section>
<citcontext>
<prevsection>
<prevsent>smoothing techniques have been used in variety of statistical natural language processing applications as means to address data sparseness, an inherent problem for statistical methods which relyon the relative frequencies of word combinations.
</prevsent>
<prevsent>the problem arises when the probability of word combinations that do not occur in the training data needs to be estimated.
</prevsent>
</prevsection>
<citsent citstr=" P93-1024 ">
the smoothing methods proposed in the literature (overviews are provided by dagan et al  (1999) and lee (1999)) <papid> P99-1004 </papid>canbe generally divided into three types: discounting (katz, 1987), class-based smoothing (resnik, 1993; brown et al , 1992; <papid> J92-4003 </papid>pereira et al , 1993), <papid> P93-1024 </papid>and distance-weighted averaging (grishman and sterling, 1994; <papid> C94-2119 </papid>dagan et al , 1999).</citsent>
<aftsection>
<nextsent>discounting methods decrease the probability of previously seen events so that the total probability of observed word co-occurrences is less than one, leaving some probability mass to be redistributed among unseen co-occurrences.
</nextsent>
<nextsent>class-based smoothing and distance-weighted averaging both relyon an intuitively simple idea: inter-word dependencies are modelled by relying on the corpus evidence available for words thatare similar to the words of interest.
</nextsent>
<nextsent>the two approaches differ in the way they measure word similarity.
</nextsent>
<nextsent>distance-weighted averaging estimate sword similarity from lexical co-occurrence information, viz., it finds similar words by taking into account the linguistic contexts in which they occur: two words are similar if they occur in similar contexts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5789">
<title id=" P01-1046.xml">evaluating smoothing algorithms against plausibility judgements </title>
<section> smoothing methods.  </section>
<citcontext>
<prevsection>
<prevsent>smoothing techniques have been used in variety of statistical natural language processing applications as means to address data sparseness, an inherent problem for statistical methods which relyon the relative frequencies of word combinations.
</prevsent>
<prevsent>the problem arises when the probability of word combinations that do not occur in the training data needs to be estimated.
</prevsent>
</prevsection>
<citsent citstr=" C94-2119 ">
the smoothing methods proposed in the literature (overviews are provided by dagan et al  (1999) and lee (1999)) <papid> P99-1004 </papid>canbe generally divided into three types: discounting (katz, 1987), class-based smoothing (resnik, 1993; brown et al , 1992; <papid> J92-4003 </papid>pereira et al , 1993), <papid> P93-1024 </papid>and distance-weighted averaging (grishman and sterling, 1994; <papid> C94-2119 </papid>dagan et al , 1999).</citsent>
<aftsection>
<nextsent>discounting methods decrease the probability of previously seen events so that the total probability of observed word co-occurrences is less than one, leaving some probability mass to be redistributed among unseen co-occurrences.
</nextsent>
<nextsent>class-based smoothing and distance-weighted averaging both relyon an intuitively simple idea: inter-word dependencies are modelled by relying on the corpus evidence available for words thatare similar to the words of interest.
</nextsent>
<nextsent>the two approaches differ in the way they measure word similarity.
</nextsent>
<nextsent>distance-weighted averaging estimate sword similarity from lexical co-occurrence information, viz., it finds similar words by taking into account the linguistic contexts in which they occur: two words are similar if they occur in similar contexts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5796">
<title id=" P01-1046.xml">evaluating smoothing algorithms against plausibility judgements </title>
<section> smoothing methods.  </section>
<citcontext>
<prevsection>
<prevsent>the word leader has two senses in wordnet and belongs to eight conceptual classes (hpersoni, hlife fromi, hentityi, hcausal agenti, hfeaturei, hmerchandisei, hcommodityi, and hobjecti).
</prevsent>
<prevsent>the words chief and leader have four conceptual classes in common, i.e., hpersoni and hlife formi, hentityi, and hcausal agenti.
</prevsent>
</prevsection>
<citsent citstr=" N01-1013 ">
this means that we will increment the observed co-occurrence count of proud and hpersoni, proud and hlife formi, proud and hentityi, and proud and hcausal agenti by 18 . since we 2there are several ways of addressing this problem, e.g., by discounting the contribution of very general classes by finding suitable class to represent given concept (clark and weir, 2001).<papid> N01-1013 </papid></citsent>
<aftsection>
<nextsent>do not know the actual class of the noun chief in the corpus, we weight the contribution of each class by taking the average of the constructed frequencies for all seven classes: (a,n) = ? c2classes(n) ? n02c (a,n0) jclasses(n0)j jclasses(n)j(2) based on (2) the recreated frequency for the pair proud chief in the bnc is 6.12 (see table 1).
</nextsent>
<nextsent>2.2 distance-weighted averaging.
</nextsent>
<nextsent>distance-weighted averaging induces classes of similar words from word co-occurrences without making reference to taxonomy.
</nextsent>
<nextsent>a key feature of this type of smoothing is the function which measures distributional similarity from cooccurrence frequencies.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5827">
<title id=" P03-1044.xml">counter training in discovery of semantic patterns </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>thus,when the learning algorithm is applied against reference corpus, the result is ranked list of patterns, and going down the list produces curve which trades off precision for recall.
</prevsent>
<prevsent>simply put, the unsupervised algorithm does not know when to stop learning.
</prevsent>
</prevsection>
<citsent citstr=" C00-2136 ">
in the absence of good stopping criterion, the resulting list of patterns must be manually reviewed by human; otherwise one can set ad-hoc thresholds, e.g., on the number of allowed iterations, as in (riloff and jones, 1999), or else to resort to supervised training to determine such thresholds which is unsatisfactory when our 1as described in, e.g., (riloff, 1996; riloff and jones, 1999; yangarber et al, 2000).<papid> C00-2136 </papid></citsent>
<aftsection>
<nextsent>goal from the outset is to try to limit supervision.
</nextsent>
<nextsent>thus, the lack of natural stopping criteria renders these algorithms less unsupervised than one wouldhope.
</nextsent>
<nextsent>more importantly, this lack makes the algorithms difficult to use in settings where training must be completely automatic, such as in general purpose information extraction system, where the topic may not be known in advance.
</nextsent>
<nextsent>at the same time, certain unsupervised learning algorithms in other domains exhibit inherently natural stopping criteria.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5829">
<title id=" P03-1044.xml">counter training in discovery of semantic patterns </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>more importantly, this lack makes the algorithms difficult to use in settings where training must be completely automatic, such as in general purpose information extraction system, where the topic may not be known in advance.
</prevsent>
<prevsent>at the same time, certain unsupervised learning algorithms in other domains exhibit inherently natural stopping criteria.
</prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
one example is the algorithm for word sense disambiguation in (yarowsky, 1995).<papid> P95-1026 </papid>of particular relevance to our method are the algorithms for semantic classification of names or nps described in (thelen and riloff, 2002; <papid> W02-1028 </papid>yangarber et al., 2002).<papid> C02-1154 </papid></citsent>
<aftsection>
<nextsent>inspired in part by these algorithms, we introduce the counter-training technique for unsupervised pattern acquisition.
</nextsent>
<nextsent>the main idea behind counter training is that several identical simple learners run simultaneously to compete with one another in different domains.
</nextsent>
<nextsent>this yields an improvement in precision, and most crucially, it provides natural indication to the learner when to stop learning namely, once it attempts to wander into territory already claimed by other learners.we review the main features of the underlying unsupervised pattern learner and related work in section 2.
</nextsent>
<nextsent>in section 3 we describe the algorithm; 3.2gives the details of the basic learner, and 3.3 introduces the counter-training framework which is super-imposed on it.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5830">
<title id=" P03-1044.xml">counter training in discovery of semantic patterns </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>more importantly, this lack makes the algorithms difficult to use in settings where training must be completely automatic, such as in general purpose information extraction system, where the topic may not be known in advance.
</prevsent>
<prevsent>at the same time, certain unsupervised learning algorithms in other domains exhibit inherently natural stopping criteria.
</prevsent>
</prevsection>
<citsent citstr=" W02-1028 ">
one example is the algorithm for word sense disambiguation in (yarowsky, 1995).<papid> P95-1026 </papid>of particular relevance to our method are the algorithms for semantic classification of names or nps described in (thelen and riloff, 2002; <papid> W02-1028 </papid>yangarber et al., 2002).<papid> C02-1154 </papid></citsent>
<aftsection>
<nextsent>inspired in part by these algorithms, we introduce the counter-training technique for unsupervised pattern acquisition.
</nextsent>
<nextsent>the main idea behind counter training is that several identical simple learners run simultaneously to compete with one another in different domains.
</nextsent>
<nextsent>this yields an improvement in precision, and most crucially, it provides natural indication to the learner when to stop learning namely, once it attempts to wander into territory already claimed by other learners.we review the main features of the underlying unsupervised pattern learner and related work in section 2.
</nextsent>
<nextsent>in section 3 we describe the algorithm; 3.2gives the details of the basic learner, and 3.3 introduces the counter-training framework which is super-imposed on it.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5831">
<title id=" P03-1044.xml">counter training in discovery of semantic patterns </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>more importantly, this lack makes the algorithms difficult to use in settings where training must be completely automatic, such as in general purpose information extraction system, where the topic may not be known in advance.
</prevsent>
<prevsent>at the same time, certain unsupervised learning algorithms in other domains exhibit inherently natural stopping criteria.
</prevsent>
</prevsection>
<citsent citstr=" C02-1154 ">
one example is the algorithm for word sense disambiguation in (yarowsky, 1995).<papid> P95-1026 </papid>of particular relevance to our method are the algorithms for semantic classification of names or nps described in (thelen and riloff, 2002; <papid> W02-1028 </papid>yangarber et al., 2002).<papid> C02-1154 </papid></citsent>
<aftsection>
<nextsent>inspired in part by these algorithms, we introduce the counter-training technique for unsupervised pattern acquisition.
</nextsent>
<nextsent>the main idea behind counter training is that several identical simple learners run simultaneously to compete with one another in different domains.
</nextsent>
<nextsent>this yields an improvement in precision, and most crucially, it provides natural indication to the learner when to stop learning namely, once it attempts to wander into territory already claimed by other learners.we review the main features of the underlying unsupervised pattern learner and related work in section 2.
</nextsent>
<nextsent>in section 3 we describe the algorithm; 3.2gives the details of the basic learner, and 3.3 introduces the counter-training framework which is super-imposed on it.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5835">
<title id=" P03-1044.xml">counter training in discovery of semantic patterns </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>a lexicon, semantic conceptual hierarchy, set of patterns, set of inference rules, set of logical representations for objects in the domain.
</prevsent>
<prevsent>each kb can be expected to be domain-specific, to greater or lesser degree.among the research that deals with automatic acquisition of knowledge from text, the following are particularly relevant to us.
</prevsent>
</prevsection>
<citsent citstr=" C96-2157 ">
(strzalkowski and wang,1996) <papid> C96-2157 </papid>proposed method for learning concepts belonging to given semantic class.</citsent>
<aftsection>
<nextsent>(riloff and jones, 1999; riloff, 1996; yangarber et al, 2000) <papid> C00-2136 </papid>present different combinations of learners of patterns and concept classes specifically for ie.</nextsent>
<nextsent>in (riloff, 1996) the system autoslog-ts learns patterns for filling an individual slot in an event template, while simultaneously acquiring set of lexicalelements/concepts eligible to fill the slot.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5843">
<title id=" P03-1044.xml">counter training in discovery of semantic patterns </title>
<section> algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>name factorization: we use name classifier to tag all proper names in the corpus as belonging toone of several categories person, location, and organization, or as an unidentified name.
</prevsent>
<prevsent>each name is replaced with its category label, single token.the name classifier also factors out other out-of vocabulary (oov) classes of items: dates, times,numeric and monetary expressions.
</prevsent>
</prevsection>
<citsent citstr=" W99-0613 ">
name classification is well-studied subject, e.g., (collins and singer, 1999).<papid> W99-0613 </papid></citsent>
<aftsection>
<nextsent>the name recognizer we use is based on lists of common name markers such as personal titles (dr., ms.) and corporate designators (ltd., gmbh)and hand-crafted rules.parsing: after name classification, we apply general english parser, from conexor oy, (tapanainen and jarvinen, 1997).<papid> A97-1011 </papid></nextsent>
<nextsent>the parser recognizes the name tags generated in the preceding step, and treats them as atomic.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5844">
<title id=" P03-1044.xml">counter training in discovery of semantic patterns </title>
<section> algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>each name is replaced with its category label, single token.the name classifier also factors out other out-of vocabulary (oov) classes of items: dates, times,numeric and monetary expressions.
</prevsent>
<prevsent>name classification is well-studied subject, e.g., (collins and singer, 1999).<papid> W99-0613 </papid></prevsent>
</prevsection>
<citsent citstr=" A97-1011 ">
the name recognizer we use is based on lists of common name markers such as personal titles (dr., ms.) and corporate designators (ltd., gmbh)and hand-crafted rules.parsing: after name classification, we apply general english parser, from conexor oy, (tapanainen and jarvinen, 1997).<papid> A97-1011 </papid></citsent>
<aftsection>
<nextsent>the parser recognizes the name tags generated in the preceding step, and treats them as atomic.
</nextsent>
<nextsent>the parsers output is set of syntactic dependency trees for each document.
</nextsent>
<nextsent>syntactic normalization: to reduce variation inthe corpus further, we apply tree-transforming program to the parse trees.
</nextsent>
<nextsent>for every (non-auxiliary)verb heading its own clause, the transformer produces corresponding active tree, where possible.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5854">
<title id=" P02-1021.xml">semi supervised maximum entropy based approach to acronym and abbreviation normalization in medical texts </title>
<section> unified medical language system?, database.  </section>
<citcontext>
<prevsection>
<prevsent>on the other side of the spectrum, the fully unsupervised learning methods such as clustering have also been successfully used (shutze 1998).
</prevsent>
<prevsent>a hybrid class of machine learning techniques for wsd relies on small set of hand labeled data used to bootstrap larger corpus of training data (hearst 1991, yarowski 1995).
</prevsent>
</prevsection>
<citsent citstr=" J98-1001 ">
regardless of the technique that is used for wsd, the most important part of the process is the context in which the word appears (ide and veronis 1998).<papid> J98-1001 </papid></citsent>
<aftsection>
<nextsent>this is also true for abbreviation normalization.
</nextsent>
<nextsent>for the problem at hand, one way to take context into account is to encode the type of discourse in which the abbreviation occurs, where discourse is defined narrowly as the type of the medical document and the medical specialty, into set of explicit rules.
</nextsent>
<nextsent>if we see ra in cardiology report, then it can be normalized to right atrial?; otherwise, if it occurs in the context of rheumatology note, it is likely to mean rheumatoid arthritis?
</nextsent>
<nextsent>or rheumatic arthritis.?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5855">
<title id=" P02-1021.xml">semi supervised maximum entropy based approach to acronym and abbreviation normalization in medical texts </title>
<section> unified medical language system?, database.  </section>
<citcontext>
<prevsection>
<prevsent>of abbreviations amusing maximum entropy (me) classifier.
</prevsent>
<prevsent>maximum entropy modeling has been used successfully in the recent years for various nlp tasks such as sentence boundary detection, part-of-speech tagging, punctuation normalization, etc.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
(berger 1996, ratnaparkhi 1996, <papid> W96-0213 </papid>1998, mikheev 1998, <papid> P98-2140 </papid>2000).</citsent>
<aftsection>
<nextsent>in this paper will demonstrate using maximum entropy for mostly data driven process of abbreviation normalization in the medical domain.
</nextsent>
<nextsent>in the following sections, will briefly describe maximum entropy as statistical technique.
</nextsent>
<nextsent>i will also describe the process of automatically generating training data for me modeling and present examples of training and testing data obtained from medical sub-domain of rheumatology.
</nextsent>
<nextsent>finally, will discuss the training and testing process and present the results of testing the me models trained on two different datasets.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5856">
<title id=" P02-1021.xml">semi supervised maximum entropy based approach to acronym and abbreviation normalization in medical texts </title>
<section> unified medical language system?, database.  </section>
<citcontext>
<prevsection>
<prevsent>of abbreviations amusing maximum entropy (me) classifier.
</prevsent>
<prevsent>maximum entropy modeling has been used successfully in the recent years for various nlp tasks such as sentence boundary detection, part-of-speech tagging, punctuation normalization, etc.
</prevsent>
</prevsection>
<citsent citstr=" P98-2140 ">
(berger 1996, ratnaparkhi 1996, <papid> W96-0213 </papid>1998, mikheev 1998, <papid> P98-2140 </papid>2000).</citsent>
<aftsection>
<nextsent>in this paper will demonstrate using maximum entropy for mostly data driven process of abbreviation normalization in the medical domain.
</nextsent>
<nextsent>in the following sections, will briefly describe maximum entropy as statistical technique.
</nextsent>
<nextsent>i will also describe the process of automatically generating training data for me modeling and present examples of training and testing data obtained from medical sub-domain of rheumatology.
</nextsent>
<nextsent>finally, will discuss the training and testing process and present the results of testing the me models trained on two different datasets.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5860">
<title id=" P00-1020.xml">an empirical study of the influence of argument conciseness on argument effectiveness </title>
<section> generating concise evaluative.  </section>
<citcontext>
<prevsection>
<prevsent>according to argumentation theory, the selection of what evidence to mention in an argument should be based on measure of the evidence strength of support (or opposition) to the main claim of the argument (mayberry and golden 1996).
</prevsent>
<prevsent>furthermore, argumentation theory suggests that for evaluative arguments the measure of evidence strength should be based on model of the intended readers values and preferences.
</prevsent>
</prevsection>
<citsent citstr=" W00-1407 ">
following argumentation theory, we have designed an argumentative strategy for generating evaluative arguments that are properly arranged and concise (carenini and moore 2000).<papid> W00-1407 </papid></citsent>
<aftsection>
<nextsent>in our strategy, we assume that the readers values and preferences are represented as an additive multi attribute value function (amvf), conceptualization based on multi attribute utility theory (maut)(clemen 1996).
</nextsent>
<nextsent>this allows us to adopt and extend measure of evidence strength proposed in previous work on explaining decision theoretic advice based on an amvf (klein1994).
</nextsent>
<nextsent>figure 1 sample additive multi attribute value function (amvf) the argumentation strategy has been implemented as part of complete argument generator.
</nextsent>
<nextsent>other modules of the generator include micro planner, which performs aggregation, pronominal ization and makes decisions about cue phrases and scalar adjectives, along with sentence realizer, which extends previous work on realizing evaluative statements (elhadad 1995).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5861">
<title id=" P01-1044.xml">parsing with treebank grammars empirical bounds theoretical models and the structure of the penn treebank </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the resulting analysis builds on the presentation of charniak (1996), but extend sit by elucidating the structure of non-terminal interrelationships in the penn treebank grammar.
</prevsent>
<prevsent>on the basis of these studies, we build simple theoretical models which closely predict observed parser performance, and, in particular, explain the originally observed super-cubic behavior.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
we used treebank grammars induced directly from the local trees of the entire wsj section of the penn treebank (marcus et al, 1993) (<papid> J93-2004 </papid>release 3).</citsent>
<aftsection>
<nextsent>for each length and parameter setting, 25 sentences evenly distributed through the treebank were parsed.
</nextsent>
<nextsent>since we were parsing sentences from among those from which our grammar was derived, coverage was never an issue.
</nextsent>
<nextsent>every sentence parsed had at least one parse ? the parse with which it was originally observed.1the sentences were parsed using an implementation of the probabilistic chart-parsing algorithm presented in (klein and manning, 2001).
</nextsent>
<nextsent>in that paper, we present theoretical analysis showing an worst-case time bound for exhaustively parsing arbitrary context-free grammars.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5862">
<title id=" P01-1044.xml">parsing with treebank grammars empirical bounds theoretical models and the structure of the penn treebank </title>
<section> parameters.  </section>
<citcontext>
<prevsection>
<prevsent>for all settings, functional tags and cross referencing annotations were stripped.
</prevsent>
<prevsent>for no transform, no other modification was made.
</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
in particular, empty nodes (represented as -none- in the treebank) were turned into rules that generated the empty string ( ), and there was no collapsing of categories (such as prt and advp) as is of ten done in parsing work (collins, 1997, <papid> P97-1003 </papid>etc.).</citsent>
<aftsection>
<nextsent>for 1effectively testing on the training set?
</nextsent>
<nextsent>would be invalid if we wished to present performance results such as precision and recall, but it is not problem for the present experiments, which focus solely on the parser load and grammar structure.
</nextsent>
<nextsent>top s-hln np-sbj-none vp vb atone top np-none vp vb atone top vp vb atone top atone top vb atone (a) (b) (c) (d) (e)figure 1: tree transforms: (a) the raw tree, (b) no transform, (c) no empties, (d) noun aries high (e) nounarieslow nnp nns nnp nnp nnjj nns jj cd nncd nndt nndt nn nns dt jj dt nn cc np np pp np sbar np nnsnn nn prp qp nns nns nns nns nnp nnp nn jj cd nn nn dt nn jj nn np cc np nn sbar pp prp qp nns nns nns nnp nnp jj nn cd nn nns dt jj nn np np cc pp sbar nn prp qp nn list trie min figure 2: grammar encodings: fsas for subset of the rules for the category np.
</nextsent>
<nextsent>non-black states are active, non-white states are accepting, and bold transitions are phrasal.noempties, empties were removed by pruning nonterminals which covered no overt words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5864">
<title id=" P04-1010.xml">data driven strategies for an automated dialogue system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(generic names and numbers were substituted for all personal details in the transcriptions.)
</prevsent>
<prevsent>this corpus spans two different application areas: software support and (a much smaller size) customer banking.
</prevsent>
</prevsection>
<citsent citstr=" W03-0704 ">
the banking corpus of several hundred calls has been collected first and it forms the basis of our initial multilingual tri aging application, implemented for english, french and german (hardy et al, 2003<papid> W03-0704 </papid>a); as well as our prototype automatic financial services system, presented in this paper, which completes variety of tasks in english.</citsent>
<aftsection>
<nextsent>the much larger software support corpus (10,000 calls in english and french) is still being collected and processed and will be used to develop the next amitis prototype.
</nextsent>
<nextsent>we observe that for interactions with structured data ? whether these data consist of flight information, spare parts, or customer account information ? domain knowledge need not be built ahead of time.
</nextsent>
<nextsent>rather, methods for handling the data can arise from the way the data are organized.
</nextsent>
<nextsent>once we know the basic data structures, the transactions, and the protocol to be followed (e.g., establish callers identity before exchanging sensitive information); we need only build dialogue models for handling various conversational situations, in order to implement dialogue system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5868">
<title id=" P04-1010.xml">data driven strategies for an automated dialogue system </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the classic trains natural-language dialogue project (allen et al, 1995) is plan-based system which requires detailed model of the domain and therefore cannot be used for wide-ranging application such as financial services.
</prevsent>
<prevsent>the us darpa communicator program has been instrumental in bringing about practical implementations of spoken dialogue systems.
</prevsent>
</prevsection>
<citsent citstr=" W00-0309 ">
systems developed under this program include cmus script-based dialogue manager, in which the travel itinerary is hierarchical composition of frames (xu and rudnicky, 2000).<papid> W00-0309 </papid></citsent>
<aftsection>
<nextsent>the at&t; mixed-initiative system uses sequential decision process model, based on concepts of dialog state and dialog actions (levin et al, 2000).
</nextsent>
<nextsent>mits mercury flight reservation system uses dialogue control strategy based on set of ordered rules as mechanism to manage complex interactions (seneff and polifroni, 2000).<papid> W00-0303 </papid></nextsent>
<nextsent>cus dialogue manager is event-driven, using set of hierarchical forms with prompts associated with fields in the forms.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5869">
<title id=" P04-1010.xml">data driven strategies for an automated dialogue system </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>systems developed under this program include cmus script-based dialogue manager, in which the travel itinerary is hierarchical composition of frames (xu and rudnicky, 2000).<papid> W00-0309 </papid></prevsent>
<prevsent>the at&t; mixed-initiative system uses sequential decision process model, based on concepts of dialog state and dialog actions (levin et al, 2000).</prevsent>
</prevsection>
<citsent citstr=" W00-0303 ">
mits mercury flight reservation system uses dialogue control strategy based on set of ordered rules as mechanism to manage complex interactions (seneff and polifroni, 2000).<papid> W00-0303 </papid></citsent>
<aftsection>
<nextsent>cus dialogue manager is event-driven, using set of hierarchical forms with prompts associated with fields in the forms.
</nextsent>
<nextsent>decisions are based not on scripts but on current context (ward and pellom, 1999).
</nextsent>
<nextsent>our data-driven strategy is similar in spirit to that of cu.
</nextsent>
<nextsent>we take statistical approach, in which large body of transcribed, annotated conversations forms the basis for task identification, dialogue act recognition, and form filling for task completion.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5870">
<title id=" P04-1010.xml">data driven strategies for an automated dialogue system </title>
<section> system architecture and components.  </section>
<citcontext>
<prevsection>
<prevsent>the goal of the language understanding component is to take the word string output of the asr module, and identify key semantic concepts relating to the target domain.
</prevsent>
<prevsent>this is specialized kind of information extraction application, and as such, we have adapted existing ie technology to this task.
</prevsent>
</prevsection>
<citsent citstr=" P02-1022 ">
hub speech recognition dialogue manager database server natl language understanding telephony server response generation customer database text-to-speech conversion we have used modified version of the annie engine (a nearly-new ie system; cunningham et al., 2002; <papid> P02-1022 </papid>maynard, 2003).</citsent>
<aftsection>
<nextsent>annie is distributed as the default built-in ie component of the gate framework (cunningham et al, 2002).<papid> P02-1022 </papid></nextsent>
<nextsent>gate is pure java-based architecture developed over the past eight years in the university of sheffield natural language processing group.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5872">
<title id=" P03-1067.xml">using model theoretic semantic interpretation to guide statistical parsing and word recognition in a spoken language interface </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>conventional language models are not sucientlypredictive to correctly analyze wide variety of inputs from wide variety of speakers, such as mightbe encountered in general-purpose interface for directing robots, oce assistants, or other agents with complex capabilities.
</prevsent>
<prevsent>such tasks may involve unlabeled objects that must be precisely described, and awider range of actions than standard database interface would require (which also must be precisely described), introducing great deal of ambiguity into input processing.this paper therefore explores the use of statistical model of language conditioned on the meanings or denot ations of input utterances in the context of an interface underlying application environ mentor world model.
</prevsent>
</prevsection>
<citsent citstr=" P96-1008 ">
this use of model-theoretic interpretation represents an important extension to the`semantic grammars  used in existing statistical spoken language interfaces, which relyon co-occurrences among lexically-determined semantic classes and slot llers (miller et al, 1996), <papid> P96-1008 </papid>in that the probability of an analysis is now also conditioned on the existence of denoted entities and relations in the world model.</citsent>
<aftsection>
<nextsent>the advantage of the interpretation-baseddisambiguation advanced here is that the probability of generating, for example, the noun phrase `thelemon next to the safe  can be more reliably estimated from the frequency with which noun phrases have non-empty denot ations { given the fact that`the lemon next to the safe  does indeed denote something in the world model { than it can from the relatively sparse co-occurrences of frame labels such as lemon and next-to, or of next-to and safe.
</nextsent>
<nextsent>since there are exponentially many word strings attributable to any utterance, and an exponential(catalan-order) number of possible parse tree analyses attributable to any string of words, this use of model-theoretic interpretation for disambiguation must involve some kind of sharing of partial results between competing analyses if interpretation is to be performed on large numbers of possible analyses in apractical interactive application.
</nextsent>
<nextsent>this paper therefore also presents formal restriction on the scope of variables in semantic grammar (without untoward constraints on the expressivity of the derived seman tics) which guarantees that the denot ations of all possible analyses of an input utterance can be calculated in polynomial time.
</nextsent>
<nextsent>empirical tests show that this use of model-theoretic interpretation in disambiguation yields statistically signi cant improvement on standard measures of parsing accuracy over baseline grammar not conditioned on denotations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5874">
<title id=" P03-1067.xml">using model theoretic semantic interpretation to guide statistical parsing and word recognition in a spoken language interface </title>
<section> model-theoretic interpretation.  </section>
<citcontext>
<prevsection>
<prevsent>recall the problem of unbounded variable proliferation described in section 2.1.
</prevsent>
<prevsent>the advantage of using tree-rewriting system to model semantic composition is that such systems allow the application of well-studied restrictions to limit their recursive capacity to generate structural descriptions (in this case, to limit the unbounded overlapping of quanti er-variable dependencies that can produce unlimited numbers of free variables at certain steps ina derivation), without limiting the multi-level structure of their elementary trees, used here for capturing the well-formedness constraint that predicate be dominated by its variables  quanti ers.
</prevsent>
</prevsection>
<citsent citstr=" P94-1022 ">
one such restriction, based on the regular form restriction de ned for tree adjoining grammars (rogers, 1994), <papid> P94-1022 </papid>prohibits grammar from allowing any cycle of elementary trees, each intervening inside spine (a path connecting the insertion sites of any argument) of the next.</citsent>
<aftsection>
<nextsent>this restriction is de ned below: de nition 2.1 let spine in an elementary tree be the path of nodes (or object-level rule applications) connecting all insertion site addresses of the same argument.
</nextsent>
<nextsent>de nition 2.2 grammar is in regular form if adirected acyclic graph hv;ei can be drawn with vertices h ; a2 corresponding to partitioned elementary trees of (partitioned as described above), and directed edges hv ; a 2   from each vertex h , corresponding to partitioned elementary tree that can host an argument, to each vertex a , corresponding to partitioned elementary tree thatcan function as its argument, whose partition intersects its spine at any place other than the top node in the spine.this restriction ensures that there will be no unbounded `pumping  of intervening tree structure in any derivation, so there will never be an unbounded amount of unrecognized tree structure to keep track of at any step in bottom-up parse, so the number of possible descriptions of each sub-span of the in put will be bounded by some constant.
</nextsent>
<nextsent>it is called `regular form  restriction because it ensures that the set of root-to-leaf paths in any derived structure will form regular language.a cky-style parser can now be built that recognizes each context-free rule in an elementary tree from the bottom up, storing in order the unrecognized rules that lie above it in the elementary tree (as well as any remaining rules from any composed sub-trees) as kind of promissory note.
</nextsent>
<nextsent>the fact that any regular-form grammar has regular path set means that only nite number of states will be required to keep track of this promised, unrecognized structure in bottom-up traversal, so the parser will have the usual o(n 3 ) complexity (times constant equal to the nite number of possible unrecognized structures).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5875">
<title id=" P03-1067.xml">using model theoretic semantic interpretation to guide statistical parsing and word recognition in a spoken language interface </title>
<section> model-theoretic interpretation.  </section>
<citcontext>
<prevsection>
<prevsent>the interpretation of any shared forest derived by this kind of regular-form tree-rewriting system can therefore be calculated in worst-case polynomial time on . denotation-annotated shared forest for the noun phrase `the girl with the hat behind the counter  is shown in figure 5, using the noun and preposition trees from figure 4, with alternative applications of parse rules represented as circles below each derived constituent.
</prevsent>
<prevsent>this shared structure subsumes two competing analyses: one containing the noun phrase `the girl with the hat , denoting the entity 1 , andthe other containing the noun phrase `the hat behind the counter , which does not denote anything in the world model.
</prevsent>
</prevsection>
<citsent citstr=" E91-1005 ">
assuming that noun phrases rarely occur with empty denot ations in the training data, the parse containing the phrase `the girl with the hat  will be preferred, because there is indeed girl with hat in the world model.this formalism has similarities with two ex np ! girl x 1 :girl(x 1 ) fg 1 ; 2 ; 3 p ! with x 1 2 :with(x 2 ; 1 ) fhh 1 ; 1 i; hh 2 ; 1 ig np ! hat x 1 :hat(x 1 ) fh 1 ; 2 ; 3 ; 4 p ! behind x 1 2 :behind(x 2 ; 1 ) fhc 1 ; 1 ig np ! counter x 1 :counter(x 1 ) fc 1 ; 2 pp ! np x 1 ::: n=2 : $1(x 1 ::: n ) ^ $2(x 1 ) fhh 1 ; 1 i; hh 2 ; 1 ig pp ! pp x 2 ::: n=2 : x 1 : $1(x 1 ::: n ) fg 1 ; 1 pp ! np x 1 ::: n=2 : $1(x 1 ::: n ) ^ $2(x 1 ) fhc 1 ; 1 ig pp ! pp x 2 ::: n=2 : x 1 : $1(x 1 ::: n ) fg 1 np ! np pp x 1 ::: n=1 : $1(x 1 ::: m=1 ) ^ $2(x 1 ; m+1 ::: n ) fg 1 np ! np pp x 1 ::: n=1 : $1(x 1 ::: m=1 ) ^ $2(x 1 ; m+1 ::: n ) ; pp ! np x 1 ::: n=2 : $1(x 1 ::: n ) ^ $2(x 1 ) ; pp ! pp x 2 ::: n=2 : x 1 : $1(x 1 ::: n ) ; np ! np pp x 1 ::: n=1 : $1(x 1 ::: m=1 ) ^ $2(x 1 ; m+1 ::: n ) ; or fg 1 figure 5: shared forest for `the girl with the hat behind the counter.  tensions of tree-adjoining grammar (joshi, 1985), namely multi-component tree adjoining grammar(becker et al, 1991) <papid> E91-1005 </papid>and description tree substitution grammar (rambow et al, 1995), <papid> P95-1021 </papid>and indeed represents something of combination of the two: 1.</citsent>
<aftsection>
<nextsent>like description tree substitution grammars,.
</nextsent>
<nextsent>but unlike multi-component tags, it allows trees to be partitioned into any desired set of contiguous components during composition, 2.
</nextsent>
<nextsent>like multi-component tags, but unlike descrip-.
</nextsent>
<nextsent>tion tree substitution grammars, it allows the speci cation of particular insertion sites within elementary trees, and(which is used for merging quanti ers from different elementary trees).the use of lambda calculus functions to de ne de composable meanings for input sentences draws on traditions of church (1940) and montague (1973),but this approach diers from the montagovian system by introducing explicit limits on computational complexity (in order to allow tractable disambigua tion).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5876">
<title id=" P03-1067.xml">using model theoretic semantic interpretation to guide statistical parsing and word recognition in a spoken language interface </title>
<section> model-theoretic interpretation.  </section>
<citcontext>
<prevsection>
<prevsent>the interpretation of any shared forest derived by this kind of regular-form tree-rewriting system can therefore be calculated in worst-case polynomial time on . denotation-annotated shared forest for the noun phrase `the girl with the hat behind the counter  is shown in figure 5, using the noun and preposition trees from figure 4, with alternative applications of parse rules represented as circles below each derived constituent.
</prevsent>
<prevsent>this shared structure subsumes two competing analyses: one containing the noun phrase `the girl with the hat , denoting the entity 1 , andthe other containing the noun phrase `the hat behind the counter , which does not denote anything in the world model.
</prevsent>
</prevsection>
<citsent citstr=" P95-1021 ">
assuming that noun phrases rarely occur with empty denot ations in the training data, the parse containing the phrase `the girl with the hat  will be preferred, because there is indeed girl with hat in the world model.this formalism has similarities with two ex np ! girl x 1 :girl(x 1 ) fg 1 ; 2 ; 3 p ! with x 1 2 :with(x 2 ; 1 ) fhh 1 ; 1 i; hh 2 ; 1 ig np ! hat x 1 :hat(x 1 ) fh 1 ; 2 ; 3 ; 4 p ! behind x 1 2 :behind(x 2 ; 1 ) fhc 1 ; 1 ig np ! counter x 1 :counter(x 1 ) fc 1 ; 2 pp ! np x 1 ::: n=2 : $1(x 1 ::: n ) ^ $2(x 1 ) fhh 1 ; 1 i; hh 2 ; 1 ig pp ! pp x 2 ::: n=2 : x 1 : $1(x 1 ::: n ) fg 1 ; 1 pp ! np x 1 ::: n=2 : $1(x 1 ::: n ) ^ $2(x 1 ) fhc 1 ; 1 ig pp ! pp x 2 ::: n=2 : x 1 : $1(x 1 ::: n ) fg 1 np ! np pp x 1 ::: n=1 : $1(x 1 ::: m=1 ) ^ $2(x 1 ; m+1 ::: n ) fg 1 np ! np pp x 1 ::: n=1 : $1(x 1 ::: m=1 ) ^ $2(x 1 ; m+1 ::: n ) ; pp ! np x 1 ::: n=2 : $1(x 1 ::: n ) ^ $2(x 1 ) ; pp ! pp x 2 ::: n=2 : x 1 : $1(x 1 ::: n ) ; np ! np pp x 1 ::: n=1 : $1(x 1 ::: m=1 ) ^ $2(x 1 ; m+1 ::: n ) ; or fg 1 figure 5: shared forest for `the girl with the hat behind the counter.  tensions of tree-adjoining grammar (joshi, 1985), namely multi-component tree adjoining grammar(becker et al, 1991) <papid> E91-1005 </papid>and description tree substitution grammar (rambow et al, 1995), <papid> P95-1021 </papid>and indeed represents something of combination of the two: 1.</citsent>
<aftsection>
<nextsent>like description tree substitution grammars,.
</nextsent>
<nextsent>but unlike multi-component tags, it allows trees to be partitioned into any desired set of contiguous components during composition, 2.
</nextsent>
<nextsent>like multi-component tags, but unlike descrip-.
</nextsent>
<nextsent>tion tree substitution grammars, it allows the speci cation of particular insertion sites within elementary trees, and(which is used for merging quanti ers from different elementary trees).the use of lambda calculus functions to de ne de composable meanings for input sentences draws on traditions of church (1940) and montague (1973),but this approach diers from the montagovian system by introducing explicit limits on computational complexity (in order to allow tractable disambigua tion).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5877">
<title id=" P03-1067.xml">using model theoretic semantic interpretation to guide statistical parsing and word recognition in a spoken language interface </title>
<section> model-theoretic interpretation.  </section>
<citcontext>
<prevsection>
<prevsent>this approach to semantics is very similar to that described by shieber (1994), in which syntactic and semantic expressions are assembled synchronously using paired tree-adjoining grammars with isomor phic derivations, except that in this approach the derived structures are isomorphic as well, hence the reduction of synchronous tree pairs to semantically annotated syntax trees.
</prevsent>
<prevsent>this isomorphism restriction on derived trees reduces the number of quanti er scoping con gur ations that can be assigned to any given input (most of which are unlikely to be used in practical application), but its relative parsimony allows syntactically ambiguous inputs to be semantically interpreted in shared forest representation in worst-case polynomial time.
</prevsent>
</prevsection>
<citsent citstr=" P94-1016 ">
the inter leaving of semantic evaluation and parsing for the purpose of disambiguation also has much in common with that of dowding et al (1994), <papid> P94-1016 </papid>except that in this case, constituents are not only semantically type-checked,but are also fully interpreted each time they are proposed.</citsent>
<aftsection>
<nextsent>there are also commonalities between the underspeci ed semantic representation of structurally ambiguous elementary tree constituents in shared forest and the underspeci ed semantic representation of (e.g. quanti er) scope ambiguity described by reyle (1993).
</nextsent>
<nextsent>3
</nextsent>
<nextsent>the contribution of this model-theoretic semantic information toward disambiguation was evaluated on set of directions to animated agents collected in acontrolled but spatially complex 3-d simulated environment (of children running lemonade stand).in order to avoid priming them towards particular linguistic constructions, subjects were shown un narrated animations of computer-simulated agents performing dierent tasks in this environment (picking fruit, operating juicer, and exchanging lemonade for money), which were described only as the `de sired behavior  of each agent.
</nextsent>
<nextsent>the subjects were then asked to direct the agents, using their own words, to perform the desired behaviors as shown.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5878">
<title id=" P04-1039.xml">relieving the data acquisition bottleneck in word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we investigate the role of large amounts of noisily sense annotated data obtained using an unsupervised approach in relieving the data acquisition bottleneck for the wsd task.
</prevsent>
<prevsent>we bootstrap supervised learning wsd system with an unsupervised seed set.
</prevsent>
</prevsection>
<citsent citstr=" P02-1033 ">
we use the sense annotated data produced by diabs unsupervised system salaam (diab&resnik;, 2002; <papid> P02-1033 </papid>diab, 2003).</citsent>
<aftsection>
<nextsent>salaam is wsd system that exploits parallel corpora for sense disambiguation of words in running text.
</nextsent>
<nextsent>to date, salaam yields the best scores for an unsupervised system on the senseval2 english all-words task (diab, 2003).
</nextsent>
<nextsent>salaam is an appealing approach as it provides automatically sense annotated data in two languages simultaneously, thereby providing amultilingual framework for solving the data acquisition problem.
</nextsent>
<nextsent>for instance, salaam has been usedto bootstrap the wsd process for arabicas illustrated in (diab, 2004).<papid> W04-1609 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5879">
<title id=" P04-1039.xml">relieving the data acquisition bottleneck in word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>to date, salaam yields the best scores for an unsupervised system on the senseval2 english all-words task (diab, 2003).
</prevsent>
<prevsent>salaam is an appealing approach as it provides automatically sense annotated data in two languages simultaneously, thereby providing amultilingual framework for solving the data acquisition problem.
</prevsent>
</prevsection>
<citsent citstr=" W04-1609 ">
for instance, salaam has been usedto bootstrap the wsd process for arabicas illustrated in (diab, 2004).<papid> W04-1609 </papid></citsent>
<aftsection>
<nextsent>in supervised learning setting, wsd is cast as classification problem, where predefined set ofsense tags constitutes the classes.
</nextsent>
<nextsent>the ambiguous words in text are assigned one or more of these classes by machine learning algorithm based on some extracted features.
</nextsent>
<nextsent>this algorithm learns parameters from explicit associations between the class and the features, or combination of features, that characterize it.
</nextsent>
<nextsent>therefore, such systems are very sensitive to the training data, and those data are, generally, assumed to be as clean as possible.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5880">
<title id=" P04-1039.xml">relieving the data acquisition bottleneck in word sense disambiguation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>to our knowledge, the earliest study of bootstrapping wsd system with noisy data is by gale et.al., (gale et al , 1992).
</prevsent>
<prevsent>their investigation was limited in scale to six data items with two senses each and bounded number of examples per test item.
</prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
two more recent investigations are by yarowsky, (yarowsky, 1995), <papid> P95-1026 </papid>and later, mihalcea, (mihalcea,2002).</citsent>
<aftsection>
<nextsent>each of the studies, in turn, addresses the issue of data quantity while maintaining good quality training examples.
</nextsent>
<nextsent>both investigations present algorithms for bootstrapping supervised wsd systems using clean data based on dictionary or an onto logical resource.
</nextsent>
<nextsent>the general idea is to start with clean initial seed and iteratively increase the seed size to cover more data.
</nextsent>
<nextsent>yarowsky starts with few tagged instances to train decision list approach.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5881">
<title id=" P04-1039.xml">relieving the data acquisition bottleneck in word sense disambiguation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>yarowsky starts with few tagged instances to train decision list approach.
</prevsent>
<prevsent>the initial seed is manually tagged with the correct senses based on entries in rogets thesaurus.
</prevsent>
</prevsection>
<citsent citstr=" P99-1020 ">
the approach yields very successful results ? 95% ? on handful of data items.mihalcea, on the other hand, bases the bootstrapping approach on generation algorithm, gencor (mihalcea&moldovan;, 1999).<papid> P99-1020 </papid></citsent>
<aftsection>
<nextsent>gencor creates seeds from monosemous words in wordnet, sem cor data, sense tagged examples from the glosses of polysemous words in wordnet, and other hand tagged data if available.
</nextsent>
<nextsent>this initial seed set is usedfor querying the web for more examples and there trieved contexts are added to the seed corpus.
</nextsent>
<nextsent>the words in the contexts of the seed words retrieved are then disambiguated.
</nextsent>
<nextsent>the disambiguated contexts are then used for querying the web for yet more examples, and so on.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5882">
<title id=" P04-1039.xml">relieving the data acquisition bottleneck in word sense disambiguation </title>
<section> factors affecting performance ratio.  </section>
<citcontext>
<prevsection>
<prevsent>at first blush, one is inclined to hypothesize that, the combination of low perplexity associated with large number of senses ? as an indication of high skew in the distribution ? is good indicator of high pr, but reviewing the data, this hypothesis is dispelled by day which has 16 senses and sense perplexity of 0 *-&amp; , yet yields low pr score of )+* )
</prevsent>
<prevsent>8 . 5.4 semantic translation entropy.
</prevsent>
</prevsection>
<citsent citstr=" W97-0207 ">
semantic translation entropy (ste) (melamed,1997) <papid> W97-0207 </papid>is special characteristic of the salaam tagged training data, since the source of evidence for salaam tagging is multilingual translations.</citsent>
<aftsection>
<nextsent>ste measures the amount of translational variation for an l1 word in l2, in parallel corpus.
</nextsent>
<nextsent>ste is variant on the entropy measure.
</nextsent>
<nextsent>ste is expressed as follows:
</nextsent>
<nextsent>   fi    0  2  (    fi *   6 7 (    fi fi (3)where  is translation in the set of possible translations  in l2; and  is l1 word.the probability of translation  is calculated directly from the alignments of the test nouns and their corresponding translations via the maximum likelihood estimate.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5883">
<title id=" N12-1091.xml">exploring semi supervised coreference resolution of medical concepts using semantic and temporal features </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>gaizauskas et al.
</prevsent>
<prevsent>(2006) learn the temporal relations before, after, is included between events from corpus of clinical text much like the event-event relation tlink learning in time bank (pustejovsky et al, 2003).
</prevsent>
</prevsection>
<citsent citstr=" P10-1142 ">
a comprehensive survey of temporal reasoning in medical data is provided by zhou and hripcsak (2007).chapman et al (2011) discuss barriers to nlp development in the clinical domain.coreference resolution is well-studied problem in computational linguistics (ng, 2010; <papid> P10-1142 </papid>raghunathan et al, 2010).<papid> D10-1048 </papid></citsent>
<aftsection>
<nextsent>supervised machine learning algorithms have been previously used for noun phrase coreference resolution with fairly good results (soon et al, 2001; <papid> J01-4004 </papid>raghunathan et al, 2010).<papid> D10-1048 </papid>recently, the i2b2 challenge2 on coreference resolution examined coreference resolution in clinicaldata.</nextsent>
<nextsent>the problem addressed in our paper is similar to the task described in the i2b2 challenge.3 besides the i2b2 challenge, there has not been significant work in mccr.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5884">
<title id=" N12-1091.xml">exploring semi supervised coreference resolution of medical concepts using semantic and temporal features </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>gaizauskas et al.
</prevsent>
<prevsent>(2006) learn the temporal relations before, after, is included between events from corpus of clinical text much like the event-event relation tlink learning in time bank (pustejovsky et al, 2003).
</prevsent>
</prevsection>
<citsent citstr=" D10-1048 ">
a comprehensive survey of temporal reasoning in medical data is provided by zhou and hripcsak (2007).chapman et al (2011) discuss barriers to nlp development in the clinical domain.coreference resolution is well-studied problem in computational linguistics (ng, 2010; <papid> P10-1142 </papid>raghunathan et al, 2010).<papid> D10-1048 </papid></citsent>
<aftsection>
<nextsent>supervised machine learning algorithms have been previously used for noun phrase coreference resolution with fairly good results (soon et al, 2001; <papid> J01-4004 </papid>raghunathan et al, 2010).<papid> D10-1048 </papid>recently, the i2b2 challenge2 on coreference resolution examined coreference resolution in clinicaldata.</nextsent>
<nextsent>the problem addressed in our paper is similar to the task described in the i2b2 challenge.3 besides the i2b2 challenge, there has not been significant work in mccr.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5886">
<title id=" N12-1091.xml">exploring semi supervised coreference resolution of medical concepts using semantic and temporal features </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>(2006) learn the temporal relations before, after, is included between events from corpus of clinical text much like the event-event relation tlink learning in time bank (pustejovsky et al, 2003).
</prevsent>
<prevsent>a comprehensive survey of temporal reasoning in medical data is provided by zhou and hripcsak (2007).chapman et al (2011) discuss barriers to nlp development in the clinical domain.coreference resolution is well-studied problem in computational linguistics (ng, 2010; <papid> P10-1142 </papid>raghunathan et al, 2010).<papid> D10-1048 </papid></prevsent>
</prevsection>
<citsent citstr=" J01-4004 ">
supervised machine learning algorithms have been previously used for noun phrase coreference resolution with fairly good results (soon et al, 2001; <papid> J01-4004 </papid>raghunathan et al, 2010).<papid> D10-1048 </papid>recently, the i2b2 challenge2 on coreference resolution examined coreference resolution in clinicaldata.</citsent>
<aftsection>
<nextsent>the problem addressed in our paper is similar to the task described in the i2b2 challenge.3 besides the i2b2 challenge, there has not been significant work in mccr.
</nextsent>
<nextsent>this may be due to various privacy concerns and the efforts required to anonymize and annotate massive amounts of patient narratives.zheng et al (2011) review heuristic-based, supervised and unsupervised methods for coreference resolution in the context of the clinical domain.
</nextsent>
<nextsent>he (2007) studied coreference resolution in discharge summaries, treating coreference resolution as binary classification problem and investigated critical features for coreference resolution for entities that fall into five medical semantic categories commonly appearing in discharge summaries.
</nextsent>
<nextsent>however, we focus on feature extraction to determine the similarity between medical concepts, both in terms of meaning and time of occurrence, for resolving co references within and across all types of clinical narratives.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5889">
<title id=" N12-1063.xml">ranking based readability assessment for early primary childrens literature </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>while 1http://www.readingrecovery.org 2http://www.fountasandpinnellleveledbooks.com 548 publishers may have standard guidelines for content providers on visual layout, these guidelines likely differ from publisher to publisher and are not available for the general public.
</prevsent>
<prevsent>moreover, in the digital age teachers are also content providers who do not have access to these guidelines, so our proposed ranking system would be very helpful as they create reading materials such as worksheets, web pages, etc.
</prevsent>
</prevsection>
<citsent citstr=" P05-1065 ">
due to the limitations of traditional approaches,more advanced methods which use statistical language processing techniques have been introduced by recent work in this area (collins-thompson and callan, 2004; schwarm and ostendorf, 2005; <papid> P05-1065 </papid>feng et al, 2010).<papid> C10-2032 </papid></citsent>
<aftsection>
<nextsent>collins-thompson and callan (2004)used smoothed unigram language model to predict the grade reading levels of web page document sand short passages.
</nextsent>
<nextsent>heilman et al (2007) <papid> N07-1058 </papid>combined language modeling approach with grammar based features to improve readability assessment for first and second language texts.</nextsent>
<nextsent>schwarm/petersen and ostendorf (2005), petersen and ostendorf (2009) used support vector machine to combine surface features with language models and parsed features.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5890">
<title id=" N12-1063.xml">ranking based readability assessment for early primary childrens literature </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>while 1http://www.readingrecovery.org 2http://www.fountasandpinnellleveledbooks.com 548 publishers may have standard guidelines for content providers on visual layout, these guidelines likely differ from publisher to publisher and are not available for the general public.
</prevsent>
<prevsent>moreover, in the digital age teachers are also content providers who do not have access to these guidelines, so our proposed ranking system would be very helpful as they create reading materials such as worksheets, web pages, etc.
</prevsent>
</prevsection>
<citsent citstr=" C10-2032 ">
due to the limitations of traditional approaches,more advanced methods which use statistical language processing techniques have been introduced by recent work in this area (collins-thompson and callan, 2004; schwarm and ostendorf, 2005; <papid> P05-1065 </papid>feng et al, 2010).<papid> C10-2032 </papid></citsent>
<aftsection>
<nextsent>collins-thompson and callan (2004)used smoothed unigram language model to predict the grade reading levels of web page document sand short passages.
</nextsent>
<nextsent>heilman et al (2007) <papid> N07-1058 </papid>combined language modeling approach with grammar based features to improve readability assessment for first and second language texts.</nextsent>
<nextsent>schwarm/petersen and ostendorf (2005), petersen and ostendorf (2009) used support vector machine to combine surface features with language models and parsed features.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5891">
<title id=" N12-1063.xml">ranking based readability assessment for early primary childrens literature </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>due to the limitations of traditional approaches,more advanced methods which use statistical language processing techniques have been introduced by recent work in this area (collins-thompson and callan, 2004; schwarm and ostendorf, 2005; <papid> P05-1065 </papid>feng et al, 2010).<papid> C10-2032 </papid></prevsent>
<prevsent>collins-thompson and callan (2004)used smoothed unigram language model to predict the grade reading levels of web page document sand short passages.</prevsent>
</prevsection>
<citsent citstr=" N07-1058 ">
heilman et al (2007) <papid> N07-1058 </papid>combined language modeling approach with grammar based features to improve readability assessment for first and second language texts.</citsent>
<aftsection>
<nextsent>schwarm/petersen and ostendorf (2005), petersen and ostendorf (2009) used support vector machine to combine surface features with language models and parsed features.
</nextsent>
<nextsent>the datasets used in these previous related works mostly consist of web page documents and short passages, or articles from educational newspapers.
</nextsent>
<nextsent>since the datasets used aretext-intensive, many efforts have been made to investigate text properties at higher linguistic level,such as discourse analysis, language modeling, part of-speech and parsed-based features.
</nextsent>
<nextsent>however, to the best of our knowledge, no prior work attempts torank scanned childrens books (in fine-grained reading levels) directly by analyzing the visual layout of the page.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5892">
<title id=" N12-1058.xml">coreference via pointing and haptics in multimodal dialogues </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the usage of haptic ostensive actions in co-reference model is novel contribution of our work.
</prevsent>
<prevsent>co-reference resolution has received lot of attention.
</prevsent>
</prevsection>
<citsent citstr=" N06-2010 ">
however, as eisenstein and davis (2006) <papid> N06-2010 </papid>noted, most research on co-reference resolution has focused on written text.</citsent>
<aftsection>
<nextsent>this task is much more difficult in dialogue, especially in multi-modal dialogue contexts.
</nextsent>
<nextsent>first, utterances are informal, ungrammatical and disfluent.
</nextsent>
<nextsent>second, people spontaneously use gestures and other body language.
</nextsent>
<nextsent>as noticed by kehler (2000), goldin-meadow (2003), and chen et al (2011), <papid> W11-2035 </papid>in multi-modal corpus,the antecedents of referring expressions are often introduced via gestures.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5893">
<title id=" N12-1058.xml">coreference via pointing and haptics in multimodal dialogues </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>first, utterances are informal, ungrammatical and disfluent.
</prevsent>
<prevsent>second, people spontaneously use gestures and other body language.
</prevsent>
</prevsection>
<citsent citstr=" W11-2035 ">
as noticed by kehler (2000), goldin-meadow (2003), and chen et al (2011), <papid> W11-2035 </papid>in multi-modal corpus,the antecedents of referring expressions are often introduced via gestures.</citsent>
<aftsection>
<nextsent>whereas the role played by pointing gestures in referring has been studied, the same is not true for other types of gestures.
</nextsent>
<nextsent>in this paper, alongside pointing gestures, we will discuss the role played by haptic-ostensive (h-o) actions, i.e., referring to an object by manipulating it in the world (landragin et al, 2002; foster et al, 2008).as far as we know, no computational models of coreference have been developed that include h-o actions: (landragin et al, 2002) focused on perceptual salience and (foster et al, 2008) on generation rather than interpretation.
</nextsent>
<nextsent>we should point out that at the time of writing we only focus on resolving third person pronouns and deictics.
</nextsent>
<nextsent>the rest of this paper is organized as follows.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5895">
<title id=" P04-2001.xml">determining the specificity of terms using compositional and contextual information </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>subtree of mesh1 tree.
</prevsent>
<prevsent>node numbers represent hierarchical structure of terms contextual information has been mainly used to represent the characteristics of terms.
</prevsent>
</prevsection>
<citsent citstr=" P99-1016 ">
(cara ballo, 1999<papid> P99-1016 </papid>a) (grefenstette, 1994) (hearst, 1992) (<papid> C92-2082 </papid>pereira, 1993) and (sanderson, 1999) used contextual information to find hyponymy relation between terms.</citsent>
<aftsection>
<nextsent>(caraballo, 1999<papid> P99-1016 </papid>b) also used contextual information to determine the specificity of nouns.</nextsent>
<nextsent>contrary, compositional information of terms has not been commonly discussed.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5896">
<title id=" P04-2001.xml">determining the specificity of terms using compositional and contextual information </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>subtree of mesh1 tree.
</prevsent>
<prevsent>node numbers represent hierarchical structure of terms contextual information has been mainly used to represent the characteristics of terms.
</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
(cara ballo, 1999<papid> P99-1016 </papid>a) (grefenstette, 1994) (hearst, 1992) (<papid> C92-2082 </papid>pereira, 1993) and (sanderson, 1999) used contextual information to find hyponymy relation between terms.</citsent>
<aftsection>
<nextsent>(caraballo, 1999<papid> P99-1016 </papid>b) also used contextual information to determine the specificity of nouns.</nextsent>
<nextsent>contrary, compositional information of terms has not been commonly discussed.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5901">
<title id=" P01-1031.xml">resolving ellipsis in clarification </title>
<section> utterance representation: grounding.  </section>
<citcontext>
<prevsection>
<prevsent>rather, given the syntactic and phonological parallelism encoded in clarification contexts,these operations need to be defined on representations that encode in parallel for each sub utterance down to the word level phonological, syntactic, semantic, and contextual information.with some minor modifications, signs as conceived in hpsg are exactly such representational format and, hence, we will use them to define coercion operations.6 more precisely, given that an addressee might not be able to come upwith unique or complete parse, due to lexical ignorance or noisy environment, we need to utilize some underspecified?
</prevsent>
<prevsent>entity (see e.g.
</prevsent>
</prevsection>
<citsent citstr=" P00-1018 ">
(milward, 2000)).<papid> P00-1018 </papid></citsent>
<aftsection>
<nextsent>for simplicity we will use descriptions of signs.
</nextsent>
<nextsent>an example of the format for signs we employ is given in (7):7 6we make two minor modifications to the version ofhpsg described in (ginzburg and sag, 2000)).
</nextsent>
<nextsent>first, we revamp the existing treatment of the feature c-indices.
</nextsent>
<nextsent>thi swill now encode the entire inventory of contextual parameters of an utterance (proper names, deictic pronouns, indexicals) not merely information about speaker/hearer/utterance time, as standardly.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5902">
<title id=" P03-2038.xml">an intelligent procedure assistant built using regulus 2 and alterf </title>
<section> regulus 2.  </section>
<citcontext>
<prevsection>
<prevsent>the system consists of set of modules, written in several different languages, which communicate with each other through the sri open agent architecture (martin et al , 1998).
</prevsent>
<prevsent>speech recognition is carried out using the nuance toolkit (nuance, 2003).
</prevsent>
</prevsection>
<citsent citstr=" E03-2010 ">
regulus 2 (rayner et al , 2003; <papid> E03-2010 </papid>regulus, 2003)is an open source environment that supports efficient compilation of typed unification grammars into speech recognisers.</citsent>
<aftsection>
<nextsent>the basic intent is to prov idea set of tools to support rapid prototyping of spoken dialogue applications in situations where little or no corpus data exists.
</nextsent>
<nextsent>the environment has already been used to build over half dozen applications with vocabularies of between 100 and 500 words.the core functionality provided by the regulus 2 environment is compilation of typed unification grammars into annotated context-free grammar language models expressed in nuance grammar specification language (gsl) notation (nuance, 2003).
</nextsent>
<nextsent>gsl language models can be converted into runnable speech recognisers by invoking the nuance toolkit compiler utility, so the net result is the ability to compile unification grammar into speech recogniser.
</nextsent>
<nextsent>experience with grammar-based spoken dialogue systems shows that there is usually substantial overlap between the structures of grammars for different domains.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5903">
<title id=" P03-2038.xml">an intelligent procedure assistant built using regulus 2 and alterf </title>
<section> alterf.  </section>
<citcontext>
<prevsection>
<prevsent>the final specialised grammar is compiled into.
</prevsent>
<prevsent>a nuance gsl grammar.
</prevsent>
</prevsection>
<citsent citstr=" E03-1078 ">
alterf (rayner and hockey, 2003) <papid> E03-1078 </papid>is another open source toolkit, whose purpose is to allow clean combination of rule-based and corpus-driven processing in the semantic interpretation phase.</citsent>
<aftsection>
<nextsent>there is typically no corpus data available at the start of project, but considerable amounts at the end: the intention behind alterf is to allow us to shift smoothly from an initial version of the system which is entirely rule-based, to final version which is largely data-driven.
</nextsent>
<nextsent>alterf characterises semantic analysis as task slightly extending the decision-list?
</nextsent>
<nextsent>classification algorithm (yarowsky, 1994; <papid> P94-1013 </papid>carter, 2000).</nextsent>
<nextsent>we start with set of semantic atoms, each representing primitive domain concept, and define semantic representation to be non-empty set of semanticatoms.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5904">
<title id=" P03-2038.xml">an intelligent procedure assistant built using regulus 2 and alterf </title>
<section> alterf.  </section>
<citcontext>
<prevsection>
<prevsent>there is typically no corpus data available at the start of project, but considerable amounts at the end: the intention behind alterf is to allow us to shift smoothly from an initial version of the system which is entirely rule-based, to final version which is largely data-driven.
</prevsent>
<prevsent>alterf characterises semantic analysis as task slightly extending the decision-list?
</prevsent>
</prevsection>
<citsent citstr=" P94-1013 ">
classification algorithm (yarowsky, 1994; <papid> P94-1013 </papid>carter, 2000).</citsent>
<aftsection>
<nextsent>we start with set of semantic atoms, each representing primitive domain concept, and define semantic representation to be non-empty set of semanticatoms.
</nextsent>
<nextsent>for example, in the procedure assistant do main we represent the utterances please speak up show me the sample syringe set an alarm for five minutes from now no said go to the next step respectively as {increase volume} {show, sample syringe} {set al rm, 5, minutes} {correction, next step} where increase volume, show, sample syringe, set al rm, 5, minutes, correction and next step are semantic atoms.
</nextsent>
<nextsent>as well as specifying the permitted semantic atoms themselves, we also define target model which for each atom specifies the other atoms with which it may legitimately combine.
</nextsent>
<nextsent>thus here, for example, correction may legitimately combine with any atom, but minutes may only combine with correction, set al rm or number.1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5906">
<title id=" P01-1060.xml">parse forest computation of expected governors </title>
<section> parse forests.  </section>
<citcontext>
<prevsection>
<prevsent>first constructed by tabular parsing, and then in asecond pass parse forest symbols are split according to headedness.
</prevsent>
<prevsent>such an algorithm is shown in appendix b. this procedure gives worst case time and space complexity which is proportional to the fifth power of the length of the sentence.
</prevsent>
</prevsection>
<citsent citstr=" P99-1059 ">
see eisner and satta (1999) <papid> P99-1059 </papid>for discussion and an algorithm with time and space requirements proportional to the fourth power of the length of the input sentence in the worst case.</citsent>
<aftsection>
<nextsent>in practical experience with broad-coverage context free grammars of several languages, we have not observed super-cubic average time or space requirements for our implementation.
</nextsent>
<nextsent>we believe this is because, for our grammars and corpora, there is limited ambiguity in the position of the head within given category-span combination.the governor algorithm stated in the next section refers to headedness in parse forest rules.this can be represented by constructing parse forest rules (as well as ordinary grammar rules) with headed tree domains of depth one.5 where ffi is parse forest symbol on the right hand side of aparse forest rule , we will simply state the condition ? ffi is the head of ?.the flow and governor algorithms stated be low call an algorithm pf-inside  3zff which computes inside probabilities in , where ? is afunction giving probability parameters for theun derlying grammar.
</nextsent>
<nextsent>any probability weighting oftrees may be used which allows inside probabilities to be computed in parse forests.
</nextsent>
<nextsent>the inside 5see footnote 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5907">
<title id=" P02-1013.xml">generating minimal definite descriptions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>from the generation perspective, this means that, starting from the set of objects to be described and from the properties known to hold of these objects by both the speaker and the hearer, definite description must be constructed which allows the user 1the other well-known function of definite is to inform the hearer of some specific attributes the referent of the np has.
</prevsent>
<prevsent>to unambiguously identify the objects being talked about.
</prevsent>
</prevsection>
<citsent citstr=" P97-1027 ">
while the task of constructing singular definite descriptions on the basis of positive properties has received much attention in the generation literature (dale and haddock, 1991; dale and reiter, 1995; horacek, 1997; <papid> P97-1027 </papid>krahmer et al, 2001), <papid> W01-0805 </papid>for longtime, more general statement of the task at hand remained outstanding.</citsent>
<aftsection>
<nextsent>recently however, several papers made step in that direction.
</nextsent>
<nextsent>(van deemter,2001) showed how to extend the basic dale andre iter algorithm (dale and reiter, 1995) to generate plural definite descriptions using not just conjunctions of positive properties but also negative and disjunctive properties; (stone, 1998) integrates the d&r; algorithm into the surface realisation process and (stone, 2000) <papid> W00-1416 </papid>extends it to deal with collective and distributive plural nps.notably, in all three cases, the incremental structure of the d&rs; algorithm is preserved: the algorithm increments set of properties till this set uniquely identifies the target set i.e., the set of objects to be described.</nextsent>
<nextsent>as (garey and johnson, 1979)shows, such an incremental algorithm while being polynomial (and this, together with certain psy cho linguistic observations, was one of the primary motivation for privileging this incremental strategy) is not guaranteed to find the minimal solution i.e., the description which uniquely identifies the target set using the smallest number of atomic properties.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5908">
<title id=" P02-1013.xml">generating minimal definite descriptions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>from the generation perspective, this means that, starting from the set of objects to be described and from the properties known to hold of these objects by both the speaker and the hearer, definite description must be constructed which allows the user 1the other well-known function of definite is to inform the hearer of some specific attributes the referent of the np has.
</prevsent>
<prevsent>to unambiguously identify the objects being talked about.
</prevsent>
</prevsection>
<citsent citstr=" W01-0805 ">
while the task of constructing singular definite descriptions on the basis of positive properties has received much attention in the generation literature (dale and haddock, 1991; dale and reiter, 1995; horacek, 1997; <papid> P97-1027 </papid>krahmer et al, 2001), <papid> W01-0805 </papid>for longtime, more general statement of the task at hand remained outstanding.</citsent>
<aftsection>
<nextsent>recently however, several papers made step in that direction.
</nextsent>
<nextsent>(van deemter,2001) showed how to extend the basic dale andre iter algorithm (dale and reiter, 1995) to generate plural definite descriptions using not just conjunctions of positive properties but also negative and disjunctive properties; (stone, 1998) integrates the d&r; algorithm into the surface realisation process and (stone, 2000) <papid> W00-1416 </papid>extends it to deal with collective and distributive plural nps.notably, in all three cases, the incremental structure of the d&rs; algorithm is preserved: the algorithm increments set of properties till this set uniquely identifies the target set i.e., the set of objects to be described.</nextsent>
<nextsent>as (garey and johnson, 1979)shows, such an incremental algorithm while being polynomial (and this, together with certain psy cho linguistic observations, was one of the primary motivation for privileging this incremental strategy) is not guaranteed to find the minimal solution i.e., the description which uniquely identifies the target set using the smallest number of atomic properties.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5910">
<title id=" P02-1013.xml">generating minimal definite descriptions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>while the task of constructing singular definite descriptions on the basis of positive properties has received much attention in the generation literature (dale and haddock, 1991; dale and reiter, 1995; horacek, 1997; <papid> P97-1027 </papid>krahmer et al, 2001), <papid> W01-0805 </papid>for longtime, more general statement of the task at hand remained outstanding.</prevsent>
<prevsent>recently however, several papers made step in that direction.</prevsent>
</prevsection>
<citsent citstr=" W00-1416 ">
(van deemter,2001) showed how to extend the basic dale andre iter algorithm (dale and reiter, 1995) to generate plural definite descriptions using not just conjunctions of positive properties but also negative and disjunctive properties; (stone, 1998) integrates the d&r; algorithm into the surface realisation process and (stone, 2000) <papid> W00-1416 </papid>extends it to deal with collective and distributive plural nps.notably, in all three cases, the incremental structure of the d&rs; algorithm is preserved: the algorithm increments set of properties till this set uniquely identifies the target set i.e., the set of objects to be described.</citsent>
<aftsection>
<nextsent>as (garey and johnson, 1979)shows, such an incremental algorithm while being polynomial (and this, together with certain psy cho linguistic observations, was one of the primary motivation for privileging this incremental strategy) is not guaranteed to find the minimal solution i.e., the description which uniquely identifies the target set using the smallest number of atomic properties.
</nextsent>
<nextsent>in this paper, argue that this characteristic of the incremental algorithm while reasonably innocuous when generating singular definite descriptions using only conjunctions of positive properties, renders it computational linguistics (acl), philadelphia, july 2002, pp.
</nextsent>
<nextsent>96-103.
</nextsent>
<nextsent>proceedings of the 40th annual meeting of the association for cognitively inappropriate when generalised to sets of individuals and disjunctive properties.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5911">
<title id=" P02-1013.xml">generating minimal definite descriptions </title>
<section> problems.  </section>
<citcontext>
<prevsection>
<prevsent>as before solutions are searched for in increasing order of size (i.e., number of liter als occurring in the description) by distributing over the cardinality of the resulting description.
</prevsent>
<prevsent>5 discussion and comparison with related.
</prevsent>
</prevsection>
<citsent citstr=" W98-1419 ">
work integration with surface realisation as (stoneand webber, 1998) <papid> W98-1419 </papid>clearly shows, the two-step strategy which consists in first computing dd and second, generating definite np realising that dd, doesnot do language justice.</citsent>
<aftsection>
<nextsent>this is because, as the following example from (stone and webber, 1998) <papid> W98-1419 </papid>illustrates, the information used to uniquely identify some object need not be localised to definite de scription.</nextsent>
<nextsent>(2) remove the rabbit from the hat.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5917">
<title id=" P01-1064.xml">a statistical model for domain independent text segmentation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>an experiment showed that the method is more accurate than or at least as accurate asa state-of-the-art text segmentation system.
</prevsent>
<prevsent>documents usually include various topics.
</prevsent>
</prevsection>
<citsent citstr=" W98-1123 ">
identifying and isolating topics by dividing documents, which is called text segmentation, is important for many natural language processing tasks, including information retrieval (hearst and plaunt, 1993; salton et al, 1996) and summarization(kan et al, 1998; <papid> W98-1123 </papid>nakao, 2000).<papid> P00-1039 </papid></citsent>
<aftsection>
<nextsent>in information retrieval, users are often interested in particular topics (parts) of retrieved documents, instead of the documents themselves.
</nextsent>
<nextsent>to meet such needs, documents should be segmented into coherent topics.
</nextsent>
<nextsent>summarization is often used for long document that includes multiple topics.
</nextsent>
<nextsent>a summary of such document can be composed of summaries of the component topics.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5920">
<title id=" P01-1064.xml">a statistical model for domain independent text segmentation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>an experiment showed that the method is more accurate than or at least as accurate asa state-of-the-art text segmentation system.
</prevsent>
<prevsent>documents usually include various topics.
</prevsent>
</prevsection>
<citsent citstr=" P00-1039 ">
identifying and isolating topics by dividing documents, which is called text segmentation, is important for many natural language processing tasks, including information retrieval (hearst and plaunt, 1993; salton et al, 1996) and summarization(kan et al, 1998; <papid> W98-1123 </papid>nakao, 2000).<papid> P00-1039 </papid></citsent>
<aftsection>
<nextsent>in information retrieval, users are often interested in particular topics (parts) of retrieved documents, instead of the documents themselves.
</nextsent>
<nextsent>to meet such needs, documents should be segmented into coherent topics.
</nextsent>
<nextsent>summarization is often used for long document that includes multiple topics.
</nextsent>
<nextsent>a summary of such document can be composed of summaries of the component topics.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5923">
<title id=" P01-1064.xml">a statistical model for domain independent text segmentation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>summarization is often used for long document that includes multiple topics.
</prevsent>
<prevsent>a summary of such document can be composed of summaries of the component topics.
</prevsent>
</prevsection>
<citsent citstr=" P93-1041 ">
identification of topics is the task of text segmentation.a lot of research has been done on text segmentation (kozima, 1993; <papid> P93-1041 </papid>hearst, 1994; <papid> P94-1002 </papid>okumura and honda, 1994; <papid> C94-2121 </papid>salton et al, 1996; yaari, 1997; kan et al, 1998; <papid> W98-1123 </papid>choi, 2000; <papid> A00-2004 </papid>nakao, 2000).<papid> P00-1039 </papid></citsent>
<aftsection>
<nextsent>a major characteristic of the methods used in this research is that they do not require training datato segment given texts.
</nextsent>
<nextsent>hearst (1994), <papid> P94-1002 </papid>for example, used only the similarity of word distributions in given text to segment the text.</nextsent>
<nextsent>consequently, these methods can be applied to any text in any domain, even if training data do not exist.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5924">
<title id=" P01-1064.xml">a statistical model for domain independent text segmentation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>summarization is often used for long document that includes multiple topics.
</prevsent>
<prevsent>a summary of such document can be composed of summaries of the component topics.
</prevsent>
</prevsection>
<citsent citstr=" P94-1002 ">
identification of topics is the task of text segmentation.a lot of research has been done on text segmentation (kozima, 1993; <papid> P93-1041 </papid>hearst, 1994; <papid> P94-1002 </papid>okumura and honda, 1994; <papid> C94-2121 </papid>salton et al, 1996; yaari, 1997; kan et al, 1998; <papid> W98-1123 </papid>choi, 2000; <papid> A00-2004 </papid>nakao, 2000).<papid> P00-1039 </papid></citsent>
<aftsection>
<nextsent>a major characteristic of the methods used in this research is that they do not require training datato segment given texts.
</nextsent>
<nextsent>hearst (1994), <papid> P94-1002 </papid>for example, used only the similarity of word distributions in given text to segment the text.</nextsent>
<nextsent>consequently, these methods can be applied to any text in any domain, even if training data do not exist.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5925">
<title id=" P01-1064.xml">a statistical model for domain independent text segmentation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>summarization is often used for long document that includes multiple topics.
</prevsent>
<prevsent>a summary of such document can be composed of summaries of the component topics.
</prevsent>
</prevsection>
<citsent citstr=" C94-2121 ">
identification of topics is the task of text segmentation.a lot of research has been done on text segmentation (kozima, 1993; <papid> P93-1041 </papid>hearst, 1994; <papid> P94-1002 </papid>okumura and honda, 1994; <papid> C94-2121 </papid>salton et al, 1996; yaari, 1997; kan et al, 1998; <papid> W98-1123 </papid>choi, 2000; <papid> A00-2004 </papid>nakao, 2000).<papid> P00-1039 </papid></citsent>
<aftsection>
<nextsent>a major characteristic of the methods used in this research is that they do not require training datato segment given texts.
</nextsent>
<nextsent>hearst (1994), <papid> P94-1002 </papid>for example, used only the similarity of word distributions in given text to segment the text.</nextsent>
<nextsent>consequently, these methods can be applied to any text in any domain, even if training data do not exist.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5929">
<title id=" P01-1064.xml">a statistical model for domain independent text segmentation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>summarization is often used for long document that includes multiple topics.
</prevsent>
<prevsent>a summary of such document can be composed of summaries of the component topics.
</prevsent>
</prevsection>
<citsent citstr=" A00-2004 ">
identification of topics is the task of text segmentation.a lot of research has been done on text segmentation (kozima, 1993; <papid> P93-1041 </papid>hearst, 1994; <papid> P94-1002 </papid>okumura and honda, 1994; <papid> C94-2121 </papid>salton et al, 1996; yaari, 1997; kan et al, 1998; <papid> W98-1123 </papid>choi, 2000; <papid> A00-2004 </papid>nakao, 2000).<papid> P00-1039 </papid></citsent>
<aftsection>
<nextsent>a major characteristic of the methods used in this research is that they do not require training datato segment given texts.
</nextsent>
<nextsent>hearst (1994), <papid> P94-1002 </papid>for example, used only the similarity of word distributions in given text to segment the text.</nextsent>
<nextsent>consequently, these methods can be applied to any text in any domain, even if training data do not exist.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5936">
<title id=" P01-1064.xml">a statistical model for domain independent text segmentation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>kozima (1993), <papid> P93-1041 </papid>for example, used cohesion based on the spreading activation on semantic network.</prevsent>
<prevsent>hearst (1994) <papid> P94-1002 </papid>used the similarity of word distributions as measured by the cosine to gauge cohesion.</prevsent>
</prevsection>
<citsent citstr=" P94-1050 ">
reynar (1994) <papid> P94-1050 </papid>used word repetition as measure of cohesion.</citsent>
<aftsection>
<nextsent>choi (2000) <papid> A00-2004 </papid>used the rank of the cosine, rather than the cosine itself, to measure the similarity of sentences.the statistical model for the algorithm is described in section 2, and the algorithm for obtaining the maximum-probability segmentation is described in section 3.</nextsent>
<nextsent>experimental results are presented in section 4.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5939">
<title id=" P01-1064.xml">a statistical model for domain independent text segmentation </title>
<section> algorithm for finding the.  </section>
<citcontext>
<prevsection>
<prevsent>to ? .
</prevsent>
<prevsent>algorithms for finding the minimum-cost path in graph are well known.
</prevsent>
</prevsection>
<citsent citstr=" C94-1032 ">
an algorithm that can provide solution for step 2 will be simpler version of the algorithm used to find the maximum probability solution in japanese morphological analysis (nagata, 1994).<papid> C94-1032 </papid></citsent>
<aftsection>
<nextsent>therefore, solution can be obtained by applying dynamic programming (dp) algorithm.4 dp algorithms have also been used for text segmentation by other researchers (ponte and croft, 1997; heinonen, 1998).<papid> P98-2244 </papid></nextsent>
<nextsent>the path thus obtained represents the minimum-cost segmentation in ? when edges correspond with segments.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5940">
<title id=" P01-1064.xml">a statistical model for domain independent text segmentation </title>
<section> algorithm for finding the.  </section>
<citcontext>
<prevsection>
<prevsent>algorithms for finding the minimum-cost path in graph are well known.
</prevsent>
<prevsent>an algorithm that can provide solution for step 2 will be simpler version of the algorithm used to find the maximum probability solution in japanese morphological analysis (nagata, 1994).<papid> C94-1032 </papid></prevsent>
</prevsection>
<citsent citstr=" P98-2244 ">
therefore, solution can be obtained by applying dynamic programming (dp) algorithm.4 dp algorithms have also been used for text segmentation by other researchers (ponte and croft, 1997; heinonen, 1998).<papid> P98-2244 </papid></citsent>
<aftsection>
<nextsent>the path thus obtained represents the minimum-cost segmentation in ? when edges correspond with segments.
</nextsent>
<nextsent>in figure 1, for example, if ? ?
</nextsent>
<nextsent>is the minimum-cost path, then ? ???
</nextsent>
<nextsent>??9?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Q5961">
<title id=" P01-1064.xml">a statistical model for domain independent text segmentation </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>therefore, our algorithm can be applied to domain-independent texts, while their algorithm is restricted to domains for which training data are available.
</prevsent>
<prevsent>it would be interesting, however, to compare our algorithm with their algorithm for the case when training data are available.
</prevsent>
</prevsection>
<citsent citstr=" P99-1046 ">
in sucha case, our model should be extended to incorporate various features such as the average segment length, clue words, named entities, and so on (reynar, 1999; <papid> P99-1046 </papid>beeferman et al, 1999).</citsent>
<aftsection>
<nextsent>our proposed algorithm naturally estimates the probabilities of words in segments.
</nextsent>
<nextsent>these probabilities, which are called word densities, have been used to detect important descriptions of words in texts (kurohashi et al, 1997).
</nextsent>
<nextsent>this method is based on the assumption that the density of word is high in segment in which the word is discussed (defined and/or explained) in some depth.
</nextsent>
<nextsent>it would be interesting to apply our method to this application.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
</paper>