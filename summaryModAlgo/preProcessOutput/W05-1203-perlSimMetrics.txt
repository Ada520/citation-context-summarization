6	6	
6	16	8.81168738979562e-05
6	8	0.000129402229876579
6	7	0.000227514298092216
6	10	0.000530899859377426
6	17	0.000361564414843421
6	9	0.0284840970932873
6	15	7.35936977980118e-05
6	1	0
6	11	0.0211929698756384
6	3	0.000369272011427355
6	2	0.000342910015227327
6	14	0.445916827341486
6	12	0.00021496275860474
6	13	0.0474952122166407
6	4	6.955930596583e-05
6	5	0.0385175455029631
16	6	8.81168738979562e-05
16	16	
16	8	0.290624190034806
16	7	0.0143586780111979
16	10	0.000120350015220821
16	17	0.0912266293206774
16	9	0.000191967239968737
16	15	8.77459160465747e-05
16	1	0
16	11	0.00942552539453311
16	3	0.0973265682275622
16	2	0.0209905462550784
16	14	0.0162958377668438
16	12	0.0128090963491453
16	13	0.175871877318237
16	4	0.145730003788559
16	5	0.207004113189641
8	6	0.000129402229876579
8	16	0.290624190034806
8	8	
8	7	0.00124527277704551
8	10	0.000181863266470778
8	17	0
8	9	8.40229839297941e-05
8	15	0.000132594573273805
8	1	0
8	11	0.151826132295764
8	3	0.115753283694914
8	2	0.0801283344673227
8	14	0.000181850935388573
8	12	0.00111499379001191
8	13	0.132950217434076
8	4	0.110114724673582
8	5	0.108652603499649
7	6	0.000227514298092216
7	16	0.0143586780111979
7	8	0.00124527277704551
7	7	
7	10	0.0973604248036807
7	17	0.00887379886303505
7	9	0.372715228237854
7	15	3.95235902001237e-05
7	1	0.320677492166184
7	11	0.413898403322627
7	3	0.140595603622875
7	2	0.180244185429601
7	14	0.0808960863544023
7	12	0.0800729904634569
7	13	0.000248057163264099
7	4	0.0642577670093828
7	5	0.0574061744430433
10	6	0.000530899859377426
10	16	0.000120350015220821
10	8	0.000181863266470778
10	7	0.0973604248036807
10	10	
10	17	0.000508146463826288
10	9	0.0859306784584543
10	15	0.000103429363512322
10	1	0.0695527570260193
10	11	0.10279652154548
10	3	0.0331968481932315
10	2	0.0642976781340076
10	14	0.178045197369177
10	12	0.133927473951889
10	13	0.000578836205894611
10	4	0.0639267068934601
10	5	0.0541329670152271
17	6	0.000361564414843421
17	16	0.0912266293206774
17	8	0
17	7	0.00887379886303505
17	10	0.000508146463826288
17	17	
17	9	0.000469539374197024
17	15	0
17	1	0
17	11	0.0277172625536702
17	3	0.000389389114728104
17	2	0.00032641364905442
17	14	0.000254056004696402
17	12	0.000239127722257128
17	13	0.0622626254218746
17	4	0
17	5	0
9	6	0.0284840970932873
9	16	0.000191967239968737
9	8	8.40229839297941e-05
9	7	0.372715228237854
9	10	0.0859306784584543
9	17	0.000469539374197024
9	9	
9	15	6.51574562248878e-05
9	1	0.287155081558911
9	11	0.0770752609778699
9	3	0.132963619710942
9	2	0.0299174557323546
9	14	0.0824018977619916
9	12	0.0620074588538203
9	13	0.039773620910055
9	4	0.145041410623349
9	5	0.0355880881895053
15	6	7.35936977980118e-05
15	16	8.77459160465747e-05
15	8	0.000132594573273805
15	7	3.95235902001237e-05
15	10	0.000103429363512322
15	17	0
15	9	6.51574562248878e-05
15	15	
15	1	0.0507101753798287
15	11	9.67971847059492e-05
15	3	0.0029018689523424
15	2	0.0800061283400149
15	14	0.000103422350573378
15	12	0.312652375362436
15	13	8.02386665935648e-05
15	4	0.000413419874225922
15	5	2.3864117553053e-05
1	6	0
1	16	0
1	8	0
1	7	0.320677492166184
1	10	0.0695527570260193
1	17	0
1	9	0.287155081558911
1	15	0.0507101753798287
1	1	
1	11	0.046549102998461
1	3	0.103563656987016
1	2	0
1	14	0.0347740205306059
1	12	0
1	13	0
1	4	0
1	5	0.123006408529428
11	6	0.0211929698756384
11	16	0.00942552539453311
11	8	0.151826132295764
11	7	0.413898403322627
11	10	0.10279652154548
11	17	0.0277172625536702
11	9	0.0770752609778699
11	15	9.67971847059492e-05
11	1	0.046549102998461
11	11	
11	3	0.0179838317530622
11	2	0.240510630235604
11	14	0.0871169282537818
11	12	0.116560742264876
11	13	0.0483549322944366
11	4	0.0858105268395508
11	5	0.0724894267359736
3	6	0.000369272011427355
3	16	0.0973265682275622
3	8	0.115753283694914
3	7	0.140595603622875
3	10	0.0331968481932315
3	17	0.000389389114728104
3	9	0.132963619710942
3	15	0.0029018689523424
3	1	0.103563656987016
3	11	0.0179838317530622
3	3	
3	2	0.00822994609796011
3	14	0.0227733355690368
3	12	0.0217146647925631
3	13	0.0400953419068592
3	4	0.0959337607838169
3	5	0.0402751520218399
2	6	0.000342910015227327
2	16	0.0209905462550784
2	8	0.0801283344673227
2	7	0.180244185429601
2	10	0.0642976781340076
2	17	0.00032641364905442
2	9	0.0299174557323546
2	15	0.0800061283400149
2	1	0
2	11	0.240510630235604
2	3	0.00822994609796011
2	2	
2	14	0.105339623544872
2	12	0.12726702023818
2	13	0.000373872263613353
2	4	0.0410682910729164
2	5	0.0131225966519861
14	6	0.445916827341486
14	16	0.0162958377668438
14	8	0.000181850935388573
14	7	0.0808960863544023
14	10	0.178045197369177
14	17	0.000254056004696402
14	9	0.0824018977619916
14	15	0.000103422350573378
14	1	0.0347740205306059
14	11	0.0871169282537818
14	3	0.0227733355690368
14	2	0.105339623544872
14	14	
14	12	0.160521747240925
14	13	0.0665137671710561
14	4	0.0610959582188948
14	5	0.0643102165041597
12	6	0.00021496275860474
12	16	0.0128090963491453
12	8	0.00111499379001191
12	7	0.0800729904634569
12	10	0.133927473951889
12	17	0.000239127722257128
12	9	0.0620074588538203
12	15	0.312652375362436
12	1	0
12	11	0.116560742264876
12	3	0.0217146647925631
12	2	0.12726702023818
12	14	0.160521747240925
12	12	
12	13	0.031358599031174
12	4	0.0874495560816564
12	5	0.00958269101260188
13	6	0.0474952122166407
13	16	0.175871877318237
13	8	0.132950217434076
13	7	0.000248057163264099
13	10	0.000578836205894611
13	17	0.0622626254218746
13	9	0.039773620910055
13	15	8.02386665935648e-05
13	1	0
13	11	0.0483549322944366
13	3	0.0400953419068592
13	2	0.000373872263613353
13	14	0.0665137671710561
13	12	0.031358599031174
13	13	
13	4	0.124418827043086
13	5	0.197300937564196
4	6	6.955930596583e-05
4	16	0.145730003788559
4	8	0.110114724673582
4	7	0.0642577670093828
4	10	0.0639267068934601
4	17	0
4	9	0.145041410623349
4	15	0.000413419874225922
4	1	0
4	11	0.0858105268395508
4	3	0.0959337607838169
4	2	0.0410682910729164
4	14	0.0610959582188948
4	12	0.0874495560816564
4	13	0.124418827043086
4	4	
4	5	0.0546948262421412
5	6	0.0385175455029631
5	16	0.207004113189641
5	8	0.108652603499649
5	7	0.0574061744430433
5	10	0.0541329670152271
5	17	0
5	9	0.0355880881895053
5	15	2.3864117553053e-05
5	1	0.123006408529428
5	11	0.0724894267359736
5	3	0.0402751520218399
5	2	0.0131225966519861
5	14	0.0643102165041597
5	12	0.00958269101260188
5	13	0.197300937564196
5	4	0.0546948262421412
5	5	
6	the wn::similarity package to compute the jiang&conrath distance as in . 
16	the system performance reported in ), which is among the best we are aware of, is also included for comparison. 
8	our approach is in line with many other researches ). 
7	second, we can use one of the wordnet similarities indicated with d ) and different relation between words such as the lexical entailment between verbs and derivationally relation between words . 
10	table 1: experimental results lexical similarity siml as defined in . 
17	pr systems that can be broadly categorized as ir-based include . 
9	a first class of methods defines measures of the distance or similarity between t and h either assuming the independence between words in a bag-of-word fashion or exploiting syntactic interpretations . 
15	it has already been applied in this way by corley & mihalcea and wu . 
1	﻿ ) applied or utilized lexical based word overlap measures. 
11	in line with many other researches ), we determine these anchors using different similarity or relatedness dectors: the exact matching between tokens or lemmas, a similarity between tokens based on their edit distance, the derivationally related form relation and the verb entailment relation in wordnet, and, finally, a wordnet-based similarity . 
3	in line with , we define it as: s1 = summationdisplay ∈a simw ×idf summationdisplay wh∈wh idf where idf is the inverse document frequency of the word w. 
2	also, we will try different similarity score functions for both the clustering and the anchor approaches, as those surveyed in corley and mihalcea . 
14	we also used the following resources: the charniak parser to carry out the syntactic analysis; the wn::similaritypackage to compute the jiang-conrath distance needed to implement the lexical similarity siml as defined in ; svm-lighttk to encode the basic tree kernel function, kt , in svm-light . 
12	then, we use this cross-pair similarity with more traditional intra-pair similarities ) to define a novel kernel function. 
13	first, as observed in the lexical-based distance kernel kl shows an accuracy significantly higher than the random baseline, i.e. 
4	third, the dramatic improvement observed in on the dataset “train:d1-test:t1” is given by the idf rather than the use of the j-c similarity . 
5	although these implications are uncontroversial, their automatic recognition is complex if we rely on models based on lexical distance between hypothesis and text, e.g., . 
