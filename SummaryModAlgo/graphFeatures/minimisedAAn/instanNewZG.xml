<paper>
<cited id="ZG0">
<title id=" W10-1818.xml">identifying sources of inter annotator variation evaluating two models of argument analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in future work two types of annotators are required: those with biomedical domain expertise and those with an understanding of rhetorical structure.
</prevsent>
<prevsent>given the vast and growing body of biomedical research literature being published there is need to develop automated text mining tools that will assist in filtering out the information most useful to researchers.
</prevsent>
</prevsection>
<citsent citstr=" E99-1015 ">
previous studies applying argumentative zoning (az) (teufel et al 1999) <papid> E99-1015 </papid>and zone analysis (za) (mizuta et al 2005) have shown that an analysis of the argumentative structure of text can be of use in information extraction (ie).</citsent>
<aftsection>
<nextsent>as an alternative approach, it was believed that toulmins work on informal logic and argument structure (1958/2003) could reflect the rhetorical strategies used by the authors of biomedical research articles.
</nextsent>
<nextsent>in order to compare and evaluate these approaches two models of argument were applied to the same set of biomedical research articles.
</nextsent>
<nextsent>inter-annotator agreement/disagreement between and within models was examined.
</nextsent>
<nextsent>given that human-annotated data are ultimately to be used for machine learning purposes, there is growing recognition of the need to analyze coder disagreements in order to differentiate between systematic variation and noise (e.g. reidsma and carletta 2008).<papid> J08-3001 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1">
<title id=" W10-1818.xml">identifying sources of inter annotator variation evaluating two models of argument analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in order to compare and evaluate these approaches two models of argument were applied to the same set of biomedical research articles.
</prevsent>
<prevsent>inter-annotator agreement/disagreement between and within models was examined.
</prevsent>
</prevsection>
<citsent citstr=" J08-3001 ">
given that human-annotated data are ultimately to be used for machine learning purposes, there is growing recognition of the need to analyze coder disagreements in order to differentiate between systematic variation and noise (e.g. reidsma and carletta 2008).<papid> J08-3001 </papid></citsent>
<aftsection>
<nextsent>the goal of this study was to identify systematic disagreements as diagnostics for improving the models of argument.
</nextsent>
<nextsent>the two models of rhetoric (argument) in tables 1 and 2 were applied to corpus of 12 articles downloaded at random from the bmc-series (biomed central) of journals.
</nextsent>
<nextsent>the corpus covered nine different domains, with total of 400 sentences; the three annotators worked independently.
</nextsent>
<nextsent>although the entire articles were read by the annotators, only the sentences in the discussion section were argumentatively categorized.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2">
<title id=" W10-1604.xml">using common sense to generate culturally contextual ized machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>mt is one of the oldest and most important areas of natural language processing (nlp) /computational linguistics (cl).2 from its beginnings we have witnessed some changes in the proposed mt paradigms ranging from the basic level in which mt is performed by just replacing words in source language by words in target language?
</prevsent>
<prevsent>to more sophisticated ones which relyon manually created translation rules (rule-based machine translation) or automatically generated statistical models (statistical machine translation, smt).
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
nowadays, the majority of the researches has being centered around the phrase-based statistical mt (pb-smt) approach such as (koehn et al., 2003) <papid> N03-1017 </papid>and (och and ney, 2004).<papid> J04-4002 </papid></citsent>
<aftsection>
<nextsent>pb-smt is considered the state-of-the-art according to the automatic evaluation measures bleu (papineni et al., 2002) <papid> P02-1040 </papid>and nist (doddington, 2002)3.</nextsent>
<nextsent>although pb-smt models have achieved the state-of-the-art translation quality, there are strong evidences that these models will not be able to go further without more linguistically motivated features, as stated by tinsley and way (2009).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3">
<title id=" W10-1604.xml">using common sense to generate culturally contextual ized machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>mt is one of the oldest and most important areas of natural language processing (nlp) /computational linguistics (cl).2 from its beginnings we have witnessed some changes in the proposed mt paradigms ranging from the basic level in which mt is performed by just replacing words in source language by words in target language?
</prevsent>
<prevsent>to more sophisticated ones which relyon manually created translation rules (rule-based machine translation) or automatically generated statistical models (statistical machine translation, smt).
</prevsent>
</prevsection>
<citsent citstr=" J04-4002 ">
nowadays, the majority of the researches has being centered around the phrase-based statistical mt (pb-smt) approach such as (koehn et al., 2003) <papid> N03-1017 </papid>and (och and ney, 2004).<papid> J04-4002 </papid></citsent>
<aftsection>
<nextsent>pb-smt is considered the state-of-the-art according to the automatic evaluation measures bleu (papineni et al., 2002) <papid> P02-1040 </papid>and nist (doddington, 2002)3.</nextsent>
<nextsent>although pb-smt models have achieved the state-of-the-art translation quality, there are strong evidences that these models will not be able to go further without more linguistically motivated features, as stated by tinsley and way (2009).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4">
<title id=" W10-1604.xml">using common sense to generate culturally contextual ized machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>to more sophisticated ones which relyon manually created translation rules (rule-based machine translation) or automatically generated statistical models (statistical machine translation, smt).
</prevsent>
<prevsent>nowadays, the majority of the researches has being centered around the phrase-based statistical mt (pb-smt) approach such as (koehn et al., 2003) <papid> N03-1017 </papid>and (och and ney, 2004).<papid> J04-4002 </papid></prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
pb-smt is considered the state-of-the-art according to the automatic evaluation measures bleu (papineni et al., 2002) <papid> P02-1040 </papid>and nist (doddington, 2002)3.</citsent>
<aftsection>
<nextsent>although pb-smt models have achieved the state-of-the-art translation quality, there are strong evidences that these models will not be able to go further without more linguistically motivated features, as stated by tinsley and way (2009).
</nextsent>
<nextsent>this is already being illustrated by the recent shift of researches towards linguistically enriched models as (koehn and hoang, 2007) <papid> D07-1091 </papid>and (tinsley and way, 2009) among others.</nextsent>
<nextsent>following the same idea of these most recent researches, here we are also interested in seeing 2in this paper we will use the terms nlp and cl interchangeably since this is the assumption adopted in brazil.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG5">
<title id=" W10-1604.xml">using common sense to generate culturally contextual ized machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>pb-smt is considered the state-of-the-art according to the automatic evaluation measures bleu (papineni et al., 2002) <papid> P02-1040 </papid>and nist (doddington, 2002)3.</prevsent>
<prevsent>although pb-smt models have achieved the state-of-the-art translation quality, there are strong evidences that these models will not be able to go further without more linguistically motivated features, as stated by tinsley and way (2009).</prevsent>
</prevsection>
<citsent citstr=" D07-1091 ">
this is already being illustrated by the recent shift of researches towards linguistically enriched models as (koehn and hoang, 2007) <papid> D07-1091 </papid>and (tinsley and way, 2009) among others.</citsent>
<aftsection>
<nextsent>following the same idea of these most recent researches, here we are also interested in seeing 2in this paper we will use the terms nlp and cl interchangeably since this is the assumption adopted in brazil.
</nextsent>
<nextsent>3bleu and nist are two automatic measures widely applied to evaluate the target mt output sentence regarding one our more reference sentences.
</nextsent>
<nextsent>24 how it is possible to improve mt performance based on more linguistically motivated features.
</nextsent>
<nextsent>in our case, we intend to investigate how to apply common sense knowledge to generate more culturally contextual ized automatic translations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG6">
<title id=" W10-1604.xml">using common sense to generate culturally contextual ized machine translation </title>
<section> machine translation.  </section>
<citcontext>
<prevsection>
<prevsent>5sentence extracted from cambridge advanced learners dictionary: http://dictionary.cambridge.org/ define.aspkey=13018&dict;=cald.
</prevsent>
<prevsent>systran6 and apertium7) but the statistical approach is now being widely applied at least in part (e.g., google8) (cancedda et al, 2009).
</prevsent>
</prevsection>
<citsent citstr=" J90-2002 ">
the smt was born in the late 1980s as an effort of researchers from ibm (brown et al, 1990).<papid> J90-2002 </papid></citsent>
<aftsection>
<nextsent>in those days, smt was performed based on two models: word-based translation model and language model.
</nextsent>
<nextsent>while the first model is concerned with the production of target equivalent versions of the source sentences, the second one guarantees that the output sentence is possible one (it is grammatical and fluent) in the target language.
</nextsent>
<nextsent>in the current pb smt systems, the word-based models were replaced by the phrase-based ones built based on sequences of words (the phrases).9 the translation and language models used in smt are built from training parallel corpora (a set of source sentences and their translations into the target language) by means of ibm models (brown et al, 1993) <papid> J93-2003 </papid>which calculate the probability of given source word (or sequences of words) be translated to target word (or sequence of words).</nextsent>
<nextsent>the availability of some open-source tool kits (such as moses (koehn et al, 2007)<papid> P07-2045 </papid>10) to train, test and evaluate smt models has helping the widely employment of this mt approach to perhaps almost any language pair and corpus type.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG7">
<title id=" W10-1604.xml">using common sense to generate culturally contextual ized machine translation </title>
<section> machine translation.  </section>
<citcontext>
<prevsection>
<prevsent>in those days, smt was performed based on two models: word-based translation model and language model.
</prevsent>
<prevsent>while the first model is concerned with the production of target equivalent versions of the source sentences, the second one guarantees that the output sentence is possible one (it is grammatical and fluent) in the target language.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
in the current pb smt systems, the word-based models were replaced by the phrase-based ones built based on sequences of words (the phrases).9 the translation and language models used in smt are built from training parallel corpora (a set of source sentences and their translations into the target language) by means of ibm models (brown et al, 1993) <papid> J93-2003 </papid>which calculate the probability of given source word (or sequences of words) be translated to target word (or sequence of words).</citsent>
<aftsection>
<nextsent>the availability of some open-source tool kits (such as moses (koehn et al, 2007)<papid> P07-2045 </papid>10) to train, test and evaluate smt models has helping the widely employment of this mt approach to perhaps almost any language pair and corpus type.</nextsent>
<nextsent>in fact, smt is an inexpensive, easy and language independent way for detecting recurrent phrases that form the language and translation models.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG8">
<title id=" W10-1604.xml">using common sense to generate culturally contextual ized machine translation </title>
<section> machine translation.  </section>
<citcontext>
<prevsection>
<prevsent>while the first model is concerned with the production of target equivalent versions of the source sentences, the second one guarantees that the output sentence is possible one (it is grammatical and fluent) in the target language.
</prevsent>
<prevsent>in the current pb smt systems, the word-based models were replaced by the phrase-based ones built based on sequences of words (the phrases).9 the translation and language models used in smt are built from training parallel corpora (a set of source sentences and their translations into the target language) by means of ibm models (brown et al, 1993) <papid> J93-2003 </papid>which calculate the probability of given source word (or sequences of words) be translated to target word (or sequence of words).</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
the availability of some open-source tool kits (such as moses (koehn et al, 2007)<papid> P07-2045 </papid>10) to train, test and evaluate smt models has helping the widely employment of this mt approach to perhaps almost any language pair and corpus type.</citsent>
<aftsection>
<nextsent>in fact, smt is an inexpensive, easy and language independent way for detecting recurrent phrases that form the language and translation models.
</nextsent>
<nextsent>however, while pb-smt models have achieved the state-of-the-art translation quality, its performance seams to be stagnated.
</nextsent>
<nextsent>consequently, there is recent common trend towards enriching the current models with some extra knowledge as the new approaches of factored translation models (koehnand hoang, 2007) <papid> D07-1091 </papid>or syntax-based (or syntax augmented) mt systems (tiedemann and kotze?, 2009; tinsley and way, 2009; zollmann et al, 2008).<papid> C08-1144 </papid></nextsent>
<nextsent>more related to our work are the proposals of musa et al (2003) and chung et al (2005).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG10">
<title id=" W10-1604.xml">using common sense to generate culturally contextual ized machine translation </title>
<section> machine translation.  </section>
<citcontext>
<prevsection>
<prevsent>in fact, smt is an inexpensive, easy and language independent way for detecting recurrent phrases that form the language and translation models.
</prevsent>
<prevsent>however, while pb-smt models have achieved the state-of-the-art translation quality, its performance seams to be stagnated.
</prevsent>
</prevsection>
<citsent citstr=" C08-1144 ">
consequently, there is recent common trend towards enriching the current models with some extra knowledge as the new approaches of factored translation models (koehnand hoang, 2007) <papid> D07-1091 </papid>or syntax-based (or syntax augmented) mt systems (tiedemann and kotze?, 2009; tinsley and way, 2009; zollmann et al, 2008).<papid> C08-1144 </papid></citsent>
<aftsection>
<nextsent>more related to our work are the proposals of musa et al (2003) and chung et al (2005).
</nextsent>
<nextsent>both 6http://www.systransoft.com/ 7http://www.apertium.org/ 8http://www.google.com/language_tools 9in smt, phrase is sequence of two or more words even though they do not form syntactic phrase.
</nextsent>
<nextsent>10http://www.statmt.org/moses/ 25 of them are cs-based translation tools which take the topics of bilingual conversation guessed by topic spotting mechanism, and use them to generate phrases that can be chosen by the end-user to follow the conversation.
</nextsent>
<nextsent>since they are interactive tools, the phrases are first displayed on the screen in the end-users native language and, then, he/she selects phrase to be translated (by text-to-speech engine) in the language in which the conversation is taking place.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG11">
<title id=" W10-1604.xml">using common sense to generate culturally contextual ized machine translation </title>
<section> common sense.  </section>
<citcontext>
<prevsection>
<prevsent>by the relation usedfor and the books translation to portuguese, livro?, is also linked with the translation of learn (aprender?)
</prevsent>
<prevsent>by relation of the same type.
</prevsent>
</prevsection>
<citsent citstr=" H05-2005 ">
different from other researches using semantic networks, such as mindnet16 (vanderwende et al., 2005), <papid> H05-2005 </papid>wordnet17 (fellbaum, 1998) and framenet18 (baker et al, 1998), <papid> P98-1013 </papid>here we propose the application of source and target concept nets together in the same application.</citsent>
<aftsection>
<nextsent>16http://research.microsoft.com/en-us/ projects/mindnet/ 17http://wordnet.princeton.edu/ 18http://framenet.icsi.berkeley.edu/
</nextsent>
<nextsent>translation as presented in the previous sections, the main goal of our research is to investigate how cs knowledge can help mt systems to generate more culturally contextual ized translations.
</nextsent>
<nextsent>to do so, we are working with two concept nets derived from omcs and omcs-br projects, that represent the cs knowledge in english and brazilian portuguese, respectively, as presented in section 3.
</nextsent>
<nextsent>in this context, we intend to investigate the application of cs knowledge in the mt process in three different moments: 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG12">
<title id=" W10-1604.xml">using common sense to generate culturally contextual ized machine translation </title>
<section> common sense.  </section>
<citcontext>
<prevsection>
<prevsent>by the relation usedfor and the books translation to portuguese, livro?, is also linked with the translation of learn (aprender?)
</prevsent>
<prevsent>by relation of the same type.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
different from other researches using semantic networks, such as mindnet16 (vanderwende et al., 2005), <papid> H05-2005 </papid>wordnet17 (fellbaum, 1998) and framenet18 (baker et al, 1998), <papid> P98-1013 </papid>here we propose the application of source and target concept nets together in the same application.</citsent>
<aftsection>
<nextsent>16http://research.microsoft.com/en-us/ projects/mindnet/ 17http://wordnet.princeton.edu/ 18http://framenet.icsi.berkeley.edu/
</nextsent>
<nextsent>translation as presented in the previous sections, the main goal of our research is to investigate how cs knowledge can help mt systems to generate more culturally contextual ized translations.
</nextsent>
<nextsent>to do so, we are working with two concept nets derived from omcs and omcs-br projects, that represent the cs knowledge in english and brazilian portuguese, respectively, as presented in section 3.
</nextsent>
<nextsent>in this context, we intend to investigate the application of cs knowledge in the mt process in three different moments: 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG13">
<title id=" W10-1604.xml">using common sense to generate culturally contextual ized machine translation </title>
<section> culturally contextual ized machine.  </section>
<citcontext>
<prevsection>
<prevsent>conceptnets.
</prevsent>
<prevsent>the first ongoing undergraduate research (barchi et al, 2009) aims at aligning the parallel concepts found in brazilian and english conceptnets.
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
this alignment can be performed, for example, based on lexical alignments automatically generated by giza++21 (och and ney, 2000) <papid> P00-1056 </papid>or the hierarchical structure of the nodes and arcs in the conceptnets.</citsent>
<aftsection>
<nextsent>the second ongoing undergraduate research (meuchi et al, 2009), in turn, is involved with the enrichment of one concept net based on the relations found in the other (parallel) concept net and also in lexically aligned parallel texts.
</nextsent>
<nextsent>the work described in this paper presents the first steps towards applying semantic knowledge to generate more culturally contextual ized translations between brazilian portuguese and english texts.
</nextsent>
<nextsent>in this sense, we see some opportunities for collaboration regarding the roles that are played by: (1) our research work, (2) the semantic resources available to be used and (3) the resources and results that will be produced by our work.
</nextsent>
<nextsent>first of all, this work is joint effort of two research areas: nlp/cl (machine translation) and human-computer interaction (hci) (common sense knowledge gathering and usage).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG14">
<title id=" W10-3006.xml">memory based resolution of in sentence scopes of hedge cues </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>he proposes pragmatic classification of hedge expressions based on an exhaustive analysis of corpus.
</prevsent>
<prevsent>the catalogue of hedging cues includes modal auxiliaries, epis temic lexical verbs, epistemic adjectives, adverbs, nouns, and variety of non lexical cues.
</prevsent>
</prevsection>
<citsent citstr=" W04-3103 ">
lightet al (2004) <papid> W04-3103 </papid>analyse the use of speculative language in medline abstracts.</citsent>
<aftsection>
<nextsent>some nlp applications incorporate modality information (fried manet al, 1994; dimarco and mercer, 2005).
</nextsent>
<nextsent>as for annotated corpora, thompson et al (2008) report on list of words and phrases that express modality in biomedical texts and put forward categorisation scheme.
</nextsent>
<nextsent>additionally, the bioscopecorpus (vincze et al, 2008) consists of collection of clinical free-texts, biological full papers, and biological abstracts annotated with negation and speculation cues and their scope.although only few pieces of research have focused on processing negation, the two tasks of the conll-2010 shared task have been addressed previously.
</nextsent>
<nextsent>as for task 1, medlock and briscoe (2007) <papid> P07-1125 </papid>provide definition of what they consider to be hedge instances and define hedge classification as weakly supervised machine learning task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG15">
<title id=" W10-3006.xml">memory based resolution of in sentence scopes of hedge cues </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>as for annotated corpora, thompson et al (2008) report on list of words and phrases that express modality in biomedical texts and put forward categorisation scheme.
</prevsent>
<prevsent>additionally, the bioscopecorpus (vincze et al, 2008) consists of collection of clinical free-texts, biological full papers, and biological abstracts annotated with negation and speculation cues and their scope.although only few pieces of research have focused on processing negation, the two tasks of the conll-2010 shared task have been addressed previously.
</prevsent>
</prevsection>
<citsent citstr=" P07-1125 ">
as for task 1, medlock and briscoe (2007) <papid> P07-1125 </papid>provide definition of what they consider to be hedge instances and define hedge classification as weakly supervised machine learning task.</citsent>
<aftsection>
<nextsent>the method they use to derive learning model from seed corpus is based on iteratively predicting labels for unlabeled training samples.
</nextsent>
<nextsent>they report experiments with svms on dataset that they make publicly available3.
</nextsent>
<nextsent>the experiments achieve recall/precision break even point(bep) of 0.76.
</nextsent>
<nextsent>they apply bag-of-words approach to sample representation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG19">
<title id=" W10-3006.xml">memory based resolution of in sentence scopes of hedge cues </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>szarvas (2008) follows medlock and briscoe (2007) <papid> P07-1125 </papid>in classifying sentences as being speculative or non-speculative.szarvas develops maxent system that incorporates bigrams and trigrams in the feature representation and performs complex feature selection procedure in order to reduce the number of keyword candidates.</prevsent>
<prevsent>it achieves up to 0.85bep and 85.08 f1 by using an external dictionary.</prevsent>
</prevsection>
<citsent citstr=" W08-0607 ">
kilicoglu and bergler (2008) <papid> W08-0607 </papid>apply linguistically motivated approach to the same classification task by using knowledge from existing lexical resources and incorporating syntactic pat terns.</citsent>
<aftsection>
<nextsent>additionally, hedge cues are weighted by automatically assigning an information gain measure and by assigning weights semi automatically depending on their types and centrality to hedging.
</nextsent>
<nextsent>the system achieves results of 0.85 bep.
</nextsent>
<nextsent>as for task 2, previous work (morante and daelemans, 2009; <papid> W09-1304 </papid>ozgur and radev, 2009) has focused on finding the scope of hedge cues in the bio scope corpus (vincze et al, 2008).</nextsent>
<nextsent>both systems approach the task in two steps, identifying the hedge cues and finding their scope.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG20">
<title id=" W10-3006.xml">memory based resolution of in sentence scopes of hedge cues </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>additionally, hedge cues are weighted by automatically assigning an information gain measure and by assigning weights semi automatically depending on their types and centrality to hedging.
</prevsent>
<prevsent>the system achieves results of 0.85 bep.
</prevsent>
</prevsection>
<citsent citstr=" W09-1304 ">
as for task 2, previous work (morante and daelemans, 2009; <papid> W09-1304 </papid>ozgur and radev, 2009) has focused on finding the scope of hedge cues in the bio scope corpus (vincze et al, 2008).</citsent>
<aftsection>
<nextsent>both systems approach the task in two steps, identifying the hedge cues and finding their scope.
</nextsent>
<nextsent>the main difference between the two systems is that morante and daelemans (2009) <papid> W09-1304 </papid>perform the second phase with machine learner, whereas ozgur and radev (2009) perform the second phase witha rule-based system that exploits syntactic infor mation.</nextsent>
<nextsent>the approach to resolving the scopes of hedge cues that we present in this paper is similar to the approach followed in morante and daelemans (2009) <papid> W09-1304 </papid>in that the task is modelled in the same way.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG37">
<title id=" W10-3006.xml">memory based resolution of in sentence scopes of hedge cues </title>
<section> preprocessing.  </section>
<citcontext>
<prevsection>
<prevsent>a third difference is that that system did not use lexicon of cues, whereas this system uses lexicon generated from the training data.
</prevsent>
<prevsent>as first step, we pre process the data in order to extract features for the machine learners.
</prevsent>
</prevsection>
<citsent citstr=" W06-2920 ">
we convert the xml files into token-per-token representation, following the standard conll format (buchholz and marsi, 2006), <papid> W06-2920 </papid>where sentences are separated by blank line and fields are separated by single tab character.</citsent>
<aftsection>
<nextsent>a sentence consists of sequence of tokens, each one starting on new line.
</nextsent>
<nextsent>the wiki data are processed with the memory based shallow parser (mbsp) (daelemans and vanden bosch, 2005) in order to obtain lemmas, part-of-speech (pos) tags, and syntactic chunks, and with the malt parser (nivre, 2006) in order to obtain dependency trees.
</nextsent>
<nextsent>the bio data are processed with the gdep parser (sagae and tsujii, 2007) <papid> D07-1111 </papid>in order to get the same information.</nextsent>
<nextsent># word lemma pos chunk ne label s 1 the the dt b-np 3 nmod o o. 2 structural structural jj i-np 3 nmod o 3 evidence evidence nn i-np 4 sub o 4 lends lend vbz b-vp 0 root f 5 strong strong jj b-np 6 nmod o 6 support support nn i-np 4 obj o 7 to to to b-pp 6 nmod o 8 the the dt b-np 11 nmod o 9 inferred inferred jj i-np 11 nmod o 10 domain domain nn i-np 11 nmod o 11 pair pair nn i-np 7 pmod l 12 , , , o 4 o o 13 resulting result vbg b-vp 4 vmod o 14 in in in b-pp 13 vmod o 15 a dt b-np 18 nmod o 16 high high jj i-np 18 nmod o 17 confidence confidence nn i-np 18 nmod o 18 set set nn i-np 14 pmod o 19 of of in b-pp 18 nmod o 20 domain domain nn b-np 21 nmod o 21 pairs pair nns i-np 19 pmod o 22 . . .</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG38">
<title id=" W10-3006.xml">memory based resolution of in sentence scopes of hedge cues </title>
<section> preprocessing.  </section>
<citcontext>
<prevsection>
<prevsent>a sentence consists of sequence of tokens, each one starting on new line.
</prevsent>
<prevsent>the wiki data are processed with the memory based shallow parser (mbsp) (daelemans and vanden bosch, 2005) in order to obtain lemmas, part-of-speech (pos) tags, and syntactic chunks, and with the malt parser (nivre, 2006) in order to obtain dependency trees.
</prevsent>
</prevsection>
<citsent citstr=" D07-1111 ">
the bio data are processed with the gdep parser (sagae and tsujii, 2007) <papid> D07-1111 </papid>in order to get the same information.</citsent>
<aftsection>
<nextsent># word lemma pos chunk ne label s 1 the the dt b-np 3 nmod o o. 2 structural structural jj i-np 3 nmod o 3 evidence evidence nn i-np 4 sub o 4 lends lend vbz b-vp 0 root f 5 strong strong jj b-np 6 nmod o 6 support support nn i-np 4 obj o 7 to to to b-pp 6 nmod o 8 the the dt b-np 11 nmod o 9 inferred inferred jj i-np 11 nmod o 10 domain domain nn i-np 11 nmod o 11 pair pair nn i-np 7 pmod l 12 , , , o 4 o o 13 resulting result vbg b-vp 4 vmod o 14 in in in b-pp 13 vmod o 15 a dt b-np 18 nmod o 16 high high jj i-np 18 nmod o 17 confidence confidence nn i-np 18 nmod o 18 set set nn i-np 14 pmod o 19 of of in b-pp 18 nmod o 20 domain domain nn b-np 21 nmod o 21 pairs pair nns i-np 19 pmod o 22 . . .
</nextsent>
<nextsent>o 4 o o table 1: preprocessed sentence.
</nextsent>
<nextsent>table 1 shows preprocessed sentence with the following information per token: the token number in the sentence, word, lemma, pos tag, chunk tag, named entity tag, head of token in the dependency tree, dependency label, cue tag, and scope tags separated by space, for as many cues as there are in the sentence.
</nextsent>
<nextsent>in order to check whether the conversion from the xml format to the conll format is source of error propagation, we convert the gold conll files into xml format and we run the scorer provided by the task organisers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG49">
<title id=" W10-1711.xml">the rwth aachen machine translation system for wmt 2010 </title>
<section> translation systems.  </section>
<citcontext>
<prevsection>
<prevsent>our phrase-based translation system is similar to the one described in (zens and ney, 2008).
</prevsent>
<prevsent>phrase pairs are extracted from word-aligned bilingual corpus and their translation probability in both directions is estimated by relative frequencies.
</prevsent>
</prevsection>
<citsent citstr=" W06-3108 ">
additional models include standard n-gram language model, phrase-level ibm1, word-, phrase and distortion-penalties and discriminative reordering model as described in (zens and ney, 2006).<papid> W06-3108 </papid></citsent>
<aftsection>
<nextsent>2.2 hierarchical system.
</nextsent>
<nextsent>our hierarchical phrase-based system is similar to the one described in (chiang, 2007).<papid> J07-2003 </papid></nextsent>
<nextsent>it allows for gaps in the phrases by employing context-freegrammar and cyk-like parsing during the decoding step.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG50">
<title id=" W10-1711.xml">the rwth aachen machine translation system for wmt 2010 </title>
<section> translation systems.  </section>
<citcontext>
<prevsection>
<prevsent>additional models include standard n-gram language model, phrase-level ibm1, word-, phrase and distortion-penalties and discriminative reordering model as described in (zens and ney, 2006).<papid> W06-3108 </papid></prevsent>
<prevsent>2.2 hierarchical system.</prevsent>
</prevsection>
<citsent citstr=" J07-2003 ">
our hierarchical phrase-based system is similar to the one described in (chiang, 2007).<papid> J07-2003 </papid></citsent>
<aftsection>
<nextsent>it allows for gaps in the phrases by employing context-freegrammar and cyk-like parsing during the decoding step.
</nextsent>
<nextsent>it has similar features as the phrase based system mentioned above.
</nextsent>
<nextsent>for some systems, we only allowed the non-terminals in hierarchical phrases to be substituted with initial phra sesas in (iglesias et al, 2009), <papid> E09-1044 </papid>which gave better results on some language pairs.</nextsent>
<nextsent>we will refer to this as shallow rules?.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG51">
<title id=" W10-1711.xml">the rwth aachen machine translation system for wmt 2010 </title>
<section> translation systems.  </section>
<citcontext>
<prevsection>
<prevsent>it allows for gaps in the phrases by employing context-freegrammar and cyk-like parsing during the decoding step.
</prevsent>
<prevsent>it has similar features as the phrase based system mentioned above.
</prevsent>
</prevsection>
<citsent citstr=" E09-1044 ">
for some systems, we only allowed the non-terminals in hierarchical phrases to be substituted with initial phra sesas in (iglesias et al, 2009), <papid> E09-1044 </papid>which gave better results on some language pairs.</citsent>
<aftsection>
<nextsent>we will refer to this as shallow rules?.
</nextsent>
<nextsent>2.3 system combination.
</nextsent>
<nextsent>the rwth approach to mt system combination of the french english systems as well as the german english systems is refined version of the rover approach in asr (fiscus, 1997) with 93 german english french english english french bleu # phrases bleu # phrases bleu # phrases standard 19.7 128m 25.5 225m 23.7 261m fa 20.0 12m 25.9 35m 24.0 33m table 1: bleu scores on test and phrase table sizes with and without forced alignment (fa).
</nextsent>
<nextsent>for german english and english french phrase table interpolation was applied.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG52">
<title id=" W10-1711.xml">the rwth aachen machine translation system for wmt 2010 </title>
<section> translation systems.  </section>
<citcontext>
<prevsection>
<prevsent>for german english and english french phrase table interpolation was applied.
</prevsent>
<prevsent>additional steps to cope with reordering between different hypotheses, and to use true casing information from the input hypotheses.
</prevsent>
</prevsection>
<citsent citstr=" E06-1005 ">
the basic concept of the approach has been described by matusov et al (2006).<papid> E06-1005 </papid></citsent>
<aftsection>
<nextsent>several improvements have been added later (matusov et al, 2008).
</nextsent>
<nextsent>this approach includes an enhanced alignment and reordering framework.
</nextsent>
<nextsent>alignments between the systems are learned by giza++, one-to-one alignment is generated from the learned state occupation probabilities.
</nextsent>
<nextsent>from these alignments, confusion network (cn) is then built using one of the hypotheses as skeleton?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG53">
<title id=" W10-1711.xml">the rwth aachen machine translation system for wmt 2010 </title>
<section> new additional models.  </section>
<citcontext>
<prevsection>
<prevsent>in previous experiments,this showed to work significantly better than using fixed non-consensus true caser, and maintains flexibility on the input systems.
</prevsent>
<prevsent>3.1 forced alignment.
</prevsent>
</prevsection>
<citsent citstr=" W06-3105 ">
for the german english, french english and english french language tasks we applied forced alignment procedure to train the phrase translation model with the em algorithm, similar to the one described in (denero et al,2006).<papid> W06-3105 </papid></citsent>
<aftsection>
<nextsent>here, the phrase translation probabilities are estimated from their relative frequencies in the phrase-aligned training data.
</nextsent>
<nextsent>the phrase alignment is produced by modified version of the translation decoder.
</nextsent>
<nextsent>in addition to providing statistically well-foundedphrase model, this has the benefit of producing smaller phrase tables and thus allowing more rapid experiments.
</nextsent>
<nextsent>for the language pairs german english and english french the best results were achieved by log-linear interpolation of the standard phrase table with the generative model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG54">
<title id=" W10-1711.xml">the rwth aachen machine translation system for wmt 2010 </title>
<section> new additional models.  </section>
<citcontext>
<prevsection>
<prevsent>3.2 extended lexicon models.
</prevsent>
<prevsent>in previous work, rwth was able to show the positive impact of extended lexicon models that cope with lexical context beyond the limited horizon of phrase pairs and n-gram language models.
</prevsent>
</prevsection>
<citsent citstr=" D09-1022 ">
mauser et al (2009) <papid> D09-1022 </papid>report improvements of up to +1% in bleu on large-scale systems forchineseenglish and arabic english by incorporating discriminative and trigger-based lexicon models into state-of-the-art phrase-based de coder.</citsent>
<aftsection>
<nextsent>they discuss how the two types of lexicon 94 models help to select content words by capturing long-distance effects.
</nextsent>
<nextsent>the triplet model is straightforward extension of the ibm model 1 with second trigger, and likethe former is trained iteratively using the em algorithm.
</nextsent>
<nextsent>in search, the triggers are usually on the source side, i.e., p(e|f, ?) is modeled.
</nextsent>
<nextsent>the path constrained triplet model restricts the first source trigger to the aligned target word, whereas the second trigger can move along the whole source sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG55">
<title id=" W10-1711.xml">the rwth aachen machine translation system for wmt 2010 </title>
<section> new additional models.  </section>
<citcontext>
<prevsection>
<prevsent>in search, the triggers are usually on the source side, i.e., p(e|f, ?) is modeled.
</prevsent>
<prevsent>the path constrained triplet model restricts the first source trigger to the aligned target word, whereas the second trigger can move along the whole source sentence.
</prevsent>
</prevsection>
<citsent citstr=" D08-1039 ">
see (hasan et al, 2008) <papid> D08-1039 </papid>for detailed description and variants of the model and its training.for the wmt 2010 evaluation, triplets modeling p(e|f, ?) were trained and applied directly in search for all relevant language pairs.path-constrained models were trained on the in domain news-commentary data only and on thenews-commentary plus the europarl data.</citsent>
<aftsection>
<nextsent>although experience from similar setups indicates that triplet lexicon models can be beneficial for machine translation between the languages english, french, and german, on this years wmttranslation tasks slight improvements on the development sets did not or only partially carry over to the held-out test sets.
</nextsent>
<nextsent>nevertheless, systems with triplets were used for system combination, as extended lexicon models often help to predict content words and to capture long-range dependencies.
</nextsent>
<nextsent>thus they can help to find strong consensus hypothesis.
</nextsent>
<nextsent>3.3 unsupervised training.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG56">
<title id=" W10-1711.xml">the rwth aachen machine translation system for wmt 2010 </title>
<section> preprocessing.  </section>
<citcontext>
<prevsection>
<prevsent>german, as flexible and morphologically rich language, raises couple of problems in machine translation.
</prevsent>
<prevsent>we picked two major problems and tackled them with morpho-syntactic pre- and post processing: compound splitting and long-range verb reordering.
</prevsent>
</prevsection>
<citsent citstr=" E03-1076 ">
for the translation from german into english, german compound words were split using the frequency-based method described in (koehn and knight, 2003).<papid> E03-1076 </papid></citsent>
<aftsection>
<nextsent>thereby, we forbid certain word sand syllables to be split.
</nextsent>
<nextsent>for the other translation direction, the english text was first translated into the modified german language with split compounds.
</nextsent>
<nextsent>the generated output was thenpostprocessed by re-merging the previously generated components using the method described in (popovic?
</nextsent>
<nextsent>et al, 2006).additionally, for the german english phrase based system, the long-range pos-based reordering rules described in (popovic?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG57">
<title id=" W10-1716.xml">lium smt machine translation system for wmt 2010 </title>
<section> resources used.  </section>
<citcontext>
<prevsection>
<prevsent>although we could have used part of the menu items as dictionary, for simplicity we applied an n-gram language model(lm) filter to remove all non-grammatical sentences.
</prevsent>
<prevsent>thanks to this filter, sentences out of the language model domain (in this case, mainly thenews domain), may also have been discarded be cause they contain many unknown or un frequent n-grams.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
the lexical filter was based on the ibm model 1 cost (brown et al, 1993) <papid> J93-2003 </papid>of each side of sentence pair given the other side, normalised with respect to both sentence lengths.</citsent>
<aftsection>
<nextsent>this filter 121 was trained on corpus composed of eparl, nc, and un data.
</nextsent>
<nextsent>the language model filter was ann-gram lm cost of the target sentence (see section 3), normalised with respect to its length.
</nextsent>
<nextsent>this filter was trained with all monolingual resources available except the 109 data.
</nextsent>
<nextsent>we generated first subset, 1091, selecting sentence pairs with lexical cost inferior to 4 and an lm cost inferior to 2.3.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG58">
<title id=" W10-1716.xml">lium smt machine translation system for wmt 2010 </title>
<section> architecture of the smt system.  </section>
<citcontext>
<prevsection>
<prevsent>in our system fourteen features functions were used, namely phrase and lexical translation probabilities in both directions, seven features for the lexicalized distortion model, word and phrase penalty and target language model (lm).
</prevsent>
<prevsent>the system is based on the moses smt toolkit (koehn et al, 2007) and constructed as follows.first, word alignments in both directions are calculated.
</prevsent>
</prevsection>
<citsent citstr=" W08-0509 ">
we used multi-threaded version of the giza++ tool (gao and vogel, 2008).<papid> W08-0509 </papid>1 this speeds up the process and corrects an error of giza++ that can appear with rare words.</citsent>
<aftsection>
<nextsent>phrases and lexical reorderings are extracted using the default settings of the moses toolkit.the parameters of moses were tuned on news test2008, using the new?
</nextsent>
<nextsent>mert tool.
</nextsent>
<nextsent>we repeated the training process three times, each with different seed value for the optimisation algorithm.
</nextsent>
<nextsent>inthis way we have an rough idea of the error introduced by the tuning process.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG59">
<title id=" W10-1206.xml">object search supporting structured queries in web search engines </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>(fails and olsen, 2003) coined the term interactive machine learning?
</prevsent>
<prevsent>and showed that learner can take advantage of user interaction to quickly acquire necessary training data.
</prevsent>
</prevsection>
<citsent citstr=" W09-1110 ">
(roth and small, 2009) <papid> W09-1110 </papid>proposed another interactive learning protocol that improves upon relation extraction task by incremetally modifying the feature representation.finally, this work is related to document retrieval mechanisms used for question answering tasks (voorhees, 2001) where precise retrieval methods are necessary to find documents which contain specific information for answering facto ids (agichtein et al, 2001).</citsent>
<aftsection>
<nextsent>we introduces the object search framework that searches the web for documents containing real world objects.
</nextsent>
<nextsent>we formalized the problem as alearning to rank for ir problem and showed an effective method to solve it.
</nextsent>
<nextsent>our approach goes beyond the traditional bag-of-words representation and views each web page as set of domain independent features.
</nextsent>
<nextsent>this representation enabled us to rank web pages with respect to object query.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG60">
<title id=" W10-3505.xml">pruning non informative text through non expert annotations to improve aspect level sentiment classification </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>noise in training data can be derived either from noisy labeling or from noisy features.
</prevsent>
<prevsent>it has been shown that labeling quality is one of the important factors that impacts the performance of learned model, and that this quality can be improved by approaches such as using multiple label ers (sheng et al, 2008).
</prevsent>
</prevsection>
<citsent citstr=" W02-1011 ">
however, noisy features can be an inherent characteristic for some text mining tasks, and it is unclear how they should be handled.for example, sentiment analysis/opinion mining from unstructured user generated content suchas online reviews and blogs often relies on learning sentiments from word-based features extracted from the training sentences and documents (pang et al, 2002; <papid> W02-1011 </papid>dave et al, 2003; kim and hovy, 2005).</citsent>
<aftsection>
<nextsent>however, not all words in the training data carry information about sentiment.
</nextsent>
<nextsent>for example, in sentence (1), (1)i filmed my daughters ballet recital and could not believe how the autofocus kept blurring then focusing.
</nextsent>
<nextsent>although words such as autofocus, blurring and focusing are informative for learning sentiment regarding the autofocus capability of the camera, words such as film, daughter and ballet recital are not informative for that type of sentiment, and they form noise if included as training data.
</nextsent>
<nextsent>if the training data contain lot of examples such as (2) in which words such as film, daughter and ballet recital also appear, but the sentence is not labelled as invoking sentiment regarding autofocus, machine learning algorithm might learn 37 that such words are not informative for sentiment classification.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG66">
<title id=" W10-3505.xml">pruning non informative text through non expert annotations to improve aspect level sentiment classification </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>conclusions are summarized in section 5.
</prevsent>
<prevsent>feature selection in the domain of sentiment analysis has focused on the following issues.
</prevsent>
</prevsection>
<citsent citstr=" J04-3002 ">
a) should word-based features be selected based on frequency or presence it has been shown that compared to word frequency, word presence is better sentiment indicator (pang et al, 2002; <papid> W02-1011 </papid>wiebe et al, 2004; <papid> J04-3002 </papid>yanget al, 2006).<papid> P06-2079 </papid></citsent>
<aftsection>
<nextsent>in other words, unlike in other domains such as topic classification where the frequency of words provides useful information regarding the topic class, sentiment information is not normally indicated by the frequency of certain words, because people are unlikely to repeatedly use the same word or phrase to express an opinion in one document.
</nextsent>
<nextsent>instead, researchers (pang et al, 2002)<papid> W02-1011 </papid>found that selecting features based on word presence rather than word frequency leads to better performance in the domain of sentiment analysis.b) which are more useful features: unigrams, higher-order n-grams or syntactically related terms?</nextsent>
<nextsent>this issue seems to be debatable.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG67">
<title id=" W10-3505.xml">pruning non informative text through non expert annotations to improve aspect level sentiment classification </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>conclusions are summarized in section 5.
</prevsent>
<prevsent>feature selection in the domain of sentiment analysis has focused on the following issues.
</prevsent>
</prevsection>
<citsent citstr=" P06-2079 ">
a) should word-based features be selected based on frequency or presence it has been shown that compared to word frequency, word presence is better sentiment indicator (pang et al, 2002; <papid> W02-1011 </papid>wiebe et al, 2004; <papid> J04-3002 </papid>yanget al, 2006).<papid> P06-2079 </papid></citsent>
<aftsection>
<nextsent>in other words, unlike in other domains such as topic classification where the frequency of words provides useful information regarding the topic class, sentiment information is not normally indicated by the frequency of certain words, because people are unlikely to repeatedly use the same word or phrase to express an opinion in one document.
</nextsent>
<nextsent>instead, researchers (pang et al, 2002)<papid> W02-1011 </papid>found that selecting features based on word presence rather than word frequency leads to better performance in the domain of sentiment analysis.b) which are more useful features: unigrams, higher-order n-grams or syntactically related terms?</nextsent>
<nextsent>this issue seems to be debatable.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG74">
<title id=" W10-3505.xml">pruning non informative text through non expert annotations to improve aspect level sentiment classification </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>instead, researchers (pang et al, 2002)<papid> W02-1011 </papid>found that selecting features based on word presence rather than word frequency leads to better performance in the domain of sentiment analysis.b) which are more useful features: unigrams, higher-order n-grams or syntactically related terms?</prevsent>
<prevsent>this issue seems to be debatable.</prevsent>
</prevsection>
<citsent citstr=" C04-1121 ">
while some researchers (pang et al, 2002)<papid> W02-1011 </papid>reported that unigrams outperform both bigrams as well as the combination of unigrams and bigrams in classifying movie reviews based on sentiment polarity,some others (dave et al, 2003) reported the opposite in some settings.similarly, some (dave et al, 2003) found syntactically related terms are not helpful for sentiment classification, whereas others (gamon, 2004; <papid> C04-1121 </papid>matsumoto et al, 2005; ng et al, 2006) <papid> P06-2079 </papid>found the opposite to be true.</citsent>
<aftsection>
<nextsent>c) in terms of part-of-speech, which types of words are more useful features?
</nextsent>
<nextsent>adjectives and adverbs are commonly used as features for sentiment learning (mullen and collier, 2004; <papid> W04-3253 </papid>turney, 2002; <papid> P02-1053 </papid>whitelaw et al, 2005).however, more recent studies show that all content words including nouns, verbs, adjectives and adverbs are useful features for sentiment analysis (dillard, 2007).</nextsent>
<nextsent>regardless of which types of features areused, these traditional approaches are still inherently noisy in the sense that non-informative 38 words/features within each sentence are included as described in section 1.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG77">
<title id=" W10-3505.xml">pruning non informative text through non expert annotations to improve aspect level sentiment classification </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>while some researchers (pang et al, 2002)<papid> W02-1011 </papid>reported that unigrams outperform both bigrams as well as the combination of unigrams and bigrams in classifying movie reviews based on sentiment polarity,some others (dave et al, 2003) reported the opposite in some settings.similarly, some (dave et al, 2003) found syntactically related terms are not helpful for sentiment classification, whereas others (gamon, 2004; <papid> C04-1121 </papid>matsumoto et al, 2005; ng et al, 2006) <papid> P06-2079 </papid>found the opposite to be true.</prevsent>
<prevsent>c) in terms of part-of-speech, which types of words are more useful features?</prevsent>
</prevsection>
<citsent citstr=" W04-3253 ">
adjectives and adverbs are commonly used as features for sentiment learning (mullen and collier, 2004; <papid> W04-3253 </papid>turney, 2002; <papid> P02-1053 </papid>whitelaw et al, 2005).however, more recent studies show that all content words including nouns, verbs, adjectives and adverbs are useful features for sentiment analysis (dillard, 2007).</citsent>
<aftsection>
<nextsent>regardless of which types of features areused, these traditional approaches are still inherently noisy in the sense that non-informative 38 words/features within each sentence are included as described in section 1.
</nextsent>
<nextsent>as far as we are aware, this is an issue that has not been addressed.
</nextsent>
<nextsent>the closest works are riloff et al (riloff and wiebe, 2003) <papid> W03-1014 </papid>and pang et al (pang et al, 2002)<papid> W02-1011 </papid>s work.</nextsent>
<nextsent>riloff et al explored removing the features that are subsumed in other features when combination of different types of features such as unigrams, bigrams and syntactically related terms is used.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG78">
<title id=" W10-3505.xml">pruning non informative text through non expert annotations to improve aspect level sentiment classification </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>while some researchers (pang et al, 2002)<papid> W02-1011 </papid>reported that unigrams outperform both bigrams as well as the combination of unigrams and bigrams in classifying movie reviews based on sentiment polarity,some others (dave et al, 2003) reported the opposite in some settings.similarly, some (dave et al, 2003) found syntactically related terms are not helpful for sentiment classification, whereas others (gamon, 2004; <papid> C04-1121 </papid>matsumoto et al, 2005; ng et al, 2006) <papid> P06-2079 </papid>found the opposite to be true.</prevsent>
<prevsent>c) in terms of part-of-speech, which types of words are more useful features?</prevsent>
</prevsection>
<citsent citstr=" P02-1053 ">
adjectives and adverbs are commonly used as features for sentiment learning (mullen and collier, 2004; <papid> W04-3253 </papid>turney, 2002; <papid> P02-1053 </papid>whitelaw et al, 2005).however, more recent studies show that all content words including nouns, verbs, adjectives and adverbs are useful features for sentiment analysis (dillard, 2007).</citsent>
<aftsection>
<nextsent>regardless of which types of features areused, these traditional approaches are still inherently noisy in the sense that non-informative 38 words/features within each sentence are included as described in section 1.
</nextsent>
<nextsent>as far as we are aware, this is an issue that has not been addressed.
</nextsent>
<nextsent>the closest works are riloff et al (riloff and wiebe, 2003) <papid> W03-1014 </papid>and pang et al (pang et al, 2002)<papid> W02-1011 </papid>s work.</nextsent>
<nextsent>riloff et al explored removing the features that are subsumed in other features when combination of different types of features such as unigrams, bigrams and syntactically related terms is used.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG79">
<title id=" W10-3505.xml">pruning non informative text through non expert annotations to improve aspect level sentiment classification </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>regardless of which types of features areused, these traditional approaches are still inherently noisy in the sense that non-informative 38 words/features within each sentence are included as described in section 1.
</prevsent>
<prevsent>as far as we are aware, this is an issue that has not been addressed.
</prevsent>
</prevsection>
<citsent citstr=" W03-1014 ">
the closest works are riloff et al (riloff and wiebe, 2003) <papid> W03-1014 </papid>and pang et al (pang et al, 2002)<papid> W02-1011 </papid>s work.</citsent>
<aftsection>
<nextsent>riloff et al explored removing the features that are subsumed in other features when combination of different types of features such as unigrams, bigrams and syntactically related terms is used.
</nextsent>
<nextsent>pang et al speculated that words that appear at certain positions in movie review are more informative for the overall opinion reflected in that review.
</nextsent>
<nextsent>however, according to pang et al, for the task of predicting the overall polarity of movie review, training on word features assumed to be more informative resulted in worse performance than training on all word features appearing in the reviews.our approach is different in that we try to identify and prune non-informative word features at the sentence level.
</nextsent>
<nextsent>we focus on identifying which portion of the sentence is informative for sentiment classification.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG81">
<title id=" W10-3505.xml">pruning non informative text through non expert annotations to improve aspect level sentiment classification </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in (nakov, 2008), non-expert annotators generated paraphrases for 250 noun-noun compounds, which were then used as the gold standard data for evaluating an automatic paraphrasing system.
</prevsent>
<prevsent>kaisser and lowe (kaisser and lowe, 2008) also use non experts to annotate answers contained in sentence sand use the annotation results to help build question answering corpus.
</prevsent>
</prevsection>
<citsent citstr=" D08-1027 ">
snow et al (snow et al., 2008) <papid> D08-1027 </papid>reported experiments using non-expertannotation for the following five nlp tasks: affect recognition, word similarity, recognizing textual entailment, event temporal ordering, and word sense disambiguation.</citsent>
<aftsection>
<nextsent>this paper presents study of using non-expertannotations to prune non-informative word features and training sentiment classifier based onsuch non-expert annotations.
</nextsent>
<nextsent>the following section describes our approach in detail.
</nextsent>
<nextsent>through non-expert annotation sto prune the non-informative features, traditional approach would be to hire and train annotators to label which portion of each training sentence is informative or non-informative.
</nextsent>
<nextsent>however,this approach is both expensive and time consuming.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG85">
<title id=" W10-1503.xml">sketching techniques for large scale nlp </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the number of these counters is up to 30 times less than the stream size which is big memory and space gain.
</prevsent>
<prevsent>in semantic orientation experiments, thepmi scores computed from 2 billion counters are as effective as exact pmi scores.
</prevsent>
</prevsection>
<citsent citstr=" D07-1090 ">
approaches to solve nlp problems (brants et al ,2007; <papid> D07-1090 </papid>turney, 2008; <papid> C08-1114 </papid>ravichandran et al , 2005) <papid> P05-1077 </papid>always benefited from having large amounts of data.in some cases (turney and littman, 2002; patwardhan and riloff, 2006), <papid> W06-0208 </papid>researchers attempted to use the evidence gathered from web via search engines to solve the problems.</citsent>
<aftsection>
<nextsent>but the commercial search engines limit the number of automatic requests on daily basis for various reasons such as to avoid fraud and computational overhead.
</nextsent>
<nextsent>though we can crawl the data and save it on disk,most of the current approaches employ data structures that reside in main memory and thus do not scale well to huge corpora.
</nextsent>
<nextsent>fig.
</nextsent>
<nextsent>1 helps us understand the seriousness ofthe situation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG86">
<title id=" W10-1503.xml">sketching techniques for large scale nlp </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the number of these counters is up to 30 times less than the stream size which is big memory and space gain.
</prevsent>
<prevsent>in semantic orientation experiments, thepmi scores computed from 2 billion counters are as effective as exact pmi scores.
</prevsent>
</prevsection>
<citsent citstr=" C08-1114 ">
approaches to solve nlp problems (brants et al ,2007; <papid> D07-1090 </papid>turney, 2008; <papid> C08-1114 </papid>ravichandran et al , 2005) <papid> P05-1077 </papid>always benefited from having large amounts of data.in some cases (turney and littman, 2002; patwardhan and riloff, 2006), <papid> W06-0208 </papid>researchers attempted to use the evidence gathered from web via search engines to solve the problems.</citsent>
<aftsection>
<nextsent>but the commercial search engines limit the number of automatic requests on daily basis for various reasons such as to avoid fraud and computational overhead.
</nextsent>
<nextsent>though we can crawl the data and save it on disk,most of the current approaches employ data structures that reside in main memory and thus do not scale well to huge corpora.
</nextsent>
<nextsent>fig.
</nextsent>
<nextsent>1 helps us understand the seriousness ofthe situation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG87">
<title id=" W10-1503.xml">sketching techniques for large scale nlp </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the number of these counters is up to 30 times less than the stream size which is big memory and space gain.
</prevsent>
<prevsent>in semantic orientation experiments, thepmi scores computed from 2 billion counters are as effective as exact pmi scores.
</prevsent>
</prevsection>
<citsent citstr=" P05-1077 ">
approaches to solve nlp problems (brants et al ,2007; <papid> D07-1090 </papid>turney, 2008; <papid> C08-1114 </papid>ravichandran et al , 2005) <papid> P05-1077 </papid>always benefited from having large amounts of data.in some cases (turney and littman, 2002; patwardhan and riloff, 2006), <papid> W06-0208 </papid>researchers attempted to use the evidence gathered from web via search engines to solve the problems.</citsent>
<aftsection>
<nextsent>but the commercial search engines limit the number of automatic requests on daily basis for various reasons such as to avoid fraud and computational overhead.
</nextsent>
<nextsent>though we can crawl the data and save it on disk,most of the current approaches employ data structures that reside in main memory and thus do not scale well to huge corpora.
</nextsent>
<nextsent>fig.
</nextsent>
<nextsent>1 helps us understand the seriousness ofthe situation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG89">
<title id=" W10-1503.xml">sketching techniques for large scale nlp </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the number of these counters is up to 30 times less than the stream size which is big memory and space gain.
</prevsent>
<prevsent>in semantic orientation experiments, thepmi scores computed from 2 billion counters are as effective as exact pmi scores.
</prevsent>
</prevsection>
<citsent citstr=" W06-0208 ">
approaches to solve nlp problems (brants et al ,2007; <papid> D07-1090 </papid>turney, 2008; <papid> C08-1114 </papid>ravichandran et al , 2005) <papid> P05-1077 </papid>always benefited from having large amounts of data.in some cases (turney and littman, 2002; patwardhan and riloff, 2006), <papid> W06-0208 </papid>researchers attempted to use the evidence gathered from web via search engines to solve the problems.</citsent>
<aftsection>
<nextsent>but the commercial search engines limit the number of automatic requests on daily basis for various reasons such as to avoid fraud and computational overhead.
</nextsent>
<nextsent>though we can crawl the data and save it on disk,most of the current approaches employ data structures that reside in main memory and thus do not scale well to huge corpora.
</nextsent>
<nextsent>fig.
</nextsent>
<nextsent>1 helps us understand the seriousness ofthe situation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG90">
<title id=" W10-1503.xml">sketching techniques for large scale nlp </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 large scale nlp problems.
</prevsent>
<prevsent>use of large data in the nlp community is not new.
</prevsent>
</prevsection>
<citsent citstr=" N09-1003 ">
a corpus of roughly 1.6 tera words was usedby agirre et al  (2009) <papid> N09-1003 </papid>to compute pairwise similarities of the words in the test sets using themapreduce infrastructure on 2, 000 cores.</citsent>
<aftsection>
<nextsent>pan tel et al  (2009) <papid> D09-1098 </papid>computed similarity between 500 million terms in the map reduce framework over 200 billion words in 50 hours using 200 quad-core nodes.</nextsent>
<nextsent>the inaccessibility of clusters for every onehas attracted the nlp community to use streaming, randomized, approximate and sampling algorithms to handle large amounts of data.a randomized data structure called bloom filter was used to construct space efficient language models (talbot and osborne, 2007) <papid> D07-1049 </papid>for statistical machine translation (smt).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG91">
<title id=" W10-1503.xml">sketching techniques for large scale nlp </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>use of large data in the nlp community is not new.
</prevsent>
<prevsent>a corpus of roughly 1.6 tera words was usedby agirre et al  (2009) <papid> N09-1003 </papid>to compute pairwise similarities of the words in the test sets using themapreduce infrastructure on 2, 000 cores.</prevsent>
</prevsection>
<citsent citstr=" D09-1098 ">
pan tel et al  (2009) <papid> D09-1098 </papid>computed similarity between 500 million terms in the map reduce framework over 200 billion words in 50 hours using 200 quad-core nodes.</citsent>
<aftsection>
<nextsent>the inaccessibility of clusters for every onehas attracted the nlp community to use streaming, randomized, approximate and sampling algorithms to handle large amounts of data.a randomized data structure called bloom filter was used to construct space efficient language models (talbot and osborne, 2007) <papid> D07-1049 </papid>for statistical machine translation (smt).</nextsent>
<nextsent>recently, the streaming algorithm paradigm has been used to provide memory and space-efficient platform to deal with tera bytes of data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG92">
<title id=" W10-1503.xml">sketching techniques for large scale nlp </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>a corpus of roughly 1.6 tera words was usedby agirre et al  (2009) <papid> N09-1003 </papid>to compute pairwise similarities of the words in the test sets using themapreduce infrastructure on 2, 000 cores.</prevsent>
<prevsent>pan tel et al  (2009) <papid> D09-1098 </papid>computed similarity between 500 million terms in the map reduce framework over 200 billion words in 50 hours using 200 quad-core nodes.</prevsent>
</prevsection>
<citsent citstr=" D07-1049 ">
the inaccessibility of clusters for every onehas attracted the nlp community to use streaming, randomized, approximate and sampling algorithms to handle large amounts of data.a randomized data structure called bloom filter was used to construct space efficient language models (talbot and osborne, 2007) <papid> D07-1049 </papid>for statistical machine translation (smt).</citsent>
<aftsection>
<nextsent>recently, the streaming algorithm paradigm has been used to provide memory and space-efficient platform to deal with tera bytes of data.
</nextsent>
<nextsent>for example, we (goyal et al , 2009) <papid> N09-1058 </papid>pose language modeling as problem of finding frequent items in stream of data and show its effectiveness in smt.</nextsent>
<nextsent>subsequently, (levenberg and osborne, 2009) <papid> D09-1079 </papid>proposed randomized language model to efficiently deal with unbounded text streams.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG93">
<title id=" W10-1503.xml">sketching techniques for large scale nlp </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>the inaccessibility of clusters for every onehas attracted the nlp community to use streaming, randomized, approximate and sampling algorithms to handle large amounts of data.a randomized data structure called bloom filter was used to construct space efficient language models (talbot and osborne, 2007) <papid> D07-1049 </papid>for statistical machine translation (smt).</prevsent>
<prevsent>recently, the streaming algorithm paradigm has been used to provide memory and space-efficient platform to deal with tera bytes of data.</prevsent>
</prevsection>
<citsent citstr=" N09-1058 ">
for example, we (goyal et al , 2009) <papid> N09-1058 </papid>pose language modeling as problem of finding frequent items in stream of data and show its effectiveness in smt.</citsent>
<aftsection>
<nextsent>subsequently, (levenberg and osborne, 2009) <papid> D09-1079 </papid>proposed randomized language model to efficiently deal with unbounded text streams.</nextsent>
<nextsent>in (van durme andlall, 2009b), authors extend talbot osborne morris bloom (tomb) (van durme and lall, 2009a) counter to find the highly ranked pmi response words given cue word.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG94">
<title id=" W10-1503.xml">sketching techniques for large scale nlp </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>recently, the streaming algorithm paradigm has been used to provide memory and space-efficient platform to deal with tera bytes of data.
</prevsent>
<prevsent>for example, we (goyal et al , 2009) <papid> N09-1058 </papid>pose language modeling as problem of finding frequent items in stream of data and show its effectiveness in smt.</prevsent>
</prevsection>
<citsent citstr=" D09-1079 ">
subsequently, (levenberg and osborne, 2009) <papid> D09-1079 </papid>proposed randomized language model to efficiently deal with unbounded text streams.</citsent>
<aftsection>
<nextsent>in (van durme andlall, 2009b), authors extend talbot osborne morris bloom (tomb) (van durme and lall, 2009a) counter to find the highly ranked pmi response words given cue word.
</nextsent>
<nextsent>the idea of tomb is similar to cm sketch.
</nextsent>
<nextsent>tomb can also be used to store word pairs and further compute pmi scores.
</nextsent>
<nextsent>however, we advocate cm sketch as it is very simple algorithm with strong guarantees and good properties (see section 3).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG95">
<title id=" W10-1503.xml">sketching techniques for large scale nlp </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>streaming algorithms were first developed in the early 80s, but gained in popularity in the late 90s as researchers first realized the challenges of dealing with massive datasets.
</prevsent>
<prevsent>a good survey of the model and core challenges can be found in(muthukrishnan, 2005).
</prevsent>
</prevsection>
<citsent citstr=" J07-3003 ">
there has been considerable work on coming up with different sketch techniques (charikar et al , 2002; cormode and muthukrishnan, 2004; li and church, 2007).<papid> J07-3003 </papid></citsent>
<aftsection>
<nextsent>a survey by (rusu and dobra, 2007; cormode and hadjieleftheriou, 2008) comprehensively reviews the literature.
</nextsent>
<nextsent>the count-min sketch (cormode and muthukrishnan, 2004) is compact summary data structure used to store the frequencies of all items in the in put stream.
</nextsent>
<nextsent>the sketch allows fundamental queries 18on the datastream such as point, range and inner product queries to be approximately answered very quickly.
</nextsent>
<nextsent>it can also be applied to solve the finding frequent items problem (manku and mot wani, 2002) in datastream.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG98">
<title id=" W10-1503.xml">sketching techniques for large scale nlp </title>
<section> intrinsic evaluations.  </section>
<citcontext>
<prevsection>
<prevsent>in this experiment, we compare the word pairs association rankings obtained using pmi with cu and exact counts.
</prevsent>
<prevsent>we use two kinds of measures, namely accuracy and spear mans correlation, to measure the overlap in the rankings obtained by both these approaches.
</prevsent>
</prevsection>
<citsent citstr=" P89-1010 ">
4.3.1 pointwise mutual information the pointwise mutual information (pmi) (church and hanks, 1989) <papid> P89-1010 </papid>between two words w1 and w2 is defined as: pmi(w1, w2) = log2 (w1, w2) (w1)p (w2) here, (w1, w2) is the likelihood that w1 and w2occur together, and (w1) and (w2) are their independent likelihoods respectively.</citsent>
<aftsection>
<nextsent>the ratio between these probabilities measures the degree of statistical dependence between w1 and w2.
</nextsent>
<nextsent>4.3.2 description of the metrics accuracy is defined as fraction of word pairs that are found in both rankings to the size of top ranked word pairs.
</nextsent>
<nextsent>accuracy = |cp-wps ? ep-wps||ep-wps| where cp-wps represent the set of top ranked word pairs under the counts stored using the cu sketch and ep-wps represent the set of top ranked word pairs with the exact counts.
</nextsent>
<nextsent>spear mans rank correlation coefficient (?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG100">
<title id=" W10-2807.xml">expectation vectors a semiotics inspired approach to geometric lexical semantic representation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it is cornerstone assumption of distributional lexical semantics that the distribution of words in corpus reflects their meaning.
</prevsent>
<prevsent>common interpretations of this include the distributional hypothesis (harris, 1954) and the contextual hypotheses (miller &amp; charles, 1991), which state that there is relationship between word meaning, and the context(s) in which it appears.
</prevsent>
</prevsection>
<citsent citstr=" C02-1007 ">
in recent years this insight has been borne out by correlations between human judgements and distributional models of word similarity (rapp, 2002), <papid> C02-1007 </papid>and steady advances in tasks such as word sense disambiguation (schtze, 1998) and information retrieval.</citsent>
<aftsection>
<nextsent>the workhorse of these approaches are word space models: vectors built from context features which serve as geometric analogues of meaning.
</nextsent>
<nextsent>despite many advances, substantial problems exist with this approach to modelling meaning.
</nextsent>
<nextsent>amongst these are the problems of data sparseness and of how to model compositional meaning.
</nextsent>
<nextsent>in this short paper, we introduce new family of word space models, based on insights gleaned from semiotics and information theory, called expectation vectors.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG101">
<title id=" W10-2807.xml">expectation vectors a semiotics inspired approach to geometric lexical semantic representation </title>
<section> modelling meaning from context.  </section>
<citcontext>
<prevsection>
<prevsent>backing off?
</prevsent>
<prevsent>to more general feature classes through say lemmatization or part-of-speech tagging affords one way of alleviating sparseness (joshi &amp; penstein-ros?, 2009), assuming these features are pertinent to the task.
</prevsent>
</prevsection>
<citsent citstr=" H93-1052 ">
similar strategies include the use of dual-context models where immediate lexical features are backed up by more general topical ones garnered from the wider context of the ambiguous word (leacock et al, 1996; yarowsky, 1993).<papid> H93-1052 </papid></citsent>
<aftsection>
<nextsent>others have tackled the problem of sparseness without recourse to generalized feature classes, 45 through the exploitation of higher-order distributional information.
</nextsent>
<nextsent>schtze (1998) popularised this approach within the wsd/wsi task.
</nextsent>
<nextsent>rather than comparing contexts directly, it is the distributional similarity of those features (in the corpus) which are compared.
</nextsent>
<nextsent>specifically, schtze composed context vectors by summing the vectors for every word in context, where those vectors were themselves formed from the total of word co-occurrence counts pertaining to every instance of that word in the corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG102">
<title id=" W10-2807.xml">expectation vectors a semiotics inspired approach to geometric lexical semantic representation </title>
<section> modelling meaning from context.  </section>
<citcontext>
<prevsection>
<prevsent>very similar techniques to both of those used by schtze have been used for query expansion and document representation in information retrieval (qiu &amp; frei, 1993; xu et al 2007).
</prevsent>
<prevsent>several variations upon schtzes approach to wsd have been explored.
</prevsent>
</prevsection>
<citsent citstr=" W96-0104 ">
dagan et al(1995) and karov &amp; edelman (1996) <papid> W96-0104 </papid>both apply what they call similarity-based?</citsent>
<aftsection>
<nextsent>methods which, while markedly different on the surface to that of schtze, are similar in spirit and intent.
</nextsent>
<nextsent>karov &amp; edelman, for example, use machine-readable dictionary glosses as opposed to corpus-derived co-occurrences, and apply an iterative bootstrapping approach to augment the available data, rather than strict second-order information.
</nextsent>
<nextsent>typically, context vectors comprise component (dimension) for each designated feature in words context.
</nextsent>
<nextsent>in simple bag-of words model this might equate to one vector component for each potential word that can appear in the context.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG103">
<title id=" W10-2807.xml">expectation vectors a semiotics inspired approach to geometric lexical semantic representation </title>
<section> system &amp; approach.  </section>
<citcontext>
<prevsection>
<prevsent>although such models are the mainstay of many systems in nlp, adopting the toolset of an expec tion transform in such case gains us little.
</prevsent>
<prevsent>therefore the relevance of the approach to the present task depends wholly upon having suitably sophisticated language model.
</prevsent>
</prevsection>
<citsent citstr=" C04-1147 ">
building on the work of washtell (2009) and terra &amp; clarke (2004), <papid> C04-1147 </papid>distance-based language model is used in the present work.</citsent>
<aftsection>
<nextsent>this is in contrast to the bag-of-words, n-gram, or syntactic dependency models more commonly described in the nlp literature.
</nextsent>
<nextsent>there are two hypothesised advantages to this approach.
</nextsent>
<nextsent>firstly, this avoids the issue of immediate context versus wider topical 47 context.
</nextsent>
<nextsent>while immediate context is generally accepted to play dominant role in wsd, both near and far context have been shown to be useful - the specific balance being somewhat dependent on the ambiguous word in question (yarowsky, 1993; <papid> H93-1052 </papid>gale et al 1992; leacock et al 1996).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG105">
<title id=" W10-2807.xml">expectation vectors a semiotics inspired approach to geometric lexical semantic representation </title>
<section> system &amp; approach.  </section>
<citcontext>
<prevsection>
<prevsent>moreover, as it is specific distance information which is being recorded, rather than (usually low) frequency counts, context vector components and the similarity measurements which arise from them exhibit good precision.
</prevsent>
<prevsent>washtell (2009) showed that these properties of distance-based metrics lead to measurable gains in information extracted from corpus.
</prevsent>
</prevsection>
<citsent citstr=" D09-1066 ">
in the context of modelling human notions of association this also led to improved predictive power (washtell &amp; markert, 2009).<papid> D09-1066 </papid></citsent>
<aftsection>
<nextsent>formal approach.
</nextsent>
<nextsent>we do not pre-compute any statistical representation of the data upon which our language model draws.
</nextsent>
<nextsent>with available approaches this would either require throwing away large number of potentially relevant higher-order dependencies, or would otherwise be intractable.
</nextsent>
<nextsent>our intuition is that the truest representation of the language encoded in the corpus is the corpus itself.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG106">
<title id=" W10-0804.xml">string net as a computational resource for discovering and investigating linguistic constructions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>up to their hosting proto constructions (e.g. the it cleft construction: its the [noun] that [verb]?).
</prevsent>
<prevsent>string net supports discovery of grammatical dependencies (e.g., subject-verb agreement) in non canonical configurations as well as lexical dependencies (e.g., adjective/noun collocations specific to families of constructions).
</prevsent>
</prevsection>
<citsent citstr=" W06-1206 ">
constructions have posed persistent challenges to the field of computational linguistics (baldwin et al  2004; sag et al 2002; zhang et al 2006).<papid> W06-1206 </papid></citsent>
<aftsection>
<nextsent>challenges to both statistical and symbolic approaches arise, for example, from the meager degree of productivity and non-canonical structures of many constructions and, as loosely defined family of linguistic phenomena, their varied mix of regularity and idiomicity (fillmore, kay, and oconnor 1988).
</nextsent>
<nextsent>it has been argued for decades that constructions are central rather than peripheral to any adequate account of linguistic knowledge and that they pose substantial challenges to mainstream accounts of language (bolinger, 1977, 1985; fill more, kay, and oconnor, 1988; goldberg, 1995; inter alia).
</nextsent>
<nextsent>but the recent attention they have been receiving in computational research is perhaps due more to their status as troublemakers (or pain in the neck?, sag et al 2002).
</nextsent>
<nextsent>baldwin et al (2004) found, for example, that 39% of parse failures on clean data (bnc) occurred on constructions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG109">
<title id=" W10-0804.xml">string net as a computational resource for discovering and investigating linguistic constructions </title>
<section> illustrating with examples.  </section>
<citcontext>
<prevsection>
<prevsent>in horizontal pruning, the shorter of the two compared hybrid n-grams is the potentially redundant one and thus the candidate for pruning.
</prevsent>
<prevsent>as with our mi measure, both vertical and horizontal pruning rate are set post hoc, applied by post-processing, and so are adjustable.
</prevsent>
</prevsection>
<citsent citstr=" W09-2108 ">
although string net can support wide range of applications (such as error detection and correction (tsao and wible 2009); <papid> W09-2108 </papid>document similarity measurement, etc.), for ease of exposition in what follows, we take search query as our access point to illustrate string net content.</citsent>
<aftsection>
<nextsent>taking eye as our query term, string net yields ranked list of 3,765 hybrid n-grams containing either this lexeme or one of its inflected forms.
</nextsent>
<nextsent>the following are samples from the top 50 (i.e., the first page of results): visible [prep] the naked eye turning blind eye to out of the corner of [dps] eye [dps] eyes filled with tears keeping an eye on the [noun] [adv] see eye to eye look [pers prn] straight in the eye cast [adj] eye [prep] (e.g., cast critical eye over, cast cold eye on) each hybrid n-gram listed in search result is accompanied by links to examples and parent and child icons that link to its parent and children hybrid n-grams.
</nextsent>
<nextsent>(see fig 1 and 2.)
</nextsent>
<nextsent>consider one of the hybrid n-grams listed in the results for eye: keep close eye on.?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG110">
<title id=" W10-0804.xml">string net as a computational resource for discovering and investigating linguistic constructions </title>
<section> illustrating with examples.  </section>
<citcontext>
<prevsection>
<prevsent>note that since it is string of lexical items, as are all substantive idioms by definition, this sort can just as easily be extracted and represented using traditional flat n-grams.
</prevsent>
<prevsent>string nets hybrid n-grams and their cross-indexing, however, allow us to see whether this is one-off lexically filled idiom or an instance of lexically open formal idiom (i.e., of construction).
</prevsent>
</prevsection>
<citsent citstr=" N09-2044 ">
without hybrid n-grams, the next step up in abstraction to determine this would be pure pos n-grams (strings of pos categories only) used in the literature (feldman et al 2009; <papid> N09-2044 </papid>florian et al 2003; <papid> W03-0425 </papid>gamon et al 2009).</citsent>
<aftsection>
<nextsent>in the case of keep close eye on?
</nextsent>
<nextsent>the corresponding pos gram would be ?[verb][det][adj][noun][prep].?
</nextsent>
<nextsent>this, however, could describe strings as far afield as buy new car with?
</nextsent>
<nextsent>or sequester the entire jury until.?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG111">
<title id=" W10-0804.xml">string net as a computational resource for discovering and investigating linguistic constructions </title>
<section> illustrating with examples.  </section>
<citcontext>
<prevsection>
<prevsent>note that since it is string of lexical items, as are all substantive idioms by definition, this sort can just as easily be extracted and represented using traditional flat n-grams.
</prevsent>
<prevsent>string nets hybrid n-grams and their cross-indexing, however, allow us to see whether this is one-off lexically filled idiom or an instance of lexically open formal idiom (i.e., of construction).
</prevsent>
</prevsection>
<citsent citstr=" W03-0425 ">
without hybrid n-grams, the next step up in abstraction to determine this would be pure pos n-grams (strings of pos categories only) used in the literature (feldman et al 2009; <papid> N09-2044 </papid>florian et al 2003; <papid> W03-0425 </papid>gamon et al 2009).</citsent>
<aftsection>
<nextsent>in the case of keep close eye on?
</nextsent>
<nextsent>the corresponding pos gram would be ?[verb][det][adj][noun][prep].?
</nextsent>
<nextsent>this, however, could describe strings as far afield as buy new car with?
</nextsent>
<nextsent>or sequester the entire jury until.?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG112">
<title id=" W10-1837.xml">pack play mining semantic data in collaborative games </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>domain and language specific corpora are useful for many language technology applications, including named entity recognition (ner), machine translation, spelling correction, and machine-readable dictionaries.
</prevsent>
<prevsent>the an crubadan project, for example, has succeeded in creating corpora for more than 400 of the worlds6000+ languages by web crawling.
</prevsent>
</prevsection>
<citsent citstr=" W06-1705 ">
with few exceptions, most of the 400+ corpora, however, lack any linguistic annotations due to the limitations of annotation tools (rayson et al, 2006).<papid> W06-1705 </papid></citsent>
<aftsection>
<nextsent>despite the many documented advantages of annotated data over raw data (granger and rayson, 1998; mair, 2005), there is dearth of annotated corpora in many domains.
</nextsent>
<nextsent>the majority of previous corpus annotation efforts relied on manual annotation by domain experts,automated prediction tagging systems, and hybrid semi-automatic systems that used both approaches.
</nextsent>
<nextsent>while yielding high quality and enormously valuable corpora, manually annotating corpora can be prohibitively costly and time consuming.
</nextsent>
<nextsent>for example, the genia corpus contains9,372 sentences, curated by five part-time annotators, one senior coordinator, and one junior coordinator over 1.5 years (kim et al, 2008).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG113">
<title id=" W10-1837.xml">pack play mining semantic data in collaborative games </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, the genia corpus contains9,372 sentences, curated by five part-time annotators, one senior coordinator, and one junior coordinator over 1.5 years (kim et al, 2008).
</prevsent>
<prevsent>semiautomatic approaches decrease human effort but often introduce significant error, while still requiring human interaction.the web can help facilitate semi-automatic approaches by connecting distributed human users at previously unfathomable scale and presents an opportunity to expand annotation efforts to countless users using human computation, the concept of outsourcing certain computational 227processes to humans, generally to solve problems that are intractable or difficult for computers.
</prevsent>
</prevsection>
<citsent citstr=" D08-1027 ">
this concept is demonstrated in our previous work, webbanc (green et al, 2009) and biodeal (breimyer et al, 2009), which allows users to annotate web documents through webbrowser plugin for the purposes of creating linguistically and biologically tagged annotated corpora and with micro-tasking via mechanical turk,which allows for low cost option for manual labor tasks (snow et al, 2008; <papid> D08-1027 </papid>kittur et al, 2008).</citsent>
<aftsection>
<nextsent>while the web and human computation may be powerful tandem for generating data and solving difficult problems, in order to succeed, users must be motivated to participate.
</nextsent>
<nextsent>humans have been fascinated with games for centuries and play them for many reasons, including for entertainment, honing skills, and gaining knowledge (fas summit, 2006).
</nextsent>
<nextsent>every year, large amount of hours are spent playing online computer games.
</nextsent>
<nextsent>the games range form simple card and word games to more complex 3-d world games.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG115">
<title id=" W10-1837.xml">pack play mining semantic data in collaborative games </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>arguably if, the games on pogo were used to harvest useful data, various fields of computer science research could be advanced.there has been recent trend to leverage humans fascination in game playing to solve difficult problems through human computation.
</prevsent>
<prevsent>twosuch games include esp and googles image labeler (ahn and dabbish, 2004), in which players annotate images in cooperative environment to correctly match image tags with their partner.
</prevsent>
</prevsection>
<citsent citstr=" W09-3309 ">
semantic annotation has also been addressed in the game phrase detectives (chamberlain et al, 2009), <papid> W09-3309 </papid>which has the goal of creating large scale training data for anaphora resolution.</citsent>
<aftsection>
<nextsent>these typesof games are part of larger, serious games, initiative (annetta, 2008).this paper introduces the web-enabled collaborative game framework, pack play, and investigates 1pogo.
</nextsent>
<nextsent>http://www.pogo.com/2protrackr.com site information and statist is tics.http://www.protrackr.com/ 3alexa: the web information company.
</nextsent>
<nextsent>http://www.alexa.com/how collaborative online gaming can affect annotation throughput and annotation accuracy.
</nextsent>
<nextsent>there are two main questions for such systems: first,will overall throughput increase compared to traditional methods of annotating, such as the manual construction of the genia corpus?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG118">
<title id=" W10-1837.xml">pack play mining semantic data in collaborative games </title>
<section> games.  </section>
<citcontext>
<prevsection>
<prevsent>this anonymity allows us to keep the asynchronous structure hidden, as well as judge new metric, intra-annotator agreement, not tested in the previous game.
</prevsent>
<prevsent>since it is possible that player in pack play may have question sampled that was previously annotated in the entity discovery game by the same player, we can use intra annotator agreement.
</prevsent>
</prevsection>
<citsent citstr=" J08-4004 ">
while well-known inter annotator statistics, such as cohens kappa, evaluate one annotator versus the other annotator, intra annotator statistics allow us to judge an annotator versus himself or herself to test for consistency (artstein and poesio, 2008).<papid> J08-4004 </papid></citsent>
<aftsection>
<nextsent>in the pack play framework this allows us to detect playerss who are randomly guessing and are therefore not consistent with themselves.
</nextsent>
<nextsent>3.2.3 scoring since entity coverage of sentence is not an issue in the multiple choice game, we made use of different scoring system that would reward first instincts.
</nextsent>
<nextsent>while the entity discovery game has set score for every answer, name that entity has sliding scale.
</nextsent>
<nextsent>for each question, the max score is 100 points, as the time ticks away the user receives fewer points.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG119">
<title id=" W10-3222.xml">chained machine translation using morphemes as pivot language </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as the smallest meaning bearing elements of the languages which have rich morphology information, morphemes arethe compact representation of words.
</prevsent>
<prevsent>using morphemes as the semantic units in the parallel corpus can not only help choose the correct inflections, but also alleviate the data sparseness problem partially.many strategies of integrating morphology information into state-of-the-art smt systems in different stages have been proposed.
</prevsent>
</prevsection>
<citsent citstr=" P09-1090 ">
(ramanathan et al, 2009) <papid> P09-1090 </papid>proposed preprocessing approach for incorporating syntactic and morphological information within phrase-based english-hindi smt system.</citsent>
<aftsection>
<nextsent>(watanabe et al, 2006) <papid> W06-3115 </papid>proposed method which uses porter stems and even 4-letter prefixes for word alignment.</nextsent>
<nextsent>(koehn et al, 2007) <papid> P07-2045 </papid>proposed the factored translation models which combine feature functions to handle syntactic,morphological, and other linguistic information in log-linear model during training.(minkov et al, 2007) <papid> P07-1017 </papid>made use of the information of morphological structure and source language in postprocessing to improve smt quality.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG120">
<title id=" W10-3222.xml">chained machine translation using morphemes as pivot language </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>using morphemes as the semantic units in the parallel corpus can not only help choose the correct inflections, but also alleviate the data sparseness problem partially.many strategies of integrating morphology information into state-of-the-art smt systems in different stages have been proposed.
</prevsent>
<prevsent>(ramanathan et al, 2009) <papid> P09-1090 </papid>proposed preprocessing approach for incorporating syntactic and morphological information within phrase-based english-hindi smt system.</prevsent>
</prevsection>
<citsent citstr=" W06-3115 ">
(watanabe et al, 2006) <papid> W06-3115 </papid>proposed method which uses porter stems and even 4-letter prefixes for word alignment.</citsent>
<aftsection>
<nextsent>(koehn et al, 2007) <papid> P07-2045 </papid>proposed the factored translation models which combine feature functions to handle syntactic,morphological, and other linguistic information in log-linear model during training.(minkov et al, 2007) <papid> P07-1017 </papid>made use of the information of morphological structure and source language in postprocessing to improve smt quality.</nextsent>
<nextsent>(de gispert et al, 2009) <papid> N09-2019 </papid>adopted the minimum bayes risk decoding strategy to combine output from identical smt system, which is trained on alternative morphological decompositions of the source language.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG121">
<title id=" W10-3222.xml">chained machine translation using morphemes as pivot language </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(ramanathan et al, 2009) <papid> P09-1090 </papid>proposed preprocessing approach for incorporating syntactic and morphological information within phrase-based english-hindi smt system.</prevsent>
<prevsent>(watanabe et al, 2006) <papid> W06-3115 </papid>proposed method which uses porter stems and even 4-letter prefixes for word alignment.</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
(koehn et al, 2007) <papid> P07-2045 </papid>proposed the factored translation models which combine feature functions to handle syntactic,morphological, and other linguistic information in log-linear model during training.(minkov et al, 2007) <papid> P07-1017 </papid>made use of the information of morphological structure and source language in postprocessing to improve smt quality.</citsent>
<aftsection>
<nextsent>(de gispert et al, 2009) <papid> N09-2019 </papid>adopted the minimum bayes risk decoding strategy to combine output from identical smt system, which is trained on alternative morphological decompositions of the source language.</nextsent>
<nextsent>meanwhile, the smt-based methods are widely used in the area of natural language processing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG122">
<title id=" W10-3222.xml">chained machine translation using morphemes as pivot language </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(ramanathan et al, 2009) <papid> P09-1090 </papid>proposed preprocessing approach for incorporating syntactic and morphological information within phrase-based english-hindi smt system.</prevsent>
<prevsent>(watanabe et al, 2006) <papid> W06-3115 </papid>proposed method which uses porter stems and even 4-letter prefixes for word alignment.</prevsent>
</prevsection>
<citsent citstr=" P07-1017 ">
(koehn et al, 2007) <papid> P07-2045 </papid>proposed the factored translation models which combine feature functions to handle syntactic,morphological, and other linguistic information in log-linear model during training.(minkov et al, 2007) <papid> P07-1017 </papid>made use of the information of morphological structure and source language in postprocessing to improve smt quality.</citsent>
<aftsection>
<nextsent>(de gispert et al, 2009) <papid> N09-2019 </papid>adopted the minimum bayes risk decoding strategy to combine output from identical smt system, which is trained on alternative morphological decompositions of the source language.</nextsent>
<nextsent>meanwhile, the smt-based methods are widely used in the area of natural language processing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG123">
<title id=" W10-3222.xml">chained machine translation using morphemes as pivot language </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(watanabe et al, 2006) <papid> W06-3115 </papid>proposed method which uses porter stems and even 4-letter prefixes for word alignment.</prevsent>
<prevsent>(koehn et al, 2007) <papid> P07-2045 </papid>proposed the factored translation models which combine feature functions to handle syntactic,morphological, and other linguistic information in log-linear model during training.(minkov et al, 2007) <papid> P07-1017 </papid>made use of the information of morphological structure and source language in postprocessing to improve smt quality.</prevsent>
</prevsection>
<citsent citstr=" N09-2019 ">
(de gispert et al, 2009) <papid> N09-2019 </papid>adopted the minimum bayes risk decoding strategy to combine output from identical smt system, which is trained on alternative morphological decompositions of the source language.</citsent>
<aftsection>
<nextsent>meanwhile, the smt-based methods are widely used in the area of natural language processing.
</nextsent>
<nextsent>(quirk et al, 2004) applied smt to generate novel paraphrases.
</nextsent>
<nextsent>(riezler et al, 2007) <papid> P07-1059 </papid>adopted an smt-based 169 method to query expansion in answer retrieval.</nextsent>
<nextsent>(jiang and zhou, 2008) used smt to generate the second sentence of the chinese couplets.as opposed to the above strategies, the paper proposes an approach that uses morphemes as pivot language in chained smt system, for translating chinese into mongolian, which consists of two smt systems.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG124">
<title id=" W10-3222.xml">chained machine translation using morphemes as pivot language </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>meanwhile, the smt-based methods are widely used in the area of natural language processing.
</prevsent>
<prevsent>(quirk et al, 2004) applied smt to generate novel paraphrases.
</prevsent>
</prevsection>
<citsent citstr=" P07-1059 ">
(riezler et al, 2007) <papid> P07-1059 </papid>adopted an smt-based 169 method to query expansion in answer retrieval.</citsent>
<aftsection>
<nextsent>(jiang and zhou, 2008) used smt to generate the second sentence of the chinese couplets.as opposed to the above strategies, the paper proposes an approach that uses morphemes as pivot language in chained smt system, for translating chinese into mongolian, which consists of two smt systems.
</nextsent>
<nextsent>first, chinese sentences are translated into mongolian morphemes instead of mongolian words in the chinese morphemes smt (smt1).
</nextsent>
<nextsent>then mongolian words are generated from morphemes in themorphemes-mongolian smt (smt2).
</nextsent>
<nextsent>the essential part of the chained smt system is howto find the mapping relations between the morphemes and words, which is considered as procedure of machine translation in our approach.more concretely, the first challenge of this approach is to investigate some effective strategies to segment the mongolian corpus in the chinese mongolian parallel corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG125">
<title id=" W10-3222.xml">chained machine translation using morphemes as pivot language </title>
<section> chained smt system.  </section>
<citcontext>
<prevsection>
<prevsent>figure 2 illustrates the overview of chained smt system.
</prevsent>
<prevsent>3.2 phrase-based smt.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
the authors assume the reader to be familiar with current approaches to machine translation, so that we briefly introduce the phrase based statistical machine translation model(koehn et al, 2003) <papid> N03-1017 </papid>here, which is the foundation of chained smt system.</citsent>
<aftsection>
<nextsent>in statistical machine translation, given source language , the aim is to seek target language e, such that (e|f) is maximized.
</nextsent>
<nextsent>the phrase-based translation model can be expressed by the following formula: e?
</nextsent>
<nextsent>= argmax p (e|f) = argmax {p (f |e)p (e)} where e?
</nextsent>
<nextsent>indicates the best result, (e) is the language model and (f |e) is the translation model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG126">
<title id=" W10-3222.xml">chained machine translation using morphemes as pivot language </title>
<section> chained smt system.  </section>
<citcontext>
<prevsection>
<prevsent>= argmax p (e|f) = argmax {p (f |e)p (e)} where e?
</prevsent>
<prevsent>indicates the best result, (e) is the language model and (f |e) is the translation model.
</prevsent>
</prevsection>
<citsent citstr=" P02-1038 ">
according to the standard log-linear model proposed by (och and ney, 2002), <papid> P02-1038 </papid>thebest result e?</citsent>
<aftsection>
<nextsent>that maximizes (e|f) can be expressed as follows: e?
</nextsent>
<nextsent>= argmax { m?
</nextsent>
<nextsent>m=1 mhm(e, f)} where is the number of feature functions, is the corresponding feature weight, each hm(e, f) is feature function.
</nextsent>
<nextsent>in our chained smt system, smt1, smt2 and the smt for morphological segmentation(namely smt-ms in section 2) are all phrase based smts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG128">
<title id=" W10-3222.xml">chained machine translation using morphemes as pivot language </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the language model of mongolian word is 3-gram model with kneser-ney smoothing too.
</prevsent>
<prevsent>all the language models are built with the sri language modeling toolkit (stolcke, 2002).
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
the log-linear model feature weights are learned by using minimum error rate training (mert) (och, 2003) <papid> P03-1021 </papid>with bleu score (papineni et al, 2002) <papid> P02-1040 </papid>as the objective function.</citsent>
<aftsection>
<nextsent>4.2 corpus preprocessing.
</nextsent>
<nextsent>the chinese-mongolian parallel corpus and monolingual sentences are obtain from the 5th china workshop on machine translation.
</nextsent>
<nextsent>in the experiments, we first convert mongolian corpus into latin mongolian.
</nextsent>
<nextsent>in morphological segmentation, the gold standard morphological segmentation corpus contains 38000 mongolian sentences, which are produced semi automatically by using the morphological analyzer darhan (nashunwukoutu, 1997) of inner mongolia university.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG129">
<title id=" W10-3222.xml">chained machine translation using morphemes as pivot language </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the language model of mongolian word is 3-gram model with kneser-ney smoothing too.
</prevsent>
<prevsent>all the language models are built with the sri language modeling toolkit (stolcke, 2002).
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
the log-linear model feature weights are learned by using minimum error rate training (mert) (och, 2003) <papid> P03-1021 </papid>with bleu score (papineni et al, 2002) <papid> P02-1040 </papid>as the objective function.</citsent>
<aftsection>
<nextsent>4.2 corpus preprocessing.
</nextsent>
<nextsent>the chinese-mongolian parallel corpus and monolingual sentences are obtain from the 5th china workshop on machine translation.
</nextsent>
<nextsent>in the experiments, we first convert mongolian corpus into latin mongolian.
</nextsent>
<nextsent>in morphological segmentation, the gold standard morphological segmentation corpus contains 38000 mongolian sentences, which are produced semi automatically by using the morphological analyzer darhan (nashunwukoutu, 1997) of inner mongolia university.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG133">
<title id=" W10-3808.xml">arabic morphosyntactic feature disambiguation in a translation context </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>the arabic morphological analyzer used consists of set of all possible morphological analyses for each word, with the unique correct syntactic feature.
</prevsent>
<prevsent>we want to choose the correct features using the features generated by the morphological analyzer for the french language in the other side.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
to obtain this data, we used the results of the alignment of word trained with giza++ (och and ney, 2003).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>arabic is characterized by rich morphology.
</nextsent>
<nextsent>due to the fact that the arabic script usually does not encode short vowels, the degree of morphological ambiguity is very high.
</nextsent>
<nextsent>in addition to being inflected for gender, number, words can be attached to various clitics for conjunction  ?
</nextsent>
<nextsent>(and), the definite article  ??
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG134">
<title id=" W10-3808.xml">arabic morphosyntactic feature disambiguation in a translation context </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>he redefines the tagging task as choice among the tags proposed by the dictionary, using log-linear model trained on specific ambiguity classes for individual morphological features.
</prevsent>
<prevsent>hajic (2000) demonstrates convincingly that morphological disambiguation can be aided by morphological analyzer, which, given word without any context, gives us the set of all possible morphological tags.
</prevsent>
</prevsection>
<citsent citstr=" N04-4038 ">
the only work on arabic tagging that uses corpus for training and evaluation, (diab et al, 2004), <papid> N04-4038 </papid>does not use morphological analyzer.</citsent>
<aftsection>
<nextsent>diab et al (2004) <papid> N04-4038 </papid>perform tokenization, pos tagging and base phrase chunking using svm based learner.</nextsent>
<nextsent>the morphological analysis and disambiguation of arabic (mada) system is described in (habash and rambow, 2005).<papid> P05-1071 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG136">
<title id=" W10-3808.xml">arabic morphosyntactic feature disambiguation in a translation context </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the only work on arabic tagging that uses corpus for training and evaluation, (diab et al, 2004), <papid> N04-4038 </papid>does not use morphological analyzer.</prevsent>
<prevsent>diab et al (2004) <papid> N04-4038 </papid>perform tokenization, pos tagging and base phrase chunking using svm based learner.</prevsent>
</prevsection>
<citsent citstr=" P05-1071 ">
the morphological analysis and disambiguation of arabic (mada) system is described in (habash and rambow, 2005).<papid> P05-1071 </papid></citsent>
<aftsection>
<nextsent>the basic approach used in mada is inspired by the work of hajic (2000) for tagging morphologically rich languages, which was extended to arabic.
</nextsent>
<nextsent>habash and rambow (2005) <papid> P05-1071 </papid>use svm-classifiers for individual morphological features and simple combining scheme for choosing among competing analyses proposed by the dictionary.</nextsent>
<nextsent>arabic is morphologically complex language.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG139">
<title id=" W10-1714.xml">exodus  exploring smt for eu institutions </title>
<section> background </section>
<citcontext>
<prevsection>
<prevsent>first of all, they contain almost exclusively perfectly aligned segments, as each segment is stored together with its translation, and secondly, 110they contain cleaner data since their content is regularly maintained by linguists and database administrators.
</prevsent>
<prevsent>smt systems are quicker to develop and easier to maintain than rule-based systems.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
the availability of free, open-source software like moses2 (koehn et al., 2007), <papid> P07-2045 </papid>giza++3 (och and ney, 2003) <papid> J03-1002 </papid>and the like constitutes further argument in their favor.early experiments with moses were started by members of dgts portuguese language department as early as summer 2008 (leal fontes and machado, 2009), then turned into wider interinstitutional project with the codename exodus, currently combining resources from european commissions dgt and european parliaments dgtrad.</citsent>
<aftsection>
<nextsent>exodus is the first joint project of the interinstitutional language technology watch group where number of eu institutions join forces in the field of language technology.
</nextsent>
<nextsent>task after the english-portuguese experiments, the first language pair for which we developed system witha sizeable amount of training data was english-to french.
</nextsent>
<nextsent>this system has been developed for testing at the european parliament.
</nextsent>
<nextsent>as english-to-french is also one of the eight translation directions evaluated inthis years shared translation task, we decided to participate.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG140">
<title id=" W10-1714.xml">exodus  exploring smt for eu institutions </title>
<section> background </section>
<citcontext>
<prevsection>
<prevsent>first of all, they contain almost exclusively perfectly aligned segments, as each segment is stored together with its translation, and secondly, 110they contain cleaner data since their content is regularly maintained by linguists and database administrators.
</prevsent>
<prevsent>smt systems are quicker to develop and easier to maintain than rule-based systems.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
the availability of free, open-source software like moses2 (koehn et al., 2007), <papid> P07-2045 </papid>giza++3 (och and ney, 2003) <papid> J03-1002 </papid>and the like constitutes further argument in their favor.early experiments with moses were started by members of dgts portuguese language department as early as summer 2008 (leal fontes and machado, 2009), then turned into wider interinstitutional project with the codename exodus, currently combining resources from european commissions dgt and european parliaments dgtrad.</citsent>
<aftsection>
<nextsent>exodus is the first joint project of the interinstitutional language technology watch group where number of eu institutions join forces in the field of language technology.
</nextsent>
<nextsent>task after the english-portuguese experiments, the first language pair for which we developed system witha sizeable amount of training data was english-to french.
</nextsent>
<nextsent>this system has been developed for testing at the european parliament.
</nextsent>
<nextsent>as english-to-french is also one of the eight translation directions evaluated inthis years shared translation task, we decided to participate.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG141">
<title id=" W10-1714.xml">exodus  exploring smt for eu institutions </title>
<section> building the models and decoding.  </section>
<citcontext>
<prevsection>
<prevsent>the parallel data described above was used to train anenglish-to-french translation model and french target language model.
</prevsent>
<prevsent>this was done on server running sun solaris with 64 gb of ram and 8 double core cpus @1800 mhz (albeit shared with other processes running simultaneously).in general, we simply used vanilla moses installation at this point, leaving the integration of more sophisticated features to later moment, i.e. after thorough analysis of the results of the present evaluation campaign when we will know which adaptations yield the most significant improvements.
</prevsent>
</prevsection>
<citsent citstr=" W08-0509 ">
for the word alignments, we chose mgiza (gaoand vogel, 2008), <papid> W08-0509 </papid>using seven threads per mgiza instance, with the parallel option, i.e. one mgiza instance per pair direction running in parallel.</citsent>
<aftsection>
<nextsent>the target language model is 7-gram, binarized irstlm (federico et al, 2008).
</nextsent>
<nextsent>the weights of the distortion, translation and language models were optimized with respect to bleu scores (papineni et al, 2002) <papid> P02-1040 </papid>on given held-out set of sentences with minimum error rate training (mert; (och, 2003)) <papid> P03-1021 </papid>in 15 iterations.</nextsent>
<nextsent>after the actual translation with moses, an additional re casing translation?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG142">
<title id=" W10-1714.xml">exodus  exploring smt for eu institutions </title>
<section> building the models and decoding.  </section>
<citcontext>
<prevsection>
<prevsent>for the word alignments, we chose mgiza (gaoand vogel, 2008), <papid> W08-0509 </papid>using seven threads per mgiza instance, with the parallel option, i.e. one mgiza instance per pair direction running in parallel.</prevsent>
<prevsent>the target language model is 7-gram, binarized irstlm (federico et al, 2008).</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
the weights of the distortion, translation and language models were optimized with respect to bleu scores (papineni et al, 2002) <papid> P02-1040 </papid>on given held-out set of sentences with minimum error rate training (mert; (och, 2003)) <papid> P03-1021 </papid>in 15 iterations.</citsent>
<aftsection>
<nextsent>after the actual translation with moses, an additional re casing translation?
</nextsent>
<nextsent>model was applied in the samemanner.
</nextsent>
<nextsent>finally, the translation output underwent minimal automatic postprocessing based on regular expression replacements.
</nextsent>
<nextsent>this was mainly undertaken in order to fix the distribution of whit espace and some remaining capitalization issues.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG143">
<title id=" W10-1714.xml">exodus  exploring smt for eu institutions </title>
<section> building the models and decoding.  </section>
<citcontext>
<prevsection>
<prevsent>for the word alignments, we chose mgiza (gaoand vogel, 2008), <papid> W08-0509 </papid>using seven threads per mgiza instance, with the parallel option, i.e. one mgiza instance per pair direction running in parallel.</prevsent>
<prevsent>the target language model is 7-gram, binarized irstlm (federico et al, 2008).</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
the weights of the distortion, translation and language models were optimized with respect to bleu scores (papineni et al, 2002) <papid> P02-1040 </papid>on given held-out set of sentences with minimum error rate training (mert; (och, 2003)) <papid> P03-1021 </papid>in 15 iterations.</citsent>
<aftsection>
<nextsent>after the actual translation with moses, an additional re casing translation?
</nextsent>
<nextsent>model was applied in the samemanner.
</nextsent>
<nextsent>finally, the translation output underwent minimal automatic postprocessing based on regular expression replacements.
</nextsent>
<nextsent>this was mainly undertaken in order to fix the distribution of whit espace and some remaining capitalization issues.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG144">
<title id=" W10-1919.xml">towards event extraction from full texts on infectious diseases </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(rzhetsky et al, 2004)) have been introduced.
</prevsent>
<prevsent>a number of recent studies have proposed more expressive representations of extracted information, introducing resources supporting advanced ie approaches (pyysalo et al, 2007; kim et al, 2008; thompson et al, 2009; ananiadou et al, 2010a).
</prevsent>
</prevsection>
<citsent citstr=" W09-1401 ">
a significant step in the development of domain ie methods capable of extracting this class of representations was taken in the bionlp09 shared task on event extraction, where24 teams participated in an ie task setting requiring the extraction of structured representations of multi-participant biological events of several types (kim et al, 2009).<papid> W09-1401 </papid>while the introduction of structured event extraction resources and methods has notably advanced the state of the art in biomedical ie representations, the focus of event extraction studies carries other limitations frequently encountered in domain ie efforts.</citsent>
<aftsection>
<nextsent>specifically, resources annotated for biomedical events contain exclusively texts from publication abstracts, typically further drawn from small sub domains of molecular biology.
</nextsent>
<nextsent>these choices constrain not only the types oftexts but also the types of events considered, restricting the applicability of event extraction.
</nextsent>
<nextsent>this paper presents results from one ongoing effort to extend an event extraction approach over these boundaries, toward event extraction from full text documents in the domain of infectious diseases.
</nextsent>
<nextsent>in this study, we consider the sub domain related to type iv secretion systems as model sub domain of interest within the broad infectious diseases domain.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG146">
<title id=" W10-1919.xml">towards event extraction from full texts on infectious diseases </title>
<section> annotation.  </section>
<citcontext>
<prevsection>
<prevsent>3.2 gene/gene product annotation.
</prevsent>
<prevsent>as gene and gene product entities are central to domain information needs and the core entities ofthe applied event extraction approach, we first introduced annotation for this entity class.
</prevsent>
</prevsection>
<citsent citstr=" W09-1313 ">
we created manual ggp annotation following the annotation guidelines of the genia ggp corpus (ohta et al, 2009).<papid> W09-1313 </papid></citsent>
<aftsection>
<nextsent>as this corpus was the source of the gene/protein entity annotation provided asthe basis of the bionlp shared task on event extraction, adopting its annotation criteria assures compatibility with recently introduced event extraction methods.
</nextsent>
<nextsent>briefly, the guidelines specify tagging for minimal continuous spans of specific gene/gene product names, without differentiating between dna/rna/protein.
</nextsent>
<nextsent>a specific name?
</nextsent>
<nextsent>is understood to be a name that allowsa domain expert to identify the entry in relevant database (entrez gene/uniprot) that the name refers to.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG150">
<title id=" W10-2006.xml">close  relevant the role of context inefficient language production </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in fact, the most efficient code requires language users to encode messages into signals of the entropy bounded by the capacity of the channel.
</prevsent>
<prevsent>one implication of this efficient encoding is that over time, the entropy of the signals is constant.
</prevsent>
</prevsection>
<citsent citstr=" P02-1026 ">
one of the first studies to investigate such constancy is genzel and charniak (2002), <papid> P02-1026 </papid>in which the authors proposed the constant entropy rate (cer)hypothesis: in written text, the entropy per signal symbol is constant across sentence positions in discourses.</citsent>
<aftsection>
<nextsent>that is, if we view sentence positions as measure of time steps, then the entropy per word at each step should be the same in order to achieve efficient communication (word is selected as the unit of signal, although it does not have to 45 be case; cf.
</nextsent>
<nextsent>qian and jaeger (2009)).
</nextsent>
<nextsent>the difficulty in testing this direct prediction is computationally specifying the code used by human speakers to obtain context-sensitive estimate of the entropy per word.
</nextsent>
<nextsent>an ngram model overestimates the entropy of upcoming messages by relying on only the preceding n-1 words within sentence, while in reality the upcoming message is also constrained by extra-sentential context that accumulates within discourse.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG152">
<title id=" W10-2006.xml">close  relevant the role of context inefficient language production </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the more extra sentential context that the ngram model ignores, the higher estimate for entropy will be.
</prevsent>
<prevsent>hence, the cer hypothesis indirectly predicts that the entropy of signals, as estimated by ngrams, will increase across sentence positions.
</prevsent>
</prevsection>
<citsent citstr=" W03-1009 ">
while some studies have found the predicted positive correlation between sentence position and the per-word entropy of signals estimated by ngrams, most of them assumed the correlation to be linear (genzel and charniak, 2002; <papid> P02-1026 </papid>genzel and charniak, 2003;<papid> W03-1009 </papid>keller, 2004; <papid> W04-3241 </papid>piantadosi and gibson, 2008).</citsent>
<aftsection>
<nextsent>how ever, in previous work, we found that log-linear regression model was better fit for empirical data than simple linear regression model based ondata of 12 languages (qian and jaeger, under re view).
</nextsent>
<nextsent>why this would be case remained puzzle.
</nextsent>
<nextsent>our research question is closely related to this indirect prediction of the constant entropy rate hypothesis.
</nextsent>
<nextsent>intuitively, the number of possible messages that speaker can choose from for an upcoming signal in discourse is often restricted by the presence of discourse context.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG153">
<title id=" W10-2006.xml">close  relevant the role of context inefficient language production </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the more extra sentential context that the ngram model ignores, the higher estimate for entropy will be.
</prevsent>
<prevsent>hence, the cer hypothesis indirectly predicts that the entropy of signals, as estimated by ngrams, will increase across sentence positions.
</prevsent>
</prevsection>
<citsent citstr=" W04-3241 ">
while some studies have found the predicted positive correlation between sentence position and the per-word entropy of signals estimated by ngrams, most of them assumed the correlation to be linear (genzel and charniak, 2002; <papid> P02-1026 </papid>genzel and charniak, 2003;<papid> W03-1009 </papid>keller, 2004; <papid> W04-3241 </papid>piantadosi and gibson, 2008).</citsent>
<aftsection>
<nextsent>how ever, in previous work, we found that log-linear regression model was better fit for empirical data than simple linear regression model based ondata of 12 languages (qian and jaeger, under re view).
</nextsent>
<nextsent>why this would be case remained puzzle.
</nextsent>
<nextsent>our research question is closely related to this indirect prediction of the constant entropy rate hypothesis.
</nextsent>
<nextsent>intuitively, the number of possible messages that speaker can choose from for an upcoming signal in discourse is often restricted by the presence of discourse context.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG154">
<title id=" W10-1502.xml">building a korean web corpus for analyzing learner language </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as first step, however, we must acquire data, and thus we present methodology for constructing large-scale corpora of korean from the web, exploring the feasibility of building corpora appropriate forgiven topic and grammatical construction.
</prevsent>
<prevsent>applications for assisting second language learners can be extremely useful when they make learners more aware of the non-native characteristics in their writing (amaral and meurers, 2006).
</prevsent>
</prevsection>
<citsent citstr=" C08-1109 ">
certain constructions, such as english prepositions, are difficult to characterize by grammar rules and thus are well suited for machine learning approaches (tetreault and chodorow, 2008; <papid> C08-1109 </papid>de felice and pulman, 2008).</citsent>
<aftsection>
<nextsent>machine learning techniques are relatively portable to new languages, but new languages bring issues in terms of defining the language learning problem and in terms of acquiring appropriate data for training machine learner.
</nextsent>
<nextsent>we focus in this paper mainly on acquiring datafor training machine learning system.
</nextsent>
<nextsent>in particular, we are interested in situations where the task is constante.g., detecting grammatical errors in particles but the domain might fluctuate.
</nextsent>
<nextsent>this is the case when learner is asked to write an essay on prompt (e.g., what do you hope to do in life??), and the prompts may vary by student, by semester, by instructor, etc. by isolating particular domain, we can hope for greater degrees of accuracy; see, for example, the high accuracies for domain-specific grammar correction in lee and seneff (2006).in this situation, we face the challenge of obtaining data which is appropriate both for: a) the topic the learners are writing about, and b) the linguistic construction of interest, i.e., containing enough relevant instances.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG155">
<title id=" W10-1502.xml">building a korean web corpus for analyzing learner language </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>korean is an important language to develop nlp techniques for (see, e.g., discussion in dickinson et al, 2008), presenting variety of features which are less prevalent in many western languages, such as agglutinative morphology, rich system of case marking, and relatively free word order.
</prevsent>
<prevsent>obtaining data is important in the general case, as non-english languages tend to lack resources.
</prevsent>
</prevsection>
<citsent citstr=" I05-1052 ">
the correct usage of korean particles relies on knowing lexical, syntactic, semantic, and discourse information (lee et al, 2005), <papid> I05-1052 </papid>which makes this challenging for both learners and machines (cf.</citsent>
<aftsection>
<nextsent>en 8 glish determiners in han et al, 2006).
</nextsent>
<nextsent>the only other approach we know of, parser-based one, had very low precision (dickinson and lee, 2009).
</nextsent>
<nextsent>asecondary contribution of this work is thus defining the particle error detection problem forma chine learner.
</nextsent>
<nextsent>it is important that the data represent the relationships between specific lexical items: in the comparable english case, for example, interest is usually found with in: interest in/*with learning.the basic framework we employ is to train machine learner on correct korean data and then apply this system to learner text, to predict correct particle usage, which may differ from the learners (cf.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG161">
<title id=" W10-2605.xml">using domain similarity for performance estimation </title>
<section> experimental design.  </section>
<citcontext>
<prevsection>
<prevsent>these annotated semantic domains are: imaginative (wridom1), natural &amp; pure science (wridom2), applied science(wridom3), social science (wridom4), world affairs (wridom5), commerce &amp; finance (wridom6), arts (wridom7), belief &amp; thought (wridom8), and leisure (wridom9).
</prevsent>
<prevsent>the extracted corpus contains sentences in which every token is tagged with part-of-speech tag as defined by the bnc.
</prevsent>
</prevsection>
<citsent citstr=" C94-1103 ">
since the bnc hasbeen tagged automatically, using the claws4 automatic tagger (leech et al, 1994) <papid> C94-1103 </papid>and the template tagger (pacey et al, 1997), the experiments in this article are artificial in the sense that they donot learn real part-of-speech tags but rather partof-speech tags as they are assigned by the automatic taggers.</citsent>
<aftsection>
<nextsent>3.2 similarity metrics.
</nextsent>
<nextsent>to measure the difference between two corpora we implemented six similarity metrics: renyi2 (renyi, 1961), variational (l1) (lee, 2001), euclidean (lee, 2001), cosine (lee, 2001), kullback-leibler (kullback and leibler, 1951) and bhattacharyya coefficient (comaniciu et al, 2003; bhattacharyya, 1943).
</nextsent>
<nextsent>we selected these measures because they are well-described and produce results for this task in an acceptable time span.the metrics are computed using the relative frequencies of words.
</nextsent>
<nextsent>for example, to calculate the 1this is done by selecting texts with bnc category codes for text type (i.e. alltyp3 (written books and periodicals)) and for medium (i.e. wrimed1 (book), wrimed2 (periodical), and wrimed3 (miscellaneous: published)).2the renyi divergence has parameter ? and kull back leibler is special case of the renyi divergence, viz.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG162">
<title id=" W10-2605.xml">using domain similarity for performance estimation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>for majority the average accuracy over all domains is 88.25% (stdev: 0.87), for mbt 94.07% (0.63), and for svmtool 95.06% (0.59).
</prevsent>
<prevsent>which are, as expected, higher scores than the figures in table 1.
</prevsent>
</prevsection>
<citsent citstr=" P08-1034 ">
in articles dealing with the influence of domain shifts on the performance of an nlp tool, the in-domain data and out-of-domain data are taken from different corpora, e.g., sentences from movie snippets, newspaper texts and personal weblogs(andreevskaia and bergler, 2008).<papid> P08-1034 </papid></citsent>
<aftsection>
<nextsent>it can be expected that these corpora are indeed dissimilar enough to consider them as separate domains, but no objective measure has been used to define them as such.
</nextsent>
<nextsent>the fact that the nlp tool produces lower results for cross-domain experiments can betaken as an indication of the presence of separate domains.
</nextsent>
<nextsent>a nice overview paper on statistical domain adaptation can be found in bellegarda (2004).
</nextsent>
<nextsent>a way to express the degree of relatedness, apart from this well-known accuracy drop, can be found in daume?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG163">
<title id=" W10-2605.xml">using domain similarity for performance estimation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>low values of pi mean that in-domain and out-of-domain data differ significantly.
</prevsent>
<prevsent>they also used kullback-leibler divergence to compute the similarity between unigram language models.
</prevsent>
</prevsection>
<citsent citstr=" P07-1056 ">
blitzer et al (2007) <papid> P07-1056 </papid>propose supervised wayof measuring the similarity between the two do mains.</citsent>
<aftsection>
<nextsent>they compute the huber loss, as proxy of the a-distance (kifer et al, 2004), for every instance that they labeled with their tool.
</nextsent>
<nextsent>there sulting measure correlates with the adaptation loss they observe when applying sentiment classification tool on different domains.
</nextsent>
<nextsent>this paper showed that it is possible to narrow down the prediction of the accuracy of an nlp tool on an unannotated corpus by measuring the similarity between this unannotated corpus and the corpus the tagger was trained on in an unsupervised way.
</nextsent>
<nextsent>a prerequisite to be able to make reliable prediction, is to have sufficient annotated data to measure the correlation between the accuracy and metric.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG164">
<title id=" W10-0904.xml">large scale relation detection </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>these sources of structured knowledge can provide large number of seed tuples for many different relations.
</prevsent>
<prevsent>this is discussed further below.furthermore, the all-tail nature of relation cover age led us to consider performing relation extraction on multiple relations at once.
</prevsent>
</prevsection>
<citsent citstr=" W09-2201 ">
some promising results on multi-relation learning have already been reported in (carlson et al, 2009), <papid> W09-2201 </papid>and the data sources mentioned above give us many more than just the handful of seed instances used in those experiments.</citsent>
<aftsection>
<nextsent>the idea of learning multiple relations at once also fits with our keep reading principle - multiple relation hypotheses may be annotated between the same arguments, with further evidence helping to disambiguate them.
</nextsent>
<nextsent>one common approach to relation extraction is tostart with seed tuples and find sentences that contain mentions of both elements of the tuple.
</nextsent>
<nextsent>from each such sentence pattern is generated using at minimum universal generalization (replace the tuple elements with variables), though adding any form of generalization here can significantly improve recall.
</nextsent>
<nextsent>finally, evaluate the patterns by applying them totext and evaluating the precision and recall of the tu ples extracted by the patterns.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG165">
<title id=" W10-0904.xml">large scale relation detection </title>
<section> approach.  </section>
<citcontext>
<prevsection>
<prevsent>thus far we have only experimented with two pattern representations: simple lexical patterns in which the known arguments are replaced in the sentence by variables (as shown in the example above), and patterns based on the spanning tree between the two arguments in dependency parse, again with the known arguments replaced by variables.
</prevsent>
<prevsent>in our initial design we downplayed the importance of the pattern representation and especially generalization, with the belief that very large scale would remove the need to generalize.
</prevsent>
</prevsection>
<citsent citstr=" P06-1015 ">
however, our initial experiments suggest that good pattern generalization would have significant impact on recall, without negative impact on precision, which agrees with findings in the literature (pantel and pennacchiotti, 2006).<papid> P06-1015 </papid></citsent>
<aftsection>
<nextsent>thus, these early results only employ rudimentary pattern generalization techniques, though this is an area we intend to improve.
</nextsent>
<nextsent>we discuss some more details of the lack of generalization below.
</nextsent>
<nextsent>in this section we present set of very early proof of concept experiments performed using drastic simplifications of the lsrd design.
</nextsent>
<nextsent>we began, in fact, by 29 relation prec rec f1 tuples seeds imdb:actedin 46.3 45.8 0.46 9m 30k frb:authorof 23.4 27.5 0.25 2m 2m imdb:directorof 22.8 22.4 0.22 700k 700k frb:parentof 68.2 8.6 0.16 10k 10k table 1: precision and recall vs. number of tuples used for 4 free base relations.using single-relation experiments, despite the centrality of multiple hypotheses to our reading system, in order to facilitate evaluation and understanding of the technique.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG166">
<title id=" W10-0904.xml">large scale relation detection </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>at the moment the former sentence generates four patterns that require the director and dates to be exactly the same.
</prevsent>
<prevsent>some articles in the corpus were biographies which were rich with relation content but also with pervasive anaphora, name abbreviations, and other coreference manifestations that severely hampered induction and evaluation.
</prevsent>
</prevsection>
<citsent citstr=" P08-1004 ">
early work in semi-supervised learning techniques such as co-training and multi-view learning (blum and mitchell, 1998) laid much of the ground workfor subsequent experiments in boot strapped learning for various nlp tasks, including named entity detection (craven et al, 2000; etzioni et al, 2005) and document classification (nigam et al, 2006).this works pattern induction technique also represents semi-supervised approach, here applied to relation learning, and at face value is similar in motivation to many of the other reported experiments in large scale relation learning (banko and etzioni, 2008; <papid> P08-1004 </papid>yates and etzioni, 2009; carlson et al, 2009; <papid> W09-2201 </papid>carlson et al, 2010).</citsent>
<aftsection>
<nextsent>however, previous techniques generally relyon small set of example relation instances and/or patterns, whereas here we explicitly require larger source of relation instances for pattern induction and training.
</nextsent>
<nextsent>this allows us to better evaluate the precision of all learned patterns across multiple relation types, as well as improve coverage 31 of the pattern space for any given relation.
</nextsent>
<nextsent>another fundamental aspect of our approach lies in the fact that we attempt to learn many relations simultaneously.
</nextsent>
<nextsent>previously, (whitelaw et al, 2008)found that such joint learning approach was useful for large-scale named entity detection, and we expect to see this result carry over to the relation extraction task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG168">
<title id=" W10-0904.xml">large scale relation detection </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>these also bear striking similarity to (agichtein and gravano, 2000), and all suffer from significantly smaller number of seed examples.
</prevsent>
<prevsent>indeed, its not using database of specific tuples that distinguishes lsrd, but that it uses so many; the scale of the induction in lsrd is designed to capture far less frequent patterns by using significantly more seedsin (ramakrishnan et al, 2006) the same intuition is captured that knowledge of the structure ofa database should be employed when trying to interpret text, though again the three basic hypotheses of lsrd are not supported.
</prevsent>
</prevsection>
<citsent citstr=" W04-1204 ">
in (huang et al, 2004), <papid> W04-1204 </papid>similar phenomenon to what we observed with the acted-in-movie relation was reported in which the chances of protein interaction relation being expressed in sentence are already quite high if two proteins are mentioned in that sentence.</citsent>
<aftsection>
<nextsent>we have presented an approach for large scale relation detection (lsrd) that is intended to be used within machine reading system as source of hypothetical interpretations of input sentences in natural language.
</nextsent>
<nextsent>the interpretations produced are semantic relations between named arguments in the sentences, and they are produced by using large knowledge source to generate many possible patterns for expressing the relations known by that source.
</nextsent>
<nextsent>we have specifically targeted the technique at the problem that the frequency of patterns occurring in text that express particular relation has very long tail (see figure 1), and without enough seed examples the extremely infrequent expressions of there lation will never be found and learned.
</nextsent>
<nextsent>further, we do not commit to any learning strategy at this stage of processing, rather we simply produce counts, foreach relation, of how often particular pattern produces tuples that are in that relation, and how often it doesnt. these counts are simply used as evidence for different possible interpretations, which can be supported or refuted by other components in the reading system, such as type detection.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG169">
<title id=" W10-3704.xml">automatic extraction of arabic multiword expressions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>accommodating mwes in nlp applications has been reported to improve tasks, such as text mining (sanjuan and ibekwesanjuan, 2006), syntactic parsing (nivre and nilsson, 2004; attia, 2006), and machine translation (deksne, 2008).
</prevsent>
<prevsent>there are two basic criteria for identifyingmwes: first, component words exhibit statistically significant co-occurrence, and second, they show certain level of semantic opaqueness ornon-compositionality.
</prevsent>
</prevsection>
<citsent citstr=" W04-0411 ">
statistically significant cooccurrence can give good indication of how likely sequence of words is to form an mwe.this is particularly interesting for statistical techniques which utilize the fact that large number of mwes are composed of words that co-occur together more often than can be expected by chance.the compositionality, or decomposabil ity (villavicencio et al 2004), <papid> W04-0411 </papid>of mwes is alsoa core issue that presents challenge for nlp applications because the meaning of the expression is not directly predicted from the meaning of the component words.</citsent>
<aftsection>
<nextsent>in this respect, compositionalily varies between phrases that are highly com 19 positional, such as,
</nextsent>
<nextsent>          qfla idatun askariyyatun, military base?, and those that show degree of idiomaticity, such as,
</nextsent>
<nextsent>          madiynatu l-malflahiy, amusement park?, lit.
</nextsent>
<nextsent>city of amusements?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG170">
<title id=" W10-3704.xml">automatic extraction of arabic multiword expressions </title>
<section> methodology.  </section>
<citcontext>
<prevsection>
<prevsent>asymmetries in this approach, our focus is on semantic nondecomposable mwes and we relyon cross lin gual correspondence asymmetries (ccas) for capturing them.
</prevsent>
<prevsent>semantic non-compositionality can be considered as powerful indication that aphrase is an mwe.
</prevsent>
</prevsection>
<citsent citstr=" W03-1812 ">
baldwin et al (2003) <papid> W03-1812 </papid>classify mwes, with respect to compositionality, into three categories: (a) non-compositional mwes,where the expression is semantically impenetrable, such as hot dog, (b) idiosyncratic ally compositional, where the component words are forced to take semantics unavailable outside the mwe,such as radar footprint, and (c) simply composi 4in arabic, the adjective follows the noun.</citsent>
<aftsection>
<nextsent>21 tional, where the phrase is institutionalized, such as trafc light.
</nextsent>
<nextsent>this, however, can only serve as an approximation, not as clear-cut division.
</nextsent>
<nextsent>as moon (1998) indicates, compositionality can be viewed more as gradient along continuum with no clear demarcations, ranging from conven tional ized, fully transparent literal expressions to completely opaque idioms.there are many signs, or indications, of non compositionality, two well-known among themare non-substitutability?, when word in the expression cannot be substituted by semantically equivalent word, and single-word paraphrasabil ity?, when the expression can be paraphrased or translated by single word.
</nextsent>
<nextsent>these two indications have been exploited differently by different researchers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG171">
<title id=" W10-3704.xml">automatic extraction of arabic multiword expressions </title>
<section> methodology.  </section>
<citcontext>
<prevsection>
<prevsent>these two indications have been exploited differently by different researchers.
</prevsent>
<prevsent>van de cruys and moiron(2006) develop an unsupervised method for detecting mwes using clusters of semantically related words and taking the ratio of the word preference over the cluster preference as an indication of how likely particular expression is tobe an mwe.
</prevsent>
</prevsection>
<citsent citstr=" W97-0311 ">
melamed (1997) <papid> W97-0311 </papid>investigates techniques for identifying non-compositional compounds in english-french parallel corpora and emphasises that translation models that take non compositional compounds into account are more accurate.</citsent>
<aftsection>
<nextsent>moiron and tiedemann (2006) use word alignment of parallel corpora to locate the translation of an mwe in target language and decide whether the original expression is idiomatic or literal.
</nextsent>
<nextsent>the technique used here is inspired by that ofzarrie?
</nextsent>
<nextsent>and kuhn (2009) who relyon the linguistic intuition that if group of words in one language is translated as single word in another language, this can be considered as an indication that we have fixed expression with non compositional meaning.
</nextsent>
<nextsent>they applied their data driven method to the german-english section ofthe europarl corpus after preprocessing with dependency parsing and word alignment, and tested their method on four german verb lemmas.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG172">
<title id=" W10-2405.xml">transliteration generation and mining with limited training resources </title>
<section> transliteration generation.  </section>
<citcontext>
<prevsection>
<prevsent>the generated alignments provide hypotheses of substring mappings in the training data.
</prevsent>
<prevsent>given aligned training data, transliteration model is trained to generate names in the target language given names in the source language.
</prevsent>
</prevsection>
<citsent citstr=" N07-1047 ">
the m2m-aligner (jiampojamarn et al, 2007) <papid> N07-1047 </papid>is based on the expectation maximization (em)algorithm.</citsent>
<aftsection>
<nextsent>it allows us to create alignments between sub strings of various lengths.
</nextsent>
<nextsent>we optimized the maximum substring sizes for the source and target based on the performance of the end task on the development sets.
</nextsent>
<nextsent>we allowed empty strings (nulls) only on the target side.
</nextsent>
<nextsent>we used the m2m-aligner for all alignment tasks, except for english-pinyin alignment.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG173">
<title id=" W10-2405.xml">transliteration generation and mining with limited training resources </title>
<section> transliteration generation.  </section>
<citcontext>
<prevsection>
<prevsent>the sequences of phonemes on the source side and the target side can then be aligned on the basis of phonetic 2http://code.google.com/p/m2m-aligner/ a c - a | | | | | | | | a - u - figure 1: an alignment example.similarity between phonemes.
</prevsent>
<prevsent>the main advantage of the phonetic alignment is that it requires no training data.
</prevsent>
</prevsection>
<citsent citstr=" A00-2038 ">
we use the aline phonetic aligner (kondrak, 2000), <papid> A00-2038 </papid>which aligns two strings of phonemes.</citsent>
<aftsection>
<nextsent>the example in figure 1 shows the alignment of the word barclay to its katakana transliteration ba-ku-ri.
</nextsent>
<nextsent>the one-to-one alignment can then be converted to many-to-many alignment by grouping the japanese phonemes that correspond to individual katakana symbols.
</nextsent>
<nextsent>2.3 directl+.
</nextsent>
<nextsent>we refer to our present approach to transliteration as directl+.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG174">
<title id=" W10-2405.xml">transliteration generation and mining with limited training resources </title>
<section> transliteration mining.  </section>
<citcontext>
<prevsection>
<prevsent>however, the seed pairs do provide example transliterations, and these can be used as positive training examples.
</prevsent>
<prevsent>the remaining issue is how to select the negative examples.we adopt two approaches for selecting negatives.
</prevsent>
</prevsection>
<citsent citstr=" P07-1083 ">
first, we generate all possible source-target pairs in the seed data, and take as negatives those pairs which are not transliterations but have longest common sub sequence ratio (lcsr) above 0.58; this mirrors the approach used by bergsma and kondrak (2007).<papid> P07-1083 </papid></citsent>
<aftsection>
<nextsent>the method assumes that the source and target words are written in the same script (e.g., the foreign word has been romanized).a second possibility is to generate all seed pairings as above, but then randomly select negative examples, thus mirroring the approach in klementiev and roth (2006).<papid> N06-1011 </papid></nextsent>
<nextsent>in this case, the source and target scripts do not need to be the same.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG177">
<title id=" W10-2405.xml">transliteration generation and mining with limited training resources </title>
<section> transliteration mining.  </section>
<citcontext>
<prevsection>
<prevsent>the remaining issue is how to select the negative examples.we adopt two approaches for selecting negatives.
</prevsent>
<prevsent>first, we generate all possible source-target pairs in the seed data, and take as negatives those pairs which are not transliterations but have longest common sub sequence ratio (lcsr) above 0.58; this mirrors the approach used by bergsma and kondrak (2007).<papid> P07-1083 </papid></prevsent>
</prevsection>
<citsent citstr=" N06-1011 ">
the method assumes that the source and target words are written in the same script (e.g., the foreign word has been romanized).a second possibility is to generate all seed pairings as above, but then randomly select negative examples, thus mirroring the approach in klementiev and roth (2006).<papid> N06-1011 </papid></citsent>
<aftsection>
<nextsent>in this case, the source and target scripts do not need to be the same.
</nextsent>
<nextsent>compared with the lcsr technique, random sampling in this manner has the potential to produce negative examples that are very easy?
</nextsent>
<nextsent>(i.e., clearly nottransliterations), and which may be of limited utility when training classifier.
</nextsent>
<nextsent>on the other hand, at test time, the set of candidates extracted from the wikipedia data will include pairs that have verylow lcsr scores; hence, it can be argued that dissimilar pairs should also appear as negative examples in the training set.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG185">
<title id=" W10-2405.xml">transliteration generation and mining with limited training resources </title>
<section> transliteration mining.  </section>
<citcontext>
<prevsection>
<prevsent>one particularly successful approach is by bergsma and kondrak (2007), <papid> P07-1083 </papid>who use discriminative learning with an improved feature repre sentation.</prevsent>
<prevsent>the features are substring pairs that are consistent with character-level alignment of thetwo strings.</prevsent>
</prevsection>
<citsent citstr=" D08-1037 ">
this approach strongly improved performance on cognate identification, while variations of it have also proven successful in transliteration discovery (goldwasser and roth, 2008).<papid> D08-1037 </papid></citsent>
<aftsection>
<nextsent>we therefore adopted this approach for the transliteration mining task.
</nextsent>
<nextsent>we produce negative training examples using the lcsr threshold approach described in section 3.2.
</nextsent>
<nextsent>for features, we extract from the aligned word pairs all substring pairs up to maximum length of three.
</nextsent>
<nextsent>we also append characters marking the beginning and end of words, as described in bergsma and kondrak (2007).<papid> P07-1083 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG192">
<title id=" W10-2405.xml">transliteration generation and mining with limited training resources </title>
<section> transliteration mining.  </section>
<citcontext>
<prevsection>
<prevsent>3.4 english-chinese string matching.
</prevsent>
<prevsent>due to the fact that names transliterated into chinese consist of multiple chinese characters and that the chinese text provided in this shared taskis not segmented, we have to adopt different approach to the english-chinese mining task (unlikemany other languages, there are no clear boundaries between chinese words).
</prevsent>
</prevsection>
<citsent citstr=" P08-1103 ">
we first train agen eration model using the seed data and then apply greedy string matching algorithm to extract transliteration pairs.the generation model is built using the discriminative training framework described in (jiampoja marn et al, 2008).<papid> P08-1103 </papid></citsent>
<aftsection>
<nextsent>two models are learned: one is trained using english and chinese characters, while the other is trained on english and pinyin (astandard phonetic representation of chinese char acters).
</nextsent>
<nextsent>in order to mine transliteration pairs from wikipedia titles, we first use the generation model to produce transliterations for each english token on the source side as both chinese characters andpinyin.
</nextsent>
<nextsent>the generated chinese characters are ultimately converted to pinyin during string matching.
</nextsent>
<nextsent>we also convert all the chinese characters on the target side to their pinyin representations when performing string matching.the transliteration pairs are then mined by combining two different strategies.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG193">
<title id=" W10-2405.xml">transliteration generation and mining with limited training resources </title>
<section> transliteration mining.  </section>
<citcontext>
<prevsection>
<prevsent>in this case, the number of tokens on both sides is often equal.
</prevsent>
<prevsent>therefore, the mining task can be formulated as matching problem.
</prevsent>
</prevsection>
<citsent citstr=" J00-2004 ">
we use competitive linking approach (melamed, 2000) <papid> J00-2004 </papid>to find the best match.</citsent>
<aftsection>
<nextsent>first, we select links between all possible pairs if similarity of strings on both sides is above threshold (0.6 ? length(pinyin)).
</nextsent>
<nextsent>we then greedily extract the pairs with highest similarity until the number of un extracted segments on either side becomes zero.
</nextsent>
<nextsent>the problem becomes harder when there is no indication of word segmentation for chinese.
</nextsent>
<nextsent>instead of trying to segment the chinese characters first, we use an incremental string matching strat 45egy.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG194">
<title id=" W10-3604.xml">a paradigm based finite state morphological analyzer for marathi </title>
<section> motivation and problem definition.  </section>
<citcontext>
<prevsection>
<prevsent>hence, although apprehensible this model is not sufficient for handling the morphology of marathi.
</prevsent>
<prevsent>many morphological analyzers have been developed using the two-level morphological model (koskenniemi, 1983) for morphological analysis.
</prevsent>
</prevsection>
<citsent citstr=" E93-1066 ">
(oflazer, 1993; <papid> E93-1066 </papid>kim et al., 1994) <papid> C94-1087 </papid>have been developed using pc kimmo (antworth, 1991), morphological parser based on the two-level model.</citsent>
<aftsection>
<nextsent>conceptually, the model segments the word in its constituent parts, and accounts for phonological and ortho graphical changes within word.
</nextsent>
<nextsent>while, the model proves to be very useful for developing the morphological analyzers for agglutina tive languages or the languages with very less degree of inflection, it fails to explicitly capture the regularities within and between paradigms present in the inflectional languages.
</nextsent>
<nextsent>marathi has well defined paradigm-based system of inflection.
</nextsent>
<nextsent>hence, we decided to develop our own model which works on the similar lines of pc-kimmo (antworth, 1991) but exploits the 26usefulness of paradigm-based inflectional system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG195">
<title id=" W10-3604.xml">a paradigm based finite state morphological analyzer for marathi </title>
<section> motivation and problem definition.  </section>
<citcontext>
<prevsection>
<prevsent>hence, although apprehensible this model is not sufficient for handling the morphology of marathi.
</prevsent>
<prevsent>many morphological analyzers have been developed using the two-level morphological model (koskenniemi, 1983) for morphological analysis.
</prevsent>
</prevsection>
<citsent citstr=" C94-1087 ">
(oflazer, 1993; <papid> E93-1066 </papid>kim et al., 1994) <papid> C94-1087 </papid>have been developed using pc kimmo (antworth, 1991), morphological parser based on the two-level model.</citsent>
<aftsection>
<nextsent>conceptually, the model segments the word in its constituent parts, and accounts for phonological and ortho graphical changes within word.
</nextsent>
<nextsent>while, the model proves to be very useful for developing the morphological analyzers for agglutina tive languages or the languages with very less degree of inflection, it fails to explicitly capture the regularities within and between paradigms present in the inflectional languages.
</nextsent>
<nextsent>marathi has well defined paradigm-based system of inflection.
</nextsent>
<nextsent>hence, we decided to develop our own model which works on the similar lines of pc-kimmo (antworth, 1991) but exploits the 26usefulness of paradigm-based inflectional system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG196">
<title id=" W10-1814.xml">cross lingual validity of propbank in the manual annotation of french </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the belief that this layer of meaning which is preserved across languages can be formally represented and automatically calculated underlies methods that use parallel corpora for the automatic generation of semantic annotations through cross lingual transfer (pado?, 2007; basili et al, 2009).
</prevsent>
<prevsent>a methodology similar in spirit ? re-use of the existing resources in different language ? hasalso been applied in developing manually annotated resources.
</prevsent>
</prevsection>
<citsent citstr=" W07-1513 ">
monachesi et al (2007) <papid> W07-1513 </papid>annotate dutch sentences using the propbank annotation scheme (palmer et al, 2005), <papid> J05-1004 </papid>while burchardt et al.</citsent>
<aftsection>
<nextsent>(2009) use the framenet framework (fillmoreet al, 2003) to annotate german corpus.
</nextsent>
<nextsent>instead of building special lexicons containing the specific semantic information needed for the annotation for each language separately, which is complex and time-consuming endeavour in itself,these approaches relyon the lexicons already developed for english.
</nextsent>
<nextsent>in this paper, we hypothesize that the levelof abstraction that is necessary to develop semantic lexicon/ontology for single language based on observable linguistic behaviour ? that is mono-lingual, item-specific annotation ? iscross-linguistically valid.
</nextsent>
<nextsent>we test this hypothesis by manually annotating french sentences using the propbank frame files developed for english.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG198">
<title id=" W10-1814.xml">cross lingual validity of propbank in the manual annotation of french </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the belief that this layer of meaning which is preserved across languages can be formally represented and automatically calculated underlies methods that use parallel corpora for the automatic generation of semantic annotations through cross lingual transfer (pado?, 2007; basili et al, 2009).
</prevsent>
<prevsent>a methodology similar in spirit ? re-use of the existing resources in different language ? hasalso been applied in developing manually annotated resources.
</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
monachesi et al (2007) <papid> W07-1513 </papid>annotate dutch sentences using the propbank annotation scheme (palmer et al, 2005), <papid> J05-1004 </papid>while burchardt et al.</citsent>
<aftsection>
<nextsent>(2009) use the framenet framework (fillmoreet al, 2003) to annotate german corpus.
</nextsent>
<nextsent>instead of building special lexicons containing the specific semantic information needed for the annotation for each language separately, which is complex and time-consuming endeavour in itself,these approaches relyon the lexicons already developed for english.
</nextsent>
<nextsent>in this paper, we hypothesize that the levelof abstraction that is necessary to develop semantic lexicon/ontology for single language based on observable linguistic behaviour ? that is mono-lingual, item-specific annotation ? iscross-linguistically valid.
</nextsent>
<nextsent>we test this hypothesis by manually annotating french sentences using the propbank frame files developed for english.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG199">
<title id=" W10-1814.xml">cross lingual validity of propbank in the manual annotation of french </title>
<section> materials and methods.  </section>
<citcontext>
<prevsection>
<prevsent>the tool shows the syntactic analysis and the plain sentence in the same window allowing the user to add semantic arcs and labels to the nodes in the syntactic dependency tree.
</prevsent>
<prevsent>the decision to show syntactic information is merely driven by the fact that we want to guide the annotator in selecting the heads of phrases during the annotation process.
</prevsent>
</prevsection>
<citsent citstr=" W07-2218 ">
the sentences are parsed by syntactic parser (titov and henderson, 2007)<papid> W07-2218 </papid>that we trained on syntactic dependency annotations for french (candito et al, 2009).</citsent>
<aftsection>
<nextsent>although the parser is state-of-the-art (87.2% labelled attachment score), in case of parse errors, we ask annotators to ignore the errors of the parser and put the label on the actual head.
</nextsent>
<nextsent>2.3 corpus.
</nextsent>
<nextsent>we selected the french sentences for the manual annotation from the parallel europarl corpus (koehn, 2005).
</nextsent>
<nextsent>because translation shifts are known to pose problems for the automatic cross lingual transfer of semantic roles (pado?, 2007) and for machine translation (ozdowska and way, 1142009), and these are more likely to appear in in direct translations, we decided to select only those parallel sentences, for which we can infer from the labels used in europarl that they are direct translations from english to french, or vice versa.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG203">
<title id=" W10-1717.xml">lessons from nrcrsquos portage system at wmt 2010 </title>
<section> portage system description.  </section>
<citcontext>
<prevsection>
<prevsent>major features in the first-pass loglinear model include phrase tables derived from symmetrized ibm2 alignments and symmetrized hmm alignments, distance-based distortion model, lexicalized distortion model, and language models (lms) that can be either static or else dynamic mixtures.
</prevsent>
<prevsent>each phrase table used was merged one, created by separately training an ibm2-based and an hmm-based joint count table on the same data and then adding the counts.
</prevsent>
</prevsection>
<citsent citstr=" N04-1033 ">
each includes relative frequency estimates and lexical estimates (based on zens and ney, 2004) <papid> N04-1033 </papid>of forward and backward conditional probabilities.</citsent>
<aftsection>
<nextsent>the lexicalized distortion probabilities are also obtained by adding ibm2 and hmm counts.
</nextsent>
<nextsent>they involve 6 features (monotone, swap and discontinuous features for following and preceding phrase) and are conditioned on phrase pairs in model similar to that of moses (koehn et al , 2005); map-based backoff smoothing scheme is used to combat data sparseness when estimating these probabilities.
</nextsent>
<nextsent>dynamic mixture lms are linear mixtures of ngram models trained on parallel sub-corpora with weights set to minimize perplexity of the current source text as described in (foster and kuhn, 2007); <papid> W07-0717 </papid>henceforth, well call them dynamic lms?.</nextsent>
<nextsent>decoding uses the cube-pruning algorithm of (huang and chiang, 2007) <papid> P07-1019 </papid>with 7-word distortion limit.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG204">
<title id=" W10-1717.xml">lessons from nrcrsquos portage system at wmt 2010 </title>
<section> portage system description.  </section>
<citcontext>
<prevsection>
<prevsent>the lexicalized distortion probabilities are also obtained by adding ibm2 and hmm counts.
</prevsent>
<prevsent>they involve 6 features (monotone, swap and discontinuous features for following and preceding phrase) and are conditioned on phrase pairs in model similar to that of moses (koehn et al , 2005); map-based backoff smoothing scheme is used to combat data sparseness when estimating these probabilities.
</prevsent>
</prevsection>
<citsent citstr=" W07-0717 ">
dynamic mixture lms are linear mixtures of ngram models trained on parallel sub-corpora with weights set to minimize perplexity of the current source text as described in (foster and kuhn, 2007); <papid> W07-0717 </papid>henceforth, well call them dynamic lms?.</citsent>
<aftsection>
<nextsent>decoding uses the cube-pruning algorithm of (huang and chiang, 2007) <papid> P07-1019 </papid>with 7-word distortion limit.</nextsent>
<nextsent>contrary to the usual implementation of distortion limits, we allow new phrase to end 127 more than 7 words past the first non-covered word, as long as the new phrase starts within 7 words from the first non-covered word.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG205">
<title id=" W10-1717.xml">lessons from nrcrsquos portage system at wmt 2010 </title>
<section> portage system description.  </section>
<citcontext>
<prevsection>
<prevsent>they involve 6 features (monotone, swap and discontinuous features for following and preceding phrase) and are conditioned on phrase pairs in model similar to that of moses (koehn et al , 2005); map-based backoff smoothing scheme is used to combat data sparseness when estimating these probabilities.
</prevsent>
<prevsent>dynamic mixture lms are linear mixtures of ngram models trained on parallel sub-corpora with weights set to minimize perplexity of the current source text as described in (foster and kuhn, 2007); <papid> W07-0717 </papid>henceforth, well call them dynamic lms?.</prevsent>
</prevsection>
<citsent citstr=" P07-1019 ">
decoding uses the cube-pruning algorithm of (huang and chiang, 2007) <papid> P07-1019 </papid>with 7-word distortion limit.</citsent>
<aftsection>
<nextsent>contrary to the usual implementation of distortion limits, we allow new phrase to end 127 more than 7 words past the first non-covered word, as long as the new phrase starts within 7 words from the first non-covered word.
</nextsent>
<nextsent>notwithstanding the distortion limit, contiguous phrases can always be swapped.
</nextsent>
<nextsent>out-of-vocabulary (oov) source words are passed through unchanged to the target.
</nextsent>
<nextsent>loglinear weights are tuned with och max-bleu algorithm over lattices (macherey et al , 2008); <papid> D08-1076 </papid>more details about lattice mert are given in the next section.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG206">
<title id=" W10-1717.xml">lessons from nrcrsquos portage system at wmt 2010 </title>
<section> portage system description.  </section>
<citcontext>
<prevsection>
<prevsent>notwithstanding the distortion limit, contiguous phrases can always be swapped.
</prevsent>
<prevsent>out-of-vocabulary (oov) source words are passed through unchanged to the target.
</prevsent>
</prevsection>
<citsent citstr=" D08-1076 ">
loglinear weights are tuned with och max-bleu algorithm over lattices (macherey et al , 2008); <papid> D08-1076 </papid>more details about lattice mert are given in the next section.</citsent>
<aftsection>
<nextsent>the second pass re scores 1000-best lists produced by the first pass, with additional features including various lm and ibm-model probabilities; ngram, length, and reordering posterior probabilities and frequencies; and quote and parenthesis mismatch indicators.
</nextsent>
<nextsent>to improve the quality of the maxima found by mert when using large sets of partial ly-overlapping rescoring features, we use greedy feature selection, first expanding from baseline set, then pruning.
</nextsent>
<nextsent>we restricted our training data to data that was directly available through the workshop web site; we didnt use the ldc resources mentioned on the website (e.g., french gigaword, english gigaword).
</nextsent>
<nextsent>below, mono?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG208">
<title id=" W10-1717.xml">lessons from nrcrsquos portage system at wmt 2010 </title>
<section> distance-based distortion model;.  </section>
<citcontext>
<prevsection>
<prevsent>3 details of lattice mert (lmert).
</prevsent>
<prevsent>our systems implementation of lmert (ma cherey et al , 2008) <papid> D08-1076 </papid>is the most notable recent change in our system.</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
as more and more features are included in the loglinear model, especially if they are correlated, n-best mert (och, 2003) <papid> P03-1021 </papid>shows more and more instability, because of convergence to local optima (foster and kuhn, 2009).<papid> W09-0439 </papid></citsent>
<aftsection>
<nextsent>we had been looking for methods that promise more stability and better convergence.
</nextsent>
<nextsent>lmert seemed to fit the bill.
</nextsent>
<nextsent>it optimizes over the complete lattice of candidate translations after decoding run.
</nextsent>
<nextsent>this avoids some of the problems of n-best lists, which lack variety, leading to poor local optima and the need for many decoder runs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG209">
<title id=" W10-1717.xml">lessons from nrcrsquos portage system at wmt 2010 </title>
<section> distance-based distortion model;.  </section>
<citcontext>
<prevsection>
<prevsent>3 details of lattice mert (lmert).
</prevsent>
<prevsent>our systems implementation of lmert (ma cherey et al , 2008) <papid> D08-1076 </papid>is the most notable recent change in our system.</prevsent>
</prevsection>
<citsent citstr=" W09-0439 ">
as more and more features are included in the loglinear model, especially if they are correlated, n-best mert (och, 2003) <papid> P03-1021 </papid>shows more and more instability, because of convergence to local optima (foster and kuhn, 2009).<papid> W09-0439 </papid></citsent>
<aftsection>
<nextsent>we had been looking for methods that promise more stability and better convergence.
</nextsent>
<nextsent>lmert seemed to fit the bill.
</nextsent>
<nextsent>it optimizes over the complete lattice of candidate translations after decoding run.
</nextsent>
<nextsent>this avoids some of the problems of n-best lists, which lack variety, leading to poor local optima and the need for many decoder runs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG211">
<title id=" W10-1717.xml">lessons from nrcrsquos portage system at wmt 2010 </title>
<section> distance-based distortion model;.  </section>
<citcontext>
<prevsection>
<prevsent>figure 2 shows more difficult case: there is single optimum, but noise dominates and pa has difficulty finding new directions.
</prevsent>
<prevsent>search often ite rates over the original co-ordinates, missing optima that are nearby but in directions not discoverable from local gradients.
</prevsent>
</prevsection>
<citsent citstr=" W08-0304 ">
probes in random directions can do better than iteration over the same directions (this is similar to the method proposed for n-best mert by cer et al , 2008).<papid> W08-0304 </papid></citsent>
<aftsection>
<nextsent>each 1-dimensional mert optimization is exact, so if our probe stabs region with better scores, it will be discovered.
</nextsent>
<nextsent>figures 1 and 2 only hint at the problem: in reality, 2-dimensional search isnt problem.
</nextsent>
<nextsent>the difficulties occur as the dimension grows: in high dimensions, it is more important to get good directions and they are harder to find.
</nextsent>
<nextsent>for wmt 2010, we crafted compromise with the best properties of pa, yet al owing for more aggressive search in more directions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG212">
<title id=" W10-1834.xml">syntactic tree queries in prolog </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>unlike in other general purpose languages, the programmer is relieved of the burden of writing functions to non deterministically search through the corpus or database.
</prevsent>
<prevsent>in comparison to dedicated query languages and their processors, the fact that one can always extend the prolog predicates that constitute the query language lifts many restrictions on the kinds of queries one can pose.
</prevsent>
</prevsection>
<citsent citstr=" E03-1074 ">
a more specific point is that we canhave fine grained control over the scope of negation and quantification in queries in prolog, something that is sometimes lacking from dedicated languages (for discussion, see lai and bird (2004); for prominent example, knig et al (2003); for an exception, kepser (2003)) <papid> E03-1074 </papid>lai and bird (2004) formulated number of queries to compare query languages for syntactically annotated corpora.</citsent>
<aftsection>
<nextsent>in this paper, we demonstrate the ease with which flexible and fast query environment can be constructed by implementing these queries and using them as rudimentary benchmark for performance.
</nextsent>
<nextsent>the tba-d/z treebank of german newspaper articles (telljohann et al, 2006, v5) comprises about 800k tokens in 45k sentences.
</nextsent>
<nextsent>we store the corpus as collection of directed acyclic graphs, with edges directed towards the roots of the syntactic trees (brants, 1997).
</nextsent>
<nextsent>% node/7 sentid nodeid mother id % form edge cat other node(153, 4, 503, die, -, art, [morph=asf]).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG213">
<title id=" W10-3409.xml">computational lexicography a feature based approach in designing an edictionary of chinese classifiers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>other previous studies on classifiers include descriptive and experimental studies of classifier systems of natural languages.
</prevsent>
<prevsent>for example, some descriptive studies make typo logical surveys of classifier systems in different languages (e.g. allan, 1977; lyons, 1977; goddard, 1998); others provide semantic analysis of classifiers and their associated nouns (e.g. downing, 1993; huang &amp; ahrens, 2003; matsumoto, 1993), and some also propose that there is an onto logical base on which classifiers and nouns are associated with (sowa 2000; philpot et al, 2003; nichols et al, 2005).
</prevsent>
</prevsection>
<citsent citstr=" I05-3004 ">
experimental studies using computer technology to apply findings of classifier knowledge to natural language processing (nlp) have provided new approach for the semantic analysis of classifiers (e.g. nirenburg &amp; raskin, 2004; hwang et al, 2007, quek, 2010) and for computer-assisted language learning (e.g. guo &amp; zhong, 2005).<papid> I05-3004 </papid></citsent>
<aftsection>
<nextsent>however, no e-learning systems developed so far are found to be able to guide second language learners to use the semantic properties to understand the links between classifiers and their associated nouns.
</nextsent>
<nextsent>the emergence of computer-assisted language learning (call) provides language learners with user-friendly and flexible e-learning tool.
</nextsent>
<nextsent>call incorporates technology into the language learning process and also applies itself across broad spectrum of teaching styles, textbooks, and courses (donaldson &amp; haggstrom, 2006).
</nextsent>
<nextsent>its bidirectional and individualized features makes it possible for learners to use it effectively to improve different aspects of language skills (e.g. mallon 2006; chang et al, 2008).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG214">
<title id=" W10-3405.xml">the color of emotions in texts </title>
<section> methodology.  </section>
<citcontext>
<prevsection>
<prevsent>firstly, the presentation and organization of the results provide good reference for our ownexperiments.
</prevsent>
<prevsent>in addition, it focusses on advertisement, which is one of the applicative fields we want to address in future work.
</prevsent>
</prevsection>
<citsent citstr=" W07-2013 ">
sensing emotions from text is an appealing task of natural language processing (pang and lee, 292008; strapparava and mihalcea, 2007): <papid> W07-2013 </papid>the automatic recognition of affective states is becoming fundamental issue in several domains suchas human-computer interaction or sentiment analysis for opinion mining.</citsent>
<aftsection>
<nextsent>indeed, large amount of textual material has become available form theweb (e.g. blogs, forums, social networks), raising the attractiveness of empirical methods analysis on this field.
</nextsent>
<nextsent>for representing the emotions, we exploit the methodology described in (strapparava and mihalcea, 2008).
</nextsent>
<nextsent>the idea underlying the method isthe distinction between direct and indirect affective words.for direct affective words (i.e. words that directly denote emotions), authors refer to the wordnet affect (strapparava and valitutti, 2004) lexicon, freely available extension of the wordnet database which employs some basic emotion labels (e.g. anger, disgust, fear, joy, sad ness) to annotate wordnet synsets.
</nextsent>
<nextsent>for indirect affective words, crucial aspect is building mechanism to represent an emotion starting from affective lexical concepts and to introduce semantic similarity among generic terms (and hence also words denoting colors) and these emotion representations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG215">
<title id=" W10-2707.xml">how was your day </title>
<section> natural language understanding and.  </section>
<citcontext>
<prevsection>
<prevsent>we use shortest path through the chart heuristic to select an interpretation.
</prevsent>
<prevsent>this is far from perfect, and we are currently working on separate more motivated disambiguation module.the final stage of processing before the dialogue manager takes over is to perform reference resolution for pronouns and definite nps.
</prevsent>
</prevsection>
<citsent citstr=" C96-1021 ">
this module is based partly on the system described by kennedy and boguraev 1996, <papid> C96-1021 </papid>with the various weighting factors based on theirs, but designed so that the weights can be trained given appropriate data.</citsent>
<aftsection>
<nextsent>currently we are collecting such data and the present set of weights are taken from kennedy and boguraev but with additional salience given to the domain-specific named entity classes.
</nextsent>
<nextsent>each referring np gives rise to discourse referent, and these are grouped into coreference classes based on grammatical, semantic, and salience properties.the dmmaintains an information state containing all objects mentioned during the conversation, and uses this information to decide whether the objects referred to in the utterance are salient ornot.
</nextsent>
<nextsent>the dm also uses type information to interpret elliptical answers to questions (system: who was at the meeting??
</nextsent>
<nextsent>user: nigel.?).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG216">
<title id=" W10-1008.xml">generating quantifiers and negation to explain homework testing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the system would then grade all students?
</prevsent>
<prevsent>programming assignments according to these criteria, and return individualized explanations 57 to students like (2) credit was lost because bar.c did not compile and no text file mentioned the files foo.h and baz.h.as this example illustrates, the tester needs to interpret and generate sentences with quantifiers and negation.
</prevsent>
</prevsection>
<citsent citstr=" J87-1005 ">
although the interpretation of quantifier sand negation is traditional research area in computational linguistics (vanlehn, 1978; hobbs and shieber, 1987; <papid> J87-1005 </papid>moran, 1988), <papid> P88-1005 </papid>their generation is much less studied (gailly, 1988).<papid> C88-1037 </papid></citsent>
<aftsection>
<nextsent>even if our system were to compose explanations entirely from the input specification sentences and their negation, it can not negate specification sentence merely by adding or removing verbal auxiliaries: the negation of source file defines main()?
</nextsent>
<nextsent>is not source file does not define main()?.
</nextsent>
<nextsent>1.1 contributions.
</nextsent>
<nextsent>we have built pro grader, rudimentary program ming-assignment tester that correctly interprets and generates small fragment of english that includes quantifiers and negation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG217">
<title id=" W10-1008.xml">generating quantifiers and negation to explain homework testing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the system would then grade all students?
</prevsent>
<prevsent>programming assignments according to these criteria, and return individualized explanations 57 to students like (2) credit was lost because bar.c did not compile and no text file mentioned the files foo.h and baz.h.as this example illustrates, the tester needs to interpret and generate sentences with quantifiers and negation.
</prevsent>
</prevsection>
<citsent citstr=" P88-1005 ">
although the interpretation of quantifier sand negation is traditional research area in computational linguistics (vanlehn, 1978; hobbs and shieber, 1987; <papid> J87-1005 </papid>moran, 1988), <papid> P88-1005 </papid>their generation is much less studied (gailly, 1988).<papid> C88-1037 </papid></citsent>
<aftsection>
<nextsent>even if our system were to compose explanations entirely from the input specification sentences and their negation, it can not negate specification sentence merely by adding or removing verbal auxiliaries: the negation of source file defines main()?
</nextsent>
<nextsent>is not source file does not define main()?.
</nextsent>
<nextsent>1.1 contributions.
</nextsent>
<nextsent>we have built pro grader, rudimentary program ming-assignment tester that correctly interprets and generates small fragment of english that includes quantifiers and negation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG218">
<title id=" W10-1008.xml">generating quantifiers and negation to explain homework testing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the system would then grade all students?
</prevsent>
<prevsent>programming assignments according to these criteria, and return individualized explanations 57 to students like (2) credit was lost because bar.c did not compile and no text file mentioned the files foo.h and baz.h.as this example illustrates, the tester needs to interpret and generate sentences with quantifiers and negation.
</prevsent>
</prevsection>
<citsent citstr=" C88-1037 ">
although the interpretation of quantifier sand negation is traditional research area in computational linguistics (vanlehn, 1978; hobbs and shieber, 1987; <papid> J87-1005 </papid>moran, 1988), <papid> P88-1005 </papid>their generation is much less studied (gailly, 1988).<papid> C88-1037 </papid></citsent>
<aftsection>
<nextsent>even if our system were to compose explanations entirely from the input specification sentences and their negation, it can not negate specification sentence merely by adding or removing verbal auxiliaries: the negation of source file defines main()?
</nextsent>
<nextsent>is not source file does not define main()?.
</nextsent>
<nextsent>1.1 contributions.
</nextsent>
<nextsent>we have built pro grader, rudimentary program ming-assignment tester that correctly interprets and generates small fragment of english that includes quantifiers and negation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG220">
<title id=" W10-1008.xml">generating quantifiers and negation to explain homework testing </title>
<section> quantifier scope, negation and.  </section>
<citcontext>
<prevsection>
<prevsent>an algorithm for generating all possible quantifier sco pings was detailed by hobbs and shieber (1987).<papid> J87-1005 </papid></prevsent>
<prevsent>however, we need solution that prefers one highly likely default scoping, that supports both interpretation and generation, and that is integrated with the type structure of our semantic representation.</prevsent>
</prevsection>
<citsent citstr=" E03-1024 ">
compositional semantics based on continuations (barker, 2002) can represent preferred scoping ofquantifiers and negation without the semantic type shifting or syntactic under specification (hendriks, 1993; steedman, 1996; bos, 1995; koller et al, 2003) <papid> E03-1024 </papid>that typically complicates interpreting and generating quantification.</citsent>
<aftsection>
<nextsent>the rough idea is to generalize montagues ptq (1974), so that every constituents semantic type has the form (
</nextsent>
<nextsent>! t)!
</nextsent>
<nextsent>t: not only does every np denote the type (e! t)!
</nextsent>
<nextsent>t instead of e, but every vp also denotes the type ((e! t)!
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG221">
<title id=" W10-1008.xml">generating quantifiers and negation to explain homework testing </title>
<section> quantifier scope, negation and.  </section>
<citcontext>
<prevsection>
<prevsent>in other words, gf cannot equate logical forms by beta-equivalence.
</prevsent>
<prevsent>therefore, we cannot just feedthe pseudo code above into gf to generate explanations.
</prevsent>
</prevsection>
<citsent citstr=" J93-1008 ">
this is an instance of the problem of logical form equivalence (shieber, 1993).<papid> J93-1008 </papid>fortunately, because denot ations using continuations are always of certain form (danvy and filin ski, 1992), we can simulate these higher-order functions using first-order records.</citsent>
<aftsection>
<nextsent>specifically, we simulate higher-order function of the form (22) lambda c: sl c(sm) sr by the triple of strings (23) { s_l = sl; s_m = sm; s_r = sr } in gf.
</nextsent>
<nextsent>the middle string sm corresponds to the core?
</nextsent>
<nextsent>of the phrase, and the left and right strings sl;sr are those parts which may take scope over other phrases.
</nextsent>
<nextsent>for example, following the pseudo code above, we write lin everysourcefile = { s_l =  everysourcefile ( lambda : ; s_m =  ; s_r =  )  }; lin compiles = { s_l =   ; s_m =  compiles ; s_r =    }; in our gf concrete grammar.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG222">
<title id=" W10-1819.xml">dependency based prop banking of clinical finnish </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>natural language processing (nlp) in the clinical domain has received substantial interest, with applications in decision support, patient managing and profiling, mining trends, and others(see the extensive review by friedman and johnson (2006)).
</prevsent>
<prevsent>while some of these applications, such as document retrieval and trend mining, can rely solely on word-frequency-based methods,others, such as information extraction and summarization require detailed linguistic analysis capturing some of the sentence semantics.
</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
among the most important steps in this direction is an analysis of verbs and their argument structures.in this work, we focus on the finnish language in the clinical domain, analyzing its verbs and their argument structures using the propbank scheme (palmer et al, 2005).<papid> J05-1004 </papid></citsent>
<aftsection>
<nextsent>the choice of this particular scheme is motivated by its practical, application-oriented nature.
</nextsent>
<nextsent>we build the clinical finnish propbank on top of the existing dependency treebank of haverinen et al (2009).
</nextsent>
<nextsent>the primary outcome of this study is the propbank of clinical finnish itself, consisting of the analyses for 157 verbs with 2,382 occurrences and 4,763 arguments, and covering 90% of all verb occurrences in the underlying treebank.
</nextsent>
<nextsent>this propbank, together with the treebank, is an important resource for the further development of clinical nlp applications for the finnish language.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG225">
<title id=" W10-1819.xml">dependency based prop banking of clinical finnish </title>
<section> prop banking clinical finnish.  </section>
<citcontext>
<prevsection>
<prevsent>many efforts have been made to capture meanings and arguments of verbs.
</prevsent>
<prevsent>for instance, the verbnet project (kipper et al, 2000) strives to create abroad on-line verb lexicon, and framenet (rup pen hofer et al, 2005) aims to document the range of vale nces of each verb in each of its senses.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
the propbank project (palmer et al, 2005) <papid> J05-1004 </papid>strives for practical approach to semantic representation, adding layer of semantic role labels to the penn treebank (marcus et al, 1993).<papid> J93-2004 </papid></citsent>
<aftsection>
<nextsent>in addition to the original propbank by palme ret al, numerous prop banks have been developed for languages other than english (e.g. chinese (xue and palmer, 2003) <papid> W03-1707 </papid>and arabic (diab et al, 2008)).</nextsent>
<nextsent>also applications attempting to automatically recover propbank-style arguments have been proposed.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG226">
<title id=" W10-1819.xml">dependency based prop banking of clinical finnish </title>
<section> prop banking clinical finnish.  </section>
<citcontext>
<prevsection>
<prevsent>for instance, the verbnet project (kipper et al, 2000) strives to create abroad on-line verb lexicon, and framenet (rup pen hofer et al, 2005) aims to document the range of vale nces of each verb in each of its senses.
</prevsent>
<prevsent>the propbank project (palmer et al, 2005) <papid> J05-1004 </papid>strives for practical approach to semantic representation, adding layer of semantic role labels to the penn treebank (marcus et al, 1993).<papid> J93-2004 </papid></prevsent>
</prevsection>
<citsent citstr=" W03-1707 ">
in addition to the original propbank by palme ret al, numerous prop banks have been developed for languages other than english (e.g. chinese (xue and palmer, 2003) <papid> W03-1707 </papid>and arabic (diab et al, 2008)).</citsent>
<aftsection>
<nextsent>also applications attempting to automatically recover propbank-style arguments have been proposed.
</nextsent>
<nextsent>for example, the conll shared task has focused on semantic role labeling four times, twice as separate task (carreras and ma`rquez, 2004; carreras and ma`rquez, 2005), and twice in conjunction with syntactic parsing (sur deanu et al, 2008; <papid> W08-2121 </papid>hajic?</nextsent>
<nextsent>et al, 2009).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG227">
<title id=" W10-1819.xml">dependency based prop banking of clinical finnish </title>
<section> prop banking clinical finnish.  </section>
<citcontext>
<prevsection>
<prevsent>in addition to the original propbank by palme ret al, numerous prop banks have been developed for languages other than english (e.g. chinese (xue and palmer, 2003) <papid> W03-1707 </papid>and arabic (diab et al, 2008)).</prevsent>
<prevsent>also applications attempting to automatically recover propbank-style arguments have been proposed.</prevsent>
</prevsection>
<citsent citstr=" W08-2121 ">
for example, the conll shared task has focused on semantic role labeling four times, twice as separate task (carreras and ma`rquez, 2004; carreras and ma`rquez, 2005), and twice in conjunction with syntactic parsing (sur deanu et al, 2008; <papid> W08-2121 </papid>hajic?</citsent>
<aftsection>
<nextsent>et al, 2009).
</nextsent>
<nextsent>2csq is new modifier subtype added by us, due to the restriction of only annotating direct syntactic dependents,which does not allow the annotation of all causal relationships with the type cau.
</nextsent>
<nextsent>in semantic analysis of clinical language, paeket al (2006) have experimented on propbank based machine learning on abstracts of randomized controlled trials (rcts), and savova etal.
</nextsent>
<nextsent>(2009) have presented work on temporal relation discovery from clinical narratives.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG228">
<title id=" W10-3706.xml">automatic extraction of complex predicates in bengali </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>consists of noun or adjective followed by light verb (lv).
</prevsent>
<prevsent>the light verbs (lvs) bear the appropriate inflections based on tense, aspect and person.
</prevsent>
</prevsection>
<citsent citstr=" W09-2906 ">
according to the definition of multi-word expressions (mwes)(baldwin and kim, 2010), the absence of conventional meaning of the light verbs in complex predicates (cps) entails us to consider the complex predicates (cps) as mwes (sinha, 2009).<papid> W09-2906 </papid></citsent>
<aftsection>
<nextsent>but, there are some typical examples of complex predicates (cps), e.g. ? ??
</nextsent>
<nextsent>dekha kara see-do?
</nextsent>
<nextsent>that bear the similar lexical pattern as full verb (fv)+ light verb (lv) but both of the full verb (fv) and light verb (lv) loose their conventional meanings and generate completely different meaning (to meet?
</nextsent>
<nextsent>in this case).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG230">
<title id=" W10-3706.xml">automatic extraction of complex predicates in bengali </title>
<section> modal control construction (mcc):.  </section>
<citcontext>
<prevsection>
<prevsent>his simple strategy exploits the fact that complex predicate is multi-word expression with meaning that is distinct from the meaning of the light verb.
</prevsent>
<prevsent>in contrast, the present task carries the identification of complex predicates (cps) from monolingual bengali corpus based on morphological information and lexical patterns.
</prevsent>
</prevsection>
<citsent citstr=" C08-2007 ">
the analysis of v+v complex predicates termed as lexical compound verbs (lcpdvs) and the linguistic tests for their detection in hindi are described in (chakrabarti et al, 2008).<papid> C08-2007 </papid></citsent>
<aftsection>
<nextsent>in addition to compound verbs, the present system also identifies the conjunct verbs in bengali.
</nextsent>
<nextsent>but, it was observed that the identification of hindi conjunct verbs that contain noun in the first slot is puzzling and therefore sophisticated solution was proposed in (das, 2009) based on the control agreement strategy with other overtly case marked noun phrases.
</nextsent>
<nextsent>the present task also agrees with the above problem in identifying conjunct verbs in bengali although the system satisfactorily identifies the conjunct verbs (conjvs).
</nextsent>
<nextsent>paul (2003) develops constraint-based mechanism within hpsg framework for composing indo-aryan compound verb constructions with special focus on bangla (bengali) compound verb sequences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG231">
<title id=" W10-3706.xml">automatic extraction of complex predicates in bengali </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>but, it is observed that the identification of lexical scopes of compound verbs (compvs) and conjunct verbs (conjvs) from long sequence of successive complex predicates (cps) increases the number of complex predicates (cps) entries along with compound verbs (compvs) and conjunct verbs (conjvs).
</prevsent>
<prevsent>the figures shown in boldface in table 3 and table 4 for the travel and tourism corpus and short story corpus of rabindranath tagore indicates the improvement of identifying lexical scopes of the complex predicates (cps).
</prevsent>
</prevsection>
<citsent citstr=" W06-1205 ">
in comparison to other similar language such as hindi (mukerjee et al, 2006) (<papid> W06-1205 </papid>there ported precision and recall are 83% and 46% respectively), our results (84.66% precision and 83.67% recall) are higher in case of extracting complex predicates (cps).</citsent>
<aftsection>
<nextsent>the reason may be of resolving the lexical scope and handling the morphosyntactic features using shallow parser.
</nextsent>
<nextsent>in addition to non-monoclausal verb (nmcv) or serial verb, the other criteria (butt, 1993; paul, 2004) are used in our present diagnostic tests to identify the complex predicates (cps).
</nextsent>
<nextsent>the frequencies of compound verb (compv), conjunct verb (conjv) and the instances of other constraints of non complex predicates (non-cps) are shown in figure 2.
</nextsent>
<nextsent>it is observed that the numbers of instances of conjunct verb (conjv), pass ives (pass), auxiliary construction (ac) and non-monoclausal verb (nmcv) or serial verb are comparatively high than other instances in both of the corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG232">
<title id=" W10-2301.xml">graph based clustering for computational linguistics a survey </title>
<section> graph-based clustering methodology.  </section>
<citcontext>
<prevsection>
<prevsent>table 3 lists the evaluation measures ever proposed (including those discussed in amigo et al, 2008 and some other measures known for coreference resolution).
</prevsent>
<prevsent>to answer the second question proposed in this section, we conclude the findings in amigo et al (2008) plus our new findings about muc and ceaf as follows: (1) all the measures except b-cubed fail the ragbag constraint and only b-cubed measure can satisfy all the four constraints; (2) two entropy based measures (vi and v) and muc only fail the ragbag constraint; (3) all the measures in set mapping category fail completeness constraint (4) all the measures in pair counting category fail cluster size vs. quantity constraint; (5) ceaf, unfortunately, fails homogeneity, completeness, ragbag constraints.
</prevsent>
</prevsection>
<citsent citstr=" M95-1005 ">
category evaluation measures set mapping purity, inverse purity, f-measure pair counting rand index, jaccard coefficient, folks and mallows fm entropy entropy, mutual information, vi, editing distance editing distance coreference resolution muc (vilain et al,1995), <papid> M95-1005 </papid>b-cubed (bagga and baldwin, 1998), ceaf (luo, 2005) <papid> H05-1004 </papid>table 3.</citsent>
<aftsection>
<nextsent>summary of evaluation measures
</nextsent>
<nextsent>a variety of structures in nlp can be naturally represented as graphs, e.g., co-occurrence graphs, coreference graphs, word/sentence/ document graphs.
</nextsent>
<nextsent>in recent years, there have been an increasing amount of interests in applying graph based clustering to some nlp problems, e.g., document clustering (zhong and ghosh, 2004), summarization (zha, 2002), coreference resolution (nicolae and nicolae, 2006), <papid> W06-1633 </papid>word sense disambiguation (dorow and widdows, 2003; vronis, 2004; agirre et al, 2007), word clustering (matsuo et al, 2006; <papid> W06-1664 </papid>biemann, 2006).<papid> W06-3812 </papid></nextsent>
<nextsent>many authors chose one or two their favorite graph clustering algorithms and claimed the effectiveness by comparing with supervised algorithms (which need expensive annotations) or other non 5 graph clustering algorithms.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG233">
<title id=" W10-2301.xml">graph based clustering for computational linguistics a survey </title>
<section> graph-based clustering methodology.  </section>
<citcontext>
<prevsection>
<prevsent>table 3 lists the evaluation measures ever proposed (including those discussed in amigo et al, 2008 and some other measures known for coreference resolution).
</prevsent>
<prevsent>to answer the second question proposed in this section, we conclude the findings in amigo et al (2008) plus our new findings about muc and ceaf as follows: (1) all the measures except b-cubed fail the ragbag constraint and only b-cubed measure can satisfy all the four constraints; (2) two entropy based measures (vi and v) and muc only fail the ragbag constraint; (3) all the measures in set mapping category fail completeness constraint (4) all the measures in pair counting category fail cluster size vs. quantity constraint; (5) ceaf, unfortunately, fails homogeneity, completeness, ragbag constraints.
</prevsent>
</prevsection>
<citsent citstr=" H05-1004 ">
category evaluation measures set mapping purity, inverse purity, f-measure pair counting rand index, jaccard coefficient, folks and mallows fm entropy entropy, mutual information, vi, editing distance editing distance coreference resolution muc (vilain et al,1995), <papid> M95-1005 </papid>b-cubed (bagga and baldwin, 1998), ceaf (luo, 2005) <papid> H05-1004 </papid>table 3.</citsent>
<aftsection>
<nextsent>summary of evaluation measures
</nextsent>
<nextsent>a variety of structures in nlp can be naturally represented as graphs, e.g., co-occurrence graphs, coreference graphs, word/sentence/ document graphs.
</nextsent>
<nextsent>in recent years, there have been an increasing amount of interests in applying graph based clustering to some nlp problems, e.g., document clustering (zhong and ghosh, 2004), summarization (zha, 2002), coreference resolution (nicolae and nicolae, 2006), <papid> W06-1633 </papid>word sense disambiguation (dorow and widdows, 2003; vronis, 2004; agirre et al, 2007), word clustering (matsuo et al, 2006; <papid> W06-1664 </papid>biemann, 2006).<papid> W06-3812 </papid></nextsent>
<nextsent>many authors chose one or two their favorite graph clustering algorithms and claimed the effectiveness by comparing with supervised algorithms (which need expensive annotations) or other non 5 graph clustering algorithms.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG234">
<title id=" W10-2301.xml">graph based clustering for computational linguistics a survey </title>
<section> applying graph clustering to nlp.  </section>
<citcontext>
<prevsection>
<prevsent>summary of evaluation measures
</prevsent>
<prevsent>a variety of structures in nlp can be naturally represented as graphs, e.g., co-occurrence graphs, coreference graphs, word/sentence/ document graphs.
</prevsent>
</prevsection>
<citsent citstr=" W06-1633 ">
in recent years, there have been an increasing amount of interests in applying graph based clustering to some nlp problems, e.g., document clustering (zhong and ghosh, 2004), summarization (zha, 2002), coreference resolution (nicolae and nicolae, 2006), <papid> W06-1633 </papid>word sense disambiguation (dorow and widdows, 2003; vronis, 2004; agirre et al, 2007), word clustering (matsuo et al, 2006; <papid> W06-1664 </papid>biemann, 2006).<papid> W06-3812 </papid></citsent>
<aftsection>
<nextsent>many authors chose one or two their favorite graph clustering algorithms and claimed the effectiveness by comparing with supervised algorithms (which need expensive annotations) or other non 5 graph clustering algorithms.
</nextsent>
<nextsent>as far as we know, there is not much work on the comparative study of various graph-based clustering algorithms for certain nlp problems.
</nextsent>
<nextsent>as mentioned at the end of section 2.5, there is not graph clustering algorithm that is effective for all applications.
</nextsent>
<nextsent>however, it is interesting to find out, for specific nlp problem, if graph clustering methods can be applied, (1) how the parameters in the graph model affects the performance?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG235">
<title id=" W10-2301.xml">graph based clustering for computational linguistics a survey </title>
<section> applying graph clustering to nlp.  </section>
<citcontext>
<prevsection>
<prevsent>summary of evaluation measures
</prevsent>
<prevsent>a variety of structures in nlp can be naturally represented as graphs, e.g., co-occurrence graphs, coreference graphs, word/sentence/ document graphs.
</prevsent>
</prevsection>
<citsent citstr=" W06-1664 ">
in recent years, there have been an increasing amount of interests in applying graph based clustering to some nlp problems, e.g., document clustering (zhong and ghosh, 2004), summarization (zha, 2002), coreference resolution (nicolae and nicolae, 2006), <papid> W06-1633 </papid>word sense disambiguation (dorow and widdows, 2003; vronis, 2004; agirre et al, 2007), word clustering (matsuo et al, 2006; <papid> W06-1664 </papid>biemann, 2006).<papid> W06-3812 </papid></citsent>
<aftsection>
<nextsent>many authors chose one or two their favorite graph clustering algorithms and claimed the effectiveness by comparing with supervised algorithms (which need expensive annotations) or other non 5 graph clustering algorithms.
</nextsent>
<nextsent>as far as we know, there is not much work on the comparative study of various graph-based clustering algorithms for certain nlp problems.
</nextsent>
<nextsent>as mentioned at the end of section 2.5, there is not graph clustering algorithm that is effective for all applications.
</nextsent>
<nextsent>however, it is interesting to find out, for specific nlp problem, if graph clustering methods can be applied, (1) how the parameters in the graph model affects the performance?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG236">
<title id=" W10-2301.xml">graph based clustering for computational linguistics a survey </title>
<section> applying graph clustering to nlp.  </section>
<citcontext>
<prevsection>
<prevsent>summary of evaluation measures
</prevsent>
<prevsent>a variety of structures in nlp can be naturally represented as graphs, e.g., co-occurrence graphs, coreference graphs, word/sentence/ document graphs.
</prevsent>
</prevsection>
<citsent citstr=" W06-3812 ">
in recent years, there have been an increasing amount of interests in applying graph based clustering to some nlp problems, e.g., document clustering (zhong and ghosh, 2004), summarization (zha, 2002), coreference resolution (nicolae and nicolae, 2006), <papid> W06-1633 </papid>word sense disambiguation (dorow and widdows, 2003; vronis, 2004; agirre et al, 2007), word clustering (matsuo et al, 2006; <papid> W06-1664 </papid>biemann, 2006).<papid> W06-3812 </papid></citsent>
<aftsection>
<nextsent>many authors chose one or two their favorite graph clustering algorithms and claimed the effectiveness by comparing with supervised algorithms (which need expensive annotations) or other non 5 graph clustering algorithms.
</nextsent>
<nextsent>as far as we know, there is not much work on the comparative study of various graph-based clustering algorithms for certain nlp problems.
</nextsent>
<nextsent>as mentioned at the end of section 2.5, there is not graph clustering algorithm that is effective for all applications.
</nextsent>
<nextsent>however, it is interesting to find out, for specific nlp problem, if graph clustering methods can be applied, (1) how the parameters in the graph model affects the performance?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG237">
<title id=" W10-2301.xml">graph based clustering for computational linguistics a survey </title>
<section> applying graph clustering to nlp.  </section>
<citcontext>
<prevsection>
<prevsent>one of the most prevalent approaches for coreference resolution is to follow two-step procedure: (1) classification step that computes how likely one mention co refers with the other and (2) clustering step that groups the mentions into clusters such that all mentions in cluster refer to the same entity.
</prevsent>
<prevsent>in the past years, nlp researchers have explored and enriched this methodogy from various directions (either in classification or clustering step).
</prevsent>
</prevsection>
<citsent citstr=" J01-4004 ">
unfortunately, most of the proposed clustering algorithms, e.g., closest-first clustering (soon et al, 2001), <papid> J01-4004 </papid>best first clustering (ng and cardie, 2002)<papid> P02-1014 </papid>suffer from drawback: an instant decision is made (in greedy style) when considering two mentions are co referent or not, therefore, the algorithm makes no attempt to search through the space of all possible clusterings, which results in sub optimal clustering (luo et al, 2004)<papid> P04-1018 </papid></citsent>
<aftsection>
<nextsent>various approaches have been proposed to alleviate this problem, of which graph clustering methodology is one of the most promising solutions.
</nextsent>
<nextsent>the problem of coreference resolution can be modeled as graph such that the vertex represents mention, and the edge weight carries the coreference likelihood between two mentions.
</nextsent>
<nextsent>nicolae and nicolae (2006) <papid> W06-1633 </papid>proposed new quality measure named bestcut which is to optimize the sum of correctly?</nextsent>
<nextsent>placed vertices in the graph.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG238">
<title id=" W10-2301.xml">graph based clustering for computational linguistics a survey </title>
<section> applying graph clustering to nlp.  </section>
<citcontext>
<prevsection>
<prevsent>one of the most prevalent approaches for coreference resolution is to follow two-step procedure: (1) classification step that computes how likely one mention co refers with the other and (2) clustering step that groups the mentions into clusters such that all mentions in cluster refer to the same entity.
</prevsent>
<prevsent>in the past years, nlp researchers have explored and enriched this methodogy from various directions (either in classification or clustering step).
</prevsent>
</prevsection>
<citsent citstr=" P02-1014 ">
unfortunately, most of the proposed clustering algorithms, e.g., closest-first clustering (soon et al, 2001), <papid> J01-4004 </papid>best first clustering (ng and cardie, 2002)<papid> P02-1014 </papid>suffer from drawback: an instant decision is made (in greedy style) when considering two mentions are co referent or not, therefore, the algorithm makes no attempt to search through the space of all possible clusterings, which results in sub optimal clustering (luo et al, 2004)<papid> P04-1018 </papid></citsent>
<aftsection>
<nextsent>various approaches have been proposed to alleviate this problem, of which graph clustering methodology is one of the most promising solutions.
</nextsent>
<nextsent>the problem of coreference resolution can be modeled as graph such that the vertex represents mention, and the edge weight carries the coreference likelihood between two mentions.
</nextsent>
<nextsent>nicolae and nicolae (2006) <papid> W06-1633 </papid>proposed new quality measure named bestcut which is to optimize the sum of correctly?</nextsent>
<nextsent>placed vertices in the graph.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG240">
<title id=" W10-2301.xml">graph based clustering for computational linguistics a survey </title>
<section> applying graph clustering to nlp.  </section>
<citcontext>
<prevsection>
<prevsent>one of the most prevalent approaches for coreference resolution is to follow two-step procedure: (1) classification step that computes how likely one mention co refers with the other and (2) clustering step that groups the mentions into clusters such that all mentions in cluster refer to the same entity.
</prevsent>
<prevsent>in the past years, nlp researchers have explored and enriched this methodogy from various directions (either in classification or clustering step).
</prevsent>
</prevsection>
<citsent citstr=" P04-1018 ">
unfortunately, most of the proposed clustering algorithms, e.g., closest-first clustering (soon et al, 2001), <papid> J01-4004 </papid>best first clustering (ng and cardie, 2002)<papid> P02-1014 </papid>suffer from drawback: an instant decision is made (in greedy style) when considering two mentions are co referent or not, therefore, the algorithm makes no attempt to search through the space of all possible clusterings, which results in sub optimal clustering (luo et al, 2004)<papid> P04-1018 </papid></citsent>
<aftsection>
<nextsent>various approaches have been proposed to alleviate this problem, of which graph clustering methodology is one of the most promising solutions.
</nextsent>
<nextsent>the problem of coreference resolution can be modeled as graph such that the vertex represents mention, and the edge weight carries the coreference likelihood between two mentions.
</nextsent>
<nextsent>nicolae and nicolae (2006) <papid> W06-1633 </papid>proposed new quality measure named bestcut which is to optimize the sum of correctly?</nextsent>
<nextsent>placed vertices in the graph.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG245">
<title id=" W10-2301.xml">graph based clustering for computational linguistics a survey </title>
<section> applying graph clustering to nlp.  </section>
<citcontext>
<prevsection>
<prevsent>they compared bestcut algorithm with (luo et al, 2004)<papid> P04-1018 </papid>s bell tree and (ng and cardie, 2002)<papid> P02-1014 </papid>s link-best algorithm and showed that using ground-truth entities, bestcut outperforms the other two with statistical significance (4.8% improvement over bell tree and link best algorithm in ecm f-measure).</prevsent>
<prevsent>nevertheless, we believe that the bestcut algorithm is not the only choice and the running complexity of bestcut,??(|??||??| + |??|2??????|??|), is not competitive, thus could be improved by other graph clustering algorithms.</prevsent>
</prevsection>
<citsent citstr=" W09-3208 ">
chen and ji (2009<papid> W09-3208 </papid>a) applied normalized spectral algorithm to conduct event coreference reso lution: partitioning set of mentions into events.</citsent>
<aftsection>
<nextsent>an event is specific occurrence involving participants.
</nextsent>
<nextsent>an event mention is textual reference to an event which includes distinguished trigger (the word that most clearly expresses an event occurs) and involving arguments (enti ties/temporal expressions that play certain roles in the event).
</nextsent>
<nextsent>a graph is similarly constructed as in entity coreference resolution except that it involves quite different feature engineering (most features are related with event trigger and argu ments).
</nextsent>
<nextsent>the graph clustering approach yields competitive results by comparing with an agglo mera tive clustering algorithm proposed in (chen et al, 2009b), unfortunately, scientific comparison among the algorithms remains unexplored.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG248">
<title id=" W10-2301.xml">graph based clustering for computational linguistics a survey </title>
<section> applying graph clustering to nlp.  </section>
<citcontext>
<prevsection>
<prevsent>the concern of their approach is the running complexity for constructing co-occurrence matrix, i.e., for ??
</prevsent>
<prevsent>words, ??(2) queries are required which is intractable for large graph.
</prevsent>
</prevsection>
<citsent citstr=" W08-2005 ">
ichioka and fukumoto (2008) <papid> W08-2005 </papid>applied similar approach as matsuo et al (2006) <papid> W06-1664 </papid>for japanese onomatopoetic word clustering, and showed that the approach outperforms ??-means clustering by 16.2%.</citsent>
<aftsection>
<nextsent>3.3 word sense disambiguation (wsd).
</nextsent>
<nextsent>word sense disambiguation is the problem of identifying which sense of word (meaning) is conveyed in the context of sentence, when the word is polysemic.
</nextsent>
<nextsent>in contrast to supervised wsd which relies on pre-defined list of senses from dictionaries, unsupervised wsd induces word senses directly from the corpus.
</nextsent>
<nextsent>among those unsupervised wsd algorithms, graph based clustering algorithms have been found competitive with supervised methods, and in many cases outperform most vector-based clustering methods.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG251">
<title id=" W10-3403.xml">exploiting lexical resources for therapeutic purposes the case of wordnet and stars sys </title>
<section> stars.sys in therapeutic context.  </section>
<citcontext>
<prevsection>
<prevsent>the resulting classification only considers concrete objects and is composed of 25 feature types.
</prevsent>
<prevsent>all of them (except the is associated with relations) belong to one of the following six rela tions) belong to one of the following six major classes: taxonomic properties, part-of- relations, feature type example has portion  bread  cut into slices has geographical part  africa  egitto has size  elephant  is big has shape  clock  is round has texture  eel  is slimy /  biscuit  is crunchy has taste  lemon  is bitter has smell  rose water  smells of rose has sound  lighting  produces thunder has colour  lemon  is yellow is used for  cup  is used for drinking is used by  cleaver  is used by butchers is used with  violin  is played with bow situation located  jacket  used in occasions space located  camel  in the desert time located  pajamas  used at night has origin  milk  comes from cows is involved in  bird  eats seeds - is hunted has attribute  subway  is fast has affective property  horror movie  is scary is associated with  dog  man table 1: stars.sys types not having parallel wordnet semantic relation 15perceptual properties, usage properties, locational properties and associated events and attributes.
</prevsent>
</prevsection>
<citsent citstr=" W08-1913 ">
a first version of this classification has been evaluated by asking 5 nave italian speakers to assign the appropriate type label to 300 concept4 feature pairs from non-normalized version of the kremer et al (2008) <papid> W08-1913 </papid>norms.</citsent>
<aftsection>
<nextsent>the inter-coder agreement between subjects (fleiss?
</nextsent>
<nextsent>multi-pi = 0,73) validated the skeleton of our classification, at the same time suggesting some minor changes that have been applied to the classification proposed here.
</nextsent>
<nextsent>an evaluation of the improved classification involving therapists has been planned for the (very near) future.
</nextsent>
<nextsent>note that in order to map all of the feature types into wordnet relations we had to create number of new relations which are not available in existing wordnets.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG252">
<title id=" W10-3403.xml">exploiting lexical resources for therapeutic purposes the case of wordnet and stars sys </title>
<section> stars.sys in therapeutic context.  </section>
<citcontext>
<prevsection>
<prevsent>whereas in wn synsets are bound to contain only lexical units (with the few exceptions of the so called artificial nodes), the target of feat ural description can be free combination of words, for instance noun modified by an adjective (e.g. has  long neck ), an adjective modified by an adverb (e.g. is  very big ) or verb with an argument (e.g. is used to  cut bread ).
</prevsent>
<prevsent>forgiving an idea of the phenomenon, consider that 27,6% of the features that composes the experimental sample in 4 in details, the subjects were submitted with concrete concepts belonging to one of the following categories: mammals, birds, fruits, vegetables, body parts, clothing, mani pulable tools, vehicles, furniture and buildings.
</prevsent>
</prevsection>
<citsent citstr=" E03-1018 ">
lebani and pianta (2010) contain target concepts expressed by free combination of words the solution we adopted to solve this problem relies on the notion of phraset proposed by bentivogli and pianta (2003), <papid> E03-1018 </papid>tivogli and pianta (2004), that is data structure used for encoding sets of synonymous free combination of words (as opposed to lexical units) which are re currently used to express concept?.</citsent>
<aftsection>
<nextsent>in the original proposal, the authors introduced such data structure to cope with lexical gaps in multingual resources or to encode alternative (linguistically complex) ways of expressing an existing concept.
</nextsent>
<nextsent>phra sets can be associated to existing synsets to represent alternative (non lexical) ways of expressing lexicalized concepts, e.g. the italian translations of dish cloth?: synset: {canovaccio, strofinaccio} phraset: {strofinaccio_per_i_piatti, straccio_per_i_piatti} where strofinaccio per piatti?
</nextsent>
<nextsent>and straccio per piatti?
</nextsent>
<nextsent>and are free combinations of words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG253">
<title id=" W10-3408.xml">conceptual structure of automatically extracted multiword terms from domain specific corpora a case study for italian </title>
<section> automatically extracting and.  </section>
<citcontext>
<prevsection>
<prevsent>however, wedo not perform any post-processing to correct errors and we leave it as it is analyzed for the moment.
</prevsent>
<prevsent>in figure 2,  corpus  is for the name of the corpus,  record  is for different texts which are usually from separate files,  info has format like  info 00/car/00 -/ 0001800/sbc/0001800 /info  with theyear of text creation 00 and the file identification 0001800.
</prevsent>
</prevsection>
<citsent citstr=" J93-1003 ">
title  is for the title,  ab  is for the text body, and  ph nb= num   is for sentence identification.acabit proposes as output list of multiword terms ranked from the most representative of the corpus using log-likelihood estimation (dunning, 1993) <papid> J93-1003 </papid>and their variations in thecorpus.</citsent>
<aftsection>
<nextsent>it also shows the semantic relation between multi-word terms.
</nextsent>
<nextsent>the example of the output is given in figure 3.
</nextsent>
<nextsent>a base term, for example area protetto (protected area?)
</nextsent>
<nextsent>is put together with its syntactic variations area nat urale protetto (natural protected area?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG254">
<title id=" W10-3408.xml">conceptual structure of automatically extracted multiword terms from domain specific corpora a case study for italian </title>
<section> discussion, conclusion and future.  </section>
<citcontext>
<prevsection>
<prevsent>this paper is based on our efforts on automatic multi-word terms extraction and its conceptual structure for multiple languages and this is case study for italian language.
</prevsent>
<prevsent>for the moment, we re implement universal stat for major romance languages.
</prevsent>
</prevsection>
<citsent citstr=" E06-2022 ">
most of previous work on extracting terms, especially for multiple languages are focusing on single-word terms and they are also often based on statistical approach with simple morphological patterns, for example bernhard (2006), <papid> E06-2022 </papid>and velupillai and dalianis (2008).<papid> W08-1403 </papid></citsent>
<aftsection>
<nextsent>54 nominal ending adjectival ending examples -zione -tivo affermazione (affirmation?)
</nextsent>
<nextsent>/ affermativo (affirmative?)
</nextsent>
<nextsent>-zione -ante comunicazione (communication?)
</nextsent>
<nextsent>/ comunicante (communicable?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG255">
<title id=" W10-3408.xml">conceptual structure of automatically extracted multiword terms from domain specific corpora a case study for italian </title>
<section> discussion, conclusion and future.  </section>
<citcontext>
<prevsection>
<prevsent>this paper is based on our efforts on automatic multi-word terms extraction and its conceptual structure for multiple languages and this is case study for italian language.
</prevsent>
<prevsent>for the moment, we re implement universal stat for major romance languages.
</prevsent>
</prevsection>
<citsent citstr=" W08-1403 ">
most of previous work on extracting terms, especially for multiple languages are focusing on single-word terms and they are also often based on statistical approach with simple morphological patterns, for example bernhard (2006), <papid> E06-2022 </papid>and velupillai and dalianis (2008).<papid> W08-1403 </papid></citsent>
<aftsection>
<nextsent>54 nominal ending adjectival ending examples -zione -tivo affermazione (affirmation?)
</nextsent>
<nextsent>/ affermativo (affirmative?)
</nextsent>
<nextsent>-zione -ante comunicazione (communication?)
</nextsent>
<nextsent>/ comunicante (communicable?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG256">
<title id=" W10-1727.xml">vs and oovs two problems for translation between german and english </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>combining them lead to improvements in both language directions.
</prevsent>
<prevsent>we present the liu translation system for the constrained condition of the wmt10 shared translation task, between german and english in both directions.
</prevsent>
</prevsection>
<citsent citstr=" W09-0421 ">
the system is based on the 2009 liu submission (holmqvist et al, 2009), <papid> W09-0421 </papid>that used compound processing, morphological sequence models, and improved alignment by reordering.this year we have focused on two issues: translation of verbs, which is problematic for translation between english and german since the verb placement is different with german verbs often being placed at the end of sentences; and oovs, out of-vocabulary words, which are problematic for machine translation in general.</citsent>
<aftsection>
<nextsent>verb translation is targeted by trying to improve alignment, which we believe is crucial step for verb translation since verbs that are far apart are often not aligned at all.
</nextsent>
<nextsent>we do this mainly by moving verbs to the end of sentences previous to alignment, which wealso combine with other alignments.
</nextsent>
<nextsent>we transform oovs into known words in post-processing step, based on casing, stemming, and splitting of hyphenated compounds.
</nextsent>
<nextsent>in addition, we perform general compound splitting for german both before training and translation, which also reduces the oov rate.all results in this article are for the development test set newstest2009, on true cased output.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG257">
<title id=" W10-1727.xml">vs and oovs two problems for translation between german and english </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we transform oovs into known words in post-processing step, based on casing, stemming, and splitting of hyphenated compounds.
</prevsent>
<prevsent>in addition, we perform general compound splitting for german both before training and translation, which also reduces the oov rate.all results in this article are for the development test set newstest2009, on true cased output.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
we report bleu scores (papineni et al, 2002) <papid> P02-1040 </papid>and meteor ranking (without wordnet) scores (agar wal and lavie, 2008), <papid> W08-0312 </papid>using percent notation.</citsent>
<aftsection>
<nextsent>we also used other metrics, but as they gave similar results they are not reported.
</nextsent>
<nextsent>for significance testing we used approximate randomization (riezler and maxwell, 2005), <papid> W05-0908 </papid>with   0.05.</nextsent>
<nextsent>the 2010 liu system is based on the pbsmt base line system for the wmt shared translation task1.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG258">
<title id=" W10-1727.xml">vs and oovs two problems for translation between german and english </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we transform oovs into known words in post-processing step, based on casing, stemming, and splitting of hyphenated compounds.
</prevsent>
<prevsent>in addition, we perform general compound splitting for german both before training and translation, which also reduces the oov rate.all results in this article are for the development test set newstest2009, on true cased output.
</prevsent>
</prevsection>
<citsent citstr=" W08-0312 ">
we report bleu scores (papineni et al, 2002) <papid> P02-1040 </papid>and meteor ranking (without wordnet) scores (agar wal and lavie, 2008), <papid> W08-0312 </papid>using percent notation.</citsent>
<aftsection>
<nextsent>we also used other metrics, but as they gave similar results they are not reported.
</nextsent>
<nextsent>for significance testing we used approximate randomization (riezler and maxwell, 2005), <papid> W05-0908 </papid>with   0.05.</nextsent>
<nextsent>the 2010 liu system is based on the pbsmt base line system for the wmt shared translation task1.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG259">
<title id=" W10-1727.xml">vs and oovs two problems for translation between german and english </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we report bleu scores (papineni et al, 2002) <papid> P02-1040 </papid>and meteor ranking (without wordnet) scores (agar wal and lavie, 2008), <papid> W08-0312 </papid>using percent notation.</prevsent>
<prevsent>we also used other metrics, but as they gave similar results they are not reported.</prevsent>
</prevsection>
<citsent citstr=" W05-0908 ">
for significance testing we used approximate randomization (riezler and maxwell, 2005), <papid> W05-0908 </papid>with   0.05.</citsent>
<aftsection>
<nextsent>the 2010 liu system is based on the pbsmt base line system for the wmt shared translation task1.
</nextsent>
<nextsent>we use the moses toolkit (koehn et al, 2007) <papid> P07-2045 </papid>for decoding and to train translation models, giza++ (och and ney, 2003) <papid> J03-1002 </papid>for word alignment, and the srilm toolkit (stolcke, 2002) to train languagemodels.</nextsent>
<nextsent>the main difference to the wmt base line is that the liu system is trained on truecaseddata, as in koehn et al (2008), instead of lower cased data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG260">
<title id=" W10-1727.xml">vs and oovs two problems for translation between german and english </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>for significance testing we used approximate randomization (riezler and maxwell, 2005), <papid> W05-0908 </papid>with   0.05.</prevsent>
<prevsent>the 2010 liu system is based on the pbsmt base line system for the wmt shared translation task1.</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
we use the moses toolkit (koehn et al, 2007) <papid> P07-2045 </papid>for decoding and to train translation models, giza++ (och and ney, 2003) <papid> J03-1002 </papid>for word alignment, and the srilm toolkit (stolcke, 2002) to train languagemodels.</citsent>
<aftsection>
<nextsent>the main difference to the wmt base line is that the liu system is trained on truecaseddata, as in koehn et al (2008), instead of lower cased data.
</nextsent>
<nextsent>this means that there is no need for full re casing step after translation, instead we only need to upper case the first word in each sentence.
</nextsent>
<nextsent>2.1 corpus.
</nextsent>
<nextsent>we participated in the constrained task, where weonly trained the liu system on the news and eu roparl corpora provided for the workshop.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG261">
<title id=" W10-1727.xml">vs and oovs two problems for translation between german and english </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>for significance testing we used approximate randomization (riezler and maxwell, 2005), <papid> W05-0908 </papid>with   0.05.</prevsent>
<prevsent>the 2010 liu system is based on the pbsmt base line system for the wmt shared translation task1.</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
we use the moses toolkit (koehn et al, 2007) <papid> P07-2045 </papid>for decoding and to train translation models, giza++ (och and ney, 2003) <papid> J03-1002 </papid>for word alignment, and the srilm toolkit (stolcke, 2002) to train languagemodels.</citsent>
<aftsection>
<nextsent>the main difference to the wmt base line is that the liu system is trained on truecaseddata, as in koehn et al (2008), instead of lower cased data.
</nextsent>
<nextsent>this means that there is no need for full re casing step after translation, instead we only need to upper case the first word in each sentence.
</nextsent>
<nextsent>2.1 corpus.
</nextsent>
<nextsent>we participated in the constrained task, where weonly trained the liu system on the news and eu roparl corpora provided for the workshop.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG263">
<title id=" W10-1727.xml">vs and oovs two problems for translation between german and english </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>the translation and reordering models were trained using the bilingual europarl and news commentary corpora, which we concatenated.
</prevsent>
<prevsent>we used two sets of language models, one where we first trained two models on europarl and news commentary, which we then interpolated 1http://www.statmt.org/wmt10/baseline.
</prevsent>
</prevsection>
<citsent citstr=" W07-0733 ">
html 183 with more weight given to the news commentary, using weights from koehn and schroeder (2007).<papid> W07-0733 </papid></citsent>
<aftsection>
<nextsent>the second set of language models were trained on monolingual news data.
</nextsent>
<nextsent>for tuning we used every second sentence, in total 1025 sentences, of news-test2008.
</nextsent>
<nextsent>2.2 training with limited computational.
</nextsent>
<nextsent>resources one challenge for us was to train the translation sytem with limited computational resources.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG264">
<title id=" W10-1727.xml">vs and oovs two problems for translation between german and english </title>
<section> morphological processing.  </section>
<citcontext>
<prevsection>
<prevsent>we utilized the factored translation framework in moses, to enrich the baseline system with an additional target sequence model.
</prevsent>
<prevsent>for english we used part-of-speech tags obtained using tree tagger (schmid, 1994), enriched with more fine grained tags for the number of determiners, in order to target more agreement issues, since nouns already have number in the tagset.
</prevsent>
</prevsection>
<citsent citstr=" C08-1098 ">
for german we used morphologically rich tags from rftagger (schmid and laws, 2008), <papid> C08-1098 </papid>that contains morphological information such as case, number, and gender for nouns and tense for verbs.</citsent>
<aftsection>
<nextsent>we used the extra factor in an additional sequence model on the target side, which can improve word order system bleu meteor baseline 13.42 48.83 + morph 13.85 49.69 + comp 14.24 49.41 table 1: results for morphological processing, english german system bleu meteor baseline 18.34 38.13 + morph 18.39 37.86 + comp 18.50 38.47 table 2: results for morphological processing, german english and agreement between words.
</nextsent>
<nextsent>for german the factor was also used for compound merging.prior to training and translation, compound processing was performed, using an empirical method (koehn and knight, 2003; <papid> E03-1076 </papid>stymne, 2008) that splits words if they can be split into parts that occur in monolingual corpus, choosing the splitting option with the highest arithmetic mean of its part frequencies in the corpus.</nextsent>
<nextsent>we split nouns, adjectives and verbs, into parts that are content words or particles.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG265">
<title id=" W10-1727.xml">vs and oovs two problems for translation between german and english </title>
<section> morphological processing.  </section>
<citcontext>
<prevsection>
<prevsent>for german we used morphologically rich tags from rftagger (schmid and laws, 2008), <papid> C08-1098 </papid>that contains morphological information such as case, number, and gender for nouns and tense for verbs.</prevsent>
<prevsent>we used the extra factor in an additional sequence model on the target side, which can improve word order system bleu meteor baseline 13.42 48.83 + morph 13.85 49.69 + comp 14.24 49.41 table 1: results for morphological processing, english german system bleu meteor baseline 18.34 38.13 + morph 18.39 37.86 + comp 18.50 38.47 table 2: results for morphological processing, german english and agreement between words.</prevsent>
</prevsection>
<citsent citstr=" E03-1076 ">
for german the factor was also used for compound merging.prior to training and translation, compound processing was performed, using an empirical method (koehn and knight, 2003; <papid> E03-1076 </papid>stymne, 2008) that splits words if they can be split into parts that occur in monolingual corpus, choosing the splitting option with the highest arithmetic mean of its part frequencies in the corpus.</citsent>
<aftsection>
<nextsent>we split nouns, adjectives and verbs, into parts that are content words or particles.
</nextsent>
<nextsent>we imposed length limit on parts of 3 characters for translation from german and of 6 characters for translation from english, and we had stop list of parts that often led to errors, such as arische (aryan) in konsularische (consular).
</nextsent>
<nextsent>we allowed 10 common letter changes(langer, 1998) and hyphens at split points.
</nextsent>
<nextsent>compound parts were given special part-of-speech tag that matches the head word.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG266">
<title id=" W10-1727.xml">vs and oovs two problems for translation between german and english </title>
<section> improved alignment by reordering.  </section>
<citcontext>
<prevsection>
<prevsent>for translation into german, compound processing gave significant improvement on both metrics compared to the baseline, and on bleu compared to the system with morphological sequence models.
</prevsent>
<prevsent>overall, we believe that both compound splitting and morphology are useful; thus all experiments reported in the sequel are based on the baseline system with morphology models and compound splitting, which we will call base.
</prevsent>
</prevsection>
<citsent citstr=" D07-1077 ">
previous work has shown that translation quality can be improved by making the source language more similar to the target language, for instance in terms of word order (wang et al, 2007; <papid> D07-1077 </papid>xia and mccord, 2004).<papid> C04-1073 </papid></citsent>
<aftsection>
<nextsent>in order to harmonize the word order of the source and target sentence, they applied hand-crafted or automatically induced reordering rules to the source sentences of the training corpus.
</nextsent>
<nextsent>at decoding time, reordering rules were again applied to input sentences before translation.
</nextsent>
<nextsent>the positive effects of such methods seemto come from combination of improved alignment and improved reordering during translation.
</nextsent>
<nextsent>in contrast, we focus on improving the word alignment by reordering the training corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG267">
<title id=" W10-1727.xml">vs and oovs two problems for translation between german and english </title>
<section> improved alignment by reordering.  </section>
<citcontext>
<prevsection>
<prevsent>for translation into german, compound processing gave significant improvement on both metrics compared to the baseline, and on bleu compared to the system with morphological sequence models.
</prevsent>
<prevsent>overall, we believe that both compound splitting and morphology are useful; thus all experiments reported in the sequel are based on the baseline system with morphology models and compound splitting, which we will call base.
</prevsent>
</prevsection>
<citsent citstr=" C04-1073 ">
previous work has shown that translation quality can be improved by making the source language more similar to the target language, for instance in terms of word order (wang et al, 2007; <papid> D07-1077 </papid>xia and mccord, 2004).<papid> C04-1073 </papid></citsent>
<aftsection>
<nextsent>in order to harmonize the word order of the source and target sentence, they applied hand-crafted or automatically induced reordering rules to the source sentences of the training corpus.
</nextsent>
<nextsent>at decoding time, reordering rules were again applied to input sentences before translation.
</nextsent>
<nextsent>the positive effects of such methods seemto come from combination of improved alignment and improved reordering during translation.
</nextsent>
<nextsent>in contrast, we focus on improving the word alignment by reordering the training corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG270">
<title id=" W10-1727.xml">vs and oovs two problems for translation between german and english </title>
<section> preprocessing of oovs.  </section>
<citcontext>
<prevsection>
<prevsent>this work is related to work by arora et al(2008), who transformed hindi oovs by using morphological analysers, before translation to japanese.
</prevsent>
<prevsent>our work has the advantage that it is more knowledge-lite, as it only needs porter stemmer and monolingual corpus.
</prevsent>
</prevsection>
<citsent citstr=" P09-1089 ">
mirkin et al(2009) <papid> P09-1089 </papid>used wordnet to replace oovs by synonyms or hypernyms, and chose the best overall translation partly based on scoring of the sourcetransformations.</citsent>
<aftsection>
<nextsent>our oov handling could potentially be used in combination with both these strategies.
</nextsent>
<nextsent>for the final liu shared task submission we used the base+verb+reorder+oov system forgermanenglish and the base+verb+oov system for english german, which had the best overall scores considering all metrics.
</nextsent>
<nextsent>to these systems we added minimum bayes risk (mbr) decoding (kumar and byrne, 2004).<papid> N04-1022 </papid></nextsent>
<nextsent>in standard decoding, the top suggestion of the translation system is chosen as the system output.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG271">
<title id=" W10-1727.xml">vs and oovs two problems for translation between german and english </title>
<section> final submission.  </section>
<citcontext>
<prevsection>
<prevsent>our oov handling could potentially be used in combination with both these strategies.
</prevsent>
<prevsent>for the final liu shared task submission we used the base+verb+reorder+oov system forgermanenglish and the base+verb+oov system for english german, which had the best overall scores considering all metrics.
</prevsent>
</prevsection>
<citsent citstr=" N04-1022 ">
to these systems we added minimum bayes risk (mbr) decoding (kumar and byrne, 2004).<papid> N04-1022 </papid></citsent>
<aftsection>
<nextsent>in standard decoding, the top suggestion of the translation system is chosen as the system output.
</nextsent>
<nextsent>in mbr decoding the risk is spread by choosing the translation that is most similar to the highest scoring translation suggestions from the system, with = 100, as suggested in koehn et al (2008).mbr decoding gave hardly any changes in automatic scores, as shown in tables 6 and 7.
</nextsent>
<nextsent>the final system was significantly better than the baseline inall cases, and significantly better than base on meteor in both translation directions, and on bleu for translation into english.
</nextsent>
<nextsent>as in holmqvist et al (2009) <papid> W09-0421 </papid>reordering by using giza++ in two phases had small, but consistent positive effect.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG273">
<title id=" W10-2416.xml">using deep belief nets for chinese named entity categorization </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>machine learning models attract more attentions recently.
</prevsent>
<prevsent>usually, they train classification models based on context features.
</prevsent>
</prevsection>
<citsent citstr=" P02-1060 ">
various lexical and syntactic features are considered, such as n-grams, part-of-speech (pos), and etc. zhou and su (2002) <papid> P02-1060 </papid>integrated four different kinds of features, which convey different semantic information, for classification model based on the hidden markov model (hmm).</citsent>
<aftsection>
<nextsent>koen (2006) built classifier with the conditional random field (crf) model to classify noun phrases in text with the wordnet synset.
</nextsent>
<nextsent>isozaki and kazawa (2002) <papid> C02-1054 </papid>studied the use of svm instead.</nextsent>
<nextsent>there were fewer studies in chinese entity categorization.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG274">
<title id=" W10-2416.xml">using deep belief nets for chinese named entity categorization </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>various lexical and syntactic features are considered, such as n-grams, part-of-speech (pos), and etc. zhou and su (2002) <papid> P02-1060 </papid>integrated four different kinds of features, which convey different semantic information, for classification model based on the hidden markov model (hmm).</prevsent>
<prevsent>koen (2006) built classifier with the conditional random field (crf) model to classify noun phrases in text with the wordnet synset.</prevsent>
</prevsection>
<citsent citstr=" C02-1054 ">
isozaki and kazawa (2002) <papid> C02-1054 </papid>studied the use of svm instead.</citsent>
<aftsection>
<nextsent>there were fewer studies in chinese entity categorization.
</nextsent>
<nextsent>guo and jiang (2005) applied robust risk minimization to classify the named entities.
</nextsent>
<nextsent>the features include seven traditional lexical features and two external-ne-hints based features.
</nextsent>
<nextsent>an important result they reported is that character-based features can be as good as word based features since they avoid the chinese word segmentation errors.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG275">
<title id=" W10-2416.xml">using deep belief nets for chinese named entity categorization </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the features include seven traditional lexical features and two external-ne-hints based features.
</prevsent>
<prevsent>an important result they reported is that character-based features can be as good as word based features since they avoid the chinese word segmentation errors.
</prevsent>
</prevsection>
<citsent citstr=" W03-1026 ">
in (jing et al, 2003), <papid> W03-1026 </papid>it was further reported that pure character-based models can even outperform word-based models with character combination features.</citsent>
<aftsection>
<nextsent>deep belief net is introduced in (hinton et al, 2006).
</nextsent>
<nextsent>according to their definition, dbn is deep neural network that consists of one or more restricted boltzmann machine (rbm) layers and back propagation (bp) layer.
</nextsent>
<nextsent>this multilayer structure leads to strong representation power of dbn.
</nextsent>
<nextsent>moreover, dbn is quite efficient by using rbm to implement the middle layers, since rbm can be learned very quickly by the contrastive divergence (cd) approach.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG276">
<title id=" W10-2901.xml">improvements in unsupervised cooccurrence based parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>huge annotated corpora consisting of sentences extracted from the internet barely exist until now.
</prevsent>
<prevsent>consequential lot of effort has been put into unsupervised grammar induction during the last years and results and performance of unsupervised parsers improved steadily.
</prevsent>
</prevsection>
<citsent citstr=" P02-1017 ">
klein and manning (2002)<papid> P02-1017 </papid>s constituent context model (ccm) obtains 51.2% f-score on atis part-of-speech strings.</citsent>
<aftsection>
<nextsent>the same model achieves 71.1% on wall street journal corpus sentences with length of at most 10 pos tags.
</nextsent>
<nextsent>in (klein and manning, 2004) <papid> P04-1061 </papid>an approach combining constituency and dependency models yields 77.6% f-score.</nextsent>
<nextsent>bod(2006)<papid> P06-1109 </papid>s all-subtree approach ? known as data oriented parsing (dop) ? reports 82.9% for uml-dop.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG277">
<title id=" W10-2901.xml">improvements in unsupervised cooccurrence based parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>klein and manning (2002)<papid> P02-1017 </papid>s constituent context model (ccm) obtains 51.2% f-score on atis part-of-speech strings.</prevsent>
<prevsent>the same model achieves 71.1% on wall street journal corpus sentences with length of at most 10 pos tags.</prevsent>
</prevsection>
<citsent citstr=" P04-1061 ">
in (klein and manning, 2004) <papid> P04-1061 </papid>an approach combining constituency and dependency models yields 77.6% f-score.</citsent>
<aftsection>
<nextsent>bod(2006)<papid> P06-1109 </papid>s all-subtree approach ? known as data oriented parsing (dop) ? reports 82.9% for uml-dop.</nextsent>
<nextsent>seginer (2007)<papid> P07-1049 </papid>s common cover links model (ccl) does not need any prior tagging and is applied on word strings directly.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG278">
<title id=" W10-2901.xml">improvements in unsupervised cooccurrence based parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the same model achieves 71.1% on wall street journal corpus sentences with length of at most 10 pos tags.
</prevsent>
<prevsent>in (klein and manning, 2004) <papid> P04-1061 </papid>an approach combining constituency and dependency models yields 77.6% f-score.</prevsent>
</prevsection>
<citsent citstr=" P06-1109 ">
bod(2006)<papid> P06-1109 </papid>s all-subtree approach ? known as data oriented parsing (dop) ? reports 82.9% for uml-dop.</citsent>
<aftsection>
<nextsent>seginer (2007)<papid> P07-1049 </papid>s common cover links model (ccl) does not need any prior tagging and is applied on word strings directly.</nextsent>
<nextsent>the f-score for english is 75.9%, and for german (negra10)59% is achieved.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG279">
<title id=" W10-2901.xml">improvements in unsupervised cooccurrence based parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in (klein and manning, 2004) <papid> P04-1061 </papid>an approach combining constituency and dependency models yields 77.6% f-score.</prevsent>
<prevsent>bod(2006)<papid> P06-1109 </papid>s all-subtree approach ? known as data oriented parsing (dop) ? reports 82.9% for uml-dop.</prevsent>
</prevsection>
<citsent citstr=" P07-1049 ">
seginer (2007)<papid> P07-1049 </papid>s common cover links model (ccl) does not need any prior tagging and is applied on word strings directly.</citsent>
<aftsection>
<nextsent>the f-score for english is 75.9%, and for german (negra10)59% is achieved.
</nextsent>
<nextsent>hanig et al (2008) present cooccurrence based constituent detection algorithm which is applied to word forms, too (unsupervisedpos tags are induced using unsupos, see (bie mann, 2006)).<papid> P06-3002 </papid></nextsent>
<nextsent>an f-score of 63.4% is reported for german data.in this paper, we want to present new unsupervised co-occurrence based grammar induction model based on hanig et al (2008).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG280">
<title id=" W10-2901.xml">improvements in unsupervised cooccurrence based parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>seginer (2007)<papid> P07-1049 </papid>s common cover links model (ccl) does not need any prior tagging and is applied on word strings directly.</prevsent>
<prevsent>the f-score for english is 75.9%, and for german (negra10)59% is achieved.</prevsent>
</prevsection>
<citsent citstr=" P06-3002 ">
hanig et al (2008) present cooccurrence based constituent detection algorithm which is applied to word forms, too (unsupervisedpos tags are induced using unsupos, see (bie mann, 2006)).<papid> P06-3002 </papid></citsent>
<aftsection>
<nextsent>an f-score of 63.4% is reported for german data.in this paper, we want to present new unsupervised co-occurrence based grammar induction model based on hanig et al (2008).
</nextsent>
<nextsent>in the following section, we give short introduction to the base algorithm unsuparse.
</nextsent>
<nextsent>afterwards, we present improvements to this algorithm.
</nextsent>
<nextsent>in the final section, we evaluate the proposed model against existing ones and discuss the results.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG281">
<title id=" W10-2901.xml">improvements in unsupervised cooccurrence based parsing </title>
<section> co-occurrence based parsing.  </section>
<citcontext>
<prevsection>
<prevsent>b = sig (?
</prevsent>
<prevsent>, b) (2)?
</prevsent>
</prevsection>
<citsent citstr=" J93-1003 ">
additionally, third value is necessary to represent the statistical significance of the neighbourhood co-occurrence containing word and b. = sig (a,b) (3) to compute those significance values for corpus, the log-likelihood measure (see (dunning, 1993)) <papid> J93-1003 </papid>is applied using corpus size n, term frequencies na and nb (for the words and b) and frequency nab of the co-occurrence of and b. to detect constituent borders between two words, separation value sepab can be defined as: sepab = c ? c = ? c2 (4) if word occurs more significantly at the end ofa sentence as in front of b, then ac   1.</citsent>
<aftsection>
<nextsent>additionally, is larger than if is observed more significantly at the beginning of sentence as after and bc will be   1.
</nextsent>
<nextsent>in this case sepab is   1 and obviously, constituent border would be situated between and b. the basic approach to create parse trees from separation values between two adjacent words isto consecutively merge the two subtrees containing the words with the smallest separation value between them ? starting with each word in separate subtree.
</nextsent>
<nextsent>in order to avoid data sparseness problems, co-occurrences and separation values are primarily calculated on part-of-speech tags.however, word co-occurrences will be used to preserve word form specific dependencies.
</nextsent>
<nextsent>in this paper, we want to present unsuparse+?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG282">
<title id=" W10-2901.xml">improvements in unsupervised cooccurrence based parsing </title>
<section> co-occurrence based parsing.  </section>
<citcontext>
<prevsection>
<prevsent>pref (pn1) ? 1 ?
</prevsent>
<prevsent>(7) an uncertainty factor is introduced by ?, as some parts-of-speech tend to not appear at the borders of sentence although they prefer certain position within constituents.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
some examples (given intable 1) of the 5 most frequent english2 and ger 2penn tree tagset, see (marcus et al, 1993) <papid> J93-2004 </papid>man3 parts-of-speech will demonstrate this effect.</citsent>
<aftsection>
<nextsent>english german nn 0.08 nn 0.30 in 31.45 art 242.48 nnp 1.39 appr 143.62 dt 84.19 adja 5.06 nns 0.31 ne 1.11table 1: values of pref (pos) for the 5 most frequent parts-of-speech of english and german in both languages proper nouns (nnp resp.
</nextsent>
<nextsent>ne)occur slightly more often at the beginning of sentence than at its end, although proper nouns prefer ? like normal nouns ? the last position of phrase.
</nextsent>
<nextsent>to account for this effect, pref (a) will be iteratively adapted to the observations of learned grammar rules as given in equ.
</nextsent>
<nextsent>8: pref (p0)?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG288">
<title id=" W10-2308.xml">cross lingual comparison between distributionally determined word similarity networks </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>language specific morphology is found to be dominating factor for the accuracy of the model.
</prevsent>
<prevsent>this work takes as its point of departure the fact that most studies of the distributional character of terms in language are language specific.
</prevsent>
</prevsection>
<citsent citstr=" C02-1114 ">
a model or technique either geometric (deerwester et al , 1990; finch and chater, 1992; lund and burgess, 1996; letsche and berry, 1997; kanerva et al , 2000) or graph based (i cancho and sole?, 2001; widdows and dorow, 2002; <papid> C02-1114 </papid>biemann, 2006)?<papid> W06-3812 </papid></citsent>
<aftsection>
<nextsent>that works quite well for one language may not be suitable for other languages.
</nextsent>
<nextsent>a general question of interest is then: what strengths and weaknesses of distributional models are universal and what are language specific in this paper we approach this question by formulating distributionally based network model, apply the model on eleven different languages, andthen compare the resulting networks.
</nextsent>
<nextsent>we compare the networks both in terms of global statistical properties and local structures of word-to-wordrelations of linguistic relevance.
</nextsent>
<nextsent>more specifically, the generated networks constitute words (vertices) that are connected with edges if they are observed to occur in similar contexts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG289">
<title id=" W10-2308.xml">cross lingual comparison between distributionally determined word similarity networks </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>language specific morphology is found to be dominating factor for the accuracy of the model.
</prevsent>
<prevsent>this work takes as its point of departure the fact that most studies of the distributional character of terms in language are language specific.
</prevsent>
</prevsection>
<citsent citstr=" W06-3812 ">
a model or technique either geometric (deerwester et al , 1990; finch and chater, 1992; lund and burgess, 1996; letsche and berry, 1997; kanerva et al , 2000) or graph based (i cancho and sole?, 2001; widdows and dorow, 2002; <papid> C02-1114 </papid>biemann, 2006)?<papid> W06-3812 </papid></citsent>
<aftsection>
<nextsent>that works quite well for one language may not be suitable for other languages.
</nextsent>
<nextsent>a general question of interest is then: what strengths and weaknesses of distributional models are universal and what are language specific in this paper we approach this question by formulating distributionally based network model, apply the model on eleven different languages, andthen compare the resulting networks.
</nextsent>
<nextsent>we compare the networks both in terms of global statistical properties and local structures of word-to-wordrelations of linguistic relevance.
</nextsent>
<nextsent>more specifically, the generated networks constitute words (vertices) that are connected with edges if they are observed to occur in similar contexts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG290">
<title id=" W10-1749.xml">lrscore for evaluating lexical and reordering quality in mt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there are two main approaches to capturing reordering.
</prevsent>
<prevsent>the first way to measure the quality of word order is to count the number of matching n-grams between the reference and the hypothesis.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
this is the approach taken by the bleu score (papineni et al , 2002).<papid> P02-1040 </papid></citsent>
<aftsection>
<nextsent>this method discounts any n-gram which is not identical to reference n-gram, and also does not consider the relative position of the strings.
</nextsent>
<nextsent>theycan be anywhere in the sentence.
</nextsent>
<nextsent>another common approach is typified by meteor (banerjee and lavie, 2005) <papid> W05-0909 </papid>and ter (snover et al , 2006).they calculate an ordering penalty for hypothesis based on the minimum number of chunks the translation needs to be broken into in order to align it to the reference.</nextsent>
<nextsent>the disadvantage of the second approach is that aligning sentences with very different words can be inaccurate.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG291">
<title id=" W10-1749.xml">lrscore for evaluating lexical and reordering quality in mt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this method discounts any n-gram which is not identical to reference n-gram, and also does not consider the relative position of the strings.
</prevsent>
<prevsent>theycan be anywhere in the sentence.
</prevsent>
</prevsection>
<citsent citstr=" W05-0909 ">
another common approach is typified by meteor (banerjee and lavie, 2005) <papid> W05-0909 </papid>and ter (snover et al , 2006).they calculate an ordering penalty for hypothesis based on the minimum number of chunks the translation needs to be broken into in order to align it to the reference.</citsent>
<aftsection>
<nextsent>the disadvantage of the second approach is that aligning sentences with very different words can be inaccurate.
</nextsent>
<nextsent>also there is no notion of how far these blocks are out of order.more sophisticated metrics, such as the rte metric (pado?
</nextsent>
<nextsent>et al , 2009), use higher level syntactic or even semantic analysis to determine the quality of the translation.
</nextsent>
<nextsent>these approaches are useful, butcan be very slow, require annotation, they are language dependent and their parameters are hard to train.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG292">
<title id=" W10-1749.xml">lrscore for evaluating lexical and reordering quality in mt </title>
<section> reordering metrics.  </section>
<citcontext>
<prevsection>
<prevsent>it consequently measures not only how many reordering there are but also the distance that words are reordered.
</prevsent>
<prevsent>in statistics, spear mans rho and ken dalls tauare widely used non-parametric measures of association for two rankings.
</prevsent>
</prevsection>
<citsent citstr=" P03-1069 ">
in natural language processing research, ken dalls tau has been used as means of estimating the distance betweena system-generated and human-generated gold standard order for the sentence ordering task (la pata, 2003).<papid> P03-1069 </papid></citsent>
<aftsection>
<nextsent>ken dalls tau has also been usedin machine translation as cost function in reordering model (eisner and tromble, 2006) and an mt metric called rouge-s (lin and och, 2004) <papid> P04-1077 </papid>is similar to ken dalls tau metric on lexical items.</nextsent>
<nextsent>rouge-s is an f-measure of ordered pairs of words in the translation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG293">
<title id=" W10-1749.xml">lrscore for evaluating lexical and reordering quality in mt </title>
<section> reordering metrics.  </section>
<citcontext>
<prevsection>
<prevsent>in statistics, spear mans rho and ken dalls tauare widely used non-parametric measures of association for two rankings.
</prevsent>
<prevsent>in natural language processing research, ken dalls tau has been used as means of estimating the distance betweena system-generated and human-generated gold standard order for the sentence ordering task (la pata, 2003).<papid> P03-1069 </papid></prevsent>
</prevsection>
<citsent citstr=" P04-1077 ">
ken dalls tau has also been usedin machine translation as cost function in reordering model (eisner and tromble, 2006) and an mt metric called rouge-s (lin and och, 2004) <papid> P04-1077 </papid>is similar to ken dalls tau metric on lexical items.</citsent>
<aftsection>
<nextsent>rouge-s is an f-measure of ordered pairs of words in the translation.
</nextsent>
<nextsent>as far as we know, ken dalls tau has not been used as reordering metric before.
</nextsent>
<nextsent>the goal of much machine translation research is either to improve the quality of the words used in the output, or their ordering.
</nextsent>
<nextsent>we use the reordering metrics and combine them with measurement of lexical performance to produce comprehensive metric, the lrscore.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG294">
<title id=" W10-3708.xml">application of the tightness continuum measure to chinese information retrieval </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>what distinguishes chinese information retrieval from information retrieval (ir) in other languages is the challenge of segmenting the queries and the documents, created by the lack of word delimiters.
</prevsent>
<prevsent>in general, there are two categories of segmenters:character-based methods and word-based methods.
</prevsent>
</prevsection>
<citsent citstr=" C02-1148 ">
despite the superior performance of bigram segment ers (nie et al , 2000; huang et al , 2000;foo and li, 2004), word-based approaches continue to be investigated because of their application in sophisticated ir tasks such as cross language ir, and within techniques such as query expansion (nie et al , 2000; peng et al , 2002<papid> C02-1148 </papid>a).</citsent>
<aftsection>
<nextsent>most word-based segment ers in chinese ir are either rule-based models, which relyon lexicon, or statistical-based models, which are trained on manually segmented corpora (zhang et al ,2003).<papid> W03-1730 </papid></nextsent>
<nextsent>however, the relationship between the accuracy of chinese word segmentation and the performance of chinese ir is non-monotonic.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG301">
<title id=" W10-3708.xml">application of the tightness continuum measure to chinese information retrieval </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in general, there are two categories of segmenters:character-based methods and word-based methods.
</prevsent>
<prevsent>despite the superior performance of bigram segment ers (nie et al , 2000; huang et al , 2000;foo and li, 2004), word-based approaches continue to be investigated because of their application in sophisticated ir tasks such as cross language ir, and within techniques such as query expansion (nie et al , 2000; peng et al , 2002<papid> C02-1148 </papid>a).</prevsent>
</prevsection>
<citsent citstr=" W03-1730 ">
most word-based segment ers in chinese ir are either rule-based models, which relyon lexicon, or statistical-based models, which are trained on manually segmented corpora (zhang et al ,2003).<papid> W03-1730 </papid></citsent>
<aftsection>
<nextsent>however, the relationship between the accuracy of chinese word segmentation and the performance of chinese ir is non-monotonic.
</nextsent>
<nextsent>penget al  (2002<papid> C02-1148 </papid>b) reported that segmentation methods achieving segmentation accuracy higher than 90% according to manual segmentation standard yield no improvement in ir performance.</nextsent>
<nextsent>they further argued that ir often benefits from splitting compound words that are annotated as single units by manual segmentation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG303">
<title id=" W10-3708.xml">application of the tightness continuum measure to chinese information retrieval </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they further argued that ir often benefits from splitting compound words that are annotated as single units by manual segmentation.
</prevsent>
<prevsent>the essence of the problem is that there is no clear definition of word in chinese.
</prevsent>
</prevsection>
<citsent citstr=" J96-3004 ">
experiment shave shown only about 75% agreement among native speakers regarding the correct word segmentation (sproat et al , 1996).<papid> J96-3004 </papid></citsent>
<aftsection>
<nextsent>while units such as ??
</nextsent>
<nextsent>(peanut) and ???|?
</nextsent>
<nextsent>(match maker) should clearly be considered as single term in chinese ir, compounds such as ??????
</nextsent>
<nextsent>(ma chine learning) are more controversial.1xu et al  (2009) proposed continuum hypothesis?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG304">
<title id=" W10-3708.xml">application of the tightness continuum measure to chinese information retrieval </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>that rejects clean binary classification of chinese semantic units as either compositional or non-compositional.
</prevsent>
<prevsent>instead, they introduced the notion of tightness measure, which quantifies the degree of compositionality.
</prevsent>
</prevsection>
<citsent citstr=" W03-1810 ">
onthis tightness continuum, at one extreme are non 1this issue is also present to certain degree in languages that do use explicit delimiters, including english (halpern, 2000; mccarthy et al , 2003; <papid> W03-1810 </papid>guenthner and blanco, 2004).</citsent>
<aftsection>
<nextsent>55 compositional semantic units, such as ???|?
</nextsent>
<nextsent>(match maker), and at the other end are sequences of consecutive words with no dependency relationship, such as 0???
</nextsent>
<nextsent>(shang hai where).
</nextsent>
<nextsent>in the middle of the spectrum are compositional compounds such as ??????
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG333">
<title id=" W10-3708.xml">application of the tightness continuum measure to chinese information retrieval </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>section 6 presents the results of our method on word segmentation andir.
</prevsent>
<prevsent>a short conclusion wraps up and gives directions for future work.
</prevsent>
</prevsection>
<citsent citstr=" D08-1111 ">
the impact of different chinese word segmentation methods on ir has received extensive attention in the literature (nie et al , 2000; peng et al , 2002<papid> C02-1148 </papid>a; peng et al , 2002<papid> C02-1148 </papid>b; huang et al , 2000; huang et al , 2003; liu et al , 2008; <papid> D08-1111 </papid>shi and nie, 2009).</citsent>
<aftsection>
<nextsent>for example, foo and li (2004)tested the effects of manual segmentation and various character-based segmentations.
</nextsent>
<nextsent>in contrast with most related work that only reports the over all performance, they provide an in-depth analysis of query results.
</nextsent>
<nextsent>they note that small test collection diminishes the significance of the results.
</nextsent>
<nextsent>in series of papers on chinese ir, pengand huang compared various segmentation methods in ir, and proposed new segmentation method (peng et al , 2002<papid> C02-1148 </papid>a; peng et al , 2002<papid> C02-1148 </papid>b; huang et al , 2000; huang et al , 2003).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG353">
<title id=" W10-3708.xml">application of the tightness continuum measure to chinese information retrieval </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>in terms of our test collection, the 203 query set clearly helps the in-depth analysis for the performance of different ir systems on different queries.
</prevsent>
<prevsent>we also plan to gather more queries and more judged documents in order to further analyze the influence of the proper treatment of semantic units in chinese information retrieval.
</prevsent>
</prevsection>
<citsent citstr=" P09-1118 ">
a large query set could also make it possible to employ machine learning models for ir (song et al , 2009).<papid> P09-1118 </papid></citsent>
<aftsection>




</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG354">
<title id=" W10-2317.xml">computing word senses by semantic mirroring and spectral graph partitioning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>dyvik(1998), dyvik(2005) has provided knowledge discovery method based on the semantic relationship between words in source language and words in target language, as manifested in parallel texts.
</prevsent>
<prevsent>his method is called semantic mirroring and the approach utilizes the way that different languages encode lexical meaning by mirroring source word sand target words back and forth, in order to establish semantic relations like synonymy and hy ponymy.
</prevsent>
</prevsection>
<citsent citstr=" P02-1033 ">
work in this area is strongly related to work within word sense disambiguation (wsd) and the observation that translations are good source for detecting such distinctions (resnik &amp; yarowsky 1999, ide 2000, diab &amp; resnik 2002).<papid> P02-1033 </papid>a word that has multiple meanings in one language is likely to have different translations in other languages.</citsent>
<aftsection>
<nextsent>this means that translations serve as sense indicators for particular source word, and make it possible to divide given word into different senses.in this paper we propose new graph-based approach to the analysis of semantic mirrors.
</nextsent>
<nextsent>the objective is to find viable way to discover synonyms and group them into different senses.
</nextsent>
<nextsent>the method has been applied to bilingual dictionary of english and swedish adjectives.
</nextsent>
<nextsent>2.1 the translation matrix.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG355">
<title id=" W10-2903.xml">driving semantic parsing from the worldrsquos response </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, providing access to databases: question posed in natural language is converted into formal database query that can be executed to retrieve information.example 1 shows nl input query and its corresponding meaning representation.
</prevsent>
<prevsent>example 1 geo query input text and output mr what is the largest state that borders texas??
</prevsent>
</prevsection>
<citsent citstr=" W05-0602 ">
largest(state(next to(const(texas)))) previous works (zelle and mooney, 1996; tang and mooney, 2001; zettlemoyer and collins, 2005; ge and mooney, 2005; <papid> W05-0602 </papid>zettlemoyer and collins, 2007; <papid> D07-1071 </papid>wong and mooney, 2007) <papid> P07-1121 </papid>employ machine learning techniques to construct semantic parser.</citsent>
<aftsection>
<nextsent>the learning algorithm is given set of input sentences and their corresponding meaning representations, and learns statistical semantic parser ? set of rules mapping lexical items and syntactic patterns to their meaning representation and score associated with each rule.
</nextsent>
<nextsent>given sentence, these rules are applied recursively to derive the most probable meaning representation.
</nextsent>
<nextsent>since semantic interpretation is limited to syntactic patterns identified in the training data, the learning algorithm requires considerable amounts of annotated data to account for the syntactic variations associated with the meaning representation.
</nextsent>
<nextsent>annotating sentences with their mr is difficult, time consuming task; minimizing the supervision effort required for learning is major challenge in scaling semantic parsers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG357">
<title id=" W10-2903.xml">driving semantic parsing from the worldrsquos response </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, providing access to databases: question posed in natural language is converted into formal database query that can be executed to retrieve information.example 1 shows nl input query and its corresponding meaning representation.
</prevsent>
<prevsent>example 1 geo query input text and output mr what is the largest state that borders texas??
</prevsent>
</prevsection>
<citsent citstr=" D07-1071 ">
largest(state(next to(const(texas)))) previous works (zelle and mooney, 1996; tang and mooney, 2001; zettlemoyer and collins, 2005; ge and mooney, 2005; <papid> W05-0602 </papid>zettlemoyer and collins, 2007; <papid> D07-1071 </papid>wong and mooney, 2007) <papid> P07-1121 </papid>employ machine learning techniques to construct semantic parser.</citsent>
<aftsection>
<nextsent>the learning algorithm is given set of input sentences and their corresponding meaning representations, and learns statistical semantic parser ? set of rules mapping lexical items and syntactic patterns to their meaning representation and score associated with each rule.
</nextsent>
<nextsent>given sentence, these rules are applied recursively to derive the most probable meaning representation.
</nextsent>
<nextsent>since semantic interpretation is limited to syntactic patterns identified in the training data, the learning algorithm requires considerable amounts of annotated data to account for the syntactic variations associated with the meaning representation.
</nextsent>
<nextsent>annotating sentences with their mr is difficult, time consuming task; minimizing the supervision effort required for learning is major challenge in scaling semantic parsers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG361">
<title id=" W10-2903.xml">driving semantic parsing from the worldrsquos response </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, providing access to databases: question posed in natural language is converted into formal database query that can be executed to retrieve information.example 1 shows nl input query and its corresponding meaning representation.
</prevsent>
<prevsent>example 1 geo query input text and output mr what is the largest state that borders texas??
</prevsent>
</prevsection>
<citsent citstr=" P07-1121 ">
largest(state(next to(const(texas)))) previous works (zelle and mooney, 1996; tang and mooney, 2001; zettlemoyer and collins, 2005; ge and mooney, 2005; <papid> W05-0602 </papid>zettlemoyer and collins, 2007; <papid> D07-1071 </papid>wong and mooney, 2007) <papid> P07-1121 </papid>employ machine learning techniques to construct semantic parser.</citsent>
<aftsection>
<nextsent>the learning algorithm is given set of input sentences and their corresponding meaning representations, and learns statistical semantic parser ? set of rules mapping lexical items and syntactic patterns to their meaning representation and score associated with each rule.
</nextsent>
<nextsent>given sentence, these rules are applied recursively to derive the most probable meaning representation.
</nextsent>
<nextsent>since semantic interpretation is limited to syntactic patterns identified in the training data, the learning algorithm requires considerable amounts of annotated data to account for the syntactic variations associated with the meaning representation.
</nextsent>
<nextsent>annotating sentences with their mr is difficult, time consuming task; minimizing the supervision effort required for learning is major challenge in scaling semantic parsers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG367">
<title id=" W10-2903.xml">driving semantic parsing from the worldrsquos response </title>
<section> model.  </section>
<citcontext>
<prevsection>
<prevsent>capital??
</prevsent>
<prevsent>the ability to adapt to unseen inputs is oneof the key challenges in semantic parsing.
</prevsent>
</prevsection>
<citsent citstr=" W08-2105 ">
several works (zettlemoyer and collins, 2007; <papid> D07-1071 </papid>kate,2008) <papid> W08-2105 </papid>have addressed this issue explicitly by manually defining syntactic transformation rules thatcan help the learned parser generalize better.</citsent>
<aftsection>
<nextsent>unfortunately these are only partial solutions as 3mistake driven algorithms that do not enforce margin constraints may not be able to generalize using this protocol since they will repeat the same prediction at training time and therefore will not update the model.
</nextsent>
<nextsent>manually constructed rule set cannot cover the many syntactic variations.
</nextsent>
<nextsent>given the previous example, we observe that it is enough to identify that the function capital(?)
</nextsent>
<nextsent>and the constant const(texas) appear in the target mr, since there is only single way to compose these entities into single formula ? capital(const(texas)).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG371">
<title id=" W10-2903.xml">driving semantic parsing from the worldrsquos response </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>to answer the second question, we compare asupervised version of our model to existing semantic parsers.
</prevsent>
<prevsent>the results are in table 2.
</prevsent>
</prevsection>
<citsent citstr=" N06-1056 ">
although the numbers are not directly comparable due to different splits in the data7, we can see that with similar number of logical forms for training our supervised approach outperforms existing systems (wong and mooney, 2006; <papid> N06-1056 </papid>wongand mooney, 2007), <papid> P07-1121 </papid>while the aggressive approach remains competitive without using any logical forms.</citsent>
<aftsection>
<nextsent>our supervised model is still very competitive with other approaches (zettlemoyer and collins, 2007; <papid> D07-1071 </papid>wong and mooney, 2007), <papid> P07-1121 </papid>which used considerably more annotated logical forms in the training phase.</nextsent>
<nextsent>in order to answer the third question, we turn our attention to the differences between the two response driven learning approaches.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG379">
<title id=" W10-2903.xml">driving semantic parsing from the worldrsquos response </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>25 70 1 2 3 4 5 6 90 0 10 20 30 40 50 60 70 80 learning iterations cc ur ac on es po ns 25 0 direct approach aggressive approach initialization figure 2: accuracy on training set as number of learning iterations increases.
</prevsent>
<prevsent>learning to map sentences to meaning representation has been studied extensively in the nlp community.
</prevsent>
</prevsection>
<citsent citstr=" W00-1317 ">
early works (zelle and mooney,1996; tang and mooney, 2000) <papid> W00-1317 </papid>employed inductive logic programming approaches to learn semantic parser.</citsent>
<aftsection>
<nextsent>more recent works apply statistical learning methods to the problem.
</nextsent>
<nextsent>in (ge and mooney, 2005; <papid> W05-0602 </papid>nguyen et al , 2006), <papid> P06-2080 </papid>the input tothe learner consists of complete syntactic derivations for the input sentences annotated with logical expressions.</nextsent>
<nextsent>other works (wong and mooney, 2006; <papid> N06-1056 </papid>kate and mooney, 2006; <papid> P06-1115 </papid>zettlemoyer and collins, 2005; zettlemoyer and collins, 2007; <papid> D07-1071 </papid>zettlemoyer and collins, 2009) <papid> P09-1110 </papid>try to alleviate the annotation effort by only taking sentence and logical form pairs to train the models.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG382">
<title id=" W10-2903.xml">driving semantic parsing from the worldrsquos response </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>early works (zelle and mooney,1996; tang and mooney, 2000) <papid> W00-1317 </papid>employed inductive logic programming approaches to learn semantic parser.</prevsent>
<prevsent>more recent works apply statistical learning methods to the problem.</prevsent>
</prevsection>
<citsent citstr=" P06-2080 ">
in (ge and mooney, 2005; <papid> W05-0602 </papid>nguyen et al , 2006), <papid> P06-2080 </papid>the input tothe learner consists of complete syntactic derivations for the input sentences annotated with logical expressions.</citsent>
<aftsection>
<nextsent>other works (wong and mooney, 2006; <papid> N06-1056 </papid>kate and mooney, 2006; <papid> P06-1115 </papid>zettlemoyer and collins, 2005; zettlemoyer and collins, 2007; <papid> D07-1071 </papid>zettlemoyer and collins, 2009) <papid> P09-1110 </papid>try to alleviate the annotation effort by only taking sentence and logical form pairs to train the models.</nextsent>
<nextsent>learning is then defined over hidden patterns in the training data that associate logical symbols with lexical and syntactic elements.in this work we take an additional step towards alleviating the difficulty of training semantic parsers and present world response based training protocol.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG385">
<title id=" W10-2903.xml">driving semantic parsing from the worldrsquos response </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>more recent works apply statistical learning methods to the problem.
</prevsent>
<prevsent>in (ge and mooney, 2005; <papid> W05-0602 </papid>nguyen et al , 2006), <papid> P06-2080 </papid>the input tothe learner consists of complete syntactic derivations for the input sentences annotated with logical expressions.</prevsent>
</prevsection>
<citsent citstr=" P06-1115 ">
other works (wong and mooney, 2006; <papid> N06-1056 </papid>kate and mooney, 2006; <papid> P06-1115 </papid>zettlemoyer and collins, 2005; zettlemoyer and collins, 2007; <papid> D07-1071 </papid>zettlemoyer and collins, 2009) <papid> P09-1110 </papid>try to alleviate the annotation effort by only taking sentence and logical form pairs to train the models.</citsent>
<aftsection>
<nextsent>learning is then defined over hidden patterns in the training data that associate logical symbols with lexical and syntactic elements.in this work we take an additional step towards alleviating the difficulty of training semantic parsers and present world response based training protocol.
</nextsent>
<nextsent>several recent works (chen and mooney, 2008; liang et al , 2009; <papid> P09-1011 </papid>branavan et al ., 2009) <papid> P09-1010 </papid>explore using an external world context as supervision signal for semantic interpretation.</nextsent>
<nextsent>these works operate in settings different to ours as they relyon an external world state that is directly referenced by the input text.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG390">
<title id=" W10-2903.xml">driving semantic parsing from the worldrsquos response </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>more recent works apply statistical learning methods to the problem.
</prevsent>
<prevsent>in (ge and mooney, 2005; <papid> W05-0602 </papid>nguyen et al , 2006), <papid> P06-2080 </papid>the input tothe learner consists of complete syntactic derivations for the input sentences annotated with logical expressions.</prevsent>
</prevsection>
<citsent citstr=" P09-1110 ">
other works (wong and mooney, 2006; <papid> N06-1056 </papid>kate and mooney, 2006; <papid> P06-1115 </papid>zettlemoyer and collins, 2005; zettlemoyer and collins, 2007; <papid> D07-1071 </papid>zettlemoyer and collins, 2009) <papid> P09-1110 </papid>try to alleviate the annotation effort by only taking sentence and logical form pairs to train the models.</citsent>
<aftsection>
<nextsent>learning is then defined over hidden patterns in the training data that associate logical symbols with lexical and syntactic elements.in this work we take an additional step towards alleviating the difficulty of training semantic parsers and present world response based training protocol.
</nextsent>
<nextsent>several recent works (chen and mooney, 2008; liang et al , 2009; <papid> P09-1011 </papid>branavan et al ., 2009) <papid> P09-1010 </papid>explore using an external world context as supervision signal for semantic interpretation.</nextsent>
<nextsent>these works operate in settings different to ours as they relyon an external world state that is directly referenced by the input text.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG391">
<title id=" W10-2903.xml">driving semantic parsing from the worldrsquos response </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>other works (wong and mooney, 2006; <papid> N06-1056 </papid>kate and mooney, 2006; <papid> P06-1115 </papid>zettlemoyer and collins, 2005; zettlemoyer and collins, 2007; <papid> D07-1071 </papid>zettlemoyer and collins, 2009) <papid> P09-1110 </papid>try to alleviate the annotation effort by only taking sentence and logical form pairs to train the models.</prevsent>
<prevsent>learning is then defined over hidden patterns in the training data that associate logical symbols with lexical and syntactic elements.in this work we take an additional step towards alleviating the difficulty of training semantic parsers and present world response based training protocol.</prevsent>
</prevsection>
<citsent citstr=" P09-1011 ">
several recent works (chen and mooney, 2008; liang et al , 2009; <papid> P09-1011 </papid>branavan et al ., 2009) <papid> P09-1010 </papid>explore using an external world context as supervision signal for semantic interpretation.</citsent>
<aftsection>
<nextsent>these works operate in settings different to ours as they relyon an external world state that is directly referenced by the input text.
</nextsent>
<nextsent>although our framework can also be applied in these settings we do not assume that the text can be grounded in world state.
</nextsent>
<nextsent>in our experiments the input text consists of generalized statements which describe some information need that does not correspond directly to grounded world state.
</nextsent>
<nextsent>our learning framework closely follows recent work on learning from indirect supervision.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG392">
<title id=" W10-2903.xml">driving semantic parsing from the worldrsquos response </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>other works (wong and mooney, 2006; <papid> N06-1056 </papid>kate and mooney, 2006; <papid> P06-1115 </papid>zettlemoyer and collins, 2005; zettlemoyer and collins, 2007; <papid> D07-1071 </papid>zettlemoyer and collins, 2009) <papid> P09-1110 </papid>try to alleviate the annotation effort by only taking sentence and logical form pairs to train the models.</prevsent>
<prevsent>learning is then defined over hidden patterns in the training data that associate logical symbols with lexical and syntactic elements.in this work we take an additional step towards alleviating the difficulty of training semantic parsers and present world response based training protocol.</prevsent>
</prevsection>
<citsent citstr=" P09-1010 ">
several recent works (chen and mooney, 2008; liang et al , 2009; <papid> P09-1011 </papid>branavan et al ., 2009) <papid> P09-1010 </papid>explore using an external world context as supervision signal for semantic interpretation.</citsent>
<aftsection>
<nextsent>these works operate in settings different to ours as they relyon an external world state that is directly referenced by the input text.
</nextsent>
<nextsent>although our framework can also be applied in these settings we do not assume that the text can be grounded in world state.
</nextsent>
<nextsent>in our experiments the input text consists of generalized statements which describe some information need that does not correspond directly to grounded world state.
</nextsent>
<nextsent>our learning framework closely follows recent work on learning from indirect supervision.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG393">
<title id=" W10-1745.xml">cmu system combination via hypothesis selection for wmtrsquo10 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we combined mt systems for french - english and german - english using provided data only.
</prevsent>
<prevsent>for the combination of machine translation systems there have been several approaches described in recent publications.
</prevsent>
</prevsection>
<citsent citstr=" W08-0329 ">
one uses confusion networks formed along skeleton sentence to combine translation systems as described in (rosti et al., 2008) <papid> W08-0329 </papid>and (karakos et al, 2008).<papid> P08-2021 </papid></citsent>
<aftsection>
<nextsent>a different approach described in (heafield et al, 2009) <papid> W09-0408 </papid>is not keeping the skeleton fixed when aligning the sys tems.</nextsent>
<nextsent>another approach selects whole hypotheses from combined n-best list (hildebrand and vogel, 2008).our setup follows the latter approach.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG394">
<title id=" W10-1745.xml">cmu system combination via hypothesis selection for wmtrsquo10 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we combined mt systems for french - english and german - english using provided data only.
</prevsent>
<prevsent>for the combination of machine translation systems there have been several approaches described in recent publications.
</prevsent>
</prevsection>
<citsent citstr=" P08-2021 ">
one uses confusion networks formed along skeleton sentence to combine translation systems as described in (rosti et al., 2008) <papid> W08-0329 </papid>and (karakos et al, 2008).<papid> P08-2021 </papid></citsent>
<aftsection>
<nextsent>a different approach described in (heafield et al, 2009) <papid> W09-0408 </papid>is not keeping the skeleton fixed when aligning the sys tems.</nextsent>
<nextsent>another approach selects whole hypotheses from combined n-best list (hildebrand and vogel, 2008).our setup follows the latter approach.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG395">
<title id=" W10-1745.xml">cmu system combination via hypothesis selection for wmtrsquo10 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for the combination of machine translation systems there have been several approaches described in recent publications.
</prevsent>
<prevsent>one uses confusion networks formed along skeleton sentence to combine translation systems as described in (rosti et al., 2008) <papid> W08-0329 </papid>and (karakos et al, 2008).<papid> P08-2021 </papid></prevsent>
</prevsection>
<citsent citstr=" W09-0408 ">
a different approach described in (heafield et al, 2009) <papid> W09-0408 </papid>is not keeping the skeleton fixed when aligning the sys tems.</citsent>
<aftsection>
<nextsent>another approach selects whole hypotheses from combined n-best list (hildebrand and vogel, 2008).our setup follows the latter approach.
</nextsent>
<nextsent>we combine the output from the submitted translation systems, including n-best lists where available, intoone joint n-best list, then calculate set of features consistently for all hypotheses.
</nextsent>
<nextsent>we use mer training on the provided development data to determine feature weights and re-rank the joint best list.
</nextsent>
<nextsent>we train to maximize bleu.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG396">
<title id=" W10-1745.xml">cmu system combination via hypothesis selection for wmtrsquo10 </title>
<section> features.  </section>
<citcontext>
<prevsection>
<prevsent>we use mer training on the provided development data to determine feature weights and re-rank the joint best list.
</prevsent>
<prevsent>we train to maximize bleu.
</prevsent>
</prevsection>
<citsent citstr=" W09-0406 ">
for our entries to the wmt09 we used the following feature groups (in parenthesis are the number of separate feature values per group): ? language model scores (3) ? word lexicon scores (6) ? sentence length features (3) ? rank feature (1) ? normalized n-gram agreement (6) ? source-target word alignment features (6) ? trained system weights (no. of systems)the details on language model and word lexicon scores can be found in (hildebrand and vogel,2008) and details on the rank feature and the normalized n-gram agreement can be found in (hilde brand and vogel, 2009).<papid> W09-0406 </papid></citsent>
<aftsection>
<nextsent>we use three sentence length features, which are the ratio of the hypothesis length to the length of the source sentence, the diversion of this ratio from the overall length ratio of the bilingual training data and the difference between the hypothesis length and the average length of the hypotheses in the n-best list for the respective source sentence.
</nextsent>
<nextsent>the system weights are trained together with the other feature weights during mert using binary feature persystem.
</nextsent>
<nextsent>to the feature vector for each hypothesis one feature per input system is added; for each hypothesis one of the features is one, indicating which system it came from, all others are zero.
</nextsent>
<nextsent>2.1 source-target word alignment features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG397">
<title id=" W10-1745.xml">cmu system combination via hypothesis selection for wmtrsquo10 </title>
<section> features.  </section>
<citcontext>
<prevsection>
<prevsent>to the feature vector for each hypothesis one feature per input system is added; for each hypothesis one of the features is one, indicating which system it came from, all others are zero.
</prevsent>
<prevsent>2.1 source-target word alignment features.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
we trained the ibm word alignment models up to model 4 using the giza++ toolkit (och and ney, 2003) <papid> J03-1002 </papid>on the bilingual training corpus.</citsent>
<aftsection>
<nextsent>then forced alignment algorithm utilizes the trained models to align each source sentence to each translation hypothesis in its respective n-best list.
</nextsent>
<nextsent>we use the alignment score given by the word alignment models, the number of unaligned words 307and the number of null aligned words, all normalized by the sentence length, as three separate features.
</nextsent>
<nextsent>we calculate these align ability features for both language directions.
</nextsent>
<nextsent>in the wmt shared translation task only very small number of participants submitted n-best lists, e.g. in the german-english track there were only four n-best lists among the 16 submissions.our combination method is proven to work significantly better when n-best lists are available.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG399">
<title id=" W10-2805.xml">a regression model of adjective noun compositionality in distributional semantics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>784787).
</prevsent>
<prevsent>while the vector-based representation of word meaning has been used for long time in computational linguistics, the techniques that are currently used have not seen much development with regards to one of the main aspects of semantics in natural language: compositionality.to be fair, the study of semantic compositionality in dsms has seen slight revival in the recent times, cf.
</prevsent>
</prevsection>
<citsent citstr=" P08-1028 ">
widdows (2008), mitchell &amp; la pata (2008), <papid> P08-1028 </papid>giesbrecht (2009), baroni &amp; lenci (2009), who propose various dsm approaches to represent argument structure, subject-verb and verb-object co-selection.</citsent>
<aftsection>
<nextsent>current approaches tocompositionality in dsms are based on the application of simple geometric operation on the basisof individual vectors (vector addition, pointwise multiplication of corresponding dimensions, tensor product) which should in principle approximate the composition of any two given vectors.
</nextsent>
<nextsent>on the contrary, since the the very nature ofcompositionality depends on the semantic relation being instantiated in syntactic structure, we propose that the composition of vector representations must be modelled as relation-specific phenomenon.
</nextsent>
<nextsent>in particular, we propose that the usual procedures from machine learning tasks must be implemented also in the search for semantic com positionality in dsm.
</nextsent>
<nextsent>in this paper we present work in progress on the computational modelling of compositionalityin data-set of english adjective-noun pairs extracted from the bnc.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG405">
<title id=" W10-3011.xml">exploiting rich features for detecting hedges and their scope </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our system achieves the third score in biological dataset for the first task, and achieves 0.5265 f1 score for the second task.
</prevsent>
<prevsent>in recent years, fair amount of approaches have been developed on detecting speculative and negative information from biomedical and natural language texts, for its benefit to the applications like information extraction.
</prevsent>
</prevsection>
<citsent citstr=" P07-1125 ">
these approaches evolve from hand-crafted rule-based approaches, which use regular expressions to match the sentences or its grammatical parsing, such as negex (chapman et al, 2001), neg finder (mutalik et al, 2001), and negexpander (aronow et al, 1999), to machine learning approaches, including semi-supervised methods (medlock and briscoe, 2007; <papid> P07-1125 </papid>szarvas, 2008), and supervised methods (morante and daelemans, 2009).<papid> W09-1304 </papid></citsent>
<aftsection>
<nextsent>in this paper, we describe the machine learning system submitted to conll-2010 shared task (farkas et al, 2010).
</nextsent>
<nextsent>our system formalizes these two tasks as consecutive sequence labeling problems, and learns the classifiers using conditional random fields approach.
</nextsent>
<nextsent>in the first task, model is trained to identify the hedge cues in sentences, and in the second task, another model is used to find the corresponding scope for each hedge cue generated in the first task.
</nextsent>
<nextsent>our system follows the study of morante and daelemans (2009), <papid> W09-1304 </papid>but applies more refined feature selection.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG406">
<title id=" W10-3011.xml">exploiting rich features for detecting hedges and their scope </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our system achieves the third score in biological dataset for the first task, and achieves 0.5265 f1 score for the second task.
</prevsent>
<prevsent>in recent years, fair amount of approaches have been developed on detecting speculative and negative information from biomedical and natural language texts, for its benefit to the applications like information extraction.
</prevsent>
</prevsection>
<citsent citstr=" W09-1304 ">
these approaches evolve from hand-crafted rule-based approaches, which use regular expressions to match the sentences or its grammatical parsing, such as negex (chapman et al, 2001), neg finder (mutalik et al, 2001), and negexpander (aronow et al, 1999), to machine learning approaches, including semi-supervised methods (medlock and briscoe, 2007; <papid> P07-1125 </papid>szarvas, 2008), and supervised methods (morante and daelemans, 2009).<papid> W09-1304 </papid></citsent>
<aftsection>
<nextsent>in this paper, we describe the machine learning system submitted to conll-2010 shared task (farkas et al, 2010).
</nextsent>
<nextsent>our system formalizes these two tasks as consecutive sequence labeling problems, and learns the classifiers using conditional random fields approach.
</nextsent>
<nextsent>in the first task, model is trained to identify the hedge cues in sentences, and in the second task, another model is used to find the corresponding scope for each hedge cue generated in the first task.
</nextsent>
<nextsent>our system follows the study of morante and daelemans (2009), <papid> W09-1304 </papid>but applies more refined feature selection.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG412">
<title id=" W10-3011.xml">exploiting rich features for detecting hedges and their scope </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>huang and low (2007) notes that structure information stored in parse trees helps identifying the scope of negative hedge cues, and szarvas (2008) points out that the scope of keyword can be determined on the basic of syntax.
</prevsent>
<prevsent>thus we believe that highly accurate extraction of syntactic structure would be beneficial for this task.
</prevsent>
</prevsection>
<citsent citstr=" D07-1111 ">
for sentences in the dataset, their dependency structures are extracted using genia dependency parser (sagae and tsujii, 2007), <papid> D07-1111 </papid>and phrase structure using brown self-trained biomedical parser (mcclosky, 2009).</citsent>
<aftsection>
<nextsent>figure 2 shows the corresponding dependency tree and figure 3 shows the corresponding phrase structure tree for the sentence in figure 1.
</nextsent>
<nextsent>in the following part in the section, we will illustrate these syntactic features and give examples for their value.
</nextsent>
<nextsent>we take the token acid?
</nextsent>
<nextsent>as the token in focus, to determine whether it is classified as f-scope, l-scope or none.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG413">
<title id=" W10-1705.xml">2010 failures in english czech phrase based mt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>thanks to david kolovratnk for the help with manual evaluation.
</prevsent>
<prevsent>1http://www.statmt.org/wmt10/ word forms in section 3.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
partly due to the large vocabulary size of czech, bleu score (papineni et al, 2002) <papid> P02-1040 </papid>correlates rather poorly with humanjudgments.</citsent>
<aftsection>
<nextsent>we summarize our efforts to use better metric in the model optimization in section 4.
</nextsent>
<nextsent>the final section 5 lists the exact configurations of our english czech primary submissions for wmt10, including the back-off to lemmas we use for czech-to-english.
</nextsent>
<nextsent>1.1 data and pre-processing pipeline.
</nextsent>
<nextsent>throughout the paper, we use czeng 0.9 (bojarand zabokrtsky?, 2009)2 as our main parallel corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG415">
<title id=" W10-1705.xml">2010 failures in english czech phrase based mt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the bleu scores reported in this paper are based on true cased word forms in the original tokenization as provided by the decoder.
</prevsent>
<prevsent>therefore they are likely to differ from figures reported else where.
</prevsent>
</prevsection>
<citsent citstr=" W04-3250 ">
the ? value given with each bleu score is the average of the distances to the lower and upper empirical 95% confidence bounds estimated using bootstrapping (koehn, 2004).<papid> W04-3250 </papid></citsent>
<aftsection>
<nextsent>table 1 summarizes the differences of czech and english vocabulary sizes in our parallel corpora.
</nextsent>
<nextsent>we see that the vocabulary size of czech forms(truecased) is more than double compared to english in the small dataset and significantly larger in the large dataset as well.
</nextsent>
<nextsent>on the other hand, the number of distinct czech and english lemmas is nearly identical.5due to the subsequent processing, incl.
</nextsent>
<nextsent>parsing, the tokenization of english follows penntreebenk style.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG416">
<title id=" W10-1705.xml">2010 failures in english czech phrase based mt </title>
<section> targetting czech word forms.  </section>
<citcontext>
<prevsection>
<prevsent>bojar (2007) experimented with several translation scenarios, including what we will call mor phg, i.e. the independent translation of lemma to lemma and tag to tag followed by generation step to produce target-side word form.
</prevsent>
<prevsent>with the small training set available then, the morphg model performed equally well as simpler direct translation followed by target-side tagging and an additional n-gram model over morphological tags.
</prevsent>
</prevsection>
<citsent citstr=" D07-1091 ">
koehn and hoang (2007) <papid> D07-1091 </papid>reports even large loss with morphg for german-to-english if the alternative of direct form-to-form translation is not available.</citsent>
<aftsection>
<nextsent>bojar et al (2009<papid> W09-0422 </papid>b) applied the two alternative decoding paths (direct form-to-form and morphg, labelled t+c+c&t;+t+g?) to english-czech but they were able to use only 84k sentences.</nextsent>
<nextsent>for the full training set of 2.2m sentences, the model was too big to fit in reasonable disk limits.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG417">
<title id=" W10-1705.xml">2010 failures in english czech phrase based mt </title>
<section> targetting czech word forms.  </section>
<citcontext>
<prevsection>
<prevsent>with the small training set available then, the morphg model performed equally well as simpler direct translation followed by target-side tagging and an additional n-gram model over morphological tags.
</prevsent>
<prevsent>koehn and hoang (2007) <papid> D07-1091 </papid>reports even large loss with morphg for german-to-english if the alternative of direct form-to-form translation is not available.</prevsent>
</prevsection>
<citsent citstr=" W09-0422 ">
bojar et al (2009<papid> W09-0422 </papid>b) applied the two alternative decoding paths (direct form-to-form and morphg, labelled t+c+c&t;+t+g?) to english-czech but they were able to use only 84k sentences.</citsent>
<aftsection>
<nextsent>for the full training set of 2.2m sentences, the model was too big to fit in reasonable disk limits.
</nextsent>
<nextsent>more importantly, already in the small data setting, the complex model suffered from little stability dueto abundance of features (5 features per phrase table plus tree features for three lms), so nearly the same performance on the development set gave largely varying quality on the independent test set.
</nextsent>
<nextsent>the most important issue of the morphg setup, however, is the explosion of translation options.
</nextsent>
<nextsent>due to the synchronous factors?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG420">
<title id=" W10-1705.xml">2010 failures in english czech phrase based mt </title>
<section> optimizing towards sempos.  </section>
<citcontext>
<prevsection>
<prevsent>this bias is not inherent to the model, only the (normalized) phrase penalty weight happened to get nearly three times bigger than in the simple model.
</prevsent>
<prevsent>63be still improved, and more importantly, the second phase of monotone decoding could be handled by more appropriate model capable of including more additional (source) context features.8
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
in our setup, we use minimum error-rate training (mert, och (2003)) <papid> P03-1021 </papid>to optimize weights of model components.</citsent>
<aftsection>
<nextsent>in the standard implementation in moses, bleu (papineni et al, 2002) <papid> P02-1040 </papid>is used as the objective function, despite its rather disputable correlation with human judgments of mt quality.</nextsent>
<nextsent>kos and bojar (2009) introduced sempos, ametric that performs much better in terms of correlation to human judgments when translating to czech.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG423">
<title id=" W10-1705.xml">2010 failures in english czech phrase based mt </title>
<section> optimizing towards sempos.  </section>
<citcontext>
<prevsection>
<prevsent>naturally, we wanted to optimize towards sempos.sempos computes the overlapping of auto semantic (content-bearing) word lemmas in the candidate and reference translations given fine grained semantic part of speech (sempos9), as defined in hajic?
</prevsent>
<prevsent>et al (2006), and outputs average overlapping score over all sempos types.
</prevsent>
</prevsection>
<citsent citstr=" W07-0734 ">
the sempos metric outperformed common metrics as bleu, ter (snover et al, 2006) or an adaptation of meteor (lavie and agarwal, 2007)<papid> W07-0734 </papid>for czech on test sets from wmt08 (callison burch et al, 2008).</citsent>
<aftsection>
<nextsent>4.1 integrating sempos to mert.
</nextsent>
<nextsent>in our experiments we used z-mert (zaidan,2009), recent implementation of the mert algorithm, to optimize model parameters.the sempos metric requires to remove all auxiliary words and to identify the (deep-syntactic)lemmas and semantic part of speech for auto semantic words.
</nextsent>
<nextsent>when employed in mert training, the whole n-best list of candidates has to processed like this at each iteration.
</nextsent>
<nextsent>we use the tectomt platform ( zabokrtsky?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG424">
<title id=" W10-1705.xml">2010 failures in english czech phrase based mt </title>
<section> our primary submissions to wmt10.  </section>
<citcontext>
<prevsection>
<prevsent>without the tag, ambiguous english words could often all translate as e.g.nouns, leading to no verb in the czech sentence.
</prevsent>
<prevsent>the default path serves as back-off.
</prevsent>
</prevsection>
<citsent citstr=" D07-1103 ">
significance filtering of the phrase tables (johnson et al,2007) <papid> D07-1103 </papid>implemented for moses by chris dyer; default settings of filter value a+e and the cut-off 30.</citsent>
<aftsection>
<nextsent>two separate 5-gram czech lms of true cased forms each of which interpol ates models trained on the following datasets; the interpolation weights were set automatically using srilm (stolcke, 2002) based on the target side of large small backed-off by source lemmas 18.950.45 14.950.48 form form only 18.410.44 14.730.47 table 10: translation from czech better when backed-off by source lemmas.
</nextsent>
<nextsent>the development set:11 ? interpolated czeng domains: news, web, fiction.
</nextsent>
<nextsent>the rationale behind the selection of the domains is that we prefer prose-like texts for lm estimation (and not e.g.technical documentation) while we want as much parallel data as possible.
</nextsent>
<nextsent>interpolated monolingual corpora: wmt09 monolingual, wmt10 monolingual, czech national corpus (kocek et al, 2000) sections syn2000+2005+2006pub.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG425">
<title id=" W10-1742.xml">an augmented three pass system combination framework dcu combination system for wmt 2010 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a cn is essentially directed acyclic graph built from set of translation hypotheses against reference or backbone?.
</prevsent>
<prevsent>each arc between two nodes in the cn denotes word or token, possibly null item, with an associated posterior probability.
</prevsent>
</prevsection>
<citsent citstr=" N04-1022 ">
typically, the dominant cn is constructed at the word level by state-of-the-art framework: firstly, minimum bayes-risk (mbr) decoder (kumarand byrne, 2004) <papid> N04-1022 </papid>is utilised to choose the back bone from merged set of hypotheses, and then the remaining hypotheses are aligned against the backbone by specific alignment approach.</citsent>
<aftsection>
<nextsent>currently, most research in system combination has focused on hypothesis alignment due to its significant influence on combination quality.
</nextsent>
<nextsent>a multiple cn or super-network?
</nextsent>
<nextsent>framework was firstly proposed in rosti et al (2007) <papid> P07-1040 </papid>who used each of all individual system results as the backbone to build cns based on the same alignment metric, ter (snover et al, 2006).</nextsent>
<nextsent>a consensus network mbr (conmbr) approach was presented in (sim et al, 2007), where mbr decoding is employed to select the best hypothesis with the minimum cost from the original single system outputs compared to the consensus output.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG426">
<title id=" W10-1742.xml">an augmented three pass system combination framework dcu combination system for wmt 2010 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>currently, most research in system combination has focused on hypothesis alignment due to its significant influence on combination quality.
</prevsent>
<prevsent>a multiple cn or super-network?
</prevsent>
</prevsection>
<citsent citstr=" P07-1040 ">
framework was firstly proposed in rosti et al (2007) <papid> P07-1040 </papid>who used each of all individual system results as the backbone to build cns based on the same alignment metric, ter (snover et al, 2006).</citsent>
<aftsection>
<nextsent>a consensus network mbr (conmbr) approach was presented in (sim et al, 2007), where mbr decoding is employed to select the best hypothesis with the minimum cost from the original single system outputs compared to the consensus output.
</nextsent>
<nextsent>du and way (2009) proposed combination strategy that employs mbr, super network, and modified conmbr (mconmbr) approach to construct three-pass system combination framework which can effectively combine different hypothesis alignment results and easily be extended to more alignment metrics.
</nextsent>
<nextsent>firstly, number of individual cns are built based on different backbones and different kinds of alignment metrics.
</nextsent>
<nextsent>each network generates 1-best output.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG427">
<title id=" W10-1742.xml">an augmented three pass system combination framework dcu combination system for wmt 2010 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the system combination task of wmt 2010,we adopted an augmented framework by extending the strategy in (du and way, 2009).
</prevsent>
<prevsent>in addition to the basic three-pass architecture, we augment our combination system as follows: ? we add rescoring component in pass 1 and pass 2.
</prevsent>
</prevsection>
<citsent citstr=" W09-0441 ">
? we introduce the terp (snover et al, 2009) <papid> W09-0441 </papid>alignment metric for the english-targeted combination.?</citsent>
<aftsection>
<nextsent>we employ different backbones and hypothesis alignment metrics to increase the diversity of candidates for our mconmbr decoding.the remainder of this paper is organised as follows.
</nextsent>
<nextsent>in section 2, we introduce the three hypothesis alignment methods used in our framework.
</nextsent>
<nextsent>section 3 details the steps for building our augmented three-pass combination framework.
</nextsent>
<nextsent>in section 4, rescoring model with rich feature sis described.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG429">
<title id=" W10-1742.xml">an augmented three pass system combination framework dcu combination system for wmt 2010 </title>
<section> hypothesis alignment methods.  </section>
<citcontext>
<prevsection>
<prevsent>then, sections 5 and 6 respectively report the experimental settings and experimental results on english-to-czech and french to-english combination tasks.
</prevsent>
<prevsent>section 7 gives our conclusions.
</prevsent>
</prevsection>
<citsent citstr=" E06-1005 ">
hypothesis alignment plays vital role in the cn, as the backbone sentence determines the skeleton and the word order of the consensus output.in the combination evaluation task, we integrated ter (snover et al, 2006), hmm (ma tusov et al, 2006) <papid> E06-1005 </papid>and terp (snover et al, 2009) <papid> W09-0441 </papid>into our augmented three-pass combination framework.</citsent>
<aftsection>
<nextsent>in this section, we briefly describe these three methods.
</nextsent>
<nextsent>2.1 ter.
</nextsent>
<nextsent>the ter (translation edit rate) metric measures the ratio of the number of edit operations between the hypothesis e?
</nextsent>
<nextsent>and the reference eb to the total number of words in eb.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG441">
<title id=" W10-1742.xml">an augmented three pass system combination framework dcu combination system for wmt 2010 </title>
<section> augmented three-pass combination.  </section>
<citcontext>
<prevsection>
<prevsent>2.
</prevsent>
<prevsent>utilise the standard mbr decoder to se-.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
lect one from the ns as the backbone given some specific loss function such as ter,bleu (papineni et al, 2002) <papid> P02-1040 </papid>and terp; additionally, in order to increase the diversity of candidates used for pass 2 and pass 3, we also use the 1-best hypotheses from the top single mt systems as the backbone.</citsent>
<aftsection>
<nextsent>add the backbones generated by mbr into ns.
</nextsent>
<nextsent>3.
</nextsent>
<nextsent>perform the word alignment between the dif-.
</nextsent>
<nextsent>ferent backbones and the other hypotheses via the ter, hmm, terp (only for english) metrics.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG443">
<title id=" W10-1742.xml">an augmented three pass system combination framework dcu combination system for wmt 2010 </title>
<section> rescoring model.  </section>
<citcontext>
<prevsection>
<prevsent>we adapted our previous rescoring model (du et al, 2009) to larger-scale data.
</prevsent>
<prevsent>the features we used are as follows: ? direct and inverse ibm model; ? 4-gram and 5-gram target language model;?
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
3, 4, and 5-gram part-of-speech (pos) language model (schmid, 1994; ratnaparkhi, 1996); ? <papid> W96-0213 </papid>sentence-length posterior probability (zens and ney, 2006);?</citsent>
<aftsection>
<nextsent>n -gram posterior probabilities within the best list (zens and ney, 2006); ? minimum bayes risk cost.
</nextsent>
<nextsent>this process is similar to the calculation of the mbr decoding in which we take the current hypothesis in the -best list as the backbone?, and then calculate and sum up all the bayes risk cost between the backbone and each of the rest of the -best list using bleu metric as the loss function;?
</nextsent>
<nextsent>length ratio between source and target sen tence.the weights are optimized via the mert algorithm (och, 2003).<papid> P03-1021 </papid></nextsent>
<nextsent>we participated in the english czech and french english system combination tasks.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG444">
<title id=" W10-1742.xml">an augmented three pass system combination framework dcu combination system for wmt 2010 </title>
<section> rescoring model.  </section>
<citcontext>
<prevsection>
<prevsent>n -gram posterior probabilities within the best list (zens and ney, 2006); ? minimum bayes risk cost.
</prevsent>
<prevsent>this process is similar to the calculation of the mbr decoding in which we take the current hypothesis in the -best list as the backbone?, and then calculate and sum up all the bayes risk cost between the backbone and each of the rest of the -best list using bleu metric as the loss function;?
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
length ratio between source and target sen tence.the weights are optimized via the mert algorithm (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>we participated in the english czech and french english system combination tasks.
</nextsent>
<nextsent>in our system combination framework, we use large-scale monolingual data to train language models and carry out pos-tagging.
</nextsent>
<nextsent>5.1 english-czech.
</nextsent>
<nextsent>training data the statistics of the data used for language models training are shown in table 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG446">
<title id=" W10-1734.xml">how to avoid burning ducks combining linguistic analysis and corpus statistics for german compound processing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>compounds are highly productive in german and cause problems of data sparsity in data-driven systems.
</prevsent>
<prevsent>compound splitting is an important component of german to english statistical machine translation systems.
</prevsent>
</prevsection>
<citsent citstr=" E03-1076 ">
the central result of work by (koehn and knight, 2003) <papid> E03-1076 </papid>is that corpus-driven approaches to compound splitting perform better than approaches based on linguistic analysis, andthis result has since been confirmed by other researchers (popovic?</citsent>
<aftsection>
<nextsent>et al, 2006; stymne, 2008).this is despite the fact that linguistic analysis performs better in terms of matching gold standard splitting.
</nextsent>
<nextsent>our work shows that integrating these two approaches, by employing high-recall linguistic analysis disambiguated using corpus statistics, effectively combines the benefits of both approaches.
</nextsent>
<nextsent>this is important due to the wide usage of the koehn and knight approach in statistical machine translation systems.
</nextsent>
<nextsent>the splittings we produce are best in terms of both end-to-end machine translation performance (resulting in an improvement of 0.59 bleu and 0.84 meteor over the corpus-driven approach.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG456">
<title id=" W10-1734.xml">how to avoid burning ducks combining linguistic analysis and corpus statistics for german compound processing </title>
<section> related work on german compound.  </section>
<citcontext>
<prevsection>
<prevsent>both systems yield similar results for large training corpus, while the linguistic-based approach is slightly superior when the amount of training data is drastically re duced.there has recently been large amount of interest in the use of input lattices in smt.
</prevsent>
<prevsent>one use of lattices is to defer disambiguation of word-level phenomena such as inflection and compounds todecoding.
</prevsent>
</prevsection>
<citsent citstr=" N09-1046 ">
dyer (2009) <papid> N09-1046 </papid>applied this to german using lattice encoding different segment ations of german words.</citsent>
<aftsection>
<nextsent>the work is evaluated by using the 1-best output of weak segmenter2 on the training data and then using lattice of the n-best output of the same segmenter on the test set to decode, which was 0.6 bleu better than the unsegmentedbaseline.
</nextsent>
<nextsent>it would be of interest to test whether deferral of disambiguation to decoding still produces an improvement when used in combination with high-performance segmenter such as the one we present, an issue we leave for future work.
</nextsent>
<nextsent>previous work has shown positive impact of compound splitting on translation quality of smt systems.
</nextsent>
<nextsent>the splitting reduces data sparsity and enhances word alignment performance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG472">
<title id=" W10-1734.xml">how to avoid burning ducks combining linguistic analysis and corpus statistics for german compound processing </title>
<section> translation performance.  </section>
<citcontext>
<prevsection>
<prevsent>and gasse (narrow street?),where smor leaves the word unsplit (but not un analyzed: it is encoded as one lexeme), while the corpus-driven approach correctly splits it.
</prevsent>
<prevsent>5.1 system description.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
the moses toolkit (koehn et al, 2007) <papid> P07-2045 </papid>was usedto construct baseline pbsmt system (with default parameters), following the instructions of the shared task9.</citsent>
<aftsection>
<nextsent>the baseline system is moses built exactly as described for the shared task baseline.contrastive systems are also built identically, except for the use of preprocessing on the german training, tuning and testing data; this ensures thatall measured effects on translation quality are attributable to the preprocessing.
</nextsent>
<nextsent>we used data from the eacl 2009 workshop on statistical machinetranslation10.
</nextsent>
<nextsent>the data include 1.2 million parallel sentences for training (europarl and news), 1,025 sentences for tuning and 1,026 sentences for testing.
</nextsent>
<nextsent>all data was lower cased and tokenized, using the shared task tokenizer.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG473">
<title id=" W10-1734.xml">how to avoid burning ducks combining linguistic analysis and corpus statistics for german compound processing </title>
<section> translation performance.  </section>
<citcontext>
<prevsection>
<prevsent>we usedthe english side of the parallel data for the language model.
</prevsent>
<prevsent>as specified in the instructions, sentences longer than 40 words were removed fromthe bilingual training corpus, but not from the language model corpus.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
the monolingual language model training data (containing roughly 227 million words11) was used to derive corpus frequencies for the splitting approaches.for tuning of feature weights we ran minimum error rate training (och, 2003) <papid> P03-1021 </papid>until convergence, individually for each system (optimiz ing bleu).</citsent>
<aftsection>
<nextsent>the experiments were evaluated using bleu (papineni et al, 2002) <papid> P02-1040 </papid>and meteor (lavieand agarwal, 2007)<papid> W07-0734 </papid>12.</nextsent>
<nextsent>tuning scores are calculated on lower cased, tokenized text; all test scores are case sensitive and performed on automatically 9 http://www.statmt.org/wmt09/baseline.html 10 http://www.statmt.org/wmt09/translation-task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG474">
<title id=" W10-1734.xml">how to avoid burning ducks combining linguistic analysis and corpus statistics for german compound processing </title>
<section> translation performance.  </section>
<citcontext>
<prevsection>
<prevsent>as specified in the instructions, sentences longer than 40 words were removed fromthe bilingual training corpus, but not from the language model corpus.
</prevsent>
<prevsent>the monolingual language model training data (containing roughly 227 million words11) was used to derive corpus frequencies for the splitting approaches.for tuning of feature weights we ran minimum error rate training (och, 2003) <papid> P03-1021 </papid>until convergence, individually for each system (optimiz ing bleu).</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
the experiments were evaluated using bleu (papineni et al, 2002) <papid> P02-1040 </papid>and meteor (lavieand agarwal, 2007)<papid> W07-0734 </papid>12.</citsent>
<aftsection>
<nextsent>tuning scores are calculated on lower cased, tokenized text; all test scores are case sensitive and performed on automatically 9 http://www.statmt.org/wmt09/baseline.html 10 http://www.statmt.org/wmt09/translation-task.
</nextsent>
<nextsent>html 11 http://www.statmt.org/wmt09/ training-monolingual.tar 12the version of meteor used is 0.7, we use exact porter-stem wn-synonmy?, weights are 0.8 0.83 0.28?.
</nextsent>
<nextsent>system tuning test test bleu bleu meteor raw 18.10 15.72 47.65 cd 18.52 16.17 49.29 sm 19.47 16.59 49.98 sm@nn 19.42 16.76 49.77 smc 19.53 16.63 50.13 smc@nn 19.61 16.40 49.64 table 6: effects of compound splitting: raw = without preprocessing, cd = corpus-driven, sm = hybrid approach using all smor analyses, smc = hybrid approach with minimal smor splits *@nn = split only nouns.
</nextsent>
<nextsent>bold-face = significant wrt.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG475">
<title id=" W10-1734.xml">how to avoid burning ducks combining linguistic analysis and corpus statistics for german compound processing </title>
<section> translation performance.  </section>
<citcontext>
<prevsection>
<prevsent>as specified in the instructions, sentences longer than 40 words were removed fromthe bilingual training corpus, but not from the language model corpus.
</prevsent>
<prevsent>the monolingual language model training data (containing roughly 227 million words11) was used to derive corpus frequencies for the splitting approaches.for tuning of feature weights we ran minimum error rate training (och, 2003) <papid> P03-1021 </papid>until convergence, individually for each system (optimiz ing bleu).</prevsent>
</prevsection>
<citsent citstr=" W07-0734 ">
the experiments were evaluated using bleu (papineni et al, 2002) <papid> P02-1040 </papid>and meteor (lavieand agarwal, 2007)<papid> W07-0734 </papid>12.</citsent>
<aftsection>
<nextsent>tuning scores are calculated on lower cased, tokenized text; all test scores are case sensitive and performed on automatically 9 http://www.statmt.org/wmt09/baseline.html 10 http://www.statmt.org/wmt09/translation-task.
</nextsent>
<nextsent>html 11 http://www.statmt.org/wmt09/ training-monolingual.tar 12the version of meteor used is 0.7, we use exact porter-stem wn-synonmy?, weights are 0.8 0.83 0.28?.
</nextsent>
<nextsent>system tuning test test bleu bleu meteor raw 18.10 15.72 47.65 cd 18.52 16.17 49.29 sm 19.47 16.59 49.98 sm@nn 19.42 16.76 49.77 smc 19.53 16.63 50.13 smc@nn 19.61 16.40 49.64 table 6: effects of compound splitting: raw = without preprocessing, cd = corpus-driven, sm = hybrid approach using all smor analyses, smc = hybrid approach with minimal smor splits *@nn = split only nouns.
</nextsent>
<nextsent>bold-face = significant wrt.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG476">
<title id=" W10-2924.xml">joint entity and relation extraction using card pyramid parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the twomost common sub-tasks of ie are extracting entities (like person, location and organization) and extracting relations between them (like work for which relates person and an organization, org based in which relates an organization and location etc.).
</prevsent>
<prevsent>figure 1 shows sample sentence annotated with entities and relations.
</prevsent>
</prevsection>
<citsent citstr=" P06-1104 ">
the application domain and requirements of the downstream tasks usually dictate the type of entities and relations that an ie system needs to extract.most work in ie has concentrated on entity extraction alone (tjong kim sang, 2002; sang and meulder, 2003) or on relation extraction assuming entities are either given or previously extracted (bunescu et al, 2005; zhang et al, 2006; <papid> P06-1104 </papid>giuliano et al, 2007; qian et al, 2008).<papid> C08-1088 </papid></citsent>
<aftsection>
<nextsent>however, these tasks are very closely inter-related.
</nextsent>
<nextsent>while identifying correct entities is essential for identifying relations between them, identifying correct relations can in turn improve identification of entities.
</nextsent>
<nextsent>for example, if the relation work for is identified with high confidence by relation extractor, then it can enforce identifying its arguments as person and organization, about which the entity extractor might not have been confident.
</nextsent>
<nextsent>a brute force algorithm for finding the most probable joint extraction will soon become intractable as the number of entities in sentence grows.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG477">
<title id=" W10-2924.xml">joint entity and relation extraction using card pyramid parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the twomost common sub-tasks of ie are extracting entities (like person, location and organization) and extracting relations between them (like work for which relates person and an organization, org based in which relates an organization and location etc.).
</prevsent>
<prevsent>figure 1 shows sample sentence annotated with entities and relations.
</prevsent>
</prevsection>
<citsent citstr=" C08-1088 ">
the application domain and requirements of the downstream tasks usually dictate the type of entities and relations that an ie system needs to extract.most work in ie has concentrated on entity extraction alone (tjong kim sang, 2002; sang and meulder, 2003) or on relation extraction assuming entities are either given or previously extracted (bunescu et al, 2005; zhang et al, 2006; <papid> P06-1104 </papid>giuliano et al, 2007; qian et al, 2008).<papid> C08-1088 </papid></citsent>
<aftsection>
<nextsent>however, these tasks are very closely inter-related.
</nextsent>
<nextsent>while identifying correct entities is essential for identifying relations between them, identifying correct relations can in turn improve identification of entities.
</nextsent>
<nextsent>for example, if the relation work for is identified with high confidence by relation extractor, then it can enforce identifying its arguments as person and organization, about which the entity extractor might not have been confident.
</nextsent>
<nextsent>a brute force algorithm for finding the most probable joint extraction will soon become intractable as the number of entities in sentence grows.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG478">
<title id=" W10-2924.xml">joint entity and relation extraction using card pyramid parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, if the relation work for is identified with high confidence by relation extractor, then it can enforce identifying its arguments as person and organization, about which the entity extractor might not have been confident.
</prevsent>
<prevsent>a brute force algorithm for finding the most probable joint extraction will soon become intractable as the number of entities in sentence grows.
</prevsent>
</prevsection>
<citsent citstr=" W04-2401 ">
if there are entities in sentence, then there are o(n2) possible relations between them and if each relation can take labels then there are o(ln2) total possibilities, which is intractable even for small and n. hence, an efficient inference mechanism is needed for joint entity and relation extraction.the only work we are aware of for jointly extracting entities and relations is by roth &amp; yih(2004),  <papid> W04-2401 </papid>yih(2007).</citsent>
<aftsection>
<nextsent>their method first identifies the possible entities and relations in sentence using separate classifiers which are applied independently and then computes most probable consistent global set of entities and relations using linear programming.
</nextsent>
<nextsent>in this paper, we present different approach to joint extraction using card-pyramid?
</nextsent>
<nextsent>graph.
</nextsent>
<nextsent>the labeled nodes in this graph compactly encode the possible entities and relations in sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG479">
<title id=" W10-2924.xml">joint entity and relation extraction using card pyramid parsing </title>
<section> card-pyramid parsing for joint.  </section>
<citcontext>
<prevsection>
<prevsent>thus, along with the two entities and the words in the sentence, information from these sub card-pyramids is also used in deciding the relation at node.
</prevsent>
<prevsent>in the next section, we further specify these entity and relation classifiers and explain how they are trained.
</prevsent>
</prevsection>
<citsent citstr=" P06-1115 ">
we note that this use of multiple classifiers to determine the most probable parse is similar to the method used in the krisp semantic parser (kate and mooney, 2006).<papid> P06-1115 </papid></citsent>
<aftsection>
<nextsent>given the candidate entities in sentence, the grammar, and the entity and relation classifiers, the card-pyramid parsing algorithm tries to find the most probable joint-labeling of all of its nodes,and thus jointly extracts entities and their relations.
</nextsent>
<nextsent>the parsing algorithm does beam sear chand maintains beam at each node of the card pyramid.
</nextsent>
<nextsent>a node is represented by l[i][j] in the pseudo-code which stands for the node in the jth position in the ith level.
</nextsent>
<nextsent>note that at level i, the nodes range from l[i][0] to l[i][n? i?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG484">
<title id=" W10-2924.xml">joint entity and relation extraction using card pyramid parsing </title>
<section> classifiers for entity and relation.  </section>
<citcontext>
<prevsection>
<prevsent>it would also not help to add hard constraints to their linear program relating the relations because they need not always hold.
</prevsent>
<prevsent>we add the kernels for each part of the input to compute the final kernel for the svm classifiers.the kernel for the second part of the input is computed by simply counting the number of common 207pairs of relations between two examples thus implicitly considering every pair of relation (as described in the last paragraph) as feature.
</prevsent>
</prevsection>
<citsent citstr=" H05-1091 ">
for the first part of the input, we use word-subsequencekernels which have shown to be effective for relation extraction (bunescu and mooney, 2005<papid> H05-1091 </papid>b).we compute the kernel as the sum of the word sub sequence kernels between: the words between the two entities (between pattern), (a parame ter) words before the first entity (before pattern), words after the second entity (after pattern) and the words from the beginning of the first entity to the end of the second entity (between-and-entity pattern).</citsent>
<aftsection>
<nextsent>the before, between and after patterns have been found useful in previous work (bunescuand mooney, 2005<papid> H05-1091 </papid>b; giuliano et al, 2007).</nextsent>
<nextsent>sometimes the words of the entities can indicate the relations they are in, hence we also use the between and-entity pattern.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG496">
<title id=" W10-2924.xml">joint entity and relation extraction using card pyramid parsing </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>this isnot possible in their approach because all classifier outputs are determined before they are passed to the linear program solver.
</prevsent>
<prevsent>thus our approach is more integrated and allows greater interaction between dependent extraction decisions.
</prevsent>
</prevsection>
<citsent citstr=" A00-2030 ">
miller et al (2000) <papid> A00-2030 </papid>adapt probabilistic context-free parser for information extraction by augmenting syntactic labels with entity and relation labels.</citsent>
<aftsection>
<nextsent>they thus do joint syntactic parsing and information extraction using fixed template.however, as designed, such cfg approach can not handle the cases when an entity is involved in multiple relations and when the relations crisscross each other in the sentence, as in figure 1.
</nextsent>
<nextsent>these cases occur frequently in the dataset weused in our experiments and many other relation extraction tasks.
</nextsent>
<nextsent>giuliano et al (2007) thoroughly evaluate the effect of entity extraction on relation extraction using the dataset used in our experiments.
</nextsent>
<nextsent>however,they employ pipeline architecture and did not investigate joint relation and entity extraction.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG497">
<title id=" W10-2924.xml">joint entity and relation extraction using card pyramid parsing </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>giuliano et al (2007) thoroughly evaluate the effect of entity extraction on relation extraction using the dataset used in our experiments.
</prevsent>
<prevsent>however,they employ pipeline architecture and did not investigate joint relation and entity extraction.
</prevsent>
</prevsection>
<citsent citstr=" W09-2201 ">
carlson et al (2009) <papid> W09-2201 </papid>present method to simultaneously do semi-supervised training of entity andre lation classifiers.</citsent>
<aftsection>
<nextsent>however, their coupling method is meant to take advantage of the available unsupervised data and does not do joint inference.riedel et al (2009) <papid> W09-1406 </papid>present an approach forex tracting bio-molecular events and their arguments using markov logic.</nextsent>
<nextsent>such an approach could also be adapted for jointly extracting entities and their relations, however, this would restrict entity and relation extraction to the same machine learning method that is used with markov logic.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG498">
<title id=" W10-2924.xml">joint entity and relation extraction using card pyramid parsing </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>however,they employ pipeline architecture and did not investigate joint relation and entity extraction.
</prevsent>
<prevsent>carlson et al (2009) <papid> W09-2201 </papid>present method to simultaneously do semi-supervised training of entity andre lation classifiers.</prevsent>
</prevsection>
<citsent citstr=" W09-1406 ">
however, their coupling method is meant to take advantage of the available unsupervised data and does not do joint inference.riedel et al (2009) <papid> W09-1406 </papid>present an approach forex tracting bio-molecular events and their arguments using markov logic.</citsent>
<aftsection>
<nextsent>such an approach could also be adapted for jointly extracting entities and their relations, however, this would restrict entity and relation extraction to the same machine learning method that is used with markov logic.
</nextsent>
<nextsent>for example, one would not be able to use kernel based svm for relation extraction, which has been very successful at this task, because markov logic does not support kernel-based machine learning.
</nextsent>
<nextsent>in contrast, our joint approach is independent ofthe individual machine learning methods for entity and relation extraction, and hence allows use of the best machine learning methods available for each of them.
</nextsent>
<nextsent>there are several possible directions for extending the current approach.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG501">
<title id=" W10-2924.xml">joint entity and relation extraction using card pyramid parsing </title>
<section> future work.  </section>
<citcontext>
<prevsection>
<prevsent>inthat case, instead of using multiple probabilistic classifiers, one could employ single jointly trained probabilistic model, which is theoretically more appealing and might give better results.
</prevsent>
<prevsent>finally, we note that better relation classifier could be used in the current approach which makes more use of linguistic information.
</prevsent>
</prevsection>
<citsent citstr=" D08-1042 ">
for example, 210 by using dependency-based kernels (bunescu and mooney, 2005<papid> H05-1091 </papid>a; kate, 2008) <papid> D08-1042 </papid>or syntactic kernels(qian et al, 2008; <papid> C08-1088 </papid>moschitti, 2009) <papid> E09-1066 </papid>or by including the word categories and their pos tags in the subsequences.</citsent>
<aftsection>
<nextsent>also, it will be interesting to see ifa kernel that computes the similarity between subcard-pyramids could be developed and used for relation classification.
</nextsent>
<nextsent>we introduced card-pyramid graph structure and presented new method for jointly extracting entities and their relations from sentence using it.
</nextsent>
<nextsent>a card-pyramid compactly encodes the entities and relations in sentence thus reducing the joint extraction task to jointly labeling its nodes.
</nextsent>
<nextsent>we presented an efficient parsing algorithm for jointly labeling card-pyramid using dynamic programming and beam search.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG503">
<title id=" W10-2924.xml">joint entity and relation extraction using card pyramid parsing </title>
<section> future work.  </section>
<citcontext>
<prevsection>
<prevsent>inthat case, instead of using multiple probabilistic classifiers, one could employ single jointly trained probabilistic model, which is theoretically more appealing and might give better results.
</prevsent>
<prevsent>finally, we note that better relation classifier could be used in the current approach which makes more use of linguistic information.
</prevsent>
</prevsection>
<citsent citstr=" E09-1066 ">
for example, 210 by using dependency-based kernels (bunescu and mooney, 2005<papid> H05-1091 </papid>a; kate, 2008) <papid> D08-1042 </papid>or syntactic kernels(qian et al, 2008; <papid> C08-1088 </papid>moschitti, 2009) <papid> E09-1066 </papid>or by including the word categories and their pos tags in the subsequences.</citsent>
<aftsection>
<nextsent>also, it will be interesting to see ifa kernel that computes the similarity between subcard-pyramids could be developed and used for relation classification.
</nextsent>
<nextsent>we introduced card-pyramid graph structure and presented new method for jointly extracting entities and their relations from sentence using it.
</nextsent>
<nextsent>a card-pyramid compactly encodes the entities and relations in sentence thus reducing the joint extraction task to jointly labeling its nodes.
</nextsent>
<nextsent>we presented an efficient parsing algorithm for jointly labeling card-pyramid using dynamic programming and beam search.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG504">
<title id=" W10-0912.xml">ana logical dialogue acts supporting learning by reading analogies </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>recently they have begun incorporating analogies into their tutor (lulis, evans, &amp; michael, 2004), but they have not focused on understanding novel analogies presented via language.
</prevsent>
<prevsent>because ea nlu is designed to explore issues of understanding, it is focused more on semantic coverage than on syntactic coverage.
</prevsent>
</prevsection>
<citsent citstr=" W08-2221 ">
the most similar system is boeings blue (clark &amp; harrison, 2008), <papid> W08-2221 </papid>which also uses simplified syntax and focuses on integrating language with knowledge base and reasoning.</citsent>
<aftsection>
<nextsent>aside from sme, we suspect that the only other current widely tested model of analogy that might be able to handle this task is iam (keane &amp; bray shaw 1988).
</nextsent>
<nextsent>cab (larkey &amp; love 2003) does not model inference, and hence could not model this task.
</nextsent>
<nextsent>although lisa (hummel &amp; holyoak, 2003) can model some ana logical inferences, the number of relations (see table 3) in these analogies is beyond the number of relationships it can currently handle (2 or 3).
</nextsent>
<nextsent>the first simulation of analogy to use natural language input was winstons (1982), input was winstons (1986), which used simple domain-specific parser in modeling the learning of if-then rules and censors.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG505">
<title id=" W10-2706.xml">an embodied dialogue system with personality and emotions </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>natural owl is template-based nlg engine, explicitly designed for generating natural language descriptions of onto logical entities,based on such entities?
</prevsent>
<prevsent>abstract properties (galanis and androutsopoulos, 2007).
</prevsent>
</prevsection>
<citsent citstr=" W09-0302 ">
the eleon authoring tool (konstantopoulos et al, 2009) <papid> W09-0302 </papid>can be used to annotate owl ontologies with linguistic and content-selection resources and inter-operateswith natural owl which can use such annotations to generate descriptions of onto logical ob jects.</citsent>
<aftsection>
<nextsent>2.2 emotions and personality.
</nextsent>
<nextsent>another relevant line of research is centred around affective interaction and intelligent virtual agents.the main focus here is the modelling and mimicking of the various affective markers that people use when they communicate, aiming at more natural and seamless human-computer interaction.such affective systems are modulated by personality representations varying from fully-blowncognitive architectures (vankov et al, 2008) to relatively simpler personality models.
</nextsent>
<nextsent>the oceanor big five model, in particular, standard framework in psychology (norman, 1963; costa and mccrae, 1992), is used to represent personality in variety of virtual agents and avatars capable for multi-modal communication acts such as speech and facial expressions (strauss and kipp, 2008; kasap et al, 2009).
</nextsent>
<nextsent>such systems are typically rich in visual expression, but lack sophistication in natural language generation, knowledge representation and dialogue structure.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG506">
<title id=" W10-1006.xml">rethinking grammatical error annotation and evaluation with the amazon mechanical turk </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>based on these results, we propose new evaluation method which makes it feasible to compare two error detection systems tested on different learner datasets.
</prevsent>
<prevsent>the last few years have seen an explosion in the development of nlp tools to detect and correct errors made by learners of english as second language(esl).
</prevsent>
</prevsection>
<citsent citstr=" I08-1059 ">
while there has been considerable emphasis placed on the system development aspect of the field, with researchers tackling some of the toughest esl errors such as those involving articles (han et al, 2006) and prepositions (gamon et al, 2008), (<papid> I08-1059 </papid>felice and pullman, 2009), there has been woeful lack of attention paid to developing best practices for annotation and evaluation.</citsent>
<aftsection>
<nextsent>annotation in the field of esl error detection has typically relied on just one trained rater, and that raters judgments then become the gold standard for evaluating system.
</nextsent>
<nextsent>so it is very rare that inter-raterreliability is reported, although, in other nlp sub fields, reporting reliability is the norm.
</nextsent>
<nextsent>time and cost are probably the two most important reasons why past work has relied on only one rater because using multiple annotators on the same esl texts would obviously increase both considerably.
</nextsent>
<nextsent>this is especially problematic for this field of research since some esl errors, such as preposition usage, occur at error rates as low as 10%.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG507">
<title id=" W10-1006.xml">rethinking grammatical error annotation and evaluation with the amazon mechanical turk </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>time and cost are probably the two most important reasons why past work has relied on only one rater because using multiple annotators on the same esl texts would obviously increase both considerably.
</prevsent>
<prevsent>this is especially problematic for this field of research since some esl errors, such as preposition usage, occur at error rates as low as 10%.
</prevsent>
</prevsection>
<citsent citstr=" W08-1205 ">
this means that to collect corpus of 1,000 preposition errors, an annotator would have to check over 10,000 prepositions.1 (tetreault and chodorow, 2008<papid> W08-1205 </papid>b) challenged the view that using one rater is adequate by showing that preposition usage errors actually do not have high inter-annotator reliability.</citsent>
<aftsection>
<nextsent>for example, trained raters typically annotate preposition errors with kappa around 0.60.
</nextsent>
<nextsent>this low rater reliability has repercussions for system evaluation: their experiments showed that system precision could vary as much as 10% depending on which raters judgments they used as the gold standard.
</nextsent>
<nextsent>for some grammatical errors such as subject-verb agreement, where rules are clearly defined, it may be acceptable to use just one rater.
</nextsent>
<nextsent>but for usage errors, the rules are less clearly defined and two native speakers can have very different judgments of what is acceptable.one way to address this is by aggregating multitude of judgments for each preposition and treating this as the gold standard, however such tactic has been impractical due to time and cost limitations.while annotation is problem in this field, comparing one system to another has also been major issue.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG537">
<title id=" W10-1006.xml">rethinking grammatical error annotation and evaluation with the amazon mechanical turk </title>
<section> amazon mechnical turk.  </section>
<citcontext>
<prevsection>
<prevsent>with amt, it is possible to efficiently collect multiple judgments for target construction.given this, we propose new method for evaluation that finally allows two systems to be compared to one another even if they are tested on different corpora.
</prevsent>
<prevsent>amazon provides service called the mechanical turk which allows requesters (companies, researchers, etc.) to post simple tasks (known as human intelligence tasks, or hits) to the amt web site for untrained raters to perform for payments as low as $0.01 in many cases (sheng et al, 2008).
</prevsent>
</prevsection>
<citsent citstr=" D08-1027 ">
recently, amt has been shown to be an effective tool for annotation and evalatuation in nlp tasks ranging from word similarity detection and emotion detection (snow et al, 2008) <papid> D08-1027 </papid>to machine translation quality evaluation (callison-burch, 2009).</citsent>
<aftsection>
<nextsent>in these cases, handful of untrained amt workers 2http://www.cambridge.org/elt (or turkers) were found to be as effective as trained raters, but with the advantage of being considerably faster and less expensive.
</nextsent>
<nextsent>given the success of using amt in other areas of nlp, we test whether wecan leverage it for our work in grammatical error detection, which is the focus of the pilot studies in the next two sections.the presence of gold standard in the above papers is crucial.
</nextsent>
<nextsent>in fact, the usability of amt for text annotation has been demostrated in those studies by showing that non-experts?
</nextsent>
<nextsent>annotation converges to the gold standard developed by expert annotators.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG559">
<title id=" W10-1728.xml">tocache or not tocache experiments with adaptive models in statistical machine translation </title>
<section> cache-based adaptive models.  </section>
<citcontext>
<prevsection>
<prevsent>plugging this in into standard phrase-based smt engine is rather straightforward.
</prevsent>
<prevsent>the use of cache based language models in smt have been investigated before (raab, 2007).
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
in our case we used moses as the base decoder (koehn et al, 2007).<papid> P07-2045 </papid></citsent>
<aftsection>
<nextsent>the cache-based language model can be integrated in the decoder by simply adjusting thecall to the language modeling toolkit appropriately.
</nextsent>
<nextsent>we implemented the exponentially decaying cache model within the standard srilm toolkit(stolcke, 2002) and added command line arguments to moses to switch to that model and to set cache parameters such as interpolation, cache size and decay.
</nextsent>
<nextsent>adding the translation model cache is bit more tricky.
</nextsent>
<nextsent>for this we added new feature function to the global log-linear model and implemented the decaying cache as explained above within the decoder.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG560">
<title id=" W10-1728.xml">tocache or not tocache experiments with adaptive models in statistical machine translation </title>
<section> cache-based adaptive models.  </section>
<citcontext>
<prevsection>
<prevsent>however,detecting noise is difficult.
</prevsent>
<prevsent>if there would be notion of noise in translation hypotheses, the decoder would avoid it.
</prevsent>
</prevsection>
<citsent citstr=" W04-3225 ">
in related work (nepveu et al,2004) <papid> W04-3225 </papid>have studied cache-based translation models in connection with interactive machine trans lation.</citsent>
<aftsection>
<nextsent>in that case, one can assume correct input after post-editing the translation suggestions.
</nextsent>
<nextsent>one way to approach noise reduction in non-interactivemt is to make use of transition costs in the translation lattice.
</nextsent>
<nextsent>assuming that this cost (which is estimated internally within the decoder during the expansion of translation hypotheses) refers to some kind of confidence we can discard translation options above certain threshold, which is what we did in the implementation of our translation model cache.
</nextsent>
<nextsent>we followed the setup proposed in the shared translation task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG561">
<title id=" W10-1728.xml">tocache or not tocache experiments with adaptive models in statistical machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>later wealso added experiments for spanish (es) and english using similar setup.
</prevsent>
<prevsent>our baseline system incorporates the followingcomponents: we trained two separate 5-gram language models for each language with the standard smoothing strategies (interpolation and kneser ney discounting), one for europarl and one for the news data.
</prevsent>
</prevsection>
<citsent citstr=" P07-1065 ">
all of them were estimated using the srilm toolkit except the english news lm for which we applied randlm (talbot and osborne, 2007) <papid> P07-1065 </papid>to cope with the large amount of training data.</citsent>
<aftsection>
<nextsent>we also included two separate translation models, one for the combined europarl and news data and one for the news data only.
</nextsent>
<nextsent>they were estimated using the standard tools giza++ (och and ney, 2003) <papid> J03-1002 </papid>and moses (koehn et al, 2007) <papid> P07-2045 </papid>applying default settings and lower cased training data.</nextsent>
<nextsent>lexicalized reordering was trained on the combined data set.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG562">
<title id=" W10-1728.xml">tocache or not tocache experiments with adaptive models in statistical machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>all of them were estimated using the srilm toolkit except the english news lm for which we applied randlm (talbot and osborne, 2007) <papid> P07-1065 </papid>to cope with the large amount of training data.</prevsent>
<prevsent>we also included two separate translation models, one for the combined europarl and news data and one for the news data only.</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
they were estimated using the standard tools giza++ (och and ney, 2003) <papid> J03-1002 </papid>and moses (koehn et al, 2007) <papid> P07-2045 </papid>applying default settings and lower cased training data.</citsent>
<aftsection>
<nextsent>lexicalized reordering was trained on the combined dataset.
</nextsent>
<nextsent>all baseline models were then tuned on the news test data from 2008 using minimum error rate training (mert) (och, 2003).<papid> P03-1021 </papid></nextsent>
<nextsent>the results in terms of lower-case bleu scores are listed in table 1.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG564">
<title id=" W10-1728.xml">tocache or not tocache experiments with adaptive models in statistical machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>they were estimated using the standard tools giza++ (och and ney, 2003) <papid> J03-1002 </papid>and moses (koehn et al, 2007) <papid> P07-2045 </papid>applying default settings and lower cased training data.</prevsent>
<prevsent>lexicalized reordering was trained on the combined data set.</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
all baseline models were then tuned on the news test data from 2008 using minimum error rate training (mert) (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>the results in terms of lower-case bleu scores are listed in table 1.
</nextsent>
<nextsent>n-gram scores bleu 1 2 3 4 de-en baseline 21.3 57.4 27.8 15.1 8.6 de-en cache 21.5 58.1 28.1 15.2 8.7 en-de baseline 15.6 52.5 21.7 10.6 5.5 en-de cache 14.4 52.6 21.0 9.9 4.9 es-en baseline 26.7 61.7 32.7 19.9 12.6 es-en cache 26.1 62.6 32.7 19.8 12.5 en-es baseline 26.9 61.5 33.3 20.5 12.9 en-es cache 23.0 60.6 30.4 17.6 10.4 table 1: results on the wmt10 test set.
</nextsent>
<nextsent>in the adaptation experiments we applied exactly the same models using the feature weights fromthe baseline with the addition of the caching components in both, language models and translation models.
</nextsent>
<nextsent>cache parameters are not particularly tuned for the task in our initial experiments which could be one reason for the disappointing results we obtained.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG565">
<title id=" W10-3022.xml">a baseline approach for detecting sentences containing uncertainty </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>training and testing with data from the same domain produces the best scores.
</prevsent>
<prevsent>higher recall scores were obtained for biological data than for wikipediadata.
</prevsent>
</prevsection>
<citsent citstr=" C00-2137 ">
standard deviations for scores were estimated with bootstrap re sampling (yeh, 2000).<papid> C00-2137 </papid></citsent>
<aftsection>
<nextsent>formance for the biological data dropped to = 84.2 (threshold 0.60) while the top score for the wikipedia data dropped to = 56.5 (0.70).
</nextsent>
<nextsent>we kept the threshold value of 0.55, built model from all available training data and tested its performance on the two test sets.
</nextsent>
<nextsent>in both cases the performances were lower than the ones obtained with domain dependent training data: = 71.8 for biological data and = 54.2 for wikipedia data (see table 1).
</nextsent>
<nextsent>as post-deadline work, we added statistics for word bigrams to the model, following up work by medlock (2008), who showed that considering word bigrams had positive effect on hedge detection.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG566">
<title id=" W10-3020.xml">features for detecting hedge cues </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the primary objective of the conll-2010 shared task (farkas et al, 2010) is to detect hedge cues and their scopes as are present in biomedical texts.
</prevsent>
<prevsent>in this paper, we focus on the biological portion of task 1, and present sequential labeling approach to hedge cue detection.
</prevsent>
</prevsection>
<citsent citstr=" W09-1304 ">
the following summarizes the steps we took to achieve this goal.similarly to previous work in hedge cue detection (morante and daelemans, 2009), <papid> W09-1304 </papid>we first convert the task into sequential labeling task based on the bio scheme, where each word in hedge cue is labeled as b-cue, i-cue, or o, indicating respectively the labeled word is at the beginning of cue, inside of cue, or outside of hedge cue; this is similar to the tagging scheme from the conll-2001 shared task.</citsent>
<aftsection>
<nextsent>we then prepared features, and fed the training data to sequential labeling system, discriminative markov model much like conditional random fields (crf), with the difference being that the model parameters are tuned using bayes point machines (bpm), and then compared our model against an equivalent crf model.
</nextsent>
<nextsent>to convert the result of sequential labeling to sentence classification, we simply used the presence of hedge cue, i.e. if cue is found, asentence is classified as uncertain and certain oth erwise.to prepare features, we ran the genia tagger to add partial syntactic parse and named entity information.
</nextsent>
<nextsent>we also applied porters stem mer (jones and willet, 1997) to each word in thecorpus.
</nextsent>
<nextsent>for each stem, we acquired the distribution of surrounding words from the unlabeled corpus, and calculated the similarity between these distributions and the distribution of hedge cues inthe training corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG567">
<title id=" W10-3020.xml">features for detecting hedge cues </title>
<section> optimization.  </section>
<citcontext>
<prevsection>
<prevsent>we now turn to the optimization of the weight parameter w. we compare three approaches ? perceptron, bayes point machines and conditional random fields, using our c++ library for structured output prediction 1.
</prevsent>
<prevsent>perceptron is an online update scheme that leaves the weights unchanged when the predicted output matches the target, and changes them when it does not.
</prevsent>
</prevsection>
<citsent citstr=" W02-1001 ">
the update is: wk := wk ? ?(xi,y) + ?(xi,yi).despite its seemingly simple update scheme, perceptron is known for its effectiveness and performance (collins, 2002).<papid> W02-1001 </papid>conditional random fields (crf) is conditional model (y|x) = 1zx exp(w  ?(x,y)) where is the weight for each feature and zx is normalization constant for each x. zx = ? exp(w ?(x,y)) 1available at http://soplib.sourceforge.net/ 139 for structured output prediction.</citsent>
<aftsection>
<nextsent>to fit the weight vector using the training set {(xi,yi)}ni=1, we use standard gradient-descent method to find the weight vector that maximizes the log likelihoodn logp (yi|xi) (sha and pereira, 2003).<papid> N03-1028 </papid></nextsent>
<nextsent>toavoid over fitting, the log likelihood is often penalized with spherical gaussian weight prior:n logp (yi|xi) ? c||w||2 . we also evaluated this penalized version, varying the trade-off parameter c. bayes point machines (bpm) for structured prediction (corston-oliver et al, 2006) is an ensemble learning algorithm that attempts to set the weight to be the bayes point which approximates to bayesian inference for linear classifiers.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG568">
<title id=" W10-3020.xml">features for detecting hedge cues </title>
<section> optimization.  </section>
<citcontext>
<prevsection>
<prevsent>perceptron is an online update scheme that leaves the weights unchanged when the predicted output matches the target, and changes them when it does not.
</prevsent>
<prevsent>the update is: wk := wk ? ?(xi,y) + ?(xi,yi).despite its seemingly simple update scheme, perceptron is known for its effectiveness and performance (collins, 2002).<papid> W02-1001 </papid>conditional random fields (crf) is conditional model (y|x) = 1zx exp(w  ?(x,y)) where is the weight for each feature and zx is normalization constant for each x. zx = ? exp(w ?(x,y)) 1available at http://soplib.sourceforge.net/ 139 for structured output prediction.</prevsent>
</prevsection>
<citsent citstr=" N03-1028 ">
to fit the weight vector using the training set {(xi,yi)}ni=1, we use standard gradient-descent method to find the weight vector that maximizes the log likelihoodn logp (yi|xi) (sha and pereira, 2003).<papid> N03-1028 </papid></citsent>
<aftsection>
<nextsent>toavoid over fitting, the log likelihood is often penalized with spherical gaussian weight prior:n logp (yi|xi) ? c||w||2 . we also evaluated this penalized version, varying the trade-off parameter c. bayes point machines (bpm) for structured prediction (corston-oliver et al, 2006) is an ensemble learning algorithm that attempts to set the weight to be the bayes point which approximates to bayesian inference for linear classifiers.
</nextsent>
<nextsent>assuming uniform prior distribution over w, we revise our belief of after observing the training data and produce posterior distribution.
</nextsent>
<nextsent>we create the final wbpm for classification using posterior distribution as follows: wbpm = ep(w|d)[w] = |v (d)|?
</nextsent>
<nextsent>i=1 p(wi|d)wi where p(w|d) is the posterior distribution of the weights given the data and ep(w|d) is the expectation taken with respect to this distribution.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG570">
<title id=" W10-3020.xml">features for detecting hedge cues </title>
<section> features.  </section>
<citcontext>
<prevsection>
<prevsent>the similarity metric we used is called the tanimoto coefficient, also called extended/vector-based jaccard coefficient.
</prevsent>
<prevsent>vi ? vj ||vi|| + ||vj || ? vi ? vj it is based on the dot product of two vectors and reduces to jaccard coefficient for binary features.
</prevsent>
</prevsection>
<citsent citstr=" I08-1072 ">
4available at: http://tartarus.org/ martin/porterstemmer/ this metric is known to perform quite well for near-synonym discovery (hagiwara et al, 2008).<papid> I08-1072 </papid></citsent>
<aftsection>
<nextsent>given stem and its similarities to different hedge cues, we took the maximum similarity and dis cretized it.
</nextsent>
<nextsent>f 16 1 if similarity is bigger than 0.9, 0 otherwise.
</nextsent>
<nextsent>f 19 1 if similarity is bigger than 0.6, 0 otherwise.
</nextsent>
<nextsent>f 24 1 if similarity is bigger than 0.1, 0 otherwise.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG572">
<title id=" W10-1105.xml">assessment of utility in web mining for the domain of public health </title>
<section> criteria for quality.  </section>
<citcontext>
<prevsection>
<prevsent>set of database records, each record containing fields like: the name of the disease/infectious agent, the location/country of the incident, the date of the incident, the number of victims, whether they are human or animal, whether they survived, etc. then the systems response can be compared to the gold standard and correctness can be computed in terms of recall and precision, f-measure, accuracy, etc.counting how many of the fields in each record were correctly extracted.
</prevsent>
<prevsent>this approach to quality is similar to the approach taken in other areas of computational linguistics:how many structures in the text were correctly identified, how many were missed, and how many spurious structures were introduced.
</prevsent>
</prevsection>
<citsent citstr=" N04-4028 ">
confidence has been studied as well, to estimate the probability of the correctness of the systems answer, e.g., in (culotta and mccallum, 2004).<papid> N04-4028 </papid></citsent>
<aftsection>
<nextsent>our system computes confidence using discourse-levelcues, (huttunen et al, 2002): e.g., confidence decreases as the distance between event trigger and event attributes increases the sentence that mentions that someone has fallen ill or died is far fromthe mention of the disease.
</nextsent>
<nextsent>confidence also depends on uniqueness of attributese.g., if document mentions only one country, the system has 30more confidence that an event referring to this country is correct.
</nextsent>
<nextsent>on the subjective side, utility, or relevance, asks how useful the result is to the user.
</nextsent>
<nextsent>there are several points to note.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG573">
<title id=" W10-1105.xml">assessment of utility in web mining for the domain of public health </title>
<section> the system: background.  </section>
<citcontext>
<prevsection>
<prevsent>puls, the pattern-based understanding and learning system, is developed at the university of helsinki to extract factual information from plain text.
</prevsent>
<prevsent>puls has been adapted to analyse texts for epidemic surveillance.1 the components of puls have been described in detail previously, (yangarber and steinberger, 2009; steinberger et al, 2008; yangarber et al, 2007).
</prevsent>
</prevsection>
<citsent citstr=" I08-2140 ">
in several respects, it is similar to other existing systems for automated epidemic surveillance, viz., bio caster (doan et al, 2008), <papid> I08-2140 </papid>medisys and puls (yangarber and steinberger, 2009), health map (freifeld et al, 2008), and others (linge et al, 2009).puls relies on ec-jrcs medisys for ir (in formation retrieval)medisys performs broad web search, using set of boolean keyword-based queries, (steinberger et al, 2008).</citsent>
<aftsection>
<nextsent>the result isa continuous stream of potentially relevant documents, updated every few minutes.
</nextsent>
<nextsent>second, an ie component, (grishman et al, 2003; yangarber and steinberger, 2009), analyzes each retrieved document, to try to find events of potential relevance to public health.
</nextsent>
<nextsent>the system stores the structured information about every detected event into adatabase.
</nextsent>
<nextsent>the ie component uses large set of linguistic patterns, which in turn depend on large scale public health ontology, similar to mesh,2 that contains concepts for diseases and infectious agents, infectious vectors and animals, medical drugs, and geographic locations.from each article, pulss pattern matching engine tries to extract set of incidents, or facts??
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG574">
<title id=" W10-2601.xml">adaptive parameters for entity recognition with perceptron hmms </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>iii, 2007).
</prevsent>
<prevsent>however, we are interested in the case in which no labeled data is available from the target domain ? except for evaluation purposes and fine tuning of hyperparameters.
</prevsent>
</prevsection>
<citsent citstr=" W06-1615 ">
most of the work in adaptation has focused so far on the input side; e.g, proposing solutions based on generating shared source-target representations (blitzer et al, 2006).<papid> W06-1615 </papid></citsent>
<aftsection>
<nextsent>here we focus instead on the output aspect.
</nextsent>
<nextsent>we hypothesize that this work was carried out while the first author was working at yahoo!
</nextsent>
<nextsent>research barcelona.
</nextsent>
<nextsent>part of the loss incurred in using model out of domain is due to its built-in class priors which do not match the class distribution in the target data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG575">
<title id=" W10-2601.xml">adaptive parameters for entity recognition with perceptron hmms </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the main findings from our experiments are as follows.
</prevsent>
<prevsent>first,the problem is challenging and only marginal improvements are possible under all evaluated frameworks.
</prevsent>
</prevsection>
<citsent citstr=" P06-1043 ">
second, we found that our method compares well with current state-of-the-art approaches such as self training and structural correspondence learning (mcclosky et al, 2006; <papid> P06-1043 </papid>blitzer et al, 2006) <papid> W06-1615 </papid>and taps on an interesting aspect which seems worth of further research.</citsent>
<aftsection>
<nextsent>although we concentrate on segmentation task within specific framework, the perceptron hmm introduced by collins (2002), <papid> W02-1001 </papid>we speculate that the same intuition could be straightforwardly applied in other learning frameworks (e.g., support vector machines) and different tasks (e.g., standard classi fication).</nextsent>
<nextsent>recent work in domain adaptation has focused on approaches such as self-training and structural correspondence learning (scl).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG577">
<title id=" W10-2601.xml">adaptive parameters for entity recognition with perceptron hmms </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>first,the problem is challenging and only marginal improvements are possible under all evaluated frameworks.
</prevsent>
<prevsent>second, we found that our method compares well with current state-of-the-art approaches such as self training and structural correspondence learning (mcclosky et al, 2006; <papid> P06-1043 </papid>blitzer et al, 2006) <papid> W06-1615 </papid>and taps on an interesting aspect which seems worth of further research.</prevsent>
</prevsection>
<citsent citstr=" W02-1001 ">
although we concentrate on segmentation task within specific framework, the perceptron hmm introduced by collins (2002), <papid> W02-1001 </papid>we speculate that the same intuition could be straightforwardly applied in other learning frameworks (e.g., support vector machines) and different tasks (e.g., standard classi fication).</citsent>
<aftsection>
<nextsent>recent work in domain adaptation has focused on approaches such as self-training and structural correspondence learning (scl).
</nextsent>
<nextsent>the former approach involves adding self-labeled data from the target domain produced by model trained in-domain (mcclosky et al, 2006).<papid> P06-1043 </papid></nextsent>
<nextsent>the latter approach focuses on ways of generating sharedsource-target representations based on good cross domain (pivot) features (blitzer et al, 2006) <papid> W06-1615 </papid>(see 1also (ando, 2004)).<papid> P04-3013 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG580">
<title id=" W10-2601.xml">adaptive parameters for entity recognition with perceptron hmms </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>recent work in domain adaptation has focused on approaches such as self-training and structural correspondence learning (scl).
</prevsent>
<prevsent>the former approach involves adding self-labeled data from the target domain produced by model trained in-domain (mcclosky et al, 2006).<papid> P06-1043 </papid></prevsent>
</prevsection>
<citsent citstr=" P04-3013 ">
the latter approach focuses on ways of generating sharedsource-target representations based on good cross domain (pivot) features (blitzer et al, 2006) <papid> W06-1615 </papid>(see 1also (ando, 2004)).<papid> P04-3013 </papid></citsent>
<aftsection>
<nextsent>self training has proved effective in syntactic parsing, particularly in tandem with discriminative re-ranking (charniak and johnson, 2005), <papid> P05-1022 </papid>while the scl has been applied successfully to tasks such pos tagging and opinion analysis (blitzer et al, 2006; <papid> W06-1615 </papid>blitzer et al,2007).<papid> P07-1056 </papid></nextsent>
<nextsent>we address different aspect of the adaptation problem, namely the difference in label distributions between source and target domains.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG581">
<title id=" W10-2601.xml">adaptive parameters for entity recognition with perceptron hmms </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the former approach involves adding self-labeled data from the target domain produced by model trained in-domain (mcclosky et al, 2006).<papid> P06-1043 </papid></prevsent>
<prevsent>the latter approach focuses on ways of generating sharedsource-target representations based on good cross domain (pivot) features (blitzer et al, 2006) <papid> W06-1615 </papid>(see 1also (ando, 2004)).<papid> P04-3013 </papid></prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
self training has proved effective in syntactic parsing, particularly in tandem with discriminative re-ranking (charniak and johnson, 2005), <papid> P05-1022 </papid>while the scl has been applied successfully to tasks such pos tagging and opinion analysis (blitzer et al, 2006; <papid> W06-1615 </papid>blitzer et al,2007).<papid> P07-1056 </papid></citsent>
<aftsection>
<nextsent>we address different aspect of the adaptation problem, namely the difference in label distributions between source and target domains.
</nextsent>
<nextsent>chan and ng (2006) <papid> P06-1012 </papid>proposed correcting the class priors for domain adaptation purposes in word sense disambiguation task.</nextsent>
<nextsent>they adopt generative framework where the base model is naive bayes classifier and priors are re-estimated with em.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG583">
<title id=" W10-2601.xml">adaptive parameters for entity recognition with perceptron hmms </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the former approach involves adding self-labeled data from the target domain produced by model trained in-domain (mcclosky et al, 2006).<papid> P06-1043 </papid></prevsent>
<prevsent>the latter approach focuses on ways of generating sharedsource-target representations based on good cross domain (pivot) features (blitzer et al, 2006) <papid> W06-1615 </papid>(see 1also (ando, 2004)).<papid> P04-3013 </papid></prevsent>
</prevsection>
<citsent citstr=" P07-1056 ">
self training has proved effective in syntactic parsing, particularly in tandem with discriminative re-ranking (charniak and johnson, 2005), <papid> P05-1022 </papid>while the scl has been applied successfully to tasks such pos tagging and opinion analysis (blitzer et al, 2006; <papid> W06-1615 </papid>blitzer et al,2007).<papid> P07-1056 </papid></citsent>
<aftsection>
<nextsent>we address different aspect of the adaptation problem, namely the difference in label distributions between source and target domains.
</nextsent>
<nextsent>chan and ng (2006) <papid> P06-1012 </papid>proposed correcting the class priors for domain adaptation purposes in word sense disambiguation task.</nextsent>
<nextsent>they adopt generative framework where the base model is naive bayes classifier and priors are re-estimated with em.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG584">
<title id=" W10-2601.xml">adaptive parameters for entity recognition with perceptron hmms </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>self training has proved effective in syntactic parsing, particularly in tandem with discriminative re-ranking (charniak and johnson, 2005), <papid> P05-1022 </papid>while the scl has been applied successfully to tasks such pos tagging and opinion analysis (blitzer et al, 2006; <papid> W06-1615 </papid>blitzer et al,2007).<papid> P07-1056 </papid></prevsent>
<prevsent>we address different aspect of the adaptation problem, namely the difference in label distributions between source and target domains.</prevsent>
</prevsection>
<citsent citstr=" P06-1012 ">
chan and ng (2006) <papid> P06-1012 </papid>proposed correcting the class priors for domain adaptation purposes in word sense disambiguation task.</citsent>
<aftsection>
<nextsent>they adopt generative framework where the base model is naive bayes classifier and priors are re-estimated with em.
</nextsent>
<nextsent>the approach proposed by chelba and acero (2004) <papid> W04-3237 </papid>is also related as they propose map adaptation via gaussian priors of maxent model for recovering the correct capitalization of text.domain adaptation naturally invokes the existence of specific task and data.</nextsent>
<nextsent>as such it is natural to consider the modeling aspects within the context of specific application.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG585">
<title id=" W10-2601.xml">adaptive parameters for entity recognition with perceptron hmms </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>chan and ng (2006) <papid> P06-1012 </papid>proposed correcting the class priors for domain adaptation purposes in word sense disambiguation task.</prevsent>
<prevsent>they adopt generative framework where the base model is naive bayes classifier and priors are re-estimated with em.</prevsent>
</prevsection>
<citsent citstr=" W04-3237 ">
the approach proposed by chelba and acero (2004) <papid> W04-3237 </papid>is also related as they propose map adaptation via gaussian priors of maxent model for recovering the correct capitalization of text.domain adaptation naturally invokes the existence of specific task and data.</citsent>
<aftsection>
<nextsent>as such it is natural to consider the modeling aspects within the context of specific application.
</nextsent>
<nextsent>here wefocus on the problem of named entity recognition (ner).
</nextsent>
<nextsent>there is still little work on adaptation for ner.
</nextsent>
<nextsent>ando (2004) <papid> P04-3013 </papid>reports successful experiments on adapting with an scl-like approach, while ciaramita and altun (2005) effectively used external knowledge in the form of gazette ers in semi-markov model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG587">
<title id=" W10-2601.xml">adaptive parameters for entity recognition with perceptron hmms </title>
<section> problem statement.  </section>
<citcontext>
<prevsection>
<prevsent>stateof the art systems, e.g., based on sequential optimization, achieve excellent accuracy in domain.however, accuracy degrades if the target data diverges in relevant distributional aspects from thesource.
</prevsent>
<prevsent>as an example, the following is the out put of perceptron hmm1 trained on the conll 2003 english data (news) (sang and muelder,.
</prevsent>
</prevsection>
<citsent citstr=" W06-1670 ">
2003) when applied to molecular biology text:2 1we used the implementation available from http: //sourceforge.net/projects/supersensetag, more details on this tagger can be found in (ciaramita and altun, 2006).<papid> W06-1670 </papid></citsent>
<aftsection>
<nextsent>2the same model achieves f-scores well in excess of 90% evaluated in domain.
</nextsent>
<nextsent>(1) cdc2-cyclin org b-activated polo-like misc kinase specifically phosphorylates at least three components of apc org . the tagger predicts several conll entities which are unlikely to occur in that context.
</nextsent>
<nextsent>one source of confusion is probably the shape of words, including case, numbers, and non alphabetical characters, which are also typical, and thus misleading, of unrelated conll entities.
</nextsent>
<nextsent>however, weargue that the problem is partially due to the parameters learned which reflect the distribution of classes in the source data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG589">
<title id=" W10-2601.xml">adaptive parameters for entity recognition with perceptron hmms </title>
<section> a perceptron with adjustable priors </section>
<citcontext>
<prevsection>
<prevsent>in the example is the end of two-word item, in the country gazetteer, because of cayman islands?.
</prevsent>
<prevsent>the remaining features capture the most frequent wordnet super sense of the word, the first and second most frequent super senses, and the total number of supersenses.
</prevsent>
</prevsection>
<citsent citstr=" P02-1022 ">
the gazette ers from gate,4 (cunningham et al, 2002) <papid> P02-1022 </papid>namely, countries, person first/last names, trigger words; and also from wordnet: using the lexicographers or super sense labels; and list of company names from fortune 500.</citsent>
<aftsection>
<nextsent>for this second baseline (model bg) we also extract the features in the bottom half of table 1.
</nextsent>
<nextsent>4.1 decoding with external priors.
</nextsent>
<nextsent>in our method training is performed on the source data using the perceptron algorithm.
</nextsent>
<nextsent>adaptation takes place at decoding time, when the score ofthe entity labels is adjusted according to kdimensional parameter vector ?, = |y |, estimated by comparing the source and the unlabeled target data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG591">
<title id=" W10-2601.xml">adaptive parameters for entity recognition with perceptron hmms </title>
<section> results and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>to put things in context, it is useful to recall that when evaluated in domain the conll and bbn-4 taggers (modelbg) achieve, respectively, 92.7% and 91.6% average f-scores on the test data.
</prevsent>
<prevsent>as the results illustrate there is considerable drop in out domain accuracy, significantly alleviated by adding features from gazette ers and to some extent by other methods.
</prevsent>
</prevsection>
<citsent citstr=" D07-1112 ">
following dredze et al (2007) <papid> D07-1112 </papid>we hypothesize that significant fraction of the loss is dueto labeling inconsistencies between datasets.</citsent>
<aftsection>
<nextsent>although we did our best to optimize the benchmark methods it is possible that even better results could be achieved with self-training and scl.
</nextsent>
<nextsent>however we stress that different methods get at different aspects of the problem: self-training targets data sparseness, scl methods aims at generating better shared input representations, while our approach focuses on generating output distribution more compatible with the target data.
</nextsent>
<nextsent>it seems reason 6 able to expect that better adaptation performance would result from composite approaches, aiming at both better machine learning and task-specific aspects for the named entity recognition problem.
</nextsent>
<nextsent>we investigated the model adaptation problem for named entity recognition where the base model is discriminatively trained hmm (collins, 2002).<papid> W02-1001 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG593">
<title id=" W10-3707.xml">handling named entities and compound verbs in phrase based statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>multi-word expressions (mwe) are defined as idiosyncratic interpretations that cross word boundaries (or spaces)?
</prevsent>
<prevsent>(sag et al, 2002).
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
traditional approaches to word alignment following ibm models (brown et al, 1993) <papid> J93-2003 </papid>do not work well with multi-word expressions, especially with nes, due to their inability to handle many to-many alignments.</citsent>
<aftsection>
<nextsent>firstly, they only carry out alignment between words and do not consider the case of complex expressions, such as multiword nes.
</nextsent>
<nextsent>secondly, the ibm models only allow at most one word in the source language to correspond to word in the target language (marcu, 2001, <papid> P01-1050 </papid>koehn et al, 2003).<papid> N03-1017 </papid></nextsent>
<nextsent>in another well-known word alignment approach, hidden markov model (hmm: vogel et al., 1996), <papid> C96-2141 </papid>the alignment probabilities depend on the alignment position of the previous word.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG594">
<title id=" W10-3707.xml">handling named entities and compound verbs in phrase based statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>traditional approaches to word alignment following ibm models (brown et al, 1993) <papid> J93-2003 </papid>do not work well with multi-word expressions, especially with nes, due to their inability to handle many to-many alignments.</prevsent>
<prevsent>firstly, they only carry out alignment between words and do not consider the case of complex expressions, such as multiword nes.</prevsent>
</prevsection>
<citsent citstr=" P01-1050 ">
secondly, the ibm models only allow at most one word in the source language to correspond to word in the target language (marcu, 2001, <papid> P01-1050 </papid>koehn et al, 2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>in another well-known word alignment approach, hidden markov model (hmm: vogel et al., 1996), <papid> C96-2141 </papid>the alignment probabilities depend on the alignment position of the previous word.</nextsent>
<nextsent>it does not explicitly consider many-to-many alignment either.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG595">
<title id=" W10-3707.xml">handling named entities and compound verbs in phrase based statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>traditional approaches to word alignment following ibm models (brown et al, 1993) <papid> J93-2003 </papid>do not work well with multi-word expressions, especially with nes, due to their inability to handle many to-many alignments.</prevsent>
<prevsent>firstly, they only carry out alignment between words and do not consider the case of complex expressions, such as multiword nes.</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
secondly, the ibm models only allow at most one word in the source language to correspond to word in the target language (marcu, 2001, <papid> P01-1050 </papid>koehn et al, 2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>in another well-known word alignment approach, hidden markov model (hmm: vogel et al., 1996), <papid> C96-2141 </papid>the alignment probabilities depend on the alignment position of the previous word.</nextsent>
<nextsent>it does not explicitly consider many-to-many alignment either.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG596">
<title id=" W10-3707.xml">handling named entities and compound verbs in phrase based statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>firstly, they only carry out alignment between words and do not consider the case of complex expressions, such as multiword nes.
</prevsent>
<prevsent>secondly, the ibm models only allow at most one word in the source language to correspond to word in the target language (marcu, 2001, <papid> P01-1050 </papid>koehn et al, 2003).<papid> N03-1017 </papid></prevsent>
</prevsection>
<citsent citstr=" C96-2141 ">
in another well-known word alignment approach, hidden markov model (hmm: vogel et al., 1996), <papid> C96-2141 </papid>the alignment probabilities depend on the alignment position of the previous word.</citsent>
<aftsection>
<nextsent>it does not explicitly consider many-to-many alignment either.
</nextsent>
<nextsent>we address this many-to-many alignment problem indirectly.
</nextsent>
<nextsent>our objective is to see how to best handle the mwes in smt.
</nextsent>
<nextsent>in this work, two types of mwes, namely nes and compound verbs, are automatically identified on both sides of the parallel corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG597">
<title id=" W10-3707.xml">handling named entities and compound verbs in phrase based statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>then, source and target language nes are aligned using statistical transliteration method.
</prevsent>
<prevsent>we relyon these automatically aligned nes and treat them as translation examples.
</prevsent>
</prevsection>
<citsent citstr=" C04-1114 ">
adding bilingual dictionaries, which in effect are instances of atomic translation pairs, to the parallel corpus is well-known practice in domain adaptation in smt (eck et al., 2004; <papid> C04-1114 </papid>wu et al, 2008).<papid> C08-1125 </papid></citsent>
<aftsection>
<nextsent>we modify the parallel corpus by converting the mwes into single tokens and adding the aligned nes in the parallel corpus in bid to improve the word alignment, and hence the phrase alignment quality.
</nextsent>
<nextsent>this 46 preprocessing results in improved mt quality in terms of automatic mt evaluation metrics.
</nextsent>
<nextsent>the remainder of the paper is organized as follows.
</nextsent>
<nextsent>in section 2 we discuss related work.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG598">
<title id=" W10-3707.xml">handling named entities and compound verbs in phrase based statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>then, source and target language nes are aligned using statistical transliteration method.
</prevsent>
<prevsent>we relyon these automatically aligned nes and treat them as translation examples.
</prevsent>
</prevsection>
<citsent citstr=" C08-1125 ">
adding bilingual dictionaries, which in effect are instances of atomic translation pairs, to the parallel corpus is well-known practice in domain adaptation in smt (eck et al., 2004; <papid> C04-1114 </papid>wu et al, 2008).<papid> C08-1125 </papid></citsent>
<aftsection>
<nextsent>we modify the parallel corpus by converting the mwes into single tokens and adding the aligned nes in the parallel corpus in bid to improve the word alignment, and hence the phrase alignment quality.
</nextsent>
<nextsent>this 46 preprocessing results in improved mt quality in terms of automatic mt evaluation metrics.
</nextsent>
<nextsent>the remainder of the paper is organized as follows.
</nextsent>
<nextsent>in section 2 we discuss related work.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG599">
<title id=" W10-3707.xml">handling named entities and compound verbs in phrase based statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>section 4 includes the results obtained, together with some analysis.
</prevsent>
<prevsent>section 5 concludes, and provides avenues for further work.
</prevsent>
</prevsection>
<citsent citstr=" E03-1035 ">
moore (2003) <papid> E03-1035 </papid>presented an approach for simultaneous ne identification and translation.</citsent>
<aftsection>
<nextsent>he uses capitalization cues for identifying nes on the english side, and then he applies statistical techniques to decide which portion of the target language corresponds to the specified english ne.
</nextsent>
<nextsent>feng et al (2004) <papid> W04-3248 </papid>proposed maximum entropy model based approach for english chinese ne alignment which significantly outperforms ibm model4 and hmm.</nextsent>
<nextsent>they considered 4 features: translation score, transliteration score, source ne and target ne co-occurrence score, and the distortion score for distinguishing identical nes in the same sentence.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG600">
<title id=" W10-3707.xml">handling named entities and compound verbs in phrase based statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>moore (2003) <papid> E03-1035 </papid>presented an approach for simultaneous ne identification and translation.</prevsent>
<prevsent>he uses capitalization cues for identifying nes on the english side, and then he applies statistical techniques to decide which portion of the target language corresponds to the specified english ne.</prevsent>
</prevsection>
<citsent citstr=" W04-3248 ">
feng et al (2004) <papid> W04-3248 </papid>proposed maximum entropy model based approach for english chinese ne alignment which significantly outperforms ibm model4 and hmm.</citsent>
<aftsection>
<nextsent>they considered 4 features: translation score, transliteration score, source ne and target ne co-occurrence score, and the distortion score for distinguishing identical nes in the same sentence.
</nextsent>
<nextsent>huang et al (2003) <papid> W03-1502 </papid>proposed method for automatically extracting ne trans lingual equivalences between chinese and english based on multi-feature cost minimization.</nextsent>
<nextsent>the costs considered are transliteration cost, word-based translation cost, and ne tagging cost.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG601">
<title id=" W10-3707.xml">handling named entities and compound verbs in phrase based statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>feng et al (2004) <papid> W04-3248 </papid>proposed maximum entropy model based approach for english chinese ne alignment which significantly outperforms ibm model4 and hmm.</prevsent>
<prevsent>they considered 4 features: translation score, transliteration score, source ne and target ne co-occurrence score, and the distortion score for distinguishing identical nes in the same sentence.</prevsent>
</prevsection>
<citsent citstr=" W03-1502 ">
huang et al (2003) <papid> W03-1502 </papid>proposed method for automatically extracting ne trans lingual equivalences between chinese and english based on multi-feature cost minimization.</citsent>
<aftsection>
<nextsent>the costs considered are transliteration cost, word-based translation cost, and ne tagging cost.
</nextsent>
<nextsent>venkatapathy and joshi (2006) <papid> W06-1204 </papid>reported discriminative approach of using the compositional ity information about verb-based multi-word expressions to improve word alignment quality.</nextsent>
<nextsent>(ren et al, 2009) <papid> W09-2907 </papid>presented log likelihood ratio based hierarchical reducing algorithm to automatically extract bilingual mwes, and investigated the usefulness of these bilingual mwes in smt by integrating bilingual mwes into moses (koehn et al, 2007) <papid> P07-2045 </papid>in three ways.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG602">
<title id=" W10-3707.xml">handling named entities and compound verbs in phrase based statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>huang et al (2003) <papid> W03-1502 </papid>proposed method for automatically extracting ne trans lingual equivalences between chinese and english based on multi-feature cost minimization.</prevsent>
<prevsent>the costs considered are transliteration cost, word-based translation cost, and ne tagging cost.</prevsent>
</prevsection>
<citsent citstr=" W06-1204 ">
venkatapathy and joshi (2006) <papid> W06-1204 </papid>reported discriminative approach of using the compositional ity information about verb-based multi-word expressions to improve word alignment quality.</citsent>
<aftsection>
<nextsent>(ren et al, 2009) <papid> W09-2907 </papid>presented log likelihood ratio based hierarchical reducing algorithm to automatically extract bilingual mwes, and investigated the usefulness of these bilingual mwes in smt by integrating bilingual mwes into moses (koehn et al, 2007) <papid> P07-2045 </papid>in three ways.</nextsent>
<nextsent>they observed the highest improvement when they used an additional feature to represent whether or not bilingual phrase contains bilingual mwes.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG603">
<title id=" W10-3707.xml">handling named entities and compound verbs in phrase based statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the costs considered are transliteration cost, word-based translation cost, and ne tagging cost.
</prevsent>
<prevsent>venkatapathy and joshi (2006) <papid> W06-1204 </papid>reported discriminative approach of using the compositional ity information about verb-based multi-word expressions to improve word alignment quality.</prevsent>
</prevsection>
<citsent citstr=" W09-2907 ">
(ren et al, 2009) <papid> W09-2907 </papid>presented log likelihood ratio based hierarchical reducing algorithm to automatically extract bilingual mwes, and investigated the usefulness of these bilingual mwes in smt by integrating bilingual mwes into moses (koehn et al, 2007) <papid> P07-2045 </papid>in three ways.</citsent>
<aftsection>
<nextsent>they observed the highest improvement when they used an additional feature to represent whether or not bilingual phrase contains bilingual mwes.
</nextsent>
<nextsent>this approach was generalized in carpuat and diab (2010).<papid> N10-1029 </papid></nextsent>
<nextsent>in their work, the binary feature was replaced by count feature representing the number of mwes in the source language phrase.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG604">
<title id=" W10-3707.xml">handling named entities and compound verbs in phrase based statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the costs considered are transliteration cost, word-based translation cost, and ne tagging cost.
</prevsent>
<prevsent>venkatapathy and joshi (2006) <papid> W06-1204 </papid>reported discriminative approach of using the compositional ity information about verb-based multi-word expressions to improve word alignment quality.</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
(ren et al, 2009) <papid> W09-2907 </papid>presented log likelihood ratio based hierarchical reducing algorithm to automatically extract bilingual mwes, and investigated the usefulness of these bilingual mwes in smt by integrating bilingual mwes into moses (koehn et al, 2007) <papid> P07-2045 </papid>in three ways.</citsent>
<aftsection>
<nextsent>they observed the highest improvement when they used an additional feature to represent whether or not bilingual phrase contains bilingual mwes.
</nextsent>
<nextsent>this approach was generalized in carpuat and diab (2010).<papid> N10-1029 </papid></nextsent>
<nextsent>in their work, the binary feature was replaced by count feature representing the number of mwes in the source language phrase.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG605">
<title id=" W10-3707.xml">handling named entities and compound verbs in phrase based statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>(ren et al, 2009) <papid> W09-2907 </papid>presented log likelihood ratio based hierarchical reducing algorithm to automatically extract bilingual mwes, and investigated the usefulness of these bilingual mwes in smt by integrating bilingual mwes into moses (koehn et al, 2007) <papid> P07-2045 </papid>in three ways.</prevsent>
<prevsent>they observed the highest improvement when they used an additional feature to represent whether or not bilingual phrase contains bilingual mwes.</prevsent>
</prevsection>
<citsent citstr=" N10-1029 ">
this approach was generalized in carpuat and diab (2010).<papid> N10-1029 </papid></citsent>
<aftsection>
<nextsent>in their work, the binary feature was replaced by count feature representing the number of mwes in the source language phrase.
</nextsent>
<nextsent>intuitively, mwes should be both aligned in the parallel corpus and translated as whole.
</nextsent>
<nextsent>however, in the state-of-the-art pb-smt, it could well be the case that constituents of an mwe are marked and aligned as parts of consecutive phrases, since pb-smt (or any other approaches to smt) does not generally treat mwes as special tokens.
</nextsent>
<nextsent>another problem smt suffers from is that verb phrases are often wrongly translated, or even sometimes deleted in the output in order to produce target sentence considered good by the language model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG607">
<title id=" W10-3707.xml">handling named entities and compound verbs in phrase based statistical machine translation </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>in addition to v+v construction, we also consider n+v and adj+v structures.
</prevsent>
<prevsent>nes are also identified on both sides of translation pairs.
</prevsent>
</prevsection>
<citsent citstr=" W09-3539 ">
nes in bangla are much harder to identify than in english (ekbal and bandyopadhyay, 2009).<papid> W09-3539 </papid></citsent>
<aftsection>
<nextsent>this can be attributed to the fact that (i) there is no concept of capitalization in bangla; and (ii) bangla common nouns are often used as proper names.
</nextsent>
<nextsent>in bangla, the problem is compounded by the fact that suffixes (case markers, plural markers, emphasizers, specifiers) are also added to proper names, just like to any other common nouns.
</nextsent>
<nextsent>as consequence, the accuracy of bangla ne recognizers (ner) is much poorer compared to that for english.
</nextsent>
<nextsent>once the compound verbs and the nes are identified on both sides of the parallel corpus, they are converted into and replaced by single tokens.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG609">
<title id=" W10-3707.xml">handling named entities and compound verbs in phrase based statistical machine translation </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>nes in bangla are identified using the ner system of ekbal and bandyopadhyay (2008).
</prevsent>
<prevsent>we use the stanford parser, stanford ner and the ner for bangla along with the default model files provided, i.e., with no additional training.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
the effectiveness of the mwe-aligned parallel corpus developed in the work is demonstrated by using the standard log-linear pb-smt model as our baseline system: giza++ implementation of ibm word alignment model 4, phrase extraction heuristics described in (koehn et al, 2003), <papid> N03-1017 </papid>minimum-error-rate training (och, 2003) <papid> P03-1021 </papid>on held-out development set, target language model with kneser-ney smoothing (kneser and 1 the eilmt and ililmt projects are funded by the de-.</citsent>
<aftsection>
<nextsent>part ment of information technology (dit), ministry of communications and information technology (mcit), government of india.
</nextsent>
<nextsent>2 http://nlp.stanford.edu/software/lex-parser.shtml 3 http://crfchunker.sourceforge.net/ 4 http://nlp.stanford.edu/software/crf-ner.shtml ney, 1995) trained with srilm (stolcke, 2002), and moses decoder (koehn et al, 2007).<papid> P07-2045 </papid></nextsent>
<nextsent>we randomly extracted 500 sentences each for the development set and testset from the initial parallel corpus, and treated the rest as the training corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG611">
<title id=" W10-3707.xml">handling named entities and compound verbs in phrase based statistical machine translation </title>
<section> experiments and results.  </section>
<citcontext>
<prevsection>
<prevsent>before evaluation, the sin gle-token (target language) underscored mwes are expanded back to words comprising the mwes.
</prevsent>
<prevsent>since we did not have the gold-standard word alignment, we could not perform intrinsic evaluation of the word alignment.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
instead we carry out extrinsic evaluation on the mt quality using the well known automatic mt evaluation metrics: bleu (papineni et al, 2002), <papid> P02-1040 </papid>meteor (banerjee and lavie, 2005), <papid> W05-0909 </papid>nist (doddington, 2002), wer, per and ter (snover et al, 2006).</citsent>
<aftsection>
<nextsent>as can be seen from the evaluation results reported in table 2, baseline moses without any preprocessing of the dataset produces bleu score of 8.74.
</nextsent>
<nextsent>the low score can be attributed to the fact that bangla, morphologically rich language, is hard to translate into.
</nextsent>
<nextsent>moreover, bangla being relatively free phrase order language (ekbal and bandyopadhyay, 2009) <papid> W09-3539 </papid>ideally requires multiple set of references for proper evalua tion.</nextsent>
<nextsent>hence using single reference set does not justify evaluating translations in bangla.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG612">
<title id=" W10-3707.xml">handling named entities and compound verbs in phrase based statistical machine translation </title>
<section> experiments and results.  </section>
<citcontext>
<prevsection>
<prevsent>before evaluation, the sin gle-token (target language) underscored mwes are expanded back to words comprising the mwes.
</prevsent>
<prevsent>since we did not have the gold-standard word alignment, we could not perform intrinsic evaluation of the word alignment.
</prevsent>
</prevsection>
<citsent citstr=" W05-0909 ">
instead we carry out extrinsic evaluation on the mt quality using the well known automatic mt evaluation metrics: bleu (papineni et al, 2002), <papid> P02-1040 </papid>meteor (banerjee and lavie, 2005), <papid> W05-0909 </papid>nist (doddington, 2002), wer, per and ter (snover et al, 2006).</citsent>
<aftsection>
<nextsent>as can be seen from the evaluation results reported in table 2, baseline moses without any preprocessing of the dataset produces bleu score of 8.74.
</nextsent>
<nextsent>the low score can be attributed to the fact that bangla, morphologically rich language, is hard to translate into.
</nextsent>
<nextsent>moreover, bangla being relatively free phrase order language (ekbal and bandyopadhyay, 2009) <papid> W09-3539 </papid>ideally requires multiple set of references for proper evalua tion.</nextsent>
<nextsent>hence using single reference set does not justify evaluating translations in bangla.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG614">
<title id=" W10-3707.xml">handling named entities and compound verbs in phrase based statistical machine translation </title>
<section> experiments and results.  </section>
<citcontext>
<prevsection>
<prevsent>when nea is combined with cvast, the improvements are substantial, but it can not beat the individual improvement on nea.
</prevsent>
<prevsent>the (?)
</prevsent>
</prevsection>
<citsent citstr=" W04-3250 ">
marked systems produce statistically significant improvements as measured by bootstrap re sampling method (koehn, 2004) <papid> W04-3250 </papid>on bleu over the baseline system.</citsent>
<aftsection>
<nextsent>metric-wise individual best scores are shown in bold in table 2.
</nextsent>
<nextsent>in this paper, we have successfully shown how the simple yet effective preprocessing of treating two types of mwes, namely nes and compound verbs, as single-tokens, in conjunction with prior ne alignment can boost the performance of pb-smt system on an englishbangla translation task.
</nextsent>
<nextsent>treating compound verbs as single-tokens provides significant gains over the baseline pb-smt system.
</nextsent>
<nextsent>amongst the mwes, nes perhaps play the most important role in mt, as we have clearly demonstrated through experiments that automatic alignment of nes by means of transliteration improves the overall mt performance substantially across all automatic mt evaluation metrics.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG615">
<title id=" W10-1722.xml">the cued hifst system for the wmt10 translation shared task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also show that lattice minimum bayes-risk decoding is an effective framework for multi-source translation, leading to large gains in bleu score.
</prevsent>
<prevsent>this paper describes the cambridge university engineering department (cued) system submission to the acl 2010 fifth workshop on statistical machine translation (wmt10).
</prevsent>
</prevsection>
<citsent citstr=" N09-1049 ">
our translation system is hifst (iglesias et al, 2009<papid> N09-1049 </papid>a), hierarchical phrase-based decoder that generates translation lattices directly.</citsent>
<aftsection>
<nextsent>decoding is guided by cyk parser based on synchronous context free grammar induced from automatic word alignments (chiang, 2007).<papid> J07-2003 </papid></nextsent>
<nextsent>the decoder is implemented with weighted finite state transducers (wfsts) using standard operations available in the openfst libraries (allauzen et al, 2007).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG618">
<title id=" W10-1722.xml">the cued hifst system for the wmt10 translation shared task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper describes the cambridge university engineering department (cued) system submission to the acl 2010 fifth workshop on statistical machine translation (wmt10).
</prevsent>
<prevsent>our translation system is hifst (iglesias et al, 2009<papid> N09-1049 </papid>a), hierarchical phrase-based decoder that generates translation lattices directly.</prevsent>
</prevsection>
<citsent citstr=" J07-2003 ">
decoding is guided by cyk parser based on synchronous context free grammar induced from automatic word alignments (chiang, 2007).<papid> J07-2003 </papid></citsent>
<aftsection>
<nextsent>the decoder is implemented with weighted finite state transducers (wfsts) using standard operations available in the openfst libraries (allauzen et al, 2007).
</nextsent>
<nextsent>the use of wfsts allows fast and efficient exploration of vast translation search space, avoiding search errors in decoding.
</nextsent>
<nextsent>it also allows better integration with other steps in our translation pipeline such as 5-gram language model (lm) rescoring and lattice minimum bayes-risk (lmbr) decoding.1now member of the department of engineering, university of cambridge, cambridge, cb2 1pz, u.k. # sentences # tokens # types (a)europarl+news-commentary fr 1.7 52.4m 139.7ken 47.6m 121.6k (b)europarl+news-commentary+un fr 8.7 277.9m 421.0ken 241.4m 482.1k (c)europarl+news-commentary+un+giga fr 30.2 962.4m 2.4men 815.3m 2.7mtable 1: parallel datasets used for french-to english experiments.
</nextsent>
<nextsent>we participated in the french-english and spanish-english translation shared tasks in each translation direction.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG620">
<title id=" W10-1722.xml">the cued hifst system for the wmt10 translation shared task </title>
<section> system development.  </section>
<citcontext>
<prevsection>
<prevsent>data was then tokenized and lower cased, so mixed case is added as post-processing.
</prevsent>
<prevsent>2.2 alignments.
</prevsent>
</prevsection>
<citsent citstr=" H05-1022 ">
parallel data was aligned using the mttk toolkit (deng and byrne, 2005).<papid> H05-1022 </papid></citsent>
<aftsection>
<nextsent>in the english-to-french and english-to-spanish directions, we trained word-to-phrase hmm model with maximum phrase length of 2.
</nextsent>
<nextsent>in the french to english and spanish to english directions, we trained word to-phrase hmm model with bigram translation table and maximum phrase length of 4.
</nextsent>
<nextsent>we also trained context-dependent alignment models (brunning et al, 2009) <papid> N09-1013 </papid>for the french english medium-size (b) dataset.</nextsent>
<nextsent>the context ofa word is based on its part-of-speech and the part of-speech tags of the surrounding words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG621">
<title id=" W10-1722.xml">the cued hifst system for the wmt10 translation shared task </title>
<section> system development.  </section>
<citcontext>
<prevsection>
<prevsent>in the english-to-french and english-to-spanish directions, we trained word-to-phrase hmm model with maximum phrase length of 2.
</prevsent>
<prevsent>in the french to english and spanish to english directions, we trained word to-phrase hmm model with bigram translation table and maximum phrase length of 4.
</prevsent>
</prevsection>
<citsent citstr=" N09-1013 ">
we also trained context-dependent alignment models (brunning et al, 2009) <papid> N09-1013 </papid>for the french english medium-size (b) dataset.</citsent>
<aftsection>
<nextsent>the context ofa word is based on its part-of-speech and the part of-speech tags of the surrounding words.
</nextsent>
<nextsent>these tags were obtained by applying the tnt tagger (brants, 2000) for english and the treetagger(schmid, 1994) for french.
</nextsent>
<nextsent>decision tree clustering based on optimisation of the em auxiliary function was used to group contexts that translate similarly.
</nextsent>
<nextsent>unfortunately, time constraints prevented us from training context-dependent models for the larger (c) dataset.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG630">
<title id=" W10-1722.xml">the cued hifst system for the wmt10 translation shared task </title>
<section> system development.  </section>
<citcontext>
<prevsection>
<prevsent>one very interesting aspect is that hifst is able to build exact search spaces with this model, i.e. there is no pruning in search that may lead to spurious under generation errors.
</prevsent>
<prevsent>2.5 parameter optimisation.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
minimum error rate training (mert) (och, 2003)<papid> P03-1021 </papid>under the bleu score (papineni et al, 2001) optimises the weights of the following decoder features with respect to the newstest2008 development set: target lm, number of usages of the glue rule, word and rule insertion penalties, word deletion scale factor, source-to-target and target to-source translation models, source-to-target and target-to-source lexical models, and three binary rule count features inspired by bender et al (2007) indicating whether rule occurs once, twice, or more than twice in the parallel training data.</citsent>
<aftsection>
<nextsent>2.6 lattice rescoring.
</nextsent>
<nextsent>one of the advantages of hifst is direct generation of large translation lattices encoding many alternative translation hypotheses.
</nextsent>
<nextsent>these first-pass lattices are rescored with second-pass higher-order lms prior to lmbr.
</nextsent>
<nextsent>2.6.1 5-gram lm lattice rescoring we build sentence-specific, zero-cutoff stupidbackoff (brants et al, 2007) <papid> D07-1090 </papid>5-gram lms estimated over approximately 6.2 billion words for english, 2.3 billion words for french, and 1.4 billion words for spanish.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG631">
<title id=" W10-1722.xml">the cued hifst system for the wmt10 translation shared task </title>
<section> system development.  </section>
<citcontext>
<prevsection>
<prevsent>one of the advantages of hifst is direct generation of large translation lattices encoding many alternative translation hypotheses.
</prevsent>
<prevsent>these first-pass lattices are rescored with second-pass higher-order lms prior to lmbr.
</prevsent>
</prevsection>
<citsent citstr=" D07-1090 ">
2.6.1 5-gram lm lattice rescoring we build sentence-specific, zero-cutoff stupidbackoff (brants et al, 2007) <papid> D07-1090 </papid>5-gram lms estimated over approximately 6.2 billion words for english, 2.3 billion words for french, and 1.4 billion words for spanish.</citsent>
<aftsection>
<nextsent>for the english-french task, the second-pass lm training data is the same monolingual data used for the first-pass lms (assummarised in tables 3, 4).
</nextsent>
<nextsent>the spanish second pass 5-gram lm includes an additional 1.4 billion words of monolingual data from the spanish gigaword second edition (mendonca et al, 2009) and europarl, which were not included in the first-pass lm (see table 5).
</nextsent>
<nextsent>2.6.2 lmbr decoding minimum bayes-risk (mbr) decoding (kumar and byrne, 2004) <papid> N04-1022 </papid>over the full evidence space of the 5-gram rescored lattices was applied to select the translation hypothesis that maximises the conditional expected gain under the linear ised sentence-level bleu score (tromble et al, 2008;<papid> D08-1065 </papid>blackwood and byrne, 2010).</nextsent>
<nextsent>the unigram precision and average recall ratio were set as described in tromble et al (2008) <papid> D08-1065 </papid>using the new stest2008 development set.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG632">
<title id=" W10-1722.xml">the cued hifst system for the wmt10 translation shared task </title>
<section> system development.  </section>
<citcontext>
<prevsection>
<prevsent>for the english-french task, the second-pass lm training data is the same monolingual data used for the first-pass lms (assummarised in tables 3, 4).
</prevsent>
<prevsent>the spanish second pass 5-gram lm includes an additional 1.4 billion words of monolingual data from the spanish gigaword second edition (mendonca et al, 2009) and europarl, which were not included in the first-pass lm (see table 5).
</prevsent>
</prevsection>
<citsent citstr=" N04-1022 ">
2.6.2 lmbr decoding minimum bayes-risk (mbr) decoding (kumar and byrne, 2004) <papid> N04-1022 </papid>over the full evidence space of the 5-gram rescored lattices was applied to select the translation hypothesis that maximises the conditional expected gain under the linear ised sentence-level bleu score (tromble et al, 2008;<papid> D08-1065 </papid>blackwood and byrne, 2010).</citsent>
<aftsection>
<nextsent>the unigram precision and average recall ratio were set as described in tromble et al (2008) <papid> D08-1065 </papid>using the new stest2008 development set.</nextsent>
<nextsent>2.7 hypothesis combination.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG633">
<title id=" W10-1722.xml">the cued hifst system for the wmt10 translation shared task </title>
<section> system development.  </section>
<citcontext>
<prevsection>
<prevsent>for the english-french task, the second-pass lm training data is the same monolingual data used for the first-pass lms (assummarised in tables 3, 4).
</prevsent>
<prevsent>the spanish second pass 5-gram lm includes an additional 1.4 billion words of monolingual data from the spanish gigaword second edition (mendonca et al, 2009) and europarl, which were not included in the first-pass lm (see table 5).
</prevsent>
</prevsection>
<citsent citstr=" D08-1065 ">
2.6.2 lmbr decoding minimum bayes-risk (mbr) decoding (kumar and byrne, 2004) <papid> N04-1022 </papid>over the full evidence space of the 5-gram rescored lattices was applied to select the translation hypothesis that maximises the conditional expected gain under the linear ised sentence-level bleu score (tromble et al, 2008;<papid> D08-1065 </papid>blackwood and byrne, 2010).</citsent>
<aftsection>
<nextsent>the unigram precision and average recall ratio were set as described in tromble et al (2008) <papid> D08-1065 </papid>using the new stest2008 development set.</nextsent>
<nextsent>2.7 hypothesis combination.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG636">
<title id=" W10-1722.xml">the cued hifst system for the wmt10 translation shared task </title>
<section> multi-source translation experiments.  </section>
<citcontext>
<prevsection>
<prevsent>this is surprising given that additional data was helpful for the french-english task.
</prevsent>
<prevsent>solving this issue is left for future work.
</prevsent>
</prevsection>
<citsent citstr=" E09-1082 ">
multi-source translation (och and ney, 2001;schroeder et al, 2009) <papid> E09-1082 </papid>is possible whenever multiple translations of the source language input sentence are available.</citsent>
<aftsection>
<nextsent>the motivation for multi source translation is that some of the ambiguity that must be resolved in translating between onepair of languages may not be present in different pair.
</nextsent>
<nextsent>in the following experiments, multiple lmbr is applied for the first time to the task of multi-source translation.
</nextsent>
<nextsent>158 task configuration newstest2008 newstest2009 newstest2010 sp ? en hifst (a) 24.6 26.0 29.1 +5g+lmbr 25.4 27.0 30.5 hifst (b) 23.7 25.4 ? hifst (b2) 24.3 25.7 ? hifst (b3) 24.2 25.6 ? en ? sp hifst (a) 23.9 24.5 28.0 +5g+lmbr 24.7 25.5 29.1 table 7: translation results for the spanish-english (sp-en) language pair, shown in lowercase ibm bleu.
</nextsent>
<nextsent>bold results correspond to submitted systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG637">
<title id=" W10-1722.xml">the cued hifst system for the wmt10 translation shared task </title>
<section> multi-source translation experiments.  </section>
<citcontext>
<prevsection>
<prevsent>separate second-pass 5-gram rescored lattices efr and ees are generated for each test set sentence using the french-to-english and spanish-toenglish hifst translation systems.
</prevsent>
<prevsent>the mbr hypothesis space is formed as the union of these lattices.
</prevsent>
</prevsection>
<citsent citstr=" N09-2019 ">
in similar manner to mbr decoding over multiple k-best lists in de gispert et al (2009),<papid> N09-2019 </papid>the path posterior probability of each n-gram required for linear ised lmbr is computed as linear interpolation of the posterior probabilities according to each individual lattice so that p(u|e) = fr p(u|efr) + es p(u|ees), where p(u|e) is thesum of the posterior probabilities of all paths containing the n-gram u. the interpolation weights fr + es = 1 are optimised for bleu score on the development set newstest2008.</citsent>
<aftsection>
<nextsent>the results of single-system and multi-sourcelmbr decoding are shown in table 8.
</nextsent>
<nextsent>the optimised interpolation weights were fr = 0.55 andes = 0.45.
</nextsent>
<nextsent>single-system lmbr gives relatively small gains on these test sets.
</nextsent>
<nextsent>much larger gains are obtained through multi-source mbr combination.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG638">
<title id=" W10-2809.xml">active learning for constrained dirichlet process mixture models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>bayesian non-parametric mixture models have the attractive property that the number of components used to model the data is not fixed in advance but is determined by the model and the data.
</prevsent>
<prevsent>this property is particularly interesting for nlp where many tasks are aimed at discovering novel information.
</prevsent>
</prevsection>
<citsent citstr=" P06-1124 ">
recent work has applied such models to various tasks with promising results, e.g. teh (2006) <papid> P06-1124 </papid>and cohn et al (2009).<papid> N09-1062 </papid></citsent>
<aftsection>
<nextsent>vlachos et al (2009) <papid> W09-0210 </papid>applied the basic model of this class, the dirichlet process mixture model (dpmm), to lexical-semantic verb clustering with encouraging results.</nextsent>
<nextsent>the task involves discovering classes of verbs similar in terms of their syntactic-semantic properties (e.g. motion class for travel, walk, run, etc.).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG639">
<title id=" W10-2809.xml">active learning for constrained dirichlet process mixture models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>bayesian non-parametric mixture models have the attractive property that the number of components used to model the data is not fixed in advance but is determined by the model and the data.
</prevsent>
<prevsent>this property is particularly interesting for nlp where many tasks are aimed at discovering novel information.
</prevsent>
</prevsection>
<citsent citstr=" N09-1062 ">
recent work has applied such models to various tasks with promising results, e.g. teh (2006) <papid> P06-1124 </papid>and cohn et al (2009).<papid> N09-1062 </papid></citsent>
<aftsection>
<nextsent>vlachos et al (2009) <papid> W09-0210 </papid>applied the basic model of this class, the dirichlet process mixture model (dpmm), to lexical-semantic verb clustering with encouraging results.</nextsent>
<nextsent>the task involves discovering classes of verbs similar in terms of their syntactic-semantic properties (e.g. motion class for travel, walk, run, etc.).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG640">
<title id=" W10-2809.xml">active learning for constrained dirichlet process mixture models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this property is particularly interesting for nlp where many tasks are aimed at discovering novel information.
</prevsent>
<prevsent>recent work has applied such models to various tasks with promising results, e.g. teh (2006) <papid> P06-1124 </papid>and cohn et al (2009).<papid> N09-1062 </papid></prevsent>
</prevsection>
<citsent citstr=" W09-0210 ">
vlachos et al (2009) <papid> W09-0210 </papid>applied the basic model of this class, the dirichlet process mixture model (dpmm), to lexical-semantic verb clustering with encouraging results.</citsent>
<aftsection>
<nextsent>the task involves discovering classes of verbs similar in terms of their syntactic-semantic properties (e.g. motion class for travel, walk, run, etc.).
</nextsent>
<nextsent>such classes can provide important support for other tasks, such asword sense disambiguation, parsing and semantic role labeling.
</nextsent>
<nextsent>(dang, 2004; swier and stevenson, 2004) <papid> W04-3213 </papid>although some fixed classifications are available these are not comprehensive and are inadequate for specific domains.furthermore, vlachos et al (2009) <papid> W09-0210 </papid>used constrained version of the dpmm in order to guide clustering towards some prior intuition or considerations relevant to the specific task at hand.</nextsent>
<nextsent>this supervision was modelled as pairwise constraints between instances and it informs the model of relations between them that cannot be recovered bythe model on the basis of the feature representation used.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG642">
<title id=" W10-2809.xml">active learning for constrained dirichlet process mixture models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the task involves discovering classes of verbs similar in terms of their syntactic-semantic properties (e.g. motion class for travel, walk, run, etc.).
</prevsent>
<prevsent>such classes can provide important support for other tasks, such asword sense disambiguation, parsing and semantic role labeling.
</prevsent>
</prevsection>
<citsent citstr=" W04-3213 ">
(dang, 2004; swier and stevenson, 2004) <papid> W04-3213 </papid>although some fixed classifications are available these are not comprehensive and are inadequate for specific domains.furthermore, vlachos et al (2009) <papid> W09-0210 </papid>used constrained version of the dpmm in order to guide clustering towards some prior intuition or considerations relevant to the specific task at hand.</citsent>
<aftsection>
<nextsent>this supervision was modelled as pairwise constraints between instances and it informs the model of relations between them that cannot be recovered bythe model on the basis of the feature representation used.
</nextsent>
<nextsent>like other forms of supervision, these constraints require manual annotation and it is important to maximize the benefits obtained from it.
</nextsent>
<nextsent>therefore it is natural to consider active learning (settles, 2009) in order to focus the supervision on clusterings on which the model is uncertain.in this work, we propose simple yet effective active learning method employing uncertainty based sampling.
</nextsent>
<nextsent>the effectiveness of the al method is demonstrated on two datasets, one of which has multiple gold standards.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG646">
<title id=" W10-2809.xml">active learning for constrained dirichlet process mixture models </title>
<section> datasets and evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>therefore, we rely exclusively on the model and the features to guide the constraint selection process.
</prevsent>
<prevsent>if the model combined with the features is not appropriate for the task then the constraints chosen are unlikely to be useful.
</prevsent>
</prevsection>
<citsent citstr=" P06-1044 ">
in our experiments we used two verb clustering datasets, one from general english (sun et al,2008) and one from the biomedical domain (korhonen et al, 2006).<papid> P06-1044 </papid></citsent>
<aftsection>
<nextsent>in both datasets the features for each verb are its subcategorization frames (scfs) which capture the syntactic context inwhich it occurs.
</nextsent>
<nextsent>they were acquired automatically using domain-independent statistical parsing toolkit, rasp (briscoe and carroll, 2002), and classifier which identifies verbal scfs.
</nextsent>
<nextsent>as aconsequence, they include some noise due to standard text processing and parsing errors and due to the subtlety of the argument-adjunct distinction.
</nextsent>
<nextsent>the general english dataset contains 204 verbs 58 belonging to 17 fine-grained classes in levins(levin, 1993) taxonomy so that each class contains 12 verbs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG647">
<title id=" W10-2809.xml">active learning for constrained dirichlet process mixture models </title>
<section> datasets and evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>both datasets were pre-processed using non-negative matrix factor ization (lin, 2007) which decomposes large sparse matrix into two dense matrices (of lower dimensionality) withnon-negative values.
</prevsent>
<prevsent>in all experiments 35 dimensions were kept.
</prevsent>
</prevsection>
<citsent citstr=" D07-1043 ">
preliminary experiments with different number of dimensions kept did not affect the performance substantially.we evaluate our results using three information theoretic measures: variation of information (meila?, 2007), v-measure (rosenberg and hirschberg, 2007) <papid> D07-1043 </papid>and v-beta (vlachos et al,2009).<papid> W09-0210 </papid></citsent>
<aftsection>
<nextsent>all three assess the two desirable properties that clustering should have with respect to gold standard, homogeneity and completeness.
</nextsent>
<nextsent>homogeneity reflects the degree to which each cluster contains instances from single class and is defined as the conditional entropy of the class distribution of the gold standard given the clustering.
</nextsent>
<nextsent>completeness reflects the degree to which each class is contained in single cluster and is defined as the conditional entropy of clustering given the class distribution in the gold standard.
</nextsent>
<nextsent>v-beta balances these properties explicitly by taking into account the ratio of the number of cluster discovered over the number of classes in the gold standard.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG649">
<title id=" W10-1913.xml">identifying the information structure of scientific abstracts an investigation of three different schemes </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, many abstracts provide some background information before defining the precise objective of the study, and the conclusions are typically preceded by the description of the results obtained.many readers of scientific abstracts are interested in specific types of information only, e.g. the general background of the study, the methods used in the study, or the results obtained.
</prevsent>
<prevsent>accordingly, many text mining tasks focus on the extraction of information from certain parts of abstracts only.
</prevsent>
</prevsection>
<citsent citstr=" J02-4002 ">
therefore classification of abstracts(or full articles) according to the categories of information structure can support both the manual study of scientific literature as well as its automatic analysis, e.g. information extraction, summarization and information retrieval (teufel and moens, 2002; <papid> J02-4002 </papid>mizuta et al, 2005; tbahriti et al, 2006; ruch et al, 2007).</citsent>
<aftsection>
<nextsent>to date, number of different schemes and techniques have been proposed for sentence-based classification of scientific literature according to information structure, e.g.
</nextsent>
<nextsent>(teufel and moens,2002; <papid> J02-4002 </papid>mizuta et al, 2005; lin et al, 2006; <papid> W06-3309 </papid>hirohata et al, 2008; <papid> I08-1050 </papid>teufel et al, 2009; <papid> D09-1155 </papid>shatkay et al, 2008; liakata et al, 2010).</nextsent>
<nextsent>some of the schemes are coarse-grained and merely classify sentences according to typical section names seen in scientific documents (lin et al, 2006; <papid> W06-3309 </papid>hirohata et al, 2008).<papid> I08-1050 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG653">
<title id=" W10-1913.xml">identifying the information structure of scientific abstracts an investigation of three different schemes </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>therefore classification of abstracts(or full articles) according to the categories of information structure can support both the manual study of scientific literature as well as its automatic analysis, e.g. information extraction, summarization and information retrieval (teufel and moens, 2002; <papid> J02-4002 </papid>mizuta et al, 2005; tbahriti et al, 2006; ruch et al, 2007).</prevsent>
<prevsent>to date, number of different schemes and techniques have been proposed for sentence-based classification of scientific literature according to information structure, e.g.</prevsent>
</prevsection>
<citsent citstr=" W06-3309 ">
(teufel and moens,2002; <papid> J02-4002 </papid>mizuta et al, 2005; lin et al, 2006; <papid> W06-3309 </papid>hirohata et al, 2008; <papid> I08-1050 </papid>teufel et al, 2009; <papid> D09-1155 </papid>shatkay et al, 2008; liakata et al, 2010).</citsent>
<aftsection>
<nextsent>some of the schemes are coarse-grained and merely classify sentences according to typical section names seen in scientific documents (lin et al, 2006; <papid> W06-3309 </papid>hirohata et al, 2008).<papid> I08-1050 </papid></nextsent>
<nextsent>others are finer-grained and based e.g. on argumentative zones (teufel and moens, 2002; <papid> J02-4002 </papid>mizuta et al, 2005; teufel et al, 2009), <papid> D09-1155 </papid>qualitative dimensions (shatkay et al, 2008) or conceptual structure (liakata et al, 2010) of doc uments.the majority of such schemes have been developed for full scientific journal articles which are richer in information and also considered to be more in need of the definition of information structure (lin, 2009).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG655">
<title id=" W10-1913.xml">identifying the information structure of scientific abstracts an investigation of three different schemes </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>therefore classification of abstracts(or full articles) according to the categories of information structure can support both the manual study of scientific literature as well as its automatic analysis, e.g. information extraction, summarization and information retrieval (teufel and moens, 2002; <papid> J02-4002 </papid>mizuta et al, 2005; tbahriti et al, 2006; ruch et al, 2007).</prevsent>
<prevsent>to date, number of different schemes and techniques have been proposed for sentence-based classification of scientific literature according to information structure, e.g.</prevsent>
</prevsection>
<citsent citstr=" I08-1050 ">
(teufel and moens,2002; <papid> J02-4002 </papid>mizuta et al, 2005; lin et al, 2006; <papid> W06-3309 </papid>hirohata et al, 2008; <papid> I08-1050 </papid>teufel et al, 2009; <papid> D09-1155 </papid>shatkay et al, 2008; liakata et al, 2010).</citsent>
<aftsection>
<nextsent>some of the schemes are coarse-grained and merely classify sentences according to typical section names seen in scientific documents (lin et al, 2006; <papid> W06-3309 </papid>hirohata et al, 2008).<papid> I08-1050 </papid></nextsent>
<nextsent>others are finer-grained and based e.g. on argumentative zones (teufel and moens, 2002; <papid> J02-4002 </papid>mizuta et al, 2005; teufel et al, 2009), <papid> D09-1155 </papid>qualitative dimensions (shatkay et al, 2008) or conceptual structure (liakata et al, 2010) of doc uments.the majority of such schemes have been developed for full scientific journal articles which are richer in information and also considered to be more in need of the definition of information structure (lin, 2009).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG656">
<title id=" W10-1913.xml">identifying the information structure of scientific abstracts an investigation of three different schemes </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>therefore classification of abstracts(or full articles) according to the categories of information structure can support both the manual study of scientific literature as well as its automatic analysis, e.g. information extraction, summarization and information retrieval (teufel and moens, 2002; <papid> J02-4002 </papid>mizuta et al, 2005; tbahriti et al, 2006; ruch et al, 2007).</prevsent>
<prevsent>to date, number of different schemes and techniques have been proposed for sentence-based classification of scientific literature according to information structure, e.g.</prevsent>
</prevsection>
<citsent citstr=" D09-1155 ">
(teufel and moens,2002; <papid> J02-4002 </papid>mizuta et al, 2005; lin et al, 2006; <papid> W06-3309 </papid>hirohata et al, 2008; <papid> I08-1050 </papid>teufel et al, 2009; <papid> D09-1155 </papid>shatkay et al, 2008; liakata et al, 2010).</citsent>
<aftsection>
<nextsent>some of the schemes are coarse-grained and merely classify sentences according to typical section names seen in scientific documents (lin et al, 2006; <papid> W06-3309 </papid>hirohata et al, 2008).<papid> I08-1050 </papid></nextsent>
<nextsent>others are finer-grained and based e.g. on argumentative zones (teufel and moens, 2002; <papid> J02-4002 </papid>mizuta et al, 2005; teufel et al, 2009), <papid> D09-1155 </papid>qualitative dimensions (shatkay et al, 2008) or conceptual structure (liakata et al, 2010) of doc uments.the majority of such schemes have been developed for full scientific journal articles which are richer in information and also considered to be more in need of the definition of information structure (lin, 2009).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG672">
<title id=" W10-1913.xml">identifying the information structure of scientific abstracts an investigation of three different schemes </title>
<section> annotation of abstracts.  </section>
<citcontext>
<prevsection>
<prevsent>because the matrix verb is not the only meaningful verb, we used all the verbs instead.
</prevsent>
<prevsent>verb class.
</prevsent>
</prevsection>
<citsent citstr=" D09-1067 ">
because individual verbs can result in sparse data problems, we also experimented with anovel feature: verb class (e.g. the class of experiment verbs for verbs such as measure and inject).we obtained 60 classes by clustering verbs appearing in full cancer risk assessment articles using the approach of sun and korhonen (2009).<papid> D09-1067 </papid>pos.</citsent>
<aftsection>
<nextsent>tense tends to vary from one category to another, e.g. past is common in res and past partici 103 plein con.
</nextsent>
<nextsent>we used the part-of-speech (pos) tag of each verb assigned by the c&c; tagger (curran et al, 2007) <papid> P07-2009 </papid>as feature.gr.</nextsent>
<nextsent>structural information about heads and dependents has proved useful in text classification.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG673">
<title id=" W10-1913.xml">identifying the information structure of scientific abstracts an investigation of three different schemes </title>
<section> annotation of abstracts.  </section>
<citcontext>
<prevsection>
<prevsent>because individual verbs can result in sparse data problems, we also experimented with anovel feature: verb class (e.g. the class of experiment verbs for verbs such as measure and inject).we obtained 60 classes by clustering verbs appearing in full cancer risk assessment articles using the approach of sun and korhonen (2009).<papid> D09-1067 </papid>pos.</prevsent>
<prevsent>tense tends to vary from one category to another, e.g. past is common in res and past partici 103 plein con.</prevsent>
</prevsection>
<citsent citstr=" P07-2009 ">
we used the part-of-speech (pos) tag of each verb assigned by the c&c; tagger (curran et al, 2007) <papid> P07-2009 </papid>as feature.gr.</citsent>
<aftsection>
<nextsent>structural information about heads and dependents has proved useful in text classification.
</nextsent>
<nextsent>we used grammatical relations (grs) returned by the c&c; parser as features.
</nextsent>
<nextsent>they consist of anamed relation, head and dependent, and possibly extra parameters depending on the relation involved, e.g.
</nextsent>
<nextsent>(dobj investigate mouse).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG679">
<title id=" W10-1913.xml">identifying the information structure of scientific abstracts an investigation of three different schemes </title>
<section> annotation of abstracts.  </section>
<citcontext>
<prevsection>
<prevsent>however, we plan to develop our features further and to make better use of the sequential nature of information structure.
</prevsent>
<prevsent>currently this is only represented as the history feature, which provides narrow window view to the category of the previous sentence.
</prevsent>
</prevsection>
<citsent citstr=" W09-3603 ">
also we plan to compare svm against methods such as crf and maximum entropy which have proved success fulin recent related works (hirohata et al, 2008; <papid> I08-1050 </papid>merity et al, 2009).<papid> W09-3603 </papid></citsent>
<aftsection>
<nextsent>the resulting models will be evaluated both directly and in the context of cra to provide an indication of their practical usefulness for real-world tasks.
</nextsent>
<nextsent>acknowledgments the work reported in this paper was funded by the royal society (uk), the swedish research council, fas (sweden), and jisc (uk) which is funding the sapient automation project.
</nextsent>
<nextsent>yg was funded by the cambridge international scholarship.
</nextsent>
<nextsent>106
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG680">
<title id=" W10-3001.xml">the conll2010 shared task learning to detect hedges and their scope in natural language text </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the term hedging was originally introduced bylakoff (1972).
</prevsent>
<prevsent>however, hedge detection has received considerable interest just recently in thenlp community.
</prevsent>
</prevsection>
<citsent citstr=" W07-1011 ">
light et al (2004) used handcrafted list of hedge cues to identify speculative sentences in medline abstracts and several biomedical nlp applications incorporate rules for identifying the certainty of extracted information(friedman et al, 1994; chapman et al, 2007; <papid> W07-1011 </papid>aramaki et al, 2009; <papid> W09-1324 </papid>conway et al, 2009).<papid> W09-1318 </papid>the most recent approaches to uncertainty detection exploit machine learning models that utilize manually labeled corpora.</citsent>
<aftsection>
<nextsent>medlock and briscoe (2007) <papid> P07-1125 </papid>used single words as input feature sin order to classify sentences from biological articles (flybase) as speculative or non-speculativebased on semi-automatically collected training ex amples.</nextsent>
<nextsent>szarvas (2008) extended the methodology of medlock and briscoe (2007) <papid> P07-1125 </papid>to use n-gram features and semi-supervised selection of the keyword features.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG681">
<title id=" W10-3001.xml">the conll2010 shared task learning to detect hedges and their scope in natural language text </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the term hedging was originally introduced bylakoff (1972).
</prevsent>
<prevsent>however, hedge detection has received considerable interest just recently in thenlp community.
</prevsent>
</prevsection>
<citsent citstr=" W09-1324 ">
light et al (2004) used handcrafted list of hedge cues to identify speculative sentences in medline abstracts and several biomedical nlp applications incorporate rules for identifying the certainty of extracted information(friedman et al, 1994; chapman et al, 2007; <papid> W07-1011 </papid>aramaki et al, 2009; <papid> W09-1324 </papid>conway et al, 2009).<papid> W09-1318 </papid>the most recent approaches to uncertainty detection exploit machine learning models that utilize manually labeled corpora.</citsent>
<aftsection>
<nextsent>medlock and briscoe (2007) <papid> P07-1125 </papid>used single words as input feature sin order to classify sentences from biological articles (flybase) as speculative or non-speculativebased on semi-automatically collected training ex amples.</nextsent>
<nextsent>szarvas (2008) extended the methodology of medlock and briscoe (2007) <papid> P07-1125 </papid>to use n-gram features and semi-supervised selection of the keyword features.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG682">
<title id=" W10-3001.xml">the conll2010 shared task learning to detect hedges and their scope in natural language text </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the term hedging was originally introduced bylakoff (1972).
</prevsent>
<prevsent>however, hedge detection has received considerable interest just recently in thenlp community.
</prevsent>
</prevsection>
<citsent citstr=" W09-1318 ">
light et al (2004) used handcrafted list of hedge cues to identify speculative sentences in medline abstracts and several biomedical nlp applications incorporate rules for identifying the certainty of extracted information(friedman et al, 1994; chapman et al, 2007; <papid> W07-1011 </papid>aramaki et al, 2009; <papid> W09-1324 </papid>conway et al, 2009).<papid> W09-1318 </papid>the most recent approaches to uncertainty detection exploit machine learning models that utilize manually labeled corpora.</citsent>
<aftsection>
<nextsent>medlock and briscoe (2007) <papid> P07-1125 </papid>used single words as input feature sin order to classify sentences from biological articles (flybase) as speculative or non-speculativebased on semi-automatically collected training ex amples.</nextsent>
<nextsent>szarvas (2008) extended the methodology of medlock and briscoe (2007) <papid> P07-1125 </papid>to use n-gram features and semi-supervised selection of the keyword features.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG683">
<title id=" W10-3001.xml">the conll2010 shared task learning to detect hedges and their scope in natural language text </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, hedge detection has received considerable interest just recently in thenlp community.
</prevsent>
<prevsent>light et al (2004) used handcrafted list of hedge cues to identify speculative sentences in medline abstracts and several biomedical nlp applications incorporate rules for identifying the certainty of extracted information(friedman et al, 1994; chapman et al, 2007; <papid> W07-1011 </papid>aramaki et al, 2009; <papid> W09-1324 </papid>conway et al, 2009).<papid> W09-1318 </papid>the most recent approaches to uncertainty detection exploit machine learning models that utilize manually labeled corpora.</prevsent>
</prevsection>
<citsent citstr=" P07-1125 ">
medlock and briscoe (2007) <papid> P07-1125 </papid>used single words as input feature sin order to classify sentences from biological articles (flybase) as speculative or non-speculativebased on semi-automatically collected training ex amples.</citsent>
<aftsection>
<nextsent>szarvas (2008) extended the methodology of medlock and briscoe (2007) <papid> P07-1125 </papid>to use n-gram features and semi-supervised selection of the keyword features.</nextsent>
<nextsent>kilicoglu and bergler (2008) <papid> W08-0607 </papid>proposed linguistically motivated approach basedon syntactic information to semi-automatically refine list of hedge cues.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG687">
<title id=" W10-3001.xml">the conll2010 shared task learning to detect hedges and their scope in natural language text </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>medlock and briscoe (2007) <papid> P07-1125 </papid>used single words as input feature sin order to classify sentences from biological articles (flybase) as speculative or non-speculativebased on semi-automatically collected training ex amples.</prevsent>
<prevsent>szarvas (2008) extended the methodology of medlock and briscoe (2007) <papid> P07-1125 </papid>to use n-gram features and semi-supervised selection of the keyword features.</prevsent>
</prevsection>
<citsent citstr=" W08-0607 ">
kilicoglu and bergler (2008) <papid> W08-0607 </papid>proposed linguistically motivated approach basedon syntactic information to semi-automatically refine list of hedge cues.</citsent>
<aftsection>
<nextsent>ganter and strube (2009)proposed an approach for the automatic detection of sentences containing uncertainty based on wikipedia weasel tags and syntactic patterns.
</nextsent>
<nextsent>the bio scope corpus (vincze et al, 2008) is manually annotated with negation and speculation cues and their linguistic scope.
</nextsent>
<nextsent>it consists of clinical free-texts, biological texts from full papers and scientific abstracts.
</nextsent>
<nextsent>using bio scope for training and evaluation, morante and daelemans(2009) <papid> W09-1304 </papid>developed scope detector following supervised sequence labeling approach while ozgur and radev (2009) developed rule-based system that exploits syntactic patterns.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG689">
<title id=" W10-3001.xml">the conll2010 shared task learning to detect hedges and their scope in natural language text </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the bio scope corpus (vincze et al, 2008) is manually annotated with negation and speculation cues and their linguistic scope.
</prevsent>
<prevsent>it consists of clinical free-texts, biological texts from full papers and scientific abstracts.
</prevsent>
</prevsection>
<citsent citstr=" W09-1304 ">
using bio scope for training and evaluation, morante and daelemans(2009) <papid> W09-1304 </papid>developed scope detector following supervised sequence labeling approach while ozgur and radev (2009) developed rule-based system that exploits syntactic patterns.</citsent>
<aftsection>
<nextsent>several related works have also been published within the framework of the bionlp09 shared task on event extraction (kim et al, 2009), <papid> W09-1401 </papid>where separate subtask was dedicated to predicting whether the recognized biological events are under negation or speculation, based on the genia event corpus annotations (kilicoglu and bergler, 2009; <papid> W09-1418 </papid>van landeghem et al, 2009).</nextsent>
<nextsent>the shared task addressed the detection of uncertainty in two domains.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG690">
<title id=" W10-3001.xml">the conll2010 shared task learning to detect hedges and their scope in natural language text </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>it consists of clinical free-texts, biological texts from full papers and scientific abstracts.
</prevsent>
<prevsent>using bio scope for training and evaluation, morante and daelemans(2009) <papid> W09-1304 </papid>developed scope detector following supervised sequence labeling approach while ozgur and radev (2009) developed rule-based system that exploits syntactic patterns.</prevsent>
</prevsection>
<citsent citstr=" W09-1401 ">
several related works have also been published within the framework of the bionlp09 shared task on event extraction (kim et al, 2009), <papid> W09-1401 </papid>where separate subtask was dedicated to predicting whether the recognized biological events are under negation or speculation, based on the genia event corpus annotations (kilicoglu and bergler, 2009; <papid> W09-1418 </papid>van landeghem et al, 2009).</citsent>
<aftsection>
<nextsent>the shared task addressed the detection of uncertainty in two domains.
</nextsent>
<nextsent>as uncertainty detection is extremely important for biomedical information extraction and most existing approaches have targeted such applications, participants were askedto develop systems for hedge detection in biological scientific articles.
</nextsent>
<nextsent>uncertainty detection is also important, e.g. in encyclopedias, where the goal is to collect reliable world knowledge about real-world concepts and topics.
</nextsent>
<nextsent>for example, wikipedia explicitly declares that statements reflecting author opinions or those not backed up by facts (e.g. references) should be avoided (see3.2 for details).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG691">
<title id=" W10-3001.xml">the conll2010 shared task learning to detect hedges and their scope in natural language text </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>it consists of clinical free-texts, biological texts from full papers and scientific abstracts.
</prevsent>
<prevsent>using bio scope for training and evaluation, morante and daelemans(2009) <papid> W09-1304 </papid>developed scope detector following supervised sequence labeling approach while ozgur and radev (2009) developed rule-based system that exploits syntactic patterns.</prevsent>
</prevsection>
<citsent citstr=" W09-1418 ">
several related works have also been published within the framework of the bionlp09 shared task on event extraction (kim et al, 2009), <papid> W09-1401 </papid>where separate subtask was dedicated to predicting whether the recognized biological events are under negation or speculation, based on the genia event corpus annotations (kilicoglu and bergler, 2009; <papid> W09-1418 </papid>van landeghem et al, 2009).</citsent>
<aftsection>
<nextsent>the shared task addressed the detection of uncertainty in two domains.
</nextsent>
<nextsent>as uncertainty detection is extremely important for biomedical information extraction and most existing approaches have targeted such applications, participants were askedto develop systems for hedge detection in biological scientific articles.
</nextsent>
<nextsent>uncertainty detection is also important, e.g. in encyclopedias, where the goal is to collect reliable world knowledge about real-world concepts and topics.
</nextsent>
<nextsent>for example, wikipedia explicitly declares that statements reflecting author opinions or those not backed up by facts (e.g. references) should be avoided (see3.2 for details).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG695">
<title id=" W10-0907.xml">semantic role labeling for open information extraction </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>open information extraction is recent paradigm for machine reading from arbitrary text.
</prevsent>
<prevsent>in contrast to existing techniques, which have used only shallow syntactic features, we investigate the use of semantic features (semantic roles) for the task of open ie.
</prevsent>
</prevsection>
<citsent citstr=" J08-2005 ">
we compare text runner (banko et al, 2007), state of the art open extractor, with our novel extractor srl-ie, which is based on uiucs srl system (punyakanok et al, 2008).<papid> J08-2005 </papid></citsent>
<aftsection>
<nextsent>wefind that srl-ie is robust to noisy heterogeneous web data and outperforms textrun ner on extraction quality.
</nextsent>
<nextsent>on the other hand, text runner performs over 2 orders of magnitude faster and achieves good precision in high locality and high redundancy extractions.
</nextsent>
<nextsent>these observations enable the construction of hybrid extractors that output higher quality results than text runner and similar quality as srl-ie in much less time.
</nextsent>
<nextsent>the grand challenge of machine reading (etzioni et al, 2006) requires, as key step, scalable system for extracting information from large, heterogeneous, unstructured text.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG696">
<title id=" W10-0907.xml">semantic role labeling for open information extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there cent open information extraction paradigm (banko et al, 2007) attempts to overcome the knowledge acquisition bottleneck with its relation-independent nature and no manually annotated training data.
</prevsent>
<prevsent>we are interested in the best possible technique for open ie.
</prevsent>
</prevsection>
<citsent citstr=" P08-1004 ">
the text runner open ie system (banko and etzioni, 2008) <papid> P08-1004 </papid>employs only shallow syntactic features in the extraction process.</citsent>
<aftsection>
<nextsent>avoiding the expensive processing of deep syntactic analysis allowed text runner to process at web scale.
</nextsent>
<nextsent>in this paper, we explore the benefits of semantic features and in particular, evaluate the application of semantic role labeling (srl) to open ie.srl is popular nlp task that has seen significant progress over the last few years.
</nextsent>
<nextsent>the advent of hand-constructed semantic resources such as propbank and framenet (martha and palmer, 2002;baker et al, 1998) <papid> P98-1013 </papid>have resulted in semantic role la belers achieving high in-domain precisions.</nextsent>
<nextsent>our first observation is that semantically labeled arguments in sentence almost always correspond to the arguments in open ie extractions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG697">
<title id=" W10-0907.xml">semantic role labeling for open information extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>avoiding the expensive processing of deep syntactic analysis allowed text runner to process at web scale.
</prevsent>
<prevsent>in this paper, we explore the benefits of semantic features and in particular, evaluate the application of semantic role labeling (srl) to open ie.srl is popular nlp task that has seen significant progress over the last few years.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
the advent of hand-constructed semantic resources such as propbank and framenet (martha and palmer, 2002;baker et al, 1998) <papid> P98-1013 </papid>have resulted in semantic role la belers achieving high in-domain precisions.</citsent>
<aftsection>
<nextsent>our first observation is that semantically labeled arguments in sentence almost always correspond to the arguments in open ie extractions.
</nextsent>
<nextsent>similarly, the verbs often match up with open ie relations.
</nextsent>
<nextsent>these observations lead us to construct new open ie extractor based on srl.
</nextsent>
<nextsent>we use uiucs publicly available srl system (punyakanok et al, 2008) <papid> J08-2005 </papid>that is known to be competitive with the state of the art and construct novel open ie extractor based on it called srl-ie.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG699">
<title id=" W10-0907.xml">semantic role labeling for open information extraction </title>
<section> srl-ie outperforms text runner along di-.  </section>
<citcontext>
<prevsection>
<prevsent>because not all roles feature in each verb the roles are commonly divided into meta-roles (a0-a7) and additional common classes such as location, time, etc. each ai can represent different role based on the verb, though a0 and a1 most often refer to agents and patients respectively.
</prevsent>
<prevsent>availability of lexical resources such as propbank (martha and palmer, 2002), which annotates text with meta-roles for each argument, has enabled significant progress in srl systems over the last few years.
</prevsent>
</prevsection>
<citsent citstr=" J08-2002 ">
recently, there have been many advances in srl (toutanova et al, 2008; <papid> J08-2002 </papid>johansson and nugues, 2008; <papid> C08-1050 </papid>coppola et al, 2009; <papid> N09-2022 </papid>moschitti et al, 2008).<papid> J08-2003 </papid>we use uiuc-srl as our base srl system (pun yakanok et al, 2008).<papid> J08-2005 </papid></citsent>
<aftsection>
<nextsent>our choice of the system is guided by the fact that its code is freely available and it is competitive with state of the art (it achieved the highest f1 score on the conll-2005 shared task).
</nextsent>
<nextsent>uiuc-srl operates in four key steps: pruning, argument identification, argument classification and 53 inference.
</nextsent>
<nextsent>pruning involves using full parse tree and heuristic rules to eliminate constituents that are unlikely to be arguments.
</nextsent>
<nextsent>argument identification uses classifier to identify constituents that are potential arguments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG700">
<title id=" W10-0907.xml">semantic role labeling for open information extraction </title>
<section> srl-ie outperforms text runner along di-.  </section>
<citcontext>
<prevsection>
<prevsent>because not all roles feature in each verb the roles are commonly divided into meta-roles (a0-a7) and additional common classes such as location, time, etc. each ai can represent different role based on the verb, though a0 and a1 most often refer to agents and patients respectively.
</prevsent>
<prevsent>availability of lexical resources such as propbank (martha and palmer, 2002), which annotates text with meta-roles for each argument, has enabled significant progress in srl systems over the last few years.
</prevsent>
</prevsection>
<citsent citstr=" C08-1050 ">
recently, there have been many advances in srl (toutanova et al, 2008; <papid> J08-2002 </papid>johansson and nugues, 2008; <papid> C08-1050 </papid>coppola et al, 2009; <papid> N09-2022 </papid>moschitti et al, 2008).<papid> J08-2003 </papid>we use uiuc-srl as our base srl system (pun yakanok et al, 2008).<papid> J08-2005 </papid></citsent>
<aftsection>
<nextsent>our choice of the system is guided by the fact that its code is freely available and it is competitive with state of the art (it achieved the highest f1 score on the conll-2005 shared task).
</nextsent>
<nextsent>uiuc-srl operates in four key steps: pruning, argument identification, argument classification and 53 inference.
</nextsent>
<nextsent>pruning involves using full parse tree and heuristic rules to eliminate constituents that are unlikely to be arguments.
</nextsent>
<nextsent>argument identification uses classifier to identify constituents that are potential arguments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG701">
<title id=" W10-0907.xml">semantic role labeling for open information extraction </title>
<section> srl-ie outperforms text runner along di-.  </section>
<citcontext>
<prevsection>
<prevsent>because not all roles feature in each verb the roles are commonly divided into meta-roles (a0-a7) and additional common classes such as location, time, etc. each ai can represent different role based on the verb, though a0 and a1 most often refer to agents and patients respectively.
</prevsent>
<prevsent>availability of lexical resources such as propbank (martha and palmer, 2002), which annotates text with meta-roles for each argument, has enabled significant progress in srl systems over the last few years.
</prevsent>
</prevsection>
<citsent citstr=" N09-2022 ">
recently, there have been many advances in srl (toutanova et al, 2008; <papid> J08-2002 </papid>johansson and nugues, 2008; <papid> C08-1050 </papid>coppola et al, 2009; <papid> N09-2022 </papid>moschitti et al, 2008).<papid> J08-2003 </papid>we use uiuc-srl as our base srl system (pun yakanok et al, 2008).<papid> J08-2005 </papid></citsent>
<aftsection>
<nextsent>our choice of the system is guided by the fact that its code is freely available and it is competitive with state of the art (it achieved the highest f1 score on the conll-2005 shared task).
</nextsent>
<nextsent>uiuc-srl operates in four key steps: pruning, argument identification, argument classification and 53 inference.
</nextsent>
<nextsent>pruning involves using full parse tree and heuristic rules to eliminate constituents that are unlikely to be arguments.
</nextsent>
<nextsent>argument identification uses classifier to identify constituents that are potential arguments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG702">
<title id=" W10-0907.xml">semantic role labeling for open information extraction </title>
<section> srl-ie outperforms text runner along di-.  </section>
<citcontext>
<prevsection>
<prevsent>because not all roles feature in each verb the roles are commonly divided into meta-roles (a0-a7) and additional common classes such as location, time, etc. each ai can represent different role based on the verb, though a0 and a1 most often refer to agents and patients respectively.
</prevsent>
<prevsent>availability of lexical resources such as propbank (martha and palmer, 2002), which annotates text with meta-roles for each argument, has enabled significant progress in srl systems over the last few years.
</prevsent>
</prevsection>
<citsent citstr=" J08-2003 ">
recently, there have been many advances in srl (toutanova et al, 2008; <papid> J08-2002 </papid>johansson and nugues, 2008; <papid> C08-1050 </papid>coppola et al, 2009; <papid> N09-2022 </papid>moschitti et al, 2008).<papid> J08-2003 </papid>we use uiuc-srl as our base srl system (pun yakanok et al, 2008).<papid> J08-2005 </papid></citsent>
<aftsection>
<nextsent>our choice of the system is guided by the fact that its code is freely available and it is competitive with state of the art (it achieved the highest f1 score on the conll-2005 shared task).
</nextsent>
<nextsent>uiuc-srl operates in four key steps: pruning, argument identification, argument classification and 53 inference.
</nextsent>
<nextsent>pruning involves using full parse tree and heuristic rules to eliminate constituents that are unlikely to be arguments.
</nextsent>
<nextsent>argument identification uses classifier to identify constituents that are potential arguments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG705">
<title id=" W10-0907.xml">semantic role labeling for open information extraction </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>another open ie system, kylin (weld et al, 2008), suggests automatically building an extractor for each relation using self-supervised training, with training data generated using wikipedia infoboxes.
</prevsent>
<prevsent>this work has the limitation that it can only extract relations expressed in wikipedia infoboxes.
</prevsent>
</prevsection>
<citsent citstr=" N06-1039 ">
a paradigm related to open ie is preemptive ie (shinyama and sekine, 2006).<papid> N06-1039 </papid></citsent>
<aftsection>
<nextsent>while one goal of preemptive ie is to avoid relation-specificity, preemptive ie does not emphasize web scala bility, which is essential to open ie.
</nextsent>
<nextsent>(carlson et al, 2009) <papid> W09-2201 </papid>presents semi-supervised approach to information extraction on the web.</nextsent>
<nextsent>it learns classifiers for different relations and couples the training of those classifiers with ontology defining constraints.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG706">
<title id=" W10-0907.xml">semantic role labeling for open information extraction </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>a paradigm related to open ie is preemptive ie (shinyama and sekine, 2006).<papid> N06-1039 </papid></prevsent>
<prevsent>while one goal of preemptive ie is to avoid relation-specificity, preemptive ie does not emphasize web scala bility, which is essential to open ie.</prevsent>
</prevsection>
<citsent citstr=" W09-2201 ">
(carlson et al, 2009) <papid> W09-2201 </papid>presents semi-supervised approach to information extraction on the web.</citsent>
<aftsection>
<nextsent>it learns classifiers for different relations and couples the training of those classifiers with ontology defining constraints.
</nextsent>
<nextsent>while we attempt to learn unknown relations, it learns pre-defined set of relations.
</nextsent>
<nextsent>another related system is wanderlust (akbikand bro?, 2009).
</nextsent>
<nextsent>the authors of this system annotated 10,000 sentences parsed with linkgrammar,resulting in 46 general link paths as patterns for relation extraction.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG707">
<title id=" W10-0907.xml">semantic role labeling for open information extraction </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>with these patterns wanderlust extracts binary relations from link grammar linkages.
</prevsent>
<prevsent>in contrast to our approaches, this requires large set of hand-labeled examples.
</prevsent>
</prevsection>
<citsent citstr=" D09-1001 ">
usp (poon and domingos, 2009) <papid> D09-1001 </papid>is based on markov logic networks and attempts to create full semantic parse in an unsupervised fashion.</citsent>
<aftsection>
<nextsent>they evaluate their work on biomedical text, so its applicability to general web text is not yet clear.
</nextsent>
<nextsent>the heavy tail: it is well accepted that information on the web is distributed according to zipfs 58 0 10 20 30 40 50 0.
</nextsent>
<nextsent>0 0.
</nextsent>
<nextsent>2 0.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG709">
<title id=" W10-1706.xml">an empirical study on development set selection strategy for machine translation learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>finally, ten groups of development sets are used to optimize the model weights, and this does help us obtain stable evaluation result.
</prevsent>
<prevsent>we present machine translation system that represents our participation for the wmt10 shared task from brain-like computing and machine intelligence lab of shanghai jiaotong university (sjtu-bcmi lab).
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
the system is based on the state-of-the-art smt toolkit moses (koehn et al, 2007).<papid> P07-2045 </papid></citsent>
<aftsection>
<nextsent>we use it to translate german, french and spanish into english.
</nextsent>
<nextsent>though different development sets used for training parameter tuning will certainly lead to quite different performance, we empirically find that the more sets we combine together, the more stable the performance is, and development set similar with test set will help the performance improvement.
</nextsent>
<nextsent>the basic model of the our system is log-linearmodel (och and ney, 2002).<papid> P02-1038 </papid></nextsent>
<nextsent>forgiven source lanthis work was partially supported by the national natural science foundation of china (grant no. 60903119, grant no. 60773090 and grant no. 90820018), the national basic research program of china (grant no. 2009cb320901), and the national high-tech research program of china (grant no.2008aa02z315).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG710">
<title id=" W10-1706.xml">an empirical study on development set selection strategy for machine translation learning </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>we use it to translate german, french and spanish into english.
</prevsent>
<prevsent>though different development sets used for training parameter tuning will certainly lead to quite different performance, we empirically find that the more sets we combine together, the more stable the performance is, and development set similar with test set will help the performance improvement.
</prevsent>
</prevsection>
<citsent citstr=" P02-1038 ">
the basic model of the our system is log-linearmodel (och and ney, 2002).<papid> P02-1038 </papid></citsent>
<aftsection>
<nextsent>forgiven source lanthis work was partially supported by the national natural science foundation of china (grant no. 60903119, grant no. 60773090 and grant no. 90820018), the national basic research program of china (grant no. 2009cb320901), and the national high-tech research program of china (grant no.2008aa02z315).
</nextsent>
<nextsent>corresponding author guage strings, the target language string will be obtained by the following equation, ti1 =argmaxti1 {pm1 (ti1 | sj1 )} =argmax ti1 { exp[ m=1 mhm(ti1, sj1 )]?
</nextsent>
<nextsent>ti1 exp[ m=1 mhm(ti1, sj1 )] }, where hm is the m-th feature function and is the m-th model weight.
</nextsent>
<nextsent>there are four main partsof features in the model: translation model, language model, reordering model and word penalty.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG711">
<title id=" W10-1706.xml">an empirical study on development set selection strategy for machine translation learning </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>we used the larger set for our primary submission.
</prevsent>
<prevsent>we adopt word alignment toolkit giza++ (och and ney, 2003) to learn word-level alignment withits default setting and grow-diag-final-and parameters.
</prevsent>
</prevsection>
<citsent citstr=" J04-4002 ">
given sentence pair and its corresponding word-level alignment, phrases will be extracted by using the approach in (och and ney, 2004).<papid> J04-4002 </papid></citsent>
<aftsection>
<nextsent>phrase probability is estimated by its relative frequency in the training corpus.
</nextsent>
<nextsent>lexical reordering is determined by using the default setting of moses with msd-bidirectional parameter.
</nextsent>
<nextsent>for training the only language model (english), the datasets are extracted from monolingual parts of both europarl-v5 and news-commentary10, 67 sentences words(s) words(t) de small 1540549 35.76m 38.53m large 1640818 37.95m 40.64m fr small 1683156 44.02m 44.20m large 8997997 251.60m 228.50m es small 1650152 43.17m 41.25m large 7971200 236.24m 207.79mtable 1: bilingual training corpora from ger man(de), french(fr) and spanish(es) to english.
</nextsent>
<nextsent>which include 1968914 sentences and 47.48mwords.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG712">
<title id=" W10-1706.xml">an empirical study on development set selection strategy for machine translation learning </title>
<section> development set selection.  </section>
<citcontext>
<prevsection>
<prevsent>3.1 motivation.
</prevsent>
<prevsent>given the previous feature functions, the model weights will be obtained by optimizing the following maximum mutual information criterion, which can be derived from the maximum entropy princi ple: m1 = argmaxm1 { s?
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
i=1 log pm1 (ti | si)} as usual, minimum error rate training (mert) is adopted for log-linear model parameter estimation (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>there are many improvements onmert in existing work (bertoldi et al, 2009; foster and kuhn, 2009), <papid> W09-0439 </papid>but there is no demonstration that the weights with better performance on the development set would lead to better result on the unseen test set.</nextsent>
<nextsent>in our experiments, we found that different development sets will cause significant bleu score differences, even as high as one percent.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG713">
<title id=" W10-1706.xml">an empirical study on development set selection strategy for machine translation learning </title>
<section> development set selection.  </section>
<citcontext>
<prevsection>
<prevsent>given the previous feature functions, the model weights will be obtained by optimizing the following maximum mutual information criterion, which can be derived from the maximum entropy princi ple: m1 = argmaxm1 { s?
</prevsent>
<prevsent>i=1 log pm1 (ti | si)} as usual, minimum error rate training (mert) is adopted for log-linear model parameter estimation (och, 2003).<papid> P03-1021 </papid></prevsent>
</prevsection>
<citsent citstr=" W09-0439 ">
there are many improvements onmert in existing work (bertoldi et al, 2009; foster and kuhn, 2009), <papid> W09-0439 </papid>but there is no demonstration that the weights with better performance on the development set would lead to better result on the unseen test set.</citsent>
<aftsection>
<nextsent>in our experiments, we found that different development sets will cause significant bleu score differences, even as high as one percent.
</nextsent>
<nextsent>thus the remained problem will be how to effectively choose the development set to obtain better and more stable performance.
</nextsent>
<nextsent>3.2 experimental settings.
</nextsent>
<nextsent>our empirical study will be demonstrated through german to english translation on the smaller corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG714">
<title id=" W10-1706.xml">an empirical study on development set selection strategy for machine translation learning </title>
<section> development set selection.  </section>
<citcontext>
<prevsection>
<prevsent>3.6 related work.
</prevsent>
<prevsent>the special challenge of the wmt shared task is domain adaptation, which is hot topic in recent years and more relative to our experiments.
</prevsent>
</prevsection>
<citsent citstr=" W07-0733 ">
many existing works are about this topic (koehn and schroeder, 2007; <papid> W07-0733 </papid>nakov, 2008; <papid> W08-0320 </papid>nakov and ng,2009; paul et al, 2009; haque et al, 2009).</citsent>
<aftsection>
<nextsent>how ever, most of previous works focus on language 69 model, translation phrase table, lexicons model and factored translation model, few of them pay attention to the domain adaptation on the development set.
</nextsent>
<nextsent>for future work we consider to use some machine learning approaches to select sentences in development sets more relevant with the test set in order to further improve translation performance.
</nextsent>
<nextsent>in this paper, we present our machine translation system for the wmt10 shared task and perform an empirical study on the development set selection.
</nextsent>
<nextsent>according to our experimental results, choosing different development sets would play an important role for translation performance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG715">
<title id=" W10-1706.xml">an empirical study on development set selection strategy for machine translation learning </title>
<section> development set selection.  </section>
<citcontext>
<prevsection>
<prevsent>3.6 related work.
</prevsent>
<prevsent>the special challenge of the wmt shared task is domain adaptation, which is hot topic in recent years and more relative to our experiments.
</prevsent>
</prevsection>
<citsent citstr=" W08-0320 ">
many existing works are about this topic (koehn and schroeder, 2007; <papid> W07-0733 </papid>nakov, 2008; <papid> W08-0320 </papid>nakov and ng,2009; paul et al, 2009; haque et al, 2009).</citsent>
<aftsection>
<nextsent>how ever, most of previous works focus on language 69 model, translation phrase table, lexicons model and factored translation model, few of them pay attention to the domain adaptation on the development set.
</nextsent>
<nextsent>for future work we consider to use some machine learning approaches to select sentences in development sets more relevant with the test set in order to further improve translation performance.
</nextsent>
<nextsent>in this paper, we present our machine translation system for the wmt10 shared task and perform an empirical study on the development set selection.
</nextsent>
<nextsent>according to our experimental results, choosing different development sets would play an important role for translation performance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG716">
<title id=" W10-1904.xml">scaling up biomedical event extraction to the entire pubmed </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there has recently been substantial interest in event models in biomedical information extraction (ie).
</prevsent>
<prevsent>the expressive event representation captures extracted knowledge as structured, recursively nested, typed associations of arbitrarily many participants in specific roles.
</prevsent>
</prevsection>
<citsent citstr=" W09-1401 ">
the bionlp09 shared task on event extraction (kim et al, 2009), <papid> W09-1401 </papid>the first large scale evaluation of biomedical event extraction systems, drew the participation of 24groups and established standard event representation scheme and datasets.</citsent>
<aftsection>
<nextsent>the training and test data of the shared task comprised 13,623 manually annotated events in 1,210 pubmed citation abstracts, and on this data the top performing system of bjorne et al (2009), bjorne et al (2010b) achieved an overall f-score of 51.95% (kim et al, 2009).<papid> W09-1401 </papid></nextsent>
<nextsent>equal contribution by first three authors.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG718">
<title id=" W10-1904.xml">scaling up biomedical event extraction to the entire pubmed </title>
<section> event extraction.  </section>
<citcontext>
<prevsection>
<prevsent>the process is illustrated in figure 1.for named entity recognition, we use the banner system of leaman and gonzales (2008), which in its current release achieves results close to the best published on the standard genetagdataset and was reported to have the best performance in recent study comparing publicly available taggers (kabiljo et al, 2009).
</prevsent>
<prevsent>titles and abstracts of all 17.8m citations in the 2009 distribution of pubmed are processed through the banner system.
</prevsent>
</prevsection>
<citsent citstr=" W03-1018 ">
titles and abstracts of pubmed citations in which at least one named entity was identified, and 29 which therefore contain possible target for event extraction, are subsequently split into sentences using maximum-entropy based sentence splitter trained on the genia corpus (kazama and tsujii, 2003) <papid> W03-1018 </papid>with limited rule-based post-processing for some common errors.</citsent>
<aftsection>
<nextsent>all sentences containing at least one named entity are then parsed with the domain-adaptedmcclosky-charniak parser (mcclosky and charniak, 2008; <papid> P08-2026 </papid>mcclosky, 2009), which has achieved the currently best published performance on the genia treebank (tateisi et al, 2005).<papid> I05-2038 </papid></nextsent>
<nextsent>the constituency parse trees are then transformed to thecollapsed-ccprocessed variant of the stanford dependency scheme using the conversion tool2 introduced by de marneffe et al (2006).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG719">
<title id=" W10-1904.xml">scaling up biomedical event extraction to the entire pubmed </title>
<section> event extraction.  </section>
<citcontext>
<prevsection>
<prevsent>titles and abstracts of all 17.8m citations in the 2009 distribution of pubmed are processed through the banner system.
</prevsent>
<prevsent>titles and abstracts of pubmed citations in which at least one named entity was identified, and 29 which therefore contain possible target for event extraction, are subsequently split into sentences using maximum-entropy based sentence splitter trained on the genia corpus (kazama and tsujii, 2003) <papid> W03-1018 </papid>with limited rule-based post-processing for some common errors.</prevsent>
</prevsection>
<citsent citstr=" P08-2026 ">
all sentences containing at least one named entity are then parsed with the domain-adaptedmcclosky-charniak parser (mcclosky and charniak, 2008; <papid> P08-2026 </papid>mcclosky, 2009), which has achieved the currently best published performance on the genia treebank (tateisi et al, 2005).<papid> I05-2038 </papid></citsent>
<aftsection>
<nextsent>the constituency parse trees are then transformed to thecollapsed-ccprocessed variant of the stanford dependency scheme using the conversion tool2 introduced by de marneffe et al (2006).
</nextsent>
<nextsent>finally, events are extracted using the turku event extraction system of bjorne et al which achieved the best performance in the bionlp09 shared task and remains fully competitive with even the most recent advances (miwa et al, 2010).
</nextsent>
<nextsent>we use recent publicly available revision of the event extraction system that performs also extraction of shared task subtask 2 and 3 information, providing additional event arguments relevant to event sites and localization (site, atloc, and tolocrole types in the shared task) as well as information on event polarity and certainty (bjorne et al, 2010b).
</nextsent>
<nextsent>2.2 extraction result and computational.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG720">
<title id=" W10-1904.xml">scaling up biomedical event extraction to the entire pubmed </title>
<section> event extraction.  </section>
<citcontext>
<prevsection>
<prevsent>titles and abstracts of all 17.8m citations in the 2009 distribution of pubmed are processed through the banner system.
</prevsent>
<prevsent>titles and abstracts of pubmed citations in which at least one named entity was identified, and 29 which therefore contain possible target for event extraction, are subsequently split into sentences using maximum-entropy based sentence splitter trained on the genia corpus (kazama and tsujii, 2003) <papid> W03-1018 </papid>with limited rule-based post-processing for some common errors.</prevsent>
</prevsection>
<citsent citstr=" I05-2038 ">
all sentences containing at least one named entity are then parsed with the domain-adaptedmcclosky-charniak parser (mcclosky and charniak, 2008; <papid> P08-2026 </papid>mcclosky, 2009), which has achieved the currently best published performance on the genia treebank (tateisi et al, 2005).<papid> I05-2038 </papid></citsent>
<aftsection>
<nextsent>the constituency parse trees are then transformed to thecollapsed-ccprocessed variant of the stanford dependency scheme using the conversion tool2 introduced by de marneffe et al (2006).
</nextsent>
<nextsent>finally, events are extracted using the turku event extraction system of bjorne et al which achieved the best performance in the bionlp09 shared task and remains fully competitive with even the most recent advances (miwa et al, 2010).
</nextsent>
<nextsent>we use recent publicly available revision of the event extraction system that performs also extraction of shared task subtask 2 and 3 information, providing additional event arguments relevant to event sites and localization (site, atloc, and tolocrole types in the shared task) as well as information on event polarity and certainty (bjorne et al, 2010b).
</nextsent>
<nextsent>2.2 extraction result and computational.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG721">
<title id=" W10-1904.xml">scaling up biomedical event extraction to the entire pubmed </title>
<section> term-ne mapping.  </section>
<citcontext>
<prevsection>
<prevsent>in the rest of this paper, we turn our attention to the extraction result.
</prevsent>
<prevsent>as the event types are drawn from the gene ontology and the original data on which the system is trained has been annotated with reference to thego definitions, the events targeted by the extraction system have well-defined biological interpretations.
</prevsent>
</prevsection>
<citsent citstr=" W09-1313 ">
the meaning of complete event structures depends also on the participating entities,which are in the primary event extraction task constrained to be of gene/gene product (ggp) types, as annotated in the genia ggp corpus (ohta et al., 2009<papid> W09-1313 </papid>a).</citsent>
<aftsection>
<nextsent>the simple and uniform nature of these entities makes the interpretation of complete events straightforward.however, the semantics of the entities automatically tagged in this work are somewhat more openly defined.
</nextsent>
<nextsent>the banner system was trained on the genetag corpus, annotated forgene/protein entities?
</nextsent>
<nextsent>without differentiating between different entity types and marking entities under broad definition that not only includes genes and gene products but also related entities such as gene promoters and protein complexes, only requiring that the tagged entities be specific (tanabe et al, 2005).
</nextsent>
<nextsent>the annotation criteria of the entities used to train the banner system as well as the event extraction system also differ in the extent of the marked spans, with genia ggp marking the minimal name and genetag allowing also the inclusion of head nouns when name occurs in modifier position.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG722">
<title id=" W10-1904.xml">scaling up biomedical event extraction to the entire pubmed </title>
<section> term-ne mapping.  </section>
<citcontext>
<prevsection>
<prevsent>the first challenge, gene/protein name normalization, is well studied task in biomedical nlp for which number of systems with promising performance have been proposed (morgan and hirschman, 2007).the second we believe to be novel.
</prevsent>
<prevsent>in the following, we propose method for resolving this task.we base the decision on how to map events referencing broadly defined terms to ones referencing associated gene/protein names in part on recently introduced dataset of static relations?
</prevsent>
</prevsection>
<citsent citstr=" W09-1301 ">
(pyysalo et al., 2009) <papid> W09-1301 </papid>between named entities and terms (ohta et al, 2009<papid> W09-1313 </papid>b).</citsent>
<aftsection>
<nextsent>this dataset was created based on approximately 10,000 cases where ggp nes, as annotated in the genia ggp corpus (ohta et al, 2009<papid> W09-1313 </papid>a), were embedded in terms, as annotated in the genia term corpus (ohta et al, 2002).</nextsent>
<nextsent>for each such case, the relation between the ne and the term was annotated using set of introduced relation types whose granularity was defined with reference to mesh terms (see table 2, ohta et al, 2009<papid> W09-1313 </papid>b).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG734">
<title id=" W10-0914.xml">supporting rule based representations with corpus derived lexical information </title>
<section> which elements in the sentence.  </section>
<citcontext>
<prevsection>
<prevsent>the question then becomes whether we can find reasoning patterns that are general enough to give interesting results.
</prevsent>
<prevsent>5whereas it is possible to enumerate an extensive partof the relevant vocabulary, there is no extensive description of meaning contribution of these elements.
</prevsent>
</prevsection>
<citsent citstr=" D09-1001 ">
the third method, already demonstrated in the context of semantic parsing (poon and domingos, 2009), <papid> D09-1001 </papid>seems also to be promising.</citsent>
<aftsection>
<nextsent>for instance, even staying within the class of movement verbs, different verbs have different signatures that might help us with the classification of their subjects and their from-to arguments.
</nextsent>
<nextsent>while go?
</nextsent>
<nextsent>has indeed the wide range of meanings that we expected, run?
</nextsent>
<nextsent>is rather dif ferent: apart from three examples where run?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG735">
<title id=" W10-1407.xml">direct parsing of discontinuous constituents in german </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in (2), the discontinuity is caused by top icalization.
</prevsent>
<prevsent>(2) himikali1 pens1 az kupuvam buy samo only evtini expensive t1 t1 as for pens, only buy expensive ones.in most constituency treebanks, sentence annotation is restricted to having the shape of trees without crossing branches, and the non-local dependencies induced by the discontinuities are modeled by an additional mechanism.
</prevsent>
</prevsection>
<citsent citstr=" H94-1020 ">
in the penn treebank (ptb) (marcus et al , 1994), <papid> H94-1020 </papid>e.g., this mechanism is combination of special labels and empty nodes,establishing implicit additional edges.</citsent>
<aftsection>
<nextsent>in the german tuba-d/z (telljohann et al , 2006), additional edges are established by combination of topolog ical field annotation and special edge labels.
</nextsent>
<nextsent>as an example, fig.
</nextsent>
<nextsent>1 shows tree from tuba-d/z withthe annotation of (1).
</nextsent>
<nextsent>note here the edge label on mod on the relative clause which indicates that the subject of the sentence (alle attribute) is modified.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG736">
<title id=" W10-1407.xml">direct parsing of discontinuous constituents in german </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>1 shows tree from tuba-d/z withthe annotation of (1).
</prevsent>
<prevsent>note here the edge label on mod on the relative clause which indicates that the subject of the sentence (alle attribute) is modified.
</prevsent>
</prevsection>
<citsent citstr=" A97-1014 ">
figure 1: tree from tuba-d/z however, in few other treebanks, such as the german negra and tiger treebanks (skut et al ,1997; <papid> A97-1014 </papid>brants et al , 2002), crossing branches areal lowed.</citsent>
<aftsection>
<nextsent>this way, all dependents of long-distance dependency can be grouped under single node.
</nextsent>
<nextsent>58 fig.
</nextsent>
<nextsent>2 shows tree from negra with the annotation of (3).
</nextsent>
<nextsent>(3) noch yet nie never habe have ich so so viel much gewahlt chosen never have had that much choice.?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG737">
<title id=" W10-1407.xml">direct parsing of discontinuous constituents in german </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>mo hd avp mo hd avp mo mo hd vp ochd sb figure 2: tree from negra since in general, the annotation mechanisms for non-local dependencies lie beyond the expressivity of context-free grammar, non-local information is inaccessible for pcfg parsing and therefore generally discarded.
</prevsent>
<prevsent>in negra/tiger annotation, e.g., tree transformation algorithms are applied before parsing in order to resolve the crossing branches.
</prevsent>
</prevsection>
<citsent citstr=" W07-1506 ">
see, e.g., kubler et al  (2008) and boyd (2007) <papid> W07-1506 </papid>for details.</citsent>
<aftsection>
<nextsent>if one wants to avoid the loss of annotation information which is implied with such transformations, one possibility is to use probabilistic parser for formalism which is more expressive than cfg.in this paper, we tackle the question if qualitatively good results can be achieved when parsing german with such parser.
</nextsent>
<nextsent>concretely, we use aparser for probabilistic linear context-free rewriting systems (plcfrs) (kallmeyer and maier, 2010).
</nextsent>
<nextsent>lcfrs (vijay-shanker et al , 1987) are anat ural extension of cfg in which single nonterminal node can dominate more than one continuous span of terminals.
</nextsent>
<nextsent>we can directly interpret negra-style trees as its derivation structures, i.e., wecan extract grammars without making further linguistic assumptions (maier and lichte, 2009) (see sect.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG738">
<title id=" W10-1407.xml">direct parsing of discontinuous constituents in german </title>
<section> a parser for plcfrs </section>
<citcontext>
<prevsection>
<prevsent>goal: [s, 0, n??]
</prevsent>
<prevsent>figure 3: weighted cyk deduction system 2.2 cyk parser for plcfrs we use the parser of kallmeyer and maier (2010).
</prevsent>
</prevsection>
<citsent citstr=" J03-1006 ">
it is probabilistic cyk parser (seki et al , 1991), using the technique of weighted deductive parsing (nederhof, 2003).<papid> J03-1006 </papid></citsent>
<aftsection>
<nextsent>while for symbolic parsing, other elaborate algorithms exist (kallmeyer and maier, 2009), <papid> W09-3808 </papid>for probabilistic parsing, cyk is natural choice.</nextsent>
<nextsent>it is assumed for the parser that our lcfrss are of rank 2 and do not contain rules where some of the lhs components are ?.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG739">
<title id=" W10-1407.xml">direct parsing of discontinuous constituents in german </title>
<section> a parser for plcfrs </section>
<citcontext>
<prevsection>
<prevsent>figure 3: weighted cyk deduction system 2.2 cyk parser for plcfrs we use the parser of kallmeyer and maier (2010).
</prevsent>
<prevsent>it is probabilistic cyk parser (seki et al , 1991), using the technique of weighted deductive parsing (nederhof, 2003).<papid> J03-1006 </papid></prevsent>
</prevsection>
<citsent citstr=" W09-3808 ">
while for symbolic parsing, other elaborate algorithms exist (kallmeyer and maier, 2009), <papid> W09-3808 </papid>for probabilistic parsing, cyk is natural choice.</citsent>
<aftsection>
<nextsent>it is assumed for the parser that our lcfrss are of rank 2 and do not contain rules where some of the lhs components are ?.
</nextsent>
<nextsent>both assumptions can be made without loss of generality since every lcfrs can be binarized (gomez-rodrguez et al , 2009) and ?-components on lhs of rules can be removed (boullier, 1998).
</nextsent>
<nextsent>we make the assumption that pos tagging is done before parsing.
</nextsent>
<nextsent>the pos tags are special non-terminals of fan-out 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG740">
<title id=" W10-1407.xml">direct parsing of discontinuous constituents in german </title>
<section> a parser for plcfrs </section>
<citcontext>
<prevsection>
<prevsent>a vector of ranges characterizing all components of the span of a. we specify the set of weighted parse items via the deduction rules in fig.
</prevsent>
<prevsent>3.
</prevsent>
</prevsection>
<citsent citstr=" N03-1016 ">
parsing time can be reduced by reordering the agenda during parsing such that those items are processed first which lead to complete parse more quickly than others (klein and manning, 2003<papid> N03-1016 </papid>a).</citsent>
<aftsection>
<nextsent>the parser uses for this purpose an admissible, but not monotonic estimate called lr estimate.
</nextsent>
<nextsent>it gives(relative to sentence length) an estimate of the out side probability of some non-terminal with span of certain length (the sum of the lengths of all the 60components of the span), certain number of terminals to the left of the first and to the right of the last component and certain number of terminals gaps in between the components of the span, i.e., filling the gaps.
</nextsent>
<nextsent>a discussion of other estimates is presented at length in kallmeyer and maier (2010).
</nextsent>
<nextsent>2.3 lcfrs for modeling discontinuities.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG744">
<title id=" W10-1407.xml">direct parsing of discontinuous constituents in german </title>
<section> evaluation methods.  </section>
<citcontext>
<prevsection>
<prevsent>using these tuple sets, we compute labeled and unlabeled recall (lr/ur), precision (lp/up), and the f1 measure (lf1/uf1) in the usual way.
</prevsent>
<prevsent>note that if = 1, our metric is identical to its pcfg version.
</prevsent>
</prevsection>
<citsent citstr=" L08-1383 ">
evalb does not necessarily reflect parser output quality (rehbein and van genabith, 2007; emms,2008; <papid> L08-1383 </papid>kubler et al , 2008).</citsent>
<aftsection>
<nextsent>one of its major problems is that attachment errors are penalized toohard.
</nextsent>
<nextsent>as the second evaluation method, we therefore choose the tree-distance measure (henceforth tdist) (zhang and shasha, 1989), which levitatesthis problem.
</nextsent>
<nextsent>it has been proposed for parser evaluation by emms (2008).<papid> L08-1383 </papid></nextsent>
<nextsent>tdist is an ideal candidate for evaluation of the output of plcfrs, since it thefact if trees have crossing branches or not is not relevant to it.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG749">
<title id=" W10-1407.xml">direct parsing of discontinuous constituents in german </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>our tiger datasets (tiger and t-cf) have 31,568 sentences of an average length of 14.81, split ted into 31,568sentences for training and 3,508 sentences for testing.
</prevsent>
<prevsent>our negra datasets (negra and n-cf) have 18,335 sentences, split ted into 16,501 sentences for training and 1,834 sentences for testing.we parse the datasets described above with activated lr estimate.
</prevsent>
</prevsection>
<citsent citstr=" W08-1006 ">
for all our experiments, we use the markov ization settings = 2 and = 1, which have proven to be successful in previous work on parsing negra (rafferty and manning, 2008).<papid> W08-1006 </papid></citsent>
<aftsection>
<nextsent>we provide the parser with the gold tagging.
</nextsent>
<nextsent>fig.
</nextsent>
<nextsent>6 shows the average parsing times for all datasets on an amd opteron node with 8gb of ram (pure java implementation), tab.
</nextsent>
<nextsent>1 shows the percentage of parsed sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG750">
<title id=" W10-1407.xml">direct parsing of discontinuous constituents in german </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>all of them were obtained using pcfg parsers: kubler (2005) (tab.
</prevsent>
<prevsent>1, plain pcfg for negra), kubler et al  (2008) (tab.
</prevsent>
</prevsection>
<citsent citstr=" N07-1051 ">
3, plain pcfg and stanford parser with markov ization = 2 and = 1 for tiger), and petrov and klein (2007) (<papid> N07-1051 </papid>tab.</citsent>
<aftsection>
<nextsent>1, berkeley parser, latent variables).
</nextsent>
<nextsent>we include the results for n-cf and t-cf.
</nextsent>
<nextsent>our results are slightly better than for the plain pcfg models.
</nextsent>
<nextsent>we would expect the result for cf to be closer to the corresponding result for the stanford parser, since we are using comparable 63 plain this work markov.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG754">
<title id=" W10-1407.xml">direct parsing of discontinuous constituents in german </title>
<section> conclusion and future work.  </section>
<citcontext>
<prevsection>
<prevsent>in order to do this, we will parse our datasets with current state-of-the-art systems.
</prevsent>
<prevsent>especially more elaborate dependency conversion should enable more informative comparison between the output of pcfg parsers and the output of the plcfrs parser.
</prevsent>
</prevsection>
<citsent citstr=" E09-1055 ">
last, since an algorithm is available which extracts lcfrss from dependency structures (kuhlmann and satta, 2009), <papid> E09-1055 </papid>the parser is instantly ready for parsing them.</citsent>
<aftsection>
<nextsent>we are currently performing the corresponding experiments.
</nextsent>
<nextsent>65
</nextsent>


</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG755">
<title id=" W10-1820.xml">building the syntactic reference corpus of medieval french using notabene rdf annotation tool </title>
<section> introducing the srcmf project.  </section>
<citcontext>
<prevsection>
<prevsent>1.1 main goals.
</prevsent>
<prevsent>there currently exists no widely available syntactically annotated corpus for medieval french.
</prevsent>
</prevsection>
<citsent citstr=" L08-1446 ">
several syntactic corpora are available for latin11the latin dependency treebank and the index thomisti cus treebank (bamman et al, 2008).<papid> L08-1446 </papid>or old portuguese.2 research for automatic annotation of medieval french is being carried out by the modliser le changement: les voies du franais project.3 srcmf is an international initiative, gathering french (dir.</citsent>
<aftsection>
<nextsent>sophie prvost, cnrs, paris) and german (dir.
</nextsent>
<nextsent>achim stein, institut fr linguis tik/romanistik, university of stuttgart) resources and teams.
</nextsent>
<nextsent>the aim of this project is to provide selected excerpts4 of the two biggest medieval french corpora ? the base de franais mdival (guillot et al, 2007), and the nouveau corpus damsterdam (kunstmann and stein, 2007a) with syntactic annotation layer that is meant to follow the same guidelines in both corpora.
</nextsent>
<nextsent>it was decided at the very beginning of the project that, at first, the syntactic analysis would be manually added to the corpus by experts, rather than automatically inserted by an automaton.5.accordingly, annotation layers that previously exist are not used to elaborate the new layer.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG756">
<title id=" W10-1205.xml">capturing the stars predicting ratings for service and product reviews </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, restaurant might receive an overall great evaluation, while the service mightbe rated below average due to slow and discourteous wait staff.
</prevsent>
<prevsent>pinpointing opinions in documents, and the entities being referenced, would provide afinergrained sentiment analysis and solid foundation to automatically summarize evaluative text, but such task becomes even more challenging when applied to generic domain and with unsupervised methods.
</prevsent>
</prevsection>
<citsent citstr=" H05-1043 ">
some significant contributions by hu and liu (2004), popescu and etzioni (2005),<papid> H05-1043 </papid>and carenini et al (2006) illustrate different techniques to find and measure opinion orientation in text documents.</citsent>
<aftsection>
<nextsent>other work in sentiment analysis(often referred as opinion mining) has explored several facets of the problem, ranging from predicting binary ratings (e.g., thumbs up/down) (turney, 2002;pang et al, 2002; <papid> W02-1011 </papid>dave et al, 2003; yu and hatzivassiloglou, 2003; pang and lee, 2004; <papid> P04-1035 </papid>yi and niblack,2005; carenini et al, 2006), to more detailed opinion analysis methods predicting multi scale ratings(e.g., number of stars) (pang and lee, 2005; <papid> P05-1015 </papid>snyder and barzilay, 2007; shimada and endo, 2008; okanohara and tsujii, 2005).<papid> I05-1028 </papid></nextsent>
<nextsent>this paper focuses on multi scale multi aspect rating prediction for textual reviews.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG757">
<title id=" W10-1205.xml">capturing the stars predicting ratings for service and product reviews </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>pinpointing opinions in documents, and the entities being referenced, would provide afinergrained sentiment analysis and solid foundation to automatically summarize evaluative text, but such task becomes even more challenging when applied to generic domain and with unsupervised methods.
</prevsent>
<prevsent>some significant contributions by hu and liu (2004), popescu and etzioni (2005),<papid> H05-1043 </papid>and carenini et al (2006) illustrate different techniques to find and measure opinion orientation in text documents.</prevsent>
</prevsection>
<citsent citstr=" W02-1011 ">
other work in sentiment analysis(often referred as opinion mining) has explored several facets of the problem, ranging from predicting binary ratings (e.g., thumbs up/down) (turney, 2002;pang et al, 2002; <papid> W02-1011 </papid>dave et al, 2003; yu and hatzivassiloglou, 2003; pang and lee, 2004; <papid> P04-1035 </papid>yi and niblack,2005; carenini et al, 2006), to more detailed opinion analysis methods predicting multi scale ratings(e.g., number of stars) (pang and lee, 2005; <papid> P05-1015 </papid>snyder and barzilay, 2007; shimada and endo, 2008; okanohara and tsujii, 2005).<papid> I05-1028 </papid></citsent>
<aftsection>
<nextsent>this paper focuses on multi scale multi aspect rating prediction for textual reviews.
</nextsent>
<nextsent>as mentioned before, textual reviews are abundant, but when trying to make buy decision on specific produc tor service, getting sufficient and reliable information can be daunting and time consuming task.on one hand, single overall rating does not provide enough information and could be unreliable, if not supported over large number of independent reviews/ratings.
</nextsent>
<nextsent>from another standpoint, reading through large number of textual reviews in orderto infer the aspect ratings could be quite time con 36 suming, and, at the same time, the outcome of the evaluation could be biased by the readers interpretation.
</nextsent>
<nextsent>in this work, instead of single overall rating, we propose to provide ratings for multiple aspects of the product/service.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG759">
<title id=" W10-1205.xml">capturing the stars predicting ratings for service and product reviews </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>pinpointing opinions in documents, and the entities being referenced, would provide afinergrained sentiment analysis and solid foundation to automatically summarize evaluative text, but such task becomes even more challenging when applied to generic domain and with unsupervised methods.
</prevsent>
<prevsent>some significant contributions by hu and liu (2004), popescu and etzioni (2005),<papid> H05-1043 </papid>and carenini et al (2006) illustrate different techniques to find and measure opinion orientation in text documents.</prevsent>
</prevsection>
<citsent citstr=" P04-1035 ">
other work in sentiment analysis(often referred as opinion mining) has explored several facets of the problem, ranging from predicting binary ratings (e.g., thumbs up/down) (turney, 2002;pang et al, 2002; <papid> W02-1011 </papid>dave et al, 2003; yu and hatzivassiloglou, 2003; pang and lee, 2004; <papid> P04-1035 </papid>yi and niblack,2005; carenini et al, 2006), to more detailed opinion analysis methods predicting multi scale ratings(e.g., number of stars) (pang and lee, 2005; <papid> P05-1015 </papid>snyder and barzilay, 2007; shimada and endo, 2008; okanohara and tsujii, 2005).<papid> I05-1028 </papid></citsent>
<aftsection>
<nextsent>this paper focuses on multi scale multi aspect rating prediction for textual reviews.
</nextsent>
<nextsent>as mentioned before, textual reviews are abundant, but when trying to make buy decision on specific produc tor service, getting sufficient and reliable information can be daunting and time consuming task.on one hand, single overall rating does not provide enough information and could be unreliable, if not supported over large number of independent reviews/ratings.
</nextsent>
<nextsent>from another standpoint, reading through large number of textual reviews in orderto infer the aspect ratings could be quite time con 36 suming, and, at the same time, the outcome of the evaluation could be biased by the readers interpretation.
</nextsent>
<nextsent>in this work, instead of single overall rating, we propose to provide ratings for multiple aspects of the product/service.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG761">
<title id=" W10-1205.xml">capturing the stars predicting ratings for service and product reviews </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>pinpointing opinions in documents, and the entities being referenced, would provide afinergrained sentiment analysis and solid foundation to automatically summarize evaluative text, but such task becomes even more challenging when applied to generic domain and with unsupervised methods.
</prevsent>
<prevsent>some significant contributions by hu and liu (2004), popescu and etzioni (2005),<papid> H05-1043 </papid>and carenini et al (2006) illustrate different techniques to find and measure opinion orientation in text documents.</prevsent>
</prevsection>
<citsent citstr=" P05-1015 ">
other work in sentiment analysis(often referred as opinion mining) has explored several facets of the problem, ranging from predicting binary ratings (e.g., thumbs up/down) (turney, 2002;pang et al, 2002; <papid> W02-1011 </papid>dave et al, 2003; yu and hatzivassiloglou, 2003; pang and lee, 2004; <papid> P04-1035 </papid>yi and niblack,2005; carenini et al, 2006), to more detailed opinion analysis methods predicting multi scale ratings(e.g., number of stars) (pang and lee, 2005; <papid> P05-1015 </papid>snyder and barzilay, 2007; shimada and endo, 2008; okanohara and tsujii, 2005).<papid> I05-1028 </papid></citsent>
<aftsection>
<nextsent>this paper focuses on multi scale multi aspect rating prediction for textual reviews.
</nextsent>
<nextsent>as mentioned before, textual reviews are abundant, but when trying to make buy decision on specific produc tor service, getting sufficient and reliable information can be daunting and time consuming task.on one hand, single overall rating does not provide enough information and could be unreliable, if not supported over large number of independent reviews/ratings.
</nextsent>
<nextsent>from another standpoint, reading through large number of textual reviews in orderto infer the aspect ratings could be quite time con 36 suming, and, at the same time, the outcome of the evaluation could be biased by the readers interpretation.
</nextsent>
<nextsent>in this work, instead of single overall rating, we propose to provide ratings for multiple aspects of the product/service.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG762">
<title id=" W10-1205.xml">capturing the stars predicting ratings for service and product reviews </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>pinpointing opinions in documents, and the entities being referenced, would provide afinergrained sentiment analysis and solid foundation to automatically summarize evaluative text, but such task becomes even more challenging when applied to generic domain and with unsupervised methods.
</prevsent>
<prevsent>some significant contributions by hu and liu (2004), popescu and etzioni (2005),<papid> H05-1043 </papid>and carenini et al (2006) illustrate different techniques to find and measure opinion orientation in text documents.</prevsent>
</prevsection>
<citsent citstr=" I05-1028 ">
other work in sentiment analysis(often referred as opinion mining) has explored several facets of the problem, ranging from predicting binary ratings (e.g., thumbs up/down) (turney, 2002;pang et al, 2002; <papid> W02-1011 </papid>dave et al, 2003; yu and hatzivassiloglou, 2003; pang and lee, 2004; <papid> P04-1035 </papid>yi and niblack,2005; carenini et al, 2006), to more detailed opinion analysis methods predicting multi scale ratings(e.g., number of stars) (pang and lee, 2005; <papid> P05-1015 </papid>snyder and barzilay, 2007; shimada and endo, 2008; okanohara and tsujii, 2005).<papid> I05-1028 </papid></citsent>
<aftsection>
<nextsent>this paper focuses on multi scale multi aspect rating prediction for textual reviews.
</nextsent>
<nextsent>as mentioned before, textual reviews are abundant, but when trying to make buy decision on specific produc tor service, getting sufficient and reliable information can be daunting and time consuming task.on one hand, single overall rating does not provide enough information and could be unreliable, if not supported over large number of independent reviews/ratings.
</nextsent>
<nextsent>from another standpoint, reading through large number of textual reviews in orderto infer the aspect ratings could be quite time con 36 suming, and, at the same time, the outcome of the evaluation could be biased by the readers interpretation.
</nextsent>
<nextsent>in this work, instead of single overall rating, we propose to provide ratings for multiple aspects of the product/service.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG770">
<title id=" W10-2402.xml">white paper of news 2010 shared task on transliteration generation </title>
<section> short papers on task (5 apr 2010).  </section>
<citcontext>
<prevsection>
<prevsent>1.
</prevsent>
<prevsent>participants will need to obtain licenses from.
</prevsent>
</prevsection>
<citsent citstr=" P04-1021 ">
the respective copyright owners and/or agree to the terms and conditions of use that are given on the downloading website (li et al, 2004; <papid> P04-1021 </papid>msri, 2010; cjki, 2010).</citsent>
<aftsection>
<nextsent>news 2010 will provide the contact details of each individual database.
</nextsent>
<nextsent>the data would be provided in unicode utf-8 encoding, in xmlformat; the results are expected to be submitted in utf-8 encoding in xml format.the xml formats details are available in appendix a. 2.
</nextsent>
<nextsent>the data are provided in 3 sets as described.
</nextsent>
<nextsent>above.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG771">
<title id=" W10-2506.xml">nbest parsing revisited </title>
<section> abstract </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" W05-1506 ">
we derive and implement an algorithm similar to (huang and chiang, 2005) <papid> W05-1506 </papid>for finding the best derivations in weighted hypergraph.</citsent>
<aftsection>
<nextsent>we prove the correctness and termination of the algorithm and we show experimental results concerning its runtime.
</nextsent>
<nextsent>our work is different from the aforementioned one in the following respects: we consider labeled hypergraphs, allowing for tree-based language models (maletti and satta, 2009); <papid> W09-3801 </papid>we specifically handle the case of cyclic hypergraphs; we admit structured weight domains, allowing for multiple features to be processed; we use the paradigm of functional programming together with lazy evaluation, achieving concise algorithmic descriptions.</nextsent>
<nextsent>in statistical natural language processing, probabilistic models play an important role which can be used to assign to some input sentence set of analyses, each carrying probability.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG772">
<title id=" W10-2506.xml">nbest parsing revisited </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>we derive and implement an algorithm similar to (huang and chiang, 2005) <papid> W05-1506 </papid>for finding the best derivations in weighted hypergraph.</prevsent>
<prevsent>we prove the correctness and termination of the algorithm and we show experimental results concerning its runtime.</prevsent>
</prevsection>
<citsent citstr=" W09-3801 ">
our work is different from the aforementioned one in the following respects: we consider labeled hypergraphs, allowing for tree-based language models (maletti and satta, 2009); <papid> W09-3801 </papid>we specifically handle the case of cyclic hypergraphs; we admit structured weight domains, allowing for multiple features to be processed; we use the paradigm of functional programming together with lazy evaluation, achieving concise algorithmic descriptions.</citsent>
<aftsection>
<nextsent>in statistical natural language processing, probabilistic models play an important role which can be used to assign to some input sentence set of analyses, each carrying probability.
</nextsent>
<nextsent>for instance,an analysis can be parse tree or possible translation.
</nextsent>
<nextsent>due to the ambiguity of natural language, the number of analyses for one input sentence can be very large.
</nextsent>
<nextsent>some models even assign an infinite number of analyses to an input sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG773">
<title id=" W10-2506.xml">nbest parsing revisited </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>while such representation is space-efficient, it may be incompatible with subsequent operations.in these cases finite subset is used as an approximation, consisting of best analyses, i. e. analyses with highest probability.
</prevsent>
<prevsent>for example, this approach has the following two applications.
</prevsent>
</prevsection>
<citsent citstr=" P02-1038 ">
(1) reranking: when log-linear models (och and ney, 2002) <papid> P02-1038 </papid>are employed, some features may ? this research was financially supported by dfg vo 1101/5-1.not permit an efficient evaluation during the computation of the analyses.</citsent>
<aftsection>
<nextsent>these features are computed using individual analyses from said approximation, leading to reranking amongst them.
</nextsent>
<nextsent>(2) spurious ambiguity: many models produce analyses which may be too fine-grained for further processing (li et al, 2009).<papid> P09-1067 </papid></nextsent>
<nextsent>as an example, consider context-free grammars, where several left most derivations may exist for the same terminalstring.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG774">
<title id=" W10-2506.xml">nbest parsing revisited </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(1) reranking: when log-linear models (och and ney, 2002) <papid> P02-1038 </papid>are employed, some features may ? this research was financially supported by dfg vo 1101/5-1.not permit an efficient evaluation during the computation of the analyses.</prevsent>
<prevsent>these features are computed using individual analyses from said approximation, leading to reranking amongst them.</prevsent>
</prevsection>
<citsent citstr=" P09-1067 ">
(2) spurious ambiguity: many models produce analyses which may be too fine-grained for further processing (li et al, 2009).<papid> P09-1067 </papid></citsent>
<aftsection>
<nextsent>as an example, consider context-free grammars, where several left most derivations may exist for the same terminalstring.
</nextsent>
<nextsent>the weight of the terminal string is obtained by summing over these derivations.
</nextsent>
<nextsent>then best left most derivations may be used to approximate this sum.
</nextsent>
<nextsent>in this paper, we consider the case where the finite, compact representation has the form of weighted hypergraph (with labeled hyperedges) and the analyses are derivations of the hypergraph.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG775">
<title id=" W10-2506.xml">nbest parsing revisited </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>then best left most derivations may be used to approximate this sum.
</prevsent>
<prevsent>in this paper, we consider the case where the finite, compact representation has the form of weighted hypergraph (with labeled hyperedges) and the analyses are derivations of the hypergraph.
</prevsent>
</prevsection>
<citsent citstr=" J99-4004 ">
this covers many parsing applications (klein and manning, 2001), including weighted deductive systems (goodman, 1999; <papid> J99-4004 </papid>nederhof, 2003), <papid> J03-1006 </papid>and also applications in machine translation (may and knight, 2006).<papid> N06-1045 </papid></citsent>
<aftsection>
<nextsent>in the nomenclature of (huang and chiang,2005), <papid> W05-1506 </papid>which we adopt here, derivation of hypergraph is tree which is obtained in the following way.</nextsent>
<nextsent>starting from some node, an ingoing hyperedge is picked and recorded as the label of theroot of the tree.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG776">
<title id=" W10-2506.xml">nbest parsing revisited </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>then best left most derivations may be used to approximate this sum.
</prevsent>
<prevsent>in this paper, we consider the case where the finite, compact representation has the form of weighted hypergraph (with labeled hyperedges) and the analyses are derivations of the hypergraph.
</prevsent>
</prevsection>
<citsent citstr=" J03-1006 ">
this covers many parsing applications (klein and manning, 2001), including weighted deductive systems (goodman, 1999; <papid> J99-4004 </papid>nederhof, 2003), <papid> J03-1006 </papid>and also applications in machine translation (may and knight, 2006).<papid> N06-1045 </papid></citsent>
<aftsection>
<nextsent>in the nomenclature of (huang and chiang,2005), <papid> W05-1506 </papid>which we adopt here, derivation of hypergraph is tree which is obtained in the following way.</nextsent>
<nextsent>starting from some node, an ingoing hyperedge is picked and recorded as the label of theroot of the tree.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG777">
<title id=" W10-2506.xml">nbest parsing revisited </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>then best left most derivations may be used to approximate this sum.
</prevsent>
<prevsent>in this paper, we consider the case where the finite, compact representation has the form of weighted hypergraph (with labeled hyperedges) and the analyses are derivations of the hypergraph.
</prevsent>
</prevsection>
<citsent citstr=" N06-1045 ">
this covers many parsing applications (klein and manning, 2001), including weighted deductive systems (goodman, 1999; <papid> J99-4004 </papid>nederhof, 2003), <papid> J03-1006 </papid>and also applications in machine translation (may and knight, 2006).<papid> N06-1045 </papid></citsent>
<aftsection>
<nextsent>in the nomenclature of (huang and chiang,2005), <papid> W05-1506 </papid>which we adopt here, derivation of hypergraph is tree which is obtained in the following way.</nextsent>
<nextsent>starting from some node, an ingoing hyperedge is picked and recorded as the label of theroot of the tree.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG784">
<title id=" W10-2506.xml">nbest parsing revisited </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>huang and chiang (2005) <papid> W05-1506 </papid>show that the best-derivations problem can be solved efficiently by first solving the 1-best-derivation problem and then extending that solution in lazy manner.huang and chiang assume weighted unlabeled hypergraphs with weights computed in the reals, and they require the weight functions to be monotone.moreover they assume that the 1-best derivation problem be solved using the viterbi algorithm, which implies that the hypergraph must be acyclic.</prevsent>
<prevsent>however they conjecture that their second phase also works for cyclic hypergraphs.</prevsent>
</prevsection>
<citsent citstr=" P09-1108 ">
pauls and klein (2009) <papid> P09-1108 </papid>propose variation of the algorithm of huang and chiang (2005) <papid> W05-1506 </papid>in which the 1-best-derivation problem is computed via an a?-based exploration of the 1-best charts.</citsent>
<aftsection>
<nextsent>in this paper, we also present an algorithm for solving the n-best-derivations problem.
</nextsent>
<nextsent>ultimately it uses the same algorithmic ideas as the one of huang and chiang (2005); <papid> W05-1506 </papid>however, it is different in the following sense: 1.</nextsent>
<nextsent>we consider labeled hypergraphs, allowing for wta to be used in parsing; 2.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG791">
<title id=" W10-1761.xml">improved translation with source syntax labels </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>hierarchical and syntax statistical machine translation have made great progress in the last few years and can claim to represent the state ofthe art in the field.
</prevsent>
<prevsent>both use synchronous context free grammar (scfg) formalism, consisting of rewrite rules which simultaneously parse the in put sentence and generate the output sentence.
</prevsent>
</prevsection>
<citsent citstr=" P05-1033 ">
the most common algorithm for decoding with scfg is currently cky+ with cube pruning works forboth hierarchical and syntactic systems, as implemented in hiero (chiang, 2005), <papid> P05-1033 </papid>joshua (li et al, 2009), <papid> W09-0424 </papid>and moses (hoang et al, 2009)rewrite rules in hierarchical systems have general applicability as their non-terminals are undecorated, giving hierarchical system broad coverage.however, rules may be used in inappropriate situations without the labeled constraints.</citsent>
<aftsection>
<nextsent>the general applicability of undecorated rules create spurious ambiguity which decreases translation performance by causing the decoder to spend more time sifting through duplicate hypotheses.
</nextsent>
<nextsent>syntactic systems makes use of linguistically motivated information tobias the search space at the expense of limiting model coverage.this paper presents work on combining hierarchical and syntax translation, utilizing the high coverage of hierarchical decoding and the insights that syntactic information can bring.
</nextsent>
<nextsent>weseek to balance the generality of using undecorated non-terminals with the specificity of labelednon-terminals.
</nextsent>
<nextsent>specifically, we will use syntactic labels from source language parser to label non-terminal in production rules.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG792">
<title id=" W10-1761.xml">improved translation with source syntax labels </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>hierarchical and syntax statistical machine translation have made great progress in the last few years and can claim to represent the state ofthe art in the field.
</prevsent>
<prevsent>both use synchronous context free grammar (scfg) formalism, consisting of rewrite rules which simultaneously parse the in put sentence and generate the output sentence.
</prevsent>
</prevsection>
<citsent citstr=" W09-0424 ">
the most common algorithm for decoding with scfg is currently cky+ with cube pruning works forboth hierarchical and syntactic systems, as implemented in hiero (chiang, 2005), <papid> P05-1033 </papid>joshua (li et al, 2009), <papid> W09-0424 </papid>and moses (hoang et al, 2009)rewrite rules in hierarchical systems have general applicability as their non-terminals are undecorated, giving hierarchical system broad coverage.however, rules may be used in inappropriate situations without the labeled constraints.</citsent>
<aftsection>
<nextsent>the general applicability of undecorated rules create spurious ambiguity which decreases translation performance by causing the decoder to spend more time sifting through duplicate hypotheses.
</nextsent>
<nextsent>syntactic systems makes use of linguistically motivated information tobias the search space at the expense of limiting model coverage.this paper presents work on combining hierarchical and syntax translation, utilizing the high coverage of hierarchical decoding and the insights that syntactic information can bring.
</nextsent>
<nextsent>weseek to balance the generality of using undecorated non-terminals with the specificity of labelednon-terminals.
</nextsent>
<nextsent>specifically, we will use syntactic labels from source language parser to label non-terminal in production rules.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG799">
<title id=" W10-1761.xml">improved translation with source syntax labels </title>
<section> past work.  </section>
<citcontext>
<prevsection>
<prevsent>syntactic labels from parse trees can be used to annotate non-terminals in the translation model.this reduces incorrect rule application by restricting rule extraction and application.
</prevsent>
<prevsent>however,as noted in (ambati and lavie, 2008) and else where,the nave approach of constraining every non-terminal to syntactic constituent severely limits the coverage of the resulting grammar, therefore, several approaches have been used to improve coverage when using syntactic information.
</prevsent>
</prevsection>
<citsent citstr=" W06-3119 ">
zollmann and venugopal (2006) <papid> W06-3119 </papid>allow rules to be extracted where non-terminals do not exactly span target constituent.</citsent>
<aftsection>
<nextsent>the non-terminals arethen labeled with complex labels which amalga mates multiple labels in the span.
</nextsent>
<nextsent>this increase coverage at the expense of increasing data sparsityas the non-terminal symbol set increases dramatically.
</nextsent>
<nextsent>huang and chiang (2008) use parse information of the source language, production rules consists of source tree fragments and target languages strings.
</nextsent>
<nextsent>during decoding, packed forest of the source sentence is used as input, the production rule tree fragments are applied to the packed forest.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG800">
<title id=" W10-1761.xml">improved translation with source syntax labels </title>
<section> past work.  </section>
<citcontext>
<prevsection>
<prevsent>huang and chiang (2008) use parse information of the source language, production rules consists of source tree fragments and target languages strings.
</prevsent>
<prevsent>during decoding, packed forest of the source sentence is used as input, the production rule tree fragments are applied to the packed forest.
</prevsent>
</prevsection>
<citsent citstr=" P09-1065 ">
liu et al (2009) <papid> P09-1065 </papid>uses joint decoding with hierarchical and tree-to-string model and find that translation performance increase for chinese-english task.</citsent>
<aftsection>
<nextsent>galley et al (2004) creates minimal translation rules which can explain parallel sentence pair but the rules generated are not optimized to produce good translations or cover age in any smt system.
</nextsent>
<nextsent>this work was extended and described in (galley et al, 2006) <papid> P06-1121 </papid>which creates rules composed of smaller, minimal rules, aswell as dealing with unaligned words.</nextsent>
<nextsent>these measures are essential for creating good smt systems, but again, the rules syntax are strictly constrained by parser.others have sought to add soft linguistic constraints to hierarchical models using addition feature functions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG801">
<title id=" W10-1761.xml">improved translation with source syntax labels </title>
<section> past work.  </section>
<citcontext>
<prevsection>
<prevsent>liu et al (2009) <papid> P09-1065 </papid>uses joint decoding with hierarchical and tree-to-string model and find that translation performance increase for chinese-english task.</prevsent>
<prevsent>galley et al (2004) creates minimal translation rules which can explain parallel sentence pair but the rules generated are not optimized to produce good translations or cover age in any smt system.</prevsent>
</prevsection>
<citsent citstr=" P06-1121 ">
this work was extended and described in (galley et al, 2006) <papid> P06-1121 </papid>which creates rules composed of smaller, minimal rules, aswell as dealing with unaligned words.</citsent>
<aftsection>
<nextsent>these measures are essential for creating good smt systems, but again, the rules syntax are strictly constrained by parser.others have sought to add soft linguistic constraints to hierarchical models using addition feature functions.
</nextsent>
<nextsent>marton and resnik (2008) <papid> P08-1114 </papid>add feature functions to penalize or reward non-terminals which cross constituent boundaries of the source sentence.</nextsent>
<nextsent>this follows on from earlier work in (chiang, 2005) <papid> P05-1033 </papid>but they see gains when finer grain feature functions which different constituency types.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG802">
<title id=" W10-1761.xml">improved translation with source syntax labels </title>
<section> past work.  </section>
<citcontext>
<prevsection>
<prevsent>this work was extended and described in (galley et al, 2006) <papid> P06-1121 </papid>which creates rules composed of smaller, minimal rules, aswell as dealing with unaligned words.</prevsent>
<prevsent>these measures are essential for creating good smt systems, but again, the rules syntax are strictly constrained by parser.others have sought to add soft linguistic constraints to hierarchical models using addition feature functions.</prevsent>
</prevsection>
<citsent citstr=" P08-1114 ">
marton and resnik (2008) <papid> P08-1114 </papid>add feature functions to penalize or reward non-terminals which cross constituent boundaries of the source sentence.</citsent>
<aftsection>
<nextsent>this follows on from earlier work in (chiang, 2005) <papid> P05-1033 </papid>but they see gains when finer grain feature functions which different constituency types.</nextsent>
<nextsent>the weights for feature function is tuned in batches due to the deficiency of mert when presented with many features.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG806">
<title id=" W10-1761.xml">improved translation with source syntax labels </title>
<section> past work.  </section>
<citcontext>
<prevsection>
<prevsent>this follows on from earlier work in (chiang, 2005) <papid> P05-1033 </papid>but they see gains when finer grain feature functions which different constituency types.</prevsent>
<prevsent>the weights for feature function is tuned in batches due to the deficiency of mert when presented with many features.</prevsent>
</prevsection>
<citsent citstr=" D08-1024 ">
chiang et al (2008) <papid> D08-1024 </papid>rectified this deficiency by using the mira to tuneall feature function weights in combination.</citsent>
<aftsection>
<nextsent>however, the translation model continues to be hierarchical.
</nextsent>
<nextsent>chiang et al (2009) <papid> N09-1025 </papid>added thousands of linguistically-motivated features to hierarchical and syntax systems, however, the source syntax features are derived from the research above.</nextsent>
<nextsent>the translation model remain constant but the parameterization changes.shen et al (2009) <papid> D09-1008 </papid>discusses soft syntax constraints and context features in dependency tree translation model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG807">
<title id=" W10-1761.xml">improved translation with source syntax labels </title>
<section> past work.  </section>
<citcontext>
<prevsection>
<prevsent>chiang et al (2008) <papid> D08-1024 </papid>rectified this deficiency by using the mira to tuneall feature function weights in combination.</prevsent>
<prevsent>however, the translation model continues to be hierar chical.</prevsent>
</prevsection>
<citsent citstr=" N09-1025 ">
chiang et al (2009) <papid> N09-1025 </papid>added thousands of linguistically-motivated features to hierarchical and syntax systems, however, the source syntax features are derived from the research above.</citsent>
<aftsection>
<nextsent>the translation model remain constant but the parameterization changes.shen et al (2009) <papid> D09-1008 </papid>discusses soft syntax constraints and context features in dependency tree translation model.</nextsent>
<nextsent>the pos tag of the target head word is used as soft constraint when applying rules.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG808">
<title id=" W10-1761.xml">improved translation with source syntax labels </title>
<section> past work.  </section>
<citcontext>
<prevsection>
<prevsent>however, the translation model continues to be hierarchical.
</prevsent>
<prevsent>chiang et al (2009) <papid> N09-1025 </papid>added thousands of linguistically-motivated features to hierarchical and syntax systems, however, the source syntax features are derived from the research above.</prevsent>
</prevsection>
<citsent citstr=" D09-1008 ">
the translation model remain constant but the parameterization changes.shen et al (2009) <papid> D09-1008 </papid>discusses soft syntax constraints and context features in dependency tree translation model.</citsent>
<aftsection>
<nextsent>the pos tag of the target head word is used as soft constraint when applying rules.
</nextsent>
<nextsent>also, source context language model anda dependency language model are also used as fea tures.most smt systems uses the viterbi approximation whereby the derivations in the log-linear model is not marginalized, but the maximum derivation is returned.
</nextsent>
<nextsent>string-to-tree models buildon this so that the most probable derivation, including syntactic labels, is assumed to the most probable translation.
</nextsent>
<nextsent>this fragments the derivation probability and the further partition the search space, leading to pruning errors.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG809">
<title id=" W10-1761.xml">improved translation with source syntax labels </title>
<section> past work.  </section>
<citcontext>
<prevsection>
<prevsent>string-to-tree models buildon this so that the most probable derivation, including syntactic labels, is assumed to the most probable translation.
</prevsent>
<prevsent>this fragments the derivation probability and the further partition the search space, leading to pruning errors.
</prevsent>
</prevsection>
<citsent citstr=" N09-1027 ">
venugopal et al(2009) <papid> N09-1027 </papid>attempts to address this by efficiently estimating the score over an equivalent unlabeled derivation from target syntax model.</citsent>
<aftsection>
<nextsent>ambati and lavie (2008); ambati et al (2009) notes that tree-to-tree often underperform models with parse tree only on one side due to the non isomorphic structure of languages.
</nextsent>
<nextsent>this motivates the creation of an isomorphic backbone into the target parse tree, while leaving the source parse unchanged.
</nextsent>
<nextsent>in extending the phrase-based model to the hierarchical model, non-terminals are used in translation rules to denote subphrases.
</nextsent>
<nextsent>hierarchical nonterminals are undecorated so are unrestricted to thespan they cover.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG810">
<title id=" W10-1761.xml">improved translation with source syntax labels </title>
<section> model.  </section>
<citcontext>
<prevsection>
<prevsent>in the soft syntax experiments, edges with the default source label, , are also created for all spans.
</prevsent>
<prevsent>nodesin the lattice represent word positions in the sentence.
</prevsent>
</prevsection>
<citsent citstr=" P08-1115 ">
we encode the lattice in chart, as described in (dyer et al, 2008).<papid> P08-1115 </papid></citsent>
<aftsection>
<nextsent>a chart is is tuple of 2 dimensional matrices   f,r  .
</nextsent>
<nextsent>fi,j is the word or non-terminal label of the jth transition starting word position i. ri,j is the end word position of the node on the right of the jth transition leaving word position i. the input sentence is decoded with set of translation rules of the form ?  ls, ?,? where ? and ? and strings of terminals and nonterminals.
</nextsent>
<nextsent>ls and the string ? are drawn from the same source alphabet, s. ? is the target string, also consisting of terminals and non-terminals.
</nextsent>
<nextsent>is the one-to-one correspondence between nonterminals in ? and ?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG812">
<title id=" W10-1761.xml">improved translation with source syntax labels </title>
<section> model.  </section>
<citcontext>
<prevsection>
<prevsent>this contrasts with the approach by (zollmann and venugopal, 2006) <papid> W06-3119 </papid>in attempting to improve the coverage of syntactic translation.</prevsent>
<prevsent>rather than creating ad-hoc schemes to categories non-terminalswith syntactic labels when they do not span syntactic constituencies, we only use labels that are presented by the parser or shallow tagger.</prevsent>
</prevsection>
<citsent citstr=" P08-1023 ">
nor dowe try to expand the space where rules can apply by propagating uncertainty from the parser in building input forests, as in (mi et al, 2008), <papid> P08-1023 </papid>but we build ambiguity into the translation rule.</citsent>
<aftsection>
<nextsent>the model also differs from (marton and resnik, 2008; <papid> P08-1114 </papid>chiang et al, 2008, <papid> D08-1024 </papid>2009) by adding informative labels to rule non-terminals andre quiring them to match the source span label.</nextsent>
<nextsent>thesoft constraint in our model pertain not to additional feature functions based on syntactic information, but to the availability of syntactic and non syntactic informed rules.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG821">
<title id=" W10-1761.xml">improved translation with source syntax labels </title>
<section> parameterization.  </section>
<citcontext>
<prevsection>
<prevsent>we estimate p(t|s) by decomposing it into component models p(t|s) = 1 ? hm(t, s) (2)where hm(t, s) is the feature function for component and is the weight given to component m. is normalization factor which is ignored inpractice.
</prevsent>
<prevsent>components are translation model scoring functions, language model, and other features.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
the problem is typically presented in log-space, which simplifies computations, but otherwise does not change the problem due to the monotonicity of the log function (hm = log hm) log p(t|s) = ? m hm(t, s) (3) an advantage of our model over (marton and resnik, 2008; <papid> P08-1114 </papid>chiang et al, 2008, <papid> D08-1024 </papid>2009) is the number of feature functions remains the same, therefore, the tuning algorithm does not need to be replaced; we continue to use mert (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>rule extraction follows the algorithm described in(chiang, 2005).<papid> P05-1033 </papid></nextsent>
<nextsent>we note the heuristics used for hierarchical phrases extraction include the following constraints: 1.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG826">
<title id=" W10-1761.xml">improved translation with source syntax labels </title>
<section> rule extraction.  </section>
<citcontext>
<prevsection>
<prevsent>all non-terminals and lhs must span parse constituent 412 5.1 rule probabilities.
</prevsent>
<prevsent>maximum likelihood phrase probabilities, p(t|s), are calculated for phrase pairs, using fractional counts as described in (chiang, 2005).<papid> P05-1033 </papid></prevsent>
</prevsection>
<citsent citstr=" W06-1607 ">
the maximum likelihood estimates are smoothed using good-turing discounting (foster et al, 2006).<papid> W06-1607 </papid></citsent>
<aftsection>
<nextsent>a phrase count feature function is also create for each translation model, however, the lexical and backward probabilities are not used.
</nextsent>
<nextsent>we use the moses implementation of the scfgbased approach (hoang et al, 2009) which support hierarchical and syntactic training and decoding used in this paper.
</nextsent>
<nextsent>the decoder implements the cky+ algorithm with cube pruning, as well ashistogram and beam pruning, all pruning parameters were identical for all experiments for fairer comparison.
</nextsent>
<nextsent>all non-terminals can cover maximum of 7 source words, similar to the maximum rule span feature other hierarchical decoders to speed up decoding time.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG827">
<title id=" W10-1761.xml">improved translation with source syntax labels </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>table 1 gives more details on the corpus.
</prevsent>
<prevsent>nc test2007 was used for testing.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
german english train sentences 82,306 words 2,034,373 1,965,325 tune sentences 2000 test sentences 1026 table 1: training, tuning, and test conditions the training corpus was cleaned and filtered using standard methods found in the moses toolkit (koehn et al, 2007) <papid> P07-2045 </papid>and aligned using giza++(och and ney, 2003).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>standard mert weight tuning was used throughout.
</nextsent>
<nextsent>the english half of the training data was also used to create trigram language model which was used for each experiment.
</nextsent>
<nextsent>all experiments use true case data and results are reported in case-sensitive bleu scores (papineni et al, 2001).
</nextsent>
<nextsent>the german side was parsed with the bitpar parser2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG828">
<title id=" W10-1761.xml">improved translation with source syntax labels </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>table 1 gives more details on the corpus.
</prevsent>
<prevsent>nc test2007 was used for testing.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
german english train sentences 82,306 words 2,034,373 1,965,325 tune sentences 2000 test sentences 1026 table 1: training, tuning, and test conditions the training corpus was cleaned and filtered using standard methods found in the moses toolkit (koehn et al, 2007) <papid> P07-2045 </papid>and aligned using giza++(och and ney, 2003).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>standard mert weight tuning was used throughout.
</nextsent>
<nextsent>the english half of the training data was also used to create trigram language model which was used for each experiment.
</nextsent>
<nextsent>all experiments use true case data and results are reported in case-sensitive bleu scores (papineni et al, 2001).
</nextsent>
<nextsent>the german side was parsed with the bitpar parser2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG830">
<title id=" W10-2304.xml">robust and efficient page rank for word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>lexical ambiguity is fundamental aspect of natural language.
</prevsent>
<prevsent>word sense disambiguation (wsd) investigates methods to automatically determine the intended sense of word in given context according to predefined set of sense definitions, provided by semantic lexicon.
</prevsent>
</prevsection>
<citsent citstr=" P07-1005 ">
intuitively, wsd can be usefully exploited in variety of nlp (e.g. machine translation (chan et al, 2007; <papid> P07-1005 </papid>carpuat and wu, 2007)) <papid> D07-1007 </papid>and information retrieval tasks such as ad hoc retrieval (krovetz, 1997; <papid> P97-1010 </papid>kim et al., 2004) or question answering (beale et al, 2004).<papid> W04-0906 </papid></citsent>
<aftsection>
<nextsent>however controversial results have been often obtained, as for example the study on text classification reported in (moschitti and basili, 2004).
</nextsent>
<nextsent>the impact of wsd on ir tasks is still an open issue and large scale assessment is needed.for this reason, unsupervised approaches to inductive wsd are appealing.
</nextsent>
<nextsent>in contrast with supervised methods that strongly relyon manually labeled datasets, those methods do not require annotated examples for all words and can thus support realistic (large scale) benchmarks, as needed in ir research.
</nextsent>
<nextsent>in recent years different approaches to word sense disambiguation task have been evaluated through comparative campaigns, such as the earlier senseval evaluation exercises.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG831">
<title id=" W10-2304.xml">robust and efficient page rank for word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>lexical ambiguity is fundamental aspect of natural language.
</prevsent>
<prevsent>word sense disambiguation (wsd) investigates methods to automatically determine the intended sense of word in given context according to predefined set of sense definitions, provided by semantic lexicon.
</prevsent>
</prevsection>
<citsent citstr=" D07-1007 ">
intuitively, wsd can be usefully exploited in variety of nlp (e.g. machine translation (chan et al, 2007; <papid> P07-1005 </papid>carpuat and wu, 2007)) <papid> D07-1007 </papid>and information retrieval tasks such as ad hoc retrieval (krovetz, 1997; <papid> P97-1010 </papid>kim et al., 2004) or question answering (beale et al, 2004).<papid> W04-0906 </papid></citsent>
<aftsection>
<nextsent>however controversial results have been often obtained, as for example the study on text classification reported in (moschitti and basili, 2004).
</nextsent>
<nextsent>the impact of wsd on ir tasks is still an open issue and large scale assessment is needed.for this reason, unsupervised approaches to inductive wsd are appealing.
</nextsent>
<nextsent>in contrast with supervised methods that strongly relyon manually labeled datasets, those methods do not require annotated examples for all words and can thus support realistic (large scale) benchmarks, as needed in ir research.
</nextsent>
<nextsent>in recent years different approaches to word sense disambiguation task have been evaluated through comparative campaigns, such as the earlier senseval evaluation exercises.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG832">
<title id=" W10-2304.xml">robust and efficient page rank for word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>lexical ambiguity is fundamental aspect of natural language.
</prevsent>
<prevsent>word sense disambiguation (wsd) investigates methods to automatically determine the intended sense of word in given context according to predefined set of sense definitions, provided by semantic lexicon.
</prevsent>
</prevsection>
<citsent citstr=" P97-1010 ">
intuitively, wsd can be usefully exploited in variety of nlp (e.g. machine translation (chan et al, 2007; <papid> P07-1005 </papid>carpuat and wu, 2007)) <papid> D07-1007 </papid>and information retrieval tasks such as ad hoc retrieval (krovetz, 1997; <papid> P97-1010 </papid>kim et al., 2004) or question answering (beale et al, 2004).<papid> W04-0906 </papid></citsent>
<aftsection>
<nextsent>however controversial results have been often obtained, as for example the study on text classification reported in (moschitti and basili, 2004).
</nextsent>
<nextsent>the impact of wsd on ir tasks is still an open issue and large scale assessment is needed.for this reason, unsupervised approaches to inductive wsd are appealing.
</nextsent>
<nextsent>in contrast with supervised methods that strongly relyon manually labeled datasets, those methods do not require annotated examples for all words and can thus support realistic (large scale) benchmarks, as needed in ir research.
</nextsent>
<nextsent>in recent years different approaches to word sense disambiguation task have been evaluated through comparative campaigns, such as the earlier senseval evaluation exercises.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG833">
<title id=" W10-2304.xml">robust and efficient page rank for word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>lexical ambiguity is fundamental aspect of natural language.
</prevsent>
<prevsent>word sense disambiguation (wsd) investigates methods to automatically determine the intended sense of word in given context according to predefined set of sense definitions, provided by semantic lexicon.
</prevsent>
</prevsection>
<citsent citstr=" W04-0906 ">
intuitively, wsd can be usefully exploited in variety of nlp (e.g. machine translation (chan et al, 2007; <papid> P07-1005 </papid>carpuat and wu, 2007)) <papid> D07-1007 </papid>and information retrieval tasks such as ad hoc retrieval (krovetz, 1997; <papid> P97-1010 </papid>kim et al., 2004) or question answering (beale et al, 2004).<papid> W04-0906 </papid></citsent>
<aftsection>
<nextsent>however controversial results have been often obtained, as for example the study on text classification reported in (moschitti and basili, 2004).
</nextsent>
<nextsent>the impact of wsd on ir tasks is still an open issue and large scale assessment is needed.for this reason, unsupervised approaches to inductive wsd are appealing.
</nextsent>
<nextsent>in contrast with supervised methods that strongly relyon manually labeled datasets, those methods do not require annotated examples for all words and can thus support realistic (large scale) benchmarks, as needed in ir research.
</nextsent>
<nextsent>in recent years different approaches to word sense disambiguation task have been evaluated through comparative campaigns, such as the earlier senseval evaluation exercises.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG834">
<title id=" W10-2304.xml">robust and efficient page rank for word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in contrast with supervised methods that strongly relyon manually labeled datasets, those methods do not require annotated examples for all words and can thus support realistic (large scale) benchmarks, as needed in ir research.
</prevsent>
<prevsent>in recent years different approaches to word sense disambiguation task have been evaluated through comparative campaigns, such as the earlier senseval evaluation exercises.
</prevsent>
</prevsection>
<citsent citstr=" W04-0811 ">
(palmer et al, 2001; snyder and palmer, 2004) <papid> W04-0811 </papid>or the most recent (pradhan et al, 2007).<papid> W07-2016 </papid></citsent>
<aftsection>
<nextsent>the best accuracy is reached by wsd based on supervised methods that exploit large amounts ofhand-tagged data to train discriminative or generative disambiguation models.
</nextsent>
<nextsent>the common alternative to supervised systems are knowledge based wsd systems that try to exploit information made available by large lexical knowledge bases (lkb).
</nextsent>
<nextsent>they enable the definition of several metrics to estimate semantic similarity (e.g.
</nextsent>
<nextsent>(lesk, 1986) or (agirre and rigau, 1996), (<papid> C96-1005 </papid>basili et al, 2004) methods) and then use it to rank the alternative senses according to the incoming context.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG835">
<title id=" W10-2304.xml">robust and efficient page rank for word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in contrast with supervised methods that strongly relyon manually labeled datasets, those methods do not require annotated examples for all words and can thus support realistic (large scale) benchmarks, as needed in ir research.
</prevsent>
<prevsent>in recent years different approaches to word sense disambiguation task have been evaluated through comparative campaigns, such as the earlier senseval evaluation exercises.
</prevsent>
</prevsection>
<citsent citstr=" W07-2016 ">
(palmer et al, 2001; snyder and palmer, 2004) <papid> W04-0811 </papid>or the most recent (pradhan et al, 2007).<papid> W07-2016 </papid></citsent>
<aftsection>
<nextsent>the best accuracy is reached by wsd based on supervised methods that exploit large amounts ofhand-tagged data to train discriminative or generative disambiguation models.
</nextsent>
<nextsent>the common alternative to supervised systems are knowledge based wsd systems that try to exploit information made available by large lexical knowledge bases (lkb).
</nextsent>
<nextsent>they enable the definition of several metrics to estimate semantic similarity (e.g.
</nextsent>
<nextsent>(lesk, 1986) or (agirre and rigau, 1996), (<papid> C96-1005 </papid>basili et al, 2004) methods) and then use it to rank the alternative senses according to the incoming context.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG836">
<title id=" W10-2304.xml">robust and efficient page rank for word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the common alternative to supervised systems are knowledge based wsd systems that try to exploit information made available by large lexical knowledge bases (lkb).
</prevsent>
<prevsent>they enable the definition of several metrics to estimate semantic similarity (e.g.
</prevsent>
</prevsection>
<citsent citstr=" C96-1005 ">
(lesk, 1986) or (agirre and rigau, 1996), (<papid> C96-1005 </papid>basili et al, 2004) methods) and then use it to rank the alternative senses according to the incoming context.</citsent>
<aftsection>
<nextsent>moreover they make available large relationship sets between pairs of lexical meaning units, such as synonymy, hyponymy or meronymy.
</nextsent>
<nextsent>the resulting networks represent at various grains and degrees of approximation models of the mental lexicons.
</nextsent>
<nextsent>it is not by chance that early research on wsd based on semantic dictionaries were applying models of network activation processes (in particular simulated annealing as in (cowie et al, 1992)) <papid> H92-1046 </papid>for precise and fast disambiguation.</nextsent>
<nextsent>it has been more recently that graph-based methods for knowledge-based wsd have gained much attention in the nlp community ((sinha and mihalcea, 2007), (navigli and lapata, 2007), (agirre and soroa, 2008), (<papid> L08-1182 </papid>agirre and soroa,2009)).<papid> E09-1005 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG837">
<title id=" W10-2304.xml">robust and efficient page rank for word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>moreover they make available large relationship sets between pairs of lexical meaning units, such as synonymy, hyponymy or meronymy.
</prevsent>
<prevsent>the resulting networks represent at various grains and degrees of approximation models of the mental lexicons.
</prevsent>
</prevsection>
<citsent citstr=" H92-1046 ">
it is not by chance that early research on wsd based on semantic dictionaries were applying models of network activation processes (in particular simulated annealing as in (cowie et al, 1992)) <papid> H92-1046 </papid>for precise and fast disambiguation.</citsent>
<aftsection>
<nextsent>it has been more recently that graph-based methods for knowledge-based wsd have gained much attention in the nlp community ((sinha and mihalcea, 2007), (navigli and lapata, 2007), (agirre and soroa, 2008), (<papid> L08-1182 </papid>agirre and soroa,2009)).<papid> E09-1005 </papid></nextsent>
<nextsent>in these methods graph representation for senses (nodes) and relation (edges) is firstbuilt.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG838">
<title id=" W10-2304.xml">robust and efficient page rank for word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the resulting networks represent at various grains and degrees of approximation models of the mental lexicons.
</prevsent>
<prevsent>it is not by chance that early research on wsd based on semantic dictionaries were applying models of network activation processes (in particular simulated annealing as in (cowie et al, 1992)) <papid> H92-1046 </papid>for precise and fast disambiguation.</prevsent>
</prevsection>
<citsent citstr=" L08-1182 ">
it has been more recently that graph-based methods for knowledge-based wsd have gained much attention in the nlp community ((sinha and mihalcea, 2007), (navigli and lapata, 2007), (agirre and soroa, 2008), (<papid> L08-1182 </papid>agirre and soroa,2009)).<papid> E09-1005 </papid></citsent>
<aftsection>
<nextsent>in these methods graph representation for senses (nodes) and relation (edges) is firstbuilt.
</nextsent>
<nextsent>then graph-based techniques that are sensible to the structural properties of the graph areused to find the best senses for words in the in coming contexts.
</nextsent>
<nextsent>the relation employed by the different methods are of several types such as syn onymy, antonymy but also co-occurrence based lexical similarity computed externally over corpus.
</nextsent>
<nextsent>these give rise to real-valued weights that determine large weighted directed graphs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG839">
<title id=" W10-2304.xml">robust and efficient page rank for word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the resulting networks represent at various grains and degrees of approximation models of the mental lexicons.
</prevsent>
<prevsent>it is not by chance that early research on wsd based on semantic dictionaries were applying models of network activation processes (in particular simulated annealing as in (cowie et al, 1992)) <papid> H92-1046 </papid>for precise and fast disambiguation.</prevsent>
</prevsection>
<citsent citstr=" E09-1005 ">
it has been more recently that graph-based methods for knowledge-based wsd have gained much attention in the nlp community ((sinha and mihalcea, 2007), (navigli and lapata, 2007), (agirre and soroa, 2008), (<papid> L08-1182 </papid>agirre and soroa,2009)).<papid> E09-1005 </papid></citsent>
<aftsection>
<nextsent>in these methods graph representation for senses (nodes) and relation (edges) is firstbuilt.
</nextsent>
<nextsent>then graph-based techniques that are sensible to the structural properties of the graph areused to find the best senses for words in the in coming contexts.
</nextsent>
<nextsent>the relation employed by the different methods are of several types such as syn onymy, antonymy but also co-occurrence based lexical similarity computed externally over corpus.
</nextsent>
<nextsent>these give rise to real-valued weights that determine large weighted directed graphs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG914">
<title id=" W10-2304.xml">robust and efficient page rank for word sense disambiguation </title>
<section> empirical evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>table 1 shows also the results of the standard ppr methods over these meval 2007 dataset.
</prevsent>
<prevsent>second, we want to analyze the efficiency of the algorithm and its impact in sentence (i.e. ppr) or word oriented (i.e. w2w)perspective.
</prevsent>
</prevsection>
<citsent citstr=" W07-2006 ">
this will allow to asses its applicability to realistic tasks, such as query processing or document indexing.experimental set-up in order to measure accuracy, the senseval 2007 coarse wsd dataset2(navigli et al, 2007) <papid> W07-2006 </papid>has been employed.</citsent>
<aftsection>
<nextsent>it includes 245 sentences for total number of 2,269 ambiguous words.
</nextsent>
<nextsent>in line with the results reported in (agirre and soroa, 2009), <papid> E09-1005 </papid>experiments against two different wordnet versions, 1.7 and 3.0, have been carried out.</nextsent>
<nextsent>notice that the best results in (agirre and soroa, 2009) <papid> E09-1005 </papid>were obtained over the enriched version of the lkb, i.e. the combination of wordnet and extra information supplied by extended wordnet (harabagiu and moldovan, 1999).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG930">
<title id=" W10-2304.xml">robust and efficient page rank for word sense disambiguation </title>
<section> empirical evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>the adopted vector space has been acquired over significant subset of the bnc 2.0 corpus, made of 923k sentences.
</prevsent>
<prevsent>the most frequent 200k words (i.e. the contextual features) were acquired through lsa.
</prevsent>
</prevsection>
<citsent citstr=" W07-2048 ">
the corpus has been processed with the lth parser (johansson and nugues, 2007) <papid> W07-2048 </papid>to obtain pos tags for every token.</citsent>
<aftsection>
<nextsent>moreover, dimensionality reduction factor of = 100 was applied.
</nextsent>
<nextsent>in subsection 4.1, comparative analysis of the accuracy achieved in the disambiguation task isdiscussed.
</nextsent>
<nextsent>subsection 4.2 presents corresponding study of the execution times aiming to compare the relative efficiency of the methods and their application into document semantic tagging task.
</nextsent>
<nextsent>4.1 comparative evaluation: accuracy on the.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG973">
<title id=" W10-3903.xml">summarizing search results using plsi </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>first, each topic summary should not contain any redundancy.
</prevsent>
<prevsent>we refer to this problem as redundancy within summary.
</prevsent>
</prevsection>
<citsent citstr=" W00-0405 ">
this problem is well known in the field of multi-document summarization (mani, 2001) and several methods have been proposed to solve it, such as maximum marginal relevance (mmr) (goldstein et al,2000) (<papid> W00-0405 </papid>mori et al, 2004), <papid> C04-1063 </papid>using integer linear programming (ilp) (filatova and hatzivassiloglou, 2004) (<papid> C04-1057 </papid>mcdonald, 2007) (takamura and okumura, 2009), <papid> E09-1089 </papid>and so on.</citsent>
<aftsection>
<nextsent>second, no topic summary should be similar to any of the other topic summaries.
</nextsent>
<nextsent>we refer to this problem as redundancy between summaries.
</nextsent>
<nextsent>for example, to summarize the abovementioned documents related to swine flu, the summary for outbreaks should contain specific information about outbreaks, whereas the summary for measures should contain specific information about measures.
</nextsent>
<nextsent>this problem is characteristic of multi-topic multi-document summarization.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG974">
<title id=" W10-3903.xml">summarizing search results using plsi </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>first, each topic summary should not contain any redundancy.
</prevsent>
<prevsent>we refer to this problem as redundancy within summary.
</prevsent>
</prevsection>
<citsent citstr=" C04-1063 ">
this problem is well known in the field of multi-document summarization (mani, 2001) and several methods have been proposed to solve it, such as maximum marginal relevance (mmr) (goldstein et al,2000) (<papid> W00-0405 </papid>mori et al, 2004), <papid> C04-1063 </papid>using integer linear programming (ilp) (filatova and hatzivassiloglou, 2004) (<papid> C04-1057 </papid>mcdonald, 2007) (takamura and okumura, 2009), <papid> E09-1089 </papid>and so on.</citsent>
<aftsection>
<nextsent>second, no topic summary should be similar to any of the other topic summaries.
</nextsent>
<nextsent>we refer to this problem as redundancy between summaries.
</nextsent>
<nextsent>for example, to summarize the abovementioned documents related to swine flu, the summary for outbreaks should contain specific information about outbreaks, whereas the summary for measures should contain specific information about measures.
</nextsent>
<nextsent>this problem is characteristic of multi-topic multi-document summarization.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG975">
<title id=" W10-3903.xml">summarizing search results using plsi </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>first, each topic summary should not contain any redundancy.
</prevsent>
<prevsent>we refer to this problem as redundancy within summary.
</prevsent>
</prevsection>
<citsent citstr=" C04-1057 ">
this problem is well known in the field of multi-document summarization (mani, 2001) and several methods have been proposed to solve it, such as maximum marginal relevance (mmr) (goldstein et al,2000) (<papid> W00-0405 </papid>mori et al, 2004), <papid> C04-1063 </papid>using integer linear programming (ilp) (filatova and hatzivassiloglou, 2004) (<papid> C04-1057 </papid>mcdonald, 2007) (takamura and okumura, 2009), <papid> E09-1089 </papid>and so on.</citsent>
<aftsection>
<nextsent>second, no topic summary should be similar to any of the other topic summaries.
</nextsent>
<nextsent>we refer to this problem as redundancy between summaries.
</nextsent>
<nextsent>for example, to summarize the abovementioned documents related to swine flu, the summary for outbreaks should contain specific information about outbreaks, whereas the summary for measures should contain specific information about measures.
</nextsent>
<nextsent>this problem is characteristic of multi-topic multi-document summarization.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG976">
<title id=" W10-3903.xml">summarizing search results using plsi </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>first, each topic summary should not contain any redundancy.
</prevsent>
<prevsent>we refer to this problem as redundancy within summary.
</prevsent>
</prevsection>
<citsent citstr=" E09-1089 ">
this problem is well known in the field of multi-document summarization (mani, 2001) and several methods have been proposed to solve it, such as maximum marginal relevance (mmr) (goldstein et al,2000) (<papid> W00-0405 </papid>mori et al, 2004), <papid> C04-1063 </papid>using integer linear programming (ilp) (filatova and hatzivassiloglou, 2004) (<papid> C04-1057 </papid>mcdonald, 2007) (takamura and okumura, 2009), <papid> E09-1089 </papid>and so on.</citsent>
<aftsection>
<nextsent>second, no topic summary should be similar to any of the other topic summaries.
</nextsent>
<nextsent>we refer to this problem as redundancy between summaries.
</nextsent>
<nextsent>for example, to summarize the abovementioned documents related to swine flu, the summary for outbreaks should contain specific information about outbreaks, whereas the summary for measures should contain specific information about measures.
</nextsent>
<nextsent>this problem is characteristic of multi-topic multi-document summarization.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG977">
<title id=" W10-3903.xml">summarizing search results using plsi </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, to summarize the abovementioned documents related to swine flu, the summary for outbreaks should contain specific information about outbreaks, whereas the summary for measures should contain specific information about measures.
</prevsent>
<prevsent>this problem is characteristic of multi-topic multi-document summarization.
</prevsent>
</prevsection>
<citsent citstr=" W00-1110 ">
some methods have been proposed to generate topic summaries from documents(radev and fan, 2000) (<papid> W00-1110 </papid>haghighi and vanderwende, 2009), <papid> N09-1041 </papid>but to the best of our knowledge, the redundancy between summaries has not yet been addressed in any study.in this paper, we focus on the document clustering process and the reduction of redundancy between summaries in the summarization pro cess.</citsent>
<aftsection>
<nextsent>furthermore, we propose method usingplsi (hofmann, 1999) to summarize search results.
</nextsent>
<nextsent>in the proposed method, we employ plsito estimate the membership degree of each document to each topic, and then classify the search results into topics using this information.
</nextsent>
<nextsent>in thesame way, we employ plsi to estimate the membership degree of each keyword to each topic,and then extract the important sentences specific to each topic using this information in order to reduce the redundancy between summaries.the evaluation results show that our method performs well in classifying search results and successfully reduces the redundancy between summaries.
</nextsent>
<nextsent>d      dz
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG978">
<title id=" W10-3903.xml">summarizing search results using plsi </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, to summarize the abovementioned documents related to swine flu, the summary for outbreaks should contain specific information about outbreaks, whereas the summary for measures should contain specific information about measures.
</prevsent>
<prevsent>this problem is characteristic of multi-topic multi-document summarization.
</prevsent>
</prevsection>
<citsent citstr=" N09-1041 ">
some methods have been proposed to generate topic summaries from documents(radev and fan, 2000) (<papid> W00-1110 </papid>haghighi and vanderwende, 2009), <papid> N09-1041 </papid>but to the best of our knowledge, the redundancy between summaries has not yet been addressed in any study.in this paper, we focus on the document clustering process and the reduction of redundancy between summaries in the summarization pro cess.</citsent>
<aftsection>
<nextsent>furthermore, we propose method usingplsi (hofmann, 1999) to summarize search results.
</nextsent>
<nextsent>in the proposed method, we employ plsito estimate the membership degree of each document to each topic, and then classify the search results into topics using this information.
</nextsent>
<nextsent>in thesame way, we employ plsi to estimate the membership degree of each keyword to each topic,and then extract the important sentences specific to each topic using this information in order to reduce the redundancy between summaries.the evaluation results show that our method performs well in classifying search results and successfully reduces the redundancy between summaries.
</nextsent>
<nextsent>d      dz
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG979">
<title id=" W10-3903.xml">summarizing search results using plsi </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>in fig.3, the colored words in the summaries are keywords specific to each topic.
</prevsent>
<prevsent>if user click son keyword, the system presents list of documents containing that keyword at the bottom of the browser.the configuration of our system was as follows.
</prevsent>
</prevsection>
<citsent citstr=" L08-1417 ">
in the acquisition process, the system obtained the search results forgiven query using the search engine tsubaki (shinzato et al, 2008<papid> L08-1417 </papid>b).</citsent>
<aftsection>
<nextsent>setting ? = 1, 000, we obtained the top 1, 000 documents in the search results for the query.
</nextsent>
<nextsent>in the keyword extraction process, we set = 100, and extracted 100 keywords related to the query from the search results.
</nextsent>
<nextsent>in the document clustering process, we performed plsi for = 3, 4, 5, and selected the with the minimum aic.
</nextsent>
<nextsent>we set the initial value of p(z) = 1/k, and the initial values of p(d|z) and p(w|z) to random values.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG983">
<title id=" W10-3903.xml">summarizing search results using plsi </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>between summaries third, we investigated how well the proposed method reduced the redundancy between summaries.
</prevsent>
<prevsent>to be more precise, we used three measures as score(z, w) to generate summaries and investigated which measure generated the least redundant summaries.
</prevsent>
</prevsection>
<citsent citstr=" W04-1013 ">
generally, methods for reducing redundancy are evaluated using rouge (lin, 2004), <papid> W04-1013 </papid>be (hovy et al, 2005), or pyramid (nenkova and passonneau, 2004).<papid> N04-1019 </papid></citsent>
<aftsection>
<nextsent>however, the use of these methods require that ideal summaries are created by humans, and thiswas not possible for the same reason as mentioned previously.
</nextsent>
<nextsent>thus, we did not perform direct evaluation using the methods such as rouge, but instead evaluated how well our method performed in reducing redundancy between summaries using the membership degree p(z|w) as score(z, w).
</nextsent>
<nextsent>the evaluation process was as follows.
</nextsent>
<nextsent>weused three measures as score(z, w), and generated three sets of summaries.summaries this set of summaries was generated using dfidf(w) as score(z, w), with dfidf(w) calculated as ldf(w) log(100million/gdf(w)), ldf(w) representing the document frequency of keywordw in the search results, and gdf(w) representing the document frequency of keyword in the tsubaki document collection (shinzato et al, 2008<papid> L08-1417 </papid>a) comprising about 100 million documents.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG984">
<title id=" W10-3903.xml">summarizing search results using plsi </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>between summaries third, we investigated how well the proposed method reduced the redundancy between summaries.
</prevsent>
<prevsent>to be more precise, we used three measures as score(z, w) to generate summaries and investigated which measure generated the least redundant summaries.
</prevsent>
</prevsection>
<citsent citstr=" N04-1019 ">
generally, methods for reducing redundancy are evaluated using rouge (lin, 2004), <papid> W04-1013 </papid>be (hovy et al, 2005), or pyramid (nenkova and passonneau, 2004).<papid> N04-1019 </papid></citsent>
<aftsection>
<nextsent>however, the use of these methods require that ideal summaries are created by humans, and thiswas not possible for the same reason as mentioned previously.
</nextsent>
<nextsent>thus, we did not perform direct evaluation using the methods such as rouge, but instead evaluated how well our method performed in reducing redundancy between summaries using the membership degree p(z|w) as score(z, w).
</nextsent>
<nextsent>the evaluation process was as follows.
</nextsent>
<nextsent>weused three measures as score(z, w), and generated three sets of summaries.summaries this set of summaries was generated using dfidf(w) as score(z, w), with dfidf(w) calculated as ldf(w) log(100million/gdf(w)), ldf(w) representing the document frequency of keywordw in the search results, and gdf(w) representing the document frequency of keyword in the tsubaki document collection (shinzato et al, 2008<papid> L08-1417 </papid>a) comprising about 100 million documents.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG989">
<title id=" W10-1710.xml">fbk at wmt 2010 word lattices for morphological reduction and chunk based reordering </title>
<section> system overview.  </section>
<citcontext>
<prevsection>
<prevsent>in the remainder of this section,an overview of the common features of our systems will be given.
</prevsent>
<prevsent>the next two sections provide more detailed description of our approaches to language modelling, morphological preprocessing and word reordering.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
both of our systems were based on the moses decoder (koehn et al, 2007).<papid> P07-2045 </papid></citsent>
<aftsection>
<nextsent>they were similar to the wmt 2010 moses baseline system.
</nextsent>
<nextsent>instead of lower casing the training data and adding re casing step, we retained the data in document case throughout our system, except for the morphologically normalised word forms described in section 3.
</nextsent>
<nextsent>our phrase tables were trained with the standard moses training script, then filtered based on statistical significance according to the method described by johnson et al (2007).<papid> D07-1103 </papid></nextsent>
<nextsent>finally, we used minimum bayes risk decoding (kumar and byrne, 2004) <papid> N04-1022 </papid>based on the bleu score (papineni et al, 2002).<papid> P02-1040 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG990">
<title id=" W10-1710.xml">fbk at wmt 2010 word lattices for morphological reduction and chunk based reordering </title>
<section> system overview.  </section>
<citcontext>
<prevsection>
<prevsent>they were similar to the wmt 2010 moses baseline system.
</prevsent>
<prevsent>instead of lower casing the training data and adding re casing step, we retained the data in document case throughout our system, except for the morphologically normalised word forms described in section 3.
</prevsent>
</prevsection>
<citsent citstr=" D07-1103 ">
our phrase tables were trained with the standard moses training script, then filtered based on statistical significance according to the method described by johnson et al (2007).<papid> D07-1103 </papid></citsent>
<aftsection>
<nextsent>finally, we used minimum bayes risk decoding (kumar and byrne, 2004) <papid> N04-1022 </papid>based on the bleu score (papineni et al, 2002).<papid> P02-1040 </papid></nextsent>
<nextsent>at the 2009 nist mt evaluation, our system obtained good results using mixture of linearly interpolated language models (lms) combining data from different sources.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG991">
<title id=" W10-1710.xml">fbk at wmt 2010 word lattices for morphological reduction and chunk based reordering </title>
<section> system overview.  </section>
<citcontext>
<prevsection>
<prevsent>instead of lower casing the training data and adding re casing step, we retained the data in document case throughout our system, except for the morphologically normalised word forms described in section 3.
</prevsent>
<prevsent>our phrase tables were trained with the standard moses training script, then filtered based on statistical significance according to the method described by johnson et al (2007).<papid> D07-1103 </papid></prevsent>
</prevsection>
<citsent citstr=" N04-1022 ">
finally, we used minimum bayes risk decoding (kumar and byrne, 2004) <papid> N04-1022 </papid>based on the bleu score (papineni et al, 2002).<papid> P02-1040 </papid></citsent>
<aftsection>
<nextsent>at the 2009 nist mt evaluation, our system obtained good results using mixture of linearly interpolated language models (lms) combining data from different sources.
</nextsent>
<nextsent>as the training data provided for the present evaluation campaign again included large set of language modelling corpora from different sources, especially for english as target language, we decided to adopt the same strategy.
</nextsent>
<nextsent>the partial corpora for english and their sizes can be found in table 1.
</nextsent>
<nextsent>our base models of the english gigaword texts were trained on version 3 of the corpus (ldc2007t07).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG992">
<title id=" W10-1710.xml">fbk at wmt 2010 word lattices for morphological reduction and chunk based reordering </title>
<section> system overview.  </section>
<citcontext>
<prevsection>
<prevsent>instead of lower casing the training data and adding re casing step, we retained the data in document case throughout our system, except for the morphologically normalised word forms described in section 3.
</prevsent>
<prevsent>our phrase tables were trained with the standard moses training script, then filtered based on statistical significance according to the method described by johnson et al (2007).<papid> D07-1103 </papid></prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
finally, we used minimum bayes risk decoding (kumar and byrne, 2004) <papid> N04-1022 </papid>based on the bleu score (papineni et al, 2002).<papid> P02-1040 </papid></citsent>
<aftsection>
<nextsent>at the 2009 nist mt evaluation, our system obtained good results using mixture of linearly interpolated language models (lms) combining data from different sources.
</nextsent>
<nextsent>as the training data provided for the present evaluation campaign again included large set of language modelling corpora from different sources, especially for english as target language, we decided to adopt the same strategy.
</nextsent>
<nextsent>the partial corpora for english and their sizes can be found in table 1.
</nextsent>
<nextsent>our base models of the english gigaword texts were trained on version 3 of the corpus (ldc2007t07).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG993">
<title id=" W10-1710.xml">fbk at wmt 2010 word lattices for morphological reduction and chunk based reordering </title>
<section> morphological reduction and.  </section>
<citcontext>
<prevsection>
<prevsent>as side effect, gertwol outputs the base formsof all words that it processes: nominative singular of nouns, infinitive of verbs etc. we decided to combine the tokens analysed by gertwol, whether or not they had been decompounded and lower cased, in further attempt to reduce data sparseness, with their original form in word lattice (see fig.
</prevsent>
<prevsent>1) and to let the decoder make the choice between the two according to the translations the phrase table can provide for each.
</prevsent>
</prevsection>
<citsent citstr=" P08-1115 ">
our word lattices are similar to those used by dyer et al (2008) <papid> P08-1115 </papid>for handling word segmentation in chinese and arabic.</citsent>
<aftsection>
<nextsent>for each word that was segmented by gertwol, we provide exactly oneal ternative edge labelled with the component word sand base forms as identified by gertwol, after removing linking morphemes.
</nextsent>
<nextsent>the edge transition probabilities are used to identify the source of anedge: their values are e1 = 0.36788 for edges deriving from gertwol analysis and e0 = 1 for edges carrying unprocessed words.
</nextsent>
<nextsent>tokens whose de compounded base form according to gertwol is identical to the surface form in the input are represented by single edge with transition probability e0.5 = 0.606531.
</nextsent>
<nextsent>these transition probabilities translate into binary feature with values1, 0.5 and 0 after taking logarithms in the decoder.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG994">
<title id=" W10-1710.xml">fbk at wmt 2010 word lattices for morphological reduction and chunk based reordering </title>
<section> morphological reduction and.  </section>
<citcontext>
<prevsection>
<prevsent>tokens whose de compounded base form according to gertwol is identical to the surface form in the input are represented by single edge with transition probability e0.5 = 0.606531.
</prevsent>
<prevsent>these transition probabilities translate into binary feature with values1, 0.5 and 0 after taking logarithms in the decoder.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
the feature weight is determined by minimum error-rate training (och, 2003), <papid> P03-1021 </papid>together with the weights of the other feature functions used in the decoder.</citsent>
<aftsection>
<nextsent>during system training, the processed version of the training corpus was con catenated with the unprocessed text.
</nextsent>
<nextsent>experiments show that decompounding and morphological analysis have significant impact on the performance of the mt system.
</nextsent>
<nextsent>after these steps, the oov rate of the newstest2009test set decreases from 5.88% to 3.21%.
</nextsent>
<nextsent>using only the news language model, the bleu score of our development system (measured on the newstest2009 corpus) increases from 18.77 to 19.31.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG995">
<title id=" W10-1710.xml">fbk at wmt 2010 word lattices for morphological reduction and chunk based reordering </title>
<section> word reordering.  </section>
<citcontext>
<prevsection>
<prevsent>the result is modest gain from 14.28 to 14.38 bleu points (newstest2009).
</prevsent>
<prevsent>in the german-english system, we applied achunk-based technique to produce lattices representing multiple permutations of the test sentences in order to enable long-range reorderings of verbphrases.
</prevsent>
</prevsection>
<citsent citstr=" W09-0435 ">
this approach is similar to the reordering technique based on part-of-speech tags presented by niehues and kolss (2009), <papid> W09-0435 </papid>which results in the addition of large number of reordering paths to the lattices.</citsent>
<aftsection>
<nextsent>by contrast, we assume that verb reorderings only occur between shallow syntax chunks, and not within them.
</nextsent>
<nextsent>this makes it possible to limit the number of long-range reordering options in an effective way.
</nextsent>
<nextsent>we used the tree tagger to perform shallow syntax chunking of the german text.
</nextsent>
<nextsent>by man 90 figure 1: word lattice for morphological reduction sonst [drohe]vc , dass auch [weitere lnder]nc [vom einbruch]pc [betroffen sein wrden]vc . figure 2: chunk reordering lattice bleu test-09 test-10 baseline 18.77 20.1 + chunk-based reordering 18.94 20.3 morphological reduction 19.31 20.6 + chunk-based reordering 19.79 21.1 note: only news lm, case-sensitive evaluation table 5: results with morphological reduction and chunk reordering on news test 2009/2010ual inspection of data sample, we then identified few recurrent patterns of long reorderings involving the verbs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG996">
<title id=" W10-1710.xml">fbk at wmt 2010 word lattices for morphological reduction and chunk based reordering </title>
<section> conclusions.  </section>
<citcontext>
<prevsection>
<prevsent>by doing so, we hope to overcome the current limitations and exploit the power of language model mixtures more fully.
</prevsent>
<prevsent>the gertwol-based morphological reduction and decompounding component we used is aworking solution that results insignificant improvement in translation quality.
</prevsent>
</prevsection>
<citsent citstr=" E03-1076 ">
it is an alternative to the popular statistical compound splitting methods, such as the one by koehn and knight(2003), <papid> E03-1076 </papid>incorporating greater amount of linguistic knowledge and offering morphological reduction even of simplex words to their base form in addition.</citsent>
<aftsection>
<nextsent>it would be interesting to compare the relative performance of the two approaches systematically.
</nextsent>
<nextsent>word reordering between german and english is complex problem.
</nextsent>
<nextsent>encouraged by the success of chunk-based verb reordering lattices on arabic english (bisazza and federico, 2010), we tried to adapt the same approach to the german-english language pair.
</nextsent>
<nextsent>it turned out that there is larger variety of long reordering patterns in this case.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG997">
<title id=" W10-1104.xml">using domain knowledge about medications to correct recognition errors in medical report creation </title>
<section> extraction of medication information,.  </section>
<citcontext>
<prevsection>
<prevsent>limited domains seem to bemore rewarding with regard to coverage and performance.
</prevsent>
<prevsent>consequently, combining speech recognition and speech understanding has so far mostly resulted in applications in the field of dialogue systems where knowledge about the domain is represented in terms of the underlying database, e.g.
</prevsent>
</prevsection>
<citsent citstr=" W00-0303 ">
(seneff and polifroni, 2000).<papid> W00-0303 </papid>several approaches have investigated the potential of improving the mapping between the user utterance and the underlying database by construct inga representation of the utterance meaning.</citsent>
<aftsection>
<nextsent>meaning analysis is either separate post-processing step or an integral part of the recognition process.
</nextsent>
<nextsent>in some approaches, the recognition result is analyzed with regards to content to support the dialogue manager in dealing with inconsistencies (macherey et al., 2003).
</nextsent>
<nextsent>as far as dictated input is concerned, which is not controlled by dialogue manager, (voll,2006) developed post-asr error-detection mechanism for radiology reports.
</nextsent>
<nextsent>the hybrid approach uses statistical as well as rule-based methods.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG998">
<title id=" W10-1104.xml">using domain knowledge about medications to correct recognition errors in medical report creation </title>
<section> extraction of medication information,.  </section>
<citcontext>
<prevsection>
<prevsent>(gurevych and porzel, 2003; gurevych et al, 2003)present rescoring approach where the hypotheses in the word graph are reordered according to semantic information.
</prevsent>
<prevsent>usually, conceptual parsers are employed which construct parse tree of concepts representing the input text for mapping between the recognition result and the underlying representation.
</prevsent>
</prevsection>
<citsent citstr=" N04-3011 ">
semantic language modeling (wangetal., 2004; <papid> N04-3011 </papid>buehler et al, 2005) enhances the language model to incorporate sequences of concepts which are considered coherent and typical for specific context.</citsent>
<aftsection>
<nextsent>in these approaches, the representations of the underlying knowledge are created specially for the applications or are derived from text corpus.
</nextsent>
<nextsent>in our approach, we aim at developing prototype 23 for integrating available knowledge sources into the analysis of the word graph during the recognitionprocess.
</nextsent>
<nextsent>we have decided not to integrate the component directly into the asr system but to introduce separate post-processing step for the recognition of information about medications with the word graph sas interface.
</nextsent>
<nextsent>this makes it easier to update themed ication knowledge base, e.g. if new medications are released.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG999">
<title id=" W10-2412.xml">mining transliterations from wikipedia using pair hmms </title>
<section> ministers for ?????????:????????.  </section>
<citcontext>
<prevsection>
<prevsent>we employ the pair hmm approach to estimate transliteration similarity for candidate source-target language words.
</prevsent>
<prevsent>a pair hmm has an emission state or states that generate two observation sequences instead of one observation sequence as is the case in standardhmms.
</prevsent>
</prevsection>
<citsent citstr=" W05-0606 ">
pair hmms originate from work in biological sequence analysis (durbin et al, 1998; rivas and eddy, 2001) from which variants we recreated and successfully applied in cognate identification (mackay and kondrak, 2005), <papid> W05-0606 </papid>dutch dialect comparison (wieling et al, 2007), <papid> W07-1307 </papid>transliteration identification (nabende et al, 2010), and transliteration generation (nabende, 2009).<papid> W09-3522 </papid></citsent>
<aftsection>
<nextsent>as mentioned earlier, we have first, tested twopair hmm variants on manually verified english russian datasets which we obtain from the previous shared task on machine transliteration (news2009) (kumaran and kellner, 2007).
</nextsent>
<nextsent>this preliminary test is aimed at determining the effect of pair hmm parameter changes on the quality of the transliteration similarity estimates.
</nextsent>
<nextsent>for the first pair hmm variant, no transitions are modeled between edit states; we only use trans tion parameters associated with transiting from start state to each of the edit operation states, and from each of the edit operation states to an end state.
</nextsent>
<nextsent>the m end 1-?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1000">
<title id=" W10-2412.xml">mining transliterations from wikipedia using pair hmms </title>
<section> ministers for ?????????:????????.  </section>
<citcontext>
<prevsection>
<prevsent>we employ the pair hmm approach to estimate transliteration similarity for candidate source-target language words.
</prevsent>
<prevsent>a pair hmm has an emission state or states that generate two observation sequences instead of one observation sequence as is the case in standardhmms.
</prevsent>
</prevsection>
<citsent citstr=" W07-1307 ">
pair hmms originate from work in biological sequence analysis (durbin et al, 1998; rivas and eddy, 2001) from which variants we recreated and successfully applied in cognate identification (mackay and kondrak, 2005), <papid> W05-0606 </papid>dutch dialect comparison (wieling et al, 2007), <papid> W07-1307 </papid>transliteration identification (nabende et al, 2010), and transliteration generation (nabende, 2009).<papid> W09-3522 </papid></citsent>
<aftsection>
<nextsent>as mentioned earlier, we have first, tested twopair hmm variants on manually verified english russian datasets which we obtain from the previous shared task on machine transliteration (news2009) (kumaran and kellner, 2007).
</nextsent>
<nextsent>this preliminary test is aimed at determining the effect of pair hmm parameter changes on the quality of the transliteration similarity estimates.
</nextsent>
<nextsent>for the first pair hmm variant, no transitions are modeled between edit states; we only use trans tion parameters associated with transiting from start state to each of the edit operation states, and from each of the edit operation states to an end state.
</nextsent>
<nextsent>the m end 1-?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1001">
<title id=" W10-2412.xml">mining transliterations from wikipedia using pair hmms </title>
<section> ministers for ?????????:????????.  </section>
<citcontext>
<prevsection>
<prevsent>we employ the pair hmm approach to estimate transliteration similarity for candidate source-target language words.
</prevsent>
<prevsent>a pair hmm has an emission state or states that generate two observation sequences instead of one observation sequence as is the case in standardhmms.
</prevsent>
</prevsection>
<citsent citstr=" W09-3522 ">
pair hmms originate from work in biological sequence analysis (durbin et al, 1998; rivas and eddy, 2001) from which variants we recreated and successfully applied in cognate identification (mackay and kondrak, 2005), <papid> W05-0606 </papid>dutch dialect comparison (wieling et al, 2007), <papid> W07-1307 </papid>transliteration identification (nabende et al, 2010), and transliteration generation (nabende, 2009).<papid> W09-3522 </papid></citsent>
<aftsection>
<nextsent>as mentioned earlier, we have first, tested twopair hmm variants on manually verified english russian datasets which we obtain from the previous shared task on machine transliteration (news2009) (kumaran and kellner, 2007).
</nextsent>
<nextsent>this preliminary test is aimed at determining the effect of pair hmm parameter changes on the quality of the transliteration similarity estimates.
</nextsent>
<nextsent>for the first pair hmm variant, no transitions are modeled between edit states; we only use trans tion parameters associated with transiting from start state to each of the edit operation states, and from each of the edit operation states to an end state.
</nextsent>
<nextsent>the m end 1-?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1002">
<title id=" W10-1756.xml">a unified approach to minimum risk training and decoding </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>by comparing our approach to lattice mbr, we are also able to gain crucial insights about both methods.
</prevsent>
<prevsent>according to statistical decision theory, the optimal decision rule for any statistical model is the solution that minimizes its risk (expected loss).
</prevsent>
</prevsection>
<citsent citstr=" N04-1022 ">
this solution is often referred to as the minimum bayes risk (mbr) solution (kumar and byrne,2004).<papid> N04-1022 </papid></citsent>
<aftsection>
<nextsent>since machine translation (mt) models are typically evaluated by bleu (papineni et al., 2002), <papid> P02-1040 </papid>loss function which rewards partial matches, the mbr solution is to be preferred to the maximum posteriori (map) solution.</nextsent>
<nextsent>in most statistical mt (smt) systems, mbris implemented as reranker of list1 of translations generated by first-pass decoder.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1003">
<title id=" W10-1756.xml">a unified approach to minimum risk training and decoding </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>according to statistical decision theory, the optimal decision rule for any statistical model is the solution that minimizes its risk (expected loss).
</prevsent>
<prevsent>this solution is often referred to as the minimum bayes risk (mbr) solution (kumar and byrne,2004).<papid> N04-1022 </papid></prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
since machine translation (mt) models are typically evaluated by bleu (papineni et al., 2002), <papid> P02-1040 </papid>loss function which rewards partial matches, the mbr solution is to be preferred to the maximum posteriori (map) solution.</citsent>
<aftsection>
<nextsent>in most statistical mt (smt) systems, mbris implemented as reranker of list1 of translations generated by first-pass decoder.
</nextsent>
<nextsent>this decoder typically assigns un normalised log probabilities (known as scores) to each translation hypoth1we use the term list to denote any enumerable representation of translation hypotheses e.g n-best list, translation lattice or forest.esis, so these scores must be converted to probabilities in order to apply mbr.
</nextsent>
<nextsent>in order to perform this conversion, it is first necessary to compute the normalization function z. since is defined as an intractable sum over all possible translations, it is approximated by summing over the translations in the list.
</nextsent>
<nextsent>the second step is to find the correct scale factor for the scores using hyper-parameter search over held-out data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1004">
<title id=" W10-1756.xml">a unified approach to minimum risk training and decoding </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in order to perform this conversion, it is first necessary to compute the normalization function z. since is defined as an intractable sum over all possible translations, it is approximated by summing over the translations in the list.
</prevsent>
<prevsent>the second step is to find the correct scale factor for the scores using hyper-parameter search over held-out data.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
this is needed because the model parameters for the first-pass decoder are normally learnt using mert (och, 2003), <papid> P03-1021 </papid>which is in variant under scaling of the scores.</citsent>
<aftsection>
<nextsent>both these steps are theoretically unsatisfactory methods of estimating the posterior probability distribution since the approximation to is an unbounded term and the scaling factor is an artificial way of inducing probability distribution.
</nextsent>
<nextsent>recently, (tromble et al, 2008; <papid> D08-1065 </papid>kumar et al,2009) <papid> P09-1019 </papid>have shown that using search lattice to improve the estimation of the true probability distribution can lead to improved mbr performance.</nextsent>
<nextsent>however, these approaches still relyon mert for training the base model, and in fact introduce several extra parameters which must also be estimated using either grid search or second mert run.the lattice pruning required to make these techniques tractable is quite drastic, and is in addition to the pruning already performed during the search.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1005">
<title id=" W10-1756.xml">a unified approach to minimum risk training and decoding </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this is needed because the model parameters for the first-pass decoder are normally learnt using mert (och, 2003), <papid> P03-1021 </papid>which is in variant under scaling of the scores.</prevsent>
<prevsent>both these steps are theoretically unsatisfactory methods of estimating the posterior probability distribution since the approximation to is an unbounded term and the scaling factor is an artificial way of inducing probability distribution.</prevsent>
</prevsection>
<citsent citstr=" D08-1065 ">
recently, (tromble et al, 2008; <papid> D08-1065 </papid>kumar et al,2009) <papid> P09-1019 </papid>have shown that using search lattice to improve the estimation of the true probability distribution can lead to improved mbr performance.</citsent>
<aftsection>
<nextsent>however, these approaches still relyon mert for training the base model, and in fact introduce several extra parameters which must also be estimated using either grid search or second mert run.the lattice pruning required to make these techniques tractable is quite drastic, and is in addition to the pruning already performed during the search.
</nextsent>
<nextsent>such extensive pruning is liable to render any probability estimates heavily biased (blunsom and osborne, 2008; <papid> D08-1023 </papid>bouchard-cote?</nextsent>
<nextsent>et al, 2009).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1006">
<title id=" W10-1756.xml">a unified approach to minimum risk training and decoding </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this is needed because the model parameters for the first-pass decoder are normally learnt using mert (och, 2003), <papid> P03-1021 </papid>which is in variant under scaling of the scores.</prevsent>
<prevsent>both these steps are theoretically unsatisfactory methods of estimating the posterior probability distribution since the approximation to is an unbounded term and the scaling factor is an artificial way of inducing probability distribution.</prevsent>
</prevsection>
<citsent citstr=" P09-1019 ">
recently, (tromble et al, 2008; <papid> D08-1065 </papid>kumar et al,2009) <papid> P09-1019 </papid>have shown that using search lattice to improve the estimation of the true probability distribution can lead to improved mbr performance.</citsent>
<aftsection>
<nextsent>however, these approaches still relyon mert for training the base model, and in fact introduce several extra parameters which must also be estimated using either grid search or second mert run.the lattice pruning required to make these techniques tractable is quite drastic, and is in addition to the pruning already performed during the search.
</nextsent>
<nextsent>such extensive pruning is liable to render any probability estimates heavily biased (blunsom and osborne, 2008; <papid> D08-1023 </papid>bouchard-cote?</nextsent>
<nextsent>et al, 2009).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1007">
<title id=" W10-1756.xml">a unified approach to minimum risk training and decoding </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recently, (tromble et al, 2008; <papid> D08-1065 </papid>kumar et al,2009) <papid> P09-1019 </papid>have shown that using search lattice to improve the estimation of the true probability distribution can lead to improved mbr performance.</prevsent>
<prevsent>however, these approaches still relyon mert for training the base model, and in fact introduce several extra parameters which must also be estimated using either grid search or second mert run.the lattice pruning required to make these techniques tractable is quite drastic, and is in addition to the pruning already performed during the search.</prevsent>
</prevsection>
<citsent citstr=" D08-1023 ">
such extensive pruning is liable to render any probability estimates heavily biased (blunsom and osborne, 2008; <papid> D08-1023 </papid>bouchard-cote?</citsent>
<aftsection>
<nextsent>et al, 2009).
</nextsent>
<nextsent>here, we present unified approach to training and decoding in phrase-based translation model (koehn et al, 2003) which keeps the objective constant across the translation pipeline and so obviates the need for any extra hyper-parameter fitting.
</nextsent>
<nextsent>we use the phrase-based gibbs sampler of arun et al (2009)<papid> W09-1114 </papid>at training time to compute the gradient of our minimum risk training objective in order to apply first-order optimization techniques, 365 and at test time we use it to estimate the posterior distribution required by mbr (section 3).</nextsent>
<nextsent>we experimented with two different objective functions for training (section 4).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1008">
<title id=" W10-1756.xml">a unified approach to minimum risk training and decoding </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>et al, 2009).
</prevsent>
<prevsent>here, we present unified approach to training and decoding in phrase-based translation model (koehn et al, 2003) which keeps the objective constant across the translation pipeline and so obviates the need for any extra hyper-parameter fitting.
</prevsent>
</prevsection>
<citsent citstr=" W09-1114 ">
we use the phrase-based gibbs sampler of arun et al (2009)<papid> W09-1114 </papid>at training time to compute the gradient of our minimum risk training objective in order to apply first-order optimization techniques, 365 and at test time we use it to estimate the posterior distribution required by mbr (section 3).</citsent>
<aftsection>
<nextsent>we experimented with two different objective functions for training (section 4).
</nextsent>
<nextsent>first, following (arun et al, 2009), <papid> W09-1114 </papid>we define our objective at the sentence-level using sentence-level variant of bleu.</nextsent>
<nextsent>then, in order to reduce the mismatch between training and test loss functions, we also tried directly optimising the expected corpus level bleu, where we introduce novel sampling technique, which we call corpus sampling to calculate the required expectations.the methods presented in this paper are theoretically sound.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1011">
<title id=" W10-1756.xml">a unified approach to minimum risk training and decoding </title>
<section> inference methods for mt.  </section>
<citcontext>
<prevsection>
<prevsent>first, the error incurred by the viterbi maximum with respect to the true model maximum is unbounded.
</prevsent>
<prevsent>second, the dp solution requires substantial pruning and restricts the use of non-local features.
</prevsent>
</prevsection>
<citsent citstr=" P09-1067 ">
the latter problem persists even in the variational approximations of li et al (2009), <papid> P09-1067 </papid>which attempt to solve the former.</citsent>
<aftsection>
<nextsent>2.1 gibbs sampling for phrase-based mt. an alternate approximate inference method for phrase-based mt without any of the previously mentioned drawbacks is the gibbs sampler (ge man and geman, 1984) of arun et al (2009)<papid> W09-1114 </papid>which draws samples from the posterior distribution of the translation model.</nextsent>
<nextsent>for the work presented in this paper, we use this sampler.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1015">
<title id=" W10-1756.xml">a unified approach to minimum risk training and decoding </title>
<section> minimum risk training.  </section>
<citcontext>
<prevsection>
<prevsent>because of the noise introduced by the sampler, we used stochastic gradient descent (sgd), with learning rate that gets updated after each step proportionally to difference in successive gradients (schraudolph, 1999).
</prevsent>
<prevsent>while our initial formulation of minimum risk training is similar to that of arun et al (2009)<papid> W09-1114 </papid>, in preliminary experiments we observed tendency for translation performance on held-out data to quickly increase to maximum and then plateau.hypothesizing that we were being trapped in local maxima as is non-convex, we decided to employ deterministic annealing (rose, 1998) to smooth the objective function to ensure that the optimizer explored as large region as possible of the space before it settled on an optimal weight set.</prevsent>
</prevsection>
<citsent citstr=" P06-2101 ">
our instantiation of deterministic annealing (da) is based on the work of smith and eisner (2006), <papid> P06-2101 </papid>and involves the addition of an entropic prior to the objective in equation 5 to give g?</citsent>
<aftsection>
<nextsent>= ? e?,fd [( ? e,a p(e, a|f)bleue?(e) ) + t.h(p) ]where h(p) is the entropy of the probability distribution p(e, a|f), and   0 is temperatureparamater which is gradually lowered as the optimization progresses according to some annealing schedule.
</nextsent>
<nextsent>differentiating with respect to then shows that the annealed gradient is given by the following expression: ? e?,f? ? e,a (bleue?(e)?
</nextsent>
<nextsent>t (1 + log p)) k where k = ( hk ? ep(e,a|f)[hk] ) p(e, a|f) high value of leads the optimizer to find weights which describe fairly flat distribution, whereas lower value of pushes the optimizer towards more peaked distribution.
</nextsent>
<nextsent>we perform 10 to 20 iterations of sgd at each temperature.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1019">
<title id=" W10-1756.xml">a unified approach to minimum risk training and decoding </title>
<section> minimum risk training.  </section>
<citcontext>
<prevsection>
<prevsent>t (1 + log p)) k where k = ( hk ? ep(e,a|f)[hk] ) p(e, a|f) high value of leads the optimizer to find weights which describe fairly flat distribution, whereas lower value of pushes the optimizer towards more peaked distribution.
</prevsent>
<prevsent>we perform 10 to 20 iterations of sgd at each temperature.
</prevsent>
</prevsection>
<citsent citstr=" D09-1005 ">
in their deterministic annealing formulation,(smith and eisner, 2006; <papid> P06-2101 </papid>li and eisner, 2009), <papid> D09-1005 </papid>express the parameterization of the distribution ? as???</citsent>
<aftsection>
<nextsent>(where ? is the scaling factor) and perform optimization in two steps, the first optimizing ??
</nextsent>
<nextsent>and the second optimizing ?.
</nextsent>
<nextsent>we experimented with this two stage optimization process, but found that simply performing an unconstrained optimization on ? gave better results.
</nextsent>
<nextsent>4.2 corpus sampling.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1020">
<title id=" W10-1756.xml">a unified approach to minimum risk training and decoding </title>
<section> minimum risk training.  </section>
<citcontext>
<prevsection>
<prevsent>4.2 corpus sampling.
</prevsent>
<prevsent>while the objective functions in equations 5 and 4.1 use sentence-level variant of bleu, the models test-time performance is evaluated with corpus level bleu.
</prevsent>
</prevsection>
<citsent citstr=" D08-1064 ">
the lack of correlation between sentence-level bleu and corpus bleu is well-known (chiang et al, 2008<papid> D08-1064 </papid>a).</citsent>
<aftsection>
<nextsent>therefore, in an effort to address this issue, we tried maximizing expected corpus bleu directly.
</nextsent>
<nextsent>in other words, given training corpus of theform cf , ce??
</nextsent>
<nextsent>where cf is set of source sentences and ce?
</nextsent>
<nextsent>its corresponding reference translations, we consider gain function defined on the 367 hypothesized translation ce of the input cf with respect to ce?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1022">
<title id=" W10-1756.xml">a unified approach to minimum risk training and decoding </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>final testing was performed on news-dev2009b (out-of-domain) and the first half of test2008 (in-domain).
</prevsent>
<prevsent>for the arabic system, the mt02 set (10 reference translations) was used for tuning and mt03 and mt05 (4 reference translations, each) were used for held-out testing and final testing respectively.
</prevsent>
</prevsection>
<citsent citstr=" D07-1103 ">
to reduce the size of the phrase table, we used the association-score technique suggested by johnson et al (2007).<papid> D07-1103 </papid></citsent>
<aftsection>
<nextsent>translation quality is reported using case-insensitive bleu.
</nextsent>
<nextsent>5.2 baseline.
</nextsent>
<nextsent>our baseline system is phrase-based moses (koehn et al, 2007) <papid> P07-2045 </papid>with feature weights trained using mert.</nextsent>
<nextsent>moses and the gibbs sampler use identical feature sets.4the mert optimization algorithm uses multiple random restarts to avoid getting stuck in poor local optima.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1023">
<title id=" W10-1756.xml">a unified approach to minimum risk training and decoding </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>translation quality is reported using case-insensitive bleu.
</prevsent>
<prevsent>5.2 baseline.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
our baseline system is phrase-based moses (koehn et al, 2007) <papid> P07-2045 </papid>with feature weights trained using mert.</citsent>
<aftsection>
<nextsent>moses and the gibbs sampler use identical feature sets.4the mert optimization algorithm uses multiple random restarts to avoid getting stuck in poor local optima.
</nextsent>
<nextsent>therefore, every time mert is run, it produces slightly different final weight vector leading to varying test set results.
</nextsent>
<nextsent>while this characteristic of mert is typically ignored, we account for it by performing mert training 10 times for each of the 3 language pairs, decoding the test sets with each of the 10 optimized weight sets.
</nextsent>
<nextsent>we present the best and the worst test set results along with the mean and the standard deviation (?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1028">
<title id=" W10-1756.xml">a unified approach to minimum risk training and decoding </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>with the addition of the entropic prior, the model is slow to converge before the so-called phase transition occurs (usually after around 50 iterations), after which performance goes up to reach peak (45.2 bleu) higher than that without the prior (44.2 bleu), before steadily declining.
</prevsent>
<prevsent>the entropic prior encourages diversity among the sample set, especially at high temperature settings.
</prevsent>
</prevsection>
<citsent citstr=" P08-1024 ">
in the presence of diversity, the benefits of marginalization over derivations is clear: max trans does better than maxderiv and mbr does best, confirm recent findings of (blunsom et al, 2008; <papid> P08-1024 </papid>arun et al, 2009) <papid> W09-1114 </papid>that max trans improves over maxderiv decoding for models trained to account for multiple derivations.</citsent>
<aftsection>
<nextsent>as the temperature decreases to zero, the model sharpens, effectively intent on maximizing one-best performance and thus voiding the benefits of max trans and mbr.
</nextsent>
<nextsent>figures 2 and 3 also show that corpus sampling improves over sentence sampling, although not by much (+ 0.3 bleu).
</nextsent>
<nextsent>5.6 comparison with mert baseline.
</nextsent>
<nextsent>having established the superiority of the pipeline of expected corpus bleu training with da followed by mbr decoding over other alternatives considered, we compare it to the best results obtained with mert optimized moses (bold scores from table 1).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1033">
<title id=" W10-1756.xml">a unified approach to minimum risk training and decoding </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>our proposed corpus sampling technique, like mert, is able to optimize corpus bleu directly whereas alternate parameter estimation techniques usually employed in smt optimize approximations ofbleu.
</prevsent>
<prevsent>chiang et al (2008<papid> D08-1064 </papid>b) accounts for the on line nature of the mira optimization algorithm by smoothing the sentence-level bleu precision counts of translation with weighted average ofthe precision counts of previously decoded sentences, thus approximating corpus bleu.</prevsent>
</prevsection>
<citsent citstr=" D07-1055 ">
as for minimum risk training, prior implementations have either used sentence-level bleu (zens et al, 2007) <papid> D07-1055 </papid>or linear approximation to bleu (smith and eisner, 2006; <papid> P06-2101 </papid>li and eisner, 2009).<papid> D09-1005 </papid></citsent>
<aftsection>
<nextsent>at test time, the sampler works best as an mbr decoder, but also allows us to verify past claims about the benefits of marginalizing over alignments during decoding.
</nextsent>
<nextsent>we compare the sampler mbr decoders performance against mert optimized moses run under three different decoding regimes, finding that the sampler does as well or better on 4 out of 5 datasets.our training and testing pipeline has the advantage of being able to handle large number of both local and global features so we expect in the future to outperform the standard mert and dynamic programming-based search pipeline further.
</nextsent>
<nextsent>as shown in section 5.2, lattice mbr in some cases leads to marked drop in performance.
</nextsent>
<nextsent>(kumar et al, 2009) <papid> P09-1019 </papid>mention that the linear approximation to bleu used in their lattice mbr algorithm is not guaranteed to match corpus bleu, especially on unseen test sets.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1047">
<title id=" W10-1756.xml">a unified approach to minimum risk training and decoding </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>one possibility is to inter leave gibbs sampling steps using low order ngram language model distributions with metropolis-hasting steps that use higher order language model distributions.
</prevsent>
<prevsent>expected bleu training for phrase-based models has been successfully attempted by (smith and eisner, 2006; <papid> P06-2101 </papid>zens et al, 2007), <papid> D07-1055 </papid>however they both used biased n-best lists to approximate the posterior distribution.</prevsent>
</prevsection>
<citsent citstr=" J07-2003 ">
li and eisner (2009) <papid> D09-1005 </papid>present work on performing expected bleu training with deterministic annealing on translation forests generated by hiero (chiang, 2007).<papid> J07-2003 </papid></citsent>
<aftsection>
<nextsent>since bleu does not factorize over the search graph, they use the linear approximation of tromble et al (2008) <papid> D08-1065 </papid>in stead.</nextsent>
<nextsent>pauls et al (2009) <papid> D09-1147 </papid>present an alternate training criterion over translation forests called cobleu, 8up to 1081 as per tromble et al (2008) <papid> D08-1065 </papid>372 similar in spirit to expected bleu training, but aimed to maximize the expected counts of n-grams appearing in reference translations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1050">
<title id=" W10-1756.xml">a unified approach to minimum risk training and decoding </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>li and eisner (2009) <papid> D09-1005 </papid>present work on performing expected bleu training with deterministic annealing on translation forests generated by hiero (chiang, 2007).<papid> J07-2003 </papid></prevsent>
<prevsent>since bleu does not factorize over the search graph, they use the linear approximation of tromble et al (2008) <papid> D08-1065 </papid>in stead.</prevsent>
</prevsection>
<citsent citstr=" D09-1147 ">
pauls et al (2009) <papid> D09-1147 </papid>present an alternate training criterion over translation forests called cobleu, 8up to 1081 as per tromble et al (2008) <papid> D08-1065 </papid>372 similar in spirit to expected bleu training, but aimed to maximize the expected counts of n-grams appearing in reference translations.</citsent>
<aftsection>
<nextsent>this training criterion is used in conjunction with consensus decoding (denero et al, 2009), <papid> P09-1064 </papid>linear-time approximation of mbr.in contrast to the approaches above, the algorithms presented in this paper are able to exp lorean un pruned search space.</nextsent>
<nextsent>by using corpus sampling, we can perform minimum risk training with corpus bleu rather than any approximations ofthis metric.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1053">
<title id=" W10-1756.xml">a unified approach to minimum risk training and decoding </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>since bleu does not factorize over the search graph, they use the linear approximation of tromble et al (2008) <papid> D08-1065 </papid>in stead.</prevsent>
<prevsent>pauls et al (2009) <papid> D09-1147 </papid>present an alternate training criterion over translation forests called cobleu, 8up to 1081 as per tromble et al (2008) <papid> D08-1065 </papid>372 similar in spirit to expected bleu training, but aimed to maximize the expected counts of n-grams appearing in reference translations.</prevsent>
</prevsection>
<citsent citstr=" P09-1064 ">
this training criterion is used in conjunction with consensus decoding (denero et al, 2009), <papid> P09-1064 </papid>linear-time approximation of mbr.in contrast to the approaches above, the algorithms presented in this paper are able to exp lorean un pruned search space.</citsent>
<aftsection>
<nextsent>by using corpus sampling, we can perform minimum risk training with corpus bleu rather than any approximations ofthis metric.
</nextsent>
<nextsent>also, since we maintain probabilistic formulation across training and decoding, our approach does not require grid-search for scaling factor as in tromble et al (2008).<papid> D08-1065 </papid></nextsent>
<nextsent>we have presented unified approach to the taskof parameter estimation and decoding for phrase based system using the standard translation evaluation metric, bleu.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1056">
<title id=" W10-0913.xml">a hybrid approach to unsupervised relation discovery based on linguistic analysis and semantic typing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there are number of challenges involved when using facts extracted from text to enrich know ledge base (kb) with semantic relations between entities: co-reference resolution as there are many co-referent objects; entity resolution in order to link the entities mentioned in text to the right entities in the kb; handling co-referent relations, as particular semantic relation between entities can be expressed in variety of ways in the text and therefore have multiple facts associated between the entities.
</prevsent>
<prevsent>in addition, the facts extracted from linguistic analysis are usually noisy and sparse.
</prevsent>
</prevsection>
<citsent citstr=" N06-1039 ">
our work focuses on recent line of exploratory work in the direction of unrestricted relation discovery which is defined as: the automatic identification of different relations in text without specifying relation or set of relations in advance (shinyama and sekine, 2006).<papid> N06-1039 </papid></citsent>
<aftsection>
<nextsent>we use the facts which are the output of linguistic analysis from power set (www.powerset.com).
</nextsent>
<nextsent>power set is an online search engine for querying wikipedia using natural language queries.
</nextsent>
<nextsent>power set performs linguistic analysis of the sentences within wikipedia and outputs facts in the form of subject, predicate and object triples which can be queried through the online interface.
</nextsent>
<nextsent>for most entities like persons, places and things, power set shows summary of facts from across wikipedia (figure 1).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1057">
<title id=" W10-0913.xml">a hybrid approach to unsupervised relation discovery based on linguistic analysis and semantic typing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>from power set as input to our system.
</prevsent>
<prevsent>power set is wikipedia independent and can run on any corpus with well-formed sentences and hence our approach is also not limited to wikipedia.
</prevsent>
</prevsection>
<citsent citstr=" P09-1115 ">
the factz output from power set may represent relations between named entities or just nouns for example, bank of america  acquired  bank bank of america  acquired  merrill lynch bank of america  owned  building linguistic analysis has been recently described as an effective technique for relation extraction (yan et al, 2009; <papid> P09-1115 </papid>kambhatla, 2004; <papid> P04-3022 </papid>nguyen et al, 2007).<papid> N07-2032 </papid></citsent>
<aftsection>
<nextsent>following that trend, we incorporate factz, that are the output of linguistic analysis done by power set, to discover semantic relations between entities.
</nextsent>
<nextsent>information from existing knowledge re figure 1.
</nextsent>
<nextsent>demonstration of power set factz available online 105sources can help in tasks like named entity disambiguation by providing additional context in the form of linked entities in the kb and aid in linking the entities mentioned in the text to the entities in the kb.
</nextsent>
<nextsent>the kb can also provide information about the entity types which can in turn be used to discover relations between entity types at different levels of abstraction and help in enriching the kb itself.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1058">
<title id=" W10-0913.xml">a hybrid approach to unsupervised relation discovery based on linguistic analysis and semantic typing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>from power set as input to our system.
</prevsent>
<prevsent>power set is wikipedia independent and can run on any corpus with well-formed sentences and hence our approach is also not limited to wikipedia.
</prevsent>
</prevsection>
<citsent citstr=" P04-3022 ">
the factz output from power set may represent relations between named entities or just nouns for example, bank of america  acquired  bank bank of america  acquired  merrill lynch bank of america  owned  building linguistic analysis has been recently described as an effective technique for relation extraction (yan et al, 2009; <papid> P09-1115 </papid>kambhatla, 2004; <papid> P04-3022 </papid>nguyen et al, 2007).<papid> N07-2032 </papid></citsent>
<aftsection>
<nextsent>following that trend, we incorporate factz, that are the output of linguistic analysis done by power set, to discover semantic relations between entities.
</nextsent>
<nextsent>information from existing knowledge re figure 1.
</nextsent>
<nextsent>demonstration of power set factz available online 105sources can help in tasks like named entity disambiguation by providing additional context in the form of linked entities in the kb and aid in linking the entities mentioned in the text to the entities in the kb.
</nextsent>
<nextsent>the kb can also provide information about the entity types which can in turn be used to discover relations between entity types at different levels of abstraction and help in enriching the kb itself.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1059">
<title id=" W10-0913.xml">a hybrid approach to unsupervised relation discovery based on linguistic analysis and semantic typing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>from power set as input to our system.
</prevsent>
<prevsent>power set is wikipedia independent and can run on any corpus with well-formed sentences and hence our approach is also not limited to wikipedia.
</prevsent>
</prevsection>
<citsent citstr=" N07-2032 ">
the factz output from power set may represent relations between named entities or just nouns for example, bank of america  acquired  bank bank of america  acquired  merrill lynch bank of america  owned  building linguistic analysis has been recently described as an effective technique for relation extraction (yan et al, 2009; <papid> P09-1115 </papid>kambhatla, 2004; <papid> P04-3022 </papid>nguyen et al, 2007).<papid> N07-2032 </papid></citsent>
<aftsection>
<nextsent>following that trend, we incorporate factz, that are the output of linguistic analysis done by power set, to discover semantic relations between entities.
</nextsent>
<nextsent>information from existing knowledge re figure 1.
</nextsent>
<nextsent>demonstration of power set factz available online 105sources can help in tasks like named entity disambiguation by providing additional context in the form of linked entities in the kb and aid in linking the entities mentioned in the text to the entities in the kb.
</nextsent>
<nextsent>the kb can also provide information about the entity types which can in turn be used to discover relations between entity types at different levels of abstraction and help in enriching the kb itself.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1061">
<title id=" W10-0913.xml">a hybrid approach to unsupervised relation discovery based on linguistic analysis and semantic typing </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>for pairs of entities they generate basic patterns that are parts of text syntactically connected to the entity and use the predicate argument structure to make the basic patterns more generalized.
</prevsent>
<prevsent>they generate basic cluster from articles based on having similar basic patterns to represent the same event and then they cluster the basic clusters to get set of events having the same relation.
</prevsent>
</prevsection>
<citsent citstr=" P07-1030 ">
davidov et al (2007) <papid> P07-1030 </papid>developed web mining approach for discovering relations in which specified concept participates based on clustering patterns in which the concept words and other words appear.</citsent>
<aftsection>
<nextsent>their system is based on the initial seed of two or more words representing the type of concept one is interested in.
</nextsent>
<nextsent>linguistic analysis has been reported as an effective technique for semantic relation extraction.
</nextsent>
<nextsent>harabagiu et al (2005) used shallow semantic parsers to enhance dependency tree kernels and to build semantic dependency structures to improve relation extraction, they reported that their method improved the quality of the extracted relations as compared to kernel-based models that used semantic class information on ly.
</nextsent>
<nextsent>nguyen et al (2007) <papid> N07-2032 </papid>presented an approach for relation extraction from wikipedia by extracting features from subtrees mined from the syntactic structure of text.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1065">
<title id=" W10-0913.xml">a hybrid approach to unsupervised relation discovery based on linguistic analysis and semantic typing </title>
<section> approach.  </section>
<citcontext>
<prevsection>
<prevsent>3.3 relation label selection.
</prevsent>
<prevsent>a pair of entities might have more than one fact associated with them.
</prevsent>
</prevsection>
<citsent citstr=" I05-2045 ">
we select representative label based on hybrid approach by combining the output from entropy based label ranking (chen et al, 2005) <papid> I05-2045 </papid>and clusters of similar relations found by relational clustering.</citsent>
<aftsection>
<nextsent>we select the relation label as the cluster label of the cluster which has the maximum member overlap with the predicates in the set of facts between pair of entities.
</nextsent>
<nextsent>in case there is an overlap of just one relation, we select the label that is ranked highest through entropy based label ranking approach (chen et al, 2005).<papid> I05-2045 </papid></nextsent>
<nextsent>according to their algorithm, the importance of terms can be assessed using the entropy criterion, which is based on the assumption that term is irrelevant if its presence obscures the separability of the dataset.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1076">
<title id=" W10-1746.xml">jhu system combination scheme for wmt 2010 </title>
<section> abstract </section>
<citcontext>
<prevsection>

<prevsent>this paper describes the jhu system combination scheme that was used inthe wmt 2010 submission.
</prevsent>
</prevsection>
<citsent citstr=" P08-2021 ">
the incremental alignment scheme of (karakoset.al, 2008) <papid> P08-2021 </papid>was used for confusion network generation.</citsent>
<aftsection>
<nextsent>the system order in the alignment of each sentence was learned using svms, following the work of (karakos et.al, 2010).
</nextsent>
<nextsent>additionally,web-scale n-grams from the google corpus were used to build language models that improved the quality of the combination output.
</nextsent>
<nextsent>experiments in spanish english, french-english, german-english and czech-english language pairs were conducted, and the results show approximately 1 bleu point and 2 ter points improvement over the best individual system.
</nextsent>
<nextsent>system combination refers to the method of combining output of multiple mt systems, to produce output better than each individual system.currently, there are several approaches to machine translation which can be classified as phrase based, hierarchical, syntax-based (hildebrand and vogel, 2008) which are equally good in their translation quality even though the underlying frameworks are completely different.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1079">
<title id=" W10-1746.xml">jhu system combination scheme for wmt 2010 </title>
<section> rescoring the final confusion network..  </section>
<citcontext>
<prevsection>
<prevsent>the order in which systems are aligned is usually decided by evaluation of systems performance.
</prevsent>
<prevsent>two alternatives for deciding the system order are discussed in section 3.
</prevsent>
</prevsection>
<citsent citstr=" J97-3002 ">
inversion transduction grammar (wu, 1997) <papid> J97-3002 </papid>is used for alignments and the cost function for aligning two confusion networks is cost(b1, b2) = 1 |b1||b2| ? wb1 ? vb2 c(v)c(w)1(w 6= v) where b1 and b2 are two different bins, |b1| and |b2| is the number of tokens in b1 and b2 respectively, c(v) and c(w) are the number of words of token and token w. which are in b1 and b2 separately.</citsent>
<aftsection>
<nextsent>the idea of this cost is to compute the probability that word from bin b1 is not equal to word from bin b2.
</nextsent>
<nextsent>cost(b1, b2) = prob(v 6= w, ? b1, ? b2) the final confusion network is rescored with a5-gram language model with kneser-ney smoothing.
</nextsent>
<nextsent>to generate the final output, we need to find the best (minimum-cost) path through the rescored confusion network.
</nextsent>
<nextsent>in the best path every bin inthe network contributes only one word to the out put.ordering the systems for incremental combination and use of different language models were thetwo components of the pipeline that were experimented with for wmt2010 shared task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1080">
<title id=" W10-1746.xml">jhu system combination scheme for wmt 2010 </title>
<section> rescoring the final confusion network..  </section>
<citcontext>
<prevsection>
<prevsent>the first few aligned translations/systems determine the word ordering in the final output andhave significant influence on the final translation quality.
</prevsent>
<prevsent>for the baseline combination the systems are aligned in the increasing order of (ter bleu) scores.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
ter and bleu (papineni et.al, 2002) <papid> P02-1040 </papid>scores are calculated over all the sentences in the training set.</citsent>
<aftsection>
<nextsent>this approach to ordering of systems is static and results in global order for all the source segments.
</nextsent>
<nextsent>an alternative approach is to learn local order of systems for every source sentence using svm ranker.
</nextsent>
<nextsent>3.1 svm rank method.
</nextsent>
<nextsent>this section describes an approach to order systems for alignment using svms (karakos et.al,2010).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1081">
<title id=" W10-2302.xml">towards the automatic creation of a wordnet from a term based lexical network </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>so, the automatic construction of such resources arises as an alternative, providing less intensive labour, easier maintenance and allowing for higher coverage, as trade off for lower, but still acceptable, precision.
</prevsent>
<prevsent>this paper is written in the scope of project where several textual resources are being exploited for the construction of lexical ontology for portuguese.
</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
we have already made first approach on the extraction of relational triples from text, where, likewise hearst (1992), <papid> C92-2082 </papid>we take advantage of textual patterns indicating semantic relations.</citsent>
<aftsection>
<nextsent>however, the extracted triples are held between two terms, which is not enough to build lexical ontology capable of dealing with ambiguity.therefore, we present our current approach towards the automatic integration of lexico-semanticknowledge into single independent lexical ontology, which will be structured on concepts and supported by fct scholarship sfrh/bd/44955/2008.adopt model close to wordnets. the task of establishing synsets and mapping term-based triple sto them is closely related to word sense disambiguation, where the only available context consists of the connections in the term-base network.
</nextsent>
<nextsent>after contextual ising this work, our approach is described.
</nextsent>
<nextsent>it involves (i) clustering procedure for obtaining thesaurus from synonymy network, (ii) the augmentation of the later with manually created thesaurus, and (iii) mapping term-basedrelational triples to the thesaurus, to obtain wordnet.
</nextsent>
<nextsent>then, our experimentation results, as well as their validation, are presented.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1083">
<title id=" W10-2302.xml">towards the automatic creation of a wordnet from a term based lexical network </title>
<section> context.  </section>
<citcontext>
<prevsection>
<prevsent>research on this field is not new and varied methods have been proposed to achieve different steps of this task including the extraction of semantic relations (e.g.
</prevsent>
<prevsent>(hearst, 1992) (<papid> C92-2082 </papid>girju et al., 2006)) or sets of similar words (e.g.</prevsent>
</prevsection>
<citsent citstr=" C02-1144 ">
(lin and pantel, 2002) (<papid> C02-1144 </papid>turney, 2001)).</citsent>
<aftsection>
<nextsent>whereas the aforementioned works are based on unstructured text, dictionaries started earlier(calzolari et al, 1973) <papid> C73-2005 </papid>to be seen as an attractive target for the automatic acquisition of lexico semantic knowledge.</nextsent>
<nextsent>mindnet (richardson et al,1998) <papid> P98-2180 </papid>is both an extraction methodology and lexical ontology different from wordnet, since it was created automatically from dictionary andits structure is based on such resources.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1085">
<title id=" W10-2302.xml">towards the automatic creation of a wordnet from a term based lexical network </title>
<section> context.  </section>
<citcontext>
<prevsection>
<prevsent>(hearst, 1992) (<papid> C92-2082 </papid>girju et al., 2006)) or sets of similar words (e.g.</prevsent>
<prevsent>(lin and pantel, 2002) (<papid> C02-1144 </papid>turney, 2001)).</prevsent>
</prevsection>
<citsent citstr=" C73-2005 ">
whereas the aforementioned works are based on unstructured text, dictionaries started earlier(calzolari et al, 1973) <papid> C73-2005 </papid>to be seen as an attractive target for the automatic acquisition of lexico semantic knowledge.</citsent>
<aftsection>
<nextsent>mindnet (richardson et al,1998) <papid> P98-2180 </papid>is both an extraction methodology and lexical ontology different from wordnet, since it was created automatically from dictionary andits structure is based on such resources.</nextsent>
<nextsent>nevertheless, it still connects sense records with semantic relations (e.g. hyponymy, cause, manner).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1086">
<title id=" W10-2302.xml">towards the automatic creation of a wordnet from a term based lexical network </title>
<section> context.  </section>
<citcontext>
<prevsection>
<prevsent>(lin and pantel, 2002) (<papid> C02-1144 </papid>turney, 2001)).</prevsent>
<prevsent>whereas the aforementioned works are based on unstructured text, dictionaries started earlier(calzolari et al, 1973) <papid> C73-2005 </papid>to be seen as an attractive target for the automatic acquisition of lexico semantic knowledge.</prevsent>
</prevsection>
<citsent citstr=" P98-2180 ">
mindnet (richardson et al,1998) <papid> P98-2180 </papid>is both an extraction methodology and lexical ontology different from wordnet, since it was created automatically from dictionary andits structure is based on such resources.</citsent>
<aftsection>
<nextsent>nevertheless, it still connects sense records with semantic relations (e.g. hyponymy, cause, manner).
</nextsent>
<nextsent>for portuguese, papel (goncalo oliveira et al., 2009) is lexical network consisting of triples denoting semantic relations between words foundin dictionary.
</nextsent>
<nextsent>other portuguese lexical ontologies, created by different means, are reviewed and compared in (santos et al, 2009) and (teixeira et al., 2010).
</nextsent>
<nextsent>besides corpora and dictionary processing, inthe later years, semi-structured collaborative resources, such as wikipedia or wiktionary, have proved to be important sources of lexico-semantic knowledge and have thus been receiving more and more attention by the community (see for instance (zesch et al, 2008) (<papid> L08-1139 </papid>navarro et al, 2009)).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1087">
<title id=" W10-2302.xml">towards the automatic creation of a wordnet from a term based lexical network </title>
<section> context.  </section>
<citcontext>
<prevsection>
<prevsent>for portuguese, papel (goncalo oliveira et al., 2009) is lexical network consisting of triples denoting semantic relations between words foundin dictionary.
</prevsent>
<prevsent>other portuguese lexical ontologies, created by different means, are reviewed and compared in (santos et al, 2009) and (teixeira et al., 2010).
</prevsent>
</prevsection>
<citsent citstr=" L08-1139 ">
besides corpora and dictionary processing, inthe later years, semi-structured collaborative resources, such as wikipedia or wiktionary, have proved to be important sources of lexico-semantic knowledge and have thus been receiving more and more attention by the community (see for instance (zesch et al, 2008) (<papid> L08-1139 </papid>navarro et al, 2009)).</citsent>
<aftsection>
<nextsent>2.2 other relevant work.
</nextsent>
<nextsent>most of the methods proposed to extract relations from text have term-based triples as output.
</nextsent>
<nextsent>such triple, term1 relation term2, indicates that possible meaning of term1 is related to possible meaning of term2 by means of relation.
</nextsent>
<nextsent>although it is possible to create lexical network from the latter, this kind of network sis often impractical for computational applications, such as the ones that deal with inference.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1090">
<title id=" W10-1301.xml">using nlg and sensors to support personal narrative for children with complex communication needs </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>we also want to allow teachers and school staff to enter information about the childs activities (such as voice messages).
</prevsent>
<prevsent>a number of data-to-text systems (reiter 2007) have been developed in recent years, which generate english summaries of sensor and other numerical data.
</prevsent>
</prevsection>
<citsent citstr=" W05-1615 ">
the most popular application area has been weather forecasting (generating textual weather forecasts from the results of numerical atmosphere simulation model), and indeed several weather forecast generators have been fielded and used operationally (goldberg, dried ger et al 1994; reiter, sripada et al 2005).<papid> W05-1615 </papid></citsent>
<aftsection>
<nextsent>a number of data-to-text systems have also been developed in the medical community, such as baby talk (gatt, portet et al. 2009), which generates summaries of clinical data from neonatal intensive care unit, and the commercial narrative engine (harris 2008) <papid> W08-1120 </papid>which summarizes data acquired during doctor/patient encounter.</nextsent>
<nextsent>most previous research in data-to-text has focused on summarizing technical data for expert users, with the goal of effectively communicating key information.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1091">
<title id=" W10-1301.xml">using nlg and sensors to support personal narrative for children with complex communication needs </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>a number of data-to-text systems (reiter 2007) have been developed in recent years, which generate english summaries of sensor and other numerical data.
</prevsent>
<prevsent>the most popular application area has been weather forecasting (generating textual weather forecasts from the results of numerical atmosphere simulation model), and indeed several weather forecast generators have been fielded and used operationally (goldberg, dried ger et al 1994; reiter, sripada et al 2005).<papid> W05-1615 </papid></prevsent>
</prevsection>
<citsent citstr=" W08-1120 ">
a number of data-to-text systems have also been developed in the medical community, such as baby talk (gatt, portet et al. 2009), which generates summaries of clinical data from neonatal intensive care unit, and the commercial narrative engine (harris 2008) <papid> W08-1120 </papid>which summarizes data acquired during doctor/patient encounter.</citsent>
<aftsection>
<nextsent>most previous research in data-to-text has focused on summarizing technical data for expert users, with the goal of effectively communicating key information.
</nextsent>
<nextsent>in our work, in contrast, the focus is on summarizing data about everyday events, with the goal of having something interesting to talk about.
</nextsent>
<nextsent>there has been consider able work in the computational creativity community on generating interesting stories (prz and sharples 2004), but it has focused on fictional written stories, where the computer system can say whatever it wishes, without the constraint of describing real events.
</nextsent>
<nextsent>most previous work in nlg has focused on computer systems which generate texts without human in put.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1092">
<title id=" W10-1301.xml">using nlg and sensors to support personal narrative for children with complex communication needs </title>
<section> current and ongoing work.  </section>
<citcontext>
<prevsection>
<prevsent>3.1 how was school today???
</prevsent>
<prevsent>we developed an initial version of how was school today???
</prevsent>
</prevsection>
<citsent citstr=" W09-0601 ">
in 2009; see reiter et al(2009) <papid> W09-0601 </papid>for more details about this system.</citsent>
<aftsection>
<nextsent>fig.
</nextsent>
<nextsent>1: participating pupil with support worker: the prototype system is mounted on the wheelchair, and the pupil has access to the system via head switch controlled row/column scanning.
</nextsent>
<nextsent>this system used radio frequency identification (rfid), an emerging application in aac to identify or give access to relevant vocabulary (bart, riny et al 2008; deruyter and fried-oken 2010).
</nextsent>
<nextsent>sensors were used to track both location (by putting tags on doors, which were automatically sensed by long-range rfid reader) and interaction (by asking staff to manually swipe rfid cards in short-range reader when the child interacted with person or object).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1093">
<title id=" W10-3016.xml">a lucene and maximum entropy model based hedge detection system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, in opinion mining, hedges can be used to assess the degree of sentiment, and refine sentiment classes from{positive, negative, objective} to {positive, somehow positive, objective, somehow objective, negative, somehow negative}.
</prevsent>
<prevsent>1http://en.wikipedia.org/wiki/ hedge(linguistics)hedge detection related work has been conducted by several people.
</prevsent>
</prevsection>
<citsent citstr=" W04-3103 ">
light et al (2004) <papid> W04-3103 </papid>started to do annotations on biomedicine article abstracts, and conducted the preliminary work of automatic classification for uncertainty.</citsent>
<aftsection>
<nextsent>medlock and briscoe (2007) <papid> P07-1125 </papid>devised detailed guidelines for hedge annotations, and used probabilistic weakly supervised learning approach to classify hedges.</nextsent>
<nextsent>ganter and strube (2009) <papid> P09-2044 </papid>took wikipedia articles as training corpus, used weasel words?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1094">
<title id=" W10-3016.xml">a lucene and maximum entropy model based hedge detection system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>1http://en.wikipedia.org/wiki/ hedge(linguistics)hedge detection related work has been conducted by several people.
</prevsent>
<prevsent>light et al (2004) <papid> W04-3103 </papid>started to do annotations on biomedicine article abstracts, and conducted the preliminary work of automatic classification for uncertainty.</prevsent>
</prevsection>
<citsent citstr=" P07-1125 ">
medlock and briscoe (2007) <papid> P07-1125 </papid>devised detailed guidelines for hedge annotations, and used probabilistic weakly supervised learning approach to classify hedges.</citsent>
<aftsection>
<nextsent>ganter and strube (2009) <papid> P09-2044 </papid>took wikipedia articles as training corpus, used weasel words?</nextsent>
<nextsent>frequency and syntactic patterns as features to classify uncertainty.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1095">
<title id=" W10-3016.xml">a lucene and maximum entropy model based hedge detection system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>light et al (2004) <papid> W04-3103 </papid>started to do annotations on biomedicine article abstracts, and conducted the preliminary work of automatic classification for uncertainty.</prevsent>
<prevsent>medlock and briscoe (2007) <papid> P07-1125 </papid>devised detailed guidelines for hedge annotations, and used probabilistic weakly supervised learning approach to classify hedges.</prevsent>
</prevsection>
<citsent citstr=" P09-2044 ">
ganter and strube (2009) <papid> P09-2044 </papid>took wikipedia articles as training corpus, used weasel words?</citsent>
<aftsection>
<nextsent>frequency and syntactic patterns as features to classify uncertainty.
</nextsent>
<nextsent>the rest of the paper is organized as follows.
</nextsent>
<nextsent>section 2 shows the architecture of our system.
</nextsent>
<nextsent>section 3 explains how we make use of apache lucene to do fuzzy string match and incorporate pos tag in hedge cues and our method to generate hedge cue candidates.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1096">
<title id=" W10-2311.xml">mulling multilevel linguistic graphs for knowledge extraction </title>
<section> knowledge extraction.  </section>
<citcontext>
<prevsection>
<prevsent>graphs are understandable quickly by humans, easy to use in automatic processes, and flexible enough to represent various data types.
</prevsent>
<prevsent>using graphs for knowledge extraction is quite classic.
</prevsent>
</prevsection>
<citsent citstr=" W06-3802 ">
they can represent relations between words (pro duced by dependency analysers from corpora), and be used to produce semantically close terms (widdows &amp; dorrow, 2002) or to group similar n-tuples (hassan et al, 2006).<papid> W06-3802 </papid></citsent>
<aftsection>
<nextsent>graphs also can be 69 generated from dictionaries, and used to produce knowledge bases (richardson et al., 1998) <papid> P98-2180 </papid>or proximity information (gaume et al, 2006).</nextsent>
<nextsent>2.2 existing graph models.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1097">
<title id=" W10-2311.xml">mulling multilevel linguistic graphs for knowledge extraction </title>
<section> knowledge extraction.  </section>
<citcontext>
<prevsection>
<prevsent>using graphs for knowledge extraction is quite classic.
</prevsent>
<prevsent>they can represent relations between words (pro duced by dependency analysers from corpora), and be used to produce semantically close terms (widdows &amp; dorrow, 2002) or to group similar n-tuples (hassan et al, 2006).<papid> W06-3802 </papid></prevsent>
</prevsection>
<citsent citstr=" P98-2180 ">
graphs also can be 69 generated from dictionaries, and used to produce knowledge bases (richardson et al., 1998) <papid> P98-2180 </papid>or proximity information (gaume et al, 2006).</citsent>
<aftsection>
<nextsent>2.2 existing graph models.
</nextsent>
<nextsent>influenced by existential graphs?
</nextsent>
<nextsent>(peirce, 19311935) where relations between elements are represented by nodes, conceptual graphs?
</nextsent>
<nextsent>(sowa, 1976) are bipartite graphs with two node types: concepts and conceptual relations (edges only associate relations and concepts).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1098">
<title id=" W10-2311.xml">mulling multilevel linguistic graphs for knowledge extraction </title>
<section> knowledge extraction.  </section>
<citcontext>
<prevsection>
<prevsent>finally, graphs can be multilevel, to represent different kinds of information.
</prevsent>
<prevsent>links are generally allowed only in same level or between two adjacent levels, like in hypertexts?
</prevsent>
</prevsection>
<citsent citstr=" W07-0202 ">
(agosti and cres tani, 1993) made of three specified levels (documents, terms, concepts), or in multi-level association graphs (witschel, 2007) <papid> W07-0202 </papid>in which there is no constraint on the number of levels.</citsent>
<aftsection>
<nextsent>we believe that the use of several levels to represent various content types is pertinent in an extraction process, as it allows to handle both the occurrences of terms, and the terms themselves.
</nextsent>
<nextsent>we introduce mulling (multi-level linguistic graph), our own graph model.
</nextsent>
<nextsent>divided in several ordered and distinct levels, it contains two kinds of edges: intra-level ones (between nodes from same level) and inter-level ones (from node on level to node on level i+1).
</nextsent>
<nextsent>intra-level edges are not unique (several edges are allowed between two nodes): every level is multigraph.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1099">
<title id=" W10-1410.xml">lemmatization and lexicalized statistical parsing of morphologically rich languages the case of french </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in order to avoid discontinuous constituents as well as traces and coindexations, treebanks for this language, such as the french treebank (ftb, (abeill?
</prevsent>
<prevsent>et al, 2003)) or the modified french treebank (mft, (schluterand van genabith, 2007)), propose flat annotation scheme with non-configurational distinction between adjunct and arguments.
</prevsent>
</prevsection>
<citsent citstr=" W09-3821 ">
finally, the extraction of treebank grammars from the french treebanks, which contain less than third of the annotated data as compared to ptb, is subject to many data sparseness issues that contribute to aperformance ceiling, preventing the statistical parsing of french to reach the same level of performance as for ptb-trained parsers (candito et al, 2009).<papid> W09-3821 </papid>this data sparseness bottleneck can be summarized as problem of optimizing parsing model along two axes: the grammar and the lexicon.</citsent>
<aftsection>
<nextsent>in both cases, the goal is either to get more compact grammar at the rule level or to obtain consider 85 ably less sparse lexicon.
</nextsent>
<nextsent>so far, both approaches have been tested for french using different means and with different degrees of success.to obtain better grammars, schluter and van genabith (2007) extracted subset of an early release of the ftb and carried out extensive restructuring,extensions and corrections (referred to as the modified french treebank mft) to support grammar acquisition for pcfg-based lfg parsing (cahill et al., 2004) <papid> P04-1041 </papid>while crabb?</nextsent>
<nextsent>and candito (2008) slightly modified the original ftb pos tagset to optimize the grammar with latent annotations extracted by the berkeley parser (bky, (petrov et al, 2006)).<papid> P06-1055 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1101">
<title id=" W10-1410.xml">lemmatization and lexicalized statistical parsing of morphologically rich languages the case of french </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>finally, the extraction of treebank grammars from the french treebanks, which contain less than third of the annotated data as compared to ptb, is subject to many data sparseness issues that contribute to aperformance ceiling, preventing the statistical parsing of french to reach the same level of performance as for ptb-trained parsers (candito et al, 2009).<papid> W09-3821 </papid>this data sparseness bottleneck can be summarized as problem of optimizing parsing model along two axes: the grammar and the lexicon.</prevsent>
<prevsent>in both cases, the goal is either to get more compact grammar at the rule level or to obtain consider 85 ably less sparse lexicon.</prevsent>
</prevsection>
<citsent citstr=" P04-1041 ">
so far, both approaches have been tested for french using different means and with different degrees of success.to obtain better grammars, schluter and van genabith (2007) extracted subset of an early release of the ftb and carried out extensive restructuring,extensions and corrections (referred to as the modified french treebank mft) to support grammar acquisition for pcfg-based lfg parsing (cahill et al., 2004) <papid> P04-1041 </papid>while crabb?</citsent>
<aftsection>
<nextsent>and candito (2008) slightly modified the original ftb pos tagset to optimize the grammar with latent annotations extracted by the berkeley parser (bky, (petrov et al, 2006)).<papid> P06-1055 </papid></nextsent>
<nextsent>moreover, research oriented towards adapting more complex parsing models to french showed that lexicalized models such as collins?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1102">
<title id=" W10-1410.xml">lemmatization and lexicalized statistical parsing of morphologically rich languages the case of french </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in both cases, the goal is either to get more compact grammar at the rule level or to obtain consider 85 ably less sparse lexicon.
</prevsent>
<prevsent>so far, both approaches have been tested for french using different means and with different degrees of success.to obtain better grammars, schluter and van genabith (2007) extracted subset of an early release of the ftb and carried out extensive restructuring,extensions and corrections (referred to as the modified french treebank mft) to support grammar acquisition for pcfg-based lfg parsing (cahill et al., 2004) <papid> P04-1041 </papid>while crabb?</prevsent>
</prevsection>
<citsent citstr=" P06-1055 ">
and candito (2008) slightly modified the original ftb pos tagset to optimize the grammar with latent annotations extracted by the berkeley parser (bky, (petrov et al, 2006)).<papid> P06-1055 </papid></citsent>
<aftsection>
<nextsent>moreover, research oriented towards adapting more complex parsing models to french showed that lexicalized models such as collins?
</nextsent>
<nextsent>model 2 (collins, 1999) can be tuned to cope effectively with the flatness of the annotation scheme in the ftb,with the charniak model (charniak, 2000) <papid> A00-2018 </papid>performing particularly well, but outperformed by the bky parser on french data (seddah et al, 2009).</nextsent>
<nextsent>focusing on the lexicon, experiments have been carried out to study the impact of different forms of word clustering on the bky parser trained on the ftb.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1103">
<title id=" W10-1410.xml">lemmatization and lexicalized statistical parsing of morphologically rich languages the case of french </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>and candito (2008) slightly modified the original ftb pos tagset to optimize the grammar with latent annotations extracted by the berkeley parser (bky, (petrov et al, 2006)).<papid> P06-1055 </papid></prevsent>
<prevsent>moreover, research oriented towards adapting more complex parsing models to french showed that lexicalized models such as collins?</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
model 2 (collins, 1999) can be tuned to cope effectively with the flatness of the annotation scheme in the ftb,with the charniak model (charniak, 2000) <papid> A00-2018 </papid>performing particularly well, but outperformed by the bky parser on french data (seddah et al, 2009).</citsent>
<aftsection>
<nextsent>focusing on the lexicon, experiments have been carried out to study the impact of different forms of word clustering on the bky parser trained on the ftb.
</nextsent>
<nextsent>candito et al (2009) <papid> W09-3821 </papid>showed that using goldlemmatization provides significant increase in per formance.</nextsent>
<nextsent>obviously, less sparse lexical data which retains critical pieces of information can only help model to perform better.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1107">
<title id=" W10-1410.xml">lemmatization and lexicalized statistical parsing of morphologically rich languages the case of french </title>
<section> morphology learning.  </section>
<citcontext>
<prevsection>
<prevsent>the s.ptb follows the same split as the ftb-uc, first 10% for test, next 10% for dev and the last 80% for training (i.e. 1380/1381/11050 sentences).
</prevsent>
<prevsent>morfette can optionally use morphological lexicon to extract features.
</prevsent>
</prevsection>
<citsent citstr=" C94-2149 ">
for french, we used the extended version of lefff (sagot et al, 2006) and for english, the lexicon used in the penn xtag project (doran et al, 1994).<papid> C94-2149 </papid></citsent>
<aftsection>
<nextsent>we reduced the granularity of the xtag tag set, keeping only the bare categories.
</nextsent>
<nextsent>both lexicons contain around 225 thousands word form entries.
</nextsent>
<nextsent>3.3 performance on french and english.
</nextsent>
<nextsent>table 2 presents results of morfette applied to the development and test sets of our treebanks.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1110">
<title id=" W10-1410.xml">lemmatization and lexicalized statistical parsing of morphologically rich languages the case of french </title>
<section> parsing experiments.  </section>
<citcontext>
<prevsection>
<prevsent>data the datasets described in section 3.2 are used throughout.
</prevsent>
<prevsent>the version of the charniak parser (charniak, 2000) <papid> A00-2018 </papid>was released in august 2005 and recently adapted to french (seddah et al, 2009).</prevsent>
</prevsection>
<citsent citstr=" D07-1066 ">
metrics we report results on sentences of length less than 40 words, with three evaluation met rics: the classical parseval labeled brackets f1score, pos tagging accuracy (excluding punctuation tags) and the leaf ancestor metric (sampsonand babarczy, 2003) which is believed to be somewhat more neutral with respect to the treebank annotation scheme than parseval (rehbein and van genabith, 2007).<papid> D07-1066 </papid>treebank tag sets our experiments involve the inclusion of pos tags directly in tokens.</citsent>
<aftsection>
<nextsent>we briefly describe our treebank tag sets below.?
</nextsent>
<nextsent>ftb-uc tag set: cc?
</nextsent>
<nextsent>this is the tag set developed by (crabb?
</nextsent>
<nextsent>and candito, 2008) (table4), known to provide the best parsing performance for french (seddah et al, 2009).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1112">
<title id=" W10-1410.xml">lemmatization and lexicalized statistical parsing of morphologically rich languages the case of french </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>91
</prevsent>
<prevsent>a fair amount of recent research in parsing morphologically rich languages has focused on coping with unknowns words and more generally with the small and limited lexicons acquired from treebanks.
</prevsent>
</prevsection>
<citsent citstr=" E09-1038 ">
for instance, goldberg et al (2009) <papid> E09-1038 </papid>augment the lexicon for generative parsing model by including lexical probabilities coming from an external lexi con.</citsent>
<aftsection>
<nextsent>these are estimated using an hmm tagger withbaum-welch training.
</nextsent>
<nextsent>this method leads to significant increase of parsing performance over previously reported results for modern hebrew.
</nextsent>
<nextsent>our method is more stratified: external lexical resources are included as features for morfette and therefore are not directly seen by the parser besides generated lemma and pos.
</nextsent>
<nextsent>for parsing german, versley and rehbein (2009) <papid> W09-3820 </papid>cluster words according to linear context features.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1113">
<title id=" W10-1410.xml">lemmatization and lexicalized statistical parsing of morphologically rich languages the case of french </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>this method leads to significant increase of parsing performance over previously reported results for modern hebrew.
</prevsent>
<prevsent>our method is more stratified: external lexical resources are included as features for morfette and therefore are not directly seen by the parser besides generated lemma and pos.
</prevsent>
</prevsection>
<citsent citstr=" W09-3820 ">
for parsing german, versley and rehbein (2009) <papid> W09-3820 </papid>cluster words according to linear context features.</citsent>
<aftsection>
<nextsent>the clusters are then integrated as features to boost discriminative parsing model to cope with unknown words.
</nextsent>
<nextsent>interestingly, they also include all possible information: valence information, extracted from lexicon, is added to verbs and pre terminal nodes are annotated with case/number.
</nextsent>
<nextsent>this leads their discriminative model to state-of-the-art results for parsing german.
</nextsent>
<nextsent>concerning french, candito and crabb?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1114">
<title id=" W10-1841.xml">annotating participant reference in english spoken conversation </title>
<section> related annotation schemes.  </section>
<citcontext>
<prevsection>
<prevsent>several schemes have been designed with the goalof testing linguistic theoretical models of discourse structure or for use in the study of discourse processing problems like anaphora resolution and reference generation.
</prevsent>
<prevsent>these schemes have been applied to both text and dialogue and label dis 257course references with rich set of syntactic, semantic, and pragmatic properties.
</prevsent>
</prevsection>
<citsent citstr=" W04-0210 ">
for example, the drama scheme (passonneau, 1997) and the gnome scheme (poesio, 2000; poesio, 2004) <papid> W04-0210 </papid>include labels for features such as bridging relation type and np type in addition to rich representation of referent semantics.</citsent>
<aftsection>
<nextsent>other schemes label an imacy, prosody, and information structure to study their relationship to the organization and salience of discourse reference (nissim et al, 2004; calhoun et al, 2005).<papid> W05-0307 </papid></nextsent>
<nextsent>recent developments include the explicit handling of anaphoric ambiguity and discourse deixis (poesio and artstein, 2008).<papid> L08-1091 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1115">
<title id=" W10-1841.xml">annotating participant reference in english spoken conversation </title>
<section> related annotation schemes.  </section>
<citcontext>
<prevsection>
<prevsent>these schemes have been applied to both text and dialogue and label dis 257course references with rich set of syntactic, semantic, and pragmatic properties.
</prevsent>
<prevsent>for example, the drama scheme (passonneau, 1997) and the gnome scheme (poesio, 2000; poesio, 2004) <papid> W04-0210 </papid>include labels for features such as bridging relation type and np type in addition to rich representation of referent semantics.</prevsent>
</prevsection>
<citsent citstr=" W05-0307 ">
other schemes label an imacy, prosody, and information structure to study their relationship to the organization and salience of discourse reference (nissim et al, 2004; calhoun et al, 2005).<papid> W05-0307 </papid></citsent>
<aftsection>
<nextsent>recent developments include the explicit handling of anaphoric ambiguity and discourse deixis (poesio and artstein, 2008).<papid> L08-1091 </papid></nextsent>
<nextsent>despite the depth and detail of these schemes,participant reference has not been their main con cern.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1116">
<title id=" W10-1841.xml">annotating participant reference in english spoken conversation </title>
<section> related annotation schemes.  </section>
<citcontext>
<prevsection>
<prevsent>for example, the drama scheme (passonneau, 1997) and the gnome scheme (poesio, 2000; poesio, 2004) <papid> W04-0210 </papid>include labels for features such as bridging relation type and np type in addition to rich representation of referent semantics.</prevsent>
<prevsent>other schemes label an imacy, prosody, and information structure to study their relationship to the organization and salience of discourse reference (nissim et al, 2004; calhoun et al, 2005).<papid> W05-0307 </papid></prevsent>
</prevsection>
<citsent citstr=" L08-1091 ">
recent developments include the explicit handling of anaphoric ambiguity and discourse deixis (poesio and artstein, 2008).<papid> L08-1091 </papid></citsent>
<aftsection>
<nextsent>despite the depth and detail of these schemes,participant reference has not been their main concern.
</nextsent>
<nextsent>the annotations by poesio et al (2000), poesio et al (2004) include dialogue source material, but the rather constrained interact ional situations do not elicit rich set of references to participants.
</nextsent>
<nextsent>the scheme thus employs simple default labels for words like and you.
</nextsent>
<nextsent>the work by nissim etal., (2004) is an annotation of the switchboard corpus (godfrey et al, 1992), which contains only two participants who are neither co-present nor socially connected.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1117">
<title id=" W10-1841.xml">annotating participant reference in english spoken conversation </title>
<section> related annotation schemes.  </section>
<citcontext>
<prevsection>
<prevsent>for example, the objective of the automatic content extraction (ace) program (dod dington et al, 2004) is to recognize and extract entities, events, and relations between them, directly from written and spoken sources, mostly from broadcast news.
</prevsent>
<prevsent>the schemes thus focuson identifying and labeling the properties of entities in the real world, and then marking expressions as referring to these entities.
</prevsent>
</prevsection>
<citsent citstr=" L08-1390 ">
recent work in the ace project has expanded the scope of this task to include cross-document recognition and resolution (strassel et al, 2008).<papid> L08-1390 </papid></citsent>
<aftsection>
<nextsent>in the ace scheme (linguistic data consortium, 2008), person reference is central component, and in the broadcast conversation component of the corpus there is an extensive inventory of participant references.
</nextsent>
<nextsent>the annotation scheme contains distinction between specific, underspecified, and general entities, as well as distinction between persons and organizations.
</nextsent>
<nextsent>another closely related set of studies are four recent investigations of second-person reference resolution (gupta et al, 2007<papid> P07-2027 </papid>a; gupta et al, 2007<papid> P07-2027 </papid>b; frampton et al, 2009; <papid> E09-1032 </papid>purver et al, 2009).<papid> W09-3944 </papid></nextsent>
<nextsent>these studies are based upon comm onset of annotations of the word you in source material from the switchboard and icsi meeting cor pora.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1118">
<title id=" W10-1841.xml">annotating participant reference in english spoken conversation </title>
<section> related annotation schemes.  </section>
<citcontext>
<prevsection>
<prevsent>in the ace scheme (linguistic data consortium, 2008), person reference is central component, and in the broadcast conversation component of the corpus there is an extensive inventory of participant references.
</prevsent>
<prevsent>the annotation scheme contains distinction between specific, underspecified, and general entities, as well as distinction between persons and organizations.
</prevsent>
</prevsection>
<citsent citstr=" P07-2027 ">
another closely related set of studies are four recent investigations of second-person reference resolution (gupta et al, 2007<papid> P07-2027 </papid>a; gupta et al, 2007<papid> P07-2027 </papid>b; frampton et al, 2009; <papid> E09-1032 </papid>purver et al, 2009).<papid> W09-3944 </papid></citsent>
<aftsection>
<nextsent>these studies are based upon comm onset of annotations of the word you in source material from the switchboard and icsi meeting corpora.
</nextsent>
<nextsent>the purpose for the annotations was to support learning of classifiers for two main prob lems: disambiguation of the generic/referential distinction, and reference resolution for referentialcases.
</nextsent>
<nextsent>in addition to the generic/referential distinction and an addressing-based reference annotation, the scheme employed special classes for reported speech and fillers and allowed annotators to indicate vague or difficult cases.
</nextsent>
<nextsent>our work builds directly upon this work by extending the annotation scheme to all person-referring expressions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1122">
<title id=" W10-1841.xml">annotating participant reference in english spoken conversation </title>
<section> related annotation schemes.  </section>
<citcontext>
<prevsection>
<prevsent>in the ace scheme (linguistic data consortium, 2008), person reference is central component, and in the broadcast conversation component of the corpus there is an extensive inventory of participant references.
</prevsent>
<prevsent>the annotation scheme contains distinction between specific, underspecified, and general entities, as well as distinction between persons and organizations.
</prevsent>
</prevsection>
<citsent citstr=" E09-1032 ">
another closely related set of studies are four recent investigations of second-person reference resolution (gupta et al, 2007<papid> P07-2027 </papid>a; gupta et al, 2007<papid> P07-2027 </papid>b; frampton et al, 2009; <papid> E09-1032 </papid>purver et al, 2009).<papid> W09-3944 </papid></citsent>
<aftsection>
<nextsent>these studies are based upon comm onset of annotations of the word you in source material from the switchboard and icsi meeting corpora.
</nextsent>
<nextsent>the purpose for the annotations was to support learning of classifiers for two main prob lems: disambiguation of the generic/referential distinction, and reference resolution for referentialcases.
</nextsent>
<nextsent>in addition to the generic/referential distinction and an addressing-based reference annotation, the scheme employed special classes for reported speech and fillers and allowed annotators to indicate vague or difficult cases.
</nextsent>
<nextsent>our work builds directly upon this work by extending the annotation scheme to all person-referring expressions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1123">
<title id=" W10-1841.xml">annotating participant reference in english spoken conversation </title>
<section> related annotation schemes.  </section>
<citcontext>
<prevsection>
<prevsent>in the ace scheme (linguistic data consortium, 2008), person reference is central component, and in the broadcast conversation component of the corpus there is an extensive inventory of participant references.
</prevsent>
<prevsent>the annotation scheme contains distinction between specific, underspecified, and general entities, as well as distinction between persons and organizations.
</prevsent>
</prevsection>
<citsent citstr=" W09-3944 ">
another closely related set of studies are four recent investigations of second-person reference resolution (gupta et al, 2007<papid> P07-2027 </papid>a; gupta et al, 2007<papid> P07-2027 </papid>b; frampton et al, 2009; <papid> E09-1032 </papid>purver et al, 2009).<papid> W09-3944 </papid></citsent>
<aftsection>
<nextsent>these studies are based upon comm onset of annotations of the word you in source material from the switchboard and icsi meeting corpora.
</nextsent>
<nextsent>the purpose for the annotations was to support learning of classifiers for two main prob lems: disambiguation of the generic/referential distinction, and reference resolution for referentialcases.
</nextsent>
<nextsent>in addition to the generic/referential distinction and an addressing-based reference annotation, the scheme employed special classes for reported speech and fillers and allowed annotators to indicate vague or difficult cases.
</nextsent>
<nextsent>our work builds directly upon this work by extending the annotation scheme to all person-referring expressions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1124">
<title id=" W10-1841.xml">annotating participant reference in english spoken conversation </title>
<section> results and analysis.  </section>
<citcontext>
<prevsection>
<prevsent>each of the decisions in the annotation procedure are assessedseparately: mark able identification, labeling referentiality, labeling specificity of person referents, and labeling addressing inclusion attributes.
</prevsent>
<prevsent>because each decision depends on the previous, we employ hierarchical assessment procedure that considers only instances where the annotators have agreed on previous decisions.
</prevsent>
</prevsection>
<citsent citstr=" J97-1002 ">
this kindof multi-level assessment corresponds to that described and used in carletta et al, (1997).<papid> J97-1002 </papid>markables the first annotation decision of interest is the identification of markables.</citsent>
<aftsection>
<nextsent>markables are either automatically identified occurrences ofa pre-defined list of pronouns, or they are identi 262 fied manually by the annotators.
</nextsent>
<nextsent>agreement on this task, assessed only for manually identified words, was very good (?=.94).
</nextsent>
<nextsent>error analysis shows that the main issue with this decision wasnot determining lexical heads, but rather determining whether phrases such as all age groups,?
</nextsent>
<nextsent>the older generation,?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1125">
<title id=" W10-1012.xml">towards identifying unresolved discussions in student online forums </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>it seems that sa-based features may help performing more difficult tasks (e.g. assessment for issues in discussions) we need further investigation on different types of assessment tasks.
</prevsent>
<prevsent>rhetorical structure theory (mann and thomson, 1988) based discourse processing has attracted much attention with successful applications in sentence compression and summarization.
</prevsent>
</prevsection>
<citsent citstr=" N03-1030 ">
most of the current work on discourse processing focuses on sentence-level text organization (soricut and marcu, 2003) <papid> N03-1030 </papid>or the intermediate step (sporleder and lapata, 2005).<papid> H05-1033 </papid></citsent>
<aftsection>
<nextsent>analyzing and utilizing discourse information at higher level, e.g., at the paragraph level, still remains challenge to the natural language community.
</nextsent>
<nextsent>in our work, we utilize the discourse information at message level.
</nextsent>
<nextsent>there has been prior work on dialogue act analysis and associated surface cue words (samuel 2000; hirschberg and litman 1993).<papid> J93-3003 </papid></nextsent>
<nextsent>there have also been dialogue acts modeling approaches for automatic tagging and recognition of conversational speech (stolcke et al, 2000) <papid> J00-3003 </papid>and related work in corpus linguistics where machine learning techniques have been used to find conversational patterns in spoken transcripts of dialogue corpus (shawar and atwell, 2005).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1126">
<title id=" W10-1012.xml">towards identifying unresolved discussions in student online forums </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>it seems that sa-based features may help performing more difficult tasks (e.g. assessment for issues in discussions) we need further investigation on different types of assessment tasks.
</prevsent>
<prevsent>rhetorical structure theory (mann and thomson, 1988) based discourse processing has attracted much attention with successful applications in sentence compression and summarization.
</prevsent>
</prevsection>
<citsent citstr=" H05-1033 ">
most of the current work on discourse processing focuses on sentence-level text organization (soricut and marcu, 2003) <papid> N03-1030 </papid>or the intermediate step (sporleder and lapata, 2005).<papid> H05-1033 </papid></citsent>
<aftsection>
<nextsent>analyzing and utilizing discourse information at higher level, e.g., at the paragraph level, still remains challenge to the natural language community.
</nextsent>
<nextsent>in our work, we utilize the discourse information at message level.
</nextsent>
<nextsent>there has been prior work on dialogue act analysis and associated surface cue words (samuel 2000; hirschberg and litman 1993).<papid> J93-3003 </papid></nextsent>
<nextsent>there have also been dialogue acts modeling approaches for automatic tagging and recognition of conversational speech (stolcke et al, 2000) <papid> J00-3003 </papid>and related work in corpus linguistics where machine learning techniques have been used to find conversational patterns in spoken transcripts of dialogue corpus (shawar and atwell, 2005).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1127">
<title id=" W10-1012.xml">towards identifying unresolved discussions in student online forums </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>analyzing and utilizing discourse information at higher level, e.g., at the paragraph level, still remains challenge to the natural language community.
</prevsent>
<prevsent>in our work, we utilize the discourse information at message level.
</prevsent>
</prevsection>
<citsent citstr=" J93-3003 ">
there has been prior work on dialogue act analysis and associated surface cue words (samuel 2000; hirschberg and litman 1993).<papid> J93-3003 </papid></citsent>
<aftsection>
<nextsent>there have also been dialogue acts modeling approaches for automatic tagging and recognition of conversational speech (stolcke et al, 2000) <papid> J00-3003 </papid>and related work in corpus linguistics where machine learning techniques have been used to find conversational patterns in spoken transcripts of dialogue corpus (shawar and atwell, 2005).</nextsent>
<nextsent>although spoken dialogue is different from message-based conversation in online discussion boards, they are closely related to our thread analysis work, and we plan to investigate potential use of conversation patterns in spoken dialogue in threaded discussions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1128">
<title id=" W10-1012.xml">towards identifying unresolved discussions in student online forums </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in our work, we utilize the discourse information at message level.
</prevsent>
<prevsent>there has been prior work on dialogue act analysis and associated surface cue words (samuel 2000; hirschberg and litman 1993).<papid> J93-3003 </papid></prevsent>
</prevsection>
<citsent citstr=" J00-3003 ">
there have also been dialogue acts modeling approaches for automatic tagging and recognition of conversational speech (stolcke et al, 2000) <papid> J00-3003 </papid>and related work in corpus linguistics where machine learning techniques have been used to find conversational patterns in spoken transcripts of dialogue corpus (shawar and atwell, 2005).</citsent>
<aftsection>
<nextsent>although spoken dialogue is different from message-based conversation in online discussion boards, they are closely related to our thread analysis work, and we plan to investigate potential use of conversation patterns in spoken dialogue in threaded discussions.
</nextsent>
<nextsent>carvalho and cohen (2005) present depend ency-network based collective classification method to classify email speech acts.
</nextsent>
<nextsent>however, estimated speech act labeling between messages is not sufficient for assessing contributor roles or identifying help needed by the participants.
</nextsent>
<nextsent>we included other features like participant profiles.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1129">
<title id=" W10-1012.xml">towards identifying unresolved discussions in student online forums </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>as in their analysis, we have higher kappa value for questions than answers, and some sources of ambiguity in human annotations such as different forms of answers also appear in our data.
</prevsent>
<prevsent>however, student discussions tend to focus on problem solving rather than task request and commitment as in project management applications, and their data show different types of ambiguity due to different nature of participant interests.
</prevsent>
</prevsection>
<citsent citstr=" W08-0907 ">
there also has been work on non-traditional, qualitative assessment of instructional discourse (graesser et al, 2005; mclaren et al, 2007; boyer et al, 2008).<papid> W08-0907 </papid></citsent>
<aftsection>
<nextsent>the assessment results can be used in finding features for student thinking skills or level of understanding.
</nextsent>
<nextsent>although the existing work has not been fully used for discussion thread analysis, we are investigating opportunities for using such features to cover additional discourse analysis capabilities.
</nextsent>
<nextsent>similar approaches for classifying speech acts were investigated (kim and ravi 2007).
</nextsent>
<nextsent>our work captures more features that are relevant to analyzing noisy student discussion threads and support full automatic analysis of student discussions instead of manual generation of thread analysis rules.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1130">
<title id=" W10-0908.xml">empirical studies in learning to read </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>co-training will offer our approach to simultaneously learn the patterns of expressing relation and its arguments.
</prevsent>
<prevsent>other researchers have also previously explored automatic pattern generation from unsupervised text, classically in (riloff &amp; jones 1999).
</prevsent>
</prevsection>
<citsent citstr=" P02-1006 ">
ravichandran and hovy (2002) <papid> P02-1006 </papid>reported experimental results for automatically generating surface patterns for relation identification; others have explored similar approaches (e.g. agichtein &amp; gravano 2000 or pantel &amp; pennacchiotti, 2006).</citsent>
<aftsection>
<nextsent>more recently (mitchell et al, 2009) has shown that for macro-reading, precision and recall can be improved by learning large set of interconnected relations and concepts simultaneously.
</nextsent>
<nextsent>we depart from this work by learning patterns that use the structural features of text-graph patterns and our particular approach to pattern and pair scoring and selection.
</nextsent>
<nextsent>most approaches to automatic pattern generation have focused on precision, e.g., ravichandran and hovy report results in the text retrieval conference (trec) question answering track, where extracting one instance of relation can be sufficient, rather than detecting all instances.
</nextsent>
<nextsent>this study has also emphasized recall.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1131">
<title id=" W10-1755.xml">the parameter optimized atec metric for mt evaluation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the latter is quantified in term of word position and information flow.
</prevsent>
<prevsent>we also discuss those aspects of language not yet covered by other existing evaluation metrics but carefully considered in the formulation of our metric.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
it is recognized that the proposal of the bleu metric (papineni et al, 2002) <papid> P02-1040 </papid>has piloted paradigm evolution to mt evaluation.</citsent>
<aftsection>
<nextsent>it provides computable solution to the task and turns it into an engineering problem of measuring text similarity and simulating human judgments of translation quality.
</nextsent>
<nextsent>related studies in recent years have extensively revealed more essential characteristics of bleu, including its strengths and weaknesses.
</nextsent>
<nextsent>this has aroused the proposal of different new evaluation metrics aimed at addressing such weaknesses so as to find some other hopefully better alternatives for the task.
</nextsent>
<nextsent>effort in this direction brings up some advanced metrics such as meteor (banerjee and lavie, 2005) <papid> W05-0909 </papid>and terp (snover et al, 2009) <papid> W09-0441 </papid>that seem to have already achieved considerably strong correlations with human judgments.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1132">
<title id=" W10-1755.xml">the parameter optimized atec metric for mt evaluation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>related studies in recent years have extensively revealed more essential characteristics of bleu, including its strengths and weaknesses.
</prevsent>
<prevsent>this has aroused the proposal of different new evaluation metrics aimed at addressing such weaknesses so as to find some other hopefully better alternatives for the task.
</prevsent>
</prevsection>
<citsent citstr=" W05-0909 ">
effort in this direction brings up some advanced metrics such as meteor (banerjee and lavie, 2005) <papid> W05-0909 </papid>and terp (snover et al, 2009) <papid> W09-0441 </papid>that seem to have already achieved considerably strong correlations with human judgments.</citsent>
<aftsection>
<nextsent>nevertheless, few metrics have really nurtured our understanding of possible parameters involved in our language comprehension and text quality judgment.
</nextsent>
<nextsent>this inadequacy limits, inevitably, the application of the existing metrics.
</nextsent>
<nextsent>the atec metric (wong and kit, 2008) was developed as response to this inadequacy, with focus to account for the process of human comprehension of sentences via two fundamental features of text, namely word choice and word order.
</nextsent>
<nextsent>it integrates various explicit measures for these two features in order to provide an intuitive and informative evaluation result.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1133">
<title id=" W10-1755.xml">the parameter optimized atec metric for mt evaluation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>related studies in recent years have extensively revealed more essential characteristics of bleu, including its strengths and weaknesses.
</prevsent>
<prevsent>this has aroused the proposal of different new evaluation metrics aimed at addressing such weaknesses so as to find some other hopefully better alternatives for the task.
</prevsent>
</prevsection>
<citsent citstr=" W09-0441 ">
effort in this direction brings up some advanced metrics such as meteor (banerjee and lavie, 2005) <papid> W05-0909 </papid>and terp (snover et al, 2009) <papid> W09-0441 </papid>that seem to have already achieved considerably strong correlations with human judgments.</citsent>
<aftsection>
<nextsent>nevertheless, few metrics have really nurtured our understanding of possible parameters involved in our language comprehension and text quality judgment.
</nextsent>
<nextsent>this inadequacy limits, inevitably, the application of the existing metrics.
</nextsent>
<nextsent>the atec metric (wong and kit, 2008) was developed as response to this inadequacy, with focus to account for the process of human comprehension of sentences via two fundamental features of text, namely word choice and word order.
</nextsent>
<nextsent>it integrates various explicit measures for these two features in order to provide an intuitive and informative evaluation result.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1134">
<title id=" W10-1755.xml">the parameter optimized atec metric for mt evaluation </title>
<section> the atec metric.  </section>
<citcontext>
<prevsection>
<prevsent>it is general consensus that the performance of an evaluation metric can be improved by matching more words between mt outputs and human references.
</prevsent>
<prevsent>linguistic resources like stemmer and wordnet are widely applied by many metrics for matching word stems and synonyms.
</prevsent>
</prevsection>
<citsent citstr=" P94-1019 ">
atec is equipped with these two modules as well, and furthermore, with two measures for word similarity, including wordnet-based (wu and palmer, 1994) <papid> P94-1019 </papid>and corpus-based measure (landauer et al, 1998) for matching word pairs of similar meanings.</citsent>
<aftsection>
<nextsent>our previous work (wong, 2010) shows that the inclusion of semantically similar words results in positive correlation gain comparable to the use of wordnet for synonym identification.
</nextsent>
<nextsent>in addition to increasing the number of legitimate matches, we also consider the importance of each match.
</nextsent>
<nextsent>although most metrics score every matched word with equal weight, different words indeed contribute different amount of information to the meaning of sentence.
</nextsent>
<nextsent>in example 1 below, both c1 and c2 contain the same number of words matched with ref, but the matches in c1 are more informative and therefore should be assigned higher weights.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1136">
<title id=" W10-1726.xml">reproducible results in parsing based machine translation the jhu shared task submission </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>while there are notable and laudable exceptions, many publications fail to provide the source code and scripts necessary to reproduce results.
</prevsent>
<prevsent>the use of restricted data, not freely available for download by any interested researcher only compounds these problems.
</prevsent>
</prevsection>
<citsent citstr=" J08-3010 ">
pedersen (2008) <papid> J08-3010 </papid>rightly argues that the implementation details so often ignored in publications are in fact essential for our research to be reproducible science.</citsent>
<aftsection>
<nextsent>reproducibility in machine translation is made more challenging by the complexity of experimental workflows.
</nextsent>
<nextsent>results in machine translation research conducted as visiting researcher at johns hopkins university tasks are dependent on cascade of processing steps and configurations.
</nextsent>
<nextsent>while interesting subsets of these usually appear in experimental descriptions, many steps (preprocessing techniques, alignment parameters, translation rule extraction parameters, language model parameters, list of features used) are invariably omitted, even though these configurations are often critical to reproducing results.this paper describes the johns hopkins university submission to the 2010 workshop on statistical machine translation shared translation task.
</nextsent>
<nextsent>links to the software, scripts, and configurations used to run the experiments described herein areprovided.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1137">
<title id=" W10-1726.xml">reproducible results in parsing based machine translation the jhu shared task submission </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>section 5 presents the shared task results.
</prevsent>
<prevsent>the last four years have witnessed the implementation and release of numerous open source machine translation systems.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
the widely used moses system (koehn et al, 2007) <papid> P07-2045 </papid>implements the standard phrase-based translation model.</citsent>
<aftsection>
<nextsent>parsing based translation models are implemented by joshua (li et al, 2009), <papid> W09-0424 </papid>samt (zollmann and venugopal, 2006)<papid> W06-3119 </papid>and cdec (dyer et al, 2010).</nextsent>
<nextsent>cunei (phillips and brown, 2009) implements statistical example-based translation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1138">
<title id=" W10-1726.xml">reproducible results in parsing based machine translation the jhu shared task submission </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the last four years have witnessed the implementation and release of numerous open source machine translation systems.
</prevsent>
<prevsent>the widely used moses system (koehn et al, 2007) <papid> P07-2045 </papid>implements the standard phrase-based translation model.</prevsent>
</prevsection>
<citsent citstr=" W09-0424 ">
parsing based translation models are implemented by joshua (li et al, 2009), <papid> W09-0424 </papid>samt (zollmann and venugopal, 2006)<papid> W06-3119 </papid>and cdec (dyer et al, 2010).</citsent>
<aftsection>
<nextsent>cunei (phillips and brown, 2009) implements statistical example-based translation.
</nextsent>
<nextsent>olteanu etal.
</nextsent>
<nextsent>(2006) and schwartz (2008) respectively provide additional open-source implementations of phrase-based and hierarchical decoders.the srilm (stolcke, 2002), irstlm (federico et al, 2008), and randlm (talbot and osborne, 2007) <papid> P07-1065 </papid>tool kits enable efficient training and 177 no rm ali ze ru nm er ru nm br on tr ue ca se dt ran sla tions un zip da ta to ke niz hi ero tr an slate su bs ample fo rt ru ec as ing train lm extra ct tr ue ca se gr am ma train tr ue ca se lm m scrip ts sr il ru nm br on tr an sla tions extra ct gr am ma align tr ue ca se dd ata align su bs ample re store to tr ue ca sej os hu do wn loa dd ata re mo ve xm be rk ele ya lig ne figure 1: machine translation workflow.</nextsent>
<nextsent>square nodes in grey indicate software and scripts.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1139">
<title id=" W10-1726.xml">reproducible results in parsing based machine translation the jhu shared task submission </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the last four years have witnessed the implementation and release of numerous open source machine translation systems.
</prevsent>
<prevsent>the widely used moses system (koehn et al, 2007) <papid> P07-2045 </papid>implements the standard phrase-based translation model.</prevsent>
</prevsection>
<citsent citstr=" W06-3119 ">
parsing based translation models are implemented by joshua (li et al, 2009), <papid> W09-0424 </papid>samt (zollmann and venugopal, 2006)<papid> W06-3119 </papid>and cdec (dyer et al, 2010).</citsent>
<aftsection>
<nextsent>cunei (phillips and brown, 2009) implements statistical example-based translation.
</nextsent>
<nextsent>olteanu etal.
</nextsent>
<nextsent>(2006) and schwartz (2008) respectively provide additional open-source implementations of phrase-based and hierarchical decoders.the srilm (stolcke, 2002), irstlm (federico et al, 2008), and randlm (talbot and osborne, 2007) <papid> P07-1065 </papid>tool kits enable efficient training and 177 no rm ali ze ru nm er ru nm br on tr ue ca se dt ran sla tions un zip da ta to ke niz hi ero tr an slate su bs ample fo rt ru ec as ing train lm extra ct tr ue ca se gr am ma train tr ue ca se lm m scrip ts sr il ru nm br on tr an sla tions extra ct gr am ma align tr ue ca se dd ata align su bs ample re store to tr ue ca sej os hu do wn loa dd ata re mo ve xm be rk ele ya lig ne figure 1: machine translation workflow.</nextsent>
<nextsent>square nodes in grey indicate software and scripts.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1141">
<title id=" W10-1726.xml">reproducible results in parsing based machine translation the jhu shared task submission </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>cunei (phillips and brown, 2009) implements statistical example-based translation.
</prevsent>
<prevsent>olteanu etal.
</prevsent>
</prevsection>
<citsent citstr=" P07-1065 ">
(2006) and schwartz (2008) respectively provide additional open-source implementations of phrase-based and hierarchical decoders.the srilm (stolcke, 2002), irstlm (federico et al, 2008), and randlm (talbot and osborne, 2007) <papid> P07-1065 </papid>tool kits enable efficient training and 177 no rm ali ze ru nm er ru nm br on tr ue ca se dt ran sla tions un zip da ta to ke niz hi ero tr an slate su bs ample fo rt ru ec as ing train lm extra ct tr ue ca se gr am ma train tr ue ca se lm m scrip ts sr il ru nm br on tr an sla tions extra ct gr am ma align tr ue ca se dd ata align su bs ample re store to tr ue ca sej os hu do wn loa dd ata re mo ve xm be rk ele ya lig ne figure 1: machine translation workflow.</citsent>
<aftsection>
<nextsent>square nodes in grey indicate software and scripts.
</nextsent>
<nextsent>the scripts and configuration files used to implement and run this workflow are available for download at http://sourceforge.net/projects/joshua/files/joshua/1.3/ wmt2010-experiment.tgz/download 178 querying of n-gram language models.freely available parallel corpora for numerous european languages have also been released in recent years.
</nextsent>
<nextsent>these include the europarl (koehn, 2005) and jrc-acquis (steinberger et al, 2006) legislative corpora, each of which includes data for most eu language pairs.
</nextsent>
<nextsent>the smaller news commentary corpora (callison-burch et al, 2007; callison-burch et al, 2008) provide smaller amounts of parallel data in the news genre.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1143">
<title id=" W10-1726.xml">reproducible results in parsing based machine translation the jhu shared task submission </title>
<section> experimental configuration.  </section>
<citcontext>
<prevsection>
<prevsent>our experimental workflow requires that srilm be compiled separately, with the $srilm environment variable set to the install location.
</prevsent>
<prevsent>179 source target parallel corpora german english news-commentary10.de-en europarl-v5.de-en english german news-commentary10.de-en europarl-v5.de-en french english news-commentary10.fr-en europarl-v5.fr-en giga-fren.release2 undoc.2000.en-fr english french news-commentary10.fr-en europarl-v5.fr-en giga-fren.release2 undoc.2000.en-fr spanish english news-commentary10.es-en europarl-v5.es-en undoc.2000.en-es english spanish news-commentary10.es-en europarl-v5.es-en undoc.2000.en-es table 1: parallel training data used for training translation model, per language pair target monolingual corpora english europarl-v5.en news-commentary10.en news.en.shuffled undoc.2000.en-fr.en giga-fren.release2.en french europarl-v5.fr news-commentary10.fr news.fr.shuffled undoc.2000.en-fr.fr giga-fren.release2.fr german europarl-v5.de news-commentary10.de news.de.shuffled spanish europarl-v5.es news-commentary10.es news.es.shuffled undoc.2000.en-es.es table 2: monolingual training data used for training language model, per target language pling; training sentences are selected based on the estimated likelihood of each sentence being useful later for translating particular test corpus.
</prevsent>
</prevsection>
<citsent citstr=" N06-1014 ">
given sub sampled parallel training corpus, word alignment is performed using the berkeley aligner4 (liang et al, 2006).<papid> N06-1014 </papid></citsent>
<aftsection>
<nextsent>for each language pair, synchronous context free translation grammar is extracted for particular test set, following the methods of lopez (2008) as implemented in (schwartz and callison-burch,2010).
</nextsent>
<nextsent>for the largest training sets (french english and english-french) the original (lopez, 2008) implementation included with hiero was used to save time during training5.because of the use of sub sampling, the extracted translation grammars are targeted for usewith specific test set.
</nextsent>
<nextsent>our experiments were be gun prior to the release of the blind newstest2010 shared task test set.
</nextsent>
<nextsent>sub sampling was performed for the development tuning set, news-test2008, and the development test set, newstest2009.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1145">
<title id=" W10-1726.xml">reproducible results in parsing based machine translation the jhu shared task submission </title>
<section> experimental configuration.  </section>
<citcontext>
<prevsection>
<prevsent>recent work has shown that parsing-based machine translation using samt (zollmann and venugopal, 2006)<papid> W06-3119 </papid>grammars with rich nonterminal sets can demonstrate substantial gains over hierarchical grammars for certain language pairs (baker et al, 2009).</prevsent>
<prevsent>joshua supports such grammars; the experimental workflow presented here could easily be extended in future research to incorporate the use of samt grammars with additional language pairs.</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
the z-mert implementation (zaidan, 2009) of minimum error rate training (och, 2003) <papid> P03-1021 </papid>was used for parameter tuning.</citsent>
<aftsection>
<nextsent>tuned grammars were usedby joshua to translate all test sets.
</nextsent>
<nextsent>the joshua decoder produces n-best lists of translations.
</nextsent>
<nextsent>rather than simply selecting the top candidate from each list, we take the preferred candidate after perform minimum bayes risk rescoring (ku mar and byrne, 2004).<papid> N04-1022 </papid></nextsent>
<nextsent>once single translation has been extracted for each sentence in the test set, we repeat the procedures described above to train language and translation models for use in translating lower cased results into more human-readable true cased form.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1146">
<title id=" W10-1726.xml">reproducible results in parsing based machine translation the jhu shared task submission </title>
<section> experimental configuration.  </section>
<citcontext>
<prevsection>
<prevsent>tuned grammars were usedby joshua to translate all test sets.
</prevsent>
<prevsent>the joshua decoder produces n-best lists of translations.
</prevsent>
</prevsection>
<citsent citstr=" N04-1022 ">
rather than simply selecting the top candidate from each list, we take the preferred candidate after perform minimum bayes risk rescoring (ku mar and byrne, 2004).<papid> N04-1022 </papid></citsent>
<aftsection>
<nextsent>once single translation has been extracted for each sentence in the test set, we repeat the procedures described above to train language and translation models for use in translating lower cased results into more human-readable true cased form.
</nextsent>
<nextsent>a true case language model is trained as above, but on the tokenized (but not normalized) monolingual target language corpus.
</nextsent>
<nextsent>monotone word alignments are deterministically created, mapping normalized lowercase training text to the original true case text.
</nextsent>
<nextsent>as in bilingual translation, sub sampling is performed for the training set, and translation grammar for lowercase-to-truecase is extracted.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1147">
<title id=" W10-1726.xml">reproducible results in parsing based machine translation the jhu shared task submission </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>the detokenize.perl and wrap-xml.perl scripts provided for the shared task were manually applied to true cased translation results prior to final submission of results.the code used for sub sampling, grammar extraction, decoding, minimum error rate training, and minimum bayes risk rescoring is provided with joshua6, with the exception of the original(lopez, 2008) grammar extraction implementation.
</prevsent>
<prevsent>the experiments described in sections 3 and 4 above provided true cased translations for six language pairs in the translation sharedtask: english-french, english-german, english spanish, french-english, german-english, andspanish-english.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
table 3 lists the automatic metric scores for the newstest2010 test set, according to the bleu (papineni et al, 2002) <papid> P02-1040 </papid>and ter (snover et al, 2006) metrics.</citsent>
<aftsection>
<nextsent>source target bleu bleu- ter cased german english 21.3 19.5 0.660 english german 15.2 14.6 0.738 french english 27.7 26.4 0.614 english french 23.8 22.8 0.681 spanish english 29.0 27.6 0.595 english spanish 28.1 26.5 0.596 table 3: automatic metric scores for the test set newstest2010 the submitted system ranked highest among shared task participants for the german-english task, according to ter.
</nextsent>
<nextsent>in order to provide points of comparison withthe 2009 workshop on statistical machine translation shared translation task participants, table 4 lists automatic metric scores for our systems?
</nextsent>
<nextsent>translations of the newstest2009 test set, which we used as development test set.
</nextsent>
<nextsent>the experiments in this paper can be reproduced by running the make scripts provided in the6http://sourceforge.net/projects/joshua/files/joshua/1.3/joshua 1.3.tgz/download ? joshua version 1.3 source target bleu german english 18.19 english german 13.57 french english 26.41 english french 25.28 spanish english 25.28 english spanish 24.02table 4: automatic metric scores for the development test set newstest2009 following file: http://sourceforge.net/ projects/joshua/files/joshua/1.3/ wmt2010-experiment.tgz/download.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1148">
<title id=" W10-1409.xml">parsing word clusters </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>furthermore, clustering also helps significantly for medium to high frequency words, suggesting that training on word clusters leads to better probability estimates for these words.
</prevsent>
<prevsent>statistical parsing techniques have dramatically improved over the last 15 years, yet lexical data sparseness remains critical problem.
</prevsent>
</prevsection>
<citsent citstr=" P08-1068 ">
and the richer the morphology of language, the sparser the treebank driven lexicons will be for that language.koo et al (2008) <papid> P08-1068 </papid>have proposed to use word clusters as features to improve graph-based statistical dependency parsing for english and czech.</citsent>
<aftsection>
<nextsent>their clusters are obtained using unsupervised clustering,which makes it possible to use raw corpus containing several million words.
</nextsent>
<nextsent>candito and crabb?
</nextsent>
<nextsent>(2009) applied clustering to generative constituency parsing for french.
</nextsent>
<nextsent>they use des inflection step that removes some inflection marks from word forms and then replaces them with word clusters, resulting insignificant improvement in parsing performance.clustering words seems useful as way of addressing the lexical data sparseness problem, since count son clusters are more reliable and lead to better probability estimates.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1149">
<title id=" W10-1409.xml">parsing word clusters </title>
<section> berkeley parser.  </section>
<citcontext>
<prevsection>
<prevsent>et al, 2003), which contains 12531 sentences, 350931 tokens, from the newspaper le monde.
</prevsent>
<prevsent>we used the treebank instantiation (hereafter ftb-uc) as first described in (candito and crabb?, 2009), where :(i) the rich original annotation containing morphological and functional information is mapped to simpler phrase-structure treebank with tagset of 28 part-of-speech tags, and no functional annotation (ii) some compounds with regular syntax are broken down into phrases containing several simple words(iii) the remaining sequences annotated ascom pound words in the ftb are merged into single token, whose components are separated with an underscore for all experiments in this paper (tagging and parsing) we used the same partition of the treebank as these authors : first 10% for test, next 10% for dev and the rest for training1.
</prevsent>
</prevsection>
<citsent citstr=" P06-1055 ">
we report here experiments using the berkeley pcfg parser with latent annotations (petrov et al, 2006), <papid> P06-1055 </papid>hereafter bky, which is constituent parser that has been proven to perform well for french (crabb?</citsent>
<aftsection>
<nextsent>and candito, 2008; seddah et al, 2009), 1more precisely the partition is : first 1235 sentences for test, next 1235 sentences for development, and remaining 9881 sentences for training.
</nextsent>
<nextsent>though little lower than combination of tagger plus the dependency-based mst parser (candito et al., 2010).
</nextsent>
<nextsent>though pcfg-style parsers operate on too narrow domain of locality, splitting symbols according to structural and/or lexical properties is known to help parsing (klein and manning., 2003).<papid> P03-1054 </papid>following (matsuzaki et al, 2005), <papid> P05-1010 </papid>the bky algorithm uses em to estimate probabilities on symbols that are automatically augmented with latent annotations, process which can be viewed as symbol splitting.</nextsent>
<nextsent>it iteratively evaluates each such split and merges back the less beneficial ones.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1150">
<title id=" W10-1409.xml">parsing word clusters </title>
<section> berkeley parser.  </section>
<citcontext>
<prevsection>
<prevsent>and candito, 2008; seddah et al, 2009), 1more precisely the partition is : first 1235 sentences for test, next 1235 sentences for development, and remaining 9881 sentences for training.
</prevsent>
<prevsent>though little lower than combination of tagger plus the dependency-based mst parser (candito et al., 2010).
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
though pcfg-style parsers operate on too narrow domain of locality, splitting symbols according to structural and/or lexical properties is known to help parsing (klein and manning., 2003).<papid> P03-1054 </papid>following (matsuzaki et al, 2005), <papid> P05-1010 </papid>the bky algorithm uses em to estimate probabilities on symbols that are automatically augmented with latent annotations, process which can be viewed as symbol splitting.</citsent>
<aftsection>
<nextsent>it iteratively evaluates each such split and merges back the less beneficial ones.
</nextsent>
<nextsent>crabb?
</nextsent>
<nextsent>and candito (2008) show that some of the information carried by the latent annotations is lexical, sincere placing words by their gold part-of-speech tag leadsto worse results than the corresponding perfect tagging test, with words unchanged.
</nextsent>
<nextsent>this is clear indication that lexical distinctions are used, and percolate up the parse tree via the latent annotations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1151">
<title id=" W10-1409.xml">parsing word clusters </title>
<section> berkeley parser.  </section>
<citcontext>
<prevsection>
<prevsent>and candito, 2008; seddah et al, 2009), 1more precisely the partition is : first 1235 sentences for test, next 1235 sentences for development, and remaining 9881 sentences for training.
</prevsent>
<prevsent>though little lower than combination of tagger plus the dependency-based mst parser (candito et al., 2010).
</prevsent>
</prevsection>
<citsent citstr=" P05-1010 ">
though pcfg-style parsers operate on too narrow domain of locality, splitting symbols according to structural and/or lexical properties is known to help parsing (klein and manning., 2003).<papid> P03-1054 </papid>following (matsuzaki et al, 2005), <papid> P05-1010 </papid>the bky algorithm uses em to estimate probabilities on symbols that are automatically augmented with latent annotations, process which can be viewed as symbol splitting.</citsent>
<aftsection>
<nextsent>it iteratively evaluates each such split and merges back the less beneficial ones.
</nextsent>
<nextsent>crabb?
</nextsent>
<nextsent>and candito (2008) show that some of the information carried by the latent annotations is lexical, sincere placing words by their gold part-of-speech tag leadsto worse results than the corresponding perfect tagging test, with words unchanged.
</nextsent>
<nextsent>this is clear indication that lexical distinctions are used, and percolate up the parse tree via the latent annotations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1152">
<title id=" W10-1409.xml">parsing word clusters </title>
<section> unsupervised clustering.  </section>
<citcontext>
<prevsection>
<prevsent>to the best of our knowledge the parts-of-speech tagging performance is state-of-the-art for french3 and the lemmatization performance has no comparable results.
</prevsent>
<prevsent>3a pure maxent based tagger is described in (denis and sagot, 2009), that also uses the lefff, under the form of features for the known categories of word in the lexicon.
</prevsent>
</prevsection>
<citsent citstr=" J92-4003 ">
the authors report 97.70% of accuracy and 90.01% for unseen data.we use the brown et al (1992) <papid> J92-4003 </papid>hard clustering algorithm, which has proven useful for various nlp tasks such as dependency parsing (koo et al, 2008)<papid> P08-1068 </papid>and named entity recognition (liang, 2005).</citsent>
<aftsection>
<nextsent>the algorithm to obtain clusters is as follows: each of the most frequent tokens of the corpus is assign edits own distinct cluster.
</nextsent>
<nextsent>for the (c + 1)th most frequent token, create (c + 1)th cluster.
</nextsent>
<nextsent>then for each pair among the + 1 resulting clusters, merge the pair that minimizes the loss in the likelihood of the corpus, according to bigram language model defined on the clusters.
</nextsent>
<nextsent>repeat this operation for the (c + 2)th most frequent token, etc. the result is hard clustering of words in the corpus into distinct clusters, though the process can be continued to further merge pairs of clusters among the clusters,ending with single cluster for the entire vocabulary.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1154">
<title id=" W10-1409.xml">parsing word clusters </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>more precisely, this previous work reports f1 = 88.29 on the test set, but for sentences ? 40 words, for dfl+clust 20 experiment, and as previously mentioned, the dev set was used as validation set for the bkyalgorithm.
</prevsent>
<prevsent>we report now f1 = 88.22 for the same less-than 40-words sentences, leaving dev set unused at training time.
</prevsent>
</prevsection>
<citsent citstr=" P95-1037 ">
8the conversion uses head propagation rules to find the headon the right-hand side of the cfg rules, first proposed for english in (magerman, 1995).<papid> P95-1037 </papid></citsent>
<aftsection>
<nextsent>hence the process is highly sensitive to part-of-speech tags.
</nextsent>
<nextsent>table 3 shows that both morphological clustering techniques (dfl and autocatlemma) slightly improve performance (+0.97 and +0.73 f1 over the baseline for the test set)9.
</nextsent>
<nextsent>in the case of autocatlemma, morphological ambiguity is totally absent in training set: each terminal symbol is the gold pos+lemma pair, and hence appears with uniquepart-of-speech in the whole training set.
</nextsent>
<nextsent>but at parsing time, the terminal symbols are the pos+lemma pairs predicted by morfette, which are wrong for approximately 3% of the tokens.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1155">
<title id=" W10-1409.xml">parsing word clusters </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>we have already cited the previous work of koo et al.
</prevsent>
<prevsent>(2008) which has directly inspired ours.
</prevsent>
</prevsection>
<citsent citstr=" W09-3829 ">
sagae and gordon (2009) <papid> W09-3829 </papid>explores the use of syntactic clustering to improve transition-based dependency parsing for english : using an available 30 million word corpus parsed with constituency parser, words are represented as vectors of paths within the obtained constituency parses.</citsent>
<aftsection>
<nextsent>words are then clustered using similarity metric between vectors of syntactic paths.
</nextsent>
<nextsent>the clusters are used as features to help transition-based dependency parser.
</nextsent>
<nextsent>note thatthe word representation for clustering is more complex (paths in parse trees), thus these authors have to cluster smaller vocabulary : the top 5000 most frequent words are clustered.agirre et al (2008) <papid> P08-1037 </papid>use the same approach of replacing words by more general symbols, but these symbols are semantic classes.</nextsent>
<nextsent>they test various methods to assign semantic classes (gold semantic class, most-frequent sense in sense-tagged data, or fully unsupervised sense tagger).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1156">
<title id=" W10-1409.xml">parsing word clusters </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>words are then clustered using similarity metric between vectors of syntactic paths.
</prevsent>
<prevsent>the clusters are used as features to help transition-based dependency parser.
</prevsent>
</prevsection>
<citsent citstr=" P08-1037 ">
note thatthe word representation for clustering is more complex (paths in parse trees), thus these authors have to cluster smaller vocabulary : the top 5000 most frequent words are clustered.agirre et al (2008) <papid> P08-1037 </papid>use the same approach of replacing words by more general symbols, but these symbols are semantic classes.</citsent>
<aftsection>
<nextsent>they test various methods to assign semantic classes (gold semantic class, most-frequent sense in sense-tagged data, or fully unsupervised sense tagger).
</nextsent>
<nextsent>though the method is very appealing, the reported improvement in parsing is rather small, especially for the fully unsupervised method.versley and rehbein (2009) <papid> W09-3820 </papid>cluster words according to linear context features, and use the clusters as features to boost discriminative german parsing for unknown words.</nextsent>
<nextsent>another approach to augment the known vocabulary for generative probabilistic parser is the one pursued in (goldberg et al, 2009).<papid> E09-1038 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1157">
<title id=" W10-1409.xml">parsing word clusters </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>note thatthe word representation for clustering is more complex (paths in parse trees), thus these authors have to cluster smaller vocabulary : the top 5000 most frequent words are clustered.agirre et al (2008) <papid> P08-1037 </papid>use the same approach of replacing words by more general symbols, but these symbols are semantic classes.</prevsent>
<prevsent>they test various methods to assign semantic classes (gold semantic class, most-frequent sense in sense-tagged data, or fully unsupervised sense tagger).</prevsent>
</prevsection>
<citsent citstr=" W09-3820 ">
though the method is very appealing, the reported improvement in parsing is rather small, especially for the fully unsupervised method.versley and rehbein (2009) <papid> W09-3820 </papid>cluster words according to linear context features, and use the clusters as features to boost discriminative german parsing for unknown words.</citsent>
<aftsection>
<nextsent>another approach to augment the known vocabulary for generative probabilistic parser is the one pursued in (goldberg et al, 2009).<papid> E09-1038 </papid></nextsent>
<nextsent>within plain pcfg, the lexical probabilities for words that are rare or absent in the treebank are taken from an external lexical probability distribution, estimated using lexicon and the baulm-welch training of an hmm tagger.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1158">
<title id=" W10-1409.xml">parsing word clusters </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>they test various methods to assign semantic classes (gold semantic class, most-frequent sense in sense-tagged data, or fully unsupervised sense tagger).
</prevsent>
<prevsent>though the method is very appealing, the reported improvement in parsing is rather small, especially for the fully unsupervised method.versley and rehbein (2009) <papid> W09-3820 </papid>cluster words according to linear context features, and use the clusters as features to boost discriminative german parsing for unknown words.</prevsent>
</prevsection>
<citsent citstr=" E09-1038 ">
another approach to augment the known vocabulary for generative probabilistic parser is the one pursued in (goldberg et al, 2009).<papid> E09-1038 </papid></citsent>
<aftsection>
<nextsent>within plain pcfg, the lexical probabilities for words that are rare or absent in the treebank are taken from an external lexical probability distribution, estimated using lexicon and the baulm-welch training of an hmm tagger.
</nextsent>
<nextsent>this is proven useful to better parse hebrew.
</nextsent>
<nextsent>we have provided thorough study of the results of parsing word clusters for french.
</nextsent>
<nextsent>we showed that the clustering improves performance both for unseen and rare words and for medium- to high frequency words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1159">
<title id=" W10-1618.xml">dialogue systems for virtual environments </title>
<section> description of the project.  </section>
<citcontext>
<prevsection>
<prevsent>for example, producing the expression the vase that is not above the chair orsofa or under the table?
</prevsent>
<prevsent>would probably not be acceptable.
</prevsent>
</prevsection>
<citsent citstr=" W08-1107 ">
areces et al (2008<papid> W08-1107 </papid>b) propose to use symbolic minimization of the model that represents th estate of the world, in order to obtain logical representation that describe each object uniquely.</citsent>
<aftsection>
<nextsent>in our project we will implement this method and evaluate it within the dialogue system.
</nextsent>
<nextsent>(3) management of the interaction context: to manage the use of the interaction context we will use existing knowledge maintenance systems such as racer2 or pellet3, which support inference tasks such as definition, maintenance and querying of ontologies.
</nextsent>
<nextsent>these systems have been used as inference engines in numerous applications in the areaand, in particular, in dialogue systems for text adventures (benotti, 2009<papid> W09-3929 </papid>b).</nextsent>
<nextsent>once we have studied the behavior of these inference engines on the task,we will analyze its limitations and investigate there quired extensions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1160">
<title id=" W10-1618.xml">dialogue systems for virtual environments </title>
<section> description of the project.  </section>
<citcontext>
<prevsection>
<prevsent>in our project we will implement this method and evaluate it within the dialogue system.
</prevsent>
<prevsent>(3) management of the interaction context: to manage the use of the interaction context we will use existing knowledge maintenance systems such as racer2 or pellet3, which support inference tasks such as definition, maintenance and querying of ontologies.
</prevsent>
</prevsection>
<citsent citstr=" W09-3929 ">
these systems have been used as inference engines in numerous applications in the areaand, in particular, in dialogue systems for text adventures (benotti, 2009<papid> W09-3929 </papid>b).</citsent>
<aftsection>
<nextsent>once we have studied the behavior of these inference engines on the task,we will analyze its limitations and investigate there quired extensions.
</nextsent>
<nextsent>2http://www.racer-systems.com 3http://clarkparsia.com/pellet(4) interpretation of user responses: the interpretation of user responses in the unidirectional system is relatively simple: it amounts to discretizing the continuous flow of user behavior in the 3d world into actions meaningful for the domain task.
</nextsent>
<nextsent>in first stage, we will use the discretizer provided by give.
</nextsent>
<nextsent>after evaluating it we can determine whether or not this module meets the requirements of our task and what are its limitations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1166">
<title id=" W10-1618.xml">dialogue systems for virtual environments </title>
<section> introducing the research group.  </section>
<citcontext>
<prevsection>
<prevsent>in relation with the study of knowledge representation, they have also investigated and developed algorithms for generating referring expressions (areces et al, 2008<papid> W08-1107 </papid>b).</prevsent>
<prevsent>the second line of research of the pln group thatis relevant for this project is context-based evalua 5http://www.cs.famaf.unc.edu.ar/pln 6http://www.glyc.dc.uba.ar/intohylo/tion.</prevsent>
</prevsection>
<citsent citstr=" L08-1401 ">
members of the group have proposed an evaluation model for machine translation systems which relates the context of use to potentially important quality characteristics (estrella et al, 2008; <papid> L08-1401 </papid>estrella et al, 2009).</citsent>
<aftsection>
<nextsent>this model is general enough to be applied to other systems that produce natural language like the ones proposed in this paper.
</nextsent>
<nextsent>thanks to the background on machine translation systems theteam has experience evaluating and comparing natural language output produced in different languages (spanish and english in particular), which will be relevant for the development of the language tutor described in section 2.4.
</nextsent>
<nextsent>finally, the team has experience developing and evaluating multimodal corpora like those described in section 2 (estrella and popescu-belis, 2008).
</nextsent>
<nextsent>the third line of research that is relevant for this project is pragmatics.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1170">
<title id=" W10-1618.xml">dialogue systems for virtual environments </title>
<section> introducing the research group.  </section>
<citcontext>
<prevsection>
<prevsent>the third line of research that is relevant for this project is pragmatics.
</prevsent>
<prevsent>in this area the team has implemented conversational agent which is able toinfer and negotiate conversational implicatures using inference tasks such as classical planning and planning under incomplete information (benotti, 2009<papid> W09-3929 </papid>b).</prevsent>
</prevsection>
<citsent citstr=" W09-3704 ">
we have also investigated how to infer conversational implicatures triggered by comparative utterances (benotti and traum, 2009).<papid> W09-3704 </papid></citsent>
<aftsection>
<nextsent>recently we have done corpus-based work, which shows what kinds of implicatures are inferred and negotiated by human dialogue participants during task situated in 3d virtual environment (benotti, 2009<papid> W09-3929 </papid>a).</nextsent>
<nextsent>other lines of research in the pln group are not directly related to the project at this stage, but might become relevant in the future.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1179">
<title id=" W10-3210.xml">the annotation of event schema in chinese </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>carlson et al (2003) describes the experience of developing dis course-annotated corpus grounded in the framework of rhetorical structure theory.
</prevsent>
<prevsent>the resulting corpus contains 385 documents selected from the penn treebank.
</prevsent>
</prevsection>
<citsent citstr=" W04-2703 ">
penn discourse treebank(miltsakaki et al, 2004; <papid> W04-2703 </papid>webber et al, 2005) is to annotate the million-word wsj corpus in the penn treebank with layer of discourse information.</citsent>
<aftsection>
<nextsent>although the idea of annotating connectives and their arguments comes from the theoretical work on discourse connectives in the framework of lexicalized grammar, the corpus itself is not tied to any particular theory.
</nextsent>
<nextsent>discourse connectives were treated as discourse-level predicates of binary discourse relations that take two abstract objects such as events, states, and propositions.
</nextsent>
<nextsent>the two arguments to discourse connective were simply labeled arg1 and arg2.
</nextsent>
<nextsent>event schema annotation 3.1 the elementary unit of event schema.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1180">
<title id=" W10-1719.xml">the karlsruhe institute for technology translation system for the aclwmt 2010 </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>in section 5 we present the performance of the system variants applying the different models and chose the systems used for creating the submissions for the english-german and german-english translation task.
</prevsent>
<prevsent>section 6draws conclusions and suggests directions for future work.
</prevsent>
</prevsection>
<citsent citstr=" W08-0303 ">
the baseline systems for the translation directionsgerman-english and english-german are both developed using discriminative word alignment (niehues and vogel, 2008) <papid> W08-0303 </papid>and the moses toolkit (koehn et al, 2007) <papid> P07-2045 </papid>for extracting phrase pair sand generating the phrase table from the discriminative word alignments.</citsent>
<aftsection>
<nextsent>the difficult reordering between german and english was modeled using pos-based reordering rules.
</nextsent>
<nextsent>these rules were learned using word-aligned parallel corpus.
</nextsent>
<nextsent>the pos tags for the reordering models are generated using the tree tagger (schmid, 1994) for all languages.
</nextsent>
<nextsent>translation is performed by the sttk decoder(vogel, 2003) and all systems are optimized towards bleu using minimum error rate training as proposed in venugopal et al (2005).<papid> W05-0836 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1181">
<title id=" W10-1719.xml">the karlsruhe institute for technology translation system for the aclwmt 2010 </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>in section 5 we present the performance of the system variants applying the different models and chose the systems used for creating the submissions for the english-german and german-english translation task.
</prevsent>
<prevsent>section 6draws conclusions and suggests directions for future work.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
the baseline systems for the translation directionsgerman-english and english-german are both developed using discriminative word alignment (niehues and vogel, 2008) <papid> W08-0303 </papid>and the moses toolkit (koehn et al, 2007) <papid> P07-2045 </papid>for extracting phrase pair sand generating the phrase table from the discriminative word alignments.</citsent>
<aftsection>
<nextsent>the difficult reordering between german and english was modeled using pos-based reordering rules.
</nextsent>
<nextsent>these rules were learned using word-aligned parallel corpus.
</nextsent>
<nextsent>the pos tags for the reordering models are generated using the tree tagger (schmid, 1994) for all languages.
</nextsent>
<nextsent>translation is performed by the sttk decoder(vogel, 2003) and all systems are optimized towards bleu using minimum error rate training as proposed in venugopal et al (2005).<papid> W05-0836 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1182">
<title id=" W10-1719.xml">the karlsruhe institute for technology translation system for the aclwmt 2010 </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>these rules were learned using word-aligned parallel corpus.
</prevsent>
<prevsent>the pos tags for the reordering models are generated using the tree tagger (schmid, 1994) for all languages.
</prevsent>
</prevsection>
<citsent citstr=" W05-0836 ">
translation is performed by the sttk decoder(vogel, 2003) and all systems are optimized towards bleu using minimum error rate training as proposed in venugopal et al (2005).<papid> W05-0836 </papid></citsent>
<aftsection>
<nextsent>2.1 training, development and test data.
</nextsent>
<nextsent>we used the data provided for the wmt for training, optimizing and testing our systems: our training corpus consists of europarl and news commentary data, for optimization we use new stest2008 as development set and newstest2009 as test set.
</nextsent>
<nextsent>the baseline language models are trained on the target language part of the europarl and news commentary corpora.
</nextsent>
<nextsent>additional, bigger language models were trained on monolingual corpora.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1183">
<title id=" W10-1719.xml">the karlsruhe institute for technology translation system for the aclwmt 2010 </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>by ss?.
</prevsent>
<prevsent>if thenew word is correct word according to the hun spell lexicon using the new spelling rules, we map the words.
</prevsent>
</prevsection>
<citsent citstr=" E03-1076 ">
when translating from german to english, we apply compound splitting as described in koehn and knight (2003) <papid> E03-1076 </papid>to the german corpus.as last preprocessing step we remove sentences that are too long and empty lines to obtain the final training corpus.</citsent>
<aftsection>
<nextsent>reordering was applied on the source side priorto decoding through the generation of lattices encoding possible reorderings of each source sentence that better match the word sequence in the target language.
</nextsent>
<nextsent>these possible reorderings were learned based on the pos of the source language words in the training corpus and the information about alignments between source and target language words in the corpus.
</nextsent>
<nextsent>for short-range reorderings, continuous reordering rules were applied to the test sentences (rottmann and vogel,2007).
</nextsent>
<nextsent>to model the long-range reorderings between german and english, different types of non continuous reordering rules were applied depending on the translation direction.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1184">
<title id=" W10-1719.xml">the karlsruhe institute for technology translation system for the aclwmt 2010 </title>
<section> word reordering model.  </section>
<citcontext>
<prevsection>
<prevsent>for short-range reorderings, continuous reordering rules were applied to the test sentences (rottmann and vogel,2007).
</prevsent>
<prevsent>to model the long-range reorderings between german and english, different types of non continuous reordering rules were applied depending on the translation direction.
</prevsent>
</prevsection>
<citsent citstr=" W09-0435 ">
(niehues and kolss, 2009).<papid> W09-0435 </papid></citsent>
<aftsection>
<nextsent>when translating from english to german, most of the changes in word order consist in shift to the right while typical word shifts in german to english translations take place in the reverse direction.
</nextsent>
<nextsent>1http://hunspell.sourceforge.net/
</nextsent>
<nextsent>the translation model was trained on the parallel corpus and the word alignment was generated by discriminative word alignment model, which is described below.
</nextsent>
<nextsent>the phrase table was trained using the moses training scripts, but for the ger manto english system we used different phrase extraction method described in detail in section 4.2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1185">
<title id=" W10-1719.xml">the karlsruhe institute for technology translation system for the aclwmt 2010 </title>
<section> translation model.  </section>
<citcontext>
<prevsection>
<prevsent>the translation model was trained on the parallel corpus and the word alignment was generated by discriminative word alignment model, which is described below.
</prevsent>
<prevsent>the phrase table was trained using the moses training scripts, but for the ger manto english system we used different phrase extraction method described in detail in section 4.2.
</prevsent>
</prevsection>
<citsent citstr=" W06-1607 ">
in addition, we applied phrase table smoothing as described in foster et al (2006).<papid> W06-1607 </papid></citsent>
<aftsection>
<nextsent>furthermore, we extended the translation model by additional features for unaligned words and introduced bilingual language models.
</nextsent>
<nextsent>4.1 word alignment.
</nextsent>
<nextsent>in most phrase-based smt systems the heuristicgrow-diag-final-and is used to combine the alignments generated by giza++ from both directions.
</nextsent>
<nextsent>then these alignments are used to extract the phrase pairs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1188">
<title id=" W10-2009.xml">modeling the noun phrase versus sentence coordination ambiguity in dutch evidence from surprisal theory </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>not all words, however, are equally easy to process.
</prevsent>
<prevsent>a words processing difficulty is affected by, for instance, its frequency orits effect on the syntactic and semantic interpretation of sentence.
</prevsent>
</prevsection>
<citsent citstr=" N01-1021 ">
a recent theory of sentence processing, surprisal theory (hale, 2001; <papid> N01-1021 </papid>levy, 2008), combines several of these aspects into one single concept, namely the surprisal of word.</citsent>
<aftsection>
<nextsent>a words surprisal is proportional to its expectancy, i.e., the extent to which that word is expected (or pre dicted).
</nextsent>
<nextsent>the processing difficulty word causes during comprehension is argued to be related linearly to its surprisal; the higher the surprisal value of word, the more difficult it is to process.
</nextsent>
<nextsent>in this paper we investigate whether surprisal theory can account for the processing difficulty involved in sentences containing the noun phrase (np) versus sentence (s) coordination ambiguity.the sentences in (1), from self-paced reading experiment by frazier (1987), exemplify this ambi guity: (1) a. piet piet kuste kissed marie marie en and / / haar zusje her sister / / ook too [1,222ms; np-coordination] b. piet piet kuste kissed marie marie en and / / haar zusje her sister / / lachte laughed [1,596ms; s-coordination] both sentences are temporarily ambiguous in the boldface region.
</nextsent>
<nextsent>sentence (1-a) is disambiguate das an np-coordination by the sentence-final adverb ook.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1196">
<title id=" W10-2009.xml">modeling the noun phrase versus sentence coordination ambiguity in dutch evidence from surprisal theory </title>
<section> surprisal theory.  </section>
<citcontext>
<prevsection>
<prevsent>wi1) ] .surprisal theory requires probabilistic language model that generates some form of word expectancy.
</prevsent>
<prevsent>the theory itself, however, is largely neutral with respect to which model is employed.models other than pcfgs can be used to estimate surprisal.
</prevsent>
</prevsection>
<citsent citstr=" P98-2157 ">
nederhof et al (1998), <papid> P98-2157 </papid>for instance, show that prefix probabilities, and therefore surprisal, can be estimated from tree adjoining grammars.</citsent>
<aftsection>
<nextsent>this approach was taken in demberg and keller (2009).
</nextsent>
<nextsent>other approaches have used trigram models (smith and levy, 2008), simple recurrent networks of the elman type (frank, 2009), markov models and echo-state networks(frank and bod, 2010).
</nextsent>
<nextsent>this illustrates that sur prisal theory is not committed to specific claims about the structural representations that language takes in the human mind.
</nextsent>
<nextsent>it rather functions as causal bottleneck?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1197">
<title id=" W10-2009.xml">modeling the noun phrase versus sentence coordination ambiguity in dutch evidence from surprisal theory </title>
<section> surprisal theory.  </section>
<citcontext>
<prevsection>
<prevsent>this approach, however, still leaves open how many analyses are considered in parallel; does the human sentence processor employ full or limited parallelism?
</prevsent>
<prevsent>jurafsky (1996) showed that full parallelism becomes more and more unmanageable when the amount of information used for disambiguation increases.
</prevsent>
</prevsection>
<citsent citstr=" J01-2004 ">
levy, on the other hand, argued that studies of probabilistic parsing reveal that typically small number of analyses are assigned the majority of probability mass (roark, 2001).<papid> J01-2004 </papid></citsent>
<aftsection>
<nextsent>thus, even when assuming full parallelism, only small number of relevant?
</nextsent>
<nextsent>analyses would be considered in parallel.
</nextsent>
<nextsent>3.1 grammar induction.
</nextsent>
<nextsent>in our simulations, we used pcfg to mode lthe phrase structure of natural language.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1199">
<title id=" W10-1007.xml">predicting cloze task quality for vocabulary training </title>
<section> automatic generation of cloze tasks.  </section>
<citcontext>
<prevsection>
<prevsent>identifying suitable sentences from natural language corpora is desirable because the sentences that are found will be authentic.
</prevsent>
<prevsent>depending on the choice of corpora, sentences should also be well-formed and suitable in terms of reading level and content.
</prevsent>
</prevsection>
<citsent citstr=" W05-0203 ">
newspaper text is one popular source (hoshino &amp; nakagawa, 2005; <papid> W05-0203 </papid>liu et al., 2005; <papid> W05-0201 </papid>lee &amp; seneff, 2007).</citsent>
<aftsection>
<nextsent>pino et al.
</nextsent>
<nextsent>(2008) use documents from corpus of texts retrieved from the internet and subsequently filtered according to readability level, category, and appropriateness of content.
</nextsent>
<nextsent>using broader corpus increases the number and variability of potential matching sentences, but also lowers the confidence that sentences will be well-formed and contain appropriate language (brown &amp; eskenazi, 2004).
</nextsent>
<nextsent>2.1 tag-based sentence search.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1200">
<title id=" W10-1007.xml">predicting cloze task quality for vocabulary training </title>
<section> automatic generation of cloze tasks.  </section>
<citcontext>
<prevsection>
<prevsent>identifying suitable sentences from natural language corpora is desirable because the sentences that are found will be authentic.
</prevsent>
<prevsent>depending on the choice of corpora, sentences should also be well-formed and suitable in terms of reading level and content.
</prevsent>
</prevsection>
<citsent citstr=" W05-0201 ">
newspaper text is one popular source (hoshino &amp; nakagawa, 2005; <papid> W05-0203 </papid>liu et al., 2005; <papid> W05-0201 </papid>lee &amp; seneff, 2007).</citsent>
<aftsection>
<nextsent>pino et al.
</nextsent>
<nextsent>(2008) use documents from corpus of texts retrieved from the internet and subsequently filtered according to readability level, category, and appropriateness of content.
</nextsent>
<nextsent>using broader corpus increases the number and variability of potential matching sentences, but also lowers the confidence that sentences will be well-formed and contain appropriate language (brown &amp; eskenazi, 2004).
</nextsent>
<nextsent>2.1 tag-based sentence search.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1203">
<title id=" W10-1007.xml">predicting cloze task quality for vocabulary training </title>
<section> automatic generation of cloze tasks.  </section>
<citcontext>
<prevsection>
<prevsent>2.2 statistical sentence search.
</prevsent>
<prevsent>pino et al(2009) use co-occurrence frequencies to identify candidate sentences.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
they used the stanford parser (klein &amp; manning, 2003) <papid> P03-1054 </papid>to detect sentences within desired range of complexity and likely well-formedness.</citsent>
<aftsection>
<nextsent>co-occurrence frequencies of words in the corpus were calculated and keys were compared to other words in the stem to determine cloze quality, producing suitable cloze questions 66.53% of the time.
</nextsent>
<nextsent>this method operates on the theory that the quality of the context of stem is based on the co-occurrence scores of other words in the sentence.
</nextsent>
<nextsent>along with this result, pino et al. incorporated syntactic complexity in terms of the number of parses found.
</nextsent>
<nextsent>hoshino &amp; nakagawa (2005) <papid> W05-0203 </papid>use machine learning techniques to train cloze task search system.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1205">
<title id=" W10-1007.xml">predicting cloze task quality for vocabulary training </title>
<section> reading level and information theory.  </section>
<citcontext>
<prevsection>
<prevsent>more recent work on the topic also focuses on readability classification at the document level.
</prevsent>
<prevsent>collins-thompson &amp; callan (2005) use unigram language models without syntactic features.
</prevsent>
</prevsection>
<citsent citstr=" W08-0909 ">
heilman et al (2008) <papid> W08-0909 </papid>use probabilistic parser and unigram language models to combine grammatical and lexical features.</citsent>
<aftsection>
<nextsent>(petersen &amp; ostendorf, 2006) add higher-order n-gram features to the above to train support vector machine classifiers for each grade level.
</nextsent>
<nextsent>these recent methods perform well to characterize the level of an entire document, but they are untested for single sentences.
</nextsent>
<nextsent>we wish to investigate if robust unigram model of reading level can be employed to improve the estimation of cloze quality at the sentence level.
</nextsent>
<nextsent>by extension of finn (1978) hypothesis, it is in fact not the 51 overall level of the sentence that has predicted effect on cloze context restriction, but rather the reading level of the words in proximity to the blank.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1207">
<title id=" W10-1826.xml">from descriptive annotation to grammar specification </title>
<section> type gram.  </section>
<citcontext>
<prevsection>
<prevsent>this grammar construction kit?
</prevsent>
<prevsent>offered by type gram clearly resembles the hpsg grammar matrix (matrix?; cf.
</prevsent>
</prevsection>
<citsent citstr=" W02-1502 ">
bender et al 2002).<papid> W02-1502 </papid></citsent>
<aftsection>
<nextsent>it differs from the matrix most essentially through the way in which the grammar internal specifications are semi-automatically?
</nextsent>
<nextsent>updated as the profile grows.
</nextsent>
<nextsent>this systematic linkage between cross-linguistic descriptive classification code and computational grammar code is not yet available in the matrix.
</nextsent>
<nextsent>nothing, though, precludes introducing the type gram architecture also there, in this respect.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1208">
<title id=" W10-1809.xml">annotating under quantification </title>
<section> motivation.  </section>
<citcontext>
<prevsection>
<prevsent>further, we will show that our own effort situ ates itself in little studied relation to formal semantics.
</prevsent>
<prevsent>the most basic type of annotation is the one where computational linguists mark large amounts of textual data with well-known and well understood labels.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
the production of treebanks like the penn treebank (marcus et al 1993) <papid> J93-2004 </papid>makes use of undisputed linguistic categories such as parts of speech.</citsent>
<aftsection>
<nextsent>the aim is to make the computer learn and use irrefutable bits of linguistics.
</nextsent>
<nextsent>(note that, despite agreement, the representation of those categories may differ: see for example the range of available parts of speech tag sets.)
</nextsent>
<nextsent>this type of task mostly involves basic syntactic knowledge,but can be taken to areas of syntax and seman 74tics where the studied phenomena have (some what) clear, agreed upon definition (kingsbury et al, 2002).
</nextsent>
<nextsent>we must clarify that in those cases, the choice of formalism may already imply certain theoretical position ? leading to potential incompatibilities between formalisms.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1209">
<title id=" W10-1809.xml">annotating under quantification </title>
<section> motivation.  </section>
<citcontext>
<prevsection>
<prevsent>however, the categories for such annotation are themselves fixed: there is generally agreed broad understanding of concepts such as noun phrases and coordination.
</prevsent>
<prevsent>another type of annotation concerns tasks where the linguistic categories at play are notfixed.
</prevsent>
</prevsection>
<citsent citstr=" W06-1312 ">
one example is discourse annotation according to rhetorical function (teufel et al 2006) <papid> W06-1312 </papid>where humans are asked to differentiate between several discursive categories such as contrast?</citsent>
<aftsection>
<nextsent>orweakness?.
</nextsent>
<nextsent>in such task, the computational linguist develops theory where different states or values are associated with various phenomena.
</nextsent>
<nextsent>in order to show that the world functions according to the model presented, experimentation is required.
</nextsent>
<nextsent>this usually takes the form of an annotation task where several human subjects are required to mark pieces of text following guidelines inferred fromthe model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1210">
<title id=" W10-1809.xml">annotating under quantification </title>
<section> motivation.  </section>
<citcontext>
<prevsection>
<prevsent>however, the scheme distinguishes only between generic and non-generic entities, as in the ace corpus case, and the corpus itself is limited to three gen res: museum labels, pharmaceutical leaflets, and tutorial dialogues.
</prevsent>
<prevsent>the guidelines are therefore tailored to the domains under consideration; for instance, bare noun phrases are said to be typically generic.
</prevsent>
</prevsection>
<citsent citstr=" W04-0210 ">
this restricted solution has the advantage of providing good agreement between annotators (poesio, 2004 <papid> W04-0210 </papid>reports kappa value of 0.82 for this annotation).</citsent>
<aftsection>
<nextsent>we use as corpus snapshot of the english version of the online encyclopaedia wikipedia.1 the choice is motivated by the fact that wikipedia can be taken as fairly balanced corpus: although it is presented as an encyclopaedia, it contains wide variety of text ranging from typical encyclopaedic descriptions to various types of narrative texts (historical reconstructions, film spoilers?, fiction summaries) to instructional material like rules ofgames.
</nextsent>
<nextsent>further, each article in wikipedia is written and edited by many contributors, meaning that speaker heterogeneity is high.
</nextsent>
<nextsent>we would also expect an encyclopaedia to contain relatively many 1http://www.wikipedia.orggenerics, allowing us to assess how our quantificational reading fares in real annotation task.
</nextsent>
<nextsent>finally, the use of an open resource means that the corpus can be freely distributed.2 in order to create our annotation corpus, we first isolated the first 100,000 pages in our snapshot and parsed them into robust minimal recur sion semantics (rmrs) representation (copes take, 2004) using first the rasp parser (briscoe et al 2006) and the rasp to rmrs converter(ritchie, 2004).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1211">
<title id=" W10-1809.xml">annotating under quantification </title>
<section> implementation and results.  </section>
<citcontext>
<prevsection>
<prevsent>table 4, however, suggests that, if agreement is perfect for the one and quant classes, it is very much lower for the some, most and all classes.
</prevsent>
<prevsent>while it is clear that the latter three are the most complex to analyse, we can show that the lower results attached to them are partly due to issues related to kappa as measure ofagreement.
</prevsent>
</prevsection>
<citsent citstr=" J04-1005 ">
feinstein and cicchetti (1990), followed by di eugenio and glass (2004) <papid> J04-1005 </papid>proved that kappa is subject to the effect of prevalence and that different marginal distributions can leadto very different kappa values for the same observed agreement.</citsent>
<aftsection>
<nextsent>it can be shown, in particular, that an unbalanced, symmetrical distribution of the data produces much lower figures than balanced or unbalanced, asymmetrical distributions because the expected agreement gets inflated.
</nextsent>
<nextsent>our confusion matrices indicate that our data falls intothe category of unbalanced, symmetrical distribution: the classes are not evenly distributed but annotators agree on the relative prevalence of each class.
</nextsent>
<nextsent>moreover, in the quantification task itself, the one class covers roughly 50% of the data.this means that, when calculating per class agree class kind not-kind quant kappa 0.63 0.71 0.88 table 3: per class inter-annotator agreement for the kind annotation class one some most all quant kappa 0.81 0.45 0.44 0.51 0.88 table 4: per class inter-annotator agreement for the quantification annotation ment, we get an approximately balanced distribution for the one label and an unbalanced, but still symmetrical, distribution for the other labels.
</nextsent>
<nextsent>this leads to the expected agreement being rather low for the one class and very high for the otherclasses.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1212">
<title id=" W10-1809.xml">annotating under quantification </title>
<section> implementation and results.  </section>
<citcontext>
<prevsection>
<prevsent>pr(a) is the observed agreement between annotators, pr(e) the expected agreement.
</prevsent>
<prevsent>with regard to the purpose of creating gold standard for quantification resolution system, wealso note that out of 300 quantification annotations, there are only 14 cases in which majority decision cannot be found, i.e., at least two annotators agreed in 95% of cases.
</prevsent>
</prevsection>
<citsent citstr=" J08-3001 ">
thus, despite some low kappa results, the data can adequately be used for the production of training material.4 4as far as such data ever can be: reidsma and carletta,2008, <papid> J08-3001 </papid>show that systematic disagreements between annotators will produce bad machine learning, regardless of the kappa obtained on the data.</citsent>
<aftsection>
<nextsent>79in section 8, we introduce difficulties encountered by our subjects, as related in post-annotation discussions.
</nextsent>
<nextsent>we focus on quantification.
</nextsent>
<nextsent>8.1 reference.
</nextsent>
<nextsent>although we tried to make the task as simple as possible for the annotators by asking them to paraphrase the sentences that they were reading, they were not free from having to work out the referent of the np (consciously or unconsciously) and we have evidence that they did not always pick the same referent, leading to disagreements at the quantification stage.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1213">
<title id=" W10-2403.xml">report of news 2010 transliteration mining shared task </title>
<section> mint? microsoft research india, india.  </section>
<citcontext>
<prevsection>
<prevsent>to calculate the ned, the target language string is first roman ized by replacing each target grapheme by the source grapheme having the highest conditional probability.
</prevsent>
<prevsent>these conditional probabilities are obtained by aligning the seed set of transliteration pairs using an m2m aligner approach (jiampojamarn et. al., 2007).
</prevsent>
</prevsection>
<citsent citstr=" P07-1083 ">
the second system uses svm based discriminative classifier trained using an improved feature representation (bk 2007) (bergsma and kondrak, 2007).<papid> P07-1083 </papid></citsent>
<aftsection>
<nextsent>these features include all substring pairs up to maximum length of three as extracted from the aligned word pairs.
</nextsent>
<nextsent>the transliteration pairs in the seed data provided for the shared task were used as positive examples.
</nextsent>
<nextsent>the negative examples were obtained by generating all possible source-target pairs in the seed data and taking those pairs which are not translitera tions but have longest common sub sequence ratio above certain threshold.
</nextsent>
<nextsent>one drawback of this system is that longer sub strings cannot be used due to the combinatorial explosion in the number of unique features as the substring length increases.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1214">
<title id=" W10-2403.xml">report of news 2010 transliteration mining shared task </title>
<section> mint? microsoft research india, india.  </section>
<citcontext>
<prevsection>
<prevsent>the three edits states are substitution state, deletion state and insertion state.
</prevsent>
<prevsent>the parameters of the pair hmm are estimated using the baum-welch expectation maximization algorithm (baum et. al. 1970).
</prevsent>
</prevsection>
<citsent citstr=" E09-1091 ">
finally, as reference, results of previously published system ? mint (udupa et. al., 2009) ? <papid> E09-1091 </papid>were also included in this report as reference.</citsent>
<aftsection>
<nextsent>mint is large scalable mining system for mining transliterations from comparable corpora, essentially multilingual news articles in the same timeline.
</nextsent>
<nextsent>while mint takes two step approach ? first aligning documents based on content similarity, and subsequently mining transliterations based on name similarity model ? for this task, only the transliteration mining step is employed.
</nextsent>
<nextsent>for mining transliterations logistic function based similarity model (lfs) trained discriminatively with the seed parallel names data was employed.
</nextsent>
<nextsent>it should be noted here that the mint algorithm was used as-is for mining transliterations from wikipedia paired titles, with no fine tuning.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1215">
<title id=" W10-2917.xml">improving word alignment by semi supervised ensemble </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the final translation quality of phrase-based translation system is slightly improved, as well.
</prevsent>
<prevsent>word alignment is the process of learning bilingual word correspondences.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
conventional word alignment process is treated as an unsupervised learning task, which automatically learns the correspondences between bilingual words using an em style algorithm (brown et al, 1993; <papid> J93-2003 </papid>vogelet al, 1996; <papid> C96-2141 </papid>och and ney, 2003).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>recently, supervised learning methods have been used to im prove the performance.
</nextsent>
<nextsent>they firstly re-formalize word alignment as some kind of classification task.
</nextsent>
<nextsent>then the labeled data is used to train the classification model, which is finally used to classify unseen test data (liu et al, 2005; <papid> P05-1057 </papid>taskar et al., 2005; <papid> H05-1010 </papid>moore, 2005; <papid> H05-1011 </papid>cherry and lin, 2006; <papid> P06-2014 </papid>haghighi et al, 2009).<papid> P09-1104 </papid></nextsent>
<nextsent>it is well understood that the performance of supervised learning relies heavily on the feature set.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1216">
<title id=" W10-2917.xml">improving word alignment by semi supervised ensemble </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the final translation quality of phrase-based translation system is slightly improved, as well.
</prevsent>
<prevsent>word alignment is the process of learning bilingual word correspondences.
</prevsent>
</prevsection>
<citsent citstr=" C96-2141 ">
conventional word alignment process is treated as an unsupervised learning task, which automatically learns the correspondences between bilingual words using an em style algorithm (brown et al, 1993; <papid> J93-2003 </papid>vogelet al, 1996; <papid> C96-2141 </papid>och and ney, 2003).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>recently, supervised learning methods have been used to im prove the performance.
</nextsent>
<nextsent>they firstly re-formalize word alignment as some kind of classification task.
</nextsent>
<nextsent>then the labeled data is used to train the classification model, which is finally used to classify unseen test data (liu et al, 2005; <papid> P05-1057 </papid>taskar et al., 2005; <papid> H05-1010 </papid>moore, 2005; <papid> H05-1011 </papid>cherry and lin, 2006; <papid> P06-2014 </papid>haghighi et al, 2009).<papid> P09-1104 </papid></nextsent>
<nextsent>it is well understood that the performance of supervised learning relies heavily on the feature set.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1217">
<title id=" W10-2917.xml">improving word alignment by semi supervised ensemble </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the final translation quality of phrase-based translation system is slightly improved, as well.
</prevsent>
<prevsent>word alignment is the process of learning bilingual word correspondences.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
conventional word alignment process is treated as an unsupervised learning task, which automatically learns the correspondences between bilingual words using an em style algorithm (brown et al, 1993; <papid> J93-2003 </papid>vogelet al, 1996; <papid> C96-2141 </papid>och and ney, 2003).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>recently, supervised learning methods have been used to im prove the performance.
</nextsent>
<nextsent>they firstly re-formalize word alignment as some kind of classification task.
</nextsent>
<nextsent>then the labeled data is used to train the classification model, which is finally used to classify unseen test data (liu et al, 2005; <papid> P05-1057 </papid>taskar et al., 2005; <papid> H05-1010 </papid>moore, 2005; <papid> H05-1011 </papid>cherry and lin, 2006; <papid> P06-2014 </papid>haghighi et al, 2009).<papid> P09-1104 </papid></nextsent>
<nextsent>it is well understood that the performance of supervised learning relies heavily on the feature set.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1218">
<title id=" W10-2917.xml">improving word alignment by semi supervised ensemble </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recently, supervised learning methods have been used to im prove the performance.
</prevsent>
<prevsent>they firstly re-formalize word alignment as some kind of classification task.
</prevsent>
</prevsection>
<citsent citstr=" P05-1057 ">
then the labeled data is used to train the classification model, which is finally used to classify unseen test data (liu et al, 2005; <papid> P05-1057 </papid>taskar et al., 2005; <papid> H05-1010 </papid>moore, 2005; <papid> H05-1011 </papid>cherry and lin, 2006; <papid> P06-2014 </papid>haghighi et al, 2009).<papid> P09-1104 </papid></citsent>
<aftsection>
<nextsent>it is well understood that the performance of supervised learning relies heavily on the feature set.
</nextsent>
<nextsent>as more and more features are added into the model, more data is needed for training.
</nextsent>
<nextsent>however, due to the expensive cost of labeling, we usually cannot get as much labeled word alignment data as we want.
</nextsent>
<nextsent>this may limit the performance of supervised methods (wu et al., 2006).<papid> P06-2117 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1219">
<title id=" W10-2917.xml">improving word alignment by semi supervised ensemble </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recently, supervised learning methods have been used to im prove the performance.
</prevsent>
<prevsent>they firstly re-formalize word alignment as some kind of classification task.
</prevsent>
</prevsection>
<citsent citstr=" H05-1010 ">
then the labeled data is used to train the classification model, which is finally used to classify unseen test data (liu et al, 2005; <papid> P05-1057 </papid>taskar et al., 2005; <papid> H05-1010 </papid>moore, 2005; <papid> H05-1011 </papid>cherry and lin, 2006; <papid> P06-2014 </papid>haghighi et al, 2009).<papid> P09-1104 </papid></citsent>
<aftsection>
<nextsent>it is well understood that the performance of supervised learning relies heavily on the feature set.
</nextsent>
<nextsent>as more and more features are added into the model, more data is needed for training.
</nextsent>
<nextsent>however, due to the expensive cost of labeling, we usually cannot get as much labeled word alignment data as we want.
</nextsent>
<nextsent>this may limit the performance of supervised methods (wu et al., 2006).<papid> P06-2117 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1220">
<title id=" W10-2917.xml">improving word alignment by semi supervised ensemble </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recently, supervised learning methods have been used to im prove the performance.
</prevsent>
<prevsent>they firstly re-formalize word alignment as some kind of classification task.
</prevsent>
</prevsection>
<citsent citstr=" H05-1011 ">
then the labeled data is used to train the classification model, which is finally used to classify unseen test data (liu et al, 2005; <papid> P05-1057 </papid>taskar et al., 2005; <papid> H05-1010 </papid>moore, 2005; <papid> H05-1011 </papid>cherry and lin, 2006; <papid> P06-2014 </papid>haghighi et al, 2009).<papid> P09-1104 </papid></citsent>
<aftsection>
<nextsent>it is well understood that the performance of supervised learning relies heavily on the feature set.
</nextsent>
<nextsent>as more and more features are added into the model, more data is needed for training.
</nextsent>
<nextsent>however, due to the expensive cost of labeling, we usually cannot get as much labeled word alignment data as we want.
</nextsent>
<nextsent>this may limit the performance of supervised methods (wu et al., 2006).<papid> P06-2117 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1221">
<title id=" W10-2917.xml">improving word alignment by semi supervised ensemble </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recently, supervised learning methods have been used to im prove the performance.
</prevsent>
<prevsent>they firstly re-formalize word alignment as some kind of classification task.
</prevsent>
</prevsection>
<citsent citstr=" P06-2014 ">
then the labeled data is used to train the classification model, which is finally used to classify unseen test data (liu et al, 2005; <papid> P05-1057 </papid>taskar et al., 2005; <papid> H05-1010 </papid>moore, 2005; <papid> H05-1011 </papid>cherry and lin, 2006; <papid> P06-2014 </papid>haghighi et al, 2009).<papid> P09-1104 </papid></citsent>
<aftsection>
<nextsent>it is well understood that the performance of supervised learning relies heavily on the feature set.
</nextsent>
<nextsent>as more and more features are added into the model, more data is needed for training.
</nextsent>
<nextsent>however, due to the expensive cost of labeling, we usually cannot get as much labeled word alignment data as we want.
</nextsent>
<nextsent>this may limit the performance of supervised methods (wu et al., 2006).<papid> P06-2117 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1223">
<title id=" W10-2917.xml">improving word alignment by semi supervised ensemble </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recently, supervised learning methods have been used to im prove the performance.
</prevsent>
<prevsent>they firstly re-formalize word alignment as some kind of classification task.
</prevsent>
</prevsection>
<citsent citstr=" P09-1104 ">
then the labeled data is used to train the classification model, which is finally used to classify unseen test data (liu et al, 2005; <papid> P05-1057 </papid>taskar et al., 2005; <papid> H05-1010 </papid>moore, 2005; <papid> H05-1011 </papid>cherry and lin, 2006; <papid> P06-2014 </papid>haghighi et al, 2009).<papid> P09-1104 </papid></citsent>
<aftsection>
<nextsent>it is well understood that the performance of supervised learning relies heavily on the feature set.
</nextsent>
<nextsent>as more and more features are added into the model, more data is needed for training.
</nextsent>
<nextsent>however, due to the expensive cost of labeling, we usually cannot get as much labeled word alignment data as we want.
</nextsent>
<nextsent>this may limit the performance of supervised methods (wu et al., 2006).<papid> P06-2117 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1225">
<title id=" W10-2917.xml">improving word alignment by semi supervised ensemble </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as more and more features are added into the model, more data is needed for training.
</prevsent>
<prevsent>however, due to the expensive cost of labeling, we usually cannot get as much labeled word alignment data as we want.
</prevsent>
</prevsection>
<citsent citstr=" P06-2117 ">
this may limit the performance of supervised methods (wu et al., 2006).<papid> P06-2117 </papid></citsent>
<aftsection>
<nextsent>one possible alternative is to use features learnt in some unsupervised manner to help the task.
</nextsent>
<nextsent>for example, moore (2005) <papid> H05-1011 </papid>uses statistics like log-likelihood-ratio and conditionallikelihood-probability to measure word associa tions; liu et al (2005)<papid> P05-1057 </papid>and taskar et al (2005)<papid> H05-1010 </papid>use results from ibm model 3 and model 4, re spectively.</nextsent>
<nextsent>ayan and dorr (2006)<papid> N06-1013 </papid>propose another way of incorporating unlabeled data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1231">
<title id=" W10-2917.xml">improving word alignment by semi supervised ensemble </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one possible alternative is to use features learnt in some unsupervised manner to help the task.
</prevsent>
<prevsent>for example, moore (2005) <papid> H05-1011 </papid>uses statistics like log-likelihood-ratio and conditionallikelihood-probability to measure word associa tions; liu et al (2005)<papid> P05-1057 </papid>and taskar et al (2005)<papid> H05-1010 </papid>use results from ibm model 3 and model 4, re spectively.</prevsent>
</prevsection>
<citsent citstr=" N06-1013 ">
ayan and dorr (2006)<papid> N06-1013 </papid>propose another way of incorporating unlabeled data.</citsent>
<aftsection>
<nextsent>they first train some existing alignment models, e.g. ibm model4 and hidden markov model, using unlabeled data.
</nextsent>
<nextsent>the results of these models are then combined using amaximum entropy classifier, which is trained using labeled data.
</nextsent>
<nextsent>this method is highly efficient in training because it only makes decisions on alignment links from existing models and avoids searching the entire alignment space.
</nextsent>
<nextsent>in this paper, we follow ayan and dorr (2006)<papid> N06-1013 </papid>s idea of combining multiple alignment results.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1239">
<title id=" W10-2917.xml">improving word alignment by semi supervised ensemble </title>
<section> experiments and results.  </section>
<citcontext>
<prevsection>
<prevsent>we use multi-references datasets from nist open mtevaluation as development and test data.
</prevsent>
<prevsent>the english side of the parallel corpus is trained into language model using srilm (stolcke, 2002).
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
moses (koehn et al, 2003) <papid> N03-1017 </papid>is used for decoding.</citsent>
<aftsection>
<nextsent>translation quality is measured by bleu4 score ignoring the case.
</nextsent>
<nextsent>4.2 experiments of sub-models.
</nextsent>
<nextsent>we use the following three sub-models: bidirectional results of giza++ (och and ney, 2003) <papid> J03-1002 </papid>model4, namely model4c2e and model4e2c, and the joint training result ofberkeleyaligner (liang et al, 2006) (<papid> N06-1014 </papid>berke leyal.).</nextsent>
<nextsent>to evaluate aer, all three datasets listed in table 1 are combined and used for the unsupervised training of each sub-model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1241">
<title id=" W10-2917.xml">improving word alignment by semi supervised ensemble </title>
<section> experiments and results.  </section>
<citcontext>
<prevsection>
<prevsent>translation quality is measured by bleu4 score ignoring the case.
</prevsent>
<prevsent>4.2 experiments of sub-models.
</prevsent>
</prevsection>
<citsent citstr=" N06-1014 ">
we use the following three sub-models: bidirectional results of giza++ (och and ney, 2003) <papid> J03-1002 </papid>model4, namely model4c2e and model4e2c, and the joint training result ofberkeleyaligner (liang et al, 2006) (<papid> N06-1014 </papid>berke leyal.).</citsent>
<aftsection>
<nextsent>to evaluate aer, all three datasets listed in table 1 are combined and used for the unsupervised training of each sub-model.
</nextsent>
<nextsent>table 2 presents the alignment quality of those sub-models, as well as supervised ensemble ofthem, as described in section 2.1.
</nextsent>
<nextsent>we use the symmetrized ibm model4 results by the grow-diag final-and heuristic as our baseline (model4gdf).
</nextsent>
<nextsent>scores in table 2 show the great improvement of supervised learning, which reduce the alignment error rate significantly (more than 5% aer points from the best sub-model, i.e. berke leyaligner).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1253">
<title id=" W10-2917.xml">improving word alignment by semi supervised ensemble </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in the area of semi-supervised learning of word alignment, callison-burch et al (2004) compare the results of interpol ating statistical machine 141translation models learnt from labeled and unlabeled data, respectively.
</prevsent>
<prevsent>wu et al (2006) <papid> P06-2117 </papid>proposea modified boosting algorithm, where two different models are also trained using labeled and unlabeled data respectively and interpolated.</prevsent>
</prevsection>
<citsent citstr=" P06-1097 ">
fraser and marcu (2006) <papid> P06-1097 </papid>propose an emd algorithm,where labeled data is used for discriminative re ranking.</citsent>
<aftsection>
<nextsent>it should be pointed out that these pieces of work all use two separate processes for learning with labeled and unlabeled data.
</nextsent>
<nextsent>they either train and interpol ate two separate models or re rank previously learnt models with labeled data only.
</nextsent>
<nextsent>our proposed semi-supervised strategy is able to incorporate both labeled and unlabeled data in the same process, which is in different line of thinking.
</nextsent>
<nextsent>semi-supervised techniques are useful when there is large amount of unlabeled data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1254">
<title id=" W10-3007.xml">resolving speculation maxent cue classification and dependency based scope rules </title>
<section> architecture and set-up.  </section>
<citcontext>
<prevsection>
<prevsent>2 unknown unknown jj degree:attributive 4 nmod 4 adjunct 3 amino amino jj degree:attributive 4 nmod 4 adjunct 4 acid acid nn pers:3|case:nom|num:sg|ntype:common 5 sbj 3 subj 5 may may md mood:ind|subcat:modal|tense:pres|clausetype:decl|passive:- 0 root 0 root 6 be be vb _ 5 vc 7 phi 7 used use vbn subcat:v-subj-obj|vtype:main|passive:+ 6 vc 5 xcomp 8 by by in _ 7 lgs 9 phi 9 these these dt deixis:proximal 10 nmod 10 specdet 10 species specie nns num:pl|pers:3|case:obl|common:count|ntype:common 8 pmod 7 obl-ag 11 . . .
</prevsent>
<prevsent>_ 5 0 punc table 1: enhanced dependency representation of the example sentence the unknown amino acid may be used by these species with geniapos-tags (pos), malt parses (head, deprel) and xle parses (xhead, xdep).lems.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
our pre-processing approach therefore deploys home-grown, cascaded finite-state tokenizer (borrowed and adapted from the open source english resource grammar; flickinger(2000)), which aims to implement the tokenization decisions made in the penn treebank (mar cus et al , 1993) ? <papid> J93-2004 </papid>much like genia, in principle ? but properly treating corner cases like the onesabove.</citsent>
<aftsection>
<nextsent>synchronized via characterization, this tokenization is then enriched with the output of no less than two pos taggers, as detailed in the next section.
</nextsent>
<nextsent>2.2 pos tagging and lemmatization.
</nextsent>
<nextsent>for pos tagging and lemmatization, we combine genia (with its built-in, occasionally deviant to kenizer) and tnt (brants, 2000), <papid> A00-1031 </papid>which operates on pre-tokenized inputs but in its default modelis trained on financial news from the penn tree bank.</nextsent>
<nextsent>our general goal here is to take advantage of the higher pos accuracy provided by genia in the biomedical domain, while using our improved tokenization and producing inputs to the parsing stage (see section 2.3 below) that as much as possible resemble the conventions used in the original training data for the parser ? the penn treebank, once again.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1255">
<title id=" W10-3007.xml">resolving speculation maxent cue classification and dependency based scope rules </title>
<section> architecture and set-up.  </section>
<citcontext>
<prevsection>
<prevsent>synchronized via characterization, this tokenization is then enriched with the output of no less than two pos taggers, as detailed in the next section.
</prevsent>
<prevsent>2.2 pos tagging and lemmatization.
</prevsent>
</prevsection>
<citsent citstr=" A00-1031 ">
for pos tagging and lemmatization, we combine genia (with its built-in, occasionally deviant to kenizer) and tnt (brants, 2000), <papid> A00-1031 </papid>which operates on pre-tokenized inputs but in its default modelis trained on financial news from the penn tree bank.</citsent>
<aftsection>
<nextsent>our general goal here is to take advantage of the higher pos accuracy provided by genia in the biomedical domain, while using our improved tokenization and producing inputs to the parsing stage (see section 2.3 below) that as much as possible resemble the conventions used in the original training data for the parser ? the penn treebank, once again.
</nextsent>
<nextsent>to this effect, for the vast majority of tokens we can align the genia tokenization with our own, and in these cases we typically use genia postags and lemmas (i.e. base forms).
</nextsent>
<nextsent>for better normalization, we down case base forms for all parts of speech except proper nouns.
</nextsent>
<nextsent>however, genia does not make pos distinction between proper and common nouns, as in the penn treebank, and hence we give precedence to tnt outputs for tokens tagged as nominal by both taggers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1256">
<title id=" W10-3007.xml">resolving speculation maxent cue classification and dependency based scope rules </title>
<section> architecture and set-up.  </section>
<citcontext>
<prevsection>
<prevsent>2.3 dependency parsing with lfg features.
</prevsent>
<prevsent>for syntactic parsing we employ data-driven dependency parser which incorporates the predictions from large-scale lfg grammar.
</prevsent>
</prevsection>
<citsent citstr=" P08-1108 ">
a technique of parser stacking is employed, which enables data-driven parser to learn from the output of another parser, in addition to gold standard treebank annotations (nivre and mcdonald,2008).<papid> P08-1108 </papid></citsent>
<aftsection>
<nextsent>this technique has been shown to provide significant improvements inaccuracy for both english and german (vrelid et al , 2009), and similar approach employing an hpsg grammar has been shown to increase domain independence in data-driven dependency parsing (zhang and wang, 2009).<papid> P09-1043 </papid></nextsent>
<nextsent>for our purposes, we decide to use parser which incorporates analyses from two quite different parsing approaches ? data-driven dependency parsing and deep?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1257">
<title id=" W10-3007.xml">resolving speculation maxent cue classification and dependency based scope rules </title>
<section> architecture and set-up.  </section>
<citcontext>
<prevsection>
<prevsent>for syntactic parsing we employ data-driven dependency parser which incorporates the predictions from large-scale lfg grammar.
</prevsent>
<prevsent>a technique of parser stacking is employed, which enables data-driven parser to learn from the output of another parser, in addition to gold standard treebank annotations (nivre and mcdonald,2008).<papid> P08-1108 </papid></prevsent>
</prevsection>
<citsent citstr=" P09-1043 ">
this technique has been shown to provide significant improvements inaccuracy for both english and german (vrelid et al , 2009), and similar approach employing an hpsg grammar has been shown to increase domain independence in data-driven dependency parsing (zhang and wang, 2009).<papid> P09-1043 </papid></citsent>
<aftsection>
<nextsent>for our purposes, we decide to use parser which incorporates analyses from two quite different parsing approaches ? data-driven dependency parsing and deep?
</nextsent>
<nextsent>parsing with handcrafted grammar ? providing us with range of different types of linguistic features which may be used in hedge detection.
</nextsent>
<nextsent>we employ the freely available maltparser(nivre et al , 2006), which is language independent system for data-driven dependencyparsing.2 it is based on deterministic parsing strategy in combination with treebank-inducedclassifiers for predicting parse transitions.
</nextsent>
<nextsent>it supports rich feature representation of the parse history in order to guide parsing and may easily be extended to take into account new features of the 2see http://maltparser.org.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1258">
<title id=" W10-3007.xml">resolving speculation maxent cue classification and dependency based scope rules </title>
<section> architecture and set-up.  </section>
<citcontext>
<prevsection>
<prevsent>parse history.
</prevsent>
<prevsent>parser stacking the procedure to enable thedata-driven parser to learn from the grammar driven parser is quite simple.
</prevsent>
</prevsection>
<citsent citstr=" W02-1503 ">
we parse treebank with the xle platform (crouch et al , 2008) and the english grammar developed within the pargram project (butt et al , 2002).<papid> W02-1503 </papid></citsent>
<aftsection>
<nextsent>we then convert the lfg output to dependency structures, so that we have two parallel versions of the treebank ? one gold standard and one with lfg-annotation.
</nextsent>
<nextsent>we extend the gold standard treebank with additional information from the corresponding lfg analysis and train the data-driven dependency parser on the enhanced dataset.
</nextsent>
<nextsent>see vrelid et al  (2010) for details of the conversion and training of the parser.table 1 shows the enhanced dependency representation of the english sentence the unknown amino acid may be used by these species, taken from the training data.
</nextsent>
<nextsent>for each token, the parsed data contains information on the surface form,lemma, and pos tag, as well as on the head and dependency relation in columns 6 and 7.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1259">
<title id=" W10-3007.xml">resolving speculation maxent cue classification and dependency based scope rules </title>
<section> identifying hedge cues.  </section>
<citcontext>
<prevsection>
<prevsent>is represented as feature vector f(wi, yi) = fi ?  d. each dimension or feature function fij can encode arbitrary properties of the data.
</prevsent>
<prevsent>the particular feature functions we are using for the cue identification are described under section 3.4 below.
</prevsent>
</prevsection>
<citsent citstr=" W02-2018 ">
for model estimation we use the tadm3 software (malouf, 2002).<papid> W02-2018 </papid></citsent>
<aftsection>
<nextsent>for feature extraction and model tuning, we build on the experimentation environment developed by velldal (2008) (in turn extending earlier work by oepen et al 3toolkit for advanced discriminative modeling; available from http://tadm.sourceforge.net/.
</nextsent>
<nextsent>50 (2004)).
</nextsent>
<nextsent>among other things, its highly optimized feature handling ? where the potentially expensive feature extraction step is performed only once and then combined with several levels of featurecaching ? make it computationally feasible to perform large-scale grid searches?
</nextsent>
<nextsent>over different configurations of features and model parameters when using many millions of features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1260">
<title id=" W10-3008.xml">combining manual rules and supervised learning for hedge cue and scope detection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>applying postprocessing rules to convert the.
</prevsent>
<prevsent>token-level annotation into predictions about scope.
</prevsent>
</prevsection>
<citsent citstr=" W09-1304 ">
parts of the system are similar to that of morante and daelemans (2009) ? <papid> W09-1304 </papid>both make use of machine learning to tag tokens as being in cue or scope.</citsent>
<aftsection>
<nextsent>the most important differences are the use of manually defined rules and the inclusion of grammatical relations from parser as critical features.
</nextsent>
<nextsent>a revised version of the bio scope corpus (vincze et al, 2008), containing annotation of cues and scopes, was provided as training data for the conll-2010 shared task (farkas et al, 2010).
</nextsent>
<nextsent>this includes 9 full papers and 1273 abstracts from biomedical research fields.
</nextsent>
<nextsent>a separate new set of full papers was released for evaluation as part of the task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1261">
<title id=" W10-3008.xml">combining manual rules and supervised learning for hedge cue and scope detection </title>
<section> data.  </section>
<citcontext>
<prevsection>
<prevsent>cues and scopes have to be continuous.for development of the system, before the evaluation data were released, we used 60% of the available corpus for training and 40% for testing.the results we give below measure the system performance on the evaluation data while using allof the training data to build the supervised classifiers.
</prevsent>
<prevsent>the manually-developed rules are based on the 60% of the development data we originally reserved for training.
</prevsent>
</prevsection>
<citsent citstr=" P06-4020 ">
all of the training and test data sentences were token ised and parsed using the rasp system (briscoe et al, 2006).<papid> P06-4020 </papid></citsent>
<aftsection>
<nextsent>multiple part-of speech (pos) tag outputs were passed to the parser (to compensate for the high number of unseen words in biomedical text), retaining just the highest ranked directed graph of grammatical relations (grs).
</nextsent>
<nextsent>each node in the graph represents word token annotated with pos, lemma, and positional order information.
</nextsent>
<nextsent>in the case of parse failure theset of unconnected graphs returned by the highest ranked spanning sub analyses for each sentence were retained.
</nextsent>
<nextsent>the hedge cues are found using conditional random field (crf) (lafferty et al, 2001) classifier, implemented using crf++ 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1263">
<title id=" W10-3008.xml">combining manual rules and supervised learning for hedge cue and scope detection </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>most of the previous work has been done on classifying sentences as hedged or not, rather than finding the scope of the hedge.the first linguistically and computationally motivated study of hedging in biomedical texts is light et al (2004).
</prevsent>
<prevsent>they present an analysis of the problem based on medline abstracts and construct an initial experiment for automated classification.
</prevsent>
</prevsection>
<citsent citstr=" P07-1125 ">
medlock and briscoe (2007) <papid> P07-1125 </papid>propose weakly supervised machine learning approach to the hedge classification problem.</citsent>
<aftsection>
<nextsent>they construct classifier with single words as features and use small amount of seed data to bootstrap the system, achieving the precision/recall break-even point (bep) of 0.76.
</nextsent>
<nextsent>szarvas (2008) extends this work by introducing bigrams and trigrams as feature types, improving feature selection and using external data sources to construct lists of cue words, achieving bep of 0.85.kilicoglu and bergler (2008) <papid> W08-0607 </papid>apply combination of lexical and syntactic methods, improving on previous results and showing that quantifying the strength of hedge can be beneficial for classification of speculative sentences.</nextsent>
<nextsent>vincze et al (2008) created publicly available annotated corpus of biomedical papers, abstracts and clinical data called bio scope, parts of which were also used as training data for the conll10shared task, building on the dataset and annotation scheme used for evaluation by medlock and briscoe (2007).<papid> P07-1125 </papid>morante and daelemans (2009) <papid> W09-1304 </papid>use the bio scope corpus to approach the problem of identifying cues and scopes via supervised machine learn ing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1264">
<title id=" W10-3008.xml">combining manual rules and supervised learning for hedge cue and scope detection </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>medlock and briscoe (2007) <papid> P07-1125 </papid>propose weakly supervised machine learning approach to the hedge classification problem.</prevsent>
<prevsent>they construct classifier with single words as features and use small amount of seed data to bootstrap the system, achieving the precision/recall break-even point (bep) of 0.76.</prevsent>
</prevsection>
<citsent citstr=" W08-0607 ">
szarvas (2008) extends this work by introducing bigrams and trigrams as feature types, improving feature selection and using external data sources to construct lists of cue words, achieving bep of 0.85.kilicoglu and bergler (2008) <papid> W08-0607 </papid>apply combination of lexical and syntactic methods, improving on previous results and showing that quantifying the strength of hedge can be beneficial for classification of speculative sentences.</citsent>
<aftsection>
<nextsent>vincze et al (2008) created publicly available annotated corpus of biomedical papers, abstracts and clinical data called bio scope, parts of which were also used as training data for the conll10shared task, building on the dataset and annotation scheme used for evaluation by medlock and briscoe (2007).<papid> P07-1125 </papid>morante and daelemans (2009) <papid> W09-1304 </papid>use the bio scope corpus to approach the problem of identifying cues and scopes via supervised machine learn ing.</nextsent>
<nextsent>they train selection of classifiers to tag each word and combine the results with final classifier, finding 65.6% of the scopes in abstracts and 35.9% of the scopes in papers.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1267">
<title id=" W10-3407.xml">an optimal and portable parsing method for romanian french and german large dictionaries </title>
<section> dictionary entry parsing.  </section>
<citcontext>
<prevsection>
<prevsent>natural language text parsing is complex process whose prerequisite essential stage is thorough modeling of the linguistic process to be developed, i.e. the structures and relations aimed to constitute the final result of the analysis.
</prevsent>
<prevsent>similarly, for dep, the semantics of the lexical structures, the sense markers, and the hierarchies (de pendencies) between sense structures must be specified.
</prevsent>
</prevsection>
<citsent citstr=" P89-1012 ">
standard approaches to dictionary entry parsing (referred to from now on as standard dep), such as the one used by (neff and boguraev, 1989), <papid> P89-1012 </papid>the lex parse system presented in (hauser and storrer, 1993; kammerer, 2000; lemnitzer and kunze, 2005), or lexicographic grammars, as those presented in (curteanu &amp; amihaesei, 2004; tufis et al, 1999), recognize the sense / sub sense definitions in strictly sequential manner, along with the incremental building of the entry sense tree.</citsent>
<aftsection>
<nextsent>the inter leaving of the two running processes is the main source of errors and inefficiency for the whole dep process.
</nextsent>
<nextsent>both the standard dep (figure 1) and our proposed method based on scd-configurations (figure 2) involve the following three running cycles and four essential phases for extracting the sense-tree structure from dictionary: [a1], [b1] ? parsing the lexicographic segments of an entry; [a2], [b2] ? parsing the sense-description segment of the dictionary entry, at the level of explicitly defined senses, until and not including the contents of the atomic definitions / senses; at this stage, the sense-tree of the sense-description segment is built having (sets of) atomic senses / definitions in their leaf-nodes.
</nextsent>
<nextsent>[a3], [b3] ? parsing the atomic definitions / senses.
</nextsent>
<nextsent>phase_1 := sense-i marker recognition; phase_2 := sense-i definition parsing; phase_3 := attach parsed sense-i definition to node-i; phase_4 := add node-i to entrysense-tree.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1268">
<title id=" W10-3407.xml">an optimal and portable parsing method for romanian french and german large dictionaries </title>
<section> parsing with scd configurations.  </section>
<citcontext>
<prevsection>
<prevsent>after presenting the scd-based dictionary parsing method, section 3.2.
</prevsent>
<prevsent>compares the parsing cycles and phases of standard dep to the ones of scd-based dep.
</prevsent>
</prevsection>
<citsent citstr=" W08-1908 ">
the scd configuration(s) method is procedural, recognition-generation computational device, that is distinct from the traditional and cumbersome formal grammars, being able to successfully replace them for several tasks of natural language parsing, including text free parsing (curteanu, 2006) and thesauri parsing (curteanu et al, 2008).<papid> W08-1908 </papid></citsent>
<aftsection>
<nextsent>for scd-based parsing, the semantics and the linguistic modeling of the text to be analyzed should be clearly specified at each parsing level, and implemented within the following components of each scd configuration (hereafter, scd-config): ? set of marker classes: marker is boundary for specific linguistic category (e.g. a., i., 1., a)., etc.).
</nextsent>
<nextsent>markers are joined into marker classes, with respect to 39 their functional similarity (e.g. {a., b., c., ?}, {1., 2., 3., ?}, {a)., b)., ?}); ? hypergraph-like hierarchy that establishes the dependencies among the marker classes; ? searching (parsing) algorithm.
</nextsent>
<nextsent>once an scd configuration is defined, parsing with the scd configuration implies identifying the markers in the text to be parsed, constructing the sequences of markers and categories, recognizing the marked text structures (spans within the bounding markers) corresponding to the scd configuration semantics, and classifying them according to the marker sequences within the pre-established hierarchy assigned to that scd configuration.
</nextsent>
<nextsent>the last step settles the dependencies and correlations among the parsed textual structures.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1279">
<title id=" W10-2417.xml">simplified feature set for arabic named entity recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the proposed features help overcome some of the morphological and orthographic complexities of arabic.
</prevsent>
<prevsent>in comparing to results in the literature using arabic specific features such pos tags on the same dataset and same crf implementation, the results in this paper are lower by 2 f-measure points for locations, but are better by 8 points for organizations and 9 points for persons.
</prevsent>
</prevsection>
<citsent citstr=" D08-1030 ">
named entity recognition (ner) continues to be an important part of many nlp applications such as information extraction, machine translation, and question answering (benajiba et al, 2008).<papid> D08-1030 </papid></citsent>
<aftsection>
<nextsent>ner is concerned with identifying sequences of words referring to named entities (nes) such as persons, locations, and organizations.
</nextsent>
<nextsent>for example, in the word sequence alan mulally, ceo of detroit based ford motor company,?
</nextsent>
<nextsent>alan mu lally, detroit, and ford motor company would be identified as person, location, and an organization respectively.
</nextsent>
<nextsent>arabic is semitic language that present interesting morphological and orthographic challenges that may complicate ner.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1283">
<title id=" W10-2417.xml">simplified feature set for arabic named entity recognition </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>they did not report per category f-measure, but they reported overall 81%, 75%, and 78% macro-average f-measure for broadcast news and newswire on the ace 2003, 2004, and 2005 datasets respectively.
</prevsent>
<prevsent>huang (2005) used an hmm based ne recognizer for arabic and reported 77% f-measure on the ace 2003 dataset.
</prevsent>
</prevsection>
<citsent citstr=" L08-1054 ">
farber et al (2008) <papid> L08-1054 </papid>used pos tags obtained from an arabic morphological analyzer to enhance ner.</citsent>
<aftsection>
<nextsent>they reported 70% measure on the ace 2005 dataset.
</nextsent>
<nextsent>shaalan and raza (2007) <papid> W07-0803 </papid>reported on rule-based system that uses handcrafted grammars and regular expressions in conjunction with gazetteers.</nextsent>
<nextsent>they reported upwards of 93% f-measure, but they conducted their experiments on non-standard datasets, making comparison difficult.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1284">
<title id=" W10-2417.xml">simplified feature set for arabic named entity recognition </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>farber et al (2008) <papid> L08-1054 </papid>used pos tags obtained from an arabic morphological analyzer to enhance ner.</prevsent>
<prevsent>they reported 70% measure on the ace 2005 dataset.</prevsent>
</prevsection>
<citsent citstr=" W07-0803 ">
shaalan and raza (2007) <papid> W07-0803 </papid>reported on rule-based system that uses handcrafted grammars and regular expressions in conjunction with gazetteers.</citsent>
<aftsection>
<nextsent>they reported upwards of 93% f-measure, but they conducted their experiments on non-standard datasets, making comparison difficult.
</nextsent>
<nextsent>mcnamee and mayfield (2002) <papid> W02-2020 </papid>explored the training of an svm classifier using many language independent binary features such as leading and trailing letters in word, word length, presence of digits in word, and capitalization.</nextsent>
<nextsent>they reported promising results for spanish and dutch.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1285">
<title id=" W10-2417.xml">simplified feature set for arabic named entity recognition </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>shaalan and raza (2007) <papid> W07-0803 </papid>reported on rule-based system that uses handcrafted grammars and regular expressions in conjunction with gazetteers.</prevsent>
<prevsent>they reported upwards of 93% f-measure, but they conducted their experiments on non-standard datasets, making comparison difficult.</prevsent>
</prevsection>
<citsent citstr=" W02-2020 ">
mcnamee and mayfield (2002) <papid> W02-2020 </papid>explored the training of an svm classifier using many language independent binary features such as leading and trailing letters in word, word length, presence of digits in word, and capitalization.</citsent>
<aftsection>
<nextsent>they reported promising results for spanish and dutch.
</nextsent>
<nextsent>in follow on work, mayfield et al (2003) <papid> W03-0429 </papid>used thousands of language independent features such character n-grams, capitalization, word length, and position in sentence, along with language dependent features such as pos tags and bp chunking.</nextsent>
<nextsent>for english, they reported 89%, 79%, and 91% f-measure for location, organization, and persons respectively.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1286">
<title id=" W10-2417.xml">simplified feature set for arabic named entity recognition </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>mcnamee and mayfield (2002) <papid> W02-2020 </papid>explored the training of an svm classifier using many language independent binary features such as leading and trailing letters in word, word length, presence of digits in word, and capitalization.</prevsent>
<prevsent>they reported promising results for spanish and dutch.</prevsent>
</prevsection>
<citsent citstr=" W03-0429 ">
in follow on work, mayfield et al (2003) <papid> W03-0429 </papid>used thousands of language independent features such character n-grams, capitalization, word length, and position in sentence, along with language dependent features such as pos tags and bp chunking.</citsent>
<aftsection>
<nextsent>for english, they reported 89%, 79%, and 91% f-measure for location, organization, and persons respectively.
</nextsent>
<nextsent>the use of crf sequence labeling has been increasing over the past few years (mccallum and li, 2003; <papid> W03-0430 </papid>nadeau and sekine, 2009) with good success (benajiba and rosso, 2008).</nextsent>
<nextsent>though, crfs are not guaranteed to be better than svms (benajiba et al, 2008).<papid> D08-1030 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1287">
<title id=" W10-2417.xml">simplified feature set for arabic named entity recognition </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>in follow on work, mayfield et al (2003) <papid> W03-0429 </papid>used thousands of language independent features such character n-grams, capitalization, word length, and position in sentence, along with language dependent features such as pos tags and bp chunking.</prevsent>
<prevsent>for english, they reported 89%, 79%, and 91% f-measure for location, organization, and persons respectively.</prevsent>
</prevsection>
<citsent citstr=" W03-0430 ">
the use of crf sequence labeling has been increasing over the past few years (mccallum and li, 2003; <papid> W03-0430 </papid>nadeau and sekine, 2009) with good success (benajiba and rosso, 2008).</citsent>
<aftsection>
<nextsent>though, crfs are not guaranteed to be better than svms (benajiba et al, 2008).<papid> D08-1030 </papid></nextsent>
<nextsent>for this work, crf sequence labeling was used.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1290">
<title id=" W10-2417.xml">simplified feature set for arabic named entity recognition </title>
<section> ner features.  </section>
<citcontext>
<prevsection>
<prevsent>though, crfs are not guaranteed to be better than svms (benajiba et al, 2008).<papid> D08-1030 </papid></prevsent>
<prevsent>for this work, crf sequence labeling was used.</prevsent>
</prevsection>
<citsent citstr=" N03-1028 ">
the advantage of using crf is that they combine hmm-like generative power with clas sifier-like discrimination (lafferty et al, 2001; sha and pereira, 2003).<papid> N03-1028 </papid></citsent>
<aftsection>
<nextsent>when crf makes decision on the label to assign to word, it also accounts for the previous and succeeding words.
</nextsent>
<nextsent>the crf was trained on large set of surface features to minimize the use of arabic morphological and syntactic features.
</nextsent>
<nextsent>apart from stemming two coordinating conjunctions, no other arabic specific features were used.
</nextsent>
<nextsent>the features used were as follows: ? leading and trailing character bigrams (6bi).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1291">
<title id=" W10-2417.xml">simplified feature set for arabic named entity recognition </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>the following processing steps of arabic were per formed: ? the coordinating conjunctions (?)
</prevsent>
<prevsent>and (?), which always appear as the first prefixes in word, were optionally stemmed.
</prevsent>
</prevsection>
<citsent citstr=" P03-1051 ">
w and were stemmed using an in-house arabic stemmer that is re implementation of the stemmer proposed by lee et al (2003).<papid> P03-1051 </papid></citsent>
<aftsection>
<nextsent>however, stemming or could have been done by stemming the or and searching for the stemmed word in large arabic corpus.
</nextsent>
<nextsent>if the stemmed word appears more than certain count, then stemming was appropriate.
</nextsent>
<nextsent>the different forms of alef (a (?), | (?),   (?), and   (?)) were normalized to (?), (?)
</nextsent>
<nextsent>and (?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1292">
<title id=" W10-2210.xml">semi supervised learning of concatenative morphology </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in many cases, the problems of availability also apply to morphologically annotated corpora, making supervised learning in feasible.in consequence, there has been need for approaches for morphological processing that would require little language-dependent resources.
</prevsent>
<prevsent>due to this need, as well as the general interest in language acquisition and unsupervised language learning, the research on unsupervised learning of morphology has been active during the pastten years.
</prevsent>
</prevsection>
<citsent citstr=" J01-2001 ">
especially, methods that perform morphological segmentation have been studied extensively (goldsmith, 2001; <papid> J01-2001 </papid>creutz and lagus, 2002; <papid> W02-0603 </papid>monson et al, 2004; <papid> W04-0107 </papid>bernhard, 2006; dasgupta and ng, 2007; snyder and barzilay, 2008<papid> P08-1084 </papid>b; poonet al, 2009).<papid> N09-1024 </papid></citsent>
<aftsection>
<nextsent>these methods have shown to produce results that improve performance in several applications, such as speech recognition and information retrieval (creutz et al, 2007; <papid> N07-1048 </papid>kurimo et al., 2008).</nextsent>
<nextsent>while unsupervised methods often work quite well across different languages, it is difficult to avoid biases toward certain kinds of languages and analyses.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1293">
<title id=" W10-2210.xml">semi supervised learning of concatenative morphology </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in many cases, the problems of availability also apply to morphologically annotated corpora, making supervised learning in feasible.in consequence, there has been need for approaches for morphological processing that would require little language-dependent resources.
</prevsent>
<prevsent>due to this need, as well as the general interest in language acquisition and unsupervised language learning, the research on unsupervised learning of morphology has been active during the pastten years.
</prevsent>
</prevsection>
<citsent citstr=" W02-0603 ">
especially, methods that perform morphological segmentation have been studied extensively (goldsmith, 2001; <papid> J01-2001 </papid>creutz and lagus, 2002; <papid> W02-0603 </papid>monson et al, 2004; <papid> W04-0107 </papid>bernhard, 2006; dasgupta and ng, 2007; snyder and barzilay, 2008<papid> P08-1084 </papid>b; poonet al, 2009).<papid> N09-1024 </papid></citsent>
<aftsection>
<nextsent>these methods have shown to produce results that improve performance in several applications, such as speech recognition and information retrieval (creutz et al, 2007; <papid> N07-1048 </papid>kurimo et al., 2008).</nextsent>
<nextsent>while unsupervised methods often work quite well across different languages, it is difficult to avoid biases toward certain kinds of languages and analyses.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1295">
<title id=" W10-2210.xml">semi supervised learning of concatenative morphology </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in many cases, the problems of availability also apply to morphologically annotated corpora, making supervised learning in feasible.in consequence, there has been need for approaches for morphological processing that would require little language-dependent resources.
</prevsent>
<prevsent>due to this need, as well as the general interest in language acquisition and unsupervised language learning, the research on unsupervised learning of morphology has been active during the pastten years.
</prevsent>
</prevsection>
<citsent citstr=" W04-0107 ">
especially, methods that perform morphological segmentation have been studied extensively (goldsmith, 2001; <papid> J01-2001 </papid>creutz and lagus, 2002; <papid> W02-0603 </papid>monson et al, 2004; <papid> W04-0107 </papid>bernhard, 2006; dasgupta and ng, 2007; snyder and barzilay, 2008<papid> P08-1084 </papid>b; poonet al, 2009).<papid> N09-1024 </papid></citsent>
<aftsection>
<nextsent>these methods have shown to produce results that improve performance in several applications, such as speech recognition and information retrieval (creutz et al, 2007; <papid> N07-1048 </papid>kurimo et al., 2008).</nextsent>
<nextsent>while unsupervised methods often work quite well across different languages, it is difficult to avoid biases toward certain kinds of languages and analyses.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1296">
<title id=" W10-2210.xml">semi supervised learning of concatenative morphology </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in many cases, the problems of availability also apply to morphologically annotated corpora, making supervised learning in feasible.in consequence, there has been need for approaches for morphological processing that would require little language-dependent resources.
</prevsent>
<prevsent>due to this need, as well as the general interest in language acquisition and unsupervised language learning, the research on unsupervised learning of morphology has been active during the pastten years.
</prevsent>
</prevsection>
<citsent citstr=" P08-1084 ">
especially, methods that perform morphological segmentation have been studied extensively (goldsmith, 2001; <papid> J01-2001 </papid>creutz and lagus, 2002; <papid> W02-0603 </papid>monson et al, 2004; <papid> W04-0107 </papid>bernhard, 2006; dasgupta and ng, 2007; snyder and barzilay, 2008<papid> P08-1084 </papid>b; poonet al, 2009).<papid> N09-1024 </papid></citsent>
<aftsection>
<nextsent>these methods have shown to produce results that improve performance in several applications, such as speech recognition and information retrieval (creutz et al, 2007; <papid> N07-1048 </papid>kurimo et al., 2008).</nextsent>
<nextsent>while unsupervised methods often work quite well across different languages, it is difficult to avoid biases toward certain kinds of languages and analyses.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1297">
<title id=" W10-2210.xml">semi supervised learning of concatenative morphology </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in many cases, the problems of availability also apply to morphologically annotated corpora, making supervised learning in feasible.in consequence, there has been need for approaches for morphological processing that would require little language-dependent resources.
</prevsent>
<prevsent>due to this need, as well as the general interest in language acquisition and unsupervised language learning, the research on unsupervised learning of morphology has been active during the pastten years.
</prevsent>
</prevsection>
<citsent citstr=" N09-1024 ">
especially, methods that perform morphological segmentation have been studied extensively (goldsmith, 2001; <papid> J01-2001 </papid>creutz and lagus, 2002; <papid> W02-0603 </papid>monson et al, 2004; <papid> W04-0107 </papid>bernhard, 2006; dasgupta and ng, 2007; snyder and barzilay, 2008<papid> P08-1084 </papid>b; poonet al, 2009).<papid> N09-1024 </papid></citsent>
<aftsection>
<nextsent>these methods have shown to produce results that improve performance in several applications, such as speech recognition and information retrieval (creutz et al, 2007; <papid> N07-1048 </papid>kurimo et al., 2008).</nextsent>
<nextsent>while unsupervised methods often work quite well across different languages, it is difficult to avoid biases toward certain kinds of languages and analyses.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1298">
<title id=" W10-2210.xml">semi supervised learning of concatenative morphology </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>due to this need, as well as the general interest in language acquisition and unsupervised language learning, the research on unsupervised learning of morphology has been active during the pastten years.
</prevsent>
<prevsent>especially, methods that perform morphological segmentation have been studied extensively (goldsmith, 2001; <papid> J01-2001 </papid>creutz and lagus, 2002; <papid> W02-0603 </papid>monson et al, 2004; <papid> W04-0107 </papid>bernhard, 2006; dasgupta and ng, 2007; snyder and barzilay, 2008<papid> P08-1084 </papid>b; poonet al, 2009).<papid> N09-1024 </papid></prevsent>
</prevsection>
<citsent citstr=" N07-1048 ">
these methods have shown to produce results that improve performance in several applications, such as speech recognition and information retrieval (creutz et al, 2007; <papid> N07-1048 </papid>kurimo et al., 2008).</citsent>
<aftsection>
<nextsent>while unsupervised methods often work quite well across different languages, it is difficult to avoid biases toward certain kinds of languages and analyses.
</nextsent>
<nextsent>for example, in isolating languages, the average amount of morphemes per word is low, whereas in synthetic languages the amount may be very high.
</nextsent>
<nextsent>also, different applications may needa particular bias, for example, not analyzing frequent compound words as consisting of smaller parts could be beneficial in information retrieval.
</nextsent>
<nextsent>in many cases, even small amount of labeled datacan be used to adapt method to particular language and task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1311">
<title id=" W10-2210.xml">semi supervised learning of concatenative morphology </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, the amount of labeled data is usually large, and unlabeled data is just an additional source of information.
</prevsent>
<prevsent>li and mccallum(2005) apply semi-supervised approach to chinese word segmentation where unlabeled data is utilized for forming word clusters, which are then used as features for supervised classifier.
</prevsent>
</prevsection>
<citsent citstr=" C08-1128 ">
xu et al (2008) <papid> C08-1128 </papid>adapt chinese word segmentation specifically to machine translation task, by using the indirect supervision from parallel corpus.</citsent>
<aftsection>
<nextsent>we present an extension of the morfessor baseline method to the semi-supervised setting.
</nextsent>
<nextsent>morfessor baseline is based on generative probabilistic model.
</nextsent>
<nextsent>it is method for modeling concatenative morphology, where the morphsi.e., the sur 79face forms of morphemes of word are its nonoverlapping segments.
</nextsent>
<nextsent>the model parameters encode morph lexicon, which includes the properties of the morphs, such as their string representations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1312">
<title id=" W10-2209.xml">comparing canonicalizations of historical german text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we present three methods for associating unknown historical word forms with syn chronically active canonical cognates and evaluate their performance on an information retrieval tas kover manually annotated corpus of historical german verse.
</prevsent>
<prevsent>historical text presents numerous challenges for contemporary natural language processing techniques.
</prevsent>
</prevsection>
<citsent citstr=" J88-1003 ">
in particular, the absence of consistent orthographic conventions in historical text presents difficulties for any system requiring reference to fixed lexicon accessed by orthographic form, such as document indexing systems (sokirko, 2003;cafarella and cutting, 2004), part-of-speech taggers (derose, 1988; <papid> J88-1003 </papid>brill, 1992; <papid> A92-1021 </papid>schmid, 1994), simple word stem mers (lovins, 1968; porter,1980), or more sophisticated morphological analyzers (geyken and hanneforth, 2006; clematide, 2008).when adopting historical text into such system, one of the most crucial tasks is the association of one or more extant equivalents with each word of the input text: syn chronically active types which best represent the relevant features of the input word.</citsent>
<aftsection>
<nextsent>which features are considered relevant?
</nextsent>
<nextsent>here depends on the application in question: for lemmatization task only the root lex eme is relevant, whereas syntactic parsing may require additional morphosyntactic features.
</nextsent>
<nextsent>for current purposes, extant equivalents are to be understood as canonical cognates, preserving boththe root(s) and morphosyntactic features of the associated historical form(s), which should suffice(modulo major grammatical and/or lexical semantic shifts) for most natural language processing tasks.in this paper, we present three methods for automatic discovery of extant canonical cognatesfor historical german text, and evaluate their performance on an information retrieval task over small gold-standard corpus.
</nextsent>
<nextsent>in this section, we present three methods for automatic discovery of extant canonical cognates for historical german input: phonetic conflation (pho), levenshtein edit distance (lev), and heuristic rewrite transducer (rw).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1313">
<title id=" W10-2209.xml">comparing canonicalizations of historical german text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we present three methods for associating unknown historical word forms with syn chronically active canonical cognates and evaluate their performance on an information retrieval tas kover manually annotated corpus of historical german verse.
</prevsent>
<prevsent>historical text presents numerous challenges for contemporary natural language processing techniques.
</prevsent>
</prevsection>
<citsent citstr=" A92-1021 ">
in particular, the absence of consistent orthographic conventions in historical text presents difficulties for any system requiring reference to fixed lexicon accessed by orthographic form, such as document indexing systems (sokirko, 2003;cafarella and cutting, 2004), part-of-speech taggers (derose, 1988; <papid> J88-1003 </papid>brill, 1992; <papid> A92-1021 </papid>schmid, 1994), simple word stem mers (lovins, 1968; porter,1980), or more sophisticated morphological analyzers (geyken and hanneforth, 2006; clematide, 2008).when adopting historical text into such system, one of the most crucial tasks is the association of one or more extant equivalents with each word of the input text: syn chronically active types which best represent the relevant features of the input word.</citsent>
<aftsection>
<nextsent>which features are considered relevant?
</nextsent>
<nextsent>here depends on the application in question: for lemmatization task only the root lex eme is relevant, whereas syntactic parsing may require additional morphosyntactic features.
</nextsent>
<nextsent>for current purposes, extant equivalents are to be understood as canonical cognates, preserving boththe root(s) and morphosyntactic features of the associated historical form(s), which should suffice(modulo major grammatical and/or lexical semantic shifts) for most natural language processing tasks.in this paper, we present three methods for automatic discovery of extant canonical cognatesfor historical german text, and evaluate their performance on an information retrieval task over small gold-standard corpus.
</nextsent>
<nextsent>in this section, we present three methods for automatic discovery of extant canonical cognates for historical german input: phonetic conflation (pho), levenshtein edit distance (lev), and heuristic rewrite transducer (rw).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1314">
<title id=" W10-2209.xml">comparing canonicalizations of historical german text </title>
<section> canonical ization methods.  </section>
<citcontext>
<prevsection>
<prevsent>vol volk people?
</prevsent>
<prevsent>voll full?
</prevsent>
</prevsection>
<citsent citstr=" J94-3001 ">
table 1: example spurious levenshtein distance conflations heuristic two-level rule-set (karttunen et al, 1987; kaplan and kay, 1994; <papid> J94-3001 </papid>laporte, 1997) whose 306rules were manually constructed to reflect linguistically plausible patterns of dia chronic variation as observed in the lemma-instance pairs automatically extracted from the full 5.5 million worddwb verse corpus (jurish, 2008).</citsent>
<aftsection>
<nextsent>in particular, phonetic phenomena such as schwa deletion, vowel shift, voicing alternation, and articulatory location shift are easily captured by such rules.of the 306 heuristic rewrite rules, 131 manipulate consonant-like strings, 115 deal with vowel like strings, and 14 operate directly on syllable like units.
</nextsent>
<nextsent>the remaining 46 rules define expansions for explicitly marked eli sions and unrecognized input.
</nextsent>
<nextsent>some examples of rules used by the rewrite transducer are given in table 2.
</nextsent>
<nextsent>formally, the rewrite transducer ? rw defines pseudo-metric j?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1315">
<title id=" W10-2209.xml">comparing canonicalizations of historical german text </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>the levenshtein edit-distance technique is at clear disadvantage here, roughly 150 times slower than the phonetic technique and 40 times slower than the specialized heuristic rewrite transducer.
</prevsent>
<prevsent>this effect is assumedly due to the density of the search space (which is maximal for an unrestricted levenshtein editor), since the gfsmxl greedy k-best search of levenshtein transducer cascade generates atleast |a| configurations per character, and single backtracking step requires an additional 3|a| heap extractions (jurish, 2010).
</prevsent>
</prevsection>
<citsent citstr=" J96-1003 ">
use of specializedlookup algorithms (oflazer, 1996) <papid> J96-1003 </papid>might ameliorate such problems.qualitative results for several conflation techniques with respect to the dwb verse test corpus are given in table 4.</citsent>
<aftsection>
<nextsent>an additional conflation relation id? using strict identity of grapheme strings 4 pho, best lev and best rw for the phonetic, levenshtein, and heuristic rewrite transducer methods respectively method time throughput pho 1.82 sec 7322 tok/sec lev 278.03 sec 48 tok/sec rw 7.02 sec 1898 tok/sectable 3: processing time for elementary canoni cal ization functions (w ? id :?
</nextsent>
<nextsent>w = v) was tested to provide baseline for the methods described in section 2.
</nextsent>
<nextsent>as expected, the strict identity baseline relation was the most precise of all methods tested, achieving 99.9% type-wise and 99.1% token-wise precision.
</nextsent>
<nextsent>this is unsurprising, since the id method yields false positives only when historical form is indistinguishable from non-equivalent extant form, as in the case of the mapping wider ; wieder (again?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1316">
<title id=" W10-2209.xml">comparing canonicalizations of historical german text </title>
<section> conclusion &amp; outlook.  </section>
<citcontext>
<prevsection>
<prevsent>the heuristic mapping of unknown forms to extant equivalents by means of linguistically motivatedcontext-sensitive rewrite rules yielded the best results in an information retrieval task on corpus of historical german verse, reducing type-wise recall errors by over 60% compared to navetext-matching strategy.
</prevsent>
<prevsent>depending on the availability of linguistic resources (e.g. phonetization rule-sets, lexica), use of phonetic canonical ization and/or levenshtein edit distance may provide amore immediately accessible route to improved recall for other languages or applications, at the expense of some additional loss of precision.we are interested in verifying our results using larger corpora than the small test corpus used here, as well as extending the techniques described here to other languages and domains.
</prevsent>
</prevsection>
<citsent citstr=" J96-4002 ">
in particular, we are interested in comparing the performance of the domain-specific rewrite transducer used here to other linguistically motivated language-independent metrics such as (covington, 1996; <papid> J96-4002 </papid>kondrak, 2000).<papid> A00-2038 </papid></citsent>
<aftsection>
<nextsent>acknowledgements the work described above was funded by deutsche forschungsgemeinschaft (dfg) grant to the project deutsches textarchiv.
</nextsent>
<nextsent>additionally, the author would like to thank jorg didakowski,oliver duntze, alexander geyken, thomas hanneforth, henriette scharnhorst, wolfgang seeker,kay-michael wurzner, and this papers anonymous reviewers for their helpful feedback and comments.
</nextsent>


</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1317">
<title id=" W10-2209.xml">comparing canonicalizations of historical german text </title>
<section> conclusion &amp; outlook.  </section>
<citcontext>
<prevsection>
<prevsent>the heuristic mapping of unknown forms to extant equivalents by means of linguistically motivatedcontext-sensitive rewrite rules yielded the best results in an information retrieval task on corpus of historical german verse, reducing type-wise recall errors by over 60% compared to navetext-matching strategy.
</prevsent>
<prevsent>depending on the availability of linguistic resources (e.g. phonetization rule-sets, lexica), use of phonetic canonical ization and/or levenshtein edit distance may provide amore immediately accessible route to improved recall for other languages or applications, at the expense of some additional loss of precision.we are interested in verifying our results using larger corpora than the small test corpus used here, as well as extending the techniques described here to other languages and domains.
</prevsent>
</prevsection>
<citsent citstr=" A00-2038 ">
in particular, we are interested in comparing the performance of the domain-specific rewrite transducer used here to other linguistically motivated language-independent metrics such as (covington, 1996; <papid> J96-4002 </papid>kondrak, 2000).<papid> A00-2038 </papid></citsent>
<aftsection>
<nextsent>acknowledgements the work described above was funded by deutsche forschungsgemeinschaft (dfg) grant to the project deutsches textarchiv.
</nextsent>
<nextsent>additionally, the author would like to thank jorg didakowski,oliver duntze, alexander geyken, thomas hanneforth, henriette scharnhorst, wolfgang seeker,kay-michael wurzner, and this papers anonymous reviewers for their helpful feedback and comments.
</nextsent>


</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1318">
<title id=" W10-1747.xml">the rwth system combination system for wmt 2010 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>novel techniques compared with rwths submission to wmt 2009 include the utilization of n-best reranking techniques, consensus true casing approach, different tuning algorithm, and the separate selection of input systems for cn construction, primary/skeleton hypotheses, hyplm, and true casing.
</prevsent>
<prevsent>the rwth approach to mt system combination is refined version of the rover approach in asr (fiscus, 1997), with additional steps to cope with reordering between different hypotheses, andto use true casing information from the input hypotheses.
</prevsent>
</prevsection>
<citsent citstr=" E06-1005 ">
the basic concept of the approach has been described by matusov et al (2006).<papid> E06-1005 </papid></citsent>
<aftsection>
<nextsent>several improvements have been added later (matusov et al., 2008).
</nextsent>
<nextsent>this approach includes an enhanced alignment and reordering framework.
</nextsent>
<nextsent>in contrast to existing approaches (jayaraman and lavie, 2005; <papid> P05-3026 </papid>rosti et al, 2007), <papid> P07-1040 </papid>the context of the whole corpus rather than single sentence is considered in this iterative, unsupervised procedure, yielding more reliable alignment.</nextsent>
<nextsent>majority voting on the generated lattice is performed using prior weights for each system as well as other statistical models such as special n-gram language model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1319">
<title id=" W10-1747.xml">the rwth system combination system for wmt 2010 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>several improvements have been added later (matusov et al., 2008).
</prevsent>
<prevsent>this approach includes an enhanced alignment and reordering framework.
</prevsent>
</prevsection>
<citsent citstr=" P05-3026 ">
in contrast to existing approaches (jayaraman and lavie, 2005; <papid> P05-3026 </papid>rosti et al, 2007), <papid> P07-1040 </papid>the context of the whole corpus rather than single sentence is considered in this iterative, unsupervised procedure, yielding more reliable alignment.</citsent>
<aftsection>
<nextsent>majority voting on the generated lattice is performed using prior weights for each system as well as other statistical models such as special n-gram language model.
</nextsent>
<nextsent>in addition to lattice rescoring, n-best list reranking techniques can be applied to best paths of this lattice.
</nextsent>
<nextsent>true casing is considered separate step in rwths approach, which also takes the input hypotheses into account.
</nextsent>
<nextsent>the pipeline, and consequently the description of the pipeline given in this paper, is based on our pipeline for wmt 2009 (leusch et al, 2009), with several extensions as described.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1320">
<title id=" W10-1747.xml">the rwth system combination system for wmt 2010 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>several improvements have been added later (matusov et al., 2008).
</prevsent>
<prevsent>this approach includes an enhanced alignment and reordering framework.
</prevsent>
</prevsection>
<citsent citstr=" P07-1040 ">
in contrast to existing approaches (jayaraman and lavie, 2005; <papid> P05-3026 </papid>rosti et al, 2007), <papid> P07-1040 </papid>the context of the whole corpus rather than single sentence is considered in this iterative, unsupervised procedure, yielding more reliable alignment.</citsent>
<aftsection>
<nextsent>majority voting on the generated lattice is performed using prior weights for each system as well as other statistical models such as special n-gram language model.
</nextsent>
<nextsent>in addition to lattice rescoring, n-best list reranking techniques can be applied to best paths of this lattice.
</nextsent>
<nextsent>true casing is considered separate step in rwths approach, which also takes the input hypotheses into account.
</nextsent>
<nextsent>the pipeline, and consequently the description of the pipeline given in this paper, is based on our pipeline for wmt 2009 (leusch et al, 2009), with several extensions as described.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1321">
<title id=" W10-1747.xml">the rwth system combination system for wmt 2010 </title>
<section> system combination algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>since it is not clear which hypothesis should be primary, i. e. has the best?
</prevsent>
<prevsent>word order, we let several or all hypothesis play the role of the primary translation, and align all pairs of hypotheses (en, em); 6= m. in this paper, we denote the number of possible primary hypotheses by . the word alignment is trained in analogy to the alignment training procedure in statistical mt. the difference is that the two sentences that have to be aligned are in the same language.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
we use theibm model 1 (brown et al, 1993) <papid> J93-2003 </papid>and the hidden markov model (hmm, (vogel et al, 1996)) <papid> C96-2141 </papid>315 alignmentgiza++- network generation weighting&rescoringreordering; 200-bestlist hyp 1 hyp k...</citsent>
<aftsection>
<nextsent>consensus translation nbestrescoring(triplets,lm, ...)
</nextsent>
<nextsent>figure 1: the system combination architecture.
</nextsent>
<nextsent>to estimate the alignment model.
</nextsent>
<nextsent>the alignment training corpus is created from test corpus of effectively ?(m1)k sentences translated by the involved mt engines.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1322">
<title id=" W10-1747.xml">the rwth system combination system for wmt 2010 </title>
<section> system combination algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>since it is not clear which hypothesis should be primary, i. e. has the best?
</prevsent>
<prevsent>word order, we let several or all hypothesis play the role of the primary translation, and align all pairs of hypotheses (en, em); 6= m. in this paper, we denote the number of possible primary hypotheses by . the word alignment is trained in analogy to the alignment training procedure in statistical mt. the difference is that the two sentences that have to be aligned are in the same language.
</prevsent>
</prevsection>
<citsent citstr=" C96-2141 ">
we use theibm model 1 (brown et al, 1993) <papid> J93-2003 </papid>and the hidden markov model (hmm, (vogel et al, 1996)) <papid> C96-2141 </papid>315 alignmentgiza++- network generation weighting&rescoringreordering; 200-bestlist hyp 1 hyp k...</citsent>
<aftsection>
<nextsent>consensus translation nbestrescoring(triplets,lm, ...)
</nextsent>
<nextsent>figure 1: the system combination architecture.
</nextsent>
<nextsent>to estimate the alignment model.
</nextsent>
<nextsent>the alignment training corpus is created from test corpus of effectively ?(m1)k sentences translated by the involved mt engines.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1323">
<title id=" W10-1747.xml">the rwth system combination system for wmt 2010 </title>
<section> system combination algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>to estimate the alignment model.
</prevsent>
<prevsent>the alignment training corpus is created from test corpus of effectively ?(m1)k sentences translated by the involved mt engines.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
model parameters are trained iteratively using the giza++toolkit (och and ney, 2003).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>the training is performed in the directions em ? en and en ? em.
</nextsent>
<nextsent>the final alignments are determined using cost matrix for each sentence pair (em, en).
</nextsent>
<nextsent>elements of this matrix are the local costs c(j, i) of aligning word em,j from em to word en,i from en.
</nextsent>
<nextsent>following matusov et al (2004), <papid> C04-1032 </papid>we compute these local costs by interpol ating the negated logarithms of the state occupation probabilities from the source-to-target?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1324">
<title id=" W10-1747.xml">the rwth system combination system for wmt 2010 </title>
<section> system combination algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>the final alignments are determined using cost matrix for each sentence pair (em, en).
</prevsent>
<prevsent>elements of this matrix are the local costs c(j, i) of aligning word em,j from em to word en,i from en.
</prevsent>
</prevsection>
<citsent citstr=" C04-1032 ">
following matusov et al (2004), <papid> C04-1032 </papid>we compute these local costs by interpol ating the negated logarithms of the state occupation probabilities from the source-to-target?</citsent>
<aftsection>
<nextsent>and target-to source?
</nextsent>
<nextsent>training of the hmm model.
</nextsent>
<nextsent>2.2 word reordering and confusion.
</nextsent>
<nextsent>network generation after reordering each secondary hypothesis em and the rows of the corresponding alignment cost matrix, we determine m1 monotone one-to-one alignments between en as the primary translation and em,m = 1, . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1326">
<title id=" W10-1747.xml">the rwth system combination system for wmt 2010 </title>
<section> word penalty.  </section>
<citcontext>
<prevsection>
<prevsent>(deen) or europarl (fren) 6.
</prevsent>
<prevsent>ibm1 scores and deletion counts based on a. word lexicon trained on wmt training data 316 7.
</prevsent>
</prevsection>
<citsent citstr=" D09-1022 ">
discriminative word lexicon score (mauser et. al., 2009) <papid> D09-1022 </papid>8.</citsent>
<aftsection>
<nextsent>triplet lexicon score (hasan et al, 2008).<papid> D08-1039 </papid></nextsent>
<nextsent>other features were also calculated, but did not seem to give an improvement on the dev set.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1327">
<title id=" W10-1747.xml">the rwth system combination system for wmt 2010 </title>
<section> word penalty.  </section>
<citcontext>
<prevsection>
<prevsent>ibm1 scores and deletion counts based on a. word lexicon trained on wmt training data 316 7.
</prevsent>
<prevsent>discriminative word lexicon score (mauser et. al., 2009) <papid> D09-1022 </papid>8.</prevsent>
</prevsection>
<citsent citstr=" D08-1039 ">
triplet lexicon score (hasan et al, 2008).<papid> D08-1039 </papid></citsent>
<aftsection>
<nextsent>other features were also calculated, but did not seem to give an improvement on the dev set.
</nextsent>
<nextsent>2.7 consensus true casing.
</nextsent>
<nextsent>previous approaches to achieve true cased output in system combination operated on true-cased lattices, used separate input-independent true caser,or used general true-cased lm to differentiate between alternative arcs in the lattice, as in (leusch et al, 2009).
</nextsent>
<nextsent>for wmt 2010, we use per-sentence information from the input systems to determine the consensus case of each outputword.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1328">
<title id=" W10-1747.xml">the rwth system combination system for wmt 2010 </title>
<section> word penalty.  </section>
<citcontext>
<prevsection>
<prevsent>rescoring for lattice rescoring, we need to tune system weights, lm factor, and word penalty to produce good consensus translations.
</prevsent>
<prevsent>the same holds for the log-linear weights in n-best reranking.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
for the wmt 2010 workshop, we selected linear combination of bleu (papineni et al,2002) <papid> P02-1040 </papid>and ter (snover et al, 2006) as optimization criterion, ??</citsent>
<aftsection>
<nextsent>:= argmax?
</nextsent>
<nextsent>{bleu ? ter}, based on previous experience (mauser et al,2008).<papid> L08-1403 </papid></nextsent>
<nextsent>for more stable results, we use the case insensitive variants for both measures, despite the explicit use of case information in the pipeline.system weights were tuned to this criterion using the downhill simplex method.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1329">
<title id=" W10-1747.xml">the rwth system combination system for wmt 2010 </title>
<section> word penalty.  </section>
<citcontext>
<prevsection>
<prevsent>for the wmt 2010 workshop, we selected linear combination of bleu (papineni et al,2002) <papid> P02-1040 </papid>and ter (snover et al, 2006) as optimization criterion, ??</prevsent>
<prevsent>:= argmax?</prevsent>
</prevsection>
<citsent citstr=" L08-1403 ">
{bleu ? ter}, based on previous experience (mauser et al,2008).<papid> L08-1403 </papid></citsent>
<aftsection>
<nextsent>for more stable results, we use the case insensitive variants for both measures, despite the explicit use of case information in the pipeline.system weights were tuned to this criterion using the downhill simplex method.
</nextsent>
<nextsent>because we considered the number of segments in the tuning set to be too small to allow for further split into an actual tuning and control (dev) part, we wentfor method closely related to 5-fold cross validation: we randomly split the tuning set into 5 equal sized parts, and tune parameters on four fifth of the set, measuring progress on the remaining fifth.
</nextsent>
<nextsent>this was repeated for the other four choices for the dev?
</nextsent>
<nextsent>part.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1330">
<title id=" W10-1608.xml">opinion identification in spanish texts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this article, we present only results on the semantic orientation of opinion verbs, opinion nouns and topic introducers (sobre/about, con respecto a/with respect to, etc.).
</prevsent>
<prevsent>there are many studies that address these is sues: pang and lee (2008), for instance, discuss in 54 detail various concepts in the area of  opinion mining  or  sentiment analysis  and present the main proposals, resources and applications.
</prevsent>
</prevsection>
<citsent citstr=" H05-1045 ">
for our work, which focuses on the identification of source, topic and message, we have mainly drawn on the following: the scheme for annotating opinions and emotions proposed by wiebe, wilson, and cardie (2005); the work on opinion-holder (source) propositional opinion identification presented in (bethard et al., 2004); system for source identification using statistical methods (choi et al, 2005); <papid> H05-1045 </papid>method for opinion-holder and topic extraction from kim and hovy (2006); <papid> W06-0301 </papid>the study on the identification of source and target presented in (ruppenhofer et al., 2008); <papid> L08-1087 </papid>and work on topic annotation (stoyanov and cardie, 2008).<papid> L08-1088 </papid></citsent>
<aftsection>
<nextsent>for our semantic orientation study, we have taken some concepts from turney and littman (2003) and analyzed some work on subjectivity operators (polanyi and zaenen, 2004; moilanen and pulman, 2007; choi and cardie, 2008).<papid> D08-1083 </papid></nextsent>
<nextsent>in what follows, we briefly present the model that has been defined to represent opinions and two methods for their automatic recognition.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1331">
<title id=" W10-1608.xml">opinion identification in spanish texts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this article, we present only results on the semantic orientation of opinion verbs, opinion nouns and topic introducers (sobre/about, con respecto a/with respect to, etc.).
</prevsent>
<prevsent>there are many studies that address these is sues: pang and lee (2008), for instance, discuss in 54 detail various concepts in the area of  opinion mining  or  sentiment analysis  and present the main proposals, resources and applications.
</prevsent>
</prevsection>
<citsent citstr=" W06-0301 ">
for our work, which focuses on the identification of source, topic and message, we have mainly drawn on the following: the scheme for annotating opinions and emotions proposed by wiebe, wilson, and cardie (2005); the work on opinion-holder (source) propositional opinion identification presented in (bethard et al., 2004); system for source identification using statistical methods (choi et al, 2005); <papid> H05-1045 </papid>method for opinion-holder and topic extraction from kim and hovy (2006); <papid> W06-0301 </papid>the study on the identification of source and target presented in (ruppenhofer et al., 2008); <papid> L08-1087 </papid>and work on topic annotation (stoyanov and cardie, 2008).<papid> L08-1088 </papid></citsent>
<aftsection>
<nextsent>for our semantic orientation study, we have taken some concepts from turney and littman (2003) and analyzed some work on subjectivity operators (polanyi and zaenen, 2004; moilanen and pulman, 2007; choi and cardie, 2008).<papid> D08-1083 </papid></nextsent>
<nextsent>in what follows, we briefly present the model that has been defined to represent opinions and two methods for their automatic recognition.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1332">
<title id=" W10-1608.xml">opinion identification in spanish texts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this article, we present only results on the semantic orientation of opinion verbs, opinion nouns and topic introducers (sobre/about, con respecto a/with respect to, etc.).
</prevsent>
<prevsent>there are many studies that address these is sues: pang and lee (2008), for instance, discuss in 54 detail various concepts in the area of  opinion mining  or  sentiment analysis  and present the main proposals, resources and applications.
</prevsent>
</prevsection>
<citsent citstr=" L08-1087 ">
for our work, which focuses on the identification of source, topic and message, we have mainly drawn on the following: the scheme for annotating opinions and emotions proposed by wiebe, wilson, and cardie (2005); the work on opinion-holder (source) propositional opinion identification presented in (bethard et al., 2004); system for source identification using statistical methods (choi et al, 2005); <papid> H05-1045 </papid>method for opinion-holder and topic extraction from kim and hovy (2006); <papid> W06-0301 </papid>the study on the identification of source and target presented in (ruppenhofer et al., 2008); <papid> L08-1087 </papid>and work on topic annotation (stoyanov and cardie, 2008).<papid> L08-1088 </papid></citsent>
<aftsection>
<nextsent>for our semantic orientation study, we have taken some concepts from turney and littman (2003) and analyzed some work on subjectivity operators (polanyi and zaenen, 2004; moilanen and pulman, 2007; choi and cardie, 2008).<papid> D08-1083 </papid></nextsent>
<nextsent>in what follows, we briefly present the model that has been defined to represent opinions and two methods for their automatic recognition.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1333">
<title id=" W10-1608.xml">opinion identification in spanish texts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this article, we present only results on the semantic orientation of opinion verbs, opinion nouns and topic introducers (sobre/about, con respecto a/with respect to, etc.).
</prevsent>
<prevsent>there are many studies that address these is sues: pang and lee (2008), for instance, discuss in 54 detail various concepts in the area of  opinion mining  or  sentiment analysis  and present the main proposals, resources and applications.
</prevsent>
</prevsection>
<citsent citstr=" L08-1088 ">
for our work, which focuses on the identification of source, topic and message, we have mainly drawn on the following: the scheme for annotating opinions and emotions proposed by wiebe, wilson, and cardie (2005); the work on opinion-holder (source) propositional opinion identification presented in (bethard et al., 2004); system for source identification using statistical methods (choi et al, 2005); <papid> H05-1045 </papid>method for opinion-holder and topic extraction from kim and hovy (2006); <papid> W06-0301 </papid>the study on the identification of source and target presented in (ruppenhofer et al., 2008); <papid> L08-1087 </papid>and work on topic annotation (stoyanov and cardie, 2008).<papid> L08-1088 </papid></citsent>
<aftsection>
<nextsent>for our semantic orientation study, we have taken some concepts from turney and littman (2003) and analyzed some work on subjectivity operators (polanyi and zaenen, 2004; moilanen and pulman, 2007; choi and cardie, 2008).<papid> D08-1083 </papid></nextsent>
<nextsent>in what follows, we briefly present the model that has been defined to represent opinions and two methods for their automatic recognition.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1334">
<title id=" W10-1608.xml">opinion identification in spanish texts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there are many studies that address these is sues: pang and lee (2008), for instance, discuss in 54 detail various concepts in the area of  opinion mining  or  sentiment analysis  and present the main proposals, resources and applications.
</prevsent>
<prevsent>for our work, which focuses on the identification of source, topic and message, we have mainly drawn on the following: the scheme for annotating opinions and emotions proposed by wiebe, wilson, and cardie (2005); the work on opinion-holder (source) propositional opinion identification presented in (bethard et al., 2004); system for source identification using statistical methods (choi et al, 2005); <papid> H05-1045 </papid>method for opinion-holder and topic extraction from kim and hovy (2006); <papid> W06-0301 </papid>the study on the identification of source and target presented in (ruppenhofer et al., 2008); <papid> L08-1087 </papid>and work on topic annotation (stoyanov and cardie, 2008).<papid> L08-1088 </papid></prevsent>
</prevsection>
<citsent citstr=" D08-1083 ">
for our semantic orientation study, we have taken some concepts from turney and littman (2003) and analyzed some work on subjectivity operators (polanyi and zaenen, 2004; moilanen and pulman, 2007; choi and cardie, 2008).<papid> D08-1083 </papid></citsent>
<aftsection>
<nextsent>in what follows, we briefly present the model that has been defined to represent opinions and two methods for their automatic recognition.
</nextsent>
<nextsent>first, we describe rule-based system that incorporates lexical resources.
</nextsent>
<nextsent>this system, whose evaluation is detailed below, achieves recall of 74% and precision of 97%.
</nextsent>
<nextsent>during the evaluation process we produced an annotated corpus of 13,000 words, by manually correcting the system output.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1335">
<title id=" W10-1608.xml">opinion identification in spanish texts </title>
<section> opinion components.  </section>
<citcontext>
<prevsection>
<prevsent>the set of opinion predicates includes verbs, nouns and prepositions (or prepositional locutions).
</prevsent>
<prevsent>verbs belong to various semantic classes: communication (decir / say, declarar / state), assessment (criticar / criticize, felicitar / compliment), belief (creer / believe, opinar / think) and acceptance (aceptar / accept, rechazar / reject).
</prevsent>
</prevsection>
<citsent citstr=" C08-2002 ">
these classes are similar to those proposed in (asher et al, 2008), <papid> C08-2002 </papid>the main difference being that they include the class sentiment but we do not.</citsent>
<aftsection>
<nextsent>nouns are generally derived from the aforementioned verbs (opinin / opinion, declaracin / statement, apoyo / support).
</nextsent>
<nextsent>some prepositions and prepositional locutions are segn, de acuerdo a, para / according to.
</nextsent>
<nextsent>the relevant arguments that we identified for the opinion predicates are, as already mentioned, source, topic and message.
</nextsent>
<nextsent>to establish this scheme we analysed syntactico-semantic schemes proposed in adesse2 for selected verb classes (garca-miguel et al, 2005) and some of the spanish framenet frames3 (subirats-rggeberg and petruck., 2003), mainly the opinion frame whose frame elements include cognizer (source), topic and opinion (message) and the communication frame for which some elements are communicator (source), topic and message.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1336">
<title id=" W10-3305.xml">learning semantic network patterns for hypernymy extraction </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the patterns are applied on set of sns which are automatically derived fromthe german wikipedia1 by deep syntacticosemantic analysis.
</prevsent>
<prevsent>furthermore, these patterns are automatically created by machine learning approach based on the mdl principle.
</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
patterns for hypernymy extraction were first introduced by hearst (hearst, 1992), <papid> C92-2082 </papid>the so called hearst patterns.</citsent>
<aftsection>
<nextsent>an example of such pattern is: nphypo {,nphypo}*{,} and other nphyper.
</nextsent>
<nextsent>these patterns are applied on arbitrary texts and the instantiated variables nphypo and nphyper are then extracted as concrete hypernymy relation.
</nextsent>
<nextsent>apart from the handcrafted patterns there was also some work to determine patterns automatically from texts (snow and others,2005).
</nextsent>
<nextsent>for that, snow et al collected sentences in given text corpus with known hy pernym noun pairs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1337">
<title id=" W10-1718.xml">joshua 20 a toolkit for parsing based machine translation with syntax semi rings discriminative training and other goodies </title>
<section> abstract </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" P09-1067 ">
we describe the progress we have made in the past year on joshua (li et al, 2009<papid> P09-1067 </papid>a), an open source toolkit for parsing based machine translation.</citsent>
<aftsection>
<nextsent>the new functionality includes: support for translation grammars with rich set of syntactic nonterminals, the ability for external modules toposit constraints on how spans in the in put sentence should be translated, lattice parsing for dealing with input uncertainty,a semi ring framework that provides unified way of doing various dynamic programming calculations, variational decoding for approximating the intractable map decoding, hypergraph-based discriminative training for better feature engineering,a parallel ized mert module, document level and tail-based mert, visualization of the derivation trees, and cleaner pipeline for mt experiments.
</nextsent>
<nextsent>joshua is an open-source toolkit for parsing-based machine translation that is written in java.
</nextsent>
<nextsent>the initial release of joshua (li et al, 2009<papid> P09-1067 </papid>a) was re-implementation of the hiero system (chiang,2007) <papid> J07-2003 </papid>and all its associated algorithms, including: chart parsing, n-gram language model integration, beam and cube pruning, and k-best ex traction.</nextsent>
<nextsent>the joshua 1.0 release also includedre-implementations of suffix array grammar extraction (lopez, 2007; <papid> D07-1104 </papid>schwartz and callison burch, 2010) and minimum error rate training(och, 2003; <papid> P03-1021 </papid>zaidan, 2009).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1343">
<title id=" W10-1718.xml">joshua 20 a toolkit for parsing based machine translation with syntax semi rings discriminative training and other goodies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the new functionality includes: support for translation grammars with rich set of syntactic nonterminals, the ability for external modules toposit constraints on how spans in the in put sentence should be translated, lattice parsing for dealing with input uncertainty,a semi ring framework that provides unified way of doing various dynamic programming calculations, variational decoding for approximating the intractable map decoding, hypergraph-based discriminative training for better feature engineering,a parallel ized mert module, document level and tail-based mert, visualization of the derivation trees, and cleaner pipeline for mt experiments.
</prevsent>
<prevsent>joshua is an open-source toolkit for parsing-based machine translation that is written in java.
</prevsent>
</prevsection>
<citsent citstr=" J07-2003 ">
the initial release of joshua (li et al, 2009<papid> P09-1067 </papid>a) was re-implementation of the hiero system (chiang,2007) <papid> J07-2003 </papid>and all its associated algorithms, including: chart parsing, n-gram language model integration, beam and cube pruning, and k-best ex traction.</citsent>
<aftsection>
<nextsent>the joshua 1.0 release also includedre-implementations of suffix array grammar extraction (lopez, 2007; <papid> D07-1104 </papid>schwartz and callison burch, 2010) and minimum error rate training(och, 2003; <papid> P03-1021 </papid>zaidan, 2009).</nextsent>
<nextsent>additionally, it included parallel and distributed computing techniques for scala bility (li and khudanpur, 2008).<papid> W08-0402 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1344">
<title id=" W10-1718.xml">joshua 20 a toolkit for parsing based machine translation with syntax semi rings discriminative training and other goodies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>joshua is an open-source toolkit for parsing-based machine translation that is written in java.
</prevsent>
<prevsent>the initial release of joshua (li et al, 2009<papid> P09-1067 </papid>a) was re-implementation of the hiero system (chiang,2007) <papid> J07-2003 </papid>and all its associated algorithms, including: chart parsing, n-gram language model integration, beam and cube pruning, and k-best ex traction.</prevsent>
</prevsection>
<citsent citstr=" D07-1104 ">
the joshua 1.0 release also includedre-implementations of suffix array grammar extraction (lopez, 2007; <papid> D07-1104 </papid>schwartz and callison burch, 2010) and minimum error rate training(och, 2003; <papid> P03-1021 </papid>zaidan, 2009).</citsent>
<aftsection>
<nextsent>additionally, it included parallel and distributed computing techniques for scala bility (li and khudanpur, 2008).<papid> W08-0402 </papid></nextsent>
<nextsent>this paper describes the additions to the toolkit over the past year, which together form the 2.0 re lease.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1345">
<title id=" W10-1718.xml">joshua 20 a toolkit for parsing based machine translation with syntax semi rings discriminative training and other goodies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>joshua is an open-source toolkit for parsing-based machine translation that is written in java.
</prevsent>
<prevsent>the initial release of joshua (li et al, 2009<papid> P09-1067 </papid>a) was re-implementation of the hiero system (chiang,2007) <papid> J07-2003 </papid>and all its associated algorithms, including: chart parsing, n-gram language model integration, beam and cube pruning, and k-best ex traction.</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
the joshua 1.0 release also includedre-implementations of suffix array grammar extraction (lopez, 2007; <papid> D07-1104 </papid>schwartz and callison burch, 2010) and minimum error rate training(och, 2003; <papid> P03-1021 </papid>zaidan, 2009).</citsent>
<aftsection>
<nextsent>additionally, it included parallel and distributed computing techniques for scala bility (li and khudanpur, 2008).<papid> W08-0402 </papid></nextsent>
<nextsent>this paper describes the additions to the toolkit over the past year, which together form the 2.0 re lease.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1346">
<title id=" W10-1718.xml">joshua 20 a toolkit for parsing based machine translation with syntax semi rings discriminative training and other goodies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the initial release of joshua (li et al, 2009<papid> P09-1067 </papid>a) was re-implementation of the hiero system (chiang,2007) <papid> J07-2003 </papid>and all its associated algorithms, including: chart parsing, n-gram language model integration, beam and cube pruning, and k-best ex traction.</prevsent>
<prevsent>the joshua 1.0 release also includedre-implementations of suffix array grammar extraction (lopez, 2007; <papid> D07-1104 </papid>schwartz and callison burch, 2010) and minimum error rate training(och, 2003; <papid> P03-1021 </papid>zaidan, 2009).</prevsent>
</prevsection>
<citsent citstr=" W08-0402 ">
additionally, it included parallel and distributed computing techniques for scala bility (li and khudanpur, 2008).<papid> W08-0402 </papid></citsent>
<aftsection>
<nextsent>this paper describes the additions to the toolkit over the past year, which together form the 2.0 release.
</nextsent>
<nextsent>the software has been heavily used by the authors and several other groups in their daily research, and has been substantially refined since the first release.
</nextsent>
<nextsent>the most important new functions in the toolkit are: ? support for any style of synchronous context free grammar (scfg) including syntax augment machine translation (samt) grammars (zollmann and venugopal, 2006)?<papid> W06-3119 </papid></nextsent>
<nextsent>support for external modules to posit translations for spans in the input sentence that constrain decoding (irvine et al, 2010)?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1347">
<title id=" W10-1718.xml">joshua 20 a toolkit for parsing based machine translation with syntax semi rings discriminative training and other goodies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper describes the additions to the toolkit over the past year, which together form the 2.0 release.
</prevsent>
<prevsent>the software has been heavily used by the authors and several other groups in their daily research, and has been substantially refined since the first release.
</prevsent>
</prevsection>
<citsent citstr=" W06-3119 ">
the most important new functions in the toolkit are: ? support for any style of synchronous context free grammar (scfg) including syntax augment machine translation (samt) grammars (zollmann and venugopal, 2006)?<papid> W06-3119 </papid></citsent>
<aftsection>
<nextsent>support for external modules to posit translations for spans in the input sentence that constrain decoding (irvine et al, 2010)?
</nextsent>
<nextsent>lattice parsing for dealing with input uncertainty, including ambiguous output from speech recognizers or chinese word seg menters (dyer et al, 2008) ? <papid> P08-1115 </papid>semi ring architecture over hypergraphs that allows many inference operations to be implemented easily and elegantly (li and eisner, 2009)?<papid> D09-1005 </papid></nextsent>
<nextsent>improvements to decoding through variational decoding and other approximate methods that overcome intractable map decoding (li et al, 2009<papid> P09-1067 </papid>b) ? hypergraph-based discriminative training for better feature engineering (li and khudanpur, 2009<papid> N09-2003 </papid>b) ? parallel ization of merts computations, and supporting document-level and tail-based optimization (zaidan, 2010)?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1348">
<title id=" W10-1718.xml">joshua 20 a toolkit for parsing based machine translation with syntax semi rings discriminative training and other goodies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the most important new functions in the toolkit are: ? support for any style of synchronous context free grammar (scfg) including syntax augment machine translation (samt) grammars (zollmann and venugopal, 2006)?<papid> W06-3119 </papid></prevsent>
<prevsent>support for external modules to posit translations for spans in the input sentence that constrain decoding (irvine et al, 2010)?</prevsent>
</prevsection>
<citsent citstr=" P08-1115 ">
lattice parsing for dealing with input uncertainty, including ambiguous output from speech recognizers or chinese word seg menters (dyer et al, 2008) ? <papid> P08-1115 </papid>semi ring architecture over hypergraphs that allows many inference operations to be implemented easily and elegantly (li and eisner, 2009)?<papid> D09-1005 </papid></citsent>
<aftsection>
<nextsent>improvements to decoding through variational decoding and other approximate methods that overcome intractable map decoding (li et al, 2009<papid> P09-1067 </papid>b) ? hypergraph-based discriminative training for better feature engineering (li and khudanpur, 2009<papid> N09-2003 </papid>b) ? parallel ization of merts computations, and supporting document-level and tail-based optimization (zaidan, 2010)?</nextsent>
<nextsent>visualization of the derivation trees and hypergraphs (weese and callison-burch, 2010) ? convenient framework for designing and running reproducible machine translation experiments (schwartz, under review) the sections below give short descriptions for each of these new functions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1349">
<title id=" W10-1718.xml">joshua 20 a toolkit for parsing based machine translation with syntax semi rings discriminative training and other goodies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the most important new functions in the toolkit are: ? support for any style of synchronous context free grammar (scfg) including syntax augment machine translation (samt) grammars (zollmann and venugopal, 2006)?<papid> W06-3119 </papid></prevsent>
<prevsent>support for external modules to posit translations for spans in the input sentence that constrain decoding (irvine et al, 2010)?</prevsent>
</prevsection>
<citsent citstr=" D09-1005 ">
lattice parsing for dealing with input uncertainty, including ambiguous output from speech recognizers or chinese word seg menters (dyer et al, 2008) ? <papid> P08-1115 </papid>semi ring architecture over hypergraphs that allows many inference operations to be implemented easily and elegantly (li and eisner, 2009)?<papid> D09-1005 </papid></citsent>
<aftsection>
<nextsent>improvements to decoding through variational decoding and other approximate methods that overcome intractable map decoding (li et al, 2009<papid> P09-1067 </papid>b) ? hypergraph-based discriminative training for better feature engineering (li and khudanpur, 2009<papid> N09-2003 </papid>b) ? parallel ization of merts computations, and supporting document-level and tail-based optimization (zaidan, 2010)?</nextsent>
<nextsent>visualization of the derivation trees and hypergraphs (weese and callison-burch, 2010) ? convenient framework for designing and running reproducible machine translation experiments (schwartz, under review) the sections below give short descriptions for each of these new functions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1353">
<title id=" W10-1718.xml">joshua 20 a toolkit for parsing based machine translation with syntax semi rings discriminative training and other goodies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>support for external modules to posit translations for spans in the input sentence that constrain decoding (irvine et al, 2010)?
</prevsent>
<prevsent>lattice parsing for dealing with input uncertainty, including ambiguous output from speech recognizers or chinese word seg menters (dyer et al, 2008) ? <papid> P08-1115 </papid>semi ring architecture over hypergraphs that allows many inference operations to be implemented easily and elegantly (li and eisner, 2009)?<papid> D09-1005 </papid></prevsent>
</prevsection>
<citsent citstr=" N09-2003 ">
improvements to decoding through variational decoding and other approximate methods that overcome intractable map decoding (li et al, 2009<papid> P09-1067 </papid>b) ? hypergraph-based discriminative training for better feature engineering (li and khudanpur, 2009<papid> N09-2003 </papid>b) ? parallel ization of merts computations, and supporting document-level and tail-based optimization (zaidan, 2010)?</citsent>
<aftsection>
<nextsent>visualization of the derivation trees and hypergraphs (weese and callison-burch, 2010) ? convenient framework for designing and running reproducible machine translation experiments (schwartz, under review) the sections below give short descriptions for each of these new functions.
</nextsent>
<nextsent>133
</nextsent>
<nextsent>the initial release of joshua supported onlyhiero-style scfgs, which use single nonterminal symbol x. this release includes support for arbitrary scfgs, including ones that use rich set of linguistic nonterminal symbols.
</nextsent>
<nextsent>in particular we have added support for zollmann and venugopal (2006)<papid> W06-3119 </papid>s syntax-augmented machine trans lation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1355">
<title id=" W10-1718.xml">joshua 20 a toolkit for parsing based machine translation with syntax semi rings discriminative training and other goodies </title>
<section> semi ring parsing.  </section>
<citcontext>
<prevsection>
<prevsent>given hypergraph, we may perform many atomic inference operations, such as finding one-best or k-best translations, or computing expectations over the hypergraph.
</prevsent>
<prevsent>foreach such operation, we could implement dedicated dynamic programming algorithm.
</prevsent>
</prevsection>
<citsent citstr=" J99-4004 ">
how ever, more general framework to specify these algorithms is semiring-weighted parsing (goodman, 1999).<papid> J99-4004 </papid></citsent>
<aftsection>
<nextsent>we have implemented the in side algorithm, the outside algorithm, and theinside-outside speedup described by li and eisner (2009), <papid> D09-1005 </papid>plut the first-order expectation semir ing (eisner, 2002) <papid> P02-1001 </papid>and its second-order version (liand eisner, 2009).<papid> D09-1005 </papid></nextsent>
<nextsent>all of these use our newly implemented semi ring framework.the first- and second-order expectation semi rings can also be used to compute many interesting quantities over hypergraphs.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1357">
<title id=" W10-1718.xml">joshua 20 a toolkit for parsing based machine translation with syntax semi rings discriminative training and other goodies </title>
<section> semi ring parsing.  </section>
<citcontext>
<prevsection>
<prevsent>foreach such operation, we could implement dedicated dynamic programming algorithm.
</prevsent>
<prevsent>how ever, more general framework to specify these algorithms is semiring-weighted parsing (goodman, 1999).<papid> J99-4004 </papid></prevsent>
</prevsection>
<citsent citstr=" P02-1001 ">
we have implemented the in side algorithm, the outside algorithm, and theinside-outside speedup described by li and eisner (2009), <papid> D09-1005 </papid>plut the first-order expectation semir ing (eisner, 2002) <papid> P02-1001 </papid>and its second-order version (liand eisner, 2009).<papid> D09-1005 </papid></citsent>
<aftsection>
<nextsent>all of these use our newly implemented semi ring framework.the first- and second-order expectation semi rings can also be used to compute many interesting quantities over hypergraphs.
</nextsent>
<nextsent>these quantities include expected translation length, feature expectation, entropy, cross-entropy, kullback-leibler divergence, bayes risk, variance of hypothesis length, gradient of entropy and bayes risk, covari ance and hessian matrix, and so on.
</nextsent>
<nextsent>we generalized the bottom-up parsing algorithm that generates the translation hypergraph so that it supports translation of word lattices instead of just sentences.
</nextsent>
<nextsent>our implementations runtime and memory overhead is proportional to the size of the lattice, rather than the number of paths in the lattice (dyer et al, 2008).<papid> P08-1115 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1364">
<title id=" W10-1718.xml">joshua 20 a toolkit for parsing based machine translation with syntax semi rings discriminative training and other goodies </title>
<section> hypergraph-based discriminative.  </section>
<citcontext>
<prevsection>
<prevsent>since the reference translation may not be in the hypergraph due to pruning or inherent defficiency of the translation grammar, weneed to use an oracle translation (i.e., the translation in the hypergraph that is most simmilar to the reference translation) as surrogate for training.
</prevsent>
<prevsent>we implemented the oracle extraction algorithm described by li and khudanpur (2009<papid> N09-2003 </papid>a) for this purpose.</prevsent>
</prevsection>
<citsent citstr=" N09-1025 ">
given the current infrastructure, other training methods (e.g., maximum conditional likelihood or mira as used by chiang et al (2009)) <papid> N09-1025 </papid>can also be easily supported with minimum coding.</citsent>
<aftsection>
<nextsent>we plan to implement large number of feature functions in joshua so that exhaustive feature engineering is possible for mt.
</nextsent>
<nextsent>joshuas mert module optimizes parameter weights so as to maximize performance on development set as measuered by an automatic evaluation metric, such as bleu (och, 2003).<papid> P03-1021 </papid></nextsent>
<nextsent>we have parallel ized our mert module intwo ways: parallelizing the computation of metric scores, and parallelizing the search over pa rameters.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1366">
<title id=" W10-2305.xml">hierarchical spectral partitioning of bipartite graphs to cluster dialects and identify distinguishing features </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>in this study we apply hierarchical spectral partitioning of bipartite graphs to dutch dialect dataset to cluster dialect varieties and determine the concomitant sound correspondences.
</prevsent>
<prevsent>an important advantage ofthis clustering method over other dialectometric methods is that the linguistic basis is simultaneously determined, bridging the gap between traditional and quantitative dialectology.
</prevsent>
</prevsection>
<citsent citstr=" W09-3203 ">
besides showing that the results of the hierarchical clustering improve over the flat spectral clustering method used in an earlier study (wieling and nerbonne, 2009), <papid> W09-3203 </papid>the values of the second singular vector used to generate the two-way clustering can be used to identify the most important sound correspondences for each cluster.</citsent>
<aftsection>
<nextsent>this is an important advantage of the hierarchical method as it obviates the need for external methods to determine the most important sound correspondences for geographical cluster.
</nextsent>
<nextsent>for almost forty years quantitative methods have been applied to the analysis of dialect variation (seguy, 1973; goebl, 1982; nerbonne et al, 1999).
</nextsent>
<nextsent>until recently, these methods focused mostly on identifying the most important dialectalgroups using an aggregate analysis of the linguistic data.
</nextsent>
<nextsent>one of these quantitative methods, clustering,has been applied frequently to dialect data, especially in an effort to compare computational analyses to traditional views on dialect areas (davisand houck, 1995; clopper and pisoni, 2004; heeringa, 2004; moisl and jones, 2005; mucha and haimerl, 2005; prokic?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1418">
<title id=" W10-2415.xml">assessing the challenge of fine grained named entity recognition and classification </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>named entity recognition and classification (cf.
</prevsent>
<prevsent>nadeau and sekine (2007)) is well-establishednlp task relevant for nearly all semantic processing and information access applications.
</prevsent>
</prevsection>
<citsent citstr=" W03-0430 ">
nerc has been investigated using supervised (mccallum and li, 2003), <papid> W03-0430 </papid>unsupervised (etzioni et al, 2005) and semi-supervised (pasca et al, 2006b) learning methods.</citsent>
<aftsection>
<nextsent>it has been investigated in multilingual settings (tjong kim sang, 2002; tjong kim sang and de meulder, 2003) and special domains, e.g. biomedicine (ananiadou et al, 2004).the classical nerc task is confined to coarse grained named entity (ne) classes established in the muc (muc-7, 1998) or conll (tjong kim sang, 2002) competitions, typically pers,loc, org, misc.
</nextsent>
<nextsent>while most recent work concentrates on feature engineering and robust statistical models for various domains, few researchers addressed the problem of recognizing and categorizing fine-grained ne classes (such as biologist, composer, or athlete) in an open-domain setting.fine-grained nerc is expected to be beneficial for wide spectrum of applications, including information retrieval (mandl and womser hacker, 2005), information extraction (pasca et al., 2006a) or question-answering (pizzato etal., 2006).
</nextsent>
<nextsent>however, manually compiling wide coverage gazette ers for fine-grained ne classes is time-consuming and error-prone.
</nextsent>
<nextsent>also, without an extrinsic evaluation, it is difficult to define priori which classes are relevant for particular domain or task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1419">
<title id=" W10-2415.xml">assessing the challenge of fine grained named entity recognition and classification </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>an early approach to fg-nerc is alfonseca and manandhar (2002), who identify it as problem related to word sense disambiguation (wsd).
</prevsent>
<prevsent>they jointly address concept hierarchy learning and instance classification using topic signatures,yet the experiments are restricted to small ontology of 9 classes.
</prevsent>
</prevsection>
<citsent citstr=" C02-1130 ">
similarly, fleischman andhovy (2002) <papid> C02-1130 </papid>extend previous work from fleischman (2001) on locations and address the acquisition of instances for 8 fine-grained person classes.</citsent>
<aftsection>
<nextsent>for supervised training they compile web corpus which is filtered using high-confident classifications from an initial classifier trained on seeds.
</nextsent>
<nextsent>due to the limitations of their method to create good sample of training data, the performance could not be generalized to held-out data.
</nextsent>
<nextsent>recent work takes the task of fg-nerc one step further by (i) extending the number of classes,(ii) relating them to reference concept hierarchies and (iii) exploring methods for building training and evaluation data, or applying weakly and unsupervised learning based on high-volumedata.
</nextsent>
<nextsent>tanev and magnini (2006) <papid> E06-1003 </papid>selected 10 nesubclasses of person and location using wordnet as reference.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1420">
<title id=" W10-2415.xml">assessing the challenge of fine grained named entity recognition and classification </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>due to the limitations of their method to create good sample of training data, the performance could not be generalized to held-out data.
</prevsent>
<prevsent>recent work takes the task of fg-nerc one step further by (i) extending the number of classes,(ii) relating them to reference concept hierarchies and (iii) exploring methods for building training and evaluation data, or applying weakly and unsupervised learning based on high-volumedata.
</prevsent>
</prevsection>
<citsent citstr=" E06-1003 ">
tanev and magnini (2006) <papid> E06-1003 </papid>selected 10 nesubclasses of person and location using wordnet as reference.</citsent>
<aftsection>
<nextsent>datasets were automatically acquired and manually filtered.
</nextsent>
<nextsent>they compare word and pattern-based supervised and semi supervised approach based on syntactic features.
</nextsent>
<nextsent>giuliano &amp; gliozzo (2007),  <papid> D07-1026 </papid>gliozzo (2008) perform neclassification against the people ontology, an excerpt of the wordnet hierarchy, comprising 21 people classes populated with at least 40 instances.</nextsent>
<nextsent>using minimally supervised lexical substitution methods, they cast ne classification as an ontology population task ? as opposed to recognition and classification in context.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1421">
<title id=" W10-2415.xml">assessing the challenge of fine grained named entity recognition and classification </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>datasets were automatically acquired and manually filtered.
</prevsent>
<prevsent>they compare word and pattern-based supervised and semi supervised approach based on syntactic features.
</prevsent>
</prevsection>
<citsent citstr=" D07-1026 ">
giuliano &amp; gliozzo (2007),  <papid> D07-1026 </papid>gliozzo (2008) perform neclassification against the people ontology, an excerpt of the wordnet hierarchy, comprising 21 people classes populated with at least 40 instances.</citsent>
<aftsection>
<nextsent>using minimally supervised lexical substitution methods, they cast ne classification as an ontology population task ? as opposed to recognition and classification in context.
</nextsent>
<nextsent>in similar setting,giuliano (2009) <papid> W09-1125 </papid>explores semi-supervised classification of the people ontology classes using latent semantic kernels, comparing models built from wikipedia and from news corpus.</nextsent>
<nextsent>in different line of research pasca (2007) and pasca andvan durme (2008) make use of query logs to acquire nes on large scale.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1422">
<title id=" W10-2415.xml">assessing the challenge of fine grained named entity recognition and classification </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>giuliano &amp; gliozzo (2007),  <papid> D07-1026 </papid>gliozzo (2008) perform neclassification against the people ontology, an excerpt of the wordnet hierarchy, comprising 21 people classes populated with at least 40 instances.</prevsent>
<prevsent>using minimally supervised lexical substitution methods, they cast ne classification as an ontology population task ? as opposed to recognition and classification in context.</prevsent>
</prevsection>
<citsent citstr=" W09-1125 ">
in similar setting,giuliano (2009) <papid> W09-1125 </papid>explores semi-supervised classification of the people ontology classes using latent semantic kernels, comparing models built from wikipedia and from news corpus.</citsent>
<aftsection>
<nextsent>in different line of research pasca (2007) and pasca andvan durme (2008) make use of query logs to acquire nes on large scale.
</nextsent>
<nextsent>while pasca (2007) extracts nes for 10 target classes, pasca and van durme (2008) combine web query logs and web documents to acquire both ne-concept pairs and concept attributes using seeds.but while these more recent approaches all offer substantially novel contributions for many ne acquisition subtasks, none of them addresses thefull task of fg-nerc, i.e., recognition and classification of ne tokens in context.
</nextsent>
<nextsent>compared to ontology population, focusing on types, classification in raw texts needs to consider any token and cannot relyon special contexts offering indicative clues for class membership.bunescu and pasca (2006) also perform disambiguation and classification of nes in context,yet in different setup.
</nextsent>
<nextsent>disambiguation is performed into one of the known possible classes for ne, as determined from wikipedia disambiguation pages.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1423">
<title id=" W10-2415.xml">assessing the challenge of fine grained named entity recognition and classification </title>
<section> acquisition of fg-nerc dataset.  </section>
<citcontext>
<prevsection>
<prevsent>in order to perform hierarchical classification of people, we need taxonomy for the domain at hand.
</prevsent>
<prevsent>we achieve this by mapping the extracted class labels to wordnet synsets.
</prevsent>
</prevsection>
<citsent citstr=" W00-0730 ">
in our setting, we map against all synsets found under person#n#1,1we use yamcha (kudo and matsumoto, 2000) <papid> W00-0730 </papid>to perform phrase chunking.</citsent>
<aftsection>
<nextsent>95which are direct hypernyms of at least one instance in wordnet (cwn pers+inst).2 since ourgoal is to map class labels to synsets (i.e. our future ne classes), we check each class label candidate against all synonyms contained in the synset.
</nextsent>
<nextsent>at this point we have to deal with two cases: two extracted class label candidates (synonyms such as doctor, physician) will map to single synset, while ambiguous class labels (e.g. director) can be mapped to more than one synset.
</nextsent>
<nextsent>in the latter case,we heuristic ally choose the synset which dominates the highest number of instances in wordnet.mapping evaluation.
</nextsent>
<nextsent>we evaluated the cover age of our mapping for two sets of class labels extracted for two different frequency thresholds: ft = 40 and ft = 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1424">
<title id=" W10-2415.xml">assessing the challenge of fine grained named entity recognition and classification </title>
<section> acquisition of fg-nerc dataset.  </section>
<citcontext>
<prevsection>
<prevsent>the type-token ratio is 1.52.
</prevsent>
<prevsent>gold standard validation.
</prevsent>
</prevsection>
<citsent citstr=" C08-1034 ">
to create gold standard dataset of entities in context labeled with fine-grained classes, we first randomly select 20 classes, as well as an additional 18 which are also found in the people ontology (giuliano and gliozzo, 2008).<papid> C08-1034 </papid></citsent>
<aftsection>
<nextsent>for each class, we randomly select 40 occurrences of instances in context, i.e. the words co-occurring in window of 60 tokens before and after the instance.
</nextsent>
<nextsent>we asked four annotators to label these extractions for correctness, and to provide the correct label for the incorrect cases, if one was available.
</nextsent>
<nextsent>only 52 contexts out of 1520 were labeled as incorrect, thus giving us 96.58% accuracy on our automatically extracted data.
</nextsent>
<nextsent>the manually validated dataset is used to provide ground-truth for fg-nerc.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1425">
<title id=" W10-2415.xml">assessing the challenge of fine grained named entity recognition and classification </title>
<section> methodology for fg-nerc.  </section>
<citcontext>
<prevsection>
<prevsent>we then present in section 5.3 an alternative proposal to perform fg nerc using global context information, as found in state-of-the-art approaches to supervised and unsupervised wsd.
</prevsent>
<prevsent>5.1 nerc using maxent tagger.
</prevsent>
</prevsection>
<citsent citstr=" W03-0420 ">
our baseline system is modeled following maximum entropy approach (bender et al, 2003, <papid> W03-0420 </papid>inter alia).</citsent>
<aftsection>
<nextsent>the maxent model produces probability for each class label (the ne tag) of classification instance, conditioned on its context of occurrence h. this probability is calculated by: (t|h) = 1 z(h) exp ? ?
</nextsent>
<nextsent>n? j=1 jfj(h, t) ? ?
</nextsent>
<nextsent>(1) where fj(h, t) is the j-th feature with associated weight and z(h) is normalization constant to ensure proper probability distribution.3 given word wi to be classified as beginning, inside or outside (iob) of ne, we extract as features: 1.
</nextsent>
<nextsent>context words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1427">
<title id=" W10-2415.xml">assessing the challenge of fine grained named entity recognition and classification </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the chosen features are: 1, 2 (with = 3), 4, 5, 6, 7 and 8.
</prevsent>
<prevsent>evaluation on the test set is performed blindly, using this feature set.
</prevsent>
</prevsection>
<citsent citstr=" W03-0425 ">
the results are presented in table 2.themaxent labeler achieves performance comparable with the conll-2003 task participants, ranking 12th among the 16 systems participating in the task, with 2 point margin off the f1 of the most similar system of bender et al (2003) <papid> W03-0420 </papid>and7 points below the best-performing system (flo rian et al, 2003).<papid> W03-0425 </papid></citsent>
<aftsection>
<nextsent>the former used relatively complex set of features and different gazetteersextracted from unannotated data.
</nextsent>
<nextsent>the latter combined four diverse classifiers, namely robust linear classifier, maximum entropy, transformation based learning and hidden markov model.
</nextsent>
<nextsent>they used different feature sets, unannotated data and an additional ne tagger.
</nextsent>
<nextsent>in comparison, our nerc system is simpler and based on small set of features that can be easily obtained for many languages.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1429">
<title id=" W10-1708.xml">further experiments with shallow hybrid mt systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in recent years the quality of machine translation (mt) output has improved greatly, although each paradigm suffers from its own particular kind oferrors: statistical machine translation (smt) of ten shows poor syntax, while rule-based engines (rbmt) experience lack in vocabulary.
</prevsent>
<prevsent>hybrid systems try to avoid these typical errors by combining techniques from both paradigms in most useful manner.
</prevsent>
</prevsection>
<citsent citstr=" W09-0411 ">
in this paper we present the improved version of the hybrid system we developed last years shared task (federmann et al, 2009).<papid> W09-0411 </papid></citsent>
<aftsection>
<nextsent>we take the out put from an rbmt engine as basis for our hybrid translations and substitute noun phrases by translations from an smt engine.
</nextsent>
<nextsent>even though general increase in quality could be observed, our system introduced errors of its own during the substitution process.
</nextsent>
<nextsent>in an internal error analysis, these degradations were classified as follows: - the translation by the smt engine is incorrect - the structure degrades through substitution (because of e.g. capitalization errors, double prepositions, etc.) - the phrase substitution goes astray (caused by alignment problems, etc.) errors of the first class cannot be corrected, as we have no way of knowing when the translation by the smt engine is incorrect.
</nextsent>
<nextsent>the other two classes could be eliminated, however, by introducing additional steps for pre- and post-processing as well as improving the hybrid algorithm itself.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1430">
<title id=" W10-1708.xml">further experiments with shallow hybrid mt systems </title>
<section> architecture.  </section>
<citcontext>
<prevsection>
<prevsent>additionally, we extended our coverage to also include the language pairs english french and english spanish in both directions as well as english german, compared to last years initial experiments for german english only.
</prevsent>
<prevsent>we were able to achieve an increase in translation quality for this language set, which shows that the substitution method works for different language configurations.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
our hybrid translation system takes translation output from a) the lucy rbmt system (alonso and thurmair, 2003) and b) moses-based smt system (koehn et al, 2007).<papid> P07-2045 </papid></citsent>
<aftsection>
<nextsent>we then identify noun phrases inside the rule-based translation and compute the most likely correspondences in the statistical translation output.
</nextsent>
<nextsent>for these, we apply factored substitution method that decides whether the original rbmt phrase should be kept or rather be replaced by the moses phrase.
</nextsent>
<nextsent>as this shallow substitution process may introduce problems at 77 phrase boundaries, we afterwards perform several post-processing steps to cleanup and finalize the hybrid translation result.
</nextsent>
<nextsent>a schematic overview of our hybrid system and its main components is given in figure 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1432">
<title id=" W10-3219.xml">development of the korean resource grammar towards grammar customization </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, this version, focusing on linguistic data with theory-oriented approaches, is unable to yield efficient parsing or generation.
</prevsent>
<prevsent>the additional limit of the krg1 is its un attested parsing efficiency with large scale of naturally occur ring data, which is prerequisite to the practical uses of the developed grammar in the area of mt. such weak points have motivated us to movethe development of krg to data-driven approach from theory-based one upon which the krg1 is couched.
</prevsent>
</prevsection>
<citsent citstr=" W02-1502 ">
in particular, this second phase of the krg (henceforth, krg2) also starts with two methods: shared grammar libraries (the grammar matrix (bender et al, 2002; <papid> W02-1502 </papid>bender et al., 2010)) <papid> P10-4001 </papid>and data-driven expansion (using the korean portions of multilingual texts).</citsent>
<aftsection>
<nextsent>next, we introduce the resources we used(?
</nextsent>
<nextsent>2).
</nextsent>
<nextsent>this is followed by more detailed motivation for our extensions (?
</nextsent>
<nextsent>3).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1434">
<title id=" W10-3219.xml">development of the korean resource grammar towards grammar customization </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, this version, focusing on linguistic data with theory-oriented approaches, is unable to yield efficient parsing or generation.
</prevsent>
<prevsent>the additional limit of the krg1 is its un attested parsing efficiency with large scale of naturally occur ring data, which is prerequisite to the practical uses of the developed grammar in the area of mt. such weak points have motivated us to movethe development of krg to data-driven approach from theory-based one upon which the krg1 is couched.
</prevsent>
</prevsection>
<citsent citstr=" P10-4001 ">
in particular, this second phase of the krg (henceforth, krg2) also starts with two methods: shared grammar libraries (the grammar matrix (bender et al, 2002; <papid> W02-1502 </papid>bender et al., 2010)) <papid> P10-4001 </papid>and data-driven expansion (using the korean portions of multilingual texts).</citsent>
<aftsection>
<nextsent>next, we introduce the resources we used(?
</nextsent>
<nextsent>2).
</nextsent>
<nextsent>this is followed by more detailed motivation for our extensions (?
</nextsent>
<nextsent>3).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1435">
<title id=" W10-3219.xml">development of the korean resource grammar towards grammar customization </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>the deep linguistic processing with hpsg initiative (delph-in: www.delph-in.net) provides an open-source collection of tools and grammars for deep linguistic processing of human language within the hpsg and mrs (min imal recur sion semantics (copestake et al,2005)) framework.
</prevsent>
<prevsent>the resources include software packages, such as the lkb for parsing and generation, pet (callmeier, 2000) for parsing, and profiling tool [incr tsdb()] (oepen, 2001).
</prevsent>
</prevsection>
<citsent citstr=" W02-1210 ">
there are also several grammars: e.g. erg; the 144 english resource grammar (flickinger, 2000), jacy; japanese grammar (siegel and bender, 2002), <papid> W02-1210 </papid>the spanish grammar, and so forth.</citsent>
<aftsection>
<nextsent>these along with some pre-compiled versions of preprocessing or experimental tools are packaged inthe logon distribution.1 most resources are under the mit license, with some parts under other open licenses such as the lgpl.2 the krg hasbeen constructed within this open-source infrastructure, and is released under the mit license3.
</nextsent>
<nextsent>2.2 the grammar matrix.
</nextsent>
<nextsent>the grammar matrix (bender et al, 2002; <papid> W02-1502 </papid>bender et al, 2010) <papid> P10-4001 </papid>offers well-structured environment for the development of precision-basedgrammars.</nextsent>
<nextsent>this framework plays role in building hpsg/mrs-based grammar in short time, and improving it continuously.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1440">
<title id=" W10-3003.xml">detecting speculative language using syntactic dependencies and logistic regression </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the participants are provided with data from two domains: biomedical scientific literature (both abstracts and full articles) and wikipedia.
</prevsent>
<prevsent>we choose to focus on the former.
</prevsent>
</prevsection>
<citsent citstr=" W08-0606 ">
the training datafor this domain are nine full articles and 1,273 abstracts from the bio scope corpus (szarvas et al, 2008) <papid> W08-0606 </papid>and the test data are 15 full articles.</citsent>
<aftsection>
<nextsent>our approach to speculative language detection relies on syntactic parsing and machine learning.
</nextsent>
<nextsent>we give description of the techniques used in sections 2 and 3.
</nextsent>
<nextsent>we treat the detection of sentences containing uncertain information (task1) asa token classification task in which we learn classifier to predict whether token is cue or not.
</nextsent>
<nextsent>in order to handle words that have speculative and non-speculative meaning (e.g. indicating?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1443">
<title id=" W10-3003.xml">detecting speculative language using syntactic dependencies and logistic regression </title>
<section> syntactic parsing for the biomedical.  </section>
<citcontext>
<prevsection>
<prevsent>an interesting aspect of this three-stage parsing approach is that, if the parse selection module fails to construct parse tree for the sentence (a common issue when syntactic parsers are ported to new domains), the lexical categories obtained by the super tagger preserve some of the syntactic information that would not be found in pos tags.
</prevsent>
<prevsent>the adaptation to the biomedical domain by rimell and clark (2009) involved re-training thepos tagger and the ccg super tagger using in domain resources, while the parse selection component was left intact.
</prevsent>
</prevsection>
<citsent citstr=" W09-1401 ">
as recent work in the bionlp 2009 shared task has shown (kim et al,2009), <papid> W09-1401 </papid>domain-adapted parsing benefits information extraction systems.the native output of the c&c; parser is converted into the stanford dependency (sd) collapsed dependency format (de marneffe and manning, 2008).</citsent>
<aftsection>
<nextsent>these dependencies define binary relations between tokens and the labels of these relations are obtained from hierarchy.
</nextsent>
<nextsent>while the conversion is unlikely to be perfect given that the native c&c; output follows different formalism, we made this choice because it allows for the use of different parsers with minimal adaptation.
</nextsent>
<nextsent>finally, an important pre-processing step we take is tokenization of the original text.
</nextsent>
<nextsent>since the pos tagger is trained on the genia corpus which follows the penn treebank tokenization scheme,we use the tokenization script provided by the tree bank.1 1http://www.cis.upenn.edu/treebank/tokenization.html
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1444">
<title id=" W10-3003.xml">detecting speculative language using syntactic dependencies and logistic regression </title>
<section> detecting sentences containing.  </section>
<citcontext>
<prevsection>
<prevsent>the syntactic context of words is useful proxy to their semantics, asshown in recent work on verb sense disambiguation (chen and palmer, 2009).
</prevsent>
<prevsent>furthermore, it is easy to obtain syntactic information automatically using parser, even though there will be some noise due to parsing errors.
</prevsent>
</prevsection>
<citsent citstr=" W08-0607 ">
similar intuitions were exploited by kilicoglu and bergler (2008) <papid> W08-0607 </papid>in refining dictionary of cues with syntactic rules.in what follows, we present the features extracted for each token for our final system, along with an example of their application in table 2.</citsent>
<aftsection>
<nextsent>where appropriate we give the relevant labels inthe stanford dependency (sd) scheme in parentheses for reproducibility: ? we extract the token itself and its lemma as features.?
</nextsent>
<nextsent>to handle cases where word senses are identifiable by the pos of token (might result?
</nextsent>
<nextsent>vs the might?), we combine the latter with the lemma and add it as feature.
</nextsent>
<nextsent>we combine the lemma with the ccg super tag and add it as feature in order to capture cases where the hedging function of word is determined by its syntactic role in the sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1452">
<title id=" W10-3003.xml">detecting speculative language using syntactic dependencies and logistic regression </title>
<section> task1 results and error analysis.  </section>
<citcontext>
<prevsection>
<prevsent>finally, we add the abstracts to the training data which improves recall but harms precision slightly (table 4) when only tokens and lemmas are used as features.
</prevsent>
<prevsent>nevertheless, we decided to keep them as they have positive effect for all other feature representations.
</prevsent>
</prevsection>
<citsent citstr=" P07-1125 ">
a misinterpretation of the bio scope paper (szarvas et al, 2008) <papid> W08-0606 </papid>led us to believe that five ofthe nine full articles in the training data were annotated using the guidelines of medlock and briscoe(2007).<papid> P07-1125 </papid></citsent>
<aftsection>
<nextsent>after the shared task, the organizers clarified to us that all the full articles were annotated using the bio scope guidelines.
</nextsent>
<nextsent>due to our misinterpretation, we change our experimental setup to cross-validate on the four full articles annotated inbioscope only, considering the other five full articles and the abstracts only as training data.
</nextsent>
<nextsent>we keep this setup for the remainder of the paper.
</nextsent>
<nextsent>we repeat the cross-validation experiments with the full feature set and this new experimental setup and report the results in table 5.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1456">
<title id=" W10-3810.xml">improved language modeling for english persian statistical machine translation </title>
<section> corpus development for persian.  </section>
<citcontext>
<prevsection>
<prevsent>shiraz corpus (amtrup, et al, 2000)is bilingual tagged corpus of about 3000 aligned persian/english sentences also collected from the hamshahri newspaper online archive and manually translated at new mexico state university.
</prevsent>
<prevsent>another corpus, tep (tehran english persian corpus), available at: http://ece.ut.ac.ir/nlp/ resources.htm , consists of 21,000 subtitle files obtained from www.opensubtitles.org.
</prevsent>
</prevsection>
<citsent citstr=" L08-1218 ">
subtitle pairs of multiple versions of same movie were extracted, total of about 1,200(itamar &amp; itai, 2008) <papid> L08-1218 </papid>then aligned the files using their proposed dynamic programming method.</citsent>
<aftsection>
<nextsent>this method operates by using the timing information contained in subtitle files so as to align the text accurately.
</nextsent>
<nextsent>the end product yielded parallel corpus of approximately 150,000 sentences which has 4,100,000 tokens in persian and 4,400,000 tokens in english.
</nextsent>
<nextsent>finally, european language resources association (elra), available at: http://catalog.elra.info/product_info.phpproduc ts_id=1111, have constructed corpus which consists of about 3,500,000 english and persian words aligned at sentence level, to give approximately 100,000 sentences distributed over 50,021 entries.
</nextsent>
<nextsent>the corpus was originally constructed with sql server, but presented in access type file.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1457">
<title id=" W10-3810.xml">improved language modeling for english persian statistical machine translation </title>
<section> statistical machine translation.  </section>
<citcontext>
<prevsection>
<prevsent>this corpus consists of several different domains, including art, culture, idioms, law, literature, medicine, poetry, politics, proverbs, religion, and science; it is available for sale online.
</prevsent>
<prevsent>3.1 general statistical machine translation (smt) can be defined as the process of maximizing the probability of sentence in the source language matching sentence in the target language.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
in other words, given sentence in the source language, we seek the sentence in the target language such that it maximizes p(t | s) which is called the conditional probability or the chance of happening given   (koehn, et al, 2007).<papid> P07-2045 </papid></citsent>
<aftsection>
<nextsent>it is also referred to as the most likely translation.
</nextsent>
<nextsent>this can be more formally written as shown in equation (1).
</nextsent>
<nextsent>arg max p(t | s) (1) using bayes rule from equation (2), we can write equation (1) for the most likely translation as shown in equation (3).
</nextsent>
<nextsent>p (t | s) = (t) * p(s | t) =p (s) (2) arg max p(t | s) = arg max p(t) * p(s | t) (3) where (t) is the target sentence, and (s) is the source sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1459">
<title id=" W10-3810.xml">improved language modeling for english persian statistical machine translation </title>
<section> statistical machine translation.  </section>
<citcontext>
<prevsection>
<prevsent>the argmax operation is the search, which is done by so-called decoder which is part of statistical machine translation system.
</prevsent>
<prevsent>3.2 statistical machine translation tools there are number of implementations of subtasks and algorithms in smt and even software tools that can be used to set up fully featured state-of-the-art smt system.
</prevsent>
</prevsection>
<citsent citstr=" J04-4002 ">
78 moses (koehn, et al, 2007) <papid> P07-2045 </papid>is an open-source statistical machine translation system which allows one to train translation models using giza++ (och &amp; ney, 2004).<papid> J04-4002 </papid>for any given language pair for which parallel corpus exists.</citsent>
<aftsection>
<nextsent>this tool was used to build the baseline system discussed in this paper.
</nextsent>
<nextsent>moses uses beam search algorithm where the translated output sentence is generated left to right in form of hypotheses.
</nextsent>
<nextsent>beam-search is an efficient search algorithm which quickly finds the highest probability translation among the exponential number of choices.
</nextsent>
<nextsent>the search begins with an initial state where no foreign input words are translated and no english output words have been generated.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1460">
<title id=" W10-3810.xml">improved language modeling for english persian statistical machine translation </title>
<section> experiments and results.  </section>
<citcontext>
<prevsection>
<prevsent>this data shows that an increased corpus size.
</prevsent>
<prevsent>will yield an improved translation quality, but only as long as the size of the language model is proportional to the corpus size.
</prevsent>
</prevsection>
<citsent citstr=" E09-1063 ">
literature refers to the fact that the size of the corpus, although important, does not have as great an effect as corpus and language model in the domain of translation (ma &amp; way, 2009).<papid> E09-1063 </papid></citsent>
<aftsection>
<nextsent>in the persian language, some problems and difficulties arise due to natural language ambiguities, anaphora resolution, idioms and differences in the types and symbols used for punctuation.
</nextsent>
<nextsent>these issues had to be resolved before any attempt at smt could be made.
</nextsent>
<nextsent>needless to stress on the fact that the better the alignment the better the results of the translation.
</nextsent>
<nextsent>(a) (b) (c) figure 3.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1461">
<title id=" W10-2906.xml">learning better monolingual models with unannotated bilingual text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for syntactic parsing, our bilingual predictor increases f1 by 2.1% absolute, and retraining monolingual model on its output gives an improvement of 2.0%.
</prevsent>
<prevsent>natural language analysis in one language can be improved by exploiting translations in another language.
</prevsent>
</prevsection>
<citsent citstr=" H01-1035 ">
this observation has formed the basis for important work on syntax projection across languages (yarowsky et al, 2001; <papid> H01-1035 </papid>hwa et al, 2005; ganchev et al, 2009) <papid> P09-1042 </papid>and unsupervised syntax induction in multiple languages (snyder et al, 2009), <papid> P09-1009 </papid>as well as other tasks, such as cross-lingual named entity recognition (huang and vogel, 2002; moore, 2003) <papid> E03-1035 </papid>and information retrieval (si and callan, 2005).</citsent>
<aftsection>
<nextsent>in all of these cases, multilingual models yield increased accuracy because different languages present different ambiguities and therefore offer complementary constraints on the shared underlying labels.
</nextsent>
<nextsent>in the present work, we consider setting wherewe already possess supervised monolingual models, and wish to improve these models using unannotated bilingual parallel text (bitext).
</nextsent>
<nextsent>we cast this problem in the multiple-view (multiview) learning framework (blum and mitchell, 1998; collins and singer, 1999; <papid> W99-0613 </papid>balcan and blum, 2005; ganchev et al., 2008).</nextsent>
<nextsent>our two views are monolingual view, which uses the supervised monolingual models but not bilingual information, and bilingual view, which exploits features that measure agreement across languages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1463">
<title id=" W10-2906.xml">learning better monolingual models with unannotated bilingual text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for syntactic parsing, our bilingual predictor increases f1 by 2.1% absolute, and retraining monolingual model on its output gives an improvement of 2.0%.
</prevsent>
<prevsent>natural language analysis in one language can be improved by exploiting translations in another language.
</prevsent>
</prevsection>
<citsent citstr=" P09-1042 ">
this observation has formed the basis for important work on syntax projection across languages (yarowsky et al, 2001; <papid> H01-1035 </papid>hwa et al, 2005; ganchev et al, 2009) <papid> P09-1042 </papid>and unsupervised syntax induction in multiple languages (snyder et al, 2009), <papid> P09-1009 </papid>as well as other tasks, such as cross-lingual named entity recognition (huang and vogel, 2002; moore, 2003) <papid> E03-1035 </papid>and information retrieval (si and callan, 2005).</citsent>
<aftsection>
<nextsent>in all of these cases, multilingual models yield increased accuracy because different languages present different ambiguities and therefore offer complementary constraints on the shared underlying labels.
</nextsent>
<nextsent>in the present work, we consider setting wherewe already possess supervised monolingual models, and wish to improve these models using unannotated bilingual parallel text (bitext).
</nextsent>
<nextsent>we cast this problem in the multiple-view (multiview) learning framework (blum and mitchell, 1998; collins and singer, 1999; <papid> W99-0613 </papid>balcan and blum, 2005; ganchev et al., 2008).</nextsent>
<nextsent>our two views are monolingual view, which uses the supervised monolingual models but not bilingual information, and bilingual view, which exploits features that measure agreement across languages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1464">
<title id=" W10-2906.xml">learning better monolingual models with unannotated bilingual text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for syntactic parsing, our bilingual predictor increases f1 by 2.1% absolute, and retraining monolingual model on its output gives an improvement of 2.0%.
</prevsent>
<prevsent>natural language analysis in one language can be improved by exploiting translations in another language.
</prevsent>
</prevsection>
<citsent citstr=" P09-1009 ">
this observation has formed the basis for important work on syntax projection across languages (yarowsky et al, 2001; <papid> H01-1035 </papid>hwa et al, 2005; ganchev et al, 2009) <papid> P09-1042 </papid>and unsupervised syntax induction in multiple languages (snyder et al, 2009), <papid> P09-1009 </papid>as well as other tasks, such as cross-lingual named entity recognition (huang and vogel, 2002; moore, 2003) <papid> E03-1035 </papid>and information retrieval (si and callan, 2005).</citsent>
<aftsection>
<nextsent>in all of these cases, multilingual models yield increased accuracy because different languages present different ambiguities and therefore offer complementary constraints on the shared underlying labels.
</nextsent>
<nextsent>in the present work, we consider setting wherewe already possess supervised monolingual models, and wish to improve these models using unannotated bilingual parallel text (bitext).
</nextsent>
<nextsent>we cast this problem in the multiple-view (multiview) learning framework (blum and mitchell, 1998; collins and singer, 1999; <papid> W99-0613 </papid>balcan and blum, 2005; ganchev et al., 2008).</nextsent>
<nextsent>our two views are monolingual view, which uses the supervised monolingual models but not bilingual information, and bilingual view, which exploits features that measure agreement across languages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1465">
<title id=" W10-2906.xml">learning better monolingual models with unannotated bilingual text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for syntactic parsing, our bilingual predictor increases f1 by 2.1% absolute, and retraining monolingual model on its output gives an improvement of 2.0%.
</prevsent>
<prevsent>natural language analysis in one language can be improved by exploiting translations in another language.
</prevsent>
</prevsection>
<citsent citstr=" E03-1035 ">
this observation has formed the basis for important work on syntax projection across languages (yarowsky et al, 2001; <papid> H01-1035 </papid>hwa et al, 2005; ganchev et al, 2009) <papid> P09-1042 </papid>and unsupervised syntax induction in multiple languages (snyder et al, 2009), <papid> P09-1009 </papid>as well as other tasks, such as cross-lingual named entity recognition (huang and vogel, 2002; moore, 2003) <papid> E03-1035 </papid>and information retrieval (si and callan, 2005).</citsent>
<aftsection>
<nextsent>in all of these cases, multilingual models yield increased accuracy because different languages present different ambiguities and therefore offer complementary constraints on the shared underlying labels.
</nextsent>
<nextsent>in the present work, we consider setting wherewe already possess supervised monolingual models, and wish to improve these models using unannotated bilingual parallel text (bitext).
</nextsent>
<nextsent>we cast this problem in the multiple-view (multiview) learning framework (blum and mitchell, 1998; collins and singer, 1999; <papid> W99-0613 </papid>balcan and blum, 2005; ganchev et al., 2008).</nextsent>
<nextsent>our two views are monolingual view, which uses the supervised monolingual models but not bilingual information, and bilingual view, which exploits features that measure agreement across languages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1466">
<title id=" W10-2906.xml">learning better monolingual models with unannotated bilingual text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in all of these cases, multilingual models yield increased accuracy because different languages present different ambiguities and therefore offer complementary constraints on the shared underlying labels.
</prevsent>
<prevsent>in the present work, we consider setting wherewe already possess supervised monolingual models, and wish to improve these models using unannotated bilingual parallel text (bitext).
</prevsent>
</prevsection>
<citsent citstr=" W99-0613 ">
we cast this problem in the multiple-view (multiview) learning framework (blum and mitchell, 1998; collins and singer, 1999; <papid> W99-0613 </papid>balcan and blum, 2005; ganchev et al., 2008).</citsent>
<aftsection>
<nextsent>our two views are monolingual view, which uses the supervised monolingual models but not bilingual information, and bilingual view, which exploits features that measure agreement across languages.
</nextsent>
<nextsent>the parameters of the bilingual view are trained to reproduce the output ofthe monolingual view.
</nextsent>
<nextsent>we show that by introducing weakened monolingual models into the bilingual view, we can optimize the parameters of the bilingual model to improve monolingual models.
</nextsent>
<nextsent>at prediction time, we automatically account for the between-view dependence introduced by the weakened monolingual models with simple but effective view-combination heuristic.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1471">
<title id=" W10-2906.xml">learning better monolingual models with unannotated bilingual text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for this problem, our method automatically learns (a variation on) earlier hand-designed rule-based bilingual ner predictors (huang and vogel, 2002; moore, 2003), <papid> E03-1035 </papid>resulting in absolute performance gains of up to16.1% f1.</prevsent>
<prevsent>the second task we consider is statistical parsing.</prevsent>
</prevsection>
<citsent citstr=" D08-1092 ">
for this task, we follow the setupof burkett and klein (2008), <papid> D08-1092 </papid>who improved chinese and english monolingual parsers using parallel, hand-parsed text.</citsent>
<aftsection>
<nextsent>we achieve nearly identical improvements using purely unlabeled bitext.
</nextsent>
<nextsent>these results carry over to machine translation, where we can achieve slightly better bleu improvements than the supervised model of burkett and klein (2008) <papid> D08-1092 </papid>since we are able to train our model directly on the parallel data where we perform rule extraction.finally, for both of our tasks, we use our bilingual model to generate additional automatically labeled monolingual training data.</nextsent>
<nextsent>we compare 46 this approach to monolingual self-training and show an improvement of up to 14.4% f1 for entity recognition.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1477">
<title id=" W10-2906.xml">learning better monolingual models with unannotated bilingual text </title>
<section> prior work on learning from.  </section>
<citcontext>
<prevsection>
<prevsent>two recent, successful unsupervised induction methods are those of blunsom et al(2009) and snyder et al (2009).<papid> P09-1009 </papid></prevsent>
<prevsent>both of themes timate hierarchical bayesian models and employ bilingual data to constrain the types of models that can be derived.</prevsent>
</prevsection>
<citsent citstr=" N01-1026 ">
projection methods, on the other hand, were among the first applications of parallel text (after machine translation) (yarowsky et al, 2001; <papid> H01-1035 </papid>yarowsky and ngai, 2001; <papid> N01-1026 </papid>hwa et al, 2005; ganchev et al, 2009).<papid> P09-1042 </papid></citsent>
<aftsection>
<nextsent>they assume the existence of good, monolingual model for one language but little or no information about the second language.
</nextsent>
<nextsent>given parallel sentence pair, they use the annotations for one language to heavily constrain the set of possible annotations for the other.
</nextsent>
<nextsent>our work falls into the final category: we wishto use bilingual data to improve monolingual models which are already trained on large amounts ofdata and effective on their own (huang and vogel, 2002; smith and smith, 2004; <papid> W04-3207 </papid>snyder and barzilay, 2008; burkett and klein, 2008).<papid> D08-1092 </papid></nextsent>
<nextsent>procedurally, our work is most closely related to thatof burkett and klein (2008).<papid> D08-1092 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1479">
<title id=" W10-2906.xml">learning better monolingual models with unannotated bilingual text </title>
<section> prior work on learning from.  </section>
<citcontext>
<prevsection>
<prevsent>they assume the existence of good, monolingual model for one language but little or no information about the second language.
</prevsent>
<prevsent>given parallel sentence pair, they use the annotations for one language to heavily constrain the set of possible annotations for the other.
</prevsent>
</prevsection>
<citsent citstr=" W04-3207 ">
our work falls into the final category: we wishto use bilingual data to improve monolingual models which are already trained on large amounts ofdata and effective on their own (huang and vogel, 2002; smith and smith, 2004; <papid> W04-3207 </papid>snyder and barzilay, 2008; burkett and klein, 2008).<papid> D08-1092 </papid></citsent>
<aftsection>
<nextsent>procedurally, our work is most closely related to thatof burkett and klein (2008).<papid> D08-1092 </papid></nextsent>
<nextsent>they used an annotated bitext to learn parse reranking models for english and chinese, exploiting features that examine pieces of parse trees in both languages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1491">
<title id=" W10-2906.xml">learning better monolingual models with unannotated bilingual text </title>
<section> a multi view bilingual model </section>
<citcontext>
<prevsection>
<prevsent>our model is conditional exponential family distribution over matchings and labels: p?(y, a|x) = exp [ ? ?(y1, a, y2)a(?;x) ] , where ? is parameter vector, and a(?;x) is the log partition function for sentence pair x. we must approximate a(?;x) because summing over all at most one-to-one matchings is #p-hard.
</prevsent>
<prevsent>we approximate this sum using the maximum-scoring matching (burkett and klein, 2008): <papid> D08-1092 </papid>a?(?;x) = log ? max ( exp [ ? ?(y1, a, y2) ]) . in order to compute the distribution on labels y, we must marginalize over hidden alignments between nodes, which we also approximate by using the maximum-scoring matching: q?(y|x) def = max exp [ ? ?(y1, a, y2)a?(?;x) ] . 47 the reports of european court org1 of auditors die berichte des europischen rechnungshofes org1 the figure 1: an example where english ner can be used to disambiguate german ner.</prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
we further simplify inference in our model by working in reranking setting (collins, 2000;charniak and johnson, 2005), <papid> P05-1022 </papid>where we only consider the top outputs from monolingual models in both languages, for total of k2 labels y. in practice, k2 ? 10, 000 for our largest problem.</citsent>
<aftsection>
<nextsent>3.1 including weakened models.
</nextsent>
<nextsent>now that we have defined our bilingual model, wecould train it to agree with the output of the monolingual model (collins and singer, 1999; <papid> W99-0613 </papid>ganchev et al, 2008).</nextsent>
<nextsent>as we will see in section 4, however,the feature functions ?(y1, a, y2) make no reference to the input sentences x, other than through afixed word alignment.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1498">
<title id=" W10-2906.xml">learning better monolingual models with unannotated bilingual text </title>
<section> ner and parsing examples.  </section>
<citcontext>
<prevsection>
<prevsent>the english monolingual parse mistakenly attaches to to theverb increased.
</prevsent>
<prevsent>in chinese, however, this ambiguity does not exist.
</prevsent>
</prevsection>
<citsent citstr=" P06-1055 ">
instead, the word ?, which aligns to to, has strong selectional preference for attaching to noun on the left.in our parsing experiments, we use the berkeley parser (petrov et al, 2006; <papid> P06-1055 </papid>petrov and klein, 2007), <papid> N07-1051 </papid>split-merge latent variable parser, for our monolingual models.</citsent>
<aftsection>
<nextsent>our full model is there sult of training the parser with five split-merge phases.
</nextsent>
<nextsent>our weakened model uses only two.
</nextsent>
<nextsent>forthe bilingual model, we use the same bilingual feature set as burkett and klein (2008).<papid> D08-1092 </papid></nextsent>
<nextsent>table 2 gives some examples, but does not exhaustively enumerate those features.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1499">
<title id=" W10-2906.xml">learning better monolingual models with unannotated bilingual text </title>
<section> ner and parsing examples.  </section>
<citcontext>
<prevsection>
<prevsent>the english monolingual parse mistakenly attaches to to theverb increased.
</prevsent>
<prevsent>in chinese, however, this ambiguity does not exist.
</prevsent>
</prevsection>
<citsent citstr=" N07-1051 ">
instead, the word ?, which aligns to to, has strong selectional preference for attaching to noun on the left.in our parsing experiments, we use the berkeley parser (petrov et al, 2006; <papid> P06-1055 </papid>petrov and klein, 2007), <papid> N07-1051 </papid>split-merge latent variable parser, for our monolingual models.</citsent>
<aftsection>
<nextsent>our full model is there sult of training the parser with five split-merge phases.
</nextsent>
<nextsent>our weakened model uses only two.
</nextsent>
<nextsent>forthe bilingual model, we use the same bilingual feature set as burkett and klein (2008).<papid> D08-1092 </papid></nextsent>
<nextsent>table 2 gives some examples, but does not exhaustively enumerate those features.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1514">
<title id=" W10-2906.xml">learning better monolingual models with unannotated bilingual text </title>
<section> ner experiments.  </section>
<citcontext>
<prevsection>
<prevsent>for testing, we used the europarl 2006 development set and the 2007 newswire test set.
</prevsent>
<prevsent>neither of these datasets were annotated with named entities, so we manually annotated 200 sentences from each of them.
</prevsent>
</prevsection>
<citsent citstr=" P05-1045 ">
we used the stanford ner tagger (finkel et al., 2005) <papid> P05-1045 </papid>with its default configuration as our full monolingual model for each language.</citsent>
<aftsection>
<nextsent>we weakened both the english and german models by removing several non-lexical and word-shape features.
</nextsent>
<nextsent>we made one more crucial change to our monolingual german model.
</nextsent>
<nextsent>the german entity recognizer has extremely low recall (44 %) when out of domain, so we chose yx from figure 3 to be the label in the top five which had the largest number of named entities.table 3 gives results for named entity recognition.
</nextsent>
<nextsent>the first two rows are the full and weakened monolingual models alone.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1515">
<title id=" W10-2906.xml">learning better monolingual models with unannotated bilingual text </title>
<section> parsing experiments.  </section>
<citcontext>
<prevsection>
<prevsent>baseline.
</prevsent>
<prevsent>our next set of experiments are on syntactic parsing of english and chinese.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
we trained both our full and weakened monolingual english models on the penn wall street journal corpus (marcus et al, 1993), <papid> J93-2004 </papid>as described in section 4.</citsent>
<aftsection>
<nextsent>our full and weakened chinese models were trained on 51 eng parliament eng newswire ger parliament ger newswire prec rec f1 prec rec f1 prec rec f1 prec rec f1 monolingual models (baseline) weak monolingual 52.6 65.9 58.5 67.7 83.0 74.6 71.3 36.4 48.2 80.0 51.5 62.7 full monolingual 65.7 71.4 68.4 80.1 88.7 84.2 69.8 44.0 54.0 73.0 56.4 63.7 multi view trained bilingual models bilingual w/ weak 56.2 70.8 62.7 71.4 86.2 78.1 70.1 66.3 68.2 76.5 76.1 76.3 bilingual w/ full 65.4 72.4 68.7 80.6 88.7 84.4 70.1 70.1 70.1 74.6 77.3 75.9 retrained monolingual models self-retrained 71.7 74.0 72.9 79.9 87.4 83.5 70.4 44.0 54.2 79.3 58.9 67.6 bilingual-retrained 68.6 70.8 69.7 80.7 89.3 84.8 74.5 63.6 68.6 77.9 69.3 73.4 table 3: ner results.
</nextsent>
<nextsent>rows are grouped by data condition.
</nextsent>
<nextsent>we bold all entries that are best in their group and beat the strongest monolingual baseline.
</nextsent>
<nextsent>chinese english monolingual models (baseline) weak monolingual 78.3 67.6 full monolingual 84.2 75.4 multi view trained bilingual models bilingual w/ weak 80.4 70.8 bilingual w/ full 85.9 77.5 supervised trained bilingual models burkett and klein (2008) <papid> D08-1092 </papid>86.1 78.2 retrained monolingual models self-retrained 83.6 76.7 bilingual-retrained 83.9 77.4 table 4: parsing results.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1517">
<title id=" W10-2906.xml">learning better monolingual models with unannotated bilingual text </title>
<section> parsing experiments.  </section>
<citcontext>
<prevsection>
<prevsent>chinese english monolingual models (baseline) weak monolingual 78.3 67.6 full monolingual 84.2 75.4 multi view trained bilingual models bilingual w/ weak 80.4 70.8 bilingual w/ full 85.9 77.5 supervised trained bilingual models burkett and klein (2008) <papid> D08-1092 </papid>86.1 78.2 retrained monolingual models self-retrained 83.6 76.7 bilingual-retrained 83.9 77.4 table 4: parsing results.</prevsent>
<prevsent>rows are grouped by data condition.</prevsent>
</prevsection>
<citsent citstr=" C02-1145 ">
we bold entries that are best in their group and beat the the full monolingual baseline.the penn chinese treebank (xue et al, 2002) (<papid> C02-1145 </papid>articles 400-1151), excluding the bilingual portion.</citsent>
<aftsection>
<nextsent>the bilingual data consists of the parallel part of the chinese treebank (articles 1-270), which also includes manually parsed english translations of each chinese sentence (bies et al, 2007).
</nextsent>
<nextsent>onlythe chinese sentences and their english translations were used to train the bilingual models ? the gold trees were ignored.
</nextsent>
<nextsent>for retraining, we used the same data, but weighted it to match the sizes of the original monolingual treebanks.
</nextsent>
<nextsent>we tested on the standard chinese treebank development set, which also includes english translations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1521">
<title id=" W10-2906.xml">learning better monolingual models with unannotated bilingual text </title>
<section> parsing experiments.  </section>
<citcontext>
<prevsection>
<prevsent>9.1 machine translation experiments.
</prevsent>
<prevsent>although we dont have hand-labeled data for our largest chinese-english parallel corpora, we can still evaluate our parsing results via our performance on downstream machine translation (mt) task.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
our experimental setup is as follows: first,we used the first 100,000 sentences of the english chinese bitext from wang et al (2007) to train moses (koehn et al, 2007), <papid> P07-2045 </papid>phrase-based mt system that we use as baseline.</citsent>
<aftsection>
<nextsent>we then used the same sentences to extract tree-to-string transducer rules from target-side (english) trees (galley et al, 2004).
</nextsent>
<nextsent>we compare the single-reference bleu scores of syntactic mt systems that result from using different parsers to generate these trees.
</nextsent>
<nextsent>52 0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 0.0 0.4 0.8 1.2 1.6 2.0 2.4 2.8 68-71 65-68 62-65 59-62 56-59 english weight german weigh german f1 70.3 70.1 59.1 * + * + (a) 0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 81.8-82.1 81.5-81.8 81.2-81.5 80.9-81.2 80.6-80.9 english weight chines weight combined f1 82.1 82.0 81.4 * + ? * + ?
</nextsent>
<nextsent>(b) figure 6: (a) ner and (b) parsing results for different values of 1 and 2 (see equation 6).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1522">
<title id=" W10-3309.xml">onto lexical resources for feature based opinion mining a case study </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>at different levels of granular ity.
</prevsent>
<prevsent>these expressions are assigned positive or negative scalar value, representing positive, negative or neutral sentiment towards some topic.
</prevsent>
</prevsection>
<citsent citstr=" W07-1515 ">
roughly, research in this field can be grouped in four main categories (which are not exclusive): ? development of linguistic and cognitive models of opinion/sentiment where already existing psycho linguistic theories of emotions are used to analyse how opinions are lexically expressed in texts (wiebe et al 2005; read et al 2007; <papid> W07-1515 </papid>asher et al 2009) ? elaboration of linguistic resources where corpus based and dictionary based approaches are used to automatically or semi automatically extract opinion bearing terms/expressions as well as their sentiment orientation (strapparava et al, 2004; turney and littman, 2002) ? opinion extraction/analysis at the document (pang et al, 2002; <papid> W02-1011 </papid>turney, 2002), <papid> P02-1053 </papid>at the sentence or at the clause level (kim et al., 2006; choi et al, 2005) where local 77 opinions are aggregated in order to compute the overall orientation of docu ment/sentence/clause.</citsent>
<aftsection>
<nextsent>feature based opinion mining (hu and liu, 2004; popescu and etzioni, 2005; <papid> H05-1043 </papid>carenini et al, 2005; cheng and xu, 2008) <papid> L08-1618 </papid>where opinions expressed towards the features of an object or product are exacted and summarized.</nextsent>
<nextsent>the work described in this paper feats into the last category.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1523">
<title id=" W10-3309.xml">onto lexical resources for feature based opinion mining a case study </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>at different levels of granular ity.
</prevsent>
<prevsent>these expressions are assigned positive or negative scalar value, representing positive, negative or neutral sentiment towards some topic.
</prevsent>
</prevsection>
<citsent citstr=" W02-1011 ">
roughly, research in this field can be grouped in four main categories (which are not exclusive): ? development of linguistic and cognitive models of opinion/sentiment where already existing psycho linguistic theories of emotions are used to analyse how opinions are lexically expressed in texts (wiebe et al 2005; read et al 2007; <papid> W07-1515 </papid>asher et al 2009) ? elaboration of linguistic resources where corpus based and dictionary based approaches are used to automatically or semi automatically extract opinion bearing terms/expressions as well as their sentiment orientation (strapparava et al, 2004; turney and littman, 2002) ? opinion extraction/analysis at the document (pang et al, 2002; <papid> W02-1011 </papid>turney, 2002), <papid> P02-1053 </papid>at the sentence or at the clause level (kim et al., 2006; choi et al, 2005) where local 77 opinions are aggregated in order to compute the overall orientation of docu ment/sentence/clause.</citsent>
<aftsection>
<nextsent>feature based opinion mining (hu and liu, 2004; popescu and etzioni, 2005; <papid> H05-1043 </papid>carenini et al, 2005; cheng and xu, 2008) <papid> L08-1618 </papid>where opinions expressed towards the features of an object or product are exacted and summarized.</nextsent>
<nextsent>the work described in this paper feats into the last category.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1524">
<title id=" W10-3309.xml">onto lexical resources for feature based opinion mining a case study </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>at different levels of granular ity.
</prevsent>
<prevsent>these expressions are assigned positive or negative scalar value, representing positive, negative or neutral sentiment towards some topic.
</prevsent>
</prevsection>
<citsent citstr=" P02-1053 ">
roughly, research in this field can be grouped in four main categories (which are not exclusive): ? development of linguistic and cognitive models of opinion/sentiment where already existing psycho linguistic theories of emotions are used to analyse how opinions are lexically expressed in texts (wiebe et al 2005; read et al 2007; <papid> W07-1515 </papid>asher et al 2009) ? elaboration of linguistic resources where corpus based and dictionary based approaches are used to automatically or semi automatically extract opinion bearing terms/expressions as well as their sentiment orientation (strapparava et al, 2004; turney and littman, 2002) ? opinion extraction/analysis at the document (pang et al, 2002; <papid> W02-1011 </papid>turney, 2002), <papid> P02-1053 </papid>at the sentence or at the clause level (kim et al., 2006; choi et al, 2005) where local 77 opinions are aggregated in order to compute the overall orientation of docu ment/sentence/clause.</citsent>
<aftsection>
<nextsent>feature based opinion mining (hu and liu, 2004; popescu and etzioni, 2005; <papid> H05-1043 </papid>carenini et al, 2005; cheng and xu, 2008) <papid> L08-1618 </papid>where opinions expressed towards the features of an object or product are exacted and summarized.</nextsent>
<nextsent>the work described in this paper feats into the last category.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1525">
<title id=" W10-3309.xml">onto lexical resources for feature based opinion mining a case study </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these expressions are assigned positive or negative scalar value, representing positive, negative or neutral sentiment towards some topic.
</prevsent>
<prevsent>roughly, research in this field can be grouped in four main categories (which are not exclusive): ? development of linguistic and cognitive models of opinion/sentiment where already existing psycho linguistic theories of emotions are used to analyse how opinions are lexically expressed in texts (wiebe et al 2005; read et al 2007; <papid> W07-1515 </papid>asher et al 2009) ? elaboration of linguistic resources where corpus based and dictionary based approaches are used to automatically or semi automatically extract opinion bearing terms/expressions as well as their sentiment orientation (strapparava et al, 2004; turney and littman, 2002) ? opinion extraction/analysis at the document (pang et al, 2002; <papid> W02-1011 </papid>turney, 2002), <papid> P02-1053 </papid>at the sentence or at the clause level (kim et al., 2006; choi et al, 2005) where local 77 opinions are aggregated in order to compute the overall orientation of docu ment/sentence/clause.</prevsent>
</prevsection>
<citsent citstr=" H05-1043 ">
feature based opinion mining (hu and liu, 2004; popescu and etzioni, 2005; <papid> H05-1043 </papid>carenini et al, 2005; cheng and xu, 2008) <papid> L08-1618 </papid>where opinions expressed towards the features of an object or product are exacted and summarized.</citsent>
<aftsection>
<nextsent>the work described in this paper feats into the last category.
</nextsent>
<nextsent>the aim is not to compute the general orientation of document or sentence, since positive sentiment towards an object does not imply positive sentiment towards all the aspects of this object, as in: like this restaurant even if the service is slow.
</nextsent>
<nextsent>in feature based opinion mining, holder (the person who posts the review) expresses positive/negative or neutral opinions towards main topic (the object or the product on which the holder expresses his opinions) and its associated features.
</nextsent>
<nextsent>as defined in (hu and liu, 2004), feature can be part-of?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1526">
<title id=" W10-3309.xml">onto lexical resources for feature based opinion mining a case study </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these expressions are assigned positive or negative scalar value, representing positive, negative or neutral sentiment towards some topic.
</prevsent>
<prevsent>roughly, research in this field can be grouped in four main categories (which are not exclusive): ? development of linguistic and cognitive models of opinion/sentiment where already existing psycho linguistic theories of emotions are used to analyse how opinions are lexically expressed in texts (wiebe et al 2005; read et al 2007; <papid> W07-1515 </papid>asher et al 2009) ? elaboration of linguistic resources where corpus based and dictionary based approaches are used to automatically or semi automatically extract opinion bearing terms/expressions as well as their sentiment orientation (strapparava et al, 2004; turney and littman, 2002) ? opinion extraction/analysis at the document (pang et al, 2002; <papid> W02-1011 </papid>turney, 2002), <papid> P02-1053 </papid>at the sentence or at the clause level (kim et al., 2006; choi et al, 2005) where local 77 opinions are aggregated in order to compute the overall orientation of docu ment/sentence/clause.</prevsent>
</prevsection>
<citsent citstr=" L08-1618 ">
feature based opinion mining (hu and liu, 2004; popescu and etzioni, 2005; <papid> H05-1043 </papid>carenini et al, 2005; cheng and xu, 2008) <papid> L08-1618 </papid>where opinions expressed towards the features of an object or product are exacted and summarized.</citsent>
<aftsection>
<nextsent>the work described in this paper feats into the last category.
</nextsent>
<nextsent>the aim is not to compute the general orientation of document or sentence, since positive sentiment towards an object does not imply positive sentiment towards all the aspects of this object, as in: like this restaurant even if the service is slow.
</nextsent>
<nextsent>in feature based opinion mining, holder (the person who posts the review) expresses positive/negative or neutral opinions towards main topic (the object or the product on which the holder expresses his opinions) and its associated features.
</nextsent>
<nextsent>as defined in (hu and liu, 2004), feature can be part-of?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1532">
<title id=" W10-3702.xml">computational lexicography of multiword units how efficient can it be </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>corpus-based machine learning approaches bring interesting complementary robustness-oriented solutions.
</prevsent>
<prevsent>however taken alone, they can hardly cope with the following important phenomenon: while mwus represent high percentage of items in natural language texts, most of them, taken separately, appear very rarely in corpora.
</prevsent>
</prevsection>
<citsent citstr=" W02-2001 ">
for instance, (baldwin and villavicencio, 2002) <papid> W02-2001 </papid>experimented with random sample of two hundred english verb-particle constructions and showed that as many as two thirds of them appear at most three times in the wall street journal corpus.</citsent>
<aftsection>
<nextsent>the variability of mwus is an other challenge to knowledge-poor methods, since basic techniques such as lemmatisation or stemming of all corpus words, result in over general izations (e.g. customs office vs. *custom office) or in overlooking of exceptions (e.g. passersby).moreover, machine learning methods cannot reliably be used alone for less resourced languages.in such cases an efficient annotation of large corpus needed for machine learning usually requires the pre-existence of e-lexicons (savary and piskorski, 2010).despite these drawbacks machine learning allows robustness and rapid development, while 2 knowledge-based methods in general have the reputation of being very labor intensive.
</nextsent>
<nextsent>in this paper we try to show how effective tools of the the latter class can be.
</nextsent>
<nextsent>we present two formalisms and tools designed in view of lexicalized mwu variant description: multi flex and poleng.
</nextsent>
<nextsent>we discuss their expressivity, mainly with respect topolish.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1533">
<title id=" W10-3702.xml">computational lexicography of multiword units how efficient can it be </title>
<section> linguistic properties and lexical.  </section>
<citcontext>
<prevsection>
<prevsent>(6) ranny ptaszek early bird?
</prevsent>
<prevsent>(7) (ten/to/te) public relations due to this complex behavior, as well as to rich semantic content, mwus have been hot topic in international research for quite number of years (rayson et al, 2010) in the context of information retrieval and extraction, named entity recognition, text alignment, machine translation, text categorization, corpus annotation, etc. in this study we are interested in lexical approaches to mwus, i.e. those in which mwus are explicitly described on the entry-per-entry basis, in particular with respect to their morpho-syntax.
</prevsent>
</prevsection>
<citsent citstr=" C92-1025 ">
earlier examples of such approaches include lexc (karttunen et al, 1992), <papid> C92-1025 </papid>fastr (jacquemin,2001), habil (alegria et al, 2004), <papid> W04-0407 </papid>and mul tiflex discussed below.</citsent>
<aftsection>
<nextsent>they mainly concentrate on contiguous nominal and adjectival mwus,sometimes considering limited insertions of external elements.
</nextsent>
<nextsent>more recent approaches, such as (villavicencio et al, 2004), (<papid> W04-0411 </papid>seretan, 2009) and (grgoire, 2010), increasingly address verbal and other noncontiguous multi-word expressions(mwes).</nextsent>
<nextsent>these studies are complemented by recent advances in parsing: robust and reliable syntactic analysis now available can be coupled withmwes identification, and possibly also transla tion.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1534">
<title id=" W10-3702.xml">computational lexicography of multiword units how efficient can it be </title>
<section> linguistic properties and lexical.  </section>
<citcontext>
<prevsection>
<prevsent>(6) ranny ptaszek early bird?
</prevsent>
<prevsent>(7) (ten/to/te) public relations due to this complex behavior, as well as to rich semantic content, mwus have been hot topic in international research for quite number of years (rayson et al, 2010) in the context of information retrieval and extraction, named entity recognition, text alignment, machine translation, text categorization, corpus annotation, etc. in this study we are interested in lexical approaches to mwus, i.e. those in which mwus are explicitly described on the entry-per-entry basis, in particular with respect to their morpho-syntax.
</prevsent>
</prevsection>
<citsent citstr=" W04-0407 ">
earlier examples of such approaches include lexc (karttunen et al, 1992), <papid> C92-1025 </papid>fastr (jacquemin,2001), habil (alegria et al, 2004), <papid> W04-0407 </papid>and mul tiflex discussed below.</citsent>
<aftsection>
<nextsent>they mainly concentrate on contiguous nominal and adjectival mwus,sometimes considering limited insertions of external elements.
</nextsent>
<nextsent>more recent approaches, such as (villavicencio et al, 2004), (<papid> W04-0411 </papid>seretan, 2009) and (grgoire, 2010), increasingly address verbal and other noncontiguous multi-word expressions(mwes).</nextsent>
<nextsent>these studies are complemented by recent advances in parsing: robust and reliable syntactic analysis now available can be coupled withmwes identification, and possibly also transla tion.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1535">
<title id=" W10-3702.xml">computational lexicography of multiword units how efficient can it be </title>
<section> linguistic properties and lexical.  </section>
<citcontext>
<prevsection>
<prevsent>earlier examples of such approaches include lexc (karttunen et al, 1992), <papid> C92-1025 </papid>fastr (jacquemin,2001), habil (alegria et al, 2004), <papid> W04-0407 </papid>and mul tiflex discussed below.</prevsent>
<prevsent>they mainly concentrate on contiguous nominal and adjectival mwus,sometimes considering limited insertions of external elements.</prevsent>
</prevsection>
<citsent citstr=" W04-0411 ">
more recent approaches, such as (villavicencio et al, 2004), (<papid> W04-0411 </papid>seretan, 2009) and (grgoire, 2010), increasingly address verbal and other noncontiguous multi-word expressions(mwes).</citsent>
<aftsection>
<nextsent>these studies are complemented by recent advances in parsing: robust and reliable syntactic analysis now available can be coupled withmwes identification, and possibly also translation.
</nextsent>
<nextsent>the poleng formalism discussed below belongs to some extent to this class of tools.
</nextsent>
<nextsent>while the processing of noncontiguous mwes is an important step forward, the morphological phenomena in mwus should still be addressed with precision, in particular in inflection ally rich languages.
</nextsent>
<nextsent>therefore we present below comparative study of multi flex and poleng based on an experiment with encoding nominal and adjectival mwus in polish.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1536">
<title id=" W10-3702.xml">computational lexicography of multiword units how efficient can it be </title>
<section> comparative evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>table 2 lists the lexical resources created within both formalisms.
</prevsent>
<prevsent>the multi flex formalism has been used for the construction of language resources of compound sin various applications (savary, 2009): (i) general purpose morphological analysis, (ii) term extraction for translation aid, (iii) named entity recognition, (iv) corpus annotation.
</prevsent>
</prevsection>
<citsent citstr=" L08-1435 ">
the multi flex implementation has been integrated into several nlp tools for corpus analysis and resource manag ment: unitex (paumier, 2008), ws2lr (krstev et al, 2006), prolexbase (maurel, 2008), <papid> L08-1435 </papid>and toposaw (wolinski et al, 2009).</citsent>
<aftsection>
<nextsent>language type of data # entries poleng polish 286,000 english 356,000 russian 26,000 german 59,000 multi flex english general language 60,000computing terms 57,000 polish general language 1,000 urban proper names 8,870 economic terms 1,000 serbian general language 2,200 french proper names 3,000 persian general language 277 figure 2: existing mwu resources described with poleng and multiflex.
</nextsent>
<nextsent>the poleng formalism has been used mainly for the description of mwu entries in polish english, polish-russian and polish-german bilingual lexicons.
</nextsent>
<nextsent>another application of thepoleng formalism was the description of multi token abbreviations6 for the purposes of text 6such polish expressions as, for example, prof. dr hab., normalization in polish text-to-speech system (gralinski et al, 2006).
</nextsent>
<nextsent>the mwus described in this manner can be taken into account in thestand-alone, monolingual (polish, english, german or russian) poleng parser as well.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1539">
<title id=" W10-2602.xml">context adaptation in statistical machine translation using models with exponentially decaying cache </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>despite its popularity, standard smt approaches fail to provide framework for general application across domains unless appropriate training data is available and used in parameter estimation and tuning.
</prevsent>
<prevsent>the main problem is the general assumption of independent and identically distributed (i.i.d.) variables in machine learning approaches applied in the estimation of static global models.
</prevsent>
</prevsection>
<citsent citstr=" C04-1059 ">
recently,there has been quite some attention to the problem of domain switching in smt (zhao et al, 2004; <papid> C04-1059 </papid>ueffing et al, 2007; civera and juan, 2007; <papid> W07-0722 </papid>bertoldi and federico, 2009) <papid> W09-0432 </papid>but groundbreaking success is still missing.</citsent>
<aftsection>
<nextsent>in this paper we report our findings in dynamic model adaptation using cache-based techniques when applying standard model to the task of translating documents from very different domain.
</nextsent>
<nextsent>the remaining part of the paper is organized asfollows: first, we will motivate the chosen approach by reviewing the general phenomenon of repetition and consistency in natural language text.thereafter, we will briefly discuss the dynamic extensions to language and translation models applied in the experiments presented in the second last section followed by some final conclusions.
</nextsent>
<nextsent>domain adaptation can be tackled in various ways.an obvious choice for empirical systems is to apply supervised techniques in case domain-specific training data is available.
</nextsent>
<nextsent>it has been shown thatsmall(er) amounts of in-domain data are sufficient for such an approach (koehn and schroeder,2007).<papid> W07-0733 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1540">
<title id=" W10-2602.xml">context adaptation in statistical machine translation using models with exponentially decaying cache </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>despite its popularity, standard smt approaches fail to provide framework for general application across domains unless appropriate training data is available and used in parameter estimation and tuning.
</prevsent>
<prevsent>the main problem is the general assumption of independent and identically distributed (i.i.d.) variables in machine learning approaches applied in the estimation of static global models.
</prevsent>
</prevsection>
<citsent citstr=" W07-0722 ">
recently,there has been quite some attention to the problem of domain switching in smt (zhao et al, 2004; <papid> C04-1059 </papid>ueffing et al, 2007; civera and juan, 2007; <papid> W07-0722 </papid>bertoldi and federico, 2009) <papid> W09-0432 </papid>but groundbreaking success is still missing.</citsent>
<aftsection>
<nextsent>in this paper we report our findings in dynamic model adaptation using cache-based techniques when applying standard model to the task of translating documents from very different domain.
</nextsent>
<nextsent>the remaining part of the paper is organized asfollows: first, we will motivate the chosen approach by reviewing the general phenomenon of repetition and consistency in natural language text.thereafter, we will briefly discuss the dynamic extensions to language and translation models applied in the experiments presented in the second last section followed by some final conclusions.
</nextsent>
<nextsent>domain adaptation can be tackled in various ways.an obvious choice for empirical systems is to apply supervised techniques in case domain-specific training data is available.
</nextsent>
<nextsent>it has been shown thatsmall(er) amounts of in-domain data are sufficient for such an approach (koehn and schroeder,2007).<papid> W07-0733 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1541">
<title id=" W10-2602.xml">context adaptation in statistical machine translation using models with exponentially decaying cache </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>despite its popularity, standard smt approaches fail to provide framework for general application across domains unless appropriate training data is available and used in parameter estimation and tuning.
</prevsent>
<prevsent>the main problem is the general assumption of independent and identically distributed (i.i.d.) variables in machine learning approaches applied in the estimation of static global models.
</prevsent>
</prevsection>
<citsent citstr=" W09-0432 ">
recently,there has been quite some attention to the problem of domain switching in smt (zhao et al, 2004; <papid> C04-1059 </papid>ueffing et al, 2007; civera and juan, 2007; <papid> W07-0722 </papid>bertoldi and federico, 2009) <papid> W09-0432 </papid>but groundbreaking success is still missing.</citsent>
<aftsection>
<nextsent>in this paper we report our findings in dynamic model adaptation using cache-based techniques when applying standard model to the task of translating documents from very different domain.
</nextsent>
<nextsent>the remaining part of the paper is organized asfollows: first, we will motivate the chosen approach by reviewing the general phenomenon of repetition and consistency in natural language text.thereafter, we will briefly discuss the dynamic extensions to language and translation models applied in the experiments presented in the second last section followed by some final conclusions.
</nextsent>
<nextsent>domain adaptation can be tackled in various ways.an obvious choice for empirical systems is to apply supervised techniques in case domain-specific training data is available.
</nextsent>
<nextsent>it has been shown thatsmall(er) amounts of in-domain data are sufficient for such an approach (koehn and schroeder,2007).<papid> W07-0733 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1542">
<title id=" W10-2602.xml">context adaptation in statistical machine translation using models with exponentially decaying cache </title>
<section> motivation.  </section>
<citcontext>
<prevsection>
<prevsent>the remaining part of the paper is organized asfollows: first, we will motivate the chosen approach by reviewing the general phenomenon of repetition and consistency in natural language text.thereafter, we will briefly discuss the dynamic extensions to language and translation models applied in the experiments presented in the second last section followed by some final conclusions.
</prevsent>
<prevsent>domain adaptation can be tackled in various ways.an obvious choice for empirical systems is to apply supervised techniques in case domain-specific training data is available.
</prevsent>
</prevsection>
<citsent citstr=" W07-0733 ">
it has been shown thatsmall(er) amounts of in-domain data are sufficient for such an approach (koehn and schroeder,2007).<papid> W07-0733 </papid></citsent>
<aftsection>
<nextsent>however, this is not really useful alternative for truly open-domain systems, which will be confronted with changing domains all the time including many new, previously unknown ones among them.
</nextsent>
<nextsent>there are also some interesting approaches to dynamic domain adaptation mainly using flexible mixture models or techniques for the automatic selection of appropriate resources (hildebrand et al, 2005; foster and kuhn, 2007; <papid> W07-0717 </papid>finch and sumita, 2008).<papid> W08-0334 </papid></nextsent>
<nextsent>ideally, system would adjust itself to the current context (and thus to the current domain)without the need of explicit topic mixtures.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1543">
<title id=" W10-2602.xml">context adaptation in statistical machine translation using models with exponentially decaying cache </title>
<section> motivation.  </section>
<citcontext>
<prevsection>
<prevsent>it has been shown thatsmall(er) amounts of in-domain data are sufficient for such an approach (koehn and schroeder,2007).<papid> W07-0733 </papid></prevsent>
<prevsent>however, this is not really useful alternative for truly open-domain systems, which will be confronted with changing domains all the time including many new, previously unknown ones among them.</prevsent>
</prevsection>
<citsent citstr=" W07-0717 ">
there are also some interesting approaches to dynamic domain adaptation mainly using flexible mixture models or techniques for the automatic selection of appropriate resources (hildebrand et al, 2005; foster and kuhn, 2007; <papid> W07-0717 </papid>finch and sumita, 2008).<papid> W08-0334 </papid></citsent>
<aftsection>
<nextsent>ideally, system would adjust itself to the current context (and thus to the current domain)without the need of explicit topic mixtures.
</nextsent>
<nextsent>therefore, we like to investigate techniques for general context adaptation and their use in out-of-domain translation.there are two types of properties in natural language and translation that we like to explore.
</nextsent>
<nextsent>first of all, repetition is very common ? much more than standard stochastic language models would predict.
</nextsent>
<nextsent>this is especially true for content words.see, for instance, the sample of medical document shown in figure 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1544">
<title id=" W10-2602.xml">context adaptation in statistical machine translation using models with exponentially decaying cache </title>
<section> motivation.  </section>
<citcontext>
<prevsection>
<prevsent>it has been shown thatsmall(er) amounts of in-domain data are sufficient for such an approach (koehn and schroeder,2007).<papid> W07-0733 </papid></prevsent>
<prevsent>however, this is not really useful alternative for truly open-domain systems, which will be confronted with changing domains all the time including many new, previously unknown ones among them.</prevsent>
</prevsection>
<citsent citstr=" W08-0334 ">
there are also some interesting approaches to dynamic domain adaptation mainly using flexible mixture models or techniques for the automatic selection of appropriate resources (hildebrand et al, 2005; foster and kuhn, 2007; <papid> W07-0717 </papid>finch and sumita, 2008).<papid> W08-0334 </papid></citsent>
<aftsection>
<nextsent>ideally, system would adjust itself to the current context (and thus to the current domain)without the need of explicit topic mixtures.
</nextsent>
<nextsent>therefore, we like to investigate techniques for general context adaptation and their use in out-of-domain translation.there are two types of properties in natural language and translation that we like to explore.
</nextsent>
<nextsent>first of all, repetition is very common ? much more than standard stochastic language models would predict.
</nextsent>
<nextsent>this is especially true for content words.see, for instance, the sample of medical document shown in figure 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1545">
<title id=" W10-2602.xml">context adaptation in statistical machine translation using models with exponentially decaying cache </title>
<section> motivation.  </section>
<citcontext>
<prevsection>
<prevsent>this effect of meaning con sistency?
</prevsent>
<prevsent>also known as the principle of one sense per discourse?
</prevsent>
</prevsection>
<citsent citstr=" H92-1045 ">
has been applied in word sense disambiguation with quite some success (gale et al., 1992).<papid> H92-1045 </papid></citsent>
<aftsection>
<nextsent>for machine translation this means that adapting to the local domain and sticking to consistent translation choices within discourse seems to be better than using global static model and context independent translations of sentence sin isolation.
</nextsent>
<nextsent>for an illustration, look at the examples in figure 2 taken from translated movie subtitles.
</nextsent>
<nextsent>interesting is not only the consistent meaning of honey?
</nextsent>
<nextsent>within each discourse but also the consistent choice among equivalent translations (synonyms alskling?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1546">
<title id=" W10-2602.xml">context adaptation in statistical machine translation using models with exponentially decaying cache </title>
<section> cache-based models.  </section>
<citcontext>
<prevsection>
<prevsent>therefore, successfully applying these adaptive language models insmt is surprisingly difficult (raab, 2007) especially due to the risk of adding noise (leading toerror propagation) and corrupting local dependen cies.in smt another type of adaptation can be ap plied: cache-based adaptation of the translation model.
</prevsent>
<prevsent>here, not only the repetition of content words is supported but also the consistency of translations as discussed earlier.
</prevsent>
</prevsection>
<citsent citstr=" W04-3225 ">
this technique has already been tried in the context of interactive machine translation (nepveu et al, 2004) <papid> W04-3225 </papid>in which cache features are introduced to adapt both the language model and the translation model.</citsent>
<aftsection>
<nextsent>however,in their model they require an automatic alignment of words in the user edited translation and the source language input.
</nextsent>
<nextsent>in our experiments we investigate close integration of the caching procedure into the decoding process of fully automatictranslation.
</nextsent>
<nextsent>for this, we fill our cache with translation options used in the best (final) translation hypothesis of previous sentences.
</nextsent>
<nextsent>in our implementation of the translation model cache we use again decaying factor in order to account for re cency.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1547">
<title id=" W10-2602.xml">context adaptation in statistical machine translation using models with exponentially decaying cache </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>this score is then used as an additional feature in the standard log-linear model of phrase-based smt1.
</prevsent>
<prevsent>our experiments are focused on the unsupervised dynamic adaptation of language and translation models to new domain using the cache-based mixture models as described above.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
we apply these techniques to standard task of translating french to english using model trained on the publicly available europarl corpus (koehn, 2005) using standard settings and tools such as the moses toolkit (koehn et al, 2007), <papid> P07-2045 </papid>giza++ (och and ney, 2003) <papid> J03-1002 </papid>and srilm (stolcke, 2002).</citsent>
<aftsection>
<nextsent>thelog-linear model is then tuned as usual with minimum error rate training (och, 2003) <papid> P03-1021 </papid>on separate development set coming from the same domain(europarl).</nextsent>
<nextsent>we modified srilm to include decaying cache model and implemented the phrase translation cache within the moses decoder.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1548">
<title id=" W10-2602.xml">context adaptation in statistical machine translation using models with exponentially decaying cache </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>this score is then used as an additional feature in the standard log-linear model of phrase-based smt1.
</prevsent>
<prevsent>our experiments are focused on the unsupervised dynamic adaptation of language and translation models to new domain using the cache-based mixture models as described above.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
we apply these techniques to standard task of translating french to english using model trained on the publicly available europarl corpus (koehn, 2005) using standard settings and tools such as the moses toolkit (koehn et al, 2007), <papid> P07-2045 </papid>giza++ (och and ney, 2003) <papid> J03-1002 </papid>and srilm (stolcke, 2002).</citsent>
<aftsection>
<nextsent>thelog-linear model is then tuned as usual with minimum error rate training (och, 2003) <papid> P03-1021 </papid>on separate development set coming from the same domain(europarl).</nextsent>
<nextsent>we modified srilm to include decaying cache model and implemented the phrase translation cache within the moses decoder.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1549">
<title id=" W10-2602.xml">context adaptation in statistical machine translation using models with exponentially decaying cache </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>our experiments are focused on the unsupervised dynamic adaptation of language and translation models to new domain using the cache-based mixture models as described above.
</prevsent>
<prevsent>we apply these techniques to standard task of translating french to english using model trained on the publicly available europarl corpus (koehn, 2005) using standard settings and tools such as the moses toolkit (koehn et al, 2007), <papid> P07-2045 </papid>giza++ (och and ney, 2003) <papid> J03-1002 </papid>and srilm (stolcke, 2002).</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
thelog-linear model is then tuned as usual with minimum error rate training (och, 2003) <papid> P03-1021 </papid>on separate development set coming from the same domain(europarl).</citsent>
<aftsection>
<nextsent>we modified srilm to include decaying cache model and implemented the phrase translation cache within the moses decoder.
</nextsent>
<nextsent>furthermore, we added the caching procedures and other features for testing the adaptive approach.
</nextsent>
<nextsent>now we can simply switch the cache models on or off using additional command-line arguments when running moses as usual.
</nextsent>
<nextsent>4.1 experimental setup.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1550">
<title id=" W10-2802.xml">manifold learning for the semi supervised induction of framenet predicates an empirical investigation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this latter is employed by embedding prior framenet-derived knowledge in the corresponding non-euclideantransformation.
</prevsent>
<prevsent>the empirical investigation here reported sheds some light on the role played by these spaces as complex kernels for supervised (i.e. support vector machine) algorithms: their use con figures, as novel way to semi-supervised lexical learning, highly appealing research direction for knowledge rich scenarios like framenet-based semantic parsing.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
automatic semantic role labeling (srl) is natural language processing (nlp) technique that maps sentences to semantic representations and identifies the semantic roles conveyed by sentential constituents (gildea and jurafsky, 2002).<papid> J02-3001 </papid></citsent>
<aftsection>
<nextsent>several nlp applications have exploited this kind of semantic representation ranging from information extraction (surdeanu et al, 2003; <papid> P03-1002 </papid>moschitti et al, 2003)) to question answering (shen and lapata, 2007), <papid> D07-1002 </papid>paraphrase identification (pado and erk,2005), and the modeling of textual entailment relations (tatu and moldovan, 2005).<papid> H05-1047 </papid></nextsent>
<nextsent>large scale annotated resources have been used by semantic role labeling methods: they are commonly developed using supervised learning paradigm where classifier learns to predict role labels based on features extracted from annotated training data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1551">
<title id=" W10-2802.xml">manifold learning for the semi supervised induction of framenet predicates an empirical investigation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the empirical investigation here reported sheds some light on the role played by these spaces as complex kernels for supervised (i.e. support vector machine) algorithms: their use con figures, as novel way to semi-supervised lexical learning, highly appealing research direction for knowledge rich scenarios like framenet-based semantic parsing.
</prevsent>
<prevsent>automatic semantic role labeling (srl) is natural language processing (nlp) technique that maps sentences to semantic representations and identifies the semantic roles conveyed by sentential constituents (gildea and jurafsky, 2002).<papid> J02-3001 </papid></prevsent>
</prevsection>
<citsent citstr=" P03-1002 ">
several nlp applications have exploited this kind of semantic representation ranging from information extraction (surdeanu et al, 2003; <papid> P03-1002 </papid>moschitti et al, 2003)) to question answering (shen and lapata, 2007), <papid> D07-1002 </papid>paraphrase identification (pado and erk,2005), and the modeling of textual entailment relations (tatu and moldovan, 2005).<papid> H05-1047 </papid></citsent>
<aftsection>
<nextsent>large scale annotated resources have been used by semantic role labeling methods: they are commonly developed using supervised learning paradigm where classifier learns to predict role labels based on features extracted from annotated training data.
</nextsent>
<nextsent>one prominent resource has been developed under the berkeley framenet project asa semantic lexicon for the core vocabulary of english, according to the so-called frame semantic model (fillmore, 1985).
</nextsent>
<nextsent>here, frame is aconceptual structure modeling prototypical situation, evoked in texts through the occurrence of its lexical units (lu) that linguistically expresses the situation of the frame.
</nextsent>
<nextsent>lexical units of thesame frame share semantic arguments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1552">
<title id=" W10-2802.xml">manifold learning for the semi supervised induction of framenet predicates an empirical investigation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the empirical investigation here reported sheds some light on the role played by these spaces as complex kernels for supervised (i.e. support vector machine) algorithms: their use con figures, as novel way to semi-supervised lexical learning, highly appealing research direction for knowledge rich scenarios like framenet-based semantic parsing.
</prevsent>
<prevsent>automatic semantic role labeling (srl) is natural language processing (nlp) technique that maps sentences to semantic representations and identifies the semantic roles conveyed by sentential constituents (gildea and jurafsky, 2002).<papid> J02-3001 </papid></prevsent>
</prevsection>
<citsent citstr=" D07-1002 ">
several nlp applications have exploited this kind of semantic representation ranging from information extraction (surdeanu et al, 2003; <papid> P03-1002 </papid>moschitti et al, 2003)) to question answering (shen and lapata, 2007), <papid> D07-1002 </papid>paraphrase identification (pado and erk,2005), and the modeling of textual entailment relations (tatu and moldovan, 2005).<papid> H05-1047 </papid></citsent>
<aftsection>
<nextsent>large scale annotated resources have been used by semantic role labeling methods: they are commonly developed using supervised learning paradigm where classifier learns to predict role labels based on features extracted from annotated training data.
</nextsent>
<nextsent>one prominent resource has been developed under the berkeley framenet project asa semantic lexicon for the core vocabulary of english, according to the so-called frame semantic model (fillmore, 1985).
</nextsent>
<nextsent>here, frame is aconceptual structure modeling prototypical situation, evoked in texts through the occurrence of its lexical units (lu) that linguistically expresses the situation of the frame.
</nextsent>
<nextsent>lexical units of thesame frame share semantic arguments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1553">
<title id=" W10-2802.xml">manifold learning for the semi supervised induction of framenet predicates an empirical investigation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the empirical investigation here reported sheds some light on the role played by these spaces as complex kernels for supervised (i.e. support vector machine) algorithms: their use con figures, as novel way to semi-supervised lexical learning, highly appealing research direction for knowledge rich scenarios like framenet-based semantic parsing.
</prevsent>
<prevsent>automatic semantic role labeling (srl) is natural language processing (nlp) technique that maps sentences to semantic representations and identifies the semantic roles conveyed by sentential constituents (gildea and jurafsky, 2002).<papid> J02-3001 </papid></prevsent>
</prevsection>
<citsent citstr=" H05-1047 ">
several nlp applications have exploited this kind of semantic representation ranging from information extraction (surdeanu et al, 2003; <papid> P03-1002 </papid>moschitti et al, 2003)) to question answering (shen and lapata, 2007), <papid> D07-1002 </papid>paraphrase identification (pado and erk,2005), and the modeling of textual entailment relations (tatu and moldovan, 2005).<papid> H05-1047 </papid></citsent>
<aftsection>
<nextsent>large scale annotated resources have been used by semantic role labeling methods: they are commonly developed using supervised learning paradigm where classifier learns to predict role labels based on features extracted from annotated training data.
</nextsent>
<nextsent>one prominent resource has been developed under the berkeley framenet project asa semantic lexicon for the core vocabulary of english, according to the so-called frame semantic model (fillmore, 1985).
</nextsent>
<nextsent>here, frame is aconceptual structure modeling prototypical situation, evoked in texts through the occurrence of its lexical units (lu) that linguistically expresses the situation of the frame.
</nextsent>
<nextsent>lexical units of thesame frame share semantic arguments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1554">
<title id=" W10-2802.xml">manifold learning for the semi supervised induction of framenet predicates an empirical investigation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the current framenet release contains about 700frames and 10,000 lus.
</prevsent>
<prevsent>a corpus of 150,000 annotated examples sentences, from the british national corpus (bnc), is also part of framenet.despite the size of this resource, it is under development and hence incomplete: several frames are not represented by evoking words and the number of annotated sentences is unbalanced across frames.
</prevsent>
</prevsection>
<citsent citstr=" W07-2018 ">
it is one of the main reason for the performance drop of supervised srl systems inout-of-domain scenarios (baker et al, 2007) (<papid> W07-2018 </papid>johansson and nugues, 2008).<papid> C08-1050 </papid></citsent>
<aftsection>
<nextsent>the limited cover age of framenet corpus is even more noticeable for the lus dictionary: it only contains 10,000 lexical units, far less than the 210,000 entries in wordnet 3.0.
</nextsent>
<nextsent>for example, the lexical unit crown,according to the annotations, evokes the accou trement frame.
</nextsent>
<nextsent>it refers to particular sense:according to wordnet, it is an ornamental jeweled headdress signifying sovereignty?.
</nextsent>
<nextsent>according to the same lexical resource, this lu has 12 lexical senses and the first one (i.e. the crown 7 (or the reigning monarch) as the symbol of the power and authority of monarchy?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1555">
<title id=" W10-2802.xml">manifold learning for the semi supervised induction of framenet predicates an empirical investigation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the current framenet release contains about 700frames and 10,000 lus.
</prevsent>
<prevsent>a corpus of 150,000 annotated examples sentences, from the british national corpus (bnc), is also part of framenet.despite the size of this resource, it is under development and hence incomplete: several frames are not represented by evoking words and the number of annotated sentences is unbalanced across frames.
</prevsent>
</prevsection>
<citsent citstr=" C08-1050 ">
it is one of the main reason for the performance drop of supervised srl systems inout-of-domain scenarios (baker et al, 2007) (<papid> W07-2018 </papid>johansson and nugues, 2008).<papid> C08-1050 </papid></citsent>
<aftsection>
<nextsent>the limited cover age of framenet corpus is even more noticeable for the lus dictionary: it only contains 10,000 lexical units, far less than the 210,000 entries in wordnet 3.0.
</nextsent>
<nextsent>for example, the lexical unit crown,according to the annotations, evokes the accou trement frame.
</nextsent>
<nextsent>it refers to particular sense:according to wordnet, it is an ornamental jeweled headdress signifying sovereignty?.
</nextsent>
<nextsent>according to the same lexical resource, this lu has 12 lexical senses and the first one (i.e. the crown 7 (or the reigning monarch) as the symbol of the power and authority of monarchy?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1556">
<title id=" W10-2802.xml">manifold learning for the semi supervised induction of framenet predicates an empirical investigation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>according to the same lexical resource, this lu has 12 lexical senses and the first one (i.e. the crown 7 (or the reigning monarch) as the symbol of the power and authority of monarchy?)
</prevsent>
<prevsent>could evoke other frames, like leadership.
</prevsent>
</prevsection>
<citsent citstr=" D08-1048 ">
in (pennacchiottiet al, 2008) <papid> D08-1048 </papid>and (de cao et al, 2008), the problem of lu automatic induction has been treated in semi-supervised fashion.</citsent>
<aftsection>
<nextsent>first, lus are modeled by exploiting the distributional analysis of an unannotated corpus and the lexical information ofwordnet.
</nextsent>
<nextsent>these representations were used in order to find out frames potentially evoked by novel words in order to extend the framenet dictionary limiting the effort of manual annotations.
</nextsent>
<nextsent>in this work the distributional model of lus is further developed.
</nextsent>
<nextsent>as in (pennacchiotti et al, 2008), <papid> D08-1048 </papid>several word spaces (pado and lapata, 2007) are investigated in order to find the most suitable representation of the properties which characterize frame.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1563">
<title id=" W10-2802.xml">manifold learning for the semi supervised induction of framenet predicates an empirical investigation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in (yang et al, 2006) it is demonstrated that basic nonlinear dimensionality reduction algorithms, such as lle, isomap, and ltsa, can be modified by taking into account prior information on exact mapping of certain data points.
</prevsent>
<prevsent>the sensitivity analysis of these algorithms shows that prior information improves stability of the solution.
</prevsent>
</prevsection>
<citsent citstr=" D09-1119 ">
in (goldbergand elhadad, 2009), <papid> D09-1119 </papid>strategy to incorporate lexical features into classification models is proposed.</citsent>
<aftsection>
<nextsent>another possible approach is the strategy pursued in recent works on deep learning techniques to nlp tasks.
</nextsent>
<nextsent>in (collobert and weston, 2008) unified architecture for nlp that learns features relevant to the tasks at hand given very limited prior knowledge is presented.
</nextsent>
<nextsent>it embodies the idea that multi task learning architecture coupled with semi-supervised learning can be effectively applied even to complex linguistic tasks such as semantic role labeling.
</nextsent>
<nextsent>in particular, (collobertand weston, 2008) proposes an embedding of lexical information using wikipedia as source, and exploits the resulting language model for the multi task learning process.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1564">
<title id=" W10-2802.xml">manifold learning for the semi supervised induction of framenet predicates an empirical investigation </title>
<section> geometrical embed dings as models of.  </section>
<citcontext>
<prevsection>
<prevsent>frame semantics the aim of this distributional approach is to model frames in semantic spaces where words are represented from the distributional analysis of their cooccurrences over corpus.
</prevsent>
<prevsent>semantic spaces are widely used in nlp for representing the meaning of words or other lexical entities.
</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
they have been successfully applied in several tasks, such as information retrieval (salton et al, 1975) and harvesting thesauri (lin, 1998).<papid> P98-2127 </papid></citsent>
<aftsection>
<nextsent>the fundamental intuition is that the meaning of word can be described by the set of textual contexts in which it appears (distributional hypothesis as described in(harris, 1964)), and that words with similar vectors are semantically related.
</nextsent>
<nextsent>contexts are words appearing together with lu: such space models generic notion of semantic relatedness, i.e. two lus spatially close in the space are likely to be either in paradigmatic or syntagmatic relation as in (sahlgren, 2006).
</nextsent>
<nextsent>here, lus delimit sub spaces modeling the prototypical semantic of the corresponding evoked frames and novel lus can be induced by exploiting their projections.
</nextsent>
<nextsent>since semantic space supports the language in use from the corpus statistics in an unsupervised fashion, vectors representing lus can be characterized by different distributions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1569">
<title id=" W10-3605.xml">web based mani puri corpus for multiword ner and re duplicated mwes identification using svm </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the present work reports the ner and re duplicated mwe identification of mani puri on web based news corpus.
</prevsent>
<prevsent>the use of web as corpus for teaching and research on languages has been proposed several times (rundell, 2000; fletcher, 2001; robb, 2003; fletcher 2004).
</prevsent>
</prevsection>
<citsent citstr=" J03-3001 ">
a special issue of the computational linguistics journal on web as corpus (kilgarriff and grefenstette, 2003) <papid> J03-3001 </papid>was published.</citsent>
<aftsection>
<nextsent>several studies have used different methods to mine web data.
</nextsent>
<nextsent>the web walked into the acl meetings starting in 1999.
</nextsent>
<nextsent>the special interest group of acl on web as corpus is promoting interest in the use of the web as source of linguistic data, and as an object of study in its own right.
</nextsent>
<nextsent>india is multilingual country with lot of cultural diversity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1570">
<title id=" W10-3111.xml">a survey on the role of negation in sentiment analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we will also discuss limits and challenges of negation modeling on that task.
</prevsent>
<prevsent>sentiment analysis is the task dealing with the automatic detection and classification of opinions expressed in text written in natural language.
</prevsent>
</prevsection>
<citsent citstr=" J94-2004 ">
subjectivity is defined as the linguistic expression of somebodys opinions, sentiments, emotions, evaluations, beliefs and speculations (wiebe, 1994).<papid> J94-2004 </papid></citsent>
<aftsection>
<nextsent>subjectivity is opposed to objectivity, which is the expression of facts.
</nextsent>
<nextsent>it is important tomake the distinction between subjectivity detection and sentiment analysis, as they are two separate tasks in natural language processing.
</nextsent>
<nextsent>sentiment analysis can be dependently or independently done from subjectivity detection, although pang and lee (2004) <papid> P04-1035 </papid>state that subjectivity detection performed prior to the sentiment analysis leads to better results in the latter.although research in this area has started only recently, the substantial growth in subjective information on the world wide web in the past year shas made sentiment analysis task on which constantly growing efforts have been concentrated.the body of research published on sentiment analysis has shown that the task is difficult, not only due to the syntactic and semantic variability of language, but also because it involves the extraction of indirect or implicit assessments of objects, by means of emotions or attitudes.</nextsent>
<nextsent>being part of subjective language, the expression of opinions involves the use of nuances and intricate surface realizations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1571">
<title id=" W10-3111.xml">a survey on the role of negation in sentiment analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>subjectivity is opposed to objectivity, which is the expression of facts.
</prevsent>
<prevsent>it is important tomake the distinction between subjectivity detection and sentiment analysis, as they are two separate tasks in natural language processing.
</prevsent>
</prevsection>
<citsent citstr=" P04-1035 ">
sentiment analysis can be dependently or independently done from subjectivity detection, although pang and lee (2004) <papid> P04-1035 </papid>state that subjectivity detection performed prior to the sentiment analysis leads to better results in the latter.although research in this area has started only recently, the substantial growth in subjective information on the world wide web in the past year shas made sentiment analysis task on which constantly growing efforts have been concentrated.the body of research published on sentiment analysis has shown that the task is difficult, not only due to the syntactic and semantic variability of language, but also because it involves the extraction of indirect or implicit assessments of objects, by means of emotions or attitudes.</citsent>
<aftsection>
<nextsent>being part of subjective language, the expression of opinions involves the use of nuances and intricate surface realizations.
</nextsent>
<nextsent>that is why the automatic study of opinions requires fine-grained linguistic analysis techniques and substantial efforts to extract features for machine learning or rule-based systems,in which subtle phenomena as negation can be appropriately incorporated.
</nextsent>
<nextsent>sentiment analysis is considered as subsequent task to subjectivity detection, which should ideally be performed to extract content that is not factual in nature.
</nextsent>
<nextsent>subsequently, sentiment analysis aims at classifying the sentiment of the opinions into polarity types (the common types are positive andnegative).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1572">
<title id=" W10-3111.xml">a survey on the role of negation in sentiment analysis </title>
<section> the survey.  </section>
<citcontext>
<prevsection>
<prevsent>3.1 negation and bag of words in supervised.
</prevsent>
<prevsent>machine learning several research efforts in polarity classification employ supervised machine-learning algorithms,like support vector machines, nave bayes classifiers or maximum entropy classifiers.
</prevsent>
</prevsection>
<citsent citstr=" W02-1011 ">
for these algorithms, already low-level representation using bag of words is fairly effective (pang et al, 2002).<papid> W02-1011 </papid></citsent>
<aftsection>
<nextsent>using bag-of-words representation, the supervised classifier has to figure out by itself which words in the dataset, or more precisely feature set, are polar and which are not.
</nextsent>
<nextsent>one either considers all words occurring in dataset or, as in the case of pang et al (2002), <papid> W02-1011 </papid>one carries outa simple feature selection, such as removing infrequent words.</nextsent>
<nextsent>thus, the standard bag-of-words representation does not contain any explicit knowledge of polar expressions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1578">
<title id=" W10-3111.xml">a survey on the role of negation in sentiment analysis </title>
<section> the survey.  </section>
<citcontext>
<prevsection>
<prevsent>imagine labeled training set of documents contains frequent bigrams, such as not appealing or less entertaining.
</prevsent>
<prevsent>then feature set using higher order n-grams implicitly contains negation modeling.
</prevsent>
</prevsection>
<citsent citstr=" P06-2079 ">
this also partially explains the effectiveness of bigrams and trigrams for this task as stated in (ng et al, 2006).<papid> P06-2079 </papid></citsent>
<aftsection>
<nextsent>the dataset used for the experiments in (pang et al., 2002; <papid> W02-1011 </papid>ng et al, 2006) <papid> P06-2079 </papid>has been established asa popular benchmark dataset for sentiment analysis and is publicly available1.</nextsent>
<nextsent>3.2 incorporating negation in models that.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1581">
<title id=" W10-3111.xml">a survey on the role of negation in sentiment analysis </title>
<section> the survey.  </section>
<citcontext>
<prevsection>
<prevsent>62final results show that modeling negation is important and relevant, even in the case of such simple methods.
</prevsent>
<prevsent>the consideration of negation words is more important than that of diminishers.
</prevsent>
</prevsection>
<citsent citstr=" H05-1044 ">
3.2.2 features for negation modeling wilson et al (2005) <papid> H05-1044 </papid>carry out more advanced negation modeling on expression-level polarity classification.</citsent>
<aftsection>
<nextsent>the work uses supervised machine learning where negation modeling is mostly encoded as features using polar expressions.
</nextsent>
<nextsent>the features for negation modeling are organized in three groups: ? negation features ? shifter features ? polarity modification features negation features directly relate to negation expressions negating polar expression.
</nextsent>
<nextsent>one feature checks whether negation expression occurs in fixed window of four words preceding the polar expression.
</nextsent>
<nextsent>the other feature accounts for polar predicate having negated subject.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1593">
<title id=" W10-3111.xml">a survey on the role of negation in sentiment analysis </title>
<section> the survey.  </section>
<citcontext>
<prevsection>
<prevsent>the approach by moilanen and pulman (2007) isnot compared against another established classification method whereas the approach by shaikh et al.
</prevsent>
<prevsent>(2007) is evaluated against non-compositional rule-based system which it outperforms.
</prevsent>
</prevsection>
<citsent citstr=" D08-1083 ">
3.3.2 shallow semantic composition choi and cardie (2008) <papid> D08-1083 </papid>present more lightweight approach using compositional semantics towards classifying the polarity of expressions.</citsent>
<aftsection>
<nextsent>their working assumption is that the polarity of phrase can be computed in two steps: ? the assessment of polarity of the constituents?
</nextsent>
<nextsent>the subsequent application of set of previously defined inference rules an example rule, such as: polarity([np1]?
</nextsent>
<nextsent>[in] [np2]?)
</nextsent>
<nextsent>= + (3) may be applied to expressions, such as [lack]np1 [of]in [crime]np2 in rural areas.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1605">
<title id=" W10-3111.xml">a survey on the role of negation in sentiment analysis </title>
<section> the survey.  </section>
<citcontext>
<prevsection>
<prevsent>the text span until the first occurrence of polar expression following the negation word ? the entire sentence the proposed method consistently outperforms the simpler methods proving that the incorporation of linguistic insights into negation modeling is meaningful.
</prevsent>
<prevsent>even on polarity document retrieval, i.e. more coarse-grained classification task where contextual disambiguation usually results in less significant improvement, the proposed method also outperforms the other scopes examined.
</prevsent>
</prevsection>
<citsent citstr=" D08-1075 ">
there have only been few research efforts in sentiment analysis examining the impact of scope modeling for negation in contrast to other research areas, such as the biomedical domain (huang and lowe, 2007; morante et al, 2008; <papid> D08-1075 </papid>morante and daelemans, 2009).<papid> W09-1105 </papid></citsent>
<aftsection>
<nextsent>this is presumably due to the fact that only for the biomedical domain, publicly available corpora containing annotation for the scope of negation exist (szarvas et al, 2008).<papid> W08-0606 </papid></nextsent>
<nextsent>the usability of those corpora for sentiment analysis has not been tested.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1606">
<title id=" W10-3111.xml">a survey on the role of negation in sentiment analysis </title>
<section> the survey.  </section>
<citcontext>
<prevsection>
<prevsent>the text span until the first occurrence of polar expression following the negation word ? the entire sentence the proposed method consistently outperforms the simpler methods proving that the incorporation of linguistic insights into negation modeling is meaningful.
</prevsent>
<prevsent>even on polarity document retrieval, i.e. more coarse-grained classification task where contextual disambiguation usually results in less significant improvement, the proposed method also outperforms the other scopes examined.
</prevsent>
</prevsection>
<citsent citstr=" W09-1105 ">
there have only been few research efforts in sentiment analysis examining the impact of scope modeling for negation in contrast to other research areas, such as the biomedical domain (huang and lowe, 2007; morante et al, 2008; <papid> D08-1075 </papid>morante and daelemans, 2009).<papid> W09-1105 </papid></citsent>
<aftsection>
<nextsent>this is presumably due to the fact that only for the biomedical domain, publicly available corpora containing annotation for the scope of negation exist (szarvas et al, 2008).<papid> W08-0606 </papid></nextsent>
<nextsent>the usability of those corpora for sentiment analysis has not been tested.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1607">
<title id=" W10-3111.xml">a survey on the role of negation in sentiment analysis </title>
<section> the survey.  </section>
<citcontext>
<prevsection>
<prevsent>even on polarity document retrieval, i.e. more coarse-grained classification task where contextual disambiguation usually results in less significant improvement, the proposed method also outperforms the other scopes examined.
</prevsent>
<prevsent>there have only been few research efforts in sentiment analysis examining the impact of scope modeling for negation in contrast to other research areas, such as the biomedical domain (huang and lowe, 2007; morante et al, 2008; <papid> D08-1075 </papid>morante and daelemans, 2009).<papid> W09-1105 </papid></prevsent>
</prevsection>
<citsent citstr=" W08-0606 ">
this is presumably due to the fact that only for the biomedical domain, publicly available corpora containing annotation for the scope of negation exist (szarvas et al, 2008).<papid> W08-0606 </papid></citsent>
<aftsection>
<nextsent>the usability of those corpora for sentiment analysis has not been tested.
</nextsent>
<nextsent>3.4 negation within words.
</nextsent>
<nextsent>so far, negation has only be considered as phenomenon that affects entire words or phrases.
</nextsent>
<nextsent>the word expressing negation and the words or phrases being negated are disjoint.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1608">
<title id=" W10-3111.xml">a survey on the role of negation in sentiment analysis </title>
<section> the survey.  </section>
<citcontext>
<prevsection>
<prevsent>in case, these words are lexicalized, such as flaw-less, and are consequently to be found polarity lexicon, this phenomenon does not need to be accounted for in sentiment analysis.
</prevsent>
<prevsent>however, since this process is (at least theoretically) productive, fairly uncommon words, such as not-so-nice, anti-war or offensive less which are not necessarily contained in lexical resources, may emerge as result of this process.
</prevsent>
</prevsection>
<citsent citstr=" D09-1131 ">
therefore, polarity classifier should also be ableto decompose words and carry out negation modeling within words.there are only few works addressing this particular aspect (moilanen and pulman, 2008; ku et al, 2009) <papid> D09-1131 </papid>so it is not clear how much impact this type of negation has on an overall polarity classification and what complexity of morphological analysis is really necessary.</citsent>
<aftsection>
<nextsent>we argue, however, that in synthetic languages where negation may regularly be realized as an affix rather than an individual word, such an analysis is much more important.
</nextsent>
<nextsent>3.5 negation in various languages.
</nextsent>
<nextsent>current research in sentiment analysis mainly focuses on english texts.
</nextsent>
<nextsent>since there are significant structural differences among the different languages, some particular methods may only capture the idiosyncratic properties of the english language.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1609">
<title id=" W10-3111.xml">a survey on the role of negation in sentiment analysis </title>
<section> the survey.  </section>
<citcontext>
<prevsection>
<prevsent>3.6 bad and not good are not the same.
</prevsent>
<prevsent>the standard approach of negation modeling suggests to consider negated polar expression, such as not bad, as an un negated polar expression with the opposite polarity, such as good.
</prevsent>
</prevsection>
<citsent citstr=" D09-1017 ">
liu and seneff(2009) <papid> D09-1017 </papid>claim, however, that this is an oversimplification of language.</citsent>
<aftsection>
<nextsent>not bad and good may havethe same polarity but they differ in their respective polar strength, i.e. not bad is less positive than good.
</nextsent>
<nextsent>that is why, liu and seneff (2009)<papid> D09-1017 </papid>suggest compositional model in which for individual adjectives and adverbs (the latter includenegations) prior rating score encoding their intensity and polarity is estimated from pros and cons of on-line reviews.</nextsent>
<nextsent>moreover, compositional rules for polar phrases, such as adverb-adjective or negation-adverb-adjective are defined exclusively using the scores of the individual words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1611">
<title id=" W10-3111.xml">a survey on the role of negation in sentiment analysis </title>
<section> the survey.  </section>
<citcontext>
<prevsection>
<prevsent>many classification approaches illustrated above depend on the knowledge of which natural language expressions are polar.
</prevsent>
<prevsent>the process of acquiring such lexical resources is called lexicon induction.
</prevsent>
</prevsection>
<citsent citstr=" C08-1135 ">
the observation that neg ations co-occur with polar expressions has been used for inducing polarity lexicons on chinese in an unsupervised manner (zagibalov and carroll, 2008).<papid> C08-1135 </papid></citsent>
<aftsection>
<nextsent>one advantage of negation is that though the induction starts with just positive polar seeds, the method also accomplishes to extract negative polar expressions since negated mentions of the positive polar seeds co-occur with negative polar expressions.
</nextsent>
<nextsent>moreover, and more importantly, the distribution of the co-occurrence between polar expressions and neg ations can be exploited for the selection of those seed lexical items.
</nextsent>
<nextsent>the model presented by zagibalov and carroll (2008) <papid> C08-1135 </papid>relies on the observation that polar expression can be negated but it occurs more frequently without the negation.</nextsent>
<nextsent>the distributional behaviour of an expression, i.e. significantly often co-occurring with negation word but significantly more often occurring without anegation word makes up property of polar ex pression.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1613">
<title id=" W10-3111.xml">a survey on the role of negation in sentiment analysis </title>
<section> limits of negation modeling in.  </section>
<citcontext>
<prevsection>
<prevsent>13.
</prevsent>
<prevsent>early symptoms of the disease are headaches, fevers,.
</prevsent>
</prevsection>
<citsent citstr=" D09-1020 ">
cold chills and body pain.in pilot study (akkaya et al, 2009), <papid> D09-1020 </papid>it has already been shown that applying subjectivity word sense disambiguation in addition to the feature based negation modeling approach of wilson et al (2005) <papid> H05-1044 </papid>results in an improvement of performance in polarity classification.</citsent>
<aftsection>
<nextsent>another problem is that some polar opinions arenot lexicalized.
</nextsent>
<nextsent>sentence 14 is negative pragmatic opinion (somasundaran and wiebe, 2009)<papid> P09-1026 </papid>which can only be detected with the help of external world knowledge.</nextsent>
<nextsent>14.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1617">
<title id=" W10-3111.xml">a survey on the role of negation in sentiment analysis </title>
<section> limits of negation modeling in.  </section>
<citcontext>
<prevsection>
<prevsent>cold chills and body pain.in pilot study (akkaya et al, 2009), <papid> D09-1020 </papid>it has already been shown that applying subjectivity word sense disambiguation in addition to the feature based negation modeling approach of wilson et al (2005) <papid> H05-1044 </papid>results in an improvement of performance in polarity classification.</prevsent>
<prevsent>another problem is that some polar opinions arenot lexicalized.</prevsent>
</prevsection>
<citsent citstr=" P09-1026 ">
sentence 14 is negative pragmatic opinion (somasundaran and wiebe, 2009)<papid> P09-1026 </papid>which can only be detected with the help of external world knowledge.</citsent>
<aftsection>
<nextsent>14.
</nextsent>
<nextsent>the next time hear this song on the radio, ill throw.
</nextsent>
<nextsent>my radio out of the window.
</nextsent>
<nextsent>moreover, the effectiveness of specific negation models can only be proven with the help of corpora containing those constructions or the type of language behaviour that is reflected in the models to be evaluated.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1618">
<title id=" W10-2701.xml">episodic memory for companion dialogue </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>for example, while the name of person is in the name property of the person class, thename of music album is contained in the property albumtitle.
</prevsent>
<prevsent>a mapping for each class to such property is stored in an annotation file.
</prevsent>
</prevsection>
<citsent citstr=" L08-1199 ">
catizone et al (2008) <papid> L08-1199 </papid>use an extended version of gates annie subsystem, combined with setof gazette ers, to identify relationships in the input to their senior companion system.</citsent>
<aftsection>
<nextsent>the focus of the senior companion is to use the data extracted from the user utterances to collect information about the users life.
</nextsent>
<nextsent>while our input analysis system is similar, it uses regular expression patterns over annotations for the matching of relations between, and properties of, individuals 5http://velocity.apache.org/ and classes.
</nextsent>
<nextsent>in terms of functionality, our system focuses on being able to answer user requests and provide continued dialogue by taking into account the previous interactions with the user.
</nextsent>
<nextsent>episodic memory has first been distinguished from other memory types by tulving (1972).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1619">
<title id=" W10-1743.xml">the upvprhlt combination system for wmt 2010 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these consensus translations always improve translation quality of the best individual system.
</prevsent>
<prevsent>the upv-prhlt approach to mt system combination is based on refined version of the algorithm described in (gonzalez-rubio and casacuberta, 2010), with additional information to cope with hypotheses of different quality.
</prevsent>
</prevsection>
<citsent citstr=" P05-3026 ">
in contrast to most of the previous approaches to combine the outputs of multiple mt systems (bangalore et al, 2001; jayaraman and lavie, 2005; <papid> P05-3026 </papid>matusov et al, 2006; <papid> E06-1005 </papid>schroeder et al., 2009), <papid> E09-1082 </papid>which are variations over the rover voting scheme (fiscus, 1997), we consider the problem of computing consensus translation as the problem of modelling set of string patterns with an adequate prototype.</citsent>
<aftsection>
<nextsent>under this framework, the translation hypotheses of each of the mt systems are considered as individual pattern sin set of string patterns.
</nextsent>
<nextsent>the (generalised) median string, which is the optimal prototype of set of strings (fu, 1982), is the chosen prototype to model the set of strings.
</nextsent>
<nextsent>the median string of set is defined as the string that minimises the sum of distances to the strings in the set.
</nextsent>
<nextsent>therefore, defining distance between strings is the primary problem to deal with.the most common definition of distance between two strings is the levenshtein distance, also known as edit distance (ed).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1620">
<title id=" W10-1743.xml">the upvprhlt combination system for wmt 2010 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these consensus translations always improve translation quality of the best individual system.
</prevsent>
<prevsent>the upv-prhlt approach to mt system combination is based on refined version of the algorithm described in (gonzalez-rubio and casacuberta, 2010), with additional information to cope with hypotheses of different quality.
</prevsent>
</prevsection>
<citsent citstr=" E06-1005 ">
in contrast to most of the previous approaches to combine the outputs of multiple mt systems (bangalore et al, 2001; jayaraman and lavie, 2005; <papid> P05-3026 </papid>matusov et al, 2006; <papid> E06-1005 </papid>schroeder et al., 2009), <papid> E09-1082 </papid>which are variations over the rover voting scheme (fiscus, 1997), we consider the problem of computing consensus translation as the problem of modelling set of string patterns with an adequate prototype.</citsent>
<aftsection>
<nextsent>under this framework, the translation hypotheses of each of the mt systems are considered as individual pattern sin set of string patterns.
</nextsent>
<nextsent>the (generalised) median string, which is the optimal prototype of set of strings (fu, 1982), is the chosen prototype to model the set of strings.
</nextsent>
<nextsent>the median string of set is defined as the string that minimises the sum of distances to the strings in the set.
</nextsent>
<nextsent>therefore, defining distance between strings is the primary problem to deal with.the most common definition of distance between two strings is the levenshtein distance, also known as edit distance (ed).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1621">
<title id=" W10-1743.xml">the upvprhlt combination system for wmt 2010 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these consensus translations always improve translation quality of the best individual system.
</prevsent>
<prevsent>the upv-prhlt approach to mt system combination is based on refined version of the algorithm described in (gonzalez-rubio and casacuberta, 2010), with additional information to cope with hypotheses of different quality.
</prevsent>
</prevsection>
<citsent citstr=" E09-1082 ">
in contrast to most of the previous approaches to combine the outputs of multiple mt systems (bangalore et al, 2001; jayaraman and lavie, 2005; <papid> P05-3026 </papid>matusov et al, 2006; <papid> E06-1005 </papid>schroeder et al., 2009), <papid> E09-1082 </papid>which are variations over the rover voting scheme (fiscus, 1997), we consider the problem of computing consensus translation as the problem of modelling set of string patterns with an adequate prototype.</citsent>
<aftsection>
<nextsent>under this framework, the translation hypotheses of each of the mt systems are considered as individual pattern sin set of string patterns.
</nextsent>
<nextsent>the (generalised) median string, which is the optimal prototype of set of strings (fu, 1982), is the chosen prototype to model the set of strings.
</nextsent>
<nextsent>the median string of set is defined as the string that minimises the sum of distances to the strings in the set.
</nextsent>
<nextsent>therefore, defining distance between strings is the primary problem to deal with.the most common definition of distance between two strings is the levenshtein distance, also known as edit distance (ed).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1622">
<title id=" W10-3606.xml">a word segmentation system for handling space omission problem in urdu script </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the words are correctly segmented with 99.15% accuracy.
</prevsent>
<prevsent>word segmentation is the foremost obligatory task in all nlp application, where the initial phase requires tokenization of input into words.
</prevsent>
</prevsection>
<citsent citstr=" H94-1054 ">
for languages like english, french and spanish etc. tokenization is considered trivial because the white space or punctuation marks between words is good approximation of where word boundary is. whilst in various asian languages such as chinese, thai and myanmar, white spaces is rarely or never used to determine the word boundaries, so one must resort to higher levels of information such as: information of morphology, syntax and statistical analysis to reconstruct the word boundary information (papageorgiou, 1994; <papid> H94-1054 </papid>nie et al  1995; wang et al , 2000; xu et al  2005).</citsent>
<aftsection>
<nextsent>though the urdu word segmentation problem is not as severe as some of the other asian language, since space is used for word delimitation, but the space is not consistently used, which gives rise to both space omission and space insertion errors in urdu.
</nextsent>
<nextsent>durrani(2007) and durrani and hussain(2010) <papid> N10-1077 </papid>have discussed in detail the various urdu word segmentation issues while jawaid and ahmed(2009) and abbas et al 2009) have discussed the hindi-urdu transliteration issues.</nextsent>
<nextsent>a word segmentation system for handling space insertion problem in urdu script has been presented by lehal(2009).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1623">
<title id=" W10-3606.xml">a word segmentation system for handling space omission problem in urdu script </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for languages like english, french and spanish etc. tokenization is considered trivial because the white space or punctuation marks between words is good approximation of where word boundary is. whilst in various asian languages such as chinese, thai and myanmar, white spaces is rarely or never used to determine the word boundaries, so one must resort to higher levels of information such as: information of morphology, syntax and statistical analysis to reconstruct the word boundary information (papageorgiou, 1994; <papid> H94-1054 </papid>nie et al  1995; wang et al , 2000; xu et al  2005).</prevsent>
<prevsent>though the urdu word segmentation problem is not as severe as some of the other asian language, since space is used for word delimitation, but the space is not consistently used, which gives rise to both space omission and space insertion errors in urdu.</prevsent>
</prevsection>
<citsent citstr=" N10-1077 ">
durrani(2007) and durrani and hussain(2010) <papid> N10-1077 </papid>have discussed in detail the various urdu word segmentation issues while jawaid and ahmed(2009) and abbas et al 2009) have discussed the hindi-urdu transliteration issues.</citsent>
<aftsection>
<nextsent>a word segmentation system for handling space insertion problem in urdu script has been presented by lehal(2009).
</nextsent>
<nextsent>hindi and urdu are variants of the same language characterized by extreme digraphia: hindi is written in the devanagari script from left to right, urdu in script derived from persian modification of arabic script written from right to left.
</nextsent>
<nextsent>hindi and urdu share grammar, morphology, vocabulary, history, classical literature etc. because of their identical grammar and nearly identical core vocabularies, 43 most linguists do not distinguish between urdu and hindi as separate languages.
</nextsent>
<nextsent>the difference in the two scripts has created script wedge as majority of urdu speaking people in pakistan cannot read devnagri, and similarly the majority of hindi speaking people in india cannot comprehend urdu script.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1627">
<title id=" W10-1739.xml">many open source mt system combination at wmtrsquo10 </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>results on wmt09 data are presented in section 4 along results of tuning on newssyscombtune2010.
</prevsent>
<prevsent>many is system combination software (bar rault, 2010) based on the decoding of lattice made of several confusion networks (cn).
</prevsent>
</prevsection>
<citsent citstr=" P07-1040 ">
this is widespread approach in mt system combination (rosti et al, 2007); (<papid> P07-1040 </papid>shen et al, 2008); (karakos et al, 2008).<papid> P08-2021 </papid></citsent>
<aftsection>
<nextsent>many can be decomposed in twomain modules.
</nextsent>
<nextsent>the first one is the alignment module which actually is modified version of terp (snover et al, 2009).
</nextsent>
<nextsent>its role is to incrementally align the hypotheses against backbone in order to create confusion network.
</nextsent>
<nextsent>those confusion networks are then connected together to create lattice.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1628">
<title id=" W10-1739.xml">many open source mt system combination at wmtrsquo10 </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>results on wmt09 data are presented in section 4 along results of tuning on newssyscombtune2010.
</prevsent>
<prevsent>many is system combination software (bar rault, 2010) based on the decoding of lattice made of several confusion networks (cn).
</prevsent>
</prevsection>
<citsent citstr=" P08-2021 ">
this is widespread approach in mt system combination (rosti et al, 2007); (<papid> P07-1040 </papid>shen et al, 2008); (karakos et al, 2008).<papid> P08-2021 </papid></citsent>
<aftsection>
<nextsent>many can be decomposed in twomain modules.
</nextsent>
<nextsent>the first one is the alignment module which actually is modified version of terp (snover et al, 2009).
</nextsent>
<nextsent>its role is to incrementally align the hypotheses against backbone in order to create confusion network.
</nextsent>
<nextsent>those confusion networks are then connected together to create lattice.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1629">
<title id=" W10-0733.xml">using mechanical turk to build machine translation evaluation sets </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for wmt08, creating test sets consisting of 2,051 sentences in six languages was approximately $26,500 usd or slightly more than $0.10 usd/word.
</prevsent>
<prevsent>in this paper we examine the use of amazons mechanical turk (mturk) to create translation test sets for statistical machine translation research.
</prevsent>
</prevsection>
<citsent citstr=" D08-1027 ">
snow et al (2008) <papid> D08-1027 </papid>showed that mturk can be useful for creating data for variety of nlp tasks, and that combination of judgments from non-experts can attain expert-level quality in many cases.</citsent>
<aftsection>
<nextsent>callison burch (2009) showed that mturk could be used for low-cost manual evaluation of machine translation quality, and suggested that it might be possible touse mturk to create mt test sets after an initial pilot study where turkers (the people who complete the work assignments posted on mturk) produced translations of 50 sentences in five languages.this paper explores this in more detail by asking turkers to translate the urdu sentences of theurdu-english test set used in the 2009 nist machine translation evaluation workshop.
</nextsent>
<nextsent>we evaluate multiple mt systems on both the professionally produced nist2009 test set and our mturk produced test set and find that the mturk-produced test set yields essentially the same conclusions about system performance as the nist2009 set yields.
</nextsent>
<nextsent>208
</nextsent>
<nextsent>mechanical turkthe nist2009 urdu-english test set1 is professionally produced machine translation evaluation set, containing four human-produced reference translations for each of 1792 urdu sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1630">
<title id=" W10-0733.xml">using mechanical turk to build machine translation evaluation sets </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>isi-syntax (the highest-performing system on nist2009 to our knowledge) is used as the baseline.
</prevsent>
<prevsent>thus, it will always have 100% as the percentage performance for all of the test sets.
</prevsent>
</prevsection>
<citsent citstr=" P06-1121 ">
to illustrate computing the percentage performance for the other systems, consider for jhu syntax tested on nist2009, that its bleu score of 32.77 divided by the bleu score of the baseline system is 32.77/33.10 ? 99.00% 2004; galley et al, 2006) <papid> P06-1121 </papid>and jhu syntax (li et al, 2009) <papid> W09-0424 </papid>augmented with (zollmann and venugopal,2006)) <papid> W06-3119 </papid>were chosen because they represent state of-the-art performance, having achieved the highest scores on nist2009 to our knowledge.</citsent>
<aftsection>
<nextsent>they also have very similar performance on nist2009 so we want to see if that similar performance is maintained as we evaluate on our mturk-produced test sets.
</nextsent>
<nextsent>the third mt system (joshua-hierarchical) (li etal., 2009), <papid> W09-0424 </papid>an open source implementation of (chiang, 2007), <papid> J07-2003 </papid>was chosen because though it is competitive system, it had clear, markedly lower performance on nist2009 than the other two systems and we want to see if that difference in performance is also maintained if we were to shift evaluation to our mturk-produced test sets.</nextsent>
<nextsent>table 2 shows the results.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1631">
<title id=" W10-0733.xml">using mechanical turk to build machine translation evaluation sets </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>isi-syntax (the highest-performing system on nist2009 to our knowledge) is used as the baseline.
</prevsent>
<prevsent>thus, it will always have 100% as the percentage performance for all of the test sets.
</prevsent>
</prevsection>
<citsent citstr=" W09-0424 ">
to illustrate computing the percentage performance for the other systems, consider for jhu syntax tested on nist2009, that its bleu score of 32.77 divided by the bleu score of the baseline system is 32.77/33.10 ? 99.00% 2004; galley et al, 2006) <papid> P06-1121 </papid>and jhu syntax (li et al, 2009) <papid> W09-0424 </papid>augmented with (zollmann and venugopal,2006)) <papid> W06-3119 </papid>were chosen because they represent state of-the-art performance, having achieved the highest scores on nist2009 to our knowledge.</citsent>
<aftsection>
<nextsent>they also have very similar performance on nist2009 so we want to see if that similar performance is maintained as we evaluate on our mturk-produced test sets.
</nextsent>
<nextsent>the third mt system (joshua-hierarchical) (li etal., 2009), <papid> W09-0424 </papid>an open source implementation of (chiang, 2007), <papid> J07-2003 </papid>was chosen because though it is competitive system, it had clear, markedly lower performance on nist2009 than the other two systems and we want to see if that difference in performance is also maintained if we were to shift evaluation to our mturk-produced test sets.</nextsent>
<nextsent>table 2 shows the results.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1632">
<title id=" W10-0733.xml">using mechanical turk to build machine translation evaluation sets </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>isi-syntax (the highest-performing system on nist2009 to our knowledge) is used as the baseline.
</prevsent>
<prevsent>thus, it will always have 100% as the percentage performance for all of the test sets.
</prevsent>
</prevsection>
<citsent citstr=" W06-3119 ">
to illustrate computing the percentage performance for the other systems, consider for jhu syntax tested on nist2009, that its bleu score of 32.77 divided by the bleu score of the baseline system is 32.77/33.10 ? 99.00% 2004; galley et al, 2006) <papid> P06-1121 </papid>and jhu syntax (li et al, 2009) <papid> W09-0424 </papid>augmented with (zollmann and venugopal,2006)) <papid> W06-3119 </papid>were chosen because they represent state of-the-art performance, having achieved the highest scores on nist2009 to our knowledge.</citsent>
<aftsection>
<nextsent>they also have very similar performance on nist2009 so we want to see if that similar performance is maintained as we evaluate on our mturk-produced test sets.
</nextsent>
<nextsent>the third mt system (joshua-hierarchical) (li etal., 2009), <papid> W09-0424 </papid>an open source implementation of (chiang, 2007), <papid> J07-2003 </papid>was chosen because though it is competitive system, it had clear, markedly lower performance on nist2009 than the other two systems and we want to see if that difference in performance is also maintained if we were to shift evaluation to our mturk-produced test sets.</nextsent>
<nextsent>table 2 shows the results.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1634">
<title id=" W10-0733.xml">using mechanical turk to build machine translation evaluation sets </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>to illustrate computing the percentage performance for the other systems, consider for jhu syntax tested on nist2009, that its bleu score of 32.77 divided by the bleu score of the baseline system is 32.77/33.10 ? 99.00% 2004; galley et al, 2006) <papid> P06-1121 </papid>and jhu syntax (li et al, 2009) <papid> W09-0424 </papid>augmented with (zollmann and venugopal,2006)) <papid> W06-3119 </papid>were chosen because they represent state of-the-art performance, having achieved the highest scores on nist2009 to our knowledge.</prevsent>
<prevsent>they also have very similar performance on nist2009 so we want to see if that similar performance is maintained as we evaluate on our mturk-produced test sets.</prevsent>
</prevsection>
<citsent citstr=" J07-2003 ">
the third mt system (joshua-hierarchical) (li etal., 2009), <papid> W09-0424 </papid>an open source implementation of (chiang, 2007), <papid> J07-2003 </papid>was chosen because though it is competitive system, it had clear, markedly lower performance on nist2009 than the other two systems and we want to see if that difference in performance is also maintained if we were to shift evaluation to our mturk-produced test sets.</citsent>
<aftsection>
<nextsent>table 2 shows the results.
</nextsent>
<nextsent>there are number of observations to make.
</nextsent>
<nextsent>one is that the absolute magnitude of the bleu scores is much lower for all systems on the mturk-produced test sets than on eval isi jhu joshua set (syntax) (syntax) (hier.)
</nextsent>
<nextsent>nist- 33.10 32.77 26.65 2009 100% 99.00% 80.51% mturk- 13.81 13.93 11.10 no editing 100% 100.87% 80.38% mturk- 14.16 14.23 11.68 edited 100% 100.49% 82.49%table 2: this table shows three mt systems evaluated using the official nist2009 test set and the two test sets we constructed (mturk-noediting and mturk-edited).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1635">
<title id=" W10-1811.xml">retrieving correct semantic boundaries in dependency structure </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>by applying heuristics, we achieved an f1-score of 99.54% for correct representation of semantic boundaries.
</prevsent>
<prevsent>furthermore, error analysis showed that some of the errors could also be considered correct, depending on the interpretation of the annotation.
</prevsent>
</prevsection>
<citsent citstr=" W04-3228 ">
dependency structure has recently gained wide interest because it is simple yet provides useful information for many nlp tasks such as sentiment analysis (kessler and nicolov, 2009) or machine translation (gildea, 2004).<papid> W04-3228 </papid></citsent>
<aftsection>
<nextsent>although dependency structure is kind of syntactic structure, it is quite different from phrase structure: phrase structure gives phrase information by grouping constituents whereas dependency structure gives dependency relations between pairs of words.
</nextsent>
<nextsent>many dependency relations (e.g., subject, object) have high correlations with semantic roles (e.g., agent, patient), which makes dependency structure suit able for representing semantic information such as predicate-argument structure.in 2009, the conference on computational natural language learning (conll) opened sharedtask: the participants were supposed to take dependency trees as input and produce semantic role labels as output (hajic?
</nextsent>
<nextsent>et al, 2009).
</nextsent>
<nextsent>the dependency trees were automatically converted from thepenn treebank (marcus et al, 1993), <papid> J93-2004 </papid>which consists of phrase structure trees, using some heuristics (cf.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1636">
<title id=" W10-1811.xml">retrieving correct semantic boundaries in dependency structure </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>many dependency relations (e.g., subject, object) have high correlations with semantic roles (e.g., agent, patient), which makes dependency structure suit able for representing semantic information such as predicate-argument structure.in 2009, the conference on computational natural language learning (conll) opened sharedtask: the participants were supposed to take dependency trees as input and produce semantic role labels as output (hajic?
</prevsent>
<prevsent>et al, 2009).
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
the dependency trees were automatically converted from thepenn treebank (marcus et al, 1993), <papid> J93-2004 </papid>which consists of phrase structure trees, using some heuristics (cf.</citsent>
<aftsection>
<nextsent>section 3).
</nextsent>
<nextsent>the semantic roles were extracted from the propbank (palmer et al, 2005).<papid> J05-1004 </papid>since propbank arguments were originally annotated at the phrase level using the penn treebank and the phrase information got lost during the conversion to the dependency trees, arguments are annotated on headwords instead of phrases in dependency trees; the subtree of each head word is assumed to include the same set of words as the annotated phrase does in phrase structure.</nextsent>
<nextsent>figure 1 shows dependency tree that has been converted from the corresponding phrase structure tree.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1637">
<title id=" W10-1811.xml">retrieving correct semantic boundaries in dependency structure </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the dependency trees were automatically converted from thepenn treebank (marcus et al, 1993), <papid> J93-2004 </papid>which consists of phrase structure trees, using some heuristics (cf.</prevsent>
<prevsent>section 3).</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
the semantic roles were extracted from the propbank (palmer et al, 2005).<papid> J05-1004 </papid>since propbank arguments were originally annotated at the phrase level using the penn treebank and the phrase information got lost during the conversion to the dependency trees, arguments are annotated on headwords instead of phrases in dependency trees; the subtree of each head word is assumed to include the same set of words as the annotated phrase does in phrase structure.</citsent>
<aftsection>
<nextsent>figure 1 shows dependency tree that has been converted from the corresponding phrase structure tree.
</nextsent>
<nextsent>s np1 dt the nns results vp vbp appear pp1 in in np np nn today pos nn news the results appear in today  news root nmod sbj loc nmod nmod root pmod figure 1: phrase vs. dependency structure 91 in the phrase structure tree, arguments of the verb predicate appear are annotated on the phrases:np1 as arg0 and pp1 as argm-loc.
</nextsent>
<nextsent>in the dependency tree, the arguments are annotated on the headwords instead: results as the arg0 and in as the argm-loc.
</nextsent>
<nextsent>in this example, both pp1 and the subtree of in consist of the same set of words {in, today, s, news} (as is the case for np1 and thesubtree of results); therefore, the phrase boundaries for the semantic arguments, called semantic boundaries, are retrieved correctly from the dependency tree.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1638">
<title id=" W10-1811.xml">retrieving correct semantic boundaries in dependency structure </title>
<section> retrieving fine-grained semantic.  </section>
<citcontext>
<prevsection>
<prevsent>first, it is often not clear how punctuation 96 named john who stayed fellow , for years nmod appo oprd dep tmp pmod nmod figure 20: past-participle example 2needs to be annotated in either treebank or prop bank; because of that, annotation for punctuation is not entirely consistent, which makes it hard toevaluate.
</prevsent>
<prevsent>second, although punctuation gives useful information for obtaining semantic boundaries, it is not crucial for semantic roles.
</prevsent>
</prevsection>
<citsent citstr=" N04-1030 ">
in fact, some of the state-of-art semantic role labeling systems, such as assert (pradhan et al, 2004), <papid> N04-1030 </papid>give an option for omitting punctuation from the output.for these reasons, our final model ignores punctuation for semantic boundaries.</citsent>
<aftsection>
<nextsent>6.1 model comparisons.
</nextsent>
<nextsent>the following list describes six models used for the experiments.
</nextsent>
<nextsent>model is the baseline approach that retrieves all words in the subtrees of headwords as semantic boundaries.
</nextsent>
<nextsent>model ii to vi use the heuristics discussed in the previous sections.each model inherits all the heuristics from the previous model and adds new heuristics; therefore, each model is expected to perform better than the previous model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1639">
<title id=" W10-3814.xml">new parameterizations and features for pscfgbased machine translation </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>hierarchical phrase-based mt suffers from spurious ambiguity: single translation for agiven source sentence can usually be accomplished by many different pscfg derivations.
</prevsent>
<prevsent>this problem is exacerbated by syntax-augmented mt with its thousands of nonterminals, and made even worse by its joint source-and-target extension.
</prevsent>
</prevsection>
<citsent citstr=" D08-1023 ">
future research should apply the work of blunsom et al (2008) and blunsom and osborne (2008), <papid> D08-1023 </papid>who marginalize over derivations to find the most probable translation rather than the most probable derivation, to these multi-nonterminal grammars.all source code underlying this work is available under the gnu lesser general public license as part of the samt?</citsent>
<aftsection>
<nextsent>system at: www.cs.cmu.edu/zollmann/samt acknowledgements this work is in part supported by nsf under the cluster exploratory program (grant nsf 0844507), and in part by the us darpa gale program.
</nextsent>
<nextsent>any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of nsf or darpa.
</nextsent>


</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1640">
<title id=" W10-1310.xml">state transition interpolation and map adaptation for hmm based dysart hric speech recognition </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>the study described in this paper investigated the development of medium vocabulary hmm recog nizers for dysart hric speech of various degrees of severity with the following aims: (1) to test the performance of sa systems relative to sd systems, for various degrees of dysarthria severity, (2) to test the performance of an sd system employing transition interpolated hmms relative to an sd system using strictly left-to-right hmms, (3) to test the performance of an sa system with transition-interpolatedhmms relative to an sd system having strictly left to-right hmms and, (4) to see if the results in the above three cases are essentially function of the talkers dysarthria severity.
</prevsent>
<prevsent>2.1 modifications investigated.
</prevsent>
</prevsection>
<citsent citstr=" H91-1053 ">
the following modifications to the hmm structure were studied in our experiments: 2.1.1 adaptation all sa systems were developed by adapting aspeaker-independent system in maximum pos teriori (map) manner, as outlined by gauvain and lee (gauvain and lee, 1991; <papid> H91-1053 </papid>gauvain and lee, 1992).<papid> H92-1036 </papid></citsent>
<aftsection>
<nextsent>map adaptation involves the use of prior knowledge about the model parameter distribution.
</nextsent>
<nextsent>hence, if we know what the parameters of the model are likely to be (before observing any adaptation data) using the prior knowledge, we might well be able to make good use of the limited adaptation data,to obtain decent map estimate.
</nextsent>
<nextsent>for map adaptation purposes, the informative priors that are generally used are the speaker independent model parameters (empirical bayes approach).
</nextsent>
<nextsent>in (gauvain andlee, 1991), <papid> H91-1053 </papid>they derive expressions of map estimates for all hmm parameters except the transition probabilities (gaussian mixture-component means, diagonal gaussian mixture-component co variance matrices and, mixture-component weights) and also provide an initialization scheme for the prior density of these parameters.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1641">
<title id=" W10-1310.xml">state transition interpolation and map adaptation for hmm based dysart hric speech recognition </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>the study described in this paper investigated the development of medium vocabulary hmm recog nizers for dysart hric speech of various degrees of severity with the following aims: (1) to test the performance of sa systems relative to sd systems, for various degrees of dysarthria severity, (2) to test the performance of an sd system employing transition interpolated hmms relative to an sd system using strictly left-to-right hmms, (3) to test the performance of an sa system with transition-interpolatedhmms relative to an sd system having strictly left to-right hmms and, (4) to see if the results in the above three cases are essentially function of the talkers dysarthria severity.
</prevsent>
<prevsent>2.1 modifications investigated.
</prevsent>
</prevsection>
<citsent citstr=" H92-1036 ">
the following modifications to the hmm structure were studied in our experiments: 2.1.1 adaptation all sa systems were developed by adapting aspeaker-independent system in maximum pos teriori (map) manner, as outlined by gauvain and lee (gauvain and lee, 1991; <papid> H91-1053 </papid>gauvain and lee, 1992).<papid> H92-1036 </papid></citsent>
<aftsection>
<nextsent>map adaptation involves the use of prior knowledge about the model parameter distribution.
</nextsent>
<nextsent>hence, if we know what the parameters of the model are likely to be (before observing any adaptation data) using the prior knowledge, we might well be able to make good use of the limited adaptation data,to obtain decent map estimate.
</nextsent>
<nextsent>for map adaptation purposes, the informative priors that are generally used are the speaker independent model parameters (empirical bayes approach).
</nextsent>
<nextsent>in (gauvain andlee, 1991), <papid> H91-1053 </papid>they derive expressions of map estimates for all hmm parameters except the transition probabilities (gaussian mixture-component means, diagonal gaussian mixture-component co variance matrices and, mixture-component weights) and also provide an initialization scheme for the prior density of these parameters.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1644">
<title id=" W10-2002.xml">did social networks shape language evolution a multi agent cognitive simulation </title>
<section> network structures.  </section>
<citcontext>
<prevsection>
<prevsent>the social network controls the interactions that the agents can experience.
</prevsent>
<prevsent>each interaction is an opportunity to develop new signs and adapt the existing communication systems.
</prevsent>
</prevsection>
<citsent citstr=" P07-1102 ">
it can be shown that even separate pairs of agents develop specialized communication systems, both empirically (garrod and doherty, 1994; reitter and moore, 2007; <papid> P07-1102 </papid>kirby and hurford, 2002) and in the specific model used here.when communication partners change, convergence towards common system and the final transmission accuracy is slower (fay et al, 2008).</citsent>
<aftsection>
<nextsent>at this point it is unclear how the structure of the communication network and the learning process interact.
</nextsent>
<nextsent>given that some types of networks show wide distribution of degrees, where some nodes communicate much more often and with wide variety of neighbors, while others communicate less often, recency and frequency of memory access will vary substantially.
</nextsent>
<nextsent>other communication networks may reflect command hierarchies in organizations, which are constructed to ensure, among other things, more predictable information propagation.we hypothesize that the human memory ap 11 paratus and preferred social network structures have co-evolved to be uniquely suited to create macro-organism that adapts its communication structures and reasoning mechanisms to novel situations.
</nextsent>
<nextsent>there is limited opportunity to test such ahypothesis under controlled conditions with sufficiently large human network; however, cognitive models that have been developed to explain and predict human performance in isolated cognitive situations can be leveraged to study the development of sign systems.in simulated network with cognitive models representing agents at the network nodes, and communication between agents along network links, we expect that the social network structures lead to better, if not optimal, adapt ivity during the establishment of communication system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1645">
<title id=" W10-1617.xml">text generation for brazilian portuguese the surface realization task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>adapting an existing application to template based realization system is usually much simpler than in grammar-based approach.
</prevsent>
<prevsent>yet, in order to take full advantage of template definitions and to obtain degree of control over the output text that is comparable to what grammar-based system would allow, it is still necessary to master the use of templates and their rules to fill in each slot adequately.
</prevsent>
</prevsection>
<citsent citstr=" A00-2023 ">
the problem of input specification to surface realization has been discussed at length in the literature in the field - see for example langkilde (2000) ? <papid> A00-2023 </papid>and we of course do not dispute that more sophisticated nlg systems will require detailed input specification.</citsent>
<aftsection>
<nextsent>however, given that the available semantics may not be provide in this level of detail, in this paper we discuss an alternative that 125 may be suitable to simpler applications, namely, those cases in which it is known in advance what the most likely output sentence structures are, for example, because corpus on that particular do main happens to be available.
</nextsent>
<nextsent>in these cases, we will argue that it may be possible to take advantage of the available knowledge to quickly deploy surface realization component based on existing corpora.
</nextsent>
<nextsent>the underlying assumption in our work is that there are simpler nlg applications for which it may be sufficient to select sentence that resembles the desired output, and then modify some or all of its constituents as needed to achieve the desired output.
</nextsent>
<nextsent>for instance, an application that is not linguistically-oriented may produce its output results as natural language text by selecting standard imperative sentence as in please reply to this message?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1646">
<title id=" W10-1617.xml">text generation for brazilian portuguese the surface realization task </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>section 2 briefly discusses related work on surface realization; section 3 provides an overview of our systems architecture; sections 4 describes the extraction of syntactically-structured templates from target corpus and section 5 presents the current features of our template-based surface realization engine.
</prevsent>
<prevsent>finally, section 6 draws preliminary conclusions and describes ongoing work, and section 7 hints at possible collaboration with the wider nlp research community in latin america and elsewhere.
</prevsent>
</prevsection>
<citsent citstr=" A00-2026 ">
mapping an application semantics to surface strings usually involves the use of surface realization grammars or similar resources, which can be either built manually (e.g., bateman, 1997) or acquired automatically from corpus (ratnaparkhi, 2000; <papid> A00-2026 </papid>zhong &amp; stent, 2005; devault et. al., 2008).<papid> W08-1111 </papid></citsent>
<aftsection>
<nextsent>the surface realization task proper can be divided into two relatively independent procedures: domain-dependant mapping from the application semantics onto linguistic structures (including, e.g., lexical choice), and language-oriented task of linearization.
</nextsent>
<nextsent>as pointed out in gatt &amp; reiter (2009), most of the existing systems tend to perform both tasks, but in some cases they focus on the latter, assuming that all lexical choices and other domain-dependent decisions have already been made.
</nextsent>
<nextsent>this is the case for example of simple nlg (gatt &amp; reiter, 2009), surface realization engine implemented as java library for sentence linearization.
</nextsent>
<nextsent>central to the development and use of surface realization system is the kind of input specification that will be expected from the application.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1647">
<title id=" W10-1617.xml">text generation for brazilian portuguese the surface realization task </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>section 2 briefly discusses related work on surface realization; section 3 provides an overview of our systems architecture; sections 4 describes the extraction of syntactically-structured templates from target corpus and section 5 presents the current features of our template-based surface realization engine.
</prevsent>
<prevsent>finally, section 6 draws preliminary conclusions and describes ongoing work, and section 7 hints at possible collaboration with the wider nlp research community in latin america and elsewhere.
</prevsent>
</prevsection>
<citsent citstr=" W08-1111 ">
mapping an application semantics to surface strings usually involves the use of surface realization grammars or similar resources, which can be either built manually (e.g., bateman, 1997) or acquired automatically from corpus (ratnaparkhi, 2000; <papid> A00-2026 </papid>zhong &amp; stent, 2005; devault et. al., 2008).<papid> W08-1111 </papid></citsent>
<aftsection>
<nextsent>the surface realization task proper can be divided into two relatively independent procedures: domain-dependant mapping from the application semantics onto linguistic structures (including, e.g., lexical choice), and language-oriented task of linearization.
</nextsent>
<nextsent>as pointed out in gatt &amp; reiter (2009), most of the existing systems tend to perform both tasks, but in some cases they focus on the latter, assuming that all lexical choices and other domain-dependent decisions have already been made.
</nextsent>
<nextsent>this is the case for example of simple nlg (gatt &amp; reiter, 2009), surface realization engine implemented as java library for sentence linearization.
</nextsent>
<nextsent>central to the development and use of surface realization system is the kind of input specification that will be expected from the application.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1650">
<title id=" W10-1617.xml">text generation for brazilian portuguese the surface realization task </title>
<section> template extraction.  </section>
<citcontext>
<prevsection>
<prevsent>the set of mappings from domain concepts to their dependency-trees (i.e., constituent templates) makes dictionary of realizations in the application domain.
</prevsent>
<prevsent>as in related work in the field (e.g., gatt &amp; reiter, 2009), we presently assume that the actual mappings are to be provided by the application.
</prevsent>
</prevsection>
<citsent citstr=" P00-1059 ">
concept-to-strings mappings are usually handcrafted, but may also be acquired automatically from corpora, as in bangalore &amp; rambow (2000).<papid> P00-1059 </papid></citsent>
<aftsection>
<nextsent>for testing purposes, we have extracted 1,548 instances of concept-to-string mappings from the target corpus, being 1,298 mappings from agent/patient entities to descriptions, pronouns and proper names, and 250 mappings from actions to vps, even though many of them will not be of practical use from the point of view of our intended application.
</nextsent>
<nextsent>using the template definitions from the previous section, we designed simple corpus-based surface realization component for our ongoing project.
</nextsent>
<nextsent>our surface realization module is currently able to accept as an input template id (to be taken as sample structure with inherited default values for the output sentence) and, optionally, parameters representing the alternative semantics of its agent, 128 patient and action constituents.
</nextsent>
<nextsent>alternatively, it is also possible to specify sentence from scratch (that is, without using any existing template as basis) in standard np vp np format.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1652">
<title id=" W10-1617.xml">text generation for brazilian portuguese the surface realization task </title>
<section> surface realization.  </section>
<citcontext>
<prevsection>
<prevsent>more complex or fine-grained dependencies (e.g., the anaphoric reference their?
</prevsent>
<prevsent>in table 2 129above) are not currently implemented.
</prevsent>
</prevsection>
<citsent citstr=" W00-0306 ">
one possible approach to this is standard generate-and select approach to nlg as in langkilde (2000), <papid> A00-2023 </papid>oh &amp; rudnicky (2000) <papid> W00-0306 </papid>and others.</citsent>
<aftsection>
<nextsent>more specifically, we may over-generate all possible realization alternatives and then use statistical language model to select the most likely output.
</nextsent>
<nextsent>in our work we intend to apply similar approach also to handle the lexical choice task, i.e., by selecting the most likely wording for each concept based on language model.
</nextsent>
<nextsent>in this paper we have described simple approach to surface realization based on the reuse of syntac tically-structured templates acquired from corpora.
</nextsent>
<nextsent>although not nearly as flexible as full nlg approach, our system may represent straightforward solution to the problem of input specification, which in our case is simply based on natural language.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1653">
<title id=" W10-1920.xml">applying the tarsqi toolkit to augment text mining of ehrs </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>electronic health records are often the most complete records of patients hospital stay, making them invaluable for retrospective cohort studies.
</prevsent>
<prevsent>however, the free text nature of these documents makes it difficult to extract complex information such as the relative timing of conditions or procedures.
</prevsent>
</prevsection>
<citsent citstr=" W09-1302 ">
while there have been recent successes in this endeavor (irvine et al, 2008; mowery et al, 2009; <papid> W09-1302 </papid>zhou et al, 2007), there is still much to be done.</citsent>
<aftsection>
<nextsent>we present work done to adapt the tarsqi toolkit (ttk) to the medical domain.
</nextsent>
<nextsent>though the use of the ttk and set of auxiliary perl scripts, we perform information extraction over set of354 discharge summaries used in the r3i realist study to answer the following question:which patients can be positively identified as being on statins at the time they were admitted to the hospital?
</nextsent>
<nextsent>the tarsqi toolkit, developed as part of the aquaint workshops, is modular system for automatic temporal and event annotation of natural language?
</nextsent>
<nextsent>in newswire texts (verhagen and pustejovsky, 2008).<papid> C08-3012 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1654">
<title id=" W10-1920.xml">applying the tarsqi toolkit to augment text mining of ehrs </title>
<section> tarsqi toolkit.  </section>
<citcontext>
<prevsection>
<prevsent>though the use of the ttk and set of auxiliary perl scripts, we perform information extraction over set of354 discharge summaries used in the r3i realist study to answer the following question:which patients can be positively identified as being on statins at the time they were admitted to the hospital?
</prevsent>
<prevsent>the tarsqi toolkit, developed as part of the aquaint workshops, is modular system for automatic temporal and event annotation of natural language?
</prevsent>
</prevsection>
<citsent citstr=" C08-3012 ">
in newswire texts (verhagen and pustejovsky, 2008).<papid> C08-3012 </papid></citsent>
<aftsection>
<nextsent>the different modules prepro cess the data, label events and times, create links between times and events (called tlinks?), and mark subordination relationships.
</nextsent>
<nextsent>output from the ttk consists documents annotated in timeml,an xml specification for event and time annotation (pustejovsky et al, 2005).
</nextsent>
<nextsent>of particular interest for this project are evita, the module responsible for finding events in text, and blinker, the module used to create syntactic rule-based links between events and timexes.
</nextsent>
<nextsent>the bodies of the electronic health records used were segmented, with each section having aheader indicating the topic of that section (med ical history?, course of treatment?, discharge medications?, etc).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1655">
<title id=" W10-1610.xml">the emergence of the modern concept of introspection a quantitative linguistic analysis </title>
<section> outlook.  </section>
<citcontext>
<prevsection>
<prevsent>disciplinary perspectives.a first step is systematizing the routines for filtering, processing and analysis of the texts.
</prevsent>
<prevsent>wewill incorporate more terms related to introspection captured in the structure of wordnet, and eventually also incorporate as part of the analysis elements of the graphical structure that underlies this database (sigman and cecchi, 2002).
</prevsent>
</prevsection>
<citsent citstr=" J06-1003 ">
some interesting developments in this area are the measures of semantic similarity between concepts (budanitsky and hirst, 2006; <papid> J06-1003 </papid>pedersen et al, 2004; patwardhan et al,2003).</citsent>
<aftsection>
<nextsent>this measure may result useful for classifying the different topics acquired using topic modeling, taking into account the similarity of the words related to introspection, as an extension to these mantic relationships established by wordnet and the various dictionaries and thesaurii currently available as databases.
</nextsent>
<nextsent>we will also incorporate the notion of concept drift to our topic modeling, expecting it to account for the temporal evolution of the use of introspection.
</nextsent>
<nextsent>a promising proposal for this purpose is thatof dynamic topic modeling.
</nextsent>
<nextsent>we are particularly interested in approaches that require minimal priori intervention; we expect that dynamic model with an unconstrained number of topics, as opposed tothe fixed number of topics proposed in the original paper (blei and lafferty, 2006), may lead more naturally to the identification of potential transitions along the text.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1656">
<title id=" W10-1737.xml">aiding pronoun translation with coreference resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>for this reason hobbs [1978] is often considered to be the most comprehensive early syntactic study of the problem, and as such, often used as baseline to evaluate anaphora resolution methods.
</prevsent>
<prevsent>we use his work and comment on it in later section.
</prevsent>
</prevsection>
<citsent citstr=" J95-2003 ">
another approach to anaphora resolution is based on the centering theory first proposed by grosz et al [1995].<papid> J95-2003 </papid></citsent>
<aftsection>
<nextsent>brennan et al [1987] <papid> P87-1022 </papid>propose an algorithm for pronoun resolution based on centering theory.</nextsent>
<nextsent>once again, the entities are ranked according to their grammatical role, where subject is more salient than existential constructs, which are more salient than direct and indirect objects.walker [1998] further improves the theory of centering theory for anaphora resolution, proposing the idea of cache model to replace the stack model described originally.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1657">
<title id=" W10-1737.xml">aiding pronoun translation with coreference resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>we use his work and comment on it in later section.
</prevsent>
<prevsent>another approach to anaphora resolution is based on the centering theory first proposed by grosz et al [1995].<papid> J95-2003 </papid></prevsent>
</prevsection>
<citsent citstr=" P87-1022 ">
brennan et al [1987] <papid> P87-1022 </papid>propose an algorithm for pronoun resolution based on centering theory.</citsent>
<aftsection>
<nextsent>once again, the entities are ranked according to their grammatical role, where subject is more salient than existential constructs, which are more salient than direct and indirect objects.walker [1998] further improves the theory of centering theory for anaphora resolution, proposing the idea of cache model to replace the stack model described originally.
</nextsent>
<nextsent>another syntactic approach to the problem of co-reference resolution is the use of weighted features by lappin and leass [1994] <papid> J94-4002 </papid>which we present in more details in further section.</nextsent>
<nextsent>this algorithm is based on two modules, syntactic filter followed by system of salience weighting.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1658">
<title id=" W10-1737.xml">aiding pronoun translation with coreference resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>brennan et al [1987] <papid> P87-1022 </papid>propose an algorithm for pronoun resolution based on centering theory.</prevsent>
<prevsent>once again, the entities are ranked according to their grammatical role, where subject is more salient than existential constructs, which are more salient than direct and indirect objects.walker [1998] further improves the theory of centering theory for anaphora resolution, proposing the idea of cache model to replace the stack model described originally.</prevsent>
</prevsection>
<citsent citstr=" J94-4002 ">
another syntactic approach to the problem of co-reference resolution is the use of weighted features by lappin and leass [1994] <papid> J94-4002 </papid>which we present in more details in further section.</citsent>
<aftsection>
<nextsent>this algorithm is based on two modules, syntactic filter followed by system of salience weighting.
</nextsent>
<nextsent>the algorithm gathers all potential noun phrase antecedents of pronoun from the current and close previous sentences.
</nextsent>
<nextsent>the syntactic filter then filters out the ones that are unlikely to be antecedents, according to different rules, including general agreement rules.
</nextsent>
<nextsent>the remaining candidate noun phrases are weighted according to salience factors.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1661">
<title id=" W10-1737.xml">aiding pronoun translation with coreference resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>2.3 co-reference : statistical approach.
</prevsent>
<prevsent>machine learning has also been applied to the problem of anaphora resolution.
</prevsent>
</prevsection>
<citsent citstr=" P05-1020 ">
ng [2005] <papid> P05-1020 </papid>gives survey of the research carried out in this area.</citsent>
<aftsection>
<nextsent>the work by aone and bennett [1995] is among the first in this field.
</nextsent>
<nextsent>it applies machine learning to anaphora resolution on japanese text.
</nextsent>
<nextsent>the authors use set of 66 features, related to both the referent itself and to the relation between the referent and 253its antecedent.
</nextsent>
<nextsent>they include lexical (e.g. cate gory), syntactic (e.g. grammatical role), semantic (e.g. semantic class), and positional (e.g. distance between anaphor and antecedent)?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1662">
<title id=" W10-1737.xml">aiding pronoun translation with coreference resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the authors use set of 66 features, related to both the referent itself and to the relation between the referent and 253its antecedent.
</prevsent>
<prevsent>they include lexical (e.g. cate gory), syntactic (e.g. grammatical role), semantic (e.g. semantic class), and positional (e.g. distance between anaphor and antecedent)?
</prevsent>
</prevsection>
<citsent citstr=" W98-1119 ">
information.ge et al [1998] <papid> W98-1119 </papid>also present statistical algorithm based on the study of statistical data in large corpus and the application of naive bayes model.</citsent>
<aftsection>
<nextsent>the authors report an accuracy rate of 82.9%, or 84.2% with the addition of statistical data on gender categorization of words.
</nextsent>
<nextsent>in more recent work, kehler et al [2004] showa move towards the use of common-sense knowledge to help the resolution of anaphors.
</nextsent>
<nextsent>they use referring probabilities taken from large annotated corpus as knowledge base.
</nextsent>
<nextsent>2.4 shared tasks and evaluation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1663">
<title id=" W10-1737.xml">aiding pronoun translation with coreference resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>pose problems [hobbs, 1978] and the field is also victim of lack of standardization.
</prevsent>
<prevsent>algorithms are evaluated on different texts and large annotated corpora with co-reference information is lacking to check results.
</prevsent>
</prevsection>
<citsent citstr=" C96-1079 ">
a response to these problems came with the creation of shared tasks, such as the muc [grishman and sundheim, 1996] <papid> C96-1079 </papid>which included co-reference sub task [chinchor and hirsch mann, 1997] and led to the creation of the muc-6 and muc-7 corpora.there are other annotation efforts worth mentioning, such as the arrau corpus [poesio and artstein, 2008] which include texts from various sources and deals with previous problems in annotation such as anaphora ambiguity and annotation of information on agreement, grammatical function and reference.</citsent>
<aftsection>
<nextsent>the anaphoric bank and the phrase detectives are both part of the anawiki project [poesio et al, 2008] <papid> L08-1329 </papid>and also promise the creation of standardized corpus.</nextsent>
<nextsent>the first one allows for the sharing of annotated corpora.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1664">
<title id=" W10-1737.xml">aiding pronoun translation with coreference resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>algorithms are evaluated on different texts and large annotated corpora with co-reference information is lacking to check results.
</prevsent>
<prevsent>a response to these problems came with the creation of shared tasks, such as the muc [grishman and sundheim, 1996] <papid> C96-1079 </papid>which included co-reference sub task [chinchor and hirsch mann, 1997] and led to the creation of the muc-6 and muc-7 corpora.there are other annotation efforts worth mentioning, such as the arrau corpus [poesio and artstein, 2008] which include texts from various sources and deals with previous problems in annotation such as anaphora ambiguity and annotation of information on agreement, grammatical function and reference.</prevsent>
</prevsection>
<citsent citstr=" L08-1329 ">
the anaphoric bank and the phrase detectives are both part of the anawiki project [poesio et al, 2008] <papid> L08-1329 </papid>and also promise the creation of standardized corpus.</citsent>
<aftsection>
<nextsent>the first one allows for the sharing of annotated corpora.
</nextsent>
<nextsent>the second is collaborative effort to annotate large corpora through the web.
</nextsent>
<nextsent>in its first year of use, the system saw the resolution of 700,000 pronouns.
</nextsent>
<nextsent>the method has two main aspects: the application of co-reference to annotate pronouns and the subsequent integration into statistical machine translation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1668">
<title id=" W10-1737.xml">aiding pronoun translation with coreference resolution </title>
<section> method.  </section>
<citcontext>
<prevsection>
<prevsent>the implementation of the algorithm we deal with here is fairly different from the one presented in the original paper, and is largely inspired from the javarap implementation [qiu et al, 2004].the first important variation was mentioned earlier and concerns the application of co-referenceresolution to machine translation.
</prevsent>
<prevsent>we concentrate in this work on the resolution of third person pronouns, and we omit reflexive pronouns (it self, themselves) (referred to as lexical anaphora in some works).
</prevsent>
</prevsection>
<citsent citstr=" J03-4003 ">
another variation comes from the use of the collins parser [collins, 2003].<papid> J03-4003 </papid></citsent>
<aftsection>
<nextsent>although work onthe original algorithm uses mccords slot grammar parser [mccord, 1990], work on javarapshows that rules can be created to simulate the categories and predicates used in slot grammar.
</nextsent>
<nextsent>also, preiss [2002] evaluates the use of different parsers for the lappin and leass algorithm, showing that performance of the algorithm is not related to the performance of the parser itself.
</nextsent>
<nextsent>the javarap implementation uses charniak parser, which performs worse than the collins parser in preiss?
</nextsent>
<nextsent>research.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1672">
<title id=" W10-1737.xml">aiding pronoun translation with coreference resolution </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the lefff lexicon, introduced by sagot et al [2006] was used to get agreement features of french words.
</prevsent>
<prevsent>it contains over 80,000 frenchwords,2 along with gender and number information.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
we used the open source moses toolkit [koehn et al, 2007] <papid> P07-2045 </papid>and trained standard phrase-based translation models.</citsent>
<aftsection>
<nextsent>as training data, we used the europarl corpus [koehn, 2005], commonly used parallel corpus in statistical machine translation research.
</nextsent>
<nextsent>while there are also commonly used europarl test sets, these do not contain sentences in sequence for complete documents.
</nextsent>
<nextsent>instead, we used as test set the proceedings from october 5, 2000 - set of 1742 sentences from the held-out portion of thecorpus.
</nextsent>
<nextsent>we translated the test set both with base line system and system trained on the annotated training data and tested on an annotated test set.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1673">
<title id=" W10-2414.xml">classifying wikipedia articles into nersquos using svmrsquos with threshold adjustment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as shown in figure 1, these resources include page redirects, disambiguation pages, informational summaries (infoboxes), cross-language links between articles covering the same topic, and 1 http://en.wikipedia.org/wiki/wikipedia 2 http://en.wikipedia.org/wiki/special:statistics hierarchical tree of categories and their mappings to articles.
</prevsent>
<prevsent>many of the wikipedia pages provide information about concepts and named entities (ne).
</prevsent>
</prevsection>
<citsent citstr=" I08-1071 ">
identifying pages that provide information about different nes can be of great help in variety of nlp applications such as named entity recognition, question answering, information extraction, and machine translation (babych and hartley, 2003; dakka and cucerzan, 2008).<papid> I08-1071 </papid></citsent>
<aftsection>
<nextsent>this paper attempts to identify multilingual wikipedia pages that provide information about different types of ne, namely persons, locations, and organizations.
</nextsent>
<nextsent>the identification is done using support vector machines (svm) classifier that is trained on variety of wikipedia features such as infobox attributes, tokens in text, and category links for different languages aided by cross language links in pages.
</nextsent>
<nextsent>using features from different languages helps in two ways, namely: clues such infobox attributes may exist in one language, but not in the other, and this allows for tagging pages in multiple languages simultaneously.
</nextsent>
<nextsent>to improve svm classification beta-gamma threshold adjustment was used to improve recall of different ne classes and consequently overall measure.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1677">
<title id=" W10-2414.xml">classifying wikipedia articles into nersquos using svmrsquos with threshold adjustment </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>they reported f-measure scores of 78% and 68% for location and person classes respectively.
</prevsent>
<prevsent>the work in this paper relies on using the content of wikipedia pages only.
</prevsent>
</prevsection>
<citsent citstr=" D07-1068 ">
watanabe et al (2007) <papid> D07-1068 </papid>considered the problem of tagging nes in wikipedia as the problem of categorizing anchor texts in articles.</citsent>
<aftsection>
<nextsent>the novelty of their approach is in exploiting dependencies between these anchor texts, which are induced from the html structure of pages.
</nextsent>
<nextsent>they used conditional random fields (crf) for classification and achieved f-measure scores of 79.8 for persons, 72.7 for locations, and 71.6 for organizations.
</nextsent>
<nextsent>this approach tags only nes referenced inside html anchors in articles and not wikipedia articles themselves.
</nextsent>
<nextsent>bhole et al (2007) and dakka and cucerzan (2008) <papid> I08-1071 </papid>used svm classifiers to classify wikipedia articles.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1682">
<title id=" W10-2414.xml">classifying wikipedia articles into nersquos using svmrsquos with threshold adjustment </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>they reported 95% and 93% f-measure for person and location respectively.
</prevsent>
<prevsent>using strictly bag of words approach does not make use of the structure of wikipedia articles and is compared against in the evaluation.
</prevsent>
</prevsection>
<citsent citstr=" P08-1001 ">
richman and schone (2008) <papid> P08-1001 </papid>and nothman et al.</citsent>
<aftsection>
<nextsent>(2008) annotated wikipedia text with ne tags to build multilingual training data for ne taggers.
</nextsent>
<nextsent>the approach of richman and schone (2008) <papid> P08-1001 </papid>is based on using wikipedia category structure to classify wikipedia titles.</nextsent>
<nextsent>identifying nes in other languages is done using cross language links of articles or categories of articles.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1686">
<title id=" W10-1751.xml">meteor next and the meteor paraphrase tables improved evaluation support for five target languages </title>
<section> the meteor-next metric.  </section>
<citcontext>
<prevsection>
<prevsent>for each of the match ers (mi), count the number of words covered by matches of this type in the hypothesis (mi(t)) and reference (mi(r)) and apply matcher weight (wi).the weighted precision and recall are then calcu lated: = ? iwi mi(t) |t| = ? iwi mi(r) |r| the parameterized harmonic mean of and (van rijsbergen, 1979) is then calculated: fmean = r ? ?
</prevsent>
<prevsent>p + (1?
</prevsent>
</prevsection>
<citsent citstr=" W07-0734 ">
?) rto account for gaps and differences in word order, fragmentation penalty (lavie and agarwal, 2007) <papid> W07-0734 </papid>is calculated using the total number of matched words (m) and number of chunks (ch): pen = ? ?</citsent>
<aftsection>
<nextsent>( ch )?
</nextsent>
<nextsent>the final meteor-next score is then calculated: score = (1?
</nextsent>
<nextsent>pen) ? fmean the parameters ?, ?, ?, and wi...wn can be tuned to maximize correlation with various types of human judgments.
</nextsent>
<nextsent>to extend support for wmt10 target languages,we use released parallel corpora to construct paraphrase tables for english, czech, german, spanish, and french.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1687">
<title id=" W10-1751.xml">meteor next and the meteor paraphrase tables improved evaluation support for five target languages </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>for each target language, tuning is conducted as an exhaustive grid search over metric parameters and possible paraphrase tables, resulting in global optima for both.
</prevsent>
<prevsent>to evaluate the impact of our paraphrase tables on metric performance, we tune versions of meteor-next with and without the paraphrasematchers for each language.
</prevsent>
</prevsection>
<citsent citstr=" W09-0441 ">
for further comparison, we tune version of meteor-next using the terp english paraphrase table (snover et al, 2009) <papid> W09-0441 </papid>used by previous versions of the metric.</citsent>
<aftsection>
<nextsent>as shown in table 4, the addition of paraphrases leads to better tuning point for every target language.
</nextsent>
<nextsent>the best scoring subset of paraphrase ta 341 language paraphrases rank consistency ? ?
</nextsent>
<nextsent>wexact wstem wsyn wpar english none 0.619 0.85 2.35 0.45 1.00 0.80 0.60 ? terp 0.625 0.70 1.40 0.25 1.00 0.80 0.80 0.60 de+es+fr 0.629 0.75 0.60 0.35 1.00 0.80 0.80 0.60 czech none 0.564 0.95 0.20 0.70 1.00 ? ?
</nextsent>
<nextsent>en 0.574 0.95 2.15 0.35 1.00 ? ?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1688">
<title id=" W10-1827.xml">an annotation schema for preposition senses in german </title>
<section> an analysis of inter-annotator.  </section>
<citcontext>
<prevsection>
<prevsent>agreement in hierarchical annotation schema weighted kappa statistic (?)
</prevsent>
<prevsent>forms standard for assessing the feasibility of annotation sche mata.
</prevsent>
</prevsection>
<citsent citstr=" J08-4004 ">
based on cohens seminal work (cohen, 1968), artstein and poesio (2008) <papid> J08-4004 </papid>suggest the measure in (4), where ? is calculated as the weighted difference between observed and expected disagreement.</citsent>
<aftsection>
<nextsent>(4)
</nextsent>
<nextsent> = 1 ?  two aspects of the present annotation schema prohibit direct application of this statistic.
</nextsent>
<nextsent>first, the annotation schema makes use of hierarchy with sub types, which leads to overlapping annotation categories.
</nextsent>
<nextsent>as an illustration, assume that one annotator has annotated given preposition with the sense presence, while second annotator makes use of the annotation analytic, the latter being subtype of the first.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1689">
<title id=" W10-1701.xml">a semi supervised word alignment algorithm with partial manual alignments </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the experiment results show an average improvement of 0.33 bleu point across 8 test sets.
</prevsent>
<prevsent>word alignment is used in various natural language processing applications, and most statistical machine translation systems relyon word alignment as preprocessing step.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
traditionally theword alignment model is trained in an unsupervised manner, e.g. the most widely used tool giza++ (och and ney, 2003), <papid> J03-1002 </papid>which implements the ibm models (brown et. al., 1993) <papid> J93-2003 </papid>and the hmm model (vogel et al, 1996).<papid> C96-2141 </papid></citsent>
<aftsection>
<nextsent>however, for language pairs such as chinese-english, the word alignment quality is often unsatisfactory (guzman et al, 2009).
</nextsent>
<nextsent>there has been increasing interest on using manual alignments in word alignment tasks.
</nextsent>
<nextsent>ittycheriah and roukos (2005) <papid> H05-1012 </papid>proposed to useonly manual alignment links in maximum entropy model.</nextsent>
<nextsent>a number of semi-supervised word align ers are proposed (blunsom and cohn, 2006; <papid> P06-1009 </papid>niehues and vogel, 2008; <papid> W08-0303 </papid>taskar et al, 2005; <papid> H05-1010 </papid>liu et al, 2005; <papid> P05-1057 </papid>moore, 2005).<papid> H05-1011 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1690">
<title id=" W10-1701.xml">a semi supervised word alignment algorithm with partial manual alignments </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the experiment results show an average improvement of 0.33 bleu point across 8 test sets.
</prevsent>
<prevsent>word alignment is used in various natural language processing applications, and most statistical machine translation systems relyon word alignment as preprocessing step.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
traditionally theword alignment model is trained in an unsupervised manner, e.g. the most widely used tool giza++ (och and ney, 2003), <papid> J03-1002 </papid>which implements the ibm models (brown et. al., 1993) <papid> J93-2003 </papid>and the hmm model (vogel et al, 1996).<papid> C96-2141 </papid></citsent>
<aftsection>
<nextsent>however, for language pairs such as chinese-english, the word alignment quality is often unsatisfactory (guzman et al, 2009).
</nextsent>
<nextsent>there has been increasing interest on using manual alignments in word alignment tasks.
</nextsent>
<nextsent>ittycheriah and roukos (2005) <papid> H05-1012 </papid>proposed to useonly manual alignment links in maximum entropy model.</nextsent>
<nextsent>a number of semi-supervised word align ers are proposed (blunsom and cohn, 2006; <papid> P06-1009 </papid>niehues and vogel, 2008; <papid> W08-0303 </papid>taskar et al, 2005; <papid> H05-1010 </papid>liu et al, 2005; <papid> P05-1057 </papid>moore, 2005).<papid> H05-1011 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1692">
<title id=" W10-1701.xml">a semi supervised word alignment algorithm with partial manual alignments </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the experiment results show an average improvement of 0.33 bleu point across 8 test sets.
</prevsent>
<prevsent>word alignment is used in various natural language processing applications, and most statistical machine translation systems relyon word alignment as preprocessing step.
</prevsent>
</prevsection>
<citsent citstr=" C96-2141 ">
traditionally theword alignment model is trained in an unsupervised manner, e.g. the most widely used tool giza++ (och and ney, 2003), <papid> J03-1002 </papid>which implements the ibm models (brown et. al., 1993) <papid> J93-2003 </papid>and the hmm model (vogel et al, 1996).<papid> C96-2141 </papid></citsent>
<aftsection>
<nextsent>however, for language pairs such as chinese-english, the word alignment quality is often unsatisfactory (guzman et al, 2009).
</nextsent>
<nextsent>there has been increasing interest on using manual alignments in word alignment tasks.
</nextsent>
<nextsent>ittycheriah and roukos (2005) <papid> H05-1012 </papid>proposed to useonly manual alignment links in maximum entropy model.</nextsent>
<nextsent>a number of semi-supervised word align ers are proposed (blunsom and cohn, 2006; <papid> P06-1009 </papid>niehues and vogel, 2008; <papid> W08-0303 </papid>taskar et al, 2005; <papid> H05-1010 </papid>liu et al, 2005; <papid> P05-1057 </papid>moore, 2005).<papid> H05-1011 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1694">
<title id=" W10-1701.xml">a semi supervised word alignment algorithm with partial manual alignments </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, for language pairs such as chinese-english, the word alignment quality is often unsatisfactory (guzman et al, 2009).
</prevsent>
<prevsent>there has been increasing interest on using manual alignments in word alignment tasks.
</prevsent>
</prevsection>
<citsent citstr=" H05-1012 ">
ittycheriah and roukos (2005) <papid> H05-1012 </papid>proposed to useonly manual alignment links in maximum entropy model.</citsent>
<aftsection>
<nextsent>a number of semi-supervised word align ers are proposed (blunsom and cohn, 2006; <papid> P06-1009 </papid>niehues and vogel, 2008; <papid> W08-0303 </papid>taskar et al, 2005; <papid> H05-1010 </papid>liu et al, 2005; <papid> P05-1057 </papid>moore, 2005).<papid> H05-1011 </papid></nextsent>
<nextsent>these approaches use held-out manual alignments to tune the weights for discriminative models, with the model parameters, model scores or alignment links from unsupervised word align ers as features.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1695">
<title id=" W10-1701.xml">a semi supervised word alignment algorithm with partial manual alignments </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there has been increasing interest on using manual alignments in word alignment tasks.
</prevsent>
<prevsent>ittycheriah and roukos (2005) <papid> H05-1012 </papid>proposed to useonly manual alignment links in maximum entropy model.</prevsent>
</prevsection>
<citsent citstr=" P06-1009 ">
a number of semi-supervised word align ers are proposed (blunsom and cohn, 2006; <papid> P06-1009 </papid>niehues and vogel, 2008; <papid> W08-0303 </papid>taskar et al, 2005; <papid> H05-1010 </papid>liu et al, 2005; <papid> P05-1057 </papid>moore, 2005).<papid> H05-1011 </papid></citsent>
<aftsection>
<nextsent>these approaches use held-out manual alignments to tune the weights for discriminative models, with the model parameters, model scores or alignment links from unsupervised word align ers as features.
</nextsent>
<nextsent>also, several models are proposed to address the problem of improving generative models with small amount of manual data, including model 6 (och and ney, 2003) <papid> J03-1002 </papid>and the model proposed by fraser and marcu (2006) <papid> P06-1097 </papid>and its extension called leaf aligner (fraser and marcu, 2007).<papid> D07-1006 </papid></nextsent>
<nextsent>the approaches use labelled data to tune parameters to combine different components of the ibm models.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1696">
<title id=" W10-1701.xml">a semi supervised word alignment algorithm with partial manual alignments </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there has been increasing interest on using manual alignments in word alignment tasks.
</prevsent>
<prevsent>ittycheriah and roukos (2005) <papid> H05-1012 </papid>proposed to useonly manual alignment links in maximum entropy model.</prevsent>
</prevsection>
<citsent citstr=" W08-0303 ">
a number of semi-supervised word align ers are proposed (blunsom and cohn, 2006; <papid> P06-1009 </papid>niehues and vogel, 2008; <papid> W08-0303 </papid>taskar et al, 2005; <papid> H05-1010 </papid>liu et al, 2005; <papid> P05-1057 </papid>moore, 2005).<papid> H05-1011 </papid></citsent>
<aftsection>
<nextsent>these approaches use held-out manual alignments to tune the weights for discriminative models, with the model parameters, model scores or alignment links from unsupervised word align ers as features.
</nextsent>
<nextsent>also, several models are proposed to address the problem of improving generative models with small amount of manual data, including model 6 (och and ney, 2003) <papid> J03-1002 </papid>and the model proposed by fraser and marcu (2006) <papid> P06-1097 </papid>and its extension called leaf aligner (fraser and marcu, 2007).<papid> D07-1006 </papid></nextsent>
<nextsent>the approaches use labelled data to tune parameters to combine different components of the ibm models.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1697">
<title id=" W10-1701.xml">a semi supervised word alignment algorithm with partial manual alignments </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there has been increasing interest on using manual alignments in word alignment tasks.
</prevsent>
<prevsent>ittycheriah and roukos (2005) <papid> H05-1012 </papid>proposed to useonly manual alignment links in maximum entropy model.</prevsent>
</prevsection>
<citsent citstr=" H05-1010 ">
a number of semi-supervised word align ers are proposed (blunsom and cohn, 2006; <papid> P06-1009 </papid>niehues and vogel, 2008; <papid> W08-0303 </papid>taskar et al, 2005; <papid> H05-1010 </papid>liu et al, 2005; <papid> P05-1057 </papid>moore, 2005).<papid> H05-1011 </papid></citsent>
<aftsection>
<nextsent>these approaches use held-out manual alignments to tune the weights for discriminative models, with the model parameters, model scores or alignment links from unsupervised word align ers as features.
</nextsent>
<nextsent>also, several models are proposed to address the problem of improving generative models with small amount of manual data, including model 6 (och and ney, 2003) <papid> J03-1002 </papid>and the model proposed by fraser and marcu (2006) <papid> P06-1097 </papid>and its extension called leaf aligner (fraser and marcu, 2007).<papid> D07-1006 </papid></nextsent>
<nextsent>the approaches use labelled data to tune parameters to combine different components of the ibm models.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1698">
<title id=" W10-1701.xml">a semi supervised word alignment algorithm with partial manual alignments </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there has been increasing interest on using manual alignments in word alignment tasks.
</prevsent>
<prevsent>ittycheriah and roukos (2005) <papid> H05-1012 </papid>proposed to useonly manual alignment links in maximum entropy model.</prevsent>
</prevsection>
<citsent citstr=" P05-1057 ">
a number of semi-supervised word align ers are proposed (blunsom and cohn, 2006; <papid> P06-1009 </papid>niehues and vogel, 2008; <papid> W08-0303 </papid>taskar et al, 2005; <papid> H05-1010 </papid>liu et al, 2005; <papid> P05-1057 </papid>moore, 2005).<papid> H05-1011 </papid></citsent>
<aftsection>
<nextsent>these approaches use held-out manual alignments to tune the weights for discriminative models, with the model parameters, model scores or alignment links from unsupervised word align ers as features.
</nextsent>
<nextsent>also, several models are proposed to address the problem of improving generative models with small amount of manual data, including model 6 (och and ney, 2003) <papid> J03-1002 </papid>and the model proposed by fraser and marcu (2006) <papid> P06-1097 </papid>and its extension called leaf aligner (fraser and marcu, 2007).<papid> D07-1006 </papid></nextsent>
<nextsent>the approaches use labelled data to tune parameters to combine different components of the ibm models.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1700">
<title id=" W10-1701.xml">a semi supervised word alignment algorithm with partial manual alignments </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there has been increasing interest on using manual alignments in word alignment tasks.
</prevsent>
<prevsent>ittycheriah and roukos (2005) <papid> H05-1012 </papid>proposed to useonly manual alignment links in maximum entropy model.</prevsent>
</prevsection>
<citsent citstr=" H05-1011 ">
a number of semi-supervised word align ers are proposed (blunsom and cohn, 2006; <papid> P06-1009 </papid>niehues and vogel, 2008; <papid> W08-0303 </papid>taskar et al, 2005; <papid> H05-1010 </papid>liu et al, 2005; <papid> P05-1057 </papid>moore, 2005).<papid> H05-1011 </papid></citsent>
<aftsection>
<nextsent>these approaches use held-out manual alignments to tune the weights for discriminative models, with the model parameters, model scores or alignment links from unsupervised word align ers as features.
</nextsent>
<nextsent>also, several models are proposed to address the problem of improving generative models with small amount of manual data, including model 6 (och and ney, 2003) <papid> J03-1002 </papid>and the model proposed by fraser and marcu (2006) <papid> P06-1097 </papid>and its extension called leaf aligner (fraser and marcu, 2007).<papid> D07-1006 </papid></nextsent>
<nextsent>the approaches use labelled data to tune parameters to combine different components of the ibm models.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1705">
<title id=" W10-1701.xml">a semi supervised word alignment algorithm with partial manual alignments </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a number of semi-supervised word align ers are proposed (blunsom and cohn, 2006; <papid> P06-1009 </papid>niehues and vogel, 2008; <papid> W08-0303 </papid>taskar et al, 2005; <papid> H05-1010 </papid>liu et al, 2005; <papid> P05-1057 </papid>moore, 2005).<papid> H05-1011 </papid></prevsent>
<prevsent>these approaches use held-out manual alignments to tune the weights for discriminative models, with the model parameters, model scores or alignment links from unsupervised word align ers as features.</prevsent>
</prevsection>
<citsent citstr=" P06-1097 ">
also, several models are proposed to address the problem of improving generative models with small amount of manual data, including model 6 (och and ney, 2003) <papid> J03-1002 </papid>and the model proposed by fraser and marcu (2006) <papid> P06-1097 </papid>and its extension called leaf aligner (fraser and marcu, 2007).<papid> D07-1006 </papid></citsent>
<aftsection>
<nextsent>the approaches use labelled data to tune parameters to combine different components of the ibm models.
</nextsent>
<nextsent>2005?
</nextsent>
<nextsent>2005nian de xiatian the summer of 2005 figure 1: partial and full alignment san interesting question is, if we only have partial alignments of sentences, can we make use ofthem?
</nextsent>
<nextsent>figure 1 shows the comparison of partial alignments (the bold link) and full alignments (both of the dashed and the bold links).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1706">
<title id=" W10-1701.xml">a semi supervised word alignment algorithm with partial manual alignments </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a number of semi-supervised word align ers are proposed (blunsom and cohn, 2006; <papid> P06-1009 </papid>niehues and vogel, 2008; <papid> W08-0303 </papid>taskar et al, 2005; <papid> H05-1010 </papid>liu et al, 2005; <papid> P05-1057 </papid>moore, 2005).<papid> H05-1011 </papid></prevsent>
<prevsent>these approaches use held-out manual alignments to tune the weights for discriminative models, with the model parameters, model scores or alignment links from unsupervised word align ers as features.</prevsent>
</prevsection>
<citsent citstr=" D07-1006 ">
also, several models are proposed to address the problem of improving generative models with small amount of manual data, including model 6 (och and ney, 2003) <papid> J03-1002 </papid>and the model proposed by fraser and marcu (2006) <papid> P06-1097 </papid>and its extension called leaf aligner (fraser and marcu, 2007).<papid> D07-1006 </papid></citsent>
<aftsection>
<nextsent>the approaches use labelled data to tune parameters to combine different components of the ibm models.
</nextsent>
<nextsent>2005?
</nextsent>
<nextsent>2005nian de xiatian the summer of 2005 figure 1: partial and full alignment san interesting question is, if we only have partial alignments of sentences, can we make use ofthem?
</nextsent>
<nextsent>figure 1 shows the comparison of partial alignments (the bold link) and full alignments (both of the dashed and the bold links).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1707">
<title id=" W10-1701.xml">a semi supervised word alignment algorithm with partial manual alignments </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the functionality is considered useful in many scenarios.
</prevsent>
<prevsent>for example, the researchers can analyse the alignments generated by giza++ and fix common error patterns, and perform training again.
</prevsent>
</prevsection>
<citsent citstr=" W09-1903 ">
on another way, an application can combine active learning (arora et al, 2009) <papid> W09-1903 </papid>and crowdsourcing, asking non-expertise such as workers of amazon mechanical turk to label crucial alignment links that can improve the system with low cost, which is now promising methodology in nlp areas (callison-burch, 2009).in this paper, we propose semi-supervised extension of the ibm models that can utilize partial alignment links.</citsent>
<aftsection>
<nextsent>more specifically, we are seeking answers for the following questions: ? given the partial alignment of sentence, how to find the most probable alignment that is consistent with the partial alignment.
</nextsent>
<nextsent>given set of partially aligned sentences, how to get the parameters that maximize the likelihood of the sentence pairs with alignments consistent with the partial alignments ? given set of partially aligned sentences, with conflicting partial alignments, how to answer the two questions above.
</nextsent>
<nextsent>in the proposed approach, the manual partial alignment links are treated as ground truth, therefore, they will be fixed.
</nextsent>
<nextsent>however, for all other links we make no additional assumption.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1734">
<title id=" W10-1701.xml">a semi supervised word alignment algorithm with partial manual alignments </title>
<section> semi-supervised word alignment.  </section>
<citcontext>
<prevsection>
<prevsent>by combining the constrained em algorithm and the count collection, the viterbi alignment is guaranteed to be consistent with the fixed alignment links, and the sufficient statistics is guaranteed to contain no statistics from inconsistent alignments.
</prevsent>
<prevsent>2.4 training scheme.
</prevsent>
</prevsection>
<citsent citstr=" W08-0509 ">
we extend the multi-thread giza++ (gao and vogel, 2008) <papid> W08-0509 </papid>to load the alignments from modified corpus file.</citsent>
<aftsection>
<nextsent>the links are appended to the end of each sentence in the corpus file in the form of indices pairs, which will be read by the alignerduring training.
</nextsent>
<nextsent>in practice, we first training unconstrained models up to model 4, and then switch to constrained model 4 and continue training for several iterations, the actual number of training order is: 5 iterations of model 1, 5 iterations of hmm, 3 iterations of model 3, 3 iterations of unconstrained model 4 and 3 iterations of constrained model 4.
</nextsent>
<nextsent>because here we actually have more model 4 iterations, to make the comparison fair, in all the experiments below we perform 6 iterations of model 4 in the baseline systems.
</nextsent>
<nextsent>given the algorithm described in the section 2, we still face the problem of obtaining alignment links to constrain the system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1735">
<title id=" W10-1701.xml">a semi supervised word alignment algorithm with partial manual alignments </title>
<section> obtaining alignment links.  </section>
<citcontext>
<prevsection>
<prevsent>3.2 using heuristics on un labelled data.
</prevsent>
<prevsent>another possible way of getting alignment linksis to make use of heuristics to generate high precision-low-recall links and feed them into thealigner.
</prevsent>
</prevsection>
<citsent citstr=" P09-1105 ">
the heuristics can be number mapping, person name translator or more sophisticated methods such as alignment confidence measure (huang, 2009).<papid> P09-1105 </papid></citsent>
<aftsection>
<nextsent>in this paper we propose to use manual dictionaries to generate alignment links.first we filter out from the dictionary the entries with high frequency in the source side, andthen build an aligner based on it.
</nextsent>
<nextsent>the aligner out put links between words if them match an entry in the dictionary.
</nextsent>
<nextsent>the method can be applied onlarge un labelled corpus and generate large number of links, after that we use the links as manual alignment links in proposed method.
</nextsent>
<nextsent>the readers may notice that giza++ supports utilizing manual dictionary as well, however it is different from our method.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1736">
<title id=" W10-1701.xml">a semi supervised word alignment algorithm with partial manual alignments </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we used the corpusldc2006g05 with 25 million words.
</prevsent>
<prevsent>the training scheme is the same as previous experiments, where the filtered ldc dictionary is used.
</prevsent>
</prevsection>
<citsent citstr=" J04-4002 ">
after word alignment, standard moses phrase extraction tool (och and ney, 2004) <papid> J04-4002 </papid>is used to build the translation models and finally moses (koehn et. al., 2007) <papid> P07-2045 </papid>is used to tune and decode.</citsent>
<aftsection>
<nextsent>we tune the system on the nist mt06 test set (1664 sentences), and test on the mt08 (1357 sentences) and the dev075 (1211 sentences) test sets, which are further divided into two sources (newswire and web data).
</nextsent>
<nextsent>a trigram language 5it is test set used by gale rosseta team 8 mt02 mt03 mt04 mt05 mt08-nw mt08-wb dev07nw dev07wb baseline 28.87 27.82 30.08 26.77 25.09 17.72 24.88 21.76 dict-link 29.59 27.67 31.01 27.13 25.14 17.96 25.51 21.88 table 4: comparison of the performance of baseline and the alignment generated by new aligner with dictionary links in bleu scores precision recall aer orl 100.00 62.61 23.00 ch-en f/ne 89.25 62.47 26.50 f/we 99.59 62.47 23.22 orl 100.00 80.98 10.51 en-ch f/ne 93.49 80.79 13.32 f/we 99.82 80.79 10.70 f/ne 90.79 87.49 10.89comb f/we 99.78 87.23 6.92 orl 100.00 72.07 16.23 ar-en f/ne 82.46 72.00 23.13 f/we 94.25 72.00 18.36 orl 100.00 90.14 5.18 en-ar f/ne 79.81 90.06 15.37 f/we 93.27 90.10 8.34 f/ne 78.91 93.07 14.59comb f/we 94.64 93.21 6.08 table 3: alignment quality of oracle alignment and force alignment, the rows with orl?
</nextsent>
<nextsent>in the second column are oracle alignments, f/ne?
</nextsent>
<nextsent>and f/we?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1737">
<title id=" W10-1701.xml">a semi supervised word alignment algorithm with partial manual alignments </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we used the corpusldc2006g05 with 25 million words.
</prevsent>
<prevsent>the training scheme is the same as previous experiments, where the filtered ldc dictionary is used.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
after word alignment, standard moses phrase extraction tool (och and ney, 2004) <papid> J04-4002 </papid>is used to build the translation models and finally moses (koehn et. al., 2007) <papid> P07-2045 </papid>is used to tune and decode.</citsent>
<aftsection>
<nextsent>we tune the system on the nist mt06 test set (1664 sentences), and test on the mt08 (1357 sentences) and the dev075 (1211 sentences) test sets, which are further divided into two sources (newswire and web data).
</nextsent>
<nextsent>a trigram language 5it is test set used by gale rosseta team 8 mt02 mt03 mt04 mt05 mt08-nw mt08-wb dev07nw dev07wb baseline 28.87 27.82 30.08 26.77 25.09 17.72 24.88 21.76 dict-link 29.59 27.67 31.01 27.13 25.14 17.96 25.51 21.88 table 4: comparison of the performance of baseline and the alignment generated by new aligner with dictionary links in bleu scores precision recall aer orl 100.00 62.61 23.00 ch-en f/ne 89.25 62.47 26.50 f/we 99.59 62.47 23.22 orl 100.00 80.98 10.51 en-ch f/ne 93.49 80.79 13.32 f/we 99.82 80.79 10.70 f/ne 90.79 87.49 10.89comb f/we 99.78 87.23 6.92 orl 100.00 72.07 16.23 ar-en f/ne 82.46 72.00 23.13 f/we 94.25 72.00 18.36 orl 100.00 90.14 5.18 en-ar f/ne 79.81 90.06 15.37 f/we 93.27 90.10 8.34 f/ne 78.91 93.07 14.59comb f/we 94.64 93.21 6.08 table 3: alignment quality of oracle alignment and force alignment, the rows with orl?
</nextsent>
<nextsent>in the second column are oracle alignments, f/ne?
</nextsent>
<nextsent>and f/we?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1738">
<title id=" W10-1701.xml">a semi supervised word alignment algorithm with partial manual alignments </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we also listed the scores of heuristic ally symmetrized alignment4.
</prevsent>
<prevsent>(comb?)model trained from gigaword v1 and v2 corpora is used.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
table 4 shows the comparison of the performances on bleu metric (papineni et al., 2002).<papid> P02-1040 </papid></citsent>
<aftsection>
<nextsent>as we can observe from the results, the proposed method outperforms the baseline on all test sets except mt03, and has significant6 improvement on mt02 (+0.72), mt04 (+0.93), and dev07nw(+0.63).
</nextsent>
<nextsent>the average improvement across all test sets is 0.35 bleu points.as summary, the purpose of the this experiment is to demonstrate an important characteristic of the proposed method.
</nextsent>
<nextsent>even with imperfect manual alignment links, we can get better alignment by applying our method.
</nextsent>
<nextsent>this characteristic opens possibility to integrate other more sophisticated aligners.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1739">
<title id=" W10-1738.xml">jane open source hierarchical translation extended with reordering and lexicon models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper we give an overview of its main features.
</prevsent>
<prevsent>we also introduce novel reordering model for the hierarchical phrase-basedapproach which further enhances translation performance, and analyze the effect some recent extended lexicon models have on the performance of the system.
</prevsent>
</prevsection>
<citsent citstr=" J07-2003 ">
we present new open source toolkit for hierarchical phrase-based translation, as described in (chiang, 2007).<papid> J07-2003 </papid></citsent>
<aftsection>
<nextsent>the hierarchical phrase model is an extension of the standard phrase model, where the phrases are allowed to have gaps?.
</nextsent>
<nextsent>inthis way, long-distance dependencies and reorderings can be modelled inconsistent way.
</nextsent>
<nextsent>as in nearly all current statistical approaches to machine translation, this model is embedded in log-linear model combination.
</nextsent>
<nextsent>rwth has been developing this tool during the last two years and it was used successfully in numerous machine translation evaluations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1740">
<title id=" W10-1738.xml">jane open source hierarchical translation extended with reordering and lexicon models </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>as we go over the features of the system we will provide the corresponding references.jane is not the first system of its kind, although it provides some unique features.
</prevsent>
<prevsent>there are other open source hierarchical decoders available.
</prevsent>
</prevsection>
<citsent citstr=" W06-3119 ">
these include ? samt (zollmann and venugopal, 2006): <papid> W06-3119 </papid>the original version is not maintained any more and we had problems working on big corpora.</citsent>
<aftsection>
<nextsent>a new version which requires hadoop has just been released, however the documentation is still missing.
</nextsent>
<nextsent>joshua (li et al, 2009): <papid> W09-0424 </papid>decoder written in java by the john hopkins university.</nextsent>
<nextsent>this project is the most similar to our own, how ever both were developed independently and each one has some unique features.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1741">
<title id=" W10-1738.xml">jane open source hierarchical translation extended with reordering and lexicon models </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>these include ? samt (zollmann and venugopal, 2006): <papid> W06-3119 </papid>the original version is not maintained any more and we had problems working on big corpora.</prevsent>
<prevsent>a new version which requires hadoop has just been released, however the documentation is still missing.</prevsent>
</prevsection>
<citsent citstr=" W09-0424 ">
joshua (li et al, 2009): <papid> W09-0424 </papid>decoder written in java by the john hopkins university.</citsent>
<aftsection>
<nextsent>this project is the most similar to our own, how ever both were developed independently and each one has some unique features.
</nextsent>
<nextsent>a brief comparison between these two systems is included in section 5.1.
</nextsent>
<nextsent>? moses (koehn et al, 2007): <papid> P07-2045 </papid>the de-facto standard phrase-based translation decoder has now been extended to support hierarchical translation.</nextsent>
<nextsent>this is still in an experimental branch, however.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1742">
<title id=" W10-1738.xml">jane open source hierarchical translation extended with reordering and lexicon models </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>this project is the most similar to our own, how ever both were developed independently and each one has some unique features.
</prevsent>
<prevsent>a brief comparison between these two systems is included in section 5.1.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
? moses (koehn et al, 2007): <papid> P07-2045 </papid>the de-facto standard phrase-based translation decoder has now been extended to support hierarchical translation.</citsent>
<aftsection>
<nextsent>this is still in an experimental branch, however.
</nextsent>
<nextsent>in this section we will only give brief overview of the features implemented in jane.
</nextsent>
<nextsent>for detailed explanation of previously published algo 262rithms and methods, we refer to the given literature.
</nextsent>
<nextsent>3.1 search algorithms.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1743">
<title id=" W10-1738.xml">jane open source hierarchical translation extended with reordering and lexicon models </title>
<section> features.  </section>
<citcontext>
<prevsection>
<prevsent>from the cyk+ chart we extract hypergraph representing the parsing space.
</prevsent>
<prevsent>in second step the translations are generated,computing the language model scores in an integrated fashion.
</prevsent>
</prevsection>
<citsent citstr=" P07-1019 ">
both the cube pruning and cube growing algorithms (huang and chiang, 2007) <papid> P07-1019 </papid>are implemented.</citsent>
<aftsection>
<nextsent>for the latter case, the extensions concerning the language model heuristics similar to (vilar and ney, 2009) have also been included.
</nextsent>
<nextsent>3.2 language models.
</nextsent>
<nextsent>jane supports four formats for n-gram language models: ? the arpa format for language models.
</nextsent>
<nextsent>we use the sri toolkit (stolcke, 2002) to support this format.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1745">
<title id=" W10-1738.xml">jane open source hierarchical translation extended with reordering and lexicon models </title>
<section> features.  </section>
<citcontext>
<prevsection>
<prevsent>in order to reduce memory consumption, the language model can be reloaded for every sentence, filtering the n-grams that will be needed for scoring the possible translations.
</prevsent>
<prevsent>this format is specially useful for this case.
</prevsent>
</prevsection>
<citsent citstr=" D07-1049 ">
randomized lms as described in (talbot and osborne, 2007), <papid> D07-1049 </papid>using the open source implementation made available by the authors of the paper.</citsent>
<aftsection>
<nextsent>this approach uses space efficient but approximate representation of the set of n-grams in the language model.
</nextsent>
<nextsent>in particular the probability for unseen n-grams may be overestimated.
</nextsent>
<nextsent>an in-house, exact representation format with on-demand loading of n-grams, using the internal prefix-tree implementation whichis also used for phrase storage (see also section 3.9).
</nextsent>
<nextsent>several language models (also of mixed formats)can be used during search.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1747">
<title id=" W10-1738.xml">jane open source hierarchical translation extended with reordering and lexicon models </title>
<section> features.  </section>
<citcontext>
<prevsection>
<prevsent>in search, they are considered as additional feature functions of the translation rules.the decoder is able to handle an arbitrary number of non-terminal symbols.
</prevsent>
<prevsent>the extraction hasbeen extended so that the extraction of samt rules is included (zollmann and venugopal, 2006) <papid> W06-3119 </papid>but this approach is not fully supported (theremay be empty parses due to the extended number of non-terminals).</prevsent>
</prevsection>
<citsent citstr=" N09-1027 ">
we instead opted to support the generalization presented in (venugopal et al., 2009), <papid> N09-1027 </papid>where the information about the new non-terminals is included as an additional feature in the log-linear model.</citsent>
<aftsection>
<nextsent>in addition, dependency information in the spirit of (shen et al, 2008) <papid> P08-1066 </papid>is included.</nextsent>
<nextsent>jane features models for string-to-dependency language models and computes various scores based on the well-formedness of the resulting dependency tree.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1748">
<title id=" W10-1738.xml">jane open source hierarchical translation extended with reordering and lexicon models </title>
<section> features.  </section>
<citcontext>
<prevsection>
<prevsent>the extraction hasbeen extended so that the extraction of samt rules is included (zollmann and venugopal, 2006) <papid> W06-3119 </papid>but this approach is not fully supported (theremay be empty parses due to the extended number of non-terminals).</prevsent>
<prevsent>we instead opted to support the generalization presented in (venugopal et al., 2009), <papid> N09-1027 </papid>where the information about the new non-terminals is included as an additional feature in the log-linear model.</prevsent>
</prevsection>
<citsent citstr=" P08-1066 ">
in addition, dependency information in the spirit of (shen et al, 2008) <papid> P08-1066 </papid>is included.</citsent>
<aftsection>
<nextsent>jane features models for string-to-dependency language models and computes various scores based on the well-formedness of the resulting dependency tree.
</nextsent>
<nextsent>jane supports the stanford parsing format,1 but can be easily extended to other parsers.
</nextsent>
<nextsent>3.4 additional reordering models.
</nextsent>
<nextsent>in the standard formulation of the hierarchical phrase-based translation model two additional rules are added: ? s0x1, s0x1?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1749">
<title id=" W10-1738.xml">jane open source hierarchical translation extended with reordering and lexicon models </title>
<section> features.  </section>
<citcontext>
<prevsection>
<prevsent>in the hierarchical model,the reordering is already integrated in the translation formalism, but there are still cases where the required reorderings are not captured by the hierarchical phrases alone.
</prevsent>
<prevsent>the flexibility of the grammar formalism allows us to add additional reordering models without the need to explicit ely modify the code for supporting them.
</prevsent>
</prevsection>
<citsent citstr=" J97-3002 ">
the most straightforward example would 1http://nlp.stanford.edu/software/lex-parser.shtml 263 be to include the itg-reorderings (wu, 1997), <papid> J97-3002 </papid>by adding following rule ? s0s1, s1s0?</citsent>
<aftsection>
<nextsent>(2) we can also model other reordering constraints.as an example, phrase-level ibm reordering constraints with window length of 1 can be included substituting the rules in equation (1) with following rules ? m0,m0?
</nextsent>
<nextsent>s ? m0s1,m0s1?
</nextsent>
<nextsent>s ? b0m1,m1b0?
</nextsent>
<nextsent>m ? x0, x0?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1750">
<title id=" W10-1738.xml">jane open source hierarchical translation extended with reordering and lexicon models </title>
<section> features.  </section>
<citcontext>
<prevsection>
<prevsent>this approach has recently been shown to improve the translation results of conventional phrase-based systems.
</prevsent>
<prevsent>in this section, we briefly review the basic aspects of these extended lexicon models.
</prevsent>
</prevsection>
<citsent citstr=" D09-1022 ">
they are similar to (mauser et al, 2009), <papid> D09-1022 </papid>and we refer there for more detailed exposition on the training procedures and results in conventional phrase-based decoding.</citsent>
<aftsection>
<nextsent>note that the training for these models is not distributed together with jane.
</nextsent>
<nextsent>3.5.1 discriminative word lexicon the first of the two lexicon models is denoted as discriminative word lexicon (dwl) and acts as statistical classifier that decides whether word from the target vocabulary should be included ina translation hypothesis.
</nextsent>
<nextsent>for that purpose, it considers all the words from the source sentence, butdoes not take any position information into account, i.e. it operates on sets, not on sequences or even trees.
</nextsent>
<nextsent>the probability of word being part of the target sentence, given set of source words, are decomposed into binary features, one for each source vocabulary entry.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1751">
<title id=" W10-1738.xml">jane open source hierarchical translation extended with reordering and lexicon models </title>
<section> features.  </section>
<citcontext>
<prevsection>
<prevsent>if not.
</prevsent>
<prevsent>as the left part of the product in equation (4) is constant given source sentence, it can be dropped, which enables us to score partial hypotheses during search.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
3.5.2 triplet lexicon the second lexicon model we employ in jane,the triplet lexicon model, is in many aspects related to ibm model 1 (brown et al, 1993), <papid> J93-2003 </papid>but extends it with an additional word in the conditioning part of the lexical probabilities.</citsent>
<aftsection>
<nextsent>this introduces means for an improved representation of long-range dependencies in the data.
</nextsent>
<nextsent>like ibm model 1, the triplets are trained iterativelywith the expectation-maximization (em) algorithm (dempster et al, 1977).
</nextsent>
<nextsent>jane implements the so-called inverse triplet model p(e|f, ?).the triplet lexicon model score t(?)
</nextsent>
<nextsent>of the application of rule ? ??, ??
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1752">
<title id=" W10-1738.xml">jane open source hierarchical translation extended with reordering and lexicon models </title>
<section> features.  </section>
<citcontext>
<prevsection>
<prevsent>non-terminals in ? have to be skipped when the rule is scored.in jane, we also implemented scoring for variant of the triplet lexicon model called the path constrained (or path-aligned) triplet model.
</prevsent>
<prevsent>the characteristic of path-constrained triplets is that the first trigger is restricted to the aligned target word e. the second trigger ? is allowed to move along the whole remaining source sentence.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
for the training of the model, we use word alignment information obtained by giza++ (och and ney, 2003).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>to be able to apply the model in search,jane has to be run with phrase table that contains word alignment for each phrase, too, with the exception of phrases which are composed purely of non-terminals.
</nextsent>
<nextsent>janes phrase extraction can optionally supply this information from the training data.
</nextsent>
<nextsent>(hasan et al, 2008) <papid> D08-1039 </papid>and (hasan and ney, 2009) employ similar techniques and provide some more discussion on the path-aligned variant of the model and other possible restrictions.</nextsent>
<nextsent>3.6 forced alignments.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1753">
<title id=" W10-1738.xml">jane open source hierarchical translation extended with reordering and lexicon models </title>
<section> features.  </section>
<citcontext>
<prevsection>
<prevsent>to be able to apply the model in search,jane has to be run with phrase table that contains word alignment for each phrase, too, with the exception of phrases which are composed purely of non-terminals.
</prevsent>
<prevsent>janes phrase extraction can optionally supply this information from the training data.
</prevsent>
</prevsection>
<citsent citstr=" D08-1039 ">
(hasan et al, 2008) <papid> D08-1039 </papid>and (hasan and ney, 2009) employ similar techniques and provide some more discussion on the path-aligned variant of the model and other possible restrictions.</citsent>
<aftsection>
<nextsent>3.6 forced alignments.
</nextsent>
<nextsent>jane has also preliminary support for forced alignments between given source and target sentence.
</nextsent>
<nextsent>given sentence in the source language and its translation in the target language, we find the best way the source sentence can be translated intothe given target sentence, using the available inventory of phrases.
</nextsent>
<nextsent>this is needed for more advanced training approaches like the ones presented in (blunsom et al, 2008) <papid> P08-1024 </papid>or (cmejrek et al, 2009).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1754">
<title id=" W10-1738.xml">jane open source hierarchical translation extended with reordering and lexicon models </title>
<section> features.  </section>
<citcontext>
<prevsection>
<prevsent>jane has also preliminary support for forced alignments between given source and target sentence.
</prevsent>
<prevsent>given sentence in the source language and its translation in the target language, we find the best way the source sentence can be translated intothe given target sentence, using the available inventory of phrases.
</prevsent>
</prevsection>
<citsent citstr=" P08-1024 ">
this is needed for more advanced training approaches like the ones presented in (blunsom et al, 2008) <papid> P08-1024 </papid>or (cmejrek et al, 2009).</citsent>
<aftsection>
<nextsent>as reported in these papers, due to the restrictions in the phrase extraction process, not all sentences in the training corpus can be aligned in this way.
</nextsent>
<nextsent>3.7 optimization methods.
</nextsent>
<nextsent>two method based on n-best for minimum error rate training (mert) of the parameters of the loglinear model are included in jane.
</nextsent>
<nextsent>the first one is the procedure described in (och, 2003), <papid> P03-1021 </papid>which has become standard in the machine translation community.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1755">
<title id=" W10-1738.xml">jane open source hierarchical translation extended with reordering and lexicon models </title>
<section> features.  </section>
<citcontext>
<prevsection>
<prevsent>3.7 optimization methods.
</prevsent>
<prevsent>two method based on n-best for minimum error rate training (mert) of the parameters of the loglinear model are included in jane.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
the first one is the procedure described in (och, 2003), <papid> P03-1021 </papid>which has become standard in the machine translation community.</citsent>
<aftsection>
<nextsent>we use an in-house implementation of the method.
</nextsent>
<nextsent>the second one is the mira algorithm, first applied for machine translation in (chiang et al, 2009).<papid> N09-1025 </papid></nextsent>
<nextsent>this algorithm is more adequate when the number of parameters to optimize is large.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1756">
<title id=" W10-1738.xml">jane open source hierarchical translation extended with reordering and lexicon models </title>
<section> features.  </section>
<citcontext>
<prevsection>
<prevsent>the first one is the procedure described in (och, 2003), <papid> P03-1021 </papid>which has become standard in the machine translation community.</prevsent>
<prevsent>we use an in-house implementation of the method.</prevsent>
</prevsection>
<citsent citstr=" N09-1025 ">
the second one is the mira algorithm, first applied for machine translation in (chiang et al, 2009).<papid> N09-1025 </papid></citsent>
<aftsection>
<nextsent>this algorithm is more adequate when the number of parameters to optimize is large.
</nextsent>
<nextsent>if the numerical recipes library (press et al, 2002) is available, an additional general purpose optimization tool is also compiled.
</nextsent>
<nextsent>using this tool single-best optimization procedure based on the downhill simplex method (nelder and mead, 1965) is included.
</nextsent>
<nextsent>this method, however, can be considered deprecated in favour of the above mentioned methods.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1757">
<title id=" W10-1738.xml">jane open source hierarchical translation extended with reordering and lexicon models </title>
<section> features.  </section>
<citcontext>
<prevsection>
<prevsent>we thustry to achieve loose coupling in the implementation.
</prevsent>
<prevsent>in addition flexible prefix tree implementation with on-demand loading capabilities is included aspart of the code.
</prevsent>
</prevsection>
<citsent citstr=" N07-1062 ">
this class has been used for implementing on-demand loading of phrases in the spirit of (zens and ney, 2007) <papid> N07-1062 </papid>and the on-demandn-gram format described in section 3.2, in addition to some intermediate steps in the phrase extraction process.</citsent>
<aftsection>
<nextsent>the code may also be reused in other, independent projects.
</nextsent>
<nextsent>3.10 code.
</nextsent>
<nextsent>the main core of jane has been implemented in c++.
</nextsent>
<nextsent>our guideline was to write code that was correct, maintainable and efficient.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1758">
<title id=" W10-1738.xml">jane open source hierarchical translation extended with reordering and lexicon models </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>4.2 nist arabic-english.
</prevsent>
<prevsent>we also show results on the arabic-englishnist08 task, using the nist06 set as development set.
</prevsent>
</prevsection>
<citsent citstr=" W09-0434 ">
it has been reported in other work that the hierarchical system is not competitive with phrase-based system for this language pair (birchet al, 2009).<papid> W09-0434 </papid></citsent>
<aftsection>
<nextsent>we report the figures of our stateof-the-art phrase-based system as comparison (de noted as pbt).
</nextsent>
<nextsent>as can be seen from table 3, the baseline jane system is in fact 0.6% worse in bleu and1.0% worse inter than the baseline pbt system.
</nextsent>
<nextsent>when we include the extended lexicon models we see that the difference in performance is reduced.
</nextsent>
<nextsent>for jane the extended lexicon models give an improvement of up to 1.9% in bleu and 1.7% inter, respectively, bringing the system on parwith the pbt system extended with the same lexicon models, and obtaining an even slightly better bleu score.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1759">
<title id=" W10-2501.xml">preservation of recognizability for synchronous tree substitution grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>with the help of characterization of the expressive powerof stsg in terms of weighted tree bimor phisms, we show that both the forward andthe backward application of an stsg preserve recognizability of weighted tree languages in all reasonable cases.
</prevsent>
<prevsent>as consequence, both the domain and the rangeof an stsg without chain rules are recognizable weighted tree languages.
</prevsent>
</prevsection>
<citsent citstr=" P01-1067 ">
the syntax-based approach to statistical machine translation (yamada and knight, 2001) <papid> P01-1067 </papid>becomes more and more competitive in machine translation, which is sub field of natural language processing (nlp).</citsent>
<aftsection>
<nextsent>in this approach the full parse treesof the involved sentences are available to the translation model, which can base its decisions on this rich structure.
</nextsent>
<nextsent>in the competing phrase-based approach (koehn et al, 2003) the translation model only has access to the linear sentence structure.
</nextsent>
<nextsent>there are two major classes of syntax-basedtranslation models: tree transducers and synchronous grammars.
</nextsent>
<nextsent>examples in the former class are the top-down tree transducer (rounds, 1970;thatcher, 1970), the extended top-down tree transducer (arnold and dauchet, 1982; galley et al, 2004; knight and graehl, 2005; graehl et al, 2008; <papid> J08-3004 </papid>maletti et al, 2009), and the extended multi bottom-up tree transducer (lilin, 1981; engelfriet et al, 2009; maletti, 2010).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1760">
<title id=" W10-2501.xml">preservation of recognizability for synchronous tree substitution grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the competing phrase-based approach (koehn et al, 2003) the translation model only has access to the linear sentence structure.
</prevsent>
<prevsent>there are two major classes of syntax-basedtranslation models: tree transducers and synchronous grammars.
</prevsent>
</prevsection>
<citsent citstr=" J08-3004 ">
examples in the former class are the top-down tree transducer (rounds, 1970;thatcher, 1970), the extended top-down tree transducer (arnold and dauchet, 1982; galley et al, 2004; knight and graehl, 2005; graehl et al, 2008; <papid> J08-3004 </papid>maletti et al, 2009), and the extended multi bottom-up tree transducer (lilin, 1981; engelfriet et al, 2009; maletti, 2010).</citsent>
<aftsection>
<nextsent>the latter class contains the syntax-directed transductions of lewis ii and stearns (1968), the generalized syntax-directed transductions (aho and ullman, 1969), the synchronous tree substitution grammar (stsg) by schabes (1990) and the synchronous tree adjoining grammar (stag) by abeille?
</nextsent>
<nextsent>et al (1990) and shieber and schabes (1990).<papid> C90-3045 </papid></nextsent>
<nextsent>the first bridge between those two classes were established in (martin and vere, 1970).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1761">
<title id=" W10-2501.xml">preservation of recognizability for synchronous tree substitution grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>examples in the former class are the top-down tree transducer (rounds, 1970;thatcher, 1970), the extended top-down tree transducer (arnold and dauchet, 1982; galley et al, 2004; knight and graehl, 2005; graehl et al, 2008; <papid> J08-3004 </papid>maletti et al, 2009), and the extended multi bottom-up tree transducer (lilin, 1981; engelfriet et al, 2009; maletti, 2010).</prevsent>
<prevsent>the latter class contains the syntax-directed transductions of lewis ii and stearns (1968), the generalized syntax-directed transductions (aho and ullman, 1969), the synchronous tree substitution grammar (stsg) by schabes (1990) and the synchronous tree adjoining grammar (stag) by abeille?</prevsent>
</prevsection>
<citsent citstr=" C90-3045 ">
et al (1990) and shieber and schabes (1990).<papid> C90-3045 </papid></citsent>
<aftsection>
<nextsent>the first bridge between those two classes were established in (martin and vere, 1970).
</nextsent>
<nextsent>further comparisons can be found in (shieber, 2004) for stsg and in (shieber, 2006) <papid> E06-1048 </papid>for stag.one of the main challenges in nlp is the ambiguity that is inherent in natural languages.</nextsent>
<nextsent>for instance, the sentence saw the man with the telescope?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1762">
<title id=" W10-2501.xml">preservation of recognizability for synchronous tree substitution grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>et al (1990) and shieber and schabes (1990).<papid> C90-3045 </papid></prevsent>
<prevsent>the first bridge between those two classes were established in (martin and vere, 1970).</prevsent>
</prevsection>
<citsent citstr=" E06-1048 ">
further comparisons can be found in (shieber, 2004) for stsg and in (shieber, 2006) <papid> E06-1048 </papid>for stag.one of the main challenges in nlp is the ambiguity that is inherent in natural languages.</citsent>
<aftsection>
<nextsent>for instance, the sentence saw the man with the telescope?
</nextsent>
<nextsent>has several different meanings.
</nextsent>
<nextsent>some of them can be distinguished by the parse tree, so that probabilistic parsers (nederhof and satta, 2006) for natural languages can (partially) achieve the disambiguation.
</nextsent>
<nextsent>such parser returns set of parse trees for each input sentence, and in addition, each returned parse tree is assigned likelihood.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1763">
<title id=" W10-2501.xml">preservation of recognizability for synchronous tree substitution grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>thus, the result can be seen as mapping from parse trees to probabilities where the impossible parses are assigned the probability 0.
</prevsent>
<prevsent>such mappings are called weighted tree languages, of which some can be finitely represented by weighted regular tree grammars (alexandrakis and bozapalidis, 1987).
</prevsent>
</prevsection>
<citsent citstr=" W05-1506 ">
those weighted tree languages are recognizable and there exist algorithms (huang and chiang, 2005) <papid> W05-1506 </papid>that efficiently extract the k-best parse trees (i.e., those with the highest probability) for further processing.in this paper we consider synchronized tree substitution grammars (stsg).</citsent>
<aftsection>
<nextsent>to overcome technical difficulty we add (grammar) nonterminals tothem.
</nextsent>
<nextsent>since an stsg often uses the nonterminals of context-free grammar as terminal symbols (i.e., its derived trees contain both terminal and nonterminal symbols of the context-free grammar), we call the newly added (grammar) nonterminals of the stsg states.
</nextsent>
<nextsent>substitution does no longer take place at synchronized nonterminals (of the context-free grammar) but at synchronized states (one for the input and one for the output side).
</nextsent>
<nextsent>the states themselves will not appear in the final derived trees, which yields that it is sufficient to assume that only identical states are synchro 1 nized.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1765">
<title id=" W10-1910.xml">exploring surface level heuristics for negation and speculation discovery in clinical texts </title>
<section> method.  </section>
<citcontext>
<prevsection>
<prevsent>negation/speculation in general english could be expressed by almost any combination of morphologic, syntactic, semantic, and discourse-level means.
</prevsent>
<prevsent>however, the scientific dryness?
</prevsent>
</prevsection>
<citsent citstr=" W08-0606 ">
of the biomedical genre and clinical texts in particular, limits language variability and simplifies the task.we evaluated the performance of the negex algorithm on the bio scope corpus (szarvas et al,2008).<papid> W08-0606 </papid></citsent>
<aftsection>
<nextsent>bio scope corpus statistics are shown in tables 1 and 2.
</nextsent>
<nextsent>corpus type sentences documents mean document size radiology reports 7520 1954 3.85 biological full papers 3352 9 372.44 biological paper abstracts 14565 1273 11.44 table 1: statistics of the bio scope corpus.
</nextsent>
<nextsent>document sizes represent number of sentences.
</nextsent>
<nextsent>corpus type negation cues speculation cues negation speculation rad reports 872 1137 6.6% 13.4% full papers 378 682 13.76% 22.29% paper abstracts 1757 2694 13.45% 17.69%table 2: the percentage of speculative sentences (last col umn) is larger than the percentage of negated sentences.we first evaluated the performance of an unmodified version of the negex algorithm on the task of cue detection (table 3).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1766">
<title id=" W10-1910.xml">exploring surface level heuristics for negation and speculation discovery in clinical texts </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>we are also exploring the discovery of degree of speculative ness (e.g. very unlikely vs very likely).
</prevsent>
<prevsent>while negex performed well on the task of identifying negation scope (f-score 95.18), further work is needed on the discovery of speculation scopes (f-score 58.90).
</prevsent>
</prevsection>
<citsent citstr=" W08-0607 ">
as hedging cues require more fine-tuned set of rules, in future work we will evaluate linguistically motivated approaches (kilicoglu and bergler, 2008) <papid> W08-0607 </papid>for the creation of set of surface-level speculation scope rules.</citsent>
<aftsection>




</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1767">
<title id=" W10-1758.xml">taming structured perceptrons on wild feature vectors </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper describes modification to the up date step and compares the performance of the resulting algorithm to standard minimum error-rate training (mert).
</prevsent>
<prevsent>in addition, preliminary results for combining mert or structured-perceptron tuning ofthe log-linear feature weights with coordinate ascent of other translation system parameters are presented.
</prevsent>
</prevsection>
<citsent citstr=" W02-1001 ">
structured perceptrons are relatively recent (collins, 2002) <papid> W02-1001 </papid>update of the classic perceptron algorithm which permit the prediction of vectors of values.</citsent>
<aftsection>
<nextsent>initially developed for part of speech taggers, they have been applied to tuning the weights of the features in the log-linear models used by statistical machine translation (arun and koehn, 2007), and found to have performance similar to the margin-infused relaxed algorithm (mira) by crammer and singer (2003), crammer and singer (2006) and minimum-error rate training (mert) by och (2003).<papid> P03-1021 </papid></nextsent>
<nextsent>parameter tuning is an important aspect of current data-driven machine translation systems, as an improper selection of feature weights can dramatically reduce scores on evaluation metrics such as bleu (papineni et al, 2002) <papid> P02-1040 </papid>or meteor (banerjee and lavie, 2005).<papid> W05-0909 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1768">
<title id=" W10-1758.xml">taming structured perceptrons on wild feature vectors </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in addition, preliminary results for combining mert or structured-perceptron tuning ofthe log-linear feature weights with coordinate ascent of other translation system parameters are presented.
</prevsent>
<prevsent>structured perceptrons are relatively recent (collins, 2002) <papid> W02-1001 </papid>update of the classic perceptron algorithm which permit the prediction of vectors of values.</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
initially developed for part of speech taggers, they have been applied to tuning the weights of the features in the log-linear models used by statistical machine translation (arun and koehn, 2007), and found to have performance similar to the margin-infused relaxed algorithm (mira) by crammer and singer (2003), crammer and singer (2006) and minimum-error rate training (mert) by och (2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>parameter tuning is an important aspect of current data-driven machine translation systems, as an improper selection of feature weights can dramatically reduce scores on evaluation metrics such as bleu (papineni et al, 2002) <papid> P02-1040 </papid>or meteor (banerjee and lavie, 2005).<papid> W05-0909 </papid></nextsent>
<nextsent>when we recently added new features to the cmu-ebmt translation system (brown, 1996; <papid> C96-1030 </papid>brown, 2008)1, in addition to splitting number of composite features into their components, our previous method of parameter tuning via coordinate ascent2 became impractical.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1769">
<title id=" W10-1758.xml">taming structured perceptrons on wild feature vectors </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>structured perceptrons are relatively recent (collins, 2002) <papid> W02-1001 </papid>update of the classic perceptron algorithm which permit the prediction of vectors of values.</prevsent>
<prevsent>initially developed for part of speech taggers, they have been applied to tuning the weights of the features in the log-linear models used by statistical machine translation (arun and koehn, 2007), and found to have performance similar to the margin-infused relaxed algorithm (mira) by crammer and singer (2003), crammer and singer (2006) and minimum-error rate training (mert) by och (2003).<papid> P03-1021 </papid></prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
parameter tuning is an important aspect of current data-driven machine translation systems, as an improper selection of feature weights can dramatically reduce scores on evaluation metrics such as bleu (papineni et al, 2002) <papid> P02-1040 </papid>or meteor (banerjee and lavie, 2005).<papid> W05-0909 </papid></citsent>
<aftsection>
<nextsent>when we recently added new features to the cmu-ebmt translation system (brown, 1996; <papid> C96-1030 </papid>brown, 2008)1, in addition to splitting number of composite features into their components, our previous method of parameter tuning via coordinate ascent2 became impractical.</nextsent>
<nextsent>with now more than 50 features partaking in the scoring model, mert no longer seemed good choice, as the common wisdom is that it is not able to reliably optimize more than about 20 features (chiang et al, 2008).<papid> D08-1024 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1770">
<title id=" W10-1758.xml">taming structured perceptrons on wild feature vectors </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>structured perceptrons are relatively recent (collins, 2002) <papid> W02-1001 </papid>update of the classic perceptron algorithm which permit the prediction of vectors of values.</prevsent>
<prevsent>initially developed for part of speech taggers, they have been applied to tuning the weights of the features in the log-linear models used by statistical machine translation (arun and koehn, 2007), and found to have performance similar to the margin-infused relaxed algorithm (mira) by crammer and singer (2003), crammer and singer (2006) and minimum-error rate training (mert) by och (2003).<papid> P03-1021 </papid></prevsent>
</prevsection>
<citsent citstr=" W05-0909 ">
parameter tuning is an important aspect of current data-driven machine translation systems, as an improper selection of feature weights can dramatically reduce scores on evaluation metrics such as bleu (papineni et al, 2002) <papid> P02-1040 </papid>or meteor (banerjee and lavie, 2005).<papid> W05-0909 </papid></citsent>
<aftsection>
<nextsent>when we recently added new features to the cmu-ebmt translation system (brown, 1996; <papid> C96-1030 </papid>brown, 2008)1, in addition to splitting number of composite features into their components, our previous method of parameter tuning via coordinate ascent2 became impractical.</nextsent>
<nextsent>with now more than 50 features partaking in the scoring model, mert no longer seemed good choice, as the common wisdom is that it is not able to reliably optimize more than about 20 features (chiang et al, 2008).<papid> D08-1024 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1771">
<title id=" W10-1758.xml">taming structured perceptrons on wild feature vectors </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>initially developed for part of speech taggers, they have been applied to tuning the weights of the features in the log-linear models used by statistical machine translation (arun and koehn, 2007), and found to have performance similar to the margin-infused relaxed algorithm (mira) by crammer and singer (2003), crammer and singer (2006) and minimum-error rate training (mert) by och (2003).<papid> P03-1021 </papid></prevsent>
<prevsent>parameter tuning is an important aspect of current data-driven machine translation systems, as an improper selection of feature weights can dramatically reduce scores on evaluation metrics such as bleu (papineni et al, 2002) <papid> P02-1040 </papid>or meteor (banerjee and lavie, 2005).<papid> W05-0909 </papid></prevsent>
</prevsection>
<citsent citstr=" C96-1030 ">
when we recently added new features to the cmu-ebmt translation system (brown, 1996; <papid> C96-1030 </papid>brown, 2008)1, in addition to splitting number of composite features into their components, our previous method of parameter tuning via coordinate ascent2 became impractical.</citsent>
<aftsection>
<nextsent>with now more than 50 features partaking in the scoring model, mert no longer seemed good choice, as the common wisdom is that it is not able to reliably optimize more than about 20 features (chiang et al, 2008).<papid> D08-1024 </papid></nextsent>
<nextsent>we had been using coordinate ascent because of need to tune substantial number of parameters which are not directly part of the log-linear model which can be tuned by mert or similar methods.our system generates translation lattice by runtime lookup in the training corpus rather than using pre computed phrase table, so important parameters include ? the size of the sample of retrieved training instances forgiven input phrase which are aligned, ? the weight of source features for ranking training instances during sampling, and ? the minimum alignment score to accept translation instance decoder parameters which are important to tune,but which are generally not mentioned in the literature include ? how many alternative translations of phrase to consider during decoding, ? the size of the reordering window, and?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1772">
<title id=" W10-1758.xml">taming structured perceptrons on wild feature vectors </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>parameter tuning is an important aspect of current data-driven machine translation systems, as an improper selection of feature weights can dramatically reduce scores on evaluation metrics such as bleu (papineni et al, 2002) <papid> P02-1040 </papid>or meteor (banerjee and lavie, 2005).<papid> W05-0909 </papid></prevsent>
<prevsent>when we recently added new features to the cmu-ebmt translation system (brown, 1996; <papid> C96-1030 </papid>brown, 2008)1, in addition to splitting number of composite features into their components, our previous method of parameter tuning via coordinate ascent2 became impractical.</prevsent>
</prevsection>
<citsent citstr=" D08-1024 ">
with now more than 50 features partaking in the scoring model, mert no longer seemed good choice, as the common wisdom is that it is not able to reliably optimize more than about 20 features (chiang et al, 2008).<papid> D08-1024 </papid></citsent>
<aftsection>
<nextsent>we had been using coordinate ascent because of need to tune substantial number of parameters which are not directly part of the log-linear model which can be tuned by mert or similar methods.our system generates translation lattice by runtime lookup in the training corpus rather than using pre computed phrase table, so important parameters include ? the size of the sample of retrieved training instances forgiven input phrase which are aligned, ? the weight of source features for ranking training instances during sampling, and ? the minimum alignment score to accept translation instance decoder parameters which are important to tune,but which are generally not mentioned in the literature include ? how many alternative translations of phrase to consider during decoding, ? the size of the reordering window, and?
</nextsent>
<nextsent>the rank of the language model (4-gram, 5 gram, etc.) in addition, it is desirable to tune parameters suchas beam width to minimize translation time with out degrading performance.
</nextsent>
<nextsent>1source code for cmu-ebmt is available from http://cmu-ebmt.sourceforge.net.2coordinate ascent is described in more detail in section 7.
</nextsent>
<nextsent>384 as result of the non-model parameters, full system tuning will involve multiple runs of the tuning algorithm for the feature weights, since the other parameters will affect the optimal weights.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1775">
<title id=" W10-1758.xml">taming structured perceptrons on wild feature vectors </title>
<section> more conservative updates for.  </section>
<citcontext>
<prevsection>
<prevsent>this is commonly addressed by using the highest-scoring (by some metric such as bleu) translation which the system can generate as pseudo-oracle.
</prevsent>
<prevsent>our initial implementation closely followed the description in (arun and koehn, 2007), including the refinement of using the objective-functionscore of the pseudo-oracle translation from the best list to modulate the learning rate of the update step, i.e. ~w ? ~w + soracle ?
</prevsent>
</prevsection>
<citsent citstr=" P04-1077 ">
(oracle ? top1) (3)as can be seen, the difference between equations 2 and 3 is simply the additional factor of soracle . 385 while we initially used sentence-level smoothed bleu as the objective function, we found it to perform very poorly (the full bleu scores on the haitian creole tuning set were well below 0.10), and instead adopted the rouge-s (skip bigrams) metric by lin and och (2004<papid> P04-1077 </papid>a) with maximum skip distance of four words, which was found to best correlate with human quality judgements (lin and och, 2004<papid> P04-1077 </papid>b).</citsent>
<aftsection>
<nextsent>in early testing, we found that both the feature weights and performance as measured by the average objective score over the tuning set oscillatedwildly.
</nextsent>
<nextsent>analyzing the results, it became apparent that the update function was overly aggressive.
</nextsent>
<nextsent>unlike the binary features used in (arun and koehn, 2007), our continuous-valued features have different operating ranges for each feature,e.g. the total distance moved as result of reordering could reach 100 on long sentence, while the proportion of training instances with at least six words of adjacent context in the bilingual corpus is unlikely to exceed 0.05, even where sampling is biased toward training instances with adjacent context.the first attempt to address the disparity in operating ranges was to perform feature-wise normalization on the update.
</nextsent>
<nextsent>instead of taking the simple difference in feature vectors between the n-best entry with the highest log-linear score andthe one with the highest objective score, we construct diff such that i(diff)?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1781">
<title id=" W10-1908.xml">cancer stage prediction based on patient online discourse </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>posts and the stage of their interlocutors can provide complementary clues to identifying cancer stages.
</prevsent>
<prevsent>researchers have begun to explore the possibility of diagnosing patients based on their speech productions.
</prevsent>
</prevsection>
<citsent citstr=" W08-0616 ">
content analysis methods, which rely on patient speech transcripts or texts authored by patients, have been leveraged for understanding cancer coping mechanisms (graves et al , 2005; bantum and owen, 2009), psychiatric diagnoses (ox manet al , 1988; elvevaag et al , 2010), and the analysis of suicide notes (pestian et al , 2008).<papid> W08-0616 </papid></citsent>
<aftsection>
<nextsent>in all cases, results, while not fully accurate, are promising and show that patient-generated content is valuable clue to diagnosis in an automated framework.
</nextsent>
<nextsent>our work departs from these experiments in that we do not attempt to predict the psychological state of patient, but rather the status of clinical condition.
</nextsent>
<nextsent>staging breast cancer provides way to summarize the status of the cancer based on clinical characteristics (the size of the tumor, whether the cancer is invasive or not, whether cancer cells are present in the lymph nodes, and whether the cancer has spread beyond the breast).
</nextsent>
<nextsent>there are five high-level stages for breast cancer.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1782">
<title id=" W10-1908.xml">cancer stage prediction based on patient online discourse </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in particular, we build social network basedon patients?
</prevsent>
<prevsent>interactions to boost text-based predictions.
</prevsent>
</prevsection>
<citsent citstr=" P05-1049 ">
graph-based methods are becoming increasingly popular in the nlp community, and similar approaches have been employed and 65shown to perform well in other areas like question answering (jurczyk, 2007) (harabagiu et al , 2006), word-sense disambiguation (niu et al , 2005), <papid> P05-1049 </papid>and textual entailment (haghighi, 2005).</citsent>
<aftsection>
<nextsent>our methods to predict cancer stage operate in supervised framework.
</nextsent>
<nextsent>we cast the task of stage prediction as 4-way classification (stage to iv).we hypothesize that the discourse of patients on line, as defined by the content of their posts in forum, can be leveraged to predict cancer stage.furthermore, we hypothesize that the social network derived by whom patients interact with can provide an additional clue for stage detection.we experimented with three methods of predicting cancer stage: text-based stage prediction classifier is trained given the post history of patient.network-based stage prediction social network representing the interactions among fo rum members is built, and label propagation algorithm is applied to infer the stage of individual patients.combined prediction classifier which combines text-based and network-based features.
</nextsent>
<nextsent>next we describe each method in detail, along with our dataset and our experimental setup.
</nextsent>
<nextsent>3.1 data collection and preprocessing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1783">
<title id=" W10-1840.xml">anatomy of annotation schemes mapping to graf </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these two components of the language specification are called its concrete and abstract syntax, respectively.
</prevsent>
<prevsent>a distinguishing feature of the proposed methodology is that the semantics is defined for the structures of the abstract syntax, rather than for the expressions that represent these structures.in this paper, we generalize the design methodology defined in (bunt, 2010) and demonstrate its use for generating mapping from an existing annotation scheme to representation in graf format.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
by way of illustration, we apply the mapping strategy to annotations from iso timeml (iso, 2009), propbank (palmer et al, 2005), and framenet (baker et al, 1998).<papid> P98-1013 </papid></citsent>
<aftsection>
<nextsent>247
</nextsent>
<nextsent>the process of corpus annotation may consist of attaching simple labels to textual elements, such as part of speech and syntactic designations and named entity tags.
</nextsent>
<nextsent>for more complex types of annotation, annotations include variety of additional information about linguistic features and relations.
</nextsent>
<nextsent>this is especially true for the kinds of semantic annotation that have recently begun to be undertaken in earnest, including semantic role labeling (e.g., framenet and propbank) andtime and event annotation (e.g., timeml).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1784">
<title id=" W10-1406.xml">factors affecting the accuracy of korean parsing </title>
<section> initial experiments.  </section>
<citcontext>
<prevsection>
<prevsent>this freedom of word order could potentially result in large number of rules, which could complicate analysis with new ambiguities.
</prevsent>
<prevsent>however, formal written korean generally conforms to canonical word order (sov).
</prevsent>
</prevsection>
<citsent citstr=" I05-2034 ">
there has been some work on korean morphological analysis showing that common statistical methods such as maximum entropy modeling and conditional random fields perform quite well (lee et al , 2000; sarkar and han, 2002; han and palmer, 2004; lee and rim, 2005).<papid> I05-2034 </papid></citsent>
<aftsection>
<nextsent>most claim accuracy rate over 95%.
</nextsent>
<nextsent>in light of this, we focus on the parsing part of the problem utilizing morphology analysis already present in the data.
</nextsent>
<nextsent>3.1 setup.
</nextsent>
<nextsent>for our experiments we used all 5,010 sentences inthe korean treebank (ktb), which are already segmented.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1785">
<title id=" W10-1406.xml">factors affecting the accuracy of korean parsing </title>
<section> initial experiments.  </section>
<citcontext>
<prevsection>
<prevsent>for english, we vary the size of the training data to provide better point of comparison against korean.
</prevsent>
<prevsent>types and tokens denote vocabulary sizes (which for korean is the mean over the folds).
</prevsent>
</prevsection>
<citsent citstr=" P06-1055 ">
was set to all words occurring more than once in it straining data, with handful of count one tokens replacing unknown words based on properties of the words surface form (all korean words were placed in single bin, and english words were binned following the rules of petrov et al  (2006)).<papid> P06-1055 </papid></citsent>
<aftsection>
<nextsent>we report scores on the development set.we report parser accuracy scores using the standard f1 metric, which balances precision and recall of the labeled constituents recovered by the parser:2pr/(p + r).
</nextsent>
<nextsent>throughout the paper, all evaluation occurs against gold standard trees that contain no null elements or nonterminal function tags or annotations, which in some cases requires there moval of those elements from parse trees output by the parser.
</nextsent>
<nextsent>3.2 treebank grammars.
</nextsent>
<nextsent>we begin by presenting in table 1 scores for the standard treebank grammar, obtained by reading standard context-free grammar from the trees in the training data and setting rule probabilities to relative frequency (charniak, 1996).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1788">
<title id=" W10-1406.xml">factors affecting the accuracy of korean parsing </title>
<section> nonterminal granularity.  </section>
<citcontext>
<prevsection>
<prevsent>this simple technique alone produces large improvement in english treebank parsing.
</prevsent>
<prevsent>klein and manning (2003) expanded this idea with series of experiments wherein they manually refined nonterminals to different degrees, which resulted in parsing accuracy rivaling that of bilexi calized parsing models of the time.
</prevsent>
</prevsection>
<citsent citstr=" P05-1010 ">
more recently, petrov et al  (2006) <papid> P06-1055 </papid>refined techniques originally proposed by matsuzaki et al  (2005) <papid> P05-1010 </papid>and prescher 51 sbj subject with nominative case marker obj complement with accusative case marker comp complement with adverbial post position adv np that function as adverbial phrase voc noun with vocative case maker lv np coupled with light?</citsent>
<aftsection>
<nextsent>verb construction table 2: function tags in the korean treebank model f1 f140 korean coarse 52.78 56.55 w/ function tags 56.18 60.21 english (small) coarse 72.20 73.29 w/ function tags 70.50 71.78 english (standard) coarse 71.61 72.74 w/ function tags 72.82 74.05 table 3: parser scores for treebank pcfgs in korean and english with and without function tags.
</nextsent>
<nextsent>the small english results were produced by training on 0204.
</nextsent>
<nextsent>(2005) for automatically learning latent annotations, resulting in state of the art parsing performance with cubic-time parsing algorithms.we begin this section by conducting some simple experiments with the existing function tags, and then apply the latent annotation learning procedures of petrov et al  (2006) <papid> P06-1055 </papid>to the ktb.</nextsent>
<nextsent>4.1 function tags.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1792">
<title id=" W10-1406.xml">factors affecting the accuracy of korean parsing </title>
<section> tree substitution grammars.  </section>
<citcontext>
<prevsection>
<prevsent>we have shown that coarse labels and the prevalence of null elements in korean both contribute to parsing difficulty.
</prevsent>
<prevsent>we now turn to grammar formalisms that allow us to work with larger fragments of parse trees than the height-one rules of standard context free grammars.
</prevsent>
</prevsection>
<citsent citstr=" P01-1010 ">
tree substitution grammars (tsgs)have been shown to improve upon the standard english treebank grammar (bod, 2001) <papid> P01-1010 </papid>in parser accuracy, and more recently, techniques for inferring tsg subtrees in bayesian framework have enabled learning more efficiently re presentable grammars, permitting some interesting analysis (odonnell et al ., 2009; cohn et al , 2009; post and gildea, 2009).</citsent>
<aftsection>
<nextsent>in this section, we try parsing the ktb with tsgs.
</nextsent>
<nextsent>we experiment with different methods of learning tsgs to see whether they can reveal any insights into the difficulties parsing korean.
</nextsent>
<nextsent>6.1 head rules.
</nextsent>
<nextsent>tsgs present some difficulties in learning and representation, but simple extraction heuristic calleda spinal grammar has been shown to be very useful (chiang, 2000; <papid> P00-1058 </papid>sangati and zuidema, 2009; post and gildea, 2009).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1793">
<title id=" W10-1406.xml">factors affecting the accuracy of korean parsing </title>
<section> tree substitution grammars.  </section>
<citcontext>
<prevsection>
<prevsent>we experiment with different methods of learning tsgs to see whether they can reveal any insights into the difficulties parsing korean.
</prevsent>
<prevsent>6.1 head rules.
</prevsent>
</prevsection>
<citsent citstr=" P00-1058 ">
tsgs present some difficulties in learning and representation, but simple extraction heuristic calleda spinal grammar has been shown to be very useful (chiang, 2000; <papid> P00-1058 </papid>sangati and zuidema, 2009; post and gildea, 2009).</citsent>
<aftsection>
<nextsent>spinal subtrees are extracted from parse tree by using set of head rules to maximally project each lexical item (a word or morpheme).
</nextsent>
<nextsent>each node in the parse tree having different head from its parent becomes the root of new subtree, which induces spinal tsg derivation inthe parse tree (see figure 1).
</nextsent>
<nextsent>a probabilistic grammar is derived by taking counts from these trees, smoothing them with counts of all depth-one rules from the same training set, and setting rule probabilities to relative frequency.
</nextsent>
<nextsent>this heuristic requires set of head rules, which we present in table 6.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1794">
<title id=" W10-1406.xml">factors affecting the accuracy of korean parsing </title>
<section> tree substitution grammars.  </section>
<citcontext>
<prevsection>
<prevsent>this heuristic requires set of head rules, which we present in table 6.
</prevsent>
<prevsent>as an evaluation of our rules, we list in table 7 the accuracy results for parsing with spinal grammars extracted using the head ruleswe developed as well as with two head rule heuristics (head-left and head-right).
</prevsent>
</prevsection>
<citsent citstr=" P95-1037 ">
as point of comparison, we provide the same results for english, using the standard magerman/collins head rules for english (magerman, 1995; <papid> P95-1037 </papid>collins, 1997).</citsent>
<aftsection>
<nextsent>function tags were retained for korean but not for english.
</nextsent>
<nextsent>we observe number of things from table 7.
</nextsent>
<nextsent>first, the relative performance of the head-left and nt rc rule sfn second rightmost child vv efn rightmost xsv vx efn rightmost vj or co adjp efn rightmost vj cv efn rightmost vv lv efn rightmost vv np efn rightmost co vj efn rightmost xsv or xsj vp efn rightmost vx, xsv, or vv ? ?
</nextsent>
<nextsent>rightmost child table 6: head rules for the korean treebank.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1795">
<title id=" W10-2914.xml">semi supervised recognition of sarcasm in twitter and amazon </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>although the negative sentiment is very explicit in the ipod review (5), the sarcastic effect emerges from the pun that assumes the knowledge that the design is oneof the most celebrated features of apples products.
</prevsent>
<prevsent>(none of the above reasoning was directly introduced to our algorithm.)
</prevsent>
</prevsection>
<citsent citstr=" H05-1043 ">
modeling the underlying patterns of sarcastic utterances is interesting from the psychological and cognitive perspectives and can benefit various nlp systems such as review summarization (popescu and etzioni, 2005; <papid> H05-1043 </papid>pang and lee, 2004; <papid> P04-1035 </papid>wiebe et al , 2004; <papid> J04-3002 </papid>hu and liu, 2004) and dialogue systems.</citsent>
<aftsection>
<nextsent>following the brilliant-but cruel?
</nextsent>
<nextsent>hypothesis (danescu-niculescu-mizil et al ,2009), it can help improve ranking and recommendation systems (tsur and rappoport, 2009).
</nextsent>
<nextsent>all systems currently fail to correctly classify the sentiment of sarcastic sentences.in this paper we utilize the semi-supervised sarcasm identification algorithm (sasi) of (tsur et al ., 2010).
</nextsent>
<nextsent>the algorithm employs two modules:semi supervised pattern acquisition for identifying sarcastic patterns that serve as features for classifier, and classification stage that classifies each sentence to sarcastic class.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1796">
<title id=" W10-2914.xml">semi supervised recognition of sarcasm in twitter and amazon </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>although the negative sentiment is very explicit in the ipod review (5), the sarcastic effect emerges from the pun that assumes the knowledge that the design is oneof the most celebrated features of apples products.
</prevsent>
<prevsent>(none of the above reasoning was directly introduced to our algorithm.)
</prevsent>
</prevsection>
<citsent citstr=" P04-1035 ">
modeling the underlying patterns of sarcastic utterances is interesting from the psychological and cognitive perspectives and can benefit various nlp systems such as review summarization (popescu and etzioni, 2005; <papid> H05-1043 </papid>pang and lee, 2004; <papid> P04-1035 </papid>wiebe et al , 2004; <papid> J04-3002 </papid>hu and liu, 2004) and dialogue systems.</citsent>
<aftsection>
<nextsent>following the brilliant-but cruel?
</nextsent>
<nextsent>hypothesis (danescu-niculescu-mizil et al ,2009), it can help improve ranking and recommendation systems (tsur and rappoport, 2009).
</nextsent>
<nextsent>all systems currently fail to correctly classify the sentiment of sarcastic sentences.in this paper we utilize the semi-supervised sarcasm identification algorithm (sasi) of (tsur et al ., 2010).
</nextsent>
<nextsent>the algorithm employs two modules:semi supervised pattern acquisition for identifying sarcastic patterns that serve as features for classifier, and classification stage that classifies each sentence to sarcastic class.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1797">
<title id=" W10-2914.xml">semi supervised recognition of sarcasm in twitter and amazon </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>although the negative sentiment is very explicit in the ipod review (5), the sarcastic effect emerges from the pun that assumes the knowledge that the design is oneof the most celebrated features of apples products.
</prevsent>
<prevsent>(none of the above reasoning was directly introduced to our algorithm.)
</prevsent>
</prevsection>
<citsent citstr=" J04-3002 ">
modeling the underlying patterns of sarcastic utterances is interesting from the psychological and cognitive perspectives and can benefit various nlp systems such as review summarization (popescu and etzioni, 2005; <papid> H05-1043 </papid>pang and lee, 2004; <papid> P04-1035 </papid>wiebe et al , 2004; <papid> J04-3002 </papid>hu and liu, 2004) and dialogue systems.</citsent>
<aftsection>
<nextsent>following the brilliant-but cruel?
</nextsent>
<nextsent>hypothesis (danescu-niculescu-mizil et al ,2009), it can help improve ranking and recommendation systems (tsur and rappoport, 2009).
</nextsent>
<nextsent>all systems currently fail to correctly classify the sentiment of sarcastic sentences.in this paper we utilize the semi-supervised sarcasm identification algorithm (sasi) of (tsur et al ., 2010).
</nextsent>
<nextsent>the algorithm employs two modules:semi supervised pattern acquisition for identifying sarcastic patterns that serve as features for classifier, and classification stage that classifies each sentence to sarcastic class.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1798">
<title id=" W10-2914.xml">semi supervised recognition of sarcasm in twitter and amazon </title>
<section> classification algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>we also removed all html tags and special symbols from the review text.
</prevsent>
<prevsent>pattern extraction our main feature type is based on surface patterns.
</prevsent>
</prevsection>
<citsent citstr=" P06-1038 ">
in order to extract such patterns automatically, we followed the algorithm given in (davidov and rappoport, 2006).<papid> P06-1038 </papid></citsent>
<aftsection>
<nextsent>we classified words into high-frequency words (hfws)and content words (cws).
</nextsent>
<nextsent>a word whose corpus frequency is more (less) than fh (fc) is considered to be hfw (cw).
</nextsent>
<nextsent>unlike in (davidov and rappoport, 2006), <papid> P06-1038 </papid>we consider all punctuation characters as hfws.</nextsent>
<nextsent>we also consider [product],[company], [title], [author] tags as hfws for pattern extraction.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1800">
<title id=" W10-2914.xml">semi supervised recognition of sarcasm in twitter and amazon </title>
<section> evaluation setup.  </section>
<citcontext>
<prevsection>
<prevsent>we used the same seed of 80 positive (sarcastic) examples and 505 negative examples described at (tsur et al , 2010).
</prevsent>
<prevsent>after automatically expanding the training set,our training data now contains 471 positive examples and 5020 negative examples.
</prevsent>
</prevsection>
<citsent citstr=" D07-1035 ">
these ratios are 6we used = 5 for all experiments.to be expected, since non-sarcastic sentences outnumber sarcastic ones, definitely when most on line reviews are positive (liu et al , 2007).<papid> D07-1035 </papid></citsent>
<aftsection>
<nextsent>this generally positive tendency is also reflected in our data ? the average number of stars is 4.12.
</nextsent>
<nextsent>seed training set with #sarcasm (twitter).
</nextsent>
<nextsent>we used sample of 1500 tweets marked with the #sarcasm hashtag as positive set that represents sarcasm styles special to twitter.
</nextsent>
<nextsent>however, this set is very noisy (see discussion in section 5).seed training set (cross domain).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1801">
<title id=" W10-2914.xml">semi supervised recognition of sarcasm in twitter and amazon </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in the context of opinion mining, sarcasm is mentioned briefly as hard nut that is yet to be cracked, see comprehensive overview by (pang and lee, 2008).
</prevsent>
<prevsent>tepper man et al  (2006) identify sarcasm in spoken dialogue systems, their work is restricted to sarcastic utterances that contain the expression yeah-right?
</prevsent>
</prevsection>
<citsent citstr=" P09-2041 ">
and it depends heavily on cues in the spoken dialogue such as laughter, pauses within the speech stream, the gender (recognized by voice) of the speaker and prosodic features.burfoot and baldwin (2009) <papid> P09-2041 </papid>use svm to determine whether newswire articles are true or satir ical.</citsent>
<aftsection>
<nextsent>they introduce the notion of validity which models absurdity via measure somewhat close to 114 pmi.
</nextsent>
<nextsent>validity is relatively lower when sentence includes made-up entity or when sentence contains unusual combinations of named entities suchas, for example, those in the satirical article beginning missing brazilian balloon ist padre spotted straddling pink floyd flying pig?.
</nextsent>
<nextsent>we note that while sarcasm can be based on exaggeration or unusual collocations, this model covers only limited subset of the sarcastic utterances.
</nextsent>
<nextsent>tsur et al  (2010) propose semi supervised framework for recognition of sarcasm.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1802">
<title id=" W10-2914.xml">semi supervised recognition of sarcasm in twitter and amazon </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>tsur et al  (2010) propose semi supervised framework for recognition of sarcasm.
</prevsent>
<prevsent>the proposed algorithm utilizes some features specific to (amazon) product reviews.
</prevsent>
</prevsection>
<citsent citstr=" C96-2162 ">
this paper continues this line, proposing sasi robust algorithm that successfully captures sarcastic sentences in other, radically different, domains such as twitter.utsumi (1996), <papid> C96-2162 </papid>utsumi (2000) introduces the implicit display theory, cognitive computational framework that models the ironic environment.</citsent>
<aftsection>
<nextsent>the complex axiomatic system depends heavily on complex formalism representing world knowledge.
</nextsent>
<nextsent>while comprehensive, it is currently impractical to implement on large scale or for an open domain.
</nextsent>
<nextsent>mihalcea and strapparava (2005) <papid> H05-1067 </papid>and mihalcea and pulman (2007) present system that identifies humorous one-liners.</nextsent>
<nextsent>they classify sentences using naive bayes and svm.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1803">
<title id=" W10-2914.xml">semi supervised recognition of sarcasm in twitter and amazon </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the complex axiomatic system depends heavily on complex formalism representing world knowledge.
</prevsent>
<prevsent>while comprehensive, it is currently impractical to implement on large scale or for an open domain.
</prevsent>
</prevsection>
<citsent citstr=" H05-1067 ">
mihalcea and strapparava (2005) <papid> H05-1067 </papid>and mihalcea and pulman (2007) present system that identifies humorous one-liners.</citsent>
<aftsection>
<nextsent>they classify sentences using naive bayes and svm.
</nextsent>
<nextsent>they conclude that the most frequently observed semantic features are negative polarity and human-centeredness.
</nextsent>
<nextsent>these features are also observed in some sarcastic utter ances.some philosophical, psychological and linguistic theories of irony and sarcasm are worth referencing as theoretical framework: the constraints satisfaction theory (utsumi, 1996; <papid> C96-2162 </papid>katz, 2005), the role playing theory (clark and gerrig, 1984),the echoic mention framework (wilson and sper ber, 1992) and the pretence framework (gibbs,1986).</nextsent>
<nextsent>these are all based on violation of the maxims proposed by grice (1975).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1805">
<title id=" W10-1807.xml">influence of pre annotation on pos tagged corpus development </title>
<section> abstract </section>
<citcontext>
<prevsection>

<prevsent>this article details series of carefully designed experiments aiming at evaluating the influence of automatic pre-annotation on the manual part-of-speech annotation of corpus, both from the quality and thetime points of view, with specific attention drawn to biases.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
for this purpose, we manually annotated parts of the penn tree bank corpus (marcus et al, 1993) <papid> J93-2004 </papid>under various experimental setups, either from scratch or using various pre-annotations.</citsent>
<aftsection>
<nextsent>these experiments confirm and detail the gain in quality observed before (marcus et al., 1993; <papid> J93-2004 </papid>dandapat et al, 2009;<papid> W09-3002 </papid>rehbein et al, 2009), <papid> W09-3003 </papid>while showing that biases do appear and should be taken into account.</nextsent>
<nextsent>they finally demonstrate that even notso accurate tagger can help improving annotation speed.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1807">
<title id=" W10-1807.xml">influence of pre annotation on pos tagged corpus development </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>this article details series of carefully designed experiments aiming at evaluating the influence of automatic pre-annotation on the manual part-of-speech annotation of corpus, both from the quality and thetime points of view, with specific attention drawn to biases.
</prevsent>
<prevsent>for this purpose, we manually annotated parts of the penn tree bank corpus (marcus et al, 1993) <papid> J93-2004 </papid>under various experimental setups, either from scratch or using various pre-annotations.</prevsent>
</prevsection>
<citsent citstr=" W09-3002 ">
these experiments confirm and detail the gain in quality observed before (marcus et al., 1993; <papid> J93-2004 </papid>dandapat et al, 2009;<papid> W09-3002 </papid>rehbein et al, 2009), <papid> W09-3003 </papid>while showing that biases do appear and should be taken into account.</citsent>
<aftsection>
<nextsent>they finally demonstrate that even notso accurate tagger can help improving annotation speed.
</nextsent>
<nextsent>training machine-learning based part-of-speech(pos) tagger implies manually tagging significant amount of text.
</nextsent>
<nextsent>the cost of this, in terms ofhuman effort, slows down the development of taggers for under-resourced languages.
</nextsent>
<nextsent>one usual way to improve this situation is to automatically pre-annotate the corpus, so that the work of the annotators is limited to the validation of this pre-annotation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1809">
<title id=" W10-1807.xml">influence of pre annotation on pos tagged corpus development </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>this article details series of carefully designed experiments aiming at evaluating the influence of automatic pre-annotation on the manual part-of-speech annotation of corpus, both from the quality and thetime points of view, with specific attention drawn to biases.
</prevsent>
<prevsent>for this purpose, we manually annotated parts of the penn tree bank corpus (marcus et al, 1993) <papid> J93-2004 </papid>under various experimental setups, either from scratch or using various pre-annotations.</prevsent>
</prevsection>
<citsent citstr=" W09-3003 ">
these experiments confirm and detail the gain in quality observed before (marcus et al., 1993; <papid> J93-2004 </papid>dandapat et al, 2009;<papid> W09-3002 </papid>rehbein et al, 2009), <papid> W09-3003 </papid>while showing that biases do appear and should be taken into account.</citsent>
<aftsection>
<nextsent>they finally demonstrate that even notso accurate tagger can help improving annotation speed.
</nextsent>
<nextsent>training machine-learning based part-of-speech(pos) tagger implies manually tagging significant amount of text.
</nextsent>
<nextsent>the cost of this, in terms ofhuman effort, slows down the development of taggers for under-resourced languages.
</nextsent>
<nextsent>one usual way to improve this situation is to automatically pre-annotate the corpus, so that the work of the annotators is limited to the validation of this pre-annotation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1819">
<title id=" W10-1807.xml">influence of pre annotation on pos tagged corpus development </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>fr/projects/lingwb/) . 57 of the penn treebank (meltallen ), and evaluated on section 23, melt exhibits 96.4% accuracy, which is reasonably close to the state-of-the-art (spoustova?
</prevsent>
<prevsent>et al (2009) report 97.4%).
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
since it is trained without any external lexicon, melt allen is very close to the original maximum-entropy based tagger (ratnaparkhi, 1996), <papid> W96-0213 </papid>which has indeed similar 96.6% accuracy.</citsent>
<aftsection>
<nextsent>we trained melton increasingly larger parts ofthe pos-tagged penn treebank,2 thus creating different taggers with growing degrees of accuracy (see table 1).
</nextsent>
<nextsent>we then pos-tagged the section 23 with each of these taggers, thus obtaining for each sentence in section 23 set of pre-annotations, one from each tagger.
</nextsent>
<nextsent>tagger nb train.
</nextsent>
<nextsent>sent.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1825">
<title id=" W10-1807.xml">influence of pre annotation on pos tagged corpus development </title>
<section> results and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>the results of this are shown in table 2.3during this manual annotation step (with no pre annotation), we noticed that the annotators used the find/replace all feature of the text editor to fasten the tagging of some obvious tokens like the or corp., which partly explains that the first groups of 10 sentences took longer to annotate.
</prevsent>
<prevsent>also, as no specific interface was use to help annotating, (very) few typographic errors were made, such as det instead of dt.
</prevsent>
</prevsection>
<citsent citstr=" J08-4004 ">
4for more information on the terminology issue, refer to the introduction of (artstein and poesio, 2008).<papid> J08-4004 </papid></citsent>
<aftsection>
<nextsent>sub corpus pi 1-100 0.955 301-400 0.963 table 2: inter-annotator agreement on subcorporathe results show very good agreement according to all scales (krippendorff, 1980; neuendorf, 2002; krippendorff, 2004) as pi is always superior to 0.9.
</nextsent>
<nextsent>besides, it improves with training (from 0.955 at the beginning to 0.963 at the end).
</nextsent>
<nextsent>we also calculated pi on the corpus we used to evaluate the pre-annotation bias (experiment 3).
</nextsent>
<nextsent>the results of this are shown in table 3.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1827">
<title id=" W10-3804.xml">syntactic constraints on phrase extraction for phrase based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>rather than filter out all non-syntactic phrases, we only apply syntactic constraints when there is phrase segmentation ambiguity arising from unaligned words.
</prevsent>
<prevsent>our method is very simple and yields 24.38% phrase pair reduction and 0.52 bleu point improvement when compared to baseline pbmt system with full-size tables.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
both pbmt models (koehn et al, 2003; <papid> N03-1017 </papid>chiang, 2005) <papid> P05-1033 </papid>and syntax-based machine translation models (yamada et al, 2000; quirk et al, 2005; <papid> P05-1034 </papid>galley et al, 2006; <papid> P06-1121 </papid>liu et al, 2006; <papid> P06-1077 </papid>marcu et al, 2006; <papid> W06-1606 </papid>and numerous others) are the state-of-the- art statistical machine translation (smt) meth ods.</citsent>
<aftsection>
<nextsent>over the last several years, an increasing amount of work has been done to combine the advantages of the two approaches.
</nextsent>
<nextsent>deneefe et al (2007) <papid> D07-1079 </papid>made quantitative comparison of the phrase pairs that each model has to work with and found it is useful to improve the phrasal coverage of their string-to-tree model.</nextsent>
<nextsent>liu et al (2007) <papid> P07-1089 </papid>proposed forest-to-string rules to capture the non-syntactic phrases in their tree-to-string model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1828">
<title id=" W10-3804.xml">syntactic constraints on phrase extraction for phrase based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>rather than filter out all non-syntactic phrases, we only apply syntactic constraints when there is phrase segmentation ambiguity arising from unaligned words.
</prevsent>
<prevsent>our method is very simple and yields 24.38% phrase pair reduction and 0.52 bleu point improvement when compared to baseline pbmt system with full-size tables.
</prevsent>
</prevsection>
<citsent citstr=" P05-1033 ">
both pbmt models (koehn et al, 2003; <papid> N03-1017 </papid>chiang, 2005) <papid> P05-1033 </papid>and syntax-based machine translation models (yamada et al, 2000; quirk et al, 2005; <papid> P05-1034 </papid>galley et al, 2006; <papid> P06-1121 </papid>liu et al, 2006; <papid> P06-1077 </papid>marcu et al, 2006; <papid> W06-1606 </papid>and numerous others) are the state-of-the- art statistical machine translation (smt) meth ods.</citsent>
<aftsection>
<nextsent>over the last several years, an increasing amount of work has been done to combine the advantages of the two approaches.
</nextsent>
<nextsent>deneefe et al (2007) <papid> D07-1079 </papid>made quantitative comparison of the phrase pairs that each model has to work with and found it is useful to improve the phrasal coverage of their string-to-tree model.</nextsent>
<nextsent>liu et al (2007) <papid> P07-1089 </papid>proposed forest-to-string rules to capture the non-syntactic phrases in their tree-to-string model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1829">
<title id=" W10-3804.xml">syntactic constraints on phrase extraction for phrase based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>rather than filter out all non-syntactic phrases, we only apply syntactic constraints when there is phrase segmentation ambiguity arising from unaligned words.
</prevsent>
<prevsent>our method is very simple and yields 24.38% phrase pair reduction and 0.52 bleu point improvement when compared to baseline pbmt system with full-size tables.
</prevsent>
</prevsection>
<citsent citstr=" P05-1034 ">
both pbmt models (koehn et al, 2003; <papid> N03-1017 </papid>chiang, 2005) <papid> P05-1033 </papid>and syntax-based machine translation models (yamada et al, 2000; quirk et al, 2005; <papid> P05-1034 </papid>galley et al, 2006; <papid> P06-1121 </papid>liu et al, 2006; <papid> P06-1077 </papid>marcu et al, 2006; <papid> W06-1606 </papid>and numerous others) are the state-of-the- art statistical machine translation (smt) meth ods.</citsent>
<aftsection>
<nextsent>over the last several years, an increasing amount of work has been done to combine the advantages of the two approaches.
</nextsent>
<nextsent>deneefe et al (2007) <papid> D07-1079 </papid>made quantitative comparison of the phrase pairs that each model has to work with and found it is useful to improve the phrasal coverage of their string-to-tree model.</nextsent>
<nextsent>liu et al (2007) <papid> P07-1089 </papid>proposed forest-to-string rules to capture the non-syntactic phrases in their tree-to-string model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1830">
<title id=" W10-3804.xml">syntactic constraints on phrase extraction for phrase based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>rather than filter out all non-syntactic phrases, we only apply syntactic constraints when there is phrase segmentation ambiguity arising from unaligned words.
</prevsent>
<prevsent>our method is very simple and yields 24.38% phrase pair reduction and 0.52 bleu point improvement when compared to baseline pbmt system with full-size tables.
</prevsent>
</prevsection>
<citsent citstr=" P06-1121 ">
both pbmt models (koehn et al, 2003; <papid> N03-1017 </papid>chiang, 2005) <papid> P05-1033 </papid>and syntax-based machine translation models (yamada et al, 2000; quirk et al, 2005; <papid> P05-1034 </papid>galley et al, 2006; <papid> P06-1121 </papid>liu et al, 2006; <papid> P06-1077 </papid>marcu et al, 2006; <papid> W06-1606 </papid>and numerous others) are the state-of-the- art statistical machine translation (smt) meth ods.</citsent>
<aftsection>
<nextsent>over the last several years, an increasing amount of work has been done to combine the advantages of the two approaches.
</nextsent>
<nextsent>deneefe et al (2007) <papid> D07-1079 </papid>made quantitative comparison of the phrase pairs that each model has to work with and found it is useful to improve the phrasal coverage of their string-to-tree model.</nextsent>
<nextsent>liu et al (2007) <papid> P07-1089 </papid>proposed forest-to-string rules to capture the non-syntactic phrases in their tree-to-string model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1831">
<title id=" W10-3804.xml">syntactic constraints on phrase extraction for phrase based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>rather than filter out all non-syntactic phrases, we only apply syntactic constraints when there is phrase segmentation ambiguity arising from unaligned words.
</prevsent>
<prevsent>our method is very simple and yields 24.38% phrase pair reduction and 0.52 bleu point improvement when compared to baseline pbmt system with full-size tables.
</prevsent>
</prevsection>
<citsent citstr=" P06-1077 ">
both pbmt models (koehn et al, 2003; <papid> N03-1017 </papid>chiang, 2005) <papid> P05-1033 </papid>and syntax-based machine translation models (yamada et al, 2000; quirk et al, 2005; <papid> P05-1034 </papid>galley et al, 2006; <papid> P06-1121 </papid>liu et al, 2006; <papid> P06-1077 </papid>marcu et al, 2006; <papid> W06-1606 </papid>and numerous others) are the state-of-the- art statistical machine translation (smt) meth ods.</citsent>
<aftsection>
<nextsent>over the last several years, an increasing amount of work has been done to combine the advantages of the two approaches.
</nextsent>
<nextsent>deneefe et al (2007) <papid> D07-1079 </papid>made quantitative comparison of the phrase pairs that each model has to work with and found it is useful to improve the phrasal coverage of their string-to-tree model.</nextsent>
<nextsent>liu et al (2007) <papid> P07-1089 </papid>proposed forest-to-string rules to capture the non-syntactic phrases in their tree-to-string model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1832">
<title id=" W10-3804.xml">syntactic constraints on phrase extraction for phrase based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>rather than filter out all non-syntactic phrases, we only apply syntactic constraints when there is phrase segmentation ambiguity arising from unaligned words.
</prevsent>
<prevsent>our method is very simple and yields 24.38% phrase pair reduction and 0.52 bleu point improvement when compared to baseline pbmt system with full-size tables.
</prevsent>
</prevsection>
<citsent citstr=" W06-1606 ">
both pbmt models (koehn et al, 2003; <papid> N03-1017 </papid>chiang, 2005) <papid> P05-1033 </papid>and syntax-based machine translation models (yamada et al, 2000; quirk et al, 2005; <papid> P05-1034 </papid>galley et al, 2006; <papid> P06-1121 </papid>liu et al, 2006; <papid> P06-1077 </papid>marcu et al, 2006; <papid> W06-1606 </papid>and numerous others) are the state-of-the- art statistical machine translation (smt) meth ods.</citsent>
<aftsection>
<nextsent>over the last several years, an increasing amount of work has been done to combine the advantages of the two approaches.
</nextsent>
<nextsent>deneefe et al (2007) <papid> D07-1079 </papid>made quantitative comparison of the phrase pairs that each model has to work with and found it is useful to improve the phrasal coverage of their string-to-tree model.</nextsent>
<nextsent>liu et al (2007) <papid> P07-1089 </papid>proposed forest-to-string rules to capture the non-syntactic phrases in their tree-to-string model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1833">
<title id=" W10-3804.xml">syntactic constraints on phrase extraction for phrase based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>both pbmt models (koehn et al, 2003; <papid> N03-1017 </papid>chiang, 2005) <papid> P05-1033 </papid>and syntax-based machine translation models (yamada et al, 2000; quirk et al, 2005; <papid> P05-1034 </papid>galley et al, 2006; <papid> P06-1121 </papid>liu et al, 2006; <papid> P06-1077 </papid>marcu et al, 2006; <papid> W06-1606 </papid>and numerous others) are the state-of-the- art statistical machine translation (smt) meth ods.</prevsent>
<prevsent>over the last several years, an increasing amount of work has been done to combine the advantages of the two approaches.</prevsent>
</prevsection>
<citsent citstr=" D07-1079 ">
deneefe et al (2007) <papid> D07-1079 </papid>made quantitative comparison of the phrase pairs that each model has to work with and found it is useful to improve the phrasal coverage of their string-to-tree model.</citsent>
<aftsection>
<nextsent>liu et al (2007) <papid> P07-1089 </papid>proposed forest-to-string rules to capture the non-syntactic phrases in their tree-to-string model.</nextsent>
<nextsent>zhang et al (2008) <papid> P08-1064 </papid>proposed tree sequence based tree-to-tree model which can describe non-syntactic phrases with syntactic structure information.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1834">
<title id=" W10-3804.xml">syntactic constraints on phrase extraction for phrase based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>over the last several years, an increasing amount of work has been done to combine the advantages of the two approaches.
</prevsent>
<prevsent>deneefe et al (2007) <papid> D07-1079 </papid>made quantitative comparison of the phrase pairs that each model has to work with and found it is useful to improve the phrasal coverage of their string-to-tree model.</prevsent>
</prevsection>
<citsent citstr=" P07-1089 ">
liu et al (2007) <papid> P07-1089 </papid>proposed forest-to-string rules to capture the non-syntactic phrases in their tree-to-string model.</citsent>
<aftsection>
<nextsent>zhang et al (2008) <papid> P08-1064 </papid>proposed tree sequence based tree-to-tree model which can describe non-syntactic phrases with syntactic structure information.</nextsent>
<nextsent>the converse of the above methods is to incorporate syntactic information into the pbmt model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1835">
<title id=" W10-3804.xml">syntactic constraints on phrase extraction for phrase based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>deneefe et al (2007) <papid> D07-1079 </papid>made quantitative comparison of the phrase pairs that each model has to work with and found it is useful to improve the phrasal coverage of their string-to-tree model.</prevsent>
<prevsent>liu et al (2007) <papid> P07-1089 </papid>proposed forest-to-string rules to capture the non-syntactic phrases in their tree-to-string model.</prevsent>
</prevsection>
<citsent citstr=" P08-1064 ">
zhang et al (2008) <papid> P08-1064 </papid>proposed tree sequence based tree-to-tree model which can describe non-syntactic phrases with syntactic structure information.</citsent>
<aftsection>
<nextsent>the converse of the above methods is to incorporate syntactic information into the pbmt model.
</nextsent>
<nextsent>zollmann and venugopal (2006) <papid> W06-3119 </papid>started with complete set of phrases as extracted by traditional pbmt heuristics, and then annotated the target side of each phrasal entry with the label of the constituent node in the target-side parse tree that subsumes the span.</nextsent>
<nextsent>marton and resnik (2008) <papid> P08-1114 </papid>and cherry (2008) <papid> P08-1009 </papid>imposed syntactic constraints on the pbmt system by making use of prior linguistic knowledge in the form of syntax analysis.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1836">
<title id=" W10-3804.xml">syntactic constraints on phrase extraction for phrase based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>zhang et al (2008) <papid> P08-1064 </papid>proposed tree sequence based tree-to-tree model which can describe non-syntactic phrases with syntactic structure information.</prevsent>
<prevsent>the converse of the above methods is to incorporate syntactic information into the pbmt model.</prevsent>
</prevsection>
<citsent citstr=" W06-3119 ">
zollmann and venugopal (2006) <papid> W06-3119 </papid>started with complete set of phrases as extracted by traditional pbmt heuristics, and then annotated the target side of each phrasal entry with the label of the constituent node in the target-side parse tree that subsumes the span.</citsent>
<aftsection>
<nextsent>marton and resnik (2008) <papid> P08-1114 </papid>and cherry (2008) <papid> P08-1009 </papid>imposed syntactic constraints on the pbmt system by making use of prior linguistic knowledge in the form of syntax analysis.</nextsent>
<nextsent>in their pbmt decoders, candidate translation gets an extra credit if it respects the source side syntactic parse tree but may incur cost if it violates constituent boundary.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1837">
<title id=" W10-3804.xml">syntactic constraints on phrase extraction for phrase based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the converse of the above methods is to incorporate syntactic information into the pbmt model.
</prevsent>
<prevsent>zollmann and venugopal (2006) <papid> W06-3119 </papid>started with complete set of phrases as extracted by traditional pbmt heuristics, and then annotated the target side of each phrasal entry with the label of the constituent node in the target-side parse tree that subsumes the span.</prevsent>
</prevsection>
<citsent citstr=" P08-1114 ">
marton and resnik (2008) <papid> P08-1114 </papid>and cherry (2008) <papid> P08-1009 </papid>imposed syntactic constraints on the pbmt system by making use of prior linguistic knowledge in the form of syntax analysis.</citsent>
<aftsection>
<nextsent>in their pbmt decoders, candidate translation gets an extra credit if it respects the source side syntactic parse tree but may incur cost if it violates constituent boundary.
</nextsent>
<nextsent>xiong et al (2009) <papid> P09-1036 </papid>proposed syn tax-driven bracketing model to predict whether phrase (a sequence of contiguous words) is bracketable or not using rich syntactic con straints.</nextsent>
<nextsent>in this paper, we try to utilize syntactic knowledge to constrain the phrase extraction from word-based alignments for pbmt system.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1838">
<title id=" W10-3804.xml">syntactic constraints on phrase extraction for phrase based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the converse of the above methods is to incorporate syntactic information into the pbmt model.
</prevsent>
<prevsent>zollmann and venugopal (2006) <papid> W06-3119 </papid>started with complete set of phrases as extracted by traditional pbmt heuristics, and then annotated the target side of each phrasal entry with the label of the constituent node in the target-side parse tree that subsumes the span.</prevsent>
</prevsection>
<citsent citstr=" P08-1009 ">
marton and resnik (2008) <papid> P08-1114 </papid>and cherry (2008) <papid> P08-1009 </papid>imposed syntactic constraints on the pbmt system by making use of prior linguistic knowledge in the form of syntax analysis.</citsent>
<aftsection>
<nextsent>in their pbmt decoders, candidate translation gets an extra credit if it respects the source side syntactic parse tree but may incur cost if it violates constituent boundary.
</nextsent>
<nextsent>xiong et al (2009) <papid> P09-1036 </papid>proposed syn tax-driven bracketing model to predict whether phrase (a sequence of contiguous words) is bracketable or not using rich syntactic con straints.</nextsent>
<nextsent>in this paper, we try to utilize syntactic knowledge to constrain the phrase extraction from word-based alignments for pbmt system.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1839">
<title id=" W10-3804.xml">syntactic constraints on phrase extraction for phrase based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>marton and resnik (2008) <papid> P08-1114 </papid>and cherry (2008) <papid> P08-1009 </papid>imposed syntactic constraints on the pbmt system by making use of prior linguistic knowledge in the form of syntax analysis.</prevsent>
<prevsent>in their pbmt decoders, candidate translation gets an extra credit if it respects the source side syntactic parse tree but may incur cost if it violates constituent boundary.</prevsent>
</prevsection>
<citsent citstr=" P09-1036 ">
xiong et al (2009) <papid> P09-1036 </papid>proposed syn tax-driven bracketing model to predict whether phrase (a sequence of contiguous words) is bracketable or not using rich syntactic con straints.</citsent>
<aftsection>
<nextsent>in this paper, we try to utilize syntactic knowledge to constrain the phrase extraction from word-based alignments for pbmt system.
</nextsent>
<nextsent>rather than filter out all non-syntactic phrases, we only apply syntactic constraints when there is phrase segmentation ambiguity arising from unaligned words.
</nextsent>
<nextsent>our method is very simple and yields 24.38% phrase pair reduction and 0.52 bleu point improvement when compared to the baseline pbmt system with full-size tables.
</nextsent>
<nextsent>based alignments in this section, we briefly review simple and effective phrase pair extraction algorithm upon which this work builds.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1840">
<title id=" W10-3804.xml">syntactic constraints on phrase extraction for phrase based machine translation </title>
<section> extracting phrase pairs from word-.  </section>
<citcontext>
<prevsection>
<prevsent>figure 1: an example parallel sentence pair and word alignment since there is no phrase segmentation information in the word-aligned sentence pair, in practice all pairs of source word sequence ||| target word sequence?
</prevsent>
<prevsent>that are consistent with word alignments are collected.
</prevsent>
</prevsection>
<citsent citstr=" W99-0604 ">
the words in legal phrase pair are only aligned to each other, and not to words outside (och et al, 1999).<papid> W99-0604 </papid></citsent>
<aftsection>
<nextsent>for example, given sentence pair and its word alignments shown in figure1, the following nine phrase pairs will be extracted: source phrase ||| target phrase f1 ||| e1 f2 ||| e2 f4 ||| e3 f1 f2 ||| e1 e2 f2 f3 ||| e2 f3 f4 ||| e3 f1 f2 f3 ||| e1 e2 f2 f3 f4 ||| e2 e3 f1 f2 f3 f4 ||| e1 e2 e3 table 1: phrase pairs extracted from the example in figure 1 note that neither the source phrase nor the target phrase can be empty.
</nextsent>
<nextsent>so f3 ||| empty?
</nextsent>
<nextsent>is not legal phrase pair.
</nextsent>
<nextsent>phrase pairs are extracted over the entire training corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1841">
<title id=" W10-3804.xml">syntactic constraints on phrase extraction for phrase based machine translation </title>
<section> extracting phrase pairs from word-.  </section>
<citcontext>
<prevsection>
<prevsent>given all the collected phrase pairs, we can estimate the phrase translation probability distribution by relative frequency.
</prevsent>
<prevsent>the collected phrase pairs will also be used to build the lexicalized reordering model.
</prevsent>
</prevsection>
<citsent citstr=" P05-1069 ">
for more details of the lexicalized reordering model, please refer to tillmann and zhang (2005) <papid> P05-1069 </papid>and section 2.7.2 of the mosess manual1.</citsent>
<aftsection>
<nextsent>the main problem of such phrase pair extraction procedure is the resulting phrase translation table is very large, especially when large quantity of parallel data is available.
</nextsent>
<nextsent>this is not desirable in real application where speed and memory consumption are often critical concerns.
</nextsent>
<nextsent>in addition, some phrase translation pairs are generated from training data errors and word alignment noise.
</nextsent>
<nextsent>therefore, we need to filter the phrase table in an appropriate way for both efficiency and translation quality (johnson et al, 2007; <papid> D07-1103 </papid>yang and zheng, 2009).<papid> P09-2060 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1842">
<title id=" W10-3804.xml">syntactic constraints on phrase extraction for phrase based machine translation </title>
<section> extracting phrase pairs from word-.  </section>
<citcontext>
<prevsection>
<prevsent>this is not desirable in real application where speed and memory consumption are often critical concerns.
</prevsent>
<prevsent>in addition, some phrase translation pairs are generated from training data errors and word alignment noise.
</prevsent>
</prevsection>
<citsent citstr=" D07-1103 ">
therefore, we need to filter the phrase table in an appropriate way for both efficiency and translation quality (johnson et al, 2007; <papid> D07-1103 </papid>yang and zheng, 2009).<papid> P09-2060 </papid></citsent>
<aftsection>
<nextsent>f1 f2 f3 f4 | | | e1 e2 e3
</nextsent>
<nextsent>extraction we can divide all the possible phrases into two types: syntactic phrases and non-syntactic phrases.
</nextsent>
<nextsent>a syntactic phrase?
</nextsent>
<nextsent>is defined as word sequence that is covered by single sub tree in syntactic parse tree (imamura, 2002).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1843">
<title id=" W10-3804.xml">syntactic constraints on phrase extraction for phrase based machine translation </title>
<section> extracting phrase pairs from word-.  </section>
<citcontext>
<prevsection>
<prevsent>this is not desirable in real application where speed and memory consumption are often critical concerns.
</prevsent>
<prevsent>in addition, some phrase translation pairs are generated from training data errors and word alignment noise.
</prevsent>
</prevsection>
<citsent citstr=" P09-2060 ">
therefore, we need to filter the phrase table in an appropriate way for both efficiency and translation quality (johnson et al, 2007; <papid> D07-1103 </papid>yang and zheng, 2009).<papid> P09-2060 </papid></citsent>
<aftsection>
<nextsent>f1 f2 f3 f4 | | | e1 e2 e3
</nextsent>
<nextsent>extraction we can divide all the possible phrases into two types: syntactic phrases and non-syntactic phrases.
</nextsent>
<nextsent>a syntactic phrase?
</nextsent>
<nextsent>is defined as word sequence that is covered by single sub tree in syntactic parse tree (imamura, 2002).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1850">
<title id=" W10-3804.xml">syntactic constraints on phrase extraction for phrase based machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>so our algorithm uses prior syntactic knowledge to keep f3 f4 ||| e3?
</prevsent>
<prevsent>and exclude f2 f3 ||| e2?.
</prevsent>
</prevsection>
<citsent citstr=" W08-0334 ">
our smt system is based on fairly typical phrase-based model (finch and sumita, 2008).<papid> W08-0334 </papid></citsent>
<aftsection>
<nextsent>for the training of our smt model, we use modified training toolkit adapted from the moses decoder.
</nextsent>
<nextsent>our decoder can operate on the same principles as the moses decoder.
</nextsent>
<nextsent>minimum error rate training (mert) with respect to bleu score is used to tune the decoders parameters, and it is performed using the standard technique of och (2003).<papid> P03-1021 </papid></nextsent>
<nextsent>a lexicalized reordering model was built by using the msdbidirectional-fe?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1851">
<title id=" W10-3804.xml">syntactic constraints on phrase extraction for phrase based machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>for the training of our smt model, we use modified training toolkit adapted from the moses decoder.
</prevsent>
<prevsent>our decoder can operate on the same principles as the moses decoder.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
minimum error rate training (mert) with respect to bleu score is used to tune the decoders parameters, and it is performed using the standard technique of och (2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>a lexicalized reordering model was built by using the msdbidirectional-fe?
</nextsent>
<nextsent>configuration in our experiments.
</nextsent>
<nextsent>the translation model was created from the fbis parallel corpus.
</nextsent>
<nextsent>we used 5-gram language model trained with modified kneser-ney smoothing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1852">
<title id=" W10-3804.xml">syntactic constraints on phrase extraction for phrase based machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the development and test sets are from the nist mt08 evaluation campaign.
</prevsent>
<prevsent>table 3 shows the statistics of the corpora used in our experiments.
</prevsent>
</prevsection>
<citsent citstr=" P09-1058 ">
n3 n2 n1 f1 f2 f3 f4 e1 e2 e3 data sentences chinese words english words training set 221,994 6,251,554 8,065,629 development set 1,664 38,779 46,387 test set 1,357 32,377 42,444 gigaword 19,049,757 - 306,221,306 table 3: corpora statistics the chinese sentences are segmented, pos tagged and parsed by the tools described in kruengkrai et al (2009) <papid> P09-1058 </papid>and cao et al (2007), both of which are trained on the penn chinese tree bank 6.0.</citsent>
<aftsection>
<nextsent>30 4.1 experiments on word alignments.
</nextsent>
<nextsent>we use giza++ to align the sentences in both the chinese-english and english-chinese directions.
</nextsent>
<nextsent>then we combine the alignments using the standard grow-diag-final-and?
</nextsent>
<nextsent>procedure provided with moses.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1853">
<title id=" W10-3804.xml">syntactic constraints on phrase extraction for phrase based machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>with the exception of the above differences in phrase translation pair extraction, all the other settings were the identical in the three experiments.
</prevsent>
<prevsent>table 5 summarizes the smt performance.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
the evaluation metric is case sensitive bleu-4 (papineni et al, 2002) <papid> P02-1040 </papid>which estimates the accuracy of translation output with respect to set of reference translations.</citsent>
<aftsection>
<nextsent>syntactic constraints number of distinct phrase pairs bleu none 14,195,686 17.26 full constraint 4,855,108 16.51 selectively constraint 10,733,731 17.78 table 5: comparison of different constraints on phrase pair extraction by translation quality as shown in the table, it is harmful to fully apply syntactic constraints on phrase extraction, even just on the source language side.
</nextsent>
<nextsent>this is consistent with the observation of (koehn et al, 2003) <papid> N03-1017 </papid>who applied both source and target constraints in german to english translation ex periments.</nextsent>
<nextsent>clearly, we obtained the best performance if we use source language syntactic constraints only on phrases whose first or last source word is unaligned.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1857">
<title id=" W10-3804.xml">syntactic constraints on phrase extraction for phrase based machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the results in table 5 show that while some non-syntactic phrases are very important to maintain the performance of pbmt system, not all of them are necessary.
</prevsent>
<prevsent>we can achieve better performance and smaller phrase table by applying syntactic constraints when there is phrase segmentation ambiguity arising from unaligned words.
</prevsent>
</prevsection>
<citsent citstr=" W08-0409 ">
to some extent, our idea is similar to ma et al (2008), <papid> W08-0409 </papid>who used an anchor word alignment model to find set of high-precision anchor links and then aligned the remaining words relying on dependency information invoked by the acquired anchor links.</citsent>
<aftsection>
<nextsent>the similarity is that both ma et al (2008) <papid> W08-0409 </papid>and this work utilize structure information to find appropriate translations for words which are difficult to align.</nextsent>
<nextsent>the differ 31 ence is that they used dependency information in the word alignment stage while our method uses syntactic information during the phrase pair extraction stage.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1859">
<title id=" W10-3804.xml">syntactic constraints on phrase extraction for phrase based machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the similarity is that both ma et al (2008) <papid> W08-0409 </papid>and this work utilize structure information to find appropriate translations for words which are difficult to align.</prevsent>
<prevsent>the differ 31 ence is that they used dependency information in the word alignment stage while our method uses syntactic information during the phrase pair extraction stage.</prevsent>
</prevsection>
<citsent citstr=" P06-2014 ">
there are also many works which leverage syntax information to improve word alignments (e.g., cherry and lin, 2006; <papid> P06-2014 </papid>denero and klein, 2007; <papid> P07-1003 </papid>fossum et al, 2008; <papid> W08-0306 </papid>hermjakob, 2009).<papid> D09-1024 </papid></citsent>
<aftsection>
<nextsent>johnson et al, (2007) <papid> D07-1103 </papid>presented technique for pruning the phrase table in pbmt system using fishers exact test.</nextsent>
<nextsent>they compute the significance value of each phrase pair and prune the table by deleting phrase pairs with significance values smaller than certain threshold.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1860">
<title id=" W10-3804.xml">syntactic constraints on phrase extraction for phrase based machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the similarity is that both ma et al (2008) <papid> W08-0409 </papid>and this work utilize structure information to find appropriate translations for words which are difficult to align.</prevsent>
<prevsent>the differ 31 ence is that they used dependency information in the word alignment stage while our method uses syntactic information during the phrase pair extraction stage.</prevsent>
</prevsection>
<citsent citstr=" P07-1003 ">
there are also many works which leverage syntax information to improve word alignments (e.g., cherry and lin, 2006; <papid> P06-2014 </papid>denero and klein, 2007; <papid> P07-1003 </papid>fossum et al, 2008; <papid> W08-0306 </papid>hermjakob, 2009).<papid> D09-1024 </papid></citsent>
<aftsection>
<nextsent>johnson et al, (2007) <papid> D07-1103 </papid>presented technique for pruning the phrase table in pbmt system using fishers exact test.</nextsent>
<nextsent>they compute the significance value of each phrase pair and prune the table by deleting phrase pairs with significance values smaller than certain threshold.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1861">
<title id=" W10-3804.xml">syntactic constraints on phrase extraction for phrase based machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the similarity is that both ma et al (2008) <papid> W08-0409 </papid>and this work utilize structure information to find appropriate translations for words which are difficult to align.</prevsent>
<prevsent>the differ 31 ence is that they used dependency information in the word alignment stage while our method uses syntactic information during the phrase pair extraction stage.</prevsent>
</prevsection>
<citsent citstr=" W08-0306 ">
there are also many works which leverage syntax information to improve word alignments (e.g., cherry and lin, 2006; <papid> P06-2014 </papid>denero and klein, 2007; <papid> P07-1003 </papid>fossum et al, 2008; <papid> W08-0306 </papid>hermjakob, 2009).<papid> D09-1024 </papid></citsent>
<aftsection>
<nextsent>johnson et al, (2007) <papid> D07-1103 </papid>presented technique for pruning the phrase table in pbmt system using fishers exact test.</nextsent>
<nextsent>they compute the significance value of each phrase pair and prune the table by deleting phrase pairs with significance values smaller than certain threshold.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1862">
<title id=" W10-3804.xml">syntactic constraints on phrase extraction for phrase based machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the similarity is that both ma et al (2008) <papid> W08-0409 </papid>and this work utilize structure information to find appropriate translations for words which are difficult to align.</prevsent>
<prevsent>the differ 31 ence is that they used dependency information in the word alignment stage while our method uses syntactic information during the phrase pair extraction stage.</prevsent>
</prevsection>
<citsent citstr=" D09-1024 ">
there are also many works which leverage syntax information to improve word alignments (e.g., cherry and lin, 2006; <papid> P06-2014 </papid>denero and klein, 2007; <papid> P07-1003 </papid>fossum et al, 2008; <papid> W08-0306 </papid>hermjakob, 2009).<papid> D09-1024 </papid></citsent>
<aftsection>
<nextsent>johnson et al, (2007) <papid> D07-1103 </papid>presented technique for pruning the phrase table in pbmt system using fishers exact test.</nextsent>
<nextsent>they compute the significance value of each phrase pair and prune the table by deleting phrase pairs with significance values smaller than certain threshold.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1867">
<title id=" W10-3804.xml">syntactic constraints on phrase extraction for phrase based machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>they compute the significance value of each phrase pair and prune the table by deleting phrase pairs with significance values smaller than certain threshold.
</prevsent>
<prevsent>yang and zheng (2008) extended the work in johnson et al, (2007) <papid> D07-1103 </papid>to hierarchical pbmt model, which is built on synchronous context free grammars (scfg).</prevsent>
</prevsection>
<citsent citstr=" W04-3243 ">
tomeh et al, (2009) described an approach for filtering phrase tables in statistical machine translation system, which relies on statistical independence measure called noise, first introduced in (moore, 2004).<papid> W04-3243 </papid></citsent>
<aftsection>
<nextsent>the difference between the above research and this work is they took advantage of some statistical measures while we use syntactic knowledge to filter phrase tables.
</nextsent>
<nextsent>phrase pair extraction plays very important role on the performance of pbmt systems.
</nextsent>
<nextsent>we utilize syntactic knowledge to constrain the phrase extraction from word-based alignments for pbmt system.
</nextsent>
<nextsent>rather than filter out all non-syntactic phrases, we only filter out non syntactic phrases whose first or last source word is unaligned.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1868">
<title id=" W10-1909.xml">an exploration of mining gene expression mentions and their anatomical locations from biomedical text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>text-mining tools aim to alleviate this problem by extracting structured information from unstructured text.
</prevsent>
<prevsent>considerable attention has been given to some areas in text-mining, such as recognizing named entities (e.g. species, genes and drugs) (rebholz-schuhmann et al, 2007; hakenberg et al, 2008; gerner et al, 2010) and extracting molecular relationships, e.g. protein protein interactions (donaldson et al, 2003; plake et al, 2006; chowdhary et al, 2009).
</prevsent>
</prevsection>
<citsent citstr=" W09-1401 ">
many other areas of text mining in the biomedical domain are less mature, including the extraction of information about the expression of genes (kim et al, 2009).<papid> W09-1401 </papid></citsent>
<aftsection>
<nextsent>the literature contains large amount of information about where and when genes are expressed, as knowledge about the expression of gene is critical for understanding its function and has therefore often been reported as part of gene studies.
</nextsent>
<nextsent>gene expression profiles from genome-wide studies are available in specialized databases such as the ncbi gene expression omnibus (barrett et al, 2009) and fly atlas (chintapalli et al, 2007), but results on gene expression from smaller studies remain locked in the primary literature.
</nextsent>
<nextsent>previously, number of data-mining projects have combined text-mining methods with structured genome-wide gene expression data in order 72to allow further interpretation of the gene expression data (natarajan et al, 2006; fundel, 2007).
</nextsent>
<nextsent>however, only recently has interest in text mining tools aimed at extracting gene expression profiles from primary literature started to grow.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1871">
<title id=" W10-1909.xml">an exploration of mining gene expression mentions and their anatomical locations from biomedical text </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>gold-standard corpus in order to make meaningful evaluation of the accuracy of text-mining applications, gold standard corpus, consisting of manually annotated mentions for set of documents, is required.
</prevsent>
<prevsent>previously, no such corpus existed that was suitable for this problem (providing annotations linked to mentions of both gene and anatomical locations).
</prevsent>
</prevsection>
<citsent citstr=" W09-1313 ">
however, the bionlp corpus (ohta et al, 2009) <papid> W09-1313 </papid>which is based on the genia corpus (kim et al, 2008), does contain annotations about gene expression.</citsent>
<aftsection>
<nextsent>annotations in the corpus contain trigger terms that are linked to genes (or gene products) where the authors discuss gene expression.
</nextsent>
<nextsent>however, anatomical locations have not been annotated in this corpus.
</nextsent>
<nextsent>in order to allow evaluation of the accuracy of our software, we extended the annotations of gene expression events in part of the bionlp corpus.
</nextsent>
<nextsent>each gene expression entry in the corpus was linked to the anatomical location or cell line that the author mentioned.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1874">
<title id=" W10-1603.xml">variable length markov models and ambiguous words in portuguese </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>previous and current work have developed wide range of models and methods for tagging.
</prevsent>
<prevsent>the vast majority uses supervised learning methods, which during the course of this work fabio received support from brazilian funding agencies capes and cnpq.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
need an already tagged corpus as input in order totrain the model, calculating relations, weights, probabilities etc. among the various models for tagging, there are maximum entropy models (dos santos et al, 2008;de almeida filho, 2002; ratnaparkhi, 1996), <papid> W96-0213 </papid>hidden markov models (hmms) (brants, 2000), <papid> A00-1031 </papid>transformation based learning (brill, 1993), <papid> P93-1035 </papid>and other succesful approaches (toutanova et al, 2003; <papid> N03-1033 </papid>tsuruoka and tsujii, 2005; <papid> H05-1059 </papid>shen et al, 2007).<papid> P07-1096 </papid></citsent>
<aftsection>
<nextsent>current state-of-the-art precision in tagging is achieved by supervised methods.
</nextsent>
<nextsent>although precision is pretty high ? less than 3% error rate for english ? the disavantage is exactly the need of tagged corpus, usually built manually.
</nextsent>
<nextsent>this is very restrictive issue for languages with lack of resources such as linguistic especial ists, corpora projects etc.the portuguese language falls in between resourceful languages, such as english, and languages with restricted resources.
</nextsent>
<nextsent>there have been initiatives both in brazil and in portugal, which include modern brazilian portuguese corpora (icmc-usp, 2010), european portuguese corpora (flo, 2008), and historical portuguese corpora (iel-unicamp and ime-usp, 2010).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1875">
<title id=" W10-1603.xml">variable length markov models and ambiguous words in portuguese </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>previous and current work have developed wide range of models and methods for tagging.
</prevsent>
<prevsent>the vast majority uses supervised learning methods, which during the course of this work fabio received support from brazilian funding agencies capes and cnpq.
</prevsent>
</prevsection>
<citsent citstr=" A00-1031 ">
need an already tagged corpus as input in order totrain the model, calculating relations, weights, probabilities etc. among the various models for tagging, there are maximum entropy models (dos santos et al, 2008;de almeida filho, 2002; ratnaparkhi, 1996), <papid> W96-0213 </papid>hidden markov models (hmms) (brants, 2000), <papid> A00-1031 </papid>transformation based learning (brill, 1993), <papid> P93-1035 </papid>and other succesful approaches (toutanova et al, 2003; <papid> N03-1033 </papid>tsuruoka and tsujii, 2005; <papid> H05-1059 </papid>shen et al, 2007).<papid> P07-1096 </papid></citsent>
<aftsection>
<nextsent>current state-of-the-art precision in tagging is achieved by supervised methods.
</nextsent>
<nextsent>although precision is pretty high ? less than 3% error rate for english ? the disavantage is exactly the need of tagged corpus, usually built manually.
</nextsent>
<nextsent>this is very restrictive issue for languages with lack of resources such as linguistic especial ists, corpora projects etc.the portuguese language falls in between resourceful languages, such as english, and languages with restricted resources.
</nextsent>
<nextsent>there have been initiatives both in brazil and in portugal, which include modern brazilian portuguese corpora (icmc-usp, 2010), european portuguese corpora (flo, 2008), and historical portuguese corpora (iel-unicamp and ime-usp, 2010).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1876">
<title id=" W10-1603.xml">variable length markov models and ambiguous words in portuguese </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>previous and current work have developed wide range of models and methods for tagging.
</prevsent>
<prevsent>the vast majority uses supervised learning methods, which during the course of this work fabio received support from brazilian funding agencies capes and cnpq.
</prevsent>
</prevsection>
<citsent citstr=" P93-1035 ">
need an already tagged corpus as input in order totrain the model, calculating relations, weights, probabilities etc. among the various models for tagging, there are maximum entropy models (dos santos et al, 2008;de almeida filho, 2002; ratnaparkhi, 1996), <papid> W96-0213 </papid>hidden markov models (hmms) (brants, 2000), <papid> A00-1031 </papid>transformation based learning (brill, 1993), <papid> P93-1035 </papid>and other succesful approaches (toutanova et al, 2003; <papid> N03-1033 </papid>tsuruoka and tsujii, 2005; <papid> H05-1059 </papid>shen et al, 2007).<papid> P07-1096 </papid></citsent>
<aftsection>
<nextsent>current state-of-the-art precision in tagging is achieved by supervised methods.
</nextsent>
<nextsent>although precision is pretty high ? less than 3% error rate for english ? the disavantage is exactly the need of tagged corpus, usually built manually.
</nextsent>
<nextsent>this is very restrictive issue for languages with lack of resources such as linguistic especial ists, corpora projects etc.the portuguese language falls in between resourceful languages, such as english, and languages with restricted resources.
</nextsent>
<nextsent>there have been initiatives both in brazil and in portugal, which include modern brazilian portuguese corpora (icmc-usp, 2010), european portuguese corpora (flo, 2008), and historical portuguese corpora (iel-unicamp and ime-usp, 2010).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1877">
<title id=" W10-1603.xml">variable length markov models and ambiguous words in portuguese </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>previous and current work have developed wide range of models and methods for tagging.
</prevsent>
<prevsent>the vast majority uses supervised learning methods, which during the course of this work fabio received support from brazilian funding agencies capes and cnpq.
</prevsent>
</prevsection>
<citsent citstr=" N03-1033 ">
need an already tagged corpus as input in order totrain the model, calculating relations, weights, probabilities etc. among the various models for tagging, there are maximum entropy models (dos santos et al, 2008;de almeida filho, 2002; ratnaparkhi, 1996), <papid> W96-0213 </papid>hidden markov models (hmms) (brants, 2000), <papid> A00-1031 </papid>transformation based learning (brill, 1993), <papid> P93-1035 </papid>and other succesful approaches (toutanova et al, 2003; <papid> N03-1033 </papid>tsuruoka and tsujii, 2005; <papid> H05-1059 </papid>shen et al, 2007).<papid> P07-1096 </papid></citsent>
<aftsection>
<nextsent>current state-of-the-art precision in tagging is achieved by supervised methods.
</nextsent>
<nextsent>although precision is pretty high ? less than 3% error rate for english ? the disavantage is exactly the need of tagged corpus, usually built manually.
</nextsent>
<nextsent>this is very restrictive issue for languages with lack of resources such as linguistic especial ists, corpora projects etc.the portuguese language falls in between resourceful languages, such as english, and languages with restricted resources.
</nextsent>
<nextsent>there have been initiatives both in brazil and in portugal, which include modern brazilian portuguese corpora (icmc-usp, 2010), european portuguese corpora (flo, 2008), and historical portuguese corpora (iel-unicamp and ime-usp, 2010).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1878">
<title id=" W10-1603.xml">variable length markov models and ambiguous words in portuguese </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>previous and current work have developed wide range of models and methods for tagging.
</prevsent>
<prevsent>the vast majority uses supervised learning methods, which during the course of this work fabio received support from brazilian funding agencies capes and cnpq.
</prevsent>
</prevsection>
<citsent citstr=" H05-1059 ">
need an already tagged corpus as input in order totrain the model, calculating relations, weights, probabilities etc. among the various models for tagging, there are maximum entropy models (dos santos et al, 2008;de almeida filho, 2002; ratnaparkhi, 1996), <papid> W96-0213 </papid>hidden markov models (hmms) (brants, 2000), <papid> A00-1031 </papid>transformation based learning (brill, 1993), <papid> P93-1035 </papid>and other succesful approaches (toutanova et al, 2003; <papid> N03-1033 </papid>tsuruoka and tsujii, 2005; <papid> H05-1059 </papid>shen et al, 2007).<papid> P07-1096 </papid></citsent>
<aftsection>
<nextsent>current state-of-the-art precision in tagging is achieved by supervised methods.
</nextsent>
<nextsent>although precision is pretty high ? less than 3% error rate for english ? the disavantage is exactly the need of tagged corpus, usually built manually.
</nextsent>
<nextsent>this is very restrictive issue for languages with lack of resources such as linguistic especial ists, corpora projects etc.the portuguese language falls in between resourceful languages, such as english, and languages with restricted resources.
</nextsent>
<nextsent>there have been initiatives both in brazil and in portugal, which include modern brazilian portuguese corpora (icmc-usp, 2010), european portuguese corpora (flo, 2008), and historical portuguese corpora (iel-unicamp and ime-usp, 2010).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1879">
<title id=" W10-1603.xml">variable length markov models and ambiguous words in portuguese </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>previous and current work have developed wide range of models and methods for tagging.
</prevsent>
<prevsent>the vast majority uses supervised learning methods, which during the course of this work fabio received support from brazilian funding agencies capes and cnpq.
</prevsent>
</prevsection>
<citsent citstr=" P07-1096 ">
need an already tagged corpus as input in order totrain the model, calculating relations, weights, probabilities etc. among the various models for tagging, there are maximum entropy models (dos santos et al, 2008;de almeida filho, 2002; ratnaparkhi, 1996), <papid> W96-0213 </papid>hidden markov models (hmms) (brants, 2000), <papid> A00-1031 </papid>transformation based learning (brill, 1993), <papid> P93-1035 </papid>and other succesful approaches (toutanova et al, 2003; <papid> N03-1033 </papid>tsuruoka and tsujii, 2005; <papid> H05-1059 </papid>shen et al, 2007).<papid> P07-1096 </papid></citsent>
<aftsection>
<nextsent>current state-of-the-art precision in tagging is achieved by supervised methods.
</nextsent>
<nextsent>although precision is pretty high ? less than 3% error rate for english ? the disavantage is exactly the need of tagged corpus, usually built manually.
</nextsent>
<nextsent>this is very restrictive issue for languages with lack of resources such as linguistic especial ists, corpora projects etc.the portuguese language falls in between resourceful languages, such as english, and languages with restricted resources.
</nextsent>
<nextsent>there have been initiatives both in brazil and in portugal, which include modern brazilian portuguese corpora (icmc-usp, 2010), european portuguese corpora (flo, 2008), and historical portuguese corpora (iel-unicamp and ime-usp, 2010).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1880">
<title id=" W10-1603.xml">variable length markov models and ambiguous words in portuguese </title>
<section> auxiliary approaches.  </section>
<citcontext>
<prevsection>
<prevsent>table 5shows what happens with the normal corpus.the error rate of is decreased almost 5% with this bidirectional approach.
</prevsent>
<prevsent>3.4 perceptron.
</prevsent>
</prevsection>
<citsent citstr=" W02-1001 ">
the perceptron algorithm was first applied to pos tagging by (collins, 2002).<papid> W02-1001 </papid></citsent>
<aftsection>
<nextsent>it is an algorithm for supervised learning that resembles reinforcement learning, but is simpler and easier to implement.(collins, 2002) <papid> W02-1001 </papid>describes the algorithm for trigram hmm taggers.</nextsent>
<nextsent>here, we will describe it forthe vlmm tagger, adapting the notation and expla nation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1887">
<title id=" W10-3304.xml">finding medical term variations using parallel corpora and distributional similarity </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in other words, you can grasp the meaning of word by looking at its contexts.
</prevsent>
<prevsent>context can be defined in many ways.
</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
previous work has been mainly concerned with the syntactic contexts word is found in (lin, 1998; <papid> P98-2127 </papid>curran, 2003).</citsent>
<aftsection>
<nextsent>for example, the verbs that are in subject relation with particular noun form part of its context.
</nextsent>
<nextsent>in accordance with the fir thian tradition these contexts can be used to determine the semantic relatedness of words.
</nextsent>
<nextsent>for instance, words that occur in object relation with the verbto drink have something in common: they are liquid.
</nextsent>
<nextsent>other work has been concerned with the bag of-word context, where the context of word are the words that are found in its proximity (wilks et al., 1993; schutze, 1992).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1888">
<title id=" W10-3304.xml">finding medical term variations using parallel corpora and distributional similarity </title>
<section> alignment-based methods.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 translational context.
</prevsent>
<prevsent>the translational context of word or multiword term is the set of translations it gets in other languages.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
for the acquisition of translations for the dutch medical terms we relyon automatic word alignment in parallel corpora.figure 1: example of bidirectional word alignments of two parallel sentences figure 1 illustrates the automatic word alignment between dutch and an english phrase as result of using the ibm alignment models (brown et al, 1993) <papid> J93-2003 </papid>implemented in the open-source tool giza++ (och, 2003).</citsent>
<aftsection>
<nextsent>the alignment of two texts is bi-directional.
</nextsent>
<nextsent>the dutch text is aligned tothe english text and vice versa (dotted lines versus continuous lines).
</nextsent>
<nextsent>the alignment models produced are asymmetric.
</nextsent>
<nextsent>several heuristics exist to combine directional word alignments which is usually called symmetrization?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1889">
<title id=" W10-3304.xml">finding medical term variations using parallel corpora and distributional similarity </title>
<section> alignment-based methods.  </section>
<citcontext>
<prevsection>
<prevsent>we will explain in section 3 what measures we have chosen in the current experiments.
</prevsent>
<prevsent>2.3 related work.
</prevsent>
</prevsection>
<citsent citstr=" W02-0808 ">
multilingual parallel corpora have mostly been used for tasks related to word sense disambiguation such as separation of senses (resnik and yarowsky, 1997; dyvik, 1998; ide et al, 2002).<papid> W02-0808 </papid></citsent>
<aftsection>
<nextsent>however, taking sense separation as basis, dyvik (2002) derives relations such as synonymyand hyponymy by applying the method of semantic mirrors.
</nextsent>
<nextsent>the paper illustrates how the method works.
</nextsent>
<nextsent>first, different senses are identified on the basis of manual word translations in sentence-aligned norwegian-english data (2,6 million words in total).
</nextsent>
<nextsent>second, senses are grouped in semantic fields.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1890">
<title id=" W10-3304.xml">finding medical term variations using parallel corpora and distributional similarity </title>
<section> alignment-based methods.  </section>
<citcontext>
<prevsection>
<prevsent>second, senses are grouped in semantic fields.
</prevsent>
<prevsent>third, features are 30assigned on the basis of inheritance.
</prevsent>
</prevsection>
<citsent citstr=" W03-1610 ">
lastly, semantic relations such synonymy and hyponymy are detected based on intersection and inclusion among feature sets .improving the syntax-based approach for synonym identification using bilingual dictionaries has been discussed in lin et al (2003) and wu and zhou (2003).<papid> W03-1610 </papid></citsent>
<aftsection>
<nextsent>in the latter parallel corpora are also applied as reference to assign translation likeli hoods to candidates derived from the dictionary.
</nextsent>
<nextsent>both of them are limited to single-word terms.
</nextsent>
<nextsent>some researchers employ multilingual corpora for the automatic acquisition of paraphrases (shimota and sumita, 2002; bannard and callison burch, 2005; <papid> P05-1074 </papid>callison-burch, 2008).</nextsent>
<nextsent>the last two are based on automatic word alignment as is our approach.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1891">
<title id=" W10-3304.xml">finding medical term variations using parallel corpora and distributional similarity </title>
<section> alignment-based methods.  </section>
<citcontext>
<prevsection>
<prevsent>in the latter parallel corpora are also applied as reference to assign translation likeli hoods to candidates derived from the dictionary.
</prevsent>
<prevsent>both of them are limited to single-word terms.
</prevsent>
</prevsection>
<citsent citstr=" P05-1074 ">
some researchers employ multilingual corpora for the automatic acquisition of paraphrases (shimota and sumita, 2002; bannard and callison burch, 2005; <papid> P05-1074 </papid>callison-burch, 2008).</citsent>
<aftsection>
<nextsent>the last two are based on automatic word alignment as is our approach.
</nextsent>
<nextsent>bannard and callison-burch (2005) use amethod that is also rooted in phrase-based statistical machine translation.
</nextsent>
<nextsent>translation probabilities provide ranking of candidate paraphrases.these are refined by taking contextual information into account in the form of language model.
</nextsent>
<nextsent>the europarl corpus (koehn, 2005) is used.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1892">
<title id=" W10-3304.xml">finding medical term variations using parallel corpora and distributional similarity </title>
<section> materials and methods.  </section>
<citcontext>
<prevsection>
<prevsent>function that induces lexical features from the bitext to be combined with length based features.
</prevsent>
<prevsent>word alignment has been performed using giza++ (och, 2003).
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
we used standard settings defined in the moses toolkit (koehn et al, 2007) <papid> P07-2045 </papid>to generate viterbi word alignments of ibm model 4 for sentences 31 not longer than 80 tokens.</citsent>
<aftsection>
<nextsent>in order to improve the statistical alignment we used lower cased tokens and lemmas in case we had them available (produced by the tree-tagger (schmid, 1994) and the alpino parser (van noord, 2006)).
</nextsent>
<nextsent>we used the grow heuristics to combine the asymmetric word alignments which starts with the intersection of the two viterbi alignments and adds block-neighboring points to it in second step.
</nextsent>
<nextsent>in this way we obtain high precision links with some many-to-many alignments.
</nextsent>
<nextsent>finally weused the phrase extraction tool from moses to extract phrase correspondences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1901">
<title id=" W10-3307.xml">developing a bio surveillance application ontology for influenzalikeillness </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>13www.nactem.ac.uk/software/termine/ 2.
</prevsent>
<prevsent>kwext (keyword extraction tool) (con-.
</prevsent>
</prevsection>
<citsent citstr=" J93-1003 ">
way, 2010) is linux based statistical key word extraction tool.14 we used kwextto extract 1536 unigrams, bigrams and trigrams using the log-likelihood method (dun ning, 1993).<papid> J93-1003 </papid></citsent>
<aftsection>
<nextsent>the log-likelihood method is designed to identify n-grams that occur withthe most frequency compared to some reference corpus.
</nextsent>
<nextsent>we used the flob corpus,15 one million multi-genre corpus consisting of american english from the early 1990s as our reference corpus.
</nextsent>
<nextsent>we ranked all n-grams according to their statistical significance and then manually identified the twenty-five highest ranked disease, finding and symptom terms.
</nextsent>
<nextsent>term lists derived using the termine andkwext tools are presented in tables 1 and 2 respectively.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1902">
<title id=" W10-2804.xml">relatedness curves for acquiring paraphrases </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>from these questions we extracted and paraphrased the most frequently occurring 20 patterns.
</prevsent>
<prevsent>since judging the correctness of these paraphrases out-of-context?
</prevsent>
</prevsection>
<citsent citstr=" P07-1058 ">
is rather difficult we limit ourselves to giving examples and analyzing errors made on this data; important observations can be clearly made this way, however in future work we plan to build proper evaluation setting (e.g. task-based or instance based in the sense of (szpektor et al, 2007)) <papid> P07-1058 </papid>for 29 more detailed analysis of the performance on the methods discussed.</citsent>
<aftsection>
<nextsent>4.1 results.
</nextsent>
<nextsent>we list the paraphrases obtained with the different methods for the pattern subj????
</nextsent>
<nextsent>show dobj????
</nextsent>
<nextsent>y . this pattern has been chosen out of the total set due to its medium difficulty in terms of paraphrasing;some of the patterns in our list are relatively accurately paraphrased by all methods, such as win, while others such as marry are almost impossible to paraphrase, for all methods.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1903">
<title id=" W10-2804.xml">relatedness curves for acquiring paraphrases </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>show dobj????
</prevsent>
<prevsent>y cost of losing coverage is not particularly difficult4 however not very useful.
</prevsent>
</prevsection>
<citsent citstr=" E09-1025 ">
previous work such as (dinu and wang, 2009) <papid> E09-1025 </papid>has shown that for these resources, the coverage is rather important aspect, since they have to capture the great variety of ways in which meaning can be expressed in different contexts.</citsent>
<aftsection>
<nextsent>curves2 dirt subj ????
</nextsent>
<nextsent>show dobj ????
</nextsent>
<nextsent>pobj ????
</nextsent>
<nextsent>in prp ???
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1904">
<title id=" W10-3009.xml">hedge detection using the rel hunter approach </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the hedge scope is the uncertain statement which is hedged by the cue.
</prevsent>
<prevsent>the scope always includes the corresponding cue.
</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
[ they indicate that [ the demonstration is possible in this context ] and there is correlation ] figure 1: sentence with two hedge instances.over the last two decades, several computational linguistic problems have been successfully modeled as local token classification tasks (brill, 1995; <papid> J95-4004 </papid>milidiu?</citsent>
<aftsection>
<nextsent>et al, 2009).
</nextsent>
<nextsent>nevertheless, the harder problems consist in identifying complex structures within text.
</nextsent>
<nextsent>these structures comprise many tokens and show non local token dependencies.
</nextsent>
<nextsent>phrase chunking (sang and buchholz, 2000) isa task that involves structure recognition.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1905">
<title id=" W10-3009.xml">hedge detection using the rel hunter approach </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>frp is very effective, although computationally expensive at both training and prediction time.
</prevsent>
<prevsent>currently, frp provides the best performing clause identification system.
</prevsent>
</prevsection>
<citsent citstr=" W09-1304 ">
in morante and daelemans (2009), <papid> W09-1304 </papid>the hedge detection task is solved as two consecutive classification tasks.</citsent>
<aftsection>
<nextsent>the first one consists of classifying the tokens of sentence as hedge cues using the iob tagging style.
</nextsent>
<nextsent>the second task consists of classifying tokens of sentence as being the start of hedge scope, the end of one, or neither.
</nextsent>
<nextsent>the result of those two tasks is combined using set of six rules to solve the hedge detection task.
</nextsent>
<nextsent>here, we describe rel hunter, new method for the extraction of structured information fromtext.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1909">
<title id=" W10-2915.xml">learning probabilistic synchronous cfgs for phrase based translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>surprisingly, our experiments on french-englishdata show that our learning method applied to far simpler models exhibits performance indistinguishable from the hiero system.
</prevsent>
<prevsent>a fundamental problem in phrase-based machine translation concerns the learning of probabilistic synchronous context-free grammar (scfg) over phrase pairs from an input parallel corpus.
</prevsent>
</prevsection>
<citsent citstr=" J07-2003 ">
chiangs hiero system (chiang, 2007) <papid> J07-2003 </papid>exemplifies the gains to be had by combining phrase-basedtranslation (och and ney, 2004) <papid> J04-4002 </papid>with the hierarchical reordering capabilities of scfgs, particularly originating from binary inversion transduction grammars (bitg) (wu, 1997).</citsent>
<aftsection>
<nextsent>yet, existing empirical work is largely based on successful heuristic techniques, and the learning of hiero-like bitg/scfg remains an unsolved problem, the difficulty of this problem stems from the need for simultaneously learning of two kinds of preferences (see fig.1) (1) lexical translation probabilities (p (e, f?
</nextsent>
<nextsent>| x)) of source (f ) and target(e) phrase pairs, and (2) phrase reordering preferences of target string relative to source string,expressed in synchronous productions probabilities (for monotone or switching productions).
</nextsent>
<nextsent>theoretically speaking, both kinds of preferences may involve latent structure relative to the parallel corpus.
</nextsent>
<nextsent>the mapping between source-targetsentence pairs can be expressed in terms of latent phrase segment ations and latent word/phrasealignments, and the hierarchical phrase reordering can be expressed in terms of latent binary synchronous hierarchical structures (cf.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1911">
<title id=" W10-2915.xml">learning probabilistic synchronous cfgs for phrase based translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>surprisingly, our experiments on french-englishdata show that our learning method applied to far simpler models exhibits performance indistinguishable from the hiero system.
</prevsent>
<prevsent>a fundamental problem in phrase-based machine translation concerns the learning of probabilistic synchronous context-free grammar (scfg) over phrase pairs from an input parallel corpus.
</prevsent>
</prevsection>
<citsent citstr=" J04-4002 ">
chiangs hiero system (chiang, 2007) <papid> J07-2003 </papid>exemplifies the gains to be had by combining phrase-basedtranslation (och and ney, 2004) <papid> J04-4002 </papid>with the hierarchical reordering capabilities of scfgs, particularly originating from binary inversion transduction grammars (bitg) (wu, 1997).</citsent>
<aftsection>
<nextsent>yet, existing empirical work is largely based on successful heuristic techniques, and the learning of hiero-like bitg/scfg remains an unsolved problem, the difficulty of this problem stems from the need for simultaneously learning of two kinds of preferences (see fig.1) (1) lexical translation probabilities (p (e, f?
</nextsent>
<nextsent>| x)) of source (f ) and target(e) phrase pairs, and (2) phrase reordering preferences of target string relative to source string,expressed in synchronous productions probabilities (for monotone or switching productions).
</nextsent>
<nextsent>theoretically speaking, both kinds of preferences may involve latent structure relative to the parallel corpus.
</nextsent>
<nextsent>the mapping between source-targetsentence pairs can be expressed in terms of latent phrase segment ations and latent word/phrasealignments, and the hierarchical phrase reordering can be expressed in terms of latent binary synchronous hierarchical structures (cf.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1912">
<title id=" W10-2915.xml">learning probabilistic synchronous cfgs for phrase based translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>fig.
</prevsent>
<prevsent>1).
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
but each of these three kinds of latent structures may be made explicit using external resources:word-alignment could be considered solved using giza++ (och and ney, 2003)), <papid> J03-1002 </papid>phrase pairs can be obtained from these word-alignments (och and ney, 2004), <papid> J04-4002 </papid>and the hierarchical synchronous structure can be grown over source/target linguistic syntactic trees output by an existing parser.</citsent>
<aftsection>
<nextsent>the joint phrase translation model (marcu and wong, 2002) <papid> W02-1018 </papid>constitutes specific case, albeit without the hierarchical, synchronous reordering start ? 1 / 1 (1) monotone ? 1 2 /x 1 2 (2) switching ? 1 2 /x 2 1 (3) emission ? / (4) figure 1: phrase-pair scfg (bitg) 117 component.</nextsent>
<nextsent>other existing work, e.g.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1914">
<title id=" W10-2915.xml">learning probabilistic synchronous cfgs for phrase based translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>1).
</prevsent>
<prevsent>but each of these three kinds of latent structures may be made explicit using external resources:word-alignment could be considered solved using giza++ (och and ney, 2003)), <papid> J03-1002 </papid>phrase pairs can be obtained from these word-alignments (och and ney, 2004), <papid> J04-4002 </papid>and the hierarchical synchronous structure can be grown over source/target linguistic syntactic trees output by an existing parser.</prevsent>
</prevsection>
<citsent citstr=" W02-1018 ">
the joint phrase translation model (marcu and wong, 2002) <papid> W02-1018 </papid>constitutes specific case, albeit without the hierarchical, synchronous reordering start ? 1 / 1 (1) monotone ? 1 2 /x 1 2 (2) switching ? 1 2 /x 2 1 (3) emission ? / (4) figure 1: phrase-pair scfg (bitg) 117 component.</citsent>
<aftsection>
<nextsent>other existing work, e.g.
</nextsent>
<nextsent>(chiang, 2007), <papid> J07-2003 </papid>assumes the word-alignments are given in the parallel corpus, but the problem of learning phrase translation probabilities is usually avoided by using surface counts of phrase pairs (koehn etal., 2003).<papid> N03-1017 </papid></nextsent>
<nextsent>the problem of learning the hierarchical, synchronous grammar reordering rules is oftentimes addressed as learning problem in its own right assuming all the rest is given (blunsom et al, 2008<papid> P08-1024 </papid>b).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1916">
<title id=" W10-2915.xml">learning probabilistic synchronous cfgs for phrase based translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the joint phrase translation model (marcu and wong, 2002) <papid> W02-1018 </papid>constitutes specific case, albeit without the hierarchical, synchronous reordering start ? 1 / 1 (1) monotone ? 1 2 /x 1 2 (2) switching ? 1 2 /x 2 1 (3) emission ? / (4) figure 1: phrase-pair scfg (bitg) 117 component.</prevsent>
<prevsent>other existing work, e.g.</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
(chiang, 2007), <papid> J07-2003 </papid>assumes the word-alignments are given in the parallel corpus, but the problem of learning phrase translation probabilities is usually avoided by using surface counts of phrase pairs (koehn etal., 2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>the problem of learning the hierarchical, synchronous grammar reordering rules is oftentimes addressed as learning problem in its own right assuming all the rest is given (blunsom et al, 2008<papid> P08-1024 </papid>b).</nextsent>
<nextsent>a small number of efforts has been dedicated to the simultaneous learning of the probabilities of phrase translation pairs as well as hierarchical reordering, e.g., (denero et al, 2008; <papid> D08-1033 </papid>zhang et al, 2008; <papid> P08-1012 </papid>blunsom et al, 2009).<papid> P09-1088 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1917">
<title id=" W10-2915.xml">learning probabilistic synchronous cfgs for phrase based translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>other existing work, e.g.
</prevsent>
<prevsent>(chiang, 2007), <papid> J07-2003 </papid>assumes the word-alignments are given in the parallel corpus, but the problem of learning phrase translation probabilities is usually avoided by using surface counts of phrase pairs (koehn etal., 2003).<papid> N03-1017 </papid></prevsent>
</prevsection>
<citsent citstr=" P08-1024 ">
the problem of learning the hierarchical, synchronous grammar reordering rules is oftentimes addressed as learning problem in its own right assuming all the rest is given (blunsom et al, 2008<papid> P08-1024 </papid>b).</citsent>
<aftsection>
<nextsent>a small number of efforts has been dedicated to the simultaneous learning of the probabilities of phrase translation pairs as well as hierarchical reordering, e.g., (denero et al, 2008; <papid> D08-1033 </papid>zhang et al, 2008; <papid> P08-1012 </papid>blunsom et al, 2009).<papid> P09-1088 </papid></nextsent>
<nextsent>of these, some concentrate on evaluating word-alignment, directly such as (zhang et al, 2008) <papid> P08-1012 </papid>or indirectly by evaluating heuristic ally trained hierarchical translation system from sampled phrasal alignments (blunsom et al, 2009).<papid> P09-1088 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1920">
<title id=" W10-2915.xml">learning probabilistic synchronous cfgs for phrase based translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(chiang, 2007), <papid> J07-2003 </papid>assumes the word-alignments are given in the parallel corpus, but the problem of learning phrase translation probabilities is usually avoided by using surface counts of phrase pairs (koehn etal., 2003).<papid> N03-1017 </papid></prevsent>
<prevsent>the problem of learning the hierarchical, synchronous grammar reordering rules is oftentimes addressed as learning problem in its own right assuming all the rest is given (blunsom et al, 2008<papid> P08-1024 </papid>b).</prevsent>
</prevsection>
<citsent citstr=" D08-1033 ">
a small number of efforts has been dedicated to the simultaneous learning of the probabilities of phrase translation pairs as well as hierarchical reordering, e.g., (denero et al, 2008; <papid> D08-1033 </papid>zhang et al, 2008; <papid> P08-1012 </papid>blunsom et al, 2009).<papid> P09-1088 </papid></citsent>
<aftsection>
<nextsent>of these, some concentrate on evaluating word-alignment, directly such as (zhang et al, 2008) <papid> P08-1012 </papid>or indirectly by evaluating heuristic ally trained hierarchical translation system from sampled phrasal alignments (blunsom et al, 2009).<papid> P09-1088 </papid></nextsent>
<nextsent>however, very few evaluate on actual translation performance of induced synchronous grammars (denero et al, 2008).<papid> D08-1033 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1921">
<title id=" W10-2915.xml">learning probabilistic synchronous cfgs for phrase based translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(chiang, 2007), <papid> J07-2003 </papid>assumes the word-alignments are given in the parallel corpus, but the problem of learning phrase translation probabilities is usually avoided by using surface counts of phrase pairs (koehn etal., 2003).<papid> N03-1017 </papid></prevsent>
<prevsent>the problem of learning the hierarchical, synchronous grammar reordering rules is oftentimes addressed as learning problem in its own right assuming all the rest is given (blunsom et al, 2008<papid> P08-1024 </papid>b).</prevsent>
</prevsection>
<citsent citstr=" P08-1012 ">
a small number of efforts has been dedicated to the simultaneous learning of the probabilities of phrase translation pairs as well as hierarchical reordering, e.g., (denero et al, 2008; <papid> D08-1033 </papid>zhang et al, 2008; <papid> P08-1012 </papid>blunsom et al, 2009).<papid> P09-1088 </papid></citsent>
<aftsection>
<nextsent>of these, some concentrate on evaluating word-alignment, directly such as (zhang et al, 2008) <papid> P08-1012 </papid>or indirectly by evaluating heuristic ally trained hierarchical translation system from sampled phrasal alignments (blunsom et al, 2009).<papid> P09-1088 </papid></nextsent>
<nextsent>however, very few evaluate on actual translation performance of induced synchronous grammars (denero et al, 2008).<papid> D08-1033 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1922">
<title id=" W10-2915.xml">learning probabilistic synchronous cfgs for phrase based translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(chiang, 2007), <papid> J07-2003 </papid>assumes the word-alignments are given in the parallel corpus, but the problem of learning phrase translation probabilities is usually avoided by using surface counts of phrase pairs (koehn etal., 2003).<papid> N03-1017 </papid></prevsent>
<prevsent>the problem of learning the hierarchical, synchronous grammar reordering rules is oftentimes addressed as learning problem in its own right assuming all the rest is given (blunsom et al, 2008<papid> P08-1024 </papid>b).</prevsent>
</prevsection>
<citsent citstr=" P09-1088 ">
a small number of efforts has been dedicated to the simultaneous learning of the probabilities of phrase translation pairs as well as hierarchical reordering, e.g., (denero et al, 2008; <papid> D08-1033 </papid>zhang et al, 2008; <papid> P08-1012 </papid>blunsom et al, 2009).<papid> P09-1088 </papid></citsent>
<aftsection>
<nextsent>of these, some concentrate on evaluating word-alignment, directly such as (zhang et al, 2008) <papid> P08-1012 </papid>or indirectly by evaluating heuristic ally trained hierarchical translation system from sampled phrasal alignments (blunsom et al, 2009).<papid> P09-1088 </papid></nextsent>
<nextsent>however, very few evaluate on actual translation performance of induced synchronous grammars (denero et al, 2008).<papid> D08-1033 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1934">
<title id=" W10-2915.xml">learning probabilistic synchronous cfgs for phrase based translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>unlike all other work that heuristic ally selects subset of phrase pairs, we start out from an scfg that works with all phrase pairs in the training set and concentrate on the aspects of learning.
</prevsent>
<prevsent>this learning problem is fraught with the risks of over fitting and can easily result in inadequate reordering preferences (see e.g.
</prevsent>
</prevsection>
<citsent citstr=" W06-3105 ">
(denero et al, 2006)).<papid> W06-3105 </papid></citsent>
<aftsection>
<nextsent>almost instantly, we find that the translation performance of all-phrase probabilistic scfgslearned in this setting crucially depends on the interplay between two aspects of learning: ? defining more constrained parameter space, where the reordering productions are phrase-lexicalised and made sensitive to neighbouring reorderings, and?
</nextsent>
<nextsent>defining an objective function that effectively smoothes the maximum-likelihood cri terion.one contribution of this paper is in devising an effective, data-driven smoothed maximum likelihood that can cope with model working with all phrase pair scfgs.
</nextsent>
<nextsent>this builds upon our previous work on estimating parameters of bag-of-phrases?
</nextsent>
<nextsent>model for machine translation(mylonakis and simaan, 2008)<papid> D08-1066 </papid>.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1935">
<title id=" W10-2915.xml">learning probabilistic synchronous cfgs for phrase based translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>defining an objective function that effectively smoothes the maximum-likelihood cri terion.one contribution of this paper is in devising an effective, data-driven smoothed maximum likelihood that can cope with model working with all phrase pair scfgs.
</prevsent>
<prevsent>this builds upon our previous work on estimating parameters of bag-of-phrases?
</prevsent>
</prevsection>
<citsent citstr=" D08-1066 ">
model for machine translation(mylonakis and simaan, 2008)<papid> D08-1066 </papid>.</citsent>
<aftsection>
<nextsent>however, learning scfgs poses significant novel challenges, the core of which lies on the hierarchical nature of astochastic scfg translation model and the relevant additional layer of latent structure.
</nextsent>
<nextsent>we address these issues in this work.
</nextsent>
<nextsent>another important contribution is in defining lexicalised reordering component within bitg that captures order divergences orthogonal to chiangs model (chi ang, 2007) <papid> J07-2003 </papid>but somewhat akin to phrase-based statistical machine translation reordering models (koehn et al, 2003).<papid> N03-1017 </papid>our analysis shows that the learning difficulties can be attributed to rather weak generative model.</nextsent>
<nextsent>yet, our best system exhibits hiero-levelperformance on french-english europarl data using an scfg-based decoder (li et al, 2009).<papid> W09-0424 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1940">
<title id=" W10-2915.xml">learning probabilistic synchronous cfgs for phrase based translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we address these issues in this work.
</prevsent>
<prevsent>another important contribution is in defining lexicalised reordering component within bitg that captures order divergences orthogonal to chiangs model (chi ang, 2007) <papid> J07-2003 </papid>but somewhat akin to phrase-based statistical machine translation reordering models (koehn et al, 2003).<papid> N03-1017 </papid>our analysis shows that the learning difficulties can be attributed to rather weak generative model.</prevsent>
</prevsection>
<citsent citstr=" W09-0424 ">
yet, our best system exhibits hiero-levelperformance on french-english europarl data using an scfg-based decoder (li et al, 2009).<papid> W09-0424 </papid></citsent>
<aftsection>
<nextsent>our findings should be insightful for others attempting to make the leap from shallow phrase-based systems to hierarchical scfg-based translation models using learning methods, as opposed to heuristics.
</nextsent>
<nextsent>the rest of the paper is structured as follows.
</nextsent>
<nextsent>section 2 briefly introduces the scfg formalism and discusses its adoption in the context of statistical machine translation (smt).
</nextsent>
<nextsent>in section 3, we consider some of the pitfalls of stochastic scfggrammar learning and address them by introducing novel learning objective and algorithm.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1941">
<title id=" W10-2915.xml">learning probabilistic synchronous cfgs for phrase based translation </title>
<section> synchronous grammars for machine.  </section>
<citcontext>
<prevsection>
<prevsent>unless otherwise stated, for the rest of the paper when we refer to scfgs we will be pointing to their stochastic extension.the rank of an scfg is defined as the maximum number of non-terminals in grammars rule right-hand side.
</prevsent>
<prevsent>contrary to monolingual context free grammars, there does not always exist conversion of an scfg of higher rank to one of lower rank with the same language of string pairs.for this, most machine translation applications focus on scfgs of rank two (binary scfgs), orbinarisable ones witch can be converted to binary scfg, given that these seem to cover mostof the translation phenomena encountered in language pairs (wu, 1997) and the related processing algorithms are less demanding computationally.
</prevsent>
</prevsection>
<citsent citstr=" P05-1033 ">
although scfgs were initially introduced for machine translation as stochastic word-basedtranslation process in the form of the inversion transduction grammar (wu, 1997), they were actually able to offer state-of-the-art performance intheir latter phrase-based implementation by chiang (chiang, 2005).<papid> P05-1033 </papid></citsent>
<aftsection>
<nextsent>chiangs hiero hierarchical translation system is based on synchronous grammar with single non-terminal covering all learned phrase-pairs.
</nextsent>
<nextsent>beginning from the start symbol s, an initial phrase-span structure is constructed monotonic ally using simple glue gram mar?: s 1 2 / 1 2 x 1 / 1 the true power of the system lies in expanding these initial phrase-spans with set of hierarchical translation rules, which allow conditioning reordering decisions based on lexical context.
</nextsent>
<nextsent>forthe french to english language pair, some examples would be: ? 1 economiques / financial 1 ? cette 1 de 2 / this 1 2 ? politique 1 commune de 2 / 2 ? common 1 policy further work builds on the hiero grammar to expand it with constituency syntax motivated nonterminals (zollmann and venugopal, 2006).
</nextsent>
<nextsent>the learning of phrase-based stochastic scfgs with maximum likelihood objective is exposed to over fitting as other all-fragment models such as phrase-based smt (pbsmt) (marcu and wong, 2002; <papid> W02-1018 </papid>denero et al, 2006) <papid> W06-3105 </papid>and data-oriented parsing (dop) (bod et al, 2003; zollmann andsimaan, 2006).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1957">
<title id=" W10-2915.xml">learning probabilistic synchronous cfgs for phrase based translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the model is further smoothed, similarly to phrase-based models and the hiero system, with smoothing features such as the lexical translation scores of the phrase-pairs involved and rule usage penalties.
</prevsent>
<prevsent>as usual with statistical translation, we aim for retrieving the target sentence corresponding to the most probable derivation ? ?
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
(f, e) with rules r, with: p(d) ? p(e)lmpscfg(e, f) scfg ? ? rd i(r) ithe interpolation weights are tuned using minimum error rate training (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>5.2 results.
</nextsent>
<nextsent>we test empirically the learners output grammars for translating from french to english, using = 5 for the cross validation data partitioning.
</nextsent>
<nextsent>the training material is giza++ word aligned corpus of 200k sentence-pairs from theeuroparl corpus (koehn, 2005), with our development and test parallel corpora of 2k sentence pairs stemming from the same source.
</nextsent>
<nextsent>training the grammar parameters until convergence demands around 6 hours on an 8-core 2.26 ghz intelxeon system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1974">
<title id=" W10-3911.xml">adverse effect relations extraction from massive clinical records </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, if we obtain the dependency structures as shown in figure 3, then we can easily determine that the structures are similar.
</prevsent>
<prevsent>of course, obtaining such perfect parsing results is not always possible.
</prevsent>
</prevsection>
<citsent citstr=" W01-0521 ">
a statistical syntactic parser is known to perform badly if text to be parsed belongs to domain which differs from domain on which the parser is trained (gildea, 2001).<papid> W01-0521 </papid></citsent>
<aftsection>
<nextsent>a statistical parser will likely output incomplete results in these texts and will likely have negative effect on relation extraction methods which depend on it.
</nextsent>
<nextsent>the specified research topic of this study is to investigate whether incomplete dependency structures are effective and how they behave in the extraction of uncertain relations.
</nextsent>
<nextsent>figure 2.
</nextsent>
<nextsent>the example of an adverse-effect relation where the suspicion is not stated.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1975">
<title id=" W10-3911.xml">adverse effect relations extraction from massive clinical records </title>
<section> related works.  </section>
<citcontext>
<prevsection>
<prevsent>this relation can be interpreted as more general relation of the adverse effect relation.
</prevsent>
<prevsent>the protein protein interaction (ppi) annotation extraction task of bio creative ii (krallinger et al, 2008) is task to extract ppi from pubmed abstracts.
</prevsent>
</prevsection>
<citsent citstr=" W09-1401 ">
bionlp09 shared task on event extraction (kim et al, 2009) <papid> W09-1401 </papid>is task to extract bio-molecular events (bio events) from the genia event corpus.</citsent>
<aftsection>
<nextsent>similar characteristics to those of the ad verse effect relation are described in previous reports in the bio-medical domain.
</nextsent>
<nextsent>friedman et al.
</nextsent>
<nextsent>(1994) describes the certainty in findings of clinical radiology.
</nextsent>
<nextsent>certainty is also known in scientific papers of biomedical domains as speculation (light et al, 2004).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1976">
<title id=" W10-3911.xml">adverse effect relations extraction from massive clinical records </title>
<section> related works.  </section>
<citcontext>
<prevsection>
<prevsent>dependency structure feature which we utilized to extract adverse effect relations are widely used in relation extraction tasks.
</prevsent>
<prevsent>we present previous works which used syntac tic/dependency information as feature of statistical method.
</prevsent>
</prevsection>
<citsent citstr=" W07-2085 ">
beamer et al (2007), <papid> W07-2085 </papid>giuliano et al (2007), <papid> W07-2028 </papid>and hendrickx et al (2007) <papid> W07-2039 </papid>all used syntactic information with machine learning techniques in semeval-2007 task:04 and achieved good performance.</citsent>
<aftsection>
<nextsent>riedel et al (2009) <papid> W09-1406 </papid>used dependency path features with statistical relational learning method in bi onlp09 shared task on event extraction and achieved the best performance in the event enrichment subtask.</nextsent>
<nextsent>miyao et al (2008) <papid> P08-1006 </papid>compared syntactic information of various statistical parsers on ppi.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1977">
<title id=" W10-3911.xml">adverse effect relations extraction from massive clinical records </title>
<section> related works.  </section>
<citcontext>
<prevsection>
<prevsent>dependency structure feature which we utilized to extract adverse effect relations are widely used in relation extraction tasks.
</prevsent>
<prevsent>we present previous works which used syntac tic/dependency information as feature of statistical method.
</prevsent>
</prevsection>
<citsent citstr=" W07-2028 ">
beamer et al (2007), <papid> W07-2085 </papid>giuliano et al (2007), <papid> W07-2028 </papid>and hendrickx et al (2007) <papid> W07-2039 </papid>all used syntactic information with machine learning techniques in semeval-2007 task:04 and achieved good performance.</citsent>
<aftsection>
<nextsent>riedel et al (2009) <papid> W09-1406 </papid>used dependency path features with statistical relational learning method in bi onlp09 shared task on event extraction and achieved the best performance in the event enrichment subtask.</nextsent>
<nextsent>miyao et al (2008) <papid> P08-1006 </papid>compared syntactic information of various statistical parsers on ppi.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1978">
<title id=" W10-3911.xml">adverse effect relations extraction from massive clinical records </title>
<section> related works.  </section>
<citcontext>
<prevsection>
<prevsent>dependency structure feature which we utilized to extract adverse effect relations are widely used in relation extraction tasks.
</prevsent>
<prevsent>we present previous works which used syntac tic/dependency information as feature of statistical method.
</prevsent>
</prevsection>
<citsent citstr=" W07-2039 ">
beamer et al (2007), <papid> W07-2085 </papid>giuliano et al (2007), <papid> W07-2028 </papid>and hendrickx et al (2007) <papid> W07-2039 </papid>all used syntactic information with machine learning techniques in semeval-2007 task:04 and achieved good performance.</citsent>
<aftsection>
<nextsent>riedel et al (2009) <papid> W09-1406 </papid>used dependency path features with statistical relational learning method in bi onlp09 shared task on event extraction and achieved the best performance in the event enrichment subtask.</nextsent>
<nextsent>miyao et al (2008) <papid> P08-1006 </papid>compared syntactic information of various statistical parsers on ppi.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1979">
<title id=" W10-3911.xml">adverse effect relations extraction from massive clinical records </title>
<section> related works.  </section>
<citcontext>
<prevsection>
<prevsent>we present previous works which used syntac tic/dependency information as feature of statistical method.
</prevsent>
<prevsent>beamer et al (2007), <papid> W07-2085 </papid>giuliano et al (2007), <papid> W07-2028 </papid>and hendrickx et al (2007) <papid> W07-2039 </papid>all used syntactic information with machine learning techniques in semeval-2007 task:04 and achieved good performance.</prevsent>
</prevsection>
<citsent citstr=" W09-1406 ">
riedel et al (2009) <papid> W09-1406 </papid>used dependency path features with statistical relational learning method in bi onlp09 shared task on event extraction and achieved the best performance in the event enrichment subtask.</citsent>
<aftsection>
<nextsent>miyao et al (2008) <papid> P08-1006 </papid>compared syntactic information of various statistical parsers on ppi.</nextsent>
<nextsent>we produced an annotated corpus of adverse?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1980">
<title id=" W10-3911.xml">adverse effect relations extraction from massive clinical records </title>
<section> related works.  </section>
<citcontext>
<prevsection>
<prevsent>beamer et al (2007), <papid> W07-2085 </papid>giuliano et al (2007), <papid> W07-2028 </papid>and hendrickx et al (2007) <papid> W07-2039 </papid>all used syntactic information with machine learning techniques in semeval-2007 task:04 and achieved good performance.</prevsent>
<prevsent>riedel et al (2009) <papid> W09-1406 </papid>used dependency path features with statistical relational learning method in bi onlp09 shared task on event extraction and achieved the best performance in the event enrichment subtask.</prevsent>
</prevsection>
<citsent citstr=" P08-1006 ">
miyao et al (2008) <papid> P08-1006 </papid>compared syntactic information of various statistical parsers on ppi.</citsent>
<aftsection>
<nextsent>we produced an annotated corpus of adverse?
</nextsent>
<nextsent>effect relations to develop and test an adverse?
</nextsent>
<nextsent>effect relation extraction method.
</nextsent>
<nextsent>this section presents description of details of the corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1982">
<title id=" W10-3911.xml">adverse effect relations extraction from massive clinical records </title>
<section> extraction method.  </section>
<citcontext>
<prevsection>
<prevsent>features based on morphological analysis and dependency analysis are used in discrimination.
</prevsent>
<prevsent>this approach is similar to the ppi extraction approach of miyao et al (2008), <papid> P08-1006 </papid>in which we binary classify pairs whether they are in ad verse effect relations or not.</prevsent>
</prevsection>
<citsent citstr=" P06-1015 ">
a pattern-based semi-supervised approach like saeger et al (2008), or more generally espresso (pantel and pennacchiotti, 2006), <papid> P06-1015 </papid>can also be taken, but we chose pair classification approach to avoid the effect of seed patterns.</citsent>
<aftsection>
<nextsent>to capture view of an adverse ness of drug, statistic of ad verse effect relations is important.
</nextsent>
<nextsent>we do not want to favor certain patterns and chose pair classification approach to equally treat every relation.
</nextsent>
<nextsent>extraction steps of our method are as presented below.
</nextsent>
<nextsent>step 1: pair extraction all combinations of drug symptom pairs that appear in same sentence are extracted.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1983">
<title id=" W10-3911.xml">adverse effect relations extraction from massive clinical records </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>c. fully automated extraction in the experiments, we used the manually annotated information to extract pairs and features.
</prevsent>
<prevsent>this setting is, of course, not real if we consider situation to extract adverse effect relations from massive clinical records, but we chose it to focus on the relation extraction problem.
</prevsent>
</prevsection>
<citsent citstr=" W09-1324 ">
we performed an event recognition experiment (aramaki et al, 2009) <papid> W09-1324 </papid>and achieved f1-score of about 80.</citsent>
<aftsection>
<nextsent>we assume that drug expressions and symptom expressions to be automatically recognized in similar accuracy.
</nextsent>
<nextsent>we are planning to perform fully automated adverse effect relations extraction from larger set of clinical texts to see the performance of our method on raw corpus.
</nextsent>
<nextsent>the extraction f1-score will likely to decrease, but we intend to observe the other aspect of the extraction, like the overall tendency of extracted relations.
</nextsent>
<nextsent>we presented method to extract adverse?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1984">
<title id=" W10-1825.xml">creating and exploiting a resource of parallel parses </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we describe the workflow and the infrastructure to create and explore corpus that contains multiple parses of german sentences.
</prevsent>
<prevsent>a corpus of alternative parses created by different tools allows us to study structural differences between the parses in systematic way.the resource described in this paper is collection of german sentences with -ung nominaliza tions extracted from the sdewac corpus (faa?
</prevsent>
</prevsection>
<citsent citstr=" E06-2001 ">
et al, 2010), based on the dewac web corpus (baroni and kilgarriff, 2006).<papid> E06-2001 </papid></citsent>
<aftsection>
<nextsent>these sentences are employed for the study of lexical ambiguities in german -ung nominalizations (eberle et al,2009); e.g., german absperrung, derived from absperren to block?, can denote an event (block ing?), state (blockade?)
</nextsent>
<nextsent>or an object (barrier?).sortal disambiguation, however, is highly context dependent, and reliable and detailed analyses ofthe linguistic context are crucial for sortal disambiguation of these nominalizations.
</nextsent>
<nextsent>more reliable and detailed linguistic analyses can be achieved, for example, by combining the information produced by different parsers: on the basis of qualitative and quantitative analyses, generalized rules for the improvement of the respective parsers can be developed, as well as rules for the mapping of their output to tool-independentrepresentation, and weights for the parallel application and combination of multiple parsers.
</nextsent>
<nextsent>this approach has been previously applied to morphological and morphosyntactic annotations (borin, 2000; zavrel and daelemans, 2000; tufis?, 2000), but only recently to syntax annotation (francom and hulden, 2008; <papid> L08-1240 </papid>de la clergerie et al, 2008).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1985">
<title id=" W10-1825.xml">creating and exploiting a resource of parallel parses </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>or an object (barrier?).sortal disambiguation, however, is highly context dependent, and reliable and detailed analyses ofthe linguistic context are crucial for sortal disambiguation of these nominalizations.
</prevsent>
<prevsent>more reliable and detailed linguistic analyses can be achieved, for example, by combining the information produced by different parsers: on the basis of qualitative and quantitative analyses, generalized rules for the improvement of the respective parsers can be developed, as well as rules for the mapping of their output to tool-independentrepresentation, and weights for the parallel application and combination of multiple parsers.
</prevsent>
</prevsection>
<citsent citstr=" L08-1240 ">
this approach has been previously applied to morphological and morphosyntactic annotations (borin, 2000; zavrel and daelemans, 2000; tufis?, 2000), but only recently to syntax annotation (francom and hulden, 2008; <papid> L08-1240 </papid>de la clergerie et al, 2008).</citsent>
<aftsection>
<nextsent>because of the complexity of syntax annotations as compared to part of speech tags, however, novel technologies have to be applied that allow us to represent, to visualize and to query multiple syntactic analyses of the same sentence.
</nextsent>
<nextsent>this paper describes the workflow from raw text to search able representation of the corpus.
</nextsent>
<nextsent>oneof the aims of this new resource is to assess potential weaknesses in the parsers as well as their characteristic strengths.
</nextsent>
<nextsent>for the example of ambiguities in pp attachment, sect.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1986">
<title id=" W10-1825.xml">creating and exploiting a resource of parallel parses </title>
<section> parsing.  </section>
<citcontext>
<prevsection>
<prevsent>in order to maximize both coverage and gran ularity of linguistic analyses, we chose parsers from different classes: probabilistic constituent parser and rule-based parser that produces semantically enriched dependency parses.
</prevsent>
<prevsent>2.1 bitpar.
</prevsent>
</prevsection>
<citsent citstr=" P06-1023 ">
bitpar (schmid, 2006) <papid> P06-1023 </papid>is probabilistic context free parser using bit-vector operations (schmid, 2004).<papid> C04-1024 </papid></citsent>
<aftsection>
<nextsent>node categories are annotated along with grammatical functions, part-of-speech tags and morphological information in parse tree.
</nextsent>
<nextsent>bitpar analyses are conform ant to the tiger annotation scheme (brants et al, 2004), and the tools output format is similar to the list-based bracketing format of the penn treebank (bies et al, 1995).
</nextsent>
<nextsent>the bitpar analysis of sentence (1) is visualized as the right-most tree in fig.
</nextsent>
<nextsent>1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1987">
<title id=" W10-1825.xml">creating and exploiting a resource of parallel parses </title>
<section> parsing.  </section>
<citcontext>
<prevsection>
<prevsent>in order to maximize both coverage and gran ularity of linguistic analyses, we chose parsers from different classes: probabilistic constituent parser and rule-based parser that produces semantically enriched dependency parses.
</prevsent>
<prevsent>2.1 bitpar.
</prevsent>
</prevsection>
<citsent citstr=" C04-1024 ">
bitpar (schmid, 2006) <papid> P06-1023 </papid>is probabilistic context free parser using bit-vector operations (schmid, 2004).<papid> C04-1024 </papid></citsent>
<aftsection>
<nextsent>node categories are annotated along with grammatical functions, part-of-speech tags and morphological information in parse tree.
</nextsent>
<nextsent>bitpar analyses are conform ant to the tiger annotation scheme (brants et al, 2004), and the tools output format is similar to the list-based bracketing format of the penn treebank (bies et al, 1995).
</nextsent>
<nextsent>the bitpar analysis of sentence (1) is visualized as the right-most tree in fig.
</nextsent>
<nextsent>1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1988">
<title id=" W10-1825.xml">creating and exploiting a resource of parallel parses </title>
<section> exploiting multiple parses.  </section>
<citcontext>
<prevsection>
<prevsent>as opposed to traditional approaches that reduce parse integration to selec dominated by its parent.
</prevsent>
<prevsent>168 tion between entire parses, cf.
</prevsent>
</prevsection>
<citsent citstr=" P02-1056 ">
crysmann et al (2002), <papid> P02-1056 </papid>we employ full merging between b3 parses and bitpar parses.</citsent>
<aftsection>
<nextsent>this merging is basedon hand-crafted rules that express preferences between pieces of information from one parse or the other in accordance with the results of quantitative and qualitative analyses as described above.b3 parses can be enriched with structural information from bitpar, e.g., by the following exemplaric rule:7 if the b3 parse indicates under spec ifi cation with respect to the pp attachment point (query 1), establish dominance edge between (i) the correspondent of the bitpar pp (the ppfrom london?
</nextsent>
<nextsent>in the example) and (ii) the correspondent of its parent node (the pp to the news?), and delete the original, underspecified b3 edge.the same procedure can also be applied to perform corrections of parse, if further quantitative and qualitative studies indicate that, for example, the b3 parser systematically fails at particular phenomenon.
</nextsent>
<nextsent>in some cases, we may also want to employcontext-dependent rules to exploit the advantageous characteristics of specific parser, e.g., to preserve ambiguities.
</nextsent>
<nextsent>example (2) illustrates thatpp attachment has an effect on the sortal interpretation of absperrung barrier/blocking/blockade?:different points of attachment can produce different possible readings.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1989">
<title id=" W10-1825.xml">creating and exploiting a resource of parallel parses </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>although originally developed for different purposes (representation and querying of richly annotated corpora), its generic character allowed us to apply it with more than satisfactory results to new scenario.subsequent research may further exploit the potential of the annis/paula infrastructure andthe development of application-specific extensions.
</prevsent>
<prevsent>in particular, it is possible to register inannis problem-specific visualization for parallel parses that applies in place of the generic tree/dag view for the name spaces bitpar and b3.
</prevsent>
</prevsection>
<citsent citstr=" W09-3005 ">
another extension pertains to the handling of conflicting tokenizations: the algorithm described by chiarcos et al (2009) <papid> W09-3005 </papid>is sufficiently generic to be applied to any paula project, but it may be extended to account for b3-specific deletions(sect.</citsent>
<aftsection>
<nextsent>2.2).
</nextsent>
<nextsent>further, annis supports an annotation enrichment cycle: matches are exported asweka tables, statistical, symbolic or neural classifiers can be trained on or applied to this data, and the modified match table can be reintegrated with the original corpus.
</nextsent>
<nextsent>this allows, for example, tolearn an automatic mapping between b3 and bit par annotations.
</nextsent>
<nextsent>acknowledgements collaborative research centre 732 (universitat stuttgart) and collaborative research centre 632 (humboldt universitat zu berlin and universitatpotsdam) are funded by deutsche forschungsge meinschaft (dfg).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1990">
<title id=" W10-1411.xml">on the role of morphosyntactic features in hindi dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we finally provide detailed error analysis and suggest possible improvements to the parsing scheme.
</prevsent>
<prevsent>the dependency parsing community has since few years shown considerable interest in parsing morphologically rich languages with flexible word order.
</prevsent>
</prevsection>
<citsent citstr=" D07-1096 ">
this is partly due to the increasing availability of dependency treebanks for such languages, but it is also motivated by the observation that the performance obtained for these languages has not been very high (nivre et al, 2007<papid> D07-1096 </papid>a).</citsent>
<aftsection>
<nextsent>attempts at handling various non-configurational aspects in these languages have pointed towards shortcomings in traditional parsing methodologies (tsarfaty and sima an, 2008; eryigit et al, 2008; seddah et al., 2009; <papid> W09-3824 </papid>husain et al, 2009; gadde et al, 2010).</nextsent>
<nextsent>among other things, it has been pointed out that the use of language specific features may play crucial role in improving the overall parsing performance.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1992">
<title id=" W10-1411.xml">on the role of morphosyntactic features in hindi dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the dependency parsing community has since few years shown considerable interest in parsing morphologically rich languages with flexible word order.
</prevsent>
<prevsent>this is partly due to the increasing availability of dependency treebanks for such languages, but it is also motivated by the observation that the performance obtained for these languages has not been very high (nivre et al, 2007<papid> D07-1096 </papid>a).</prevsent>
</prevsection>
<citsent citstr=" W09-3824 ">
attempts at handling various non-configurational aspects in these languages have pointed towards shortcomings in traditional parsing methodologies (tsarfaty and sima an, 2008; eryigit et al, 2008; seddah et al., 2009; <papid> W09-3824 </papid>husain et al, 2009; gadde et al, 2010).</citsent>
<aftsection>
<nextsent>among other things, it has been pointed out that the use of language specific features may play crucial role in improving the overall parsing performance.
</nextsent>
<nextsent>different languages tend to encode syntactically relevant information in different ways, and it has been hypothesized that the integration of morphological and syntactic information could be key to better accuracy.
</nextsent>
<nextsent>however, it has also been noted that incorporating these language specific features in parsing is not always straightforward and many intuitive features do not always work in expected ways.
</nextsent>
<nextsent>in this paper, we are concerned with hindi, an indian language with moderately rich morphology and relatively free word order.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1993">
<title id=" W10-1411.xml">on the role of morphosyntactic features in hindi dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, it has also been noted that incorporating these language specific features in parsing is not always straightforward and many intuitive features do not always work in expected ways.
</prevsent>
<prevsent>in this paper, we are concerned with hindi, an indian language with moderately rich morphology and relatively free word order.
</prevsent>
</prevsection>
<citsent citstr=" W09-3812 ">
there have been several previous attempts at parsing hindi as well as other indian languages (bharati et al, 1995, bharati et al, 2009<papid> W09-3812 </papid>b).</citsent>
<aftsection>
<nextsent>many techniques were tried out recently at the icon09 dependency parsing tools contest (husain, 2009).
</nextsent>
<nextsent>both the best performing system (ambati et al, 2009a) and the system in second place (nivre, 2009<papid> P09-1040 </papid>b) used transition-based approach to dependency parsing, as implemented in malt parser (nivre et al, 2007<papid> D07-1096 </papid>b).</nextsent>
<nextsent>other data driven parsing efforts for indian languages in the past have been bharati et al (2008), husain et al (2009), mannem et al (2009<papid> P09-3002 </papid>b) and gadde et al (2010).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1994">
<title id=" W10-1411.xml">on the role of morphosyntactic features in hindi dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there have been several previous attempts at parsing hindi as well as other indian languages (bharati et al, 1995, bharati et al, 2009<papid> W09-3812 </papid>b).</prevsent>
<prevsent>many techniques were tried out recently at the icon09 dependency parsing tools contest (husain, 2009).</prevsent>
</prevsection>
<citsent citstr=" P09-1040 ">
both the best performing system (ambati et al, 2009a) and the system in second place (nivre, 2009<papid> P09-1040 </papid>b) used transition-based approach to dependency parsing, as implemented in malt parser (nivre et al, 2007<papid> D07-1096 </papid>b).</citsent>
<aftsection>
<nextsent>other data driven parsing efforts for indian languages in the past have been bharati et al (2008), husain et al (2009), mannem et al (2009<papid> P09-3002 </papid>b) and gadde et al (2010).</nextsent>
<nextsent>in this paper, we continue to explore the transi tion-based approach to hindi dependency parsing, building on the state-of-the-art results of ambati et al.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG1998">
<title id=" W10-1411.xml">on the role of morphosyntactic features in hindi dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>many techniques were tried out recently at the icon09 dependency parsing tools contest (husain, 2009).
</prevsent>
<prevsent>both the best performing system (ambati et al, 2009a) and the system in second place (nivre, 2009<papid> P09-1040 </papid>b) used transition-based approach to dependency parsing, as implemented in malt parser (nivre et al, 2007<papid> D07-1096 </papid>b).</prevsent>
</prevsection>
<citsent citstr=" P09-3002 ">
other data driven parsing efforts for indian languages in the past have been bharati et al (2008), husain et al (2009), mannem et al (2009<papid> P09-3002 </papid>b) and gadde et al (2010).</citsent>
<aftsection>
<nextsent>in this paper, we continue to explore the transi tion-based approach to hindi dependency parsing, building on the state-of-the-art results of ambati et al.
</nextsent>
<nextsent>(2009a) and nivre (2009<papid> P09-1040 </papid>b) and exploring the common pool of features used by those systems.</nextsent>
<nextsent>through series of experiments we select features incrementally to arrive at the best parser features.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2004">
<title id=" W10-1411.xml">on the role of morphosyntactic features in hindi dependency parsing </title>
<section> the hindi dependency treebank.  </section>
<citcontext>
<prevsection>
<prevsent>(do-io-s-v) hindi also has rich case marking system, although case marking is not obligatory.
</prevsent>
<prevsent>for example, in (1), while the subject and indirect object are explicitly marked for the ergative (erg) and da tive (dat) cases, the direct object is unmarked for the accusative.
</prevsent>
</prevsection>
<citsent citstr=" I08-2099 ">
the hindi dependency treebank (begum et al, 2008) <papid> I08-2099 </papid>used for the experiment was released as part of the icon09 dependency parsing tools contest (husain, 2009).</citsent>
<aftsection>
<nextsent>the dependency framework (bha rati et al, 1995) used in the treebank is inspired by paninis grammar of sanskrit.
</nextsent>
<nextsent>the core labels, called karakas, are syntactico-semantic relations that identify the participant in the action denoted by the verb.
</nextsent>
<nextsent>for example, in (1), malay?
</nextsent>
<nextsent>is the agent, book?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2007">
<title id=" W10-1411.xml">on the role of morphosyntactic features in hindi dependency parsing </title>
<section> transition-based dependency parsing.  </section>
<citcontext>
<prevsection>
<prevsent>the test data consisted of 150 sentences (~1.6k words).
</prevsent>
<prevsent>the average sentence length is 19.85.
</prevsent>
</prevsection>
<citsent citstr=" J08-4003 ">
a transition-based dependency parser is built of two essential components (nivre, 2008): ? <papid> J08-4003 </papid>transition system for mapping sentences to dependency trees ? classifier for predicting the next transition for every possible system configuration 95 ptag ctag form lemma deprel ctam others stack: top 1 5 1 7 9 input: next 1 5 1 7 9 input: next+1 2 5 6 7 input: next+2 2 input: next+3 2 stack: top-1 3 string: predecessor of top 3 tree: head of top 4 tree: left most dep of next 4 5 6 tree: rightmost dep of top 8 tree: left sibling of rightmost dep of top 8 merge: ptag of top and next 10 merge: ctam and deprel of top 10 table 1.</citsent>
<aftsection>
<nextsent>feature pool based on selection from ambati et al (2009a) and nivre (2009<papid> P09-1040 </papid>b).</nextsent>
<nextsent>given these two components, dependency parsing can be realized as deterministic search through the transition system, guided by the classifier.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2030">
<title id=" W10-1411.xml">on the role of morphosyntactic features in hindi dependency parsing </title>
<section> error analysis.  </section>
<citcontext>
<prevsection>
<prevsent>the agreement problem worsens when there is coordination or when there is complex verb.
</prevsent>
<prevsent>it is understandable then that the parser is unable to learn the selective agreement pattern which needs to be followed.
</prevsent>
</prevsection>
<citsent citstr=" W09-3819 ">
similar problems with agreement features have also been noted by goldberg and elhadad (2009).<papid> W09-3819 </papid></citsent>
<aftsection>
<nextsent>in the following sections, we analyze the errors due to different constructions and suggest possible remedies.
</nextsent>
<nextsent>5.1 simple sentences.
</nextsent>
<nextsent>a simple sentence is one that has only one main verb.
</nextsent>
<nextsent>in these sentences, the root of the dependency tree is the main verb, which is easily identified by the parser.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2032">
<title id=" W10-1411.xml">on the role of morphosyntactic features in hindi dependency parsing </title>
<section> error analysis.  </section>
<citcontext>
<prevsection>
<prevsent>the hindi treebank has ~14% non-projective arcs (mannem et al, 2009<papid> P09-3002 </papid>a).</prevsent>
<prevsent>in the test set, there were total of 11 non projective arcs, but the parser did not find any of them.</prevsent>
</prevsection>
<citsent citstr=" P07-1122 ">
this is consistent with earlier results showing that pseudo-projective parsing has high precision but low recall, especially when the percentage of non-projective relations is small (nilsson et al 2007).<papid> P07-1122 </papid></citsent>
<aftsection>
<nextsent>non-projectivity has proven to be one of thema jor problems in dependency parsing, especially for free word-order languages.
</nextsent>
<nextsent>in hindi, the majority of non-projective arcs are inter-clausal (mannem et al., 2009<papid> P09-3002 </papid>a), involving conjunctions and relative clauses.</nextsent>
<nextsent>there have been some attempts at handling inter-clausal non-projectivity in hindi.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2034">
<title id=" W10-1401.xml">statistical parsing of morphologically rich languages spmrl what how and whither </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the overarching analysis suggests itself as source of directions for future investigations.
</prevsent>
<prevsent>the availability of large syntactically annotated corpora led to an explosion of interest in automatically inducing models for syntactic analysis and disambiguation called statistical parsers.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
the development of successful statistical parsing models for english focused on the wall street journal penn treebank (ptb, (marcus et al, 1993)) <papid> J93-2004 </papid>as the primary, and sometimes only, resource.</citsent>
<aftsection>
<nextsent>since the initial release of the penn treebank (ptb marcus et al.
</nextsent>
<nextsent>(1993)), many different constituent-based parsing models have been developed in the context of parsing english (e.g.
</nextsent>
<nextsent>(magerman, 1995; <papid> P95-1037 </papid>collins, 1997;<papid> P97-1003 </papid>charniak, 2000; <papid> A00-2018 </papid>chiang, 2000; <papid> P00-1058 </papid>bod, 2003; <papid> E03-1005 </papid>charniak and johnson, 2005; <papid> P05-1022 </papid>petrov et al, 2006; <papid> P06-1055 </papid>huang, 2008; <papid> P08-1067 </papid>finkel et al, 2008; <papid> P08-1109 </papid>carreras et al, 2008)).<papid> W08-2102 </papid></nextsent>
<nextsent>at their time, each of these models improved the state-of-the-art, bringing parsing performance on the standard test set of the wall-street-journal to performance ceiling of 92% f1-score using the parseval evaluation metrics (black et al, 1991).<papid> H91-1060 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2035">
<title id=" W10-1401.xml">statistical parsing of morphologically rich languages spmrl what how and whither </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>since the initial release of the penn treebank (ptb marcus et al.
</prevsent>
<prevsent>(1993)), many different constituent-based parsing models have been developed in the context of parsing english (e.g.
</prevsent>
</prevsection>
<citsent citstr=" P95-1037 ">
(magerman, 1995; <papid> P95-1037 </papid>collins, 1997;<papid> P97-1003 </papid>charniak, 2000; <papid> A00-2018 </papid>chiang, 2000; <papid> P00-1058 </papid>bod, 2003; <papid> E03-1005 </papid>charniak and johnson, 2005; <papid> P05-1022 </papid>petrov et al, 2006; <papid> P06-1055 </papid>huang, 2008; <papid> P08-1067 </papid>finkel et al, 2008; <papid> P08-1109 </papid>carreras et al, 2008)).<papid> W08-2102 </papid></citsent>
<aftsection>
<nextsent>at their time, each of these models improved the state-of-the-art, bringing parsing performance on the standard test set of the wall-street-journal to performance ceiling of 92% f1-score using the parseval evaluation metrics (black et al, 1991).<papid> H91-1060 </papid></nextsent>
<nextsent>someof these parsers have been adapted to other lan guage/treebank pairs, but many of these adaptations have been shown to be considerably less successful.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2036">
<title id=" W10-1401.xml">statistical parsing of morphologically rich languages spmrl what how and whither </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>since the initial release of the penn treebank (ptb marcus et al.
</prevsent>
<prevsent>(1993)), many different constituent-based parsing models have been developed in the context of parsing english (e.g.
</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
(magerman, 1995; <papid> P95-1037 </papid>collins, 1997;<papid> P97-1003 </papid>charniak, 2000; <papid> A00-2018 </papid>chiang, 2000; <papid> P00-1058 </papid>bod, 2003; <papid> E03-1005 </papid>charniak and johnson, 2005; <papid> P05-1022 </papid>petrov et al, 2006; <papid> P06-1055 </papid>huang, 2008; <papid> P08-1067 </papid>finkel et al, 2008; <papid> P08-1109 </papid>carreras et al, 2008)).<papid> W08-2102 </papid></citsent>
<aftsection>
<nextsent>at their time, each of these models improved the state-of-the-art, bringing parsing performance on the standard test set of the wall-street-journal to performance ceiling of 92% f1-score using the parseval evaluation metrics (black et al, 1991).<papid> H91-1060 </papid></nextsent>
<nextsent>someof these parsers have been adapted to other lan guage/treebank pairs, but many of these adaptations have been shown to be considerably less successful.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2037">
<title id=" W10-1401.xml">statistical parsing of morphologically rich languages spmrl what how and whither </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>since the initial release of the penn treebank (ptb marcus et al.
</prevsent>
<prevsent>(1993)), many different constituent-based parsing models have been developed in the context of parsing english (e.g.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
(magerman, 1995; <papid> P95-1037 </papid>collins, 1997;<papid> P97-1003 </papid>charniak, 2000; <papid> A00-2018 </papid>chiang, 2000; <papid> P00-1058 </papid>bod, 2003; <papid> E03-1005 </papid>charniak and johnson, 2005; <papid> P05-1022 </papid>petrov et al, 2006; <papid> P06-1055 </papid>huang, 2008; <papid> P08-1067 </papid>finkel et al, 2008; <papid> P08-1109 </papid>carreras et al, 2008)).<papid> W08-2102 </papid></citsent>
<aftsection>
<nextsent>at their time, each of these models improved the state-of-the-art, bringing parsing performance on the standard test set of the wall-street-journal to performance ceiling of 92% f1-score using the parseval evaluation metrics (black et al, 1991).<papid> H91-1060 </papid></nextsent>
<nextsent>someof these parsers have been adapted to other lan guage/treebank pairs, but many of these adaptations have been shown to be considerably less successful.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2038">
<title id=" W10-1401.xml">statistical parsing of morphologically rich languages spmrl what how and whither </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>since the initial release of the penn treebank (ptb marcus et al.
</prevsent>
<prevsent>(1993)), many different constituent-based parsing models have been developed in the context of parsing english (e.g.
</prevsent>
</prevsection>
<citsent citstr=" P00-1058 ">
(magerman, 1995; <papid> P95-1037 </papid>collins, 1997;<papid> P97-1003 </papid>charniak, 2000; <papid> A00-2018 </papid>chiang, 2000; <papid> P00-1058 </papid>bod, 2003; <papid> E03-1005 </papid>charniak and johnson, 2005; <papid> P05-1022 </papid>petrov et al, 2006; <papid> P06-1055 </papid>huang, 2008; <papid> P08-1067 </papid>finkel et al, 2008; <papid> P08-1109 </papid>carreras et al, 2008)).<papid> W08-2102 </papid></citsent>
<aftsection>
<nextsent>at their time, each of these models improved the state-of-the-art, bringing parsing performance on the standard test set of the wall-street-journal to performance ceiling of 92% f1-score using the parseval evaluation metrics (black et al, 1991).<papid> H91-1060 </papid></nextsent>
<nextsent>someof these parsers have been adapted to other lan guage/treebank pairs, but many of these adaptations have been shown to be considerably less successful.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2039">
<title id=" W10-1401.xml">statistical parsing of morphologically rich languages spmrl what how and whither </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>since the initial release of the penn treebank (ptb marcus et al.
</prevsent>
<prevsent>(1993)), many different constituent-based parsing models have been developed in the context of parsing english (e.g.
</prevsent>
</prevsection>
<citsent citstr=" E03-1005 ">
(magerman, 1995; <papid> P95-1037 </papid>collins, 1997;<papid> P97-1003 </papid>charniak, 2000; <papid> A00-2018 </papid>chiang, 2000; <papid> P00-1058 </papid>bod, 2003; <papid> E03-1005 </papid>charniak and johnson, 2005; <papid> P05-1022 </papid>petrov et al, 2006; <papid> P06-1055 </papid>huang, 2008; <papid> P08-1067 </papid>finkel et al, 2008; <papid> P08-1109 </papid>carreras et al, 2008)).<papid> W08-2102 </papid></citsent>
<aftsection>
<nextsent>at their time, each of these models improved the state-of-the-art, bringing parsing performance on the standard test set of the wall-street-journal to performance ceiling of 92% f1-score using the parseval evaluation metrics (black et al, 1991).<papid> H91-1060 </papid></nextsent>
<nextsent>someof these parsers have been adapted to other lan guage/treebank pairs, but many of these adaptations have been shown to be considerably less successful.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2040">
<title id=" W10-1401.xml">statistical parsing of morphologically rich languages spmrl what how and whither </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>since the initial release of the penn treebank (ptb marcus et al.
</prevsent>
<prevsent>(1993)), many different constituent-based parsing models have been developed in the context of parsing english (e.g.
</prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
(magerman, 1995; <papid> P95-1037 </papid>collins, 1997;<papid> P97-1003 </papid>charniak, 2000; <papid> A00-2018 </papid>chiang, 2000; <papid> P00-1058 </papid>bod, 2003; <papid> E03-1005 </papid>charniak and johnson, 2005; <papid> P05-1022 </papid>petrov et al, 2006; <papid> P06-1055 </papid>huang, 2008; <papid> P08-1067 </papid>finkel et al, 2008; <papid> P08-1109 </papid>carreras et al, 2008)).<papid> W08-2102 </papid></citsent>
<aftsection>
<nextsent>at their time, each of these models improved the state-of-the-art, bringing parsing performance on the standard test set of the wall-street-journal to performance ceiling of 92% f1-score using the parseval evaluation metrics (black et al, 1991).<papid> H91-1060 </papid></nextsent>
<nextsent>someof these parsers have been adapted to other lan guage/treebank pairs, but many of these adaptations have been shown to be considerably less successful.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2041">
<title id=" W10-1401.xml">statistical parsing of morphologically rich languages spmrl what how and whither </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>since the initial release of the penn treebank (ptb marcus et al.
</prevsent>
<prevsent>(1993)), many different constituent-based parsing models have been developed in the context of parsing english (e.g.
</prevsent>
</prevsection>
<citsent citstr=" P06-1055 ">
(magerman, 1995; <papid> P95-1037 </papid>collins, 1997;<papid> P97-1003 </papid>charniak, 2000; <papid> A00-2018 </papid>chiang, 2000; <papid> P00-1058 </papid>bod, 2003; <papid> E03-1005 </papid>charniak and johnson, 2005; <papid> P05-1022 </papid>petrov et al, 2006; <papid> P06-1055 </papid>huang, 2008; <papid> P08-1067 </papid>finkel et al, 2008; <papid> P08-1109 </papid>carreras et al, 2008)).<papid> W08-2102 </papid></citsent>
<aftsection>
<nextsent>at their time, each of these models improved the state-of-the-art, bringing parsing performance on the standard test set of the wall-street-journal to performance ceiling of 92% f1-score using the parseval evaluation metrics (black et al, 1991).<papid> H91-1060 </papid></nextsent>
<nextsent>someof these parsers have been adapted to other lan guage/treebank pairs, but many of these adaptations have been shown to be considerably less successful.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2042">
<title id=" W10-1401.xml">statistical parsing of morphologically rich languages spmrl what how and whither </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>since the initial release of the penn treebank (ptb marcus et al.
</prevsent>
<prevsent>(1993)), many different constituent-based parsing models have been developed in the context of parsing english (e.g.
</prevsent>
</prevsection>
<citsent citstr=" P08-1067 ">
(magerman, 1995; <papid> P95-1037 </papid>collins, 1997;<papid> P97-1003 </papid>charniak, 2000; <papid> A00-2018 </papid>chiang, 2000; <papid> P00-1058 </papid>bod, 2003; <papid> E03-1005 </papid>charniak and johnson, 2005; <papid> P05-1022 </papid>petrov et al, 2006; <papid> P06-1055 </papid>huang, 2008; <papid> P08-1067 </papid>finkel et al, 2008; <papid> P08-1109 </papid>carreras et al, 2008)).<papid> W08-2102 </papid></citsent>
<aftsection>
<nextsent>at their time, each of these models improved the state-of-the-art, bringing parsing performance on the standard test set of the wall-street-journal to performance ceiling of 92% f1-score using the parseval evaluation metrics (black et al, 1991).<papid> H91-1060 </papid></nextsent>
<nextsent>someof these parsers have been adapted to other lan guage/treebank pairs, but many of these adaptations have been shown to be considerably less successful.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2043">
<title id=" W10-1401.xml">statistical parsing of morphologically rich languages spmrl what how and whither </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>since the initial release of the penn treebank (ptb marcus et al.
</prevsent>
<prevsent>(1993)), many different constituent-based parsing models have been developed in the context of parsing english (e.g.
</prevsent>
</prevsection>
<citsent citstr=" P08-1109 ">
(magerman, 1995; <papid> P95-1037 </papid>collins, 1997;<papid> P97-1003 </papid>charniak, 2000; <papid> A00-2018 </papid>chiang, 2000; <papid> P00-1058 </papid>bod, 2003; <papid> E03-1005 </papid>charniak and johnson, 2005; <papid> P05-1022 </papid>petrov et al, 2006; <papid> P06-1055 </papid>huang, 2008; <papid> P08-1067 </papid>finkel et al, 2008; <papid> P08-1109 </papid>carreras et al, 2008)).<papid> W08-2102 </papid></citsent>
<aftsection>
<nextsent>at their time, each of these models improved the state-of-the-art, bringing parsing performance on the standard test set of the wall-street-journal to performance ceiling of 92% f1-score using the parseval evaluation metrics (black et al, 1991).<papid> H91-1060 </papid></nextsent>
<nextsent>someof these parsers have been adapted to other lan guage/treebank pairs, but many of these adaptations have been shown to be considerably less successful.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2044">
<title id=" W10-1401.xml">statistical parsing of morphologically rich languages spmrl what how and whither </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>since the initial release of the penn treebank (ptb marcus et al.
</prevsent>
<prevsent>(1993)), many different constituent-based parsing models have been developed in the context of parsing english (e.g.
</prevsent>
</prevsection>
<citsent citstr=" W08-2102 ">
(magerman, 1995; <papid> P95-1037 </papid>collins, 1997;<papid> P97-1003 </papid>charniak, 2000; <papid> A00-2018 </papid>chiang, 2000; <papid> P00-1058 </papid>bod, 2003; <papid> E03-1005 </papid>charniak and johnson, 2005; <papid> P05-1022 </papid>petrov et al, 2006; <papid> P06-1055 </papid>huang, 2008; <papid> P08-1067 </papid>finkel et al, 2008; <papid> P08-1109 </papid>carreras et al, 2008)).<papid> W08-2102 </papid></citsent>
<aftsection>
<nextsent>at their time, each of these models improved the state-of-the-art, bringing parsing performance on the standard test set of the wall-street-journal to performance ceiling of 92% f1-score using the parseval evaluation metrics (black et al, 1991).<papid> H91-1060 </papid></nextsent>
<nextsent>someof these parsers have been adapted to other lan guage/treebank pairs, but many of these adaptations have been shown to be considerably less successful.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2045">
<title id=" W10-1401.xml">statistical parsing of morphologically rich languages spmrl what how and whither </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(1993)), many different constituent-based parsing models have been developed in the context of parsing english (e.g.
</prevsent>
<prevsent>(magerman, 1995; <papid> P95-1037 </papid>collins, 1997;<papid> P97-1003 </papid>charniak, 2000; <papid> A00-2018 </papid>chiang, 2000; <papid> P00-1058 </papid>bod, 2003; <papid> E03-1005 </papid>charniak and johnson, 2005; <papid> P05-1022 </papid>petrov et al, 2006; <papid> P06-1055 </papid>huang, 2008; <papid> P08-1067 </papid>finkel et al, 2008; <papid> P08-1109 </papid>carreras et al, 2008)).<papid> W08-2102 </papid></prevsent>
</prevsection>
<citsent citstr=" H91-1060 ">
at their time, each of these models improved the state-of-the-art, bringing parsing performance on the standard test set of the wall-street-journal to performance ceiling of 92% f1-score using the parseval evaluation metrics (black et al, 1991).<papid> H91-1060 </papid></citsent>
<aftsection>
<nextsent>someof these parsers have been adapted to other lan guage/treebank pairs, but many of these adaptations have been shown to be considerably less successful.
</nextsent>
<nextsent>among the arguments that have been proposed to explain this performance gap are the impact of small datasets, differences in treebanks?
</nextsent>
<nextsent>annotation schemes, and inadequacy of the widely used parseval evaluation metrics.
</nextsent>
<nextsent>none of these aspects in isolation can account for the systematic performance deterioration, but observed from wider, cross linguistic perspective, picture begins to emerge ? that the morphologically rich nature of some of the languages makes them inherently more susceptible to such performance degradation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2047">
<title id=" W10-1401.xml">statistical parsing of morphologically rich languages spmrl what how and whither </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>2.2 parsing mrls.
</prevsent>
<prevsent>pushing the envelope of constituency parsing: the head-driven models of the type proposed by collins (1997) <papid> P97-1003 </papid>have been ported to parsing many mrls, often via the implementation of bikel (2002).</prevsent>
</prevsection>
<citsent citstr=" P99-1065 ">
for czech, the adaptation by collins et al (1999) <papid> P99-1065 </papid>culminated in an 80 f1-score.</citsent>
<aftsection>
<nextsent>german has become almost an archetype of the problems caused by mrls; even though german has moderately rich morphology and moderately free word order, parsing results are far from those for english (see (kubler, 2008) and references therein).
</nextsent>
<nextsent>dubey (2005) <papid> P05-1039 </papid>showed that, for german parsing, adding case and morphology information together with smoothed markov ization and an adequate unknown-word model is more important than lexicalization (dubey and keller, 2003).<papid> P03-1013 </papid></nextsent>
<nextsent>for modern hebrew, tsarfaty and simaan (2007) <papid> W07-2219 </papid>show that simple treebank pcfg augmented with parent annotation and morphological information as state-splits significantly outperforms head-driven markov ized models of the kind made popular by klein and manning (2003).<papid> P03-1054 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2048">
<title id=" W10-1401.xml">statistical parsing of morphologically rich languages spmrl what how and whither </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>for czech, the adaptation by collins et al (1999) <papid> P99-1065 </papid>culminated in an 80 f1-score.</prevsent>
<prevsent>german has become almost an archetype of the problems caused by mrls; even though german has moderately rich morphology and moderately free word order, parsing results are far from those for english (see (kubler, 2008) and references therein).</prevsent>
</prevsection>
<citsent citstr=" P05-1039 ">
dubey (2005) <papid> P05-1039 </papid>showed that, for german parsing, adding case and morphology information together with smoothed markov ization and an adequate unknown-word model is more important than lexicalization (dubey and keller, 2003).<papid> P03-1013 </papid></citsent>
<aftsection>
<nextsent>for modern hebrew, tsarfaty and simaan (2007) <papid> W07-2219 </papid>show that simple treebank pcfg augmented with parent annotation and morphological information as state-splits significantly outperforms head-driven markov ized models of the kind made popular by klein and manning (2003).<papid> P03-1054 </papid></nextsent>
<nextsent>results for parsing modern standard arabic using bikels implementation on gold-standard tagging and segmentation have not improved substantially since the initial release of the treebank (maamouri et al, 2004; kulick et al, 2006; maamouri et al, 2008).for italian, corazza et al (2004) used the stanford parser and bikels parser emulation of collins?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2049">
<title id=" W10-1401.xml">statistical parsing of morphologically rich languages spmrl what how and whither </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>for czech, the adaptation by collins et al (1999) <papid> P99-1065 </papid>culminated in an 80 f1-score.</prevsent>
<prevsent>german has become almost an archetype of the problems caused by mrls; even though german has moderately rich morphology and moderately free word order, parsing results are far from those for english (see (kubler, 2008) and references therein).</prevsent>
</prevsection>
<citsent citstr=" P03-1013 ">
dubey (2005) <papid> P05-1039 </papid>showed that, for german parsing, adding case and morphology information together with smoothed markov ization and an adequate unknown-word model is more important than lexicalization (dubey and keller, 2003).<papid> P03-1013 </papid></citsent>
<aftsection>
<nextsent>for modern hebrew, tsarfaty and simaan (2007) <papid> W07-2219 </papid>show that simple treebank pcfg augmented with parent annotation and morphological information as state-splits significantly outperforms head-driven markov ized models of the kind made popular by klein and manning (2003).<papid> P03-1054 </papid></nextsent>
<nextsent>results for parsing modern standard arabic using bikels implementation on gold-standard tagging and segmentation have not improved substantially since the initial release of the treebank (maamouri et al, 2004; kulick et al, 2006; maamouri et al, 2008).for italian, corazza et al (2004) used the stanford parser and bikels parser emulation of collins?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2050">
<title id=" W10-1401.xml">statistical parsing of morphologically rich languages spmrl what how and whither </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>german has become almost an archetype of the problems caused by mrls; even though german has moderately rich morphology and moderately free word order, parsing results are far from those for english (see (kubler, 2008) and references therein).
</prevsent>
<prevsent>dubey (2005) <papid> P05-1039 </papid>showed that, for german parsing, adding case and morphology information together with smoothed markov ization and an adequate unknown-word model is more important than lexicalization (dubey and keller, 2003).<papid> P03-1013 </papid></prevsent>
</prevsection>
<citsent citstr=" W07-2219 ">
for modern hebrew, tsarfaty and simaan (2007) <papid> W07-2219 </papid>show that simple treebank pcfg augmented with parent annotation and morphological information as state-splits significantly outperforms head-driven markov ized models of the kind made popular by klein and manning (2003).<papid> P03-1054 </papid></citsent>
<aftsection>
<nextsent>results for parsing modern standard arabic using bikels implementation on gold-standard tagging and segmentation have not improved substantially since the initial release of the treebank (maamouri et al, 2004; kulick et al, 2006; maamouri et al, 2008).for italian, corazza et al (2004) used the stanford parser and bikels parser emulation of collins?
</nextsent>
<nextsent>model 2 (collins, 1997) <papid> P97-1003 </papid>on the isst treebank, and obtained significantly lower results compared to english.</nextsent>
<nextsent>it is notable that these models were applied without adding morphological signatures, using gold lemmas instead.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2051">
<title id=" W10-1401.xml">statistical parsing of morphologically rich languages spmrl what how and whither </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>german has become almost an archetype of the problems caused by mrls; even though german has moderately rich morphology and moderately free word order, parsing results are far from those for english (see (kubler, 2008) and references therein).
</prevsent>
<prevsent>dubey (2005) <papid> P05-1039 </papid>showed that, for german parsing, adding case and morphology information together with smoothed markov ization and an adequate unknown-word model is more important than lexicalization (dubey and keller, 2003).<papid> P03-1013 </papid></prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
for modern hebrew, tsarfaty and simaan (2007) <papid> W07-2219 </papid>show that simple treebank pcfg augmented with parent annotation and morphological information as state-splits significantly outperforms head-driven markov ized models of the kind made popular by klein and manning (2003).<papid> P03-1054 </papid></citsent>
<aftsection>
<nextsent>results for parsing modern standard arabic using bikels implementation on gold-standard tagging and segmentation have not improved substantially since the initial release of the treebank (maamouri et al, 2004; kulick et al, 2006; maamouri et al, 2008).for italian, corazza et al (2004) used the stanford parser and bikels parser emulation of collins?
</nextsent>
<nextsent>model 2 (collins, 1997) <papid> P97-1003 </papid>on the isst treebank, and obtained significantly lower results compared to english.</nextsent>
<nextsent>it is notable that these models were applied without adding morphological signatures, using gold lemmas instead.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2060">
<title id=" W10-1401.xml">statistical parsing of morphologically rich languages spmrl what how and whither </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>corazza et al (2004) further tried different refinements including parent annotation and horizontal markov ization, but none of them obtained the desired improvement.for french, crabbe?
</prevsent>
<prevsent>and candito (2008) and seddah et al (2010) show that, given corpus comparable in size and properties (i.e. the number of tokens and grammar size), the performance level, both forcharniaks parser (charniak, 2000) <papid> A00-2018 </papid>and the berkeley parser (petrov et al, 2006) <papid> P06-1055 </papid>was higher for parsing the ptb than it was for french.</prevsent>
</prevsection>
<citsent citstr=" N07-1051 ">
the split-mergesmooth implementation of (petrov et al, 2006) <papid> P06-1055 </papid>consistently outperform various lexicalized and unlexi calized models for french (seddah et al, 2009) and for many other languages (petrov and klein, 2007).<papid> N07-1051 </papid></citsent>
<aftsection>
<nextsent>in this respect, (petrov et al, 2006) <papid> P06-1055 </papid>is considered mrl-friendly, due to its language agnostic design.</nextsent>
<nextsent>the rise of dependency parsing: it is commonly assumed that dependency structures are better suited for representing the syntactic structures of free word order, morphologically rich, languages, because this representation format does not rely crucially on the position of words and the internal grouping of surface chunks (melcuk, 1988).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2064">
<title id=" W10-1401.xml">statistical parsing of morphologically rich languages spmrl what how and whither </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>in this respect, (petrov et al, 2006) <papid> P06-1055 </papid>is considered mrl-friendly, due to its language agnostic design.</prevsent>
<prevsent>the rise of dependency parsing: it is commonly assumed that dependency structures are better suited for representing the syntactic structures of free word order, morphologically rich, languages, because this representation format does not rely crucially on the position of words and the internal grouping of surface chunks (melcuk, 1988).</prevsent>
</prevsection>
<citsent citstr=" W06-2920 ">
it is an entirely different question, however, whether dependency parsers are in fact better suited for parsing such languages.the conll shared tasks on multilingual dependency parsing in 2006 and 2007 (buchholz and marsi, 2006; <papid> W06-2920 </papid>nivre et al, 2007<papid> D07-1096 </papid>a) demonstrated that dependency parsing for mrls is quite challenging.</citsent>
<aftsection>
<nextsent>while dependency parsers are adaptable to many languages, as reflected in the multiplicity of the languages covered,1 the analysis by nivre et al (2007<papid> D07-1096 </papid>b) shows that the best result was obtained for english,followed by catalan, and that the most difficult languages to parse were arabic, basque, and greek.</nextsent>
<nextsent>nivre et al (2007<papid> D07-1096 </papid>a) drew somewhat typo logical conclusion, that languages with rich morphology and free word order are the hardest to parse.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2065">
<title id=" W10-1401.xml">statistical parsing of morphologically rich languages spmrl what how and whither </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>in this respect, (petrov et al, 2006) <papid> P06-1055 </papid>is considered mrl-friendly, due to its language agnostic design.</prevsent>
<prevsent>the rise of dependency parsing: it is commonly assumed that dependency structures are better suited for representing the syntactic structures of free word order, morphologically rich, languages, because this representation format does not rely crucially on the position of words and the internal grouping of surface chunks (melcuk, 1988).</prevsent>
</prevsection>
<citsent citstr=" D07-1096 ">
it is an entirely different question, however, whether dependency parsers are in fact better suited for parsing such languages.the conll shared tasks on multilingual dependency parsing in 2006 and 2007 (buchholz and marsi, 2006; <papid> W06-2920 </papid>nivre et al, 2007<papid> D07-1096 </papid>a) demonstrated that dependency parsing for mrls is quite challenging.</citsent>
<aftsection>
<nextsent>while dependency parsers are adaptable to many languages, as reflected in the multiplicity of the languages covered,1 the analysis by nivre et al (2007<papid> D07-1096 </papid>b) shows that the best result was obtained for english,followed by catalan, and that the most difficult languages to parse were arabic, basque, and greek.</nextsent>
<nextsent>nivre et al (2007<papid> D07-1096 </papid>a) drew somewhat typo logical conclusion, that languages with rich morphology and free word order are the hardest to parse.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2075">
<title id=" W10-1401.xml">statistical parsing of morphologically rich languages spmrl what how and whither </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>while dependency parsers are adaptable to many languages, as reflected in the multiplicity of the languages covered,1 the analysis by nivre et al (2007<papid> D07-1096 </papid>b) shows that the best result was obtained for english,followed by catalan, and that the most difficult languages to parse were arabic, basque, and greek.</prevsent>
<prevsent>nivre et al (2007<papid> D07-1096 </papid>a) drew somewhat typo logical conclusion, that languages with rich morphology and free word order are the hardest to parse.</prevsent>
</prevsection>
<citsent citstr=" P05-1012 ">
this was shown to be the case for both malt parser (nivre et al, 2007<papid> D07-1096 </papid>c) and mst (mcdonald et al, 2005), <papid> P05-1012 </papid>two of the best performing parsers on the whole.annotation and evaluation matter: an emerging question is therefore whether models that have been so successful in parsing english are necessarily appropriate for parsing mrls ? but associated with this question are important questions concerning the annotation scheme of the related treebanks.</citsent>
<aftsection>
<nextsent>obviously, when annotating structures for languages with characteristics different than english one has to face different annotation decisions, and it comes as no surprise that the annotated structures for mrls often differ from those employed in the ptb.
</nextsent>
<nextsent>1the shared tasks involved 18 languages, including many mrls such as arabic, basque, czech, hungarian, and turkish.
</nextsent>
<nextsent>3 for spanish and french, it was shown by cowan and collins (2005) <papid> H05-1100 </papid>and in (arun and keller, 2005; <papid> P05-1038 </papid>schluter and van genabith, 2007), that restructuring the treebanks?</nextsent>
<nextsent>native annotation scheme to match the ptb annotation style led to significant gain in parsing performance of head-driven models of the kind proposed in (collins, 1997).<papid> P97-1003 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2076">
<title id=" W10-1401.xml">statistical parsing of morphologically rich languages spmrl what how and whither </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>obviously, when annotating structures for languages with characteristics different than english one has to face different annotation decisions, and it comes as no surprise that the annotated structures for mrls often differ from those employed in the ptb.
</prevsent>
<prevsent>1the shared tasks involved 18 languages, including many mrls such as arabic, basque, czech, hungarian, and turkish.
</prevsent>
</prevsection>
<citsent citstr=" H05-1100 ">
3 for spanish and french, it was shown by cowan and collins (2005) <papid> H05-1100 </papid>and in (arun and keller, 2005; <papid> P05-1038 </papid>schluter and van genabith, 2007), that restructuring the treebanks?</citsent>
<aftsection>
<nextsent>native annotation scheme to match the ptb annotation style led to significant gain in parsing performance of head-driven models of the kind proposed in (collins, 1997).<papid> P97-1003 </papid></nextsent>
<nextsent>for german, alan guage with four different treebanks and two substantially different annotation schemes, it has been shown that pcfg parser is sensitive to the kind of representation employed in the treebank.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2077">
<title id=" W10-1401.xml">statistical parsing of morphologically rich languages spmrl what how and whither </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>obviously, when annotating structures for languages with characteristics different than english one has to face different annotation decisions, and it comes as no surprise that the annotated structures for mrls often differ from those employed in the ptb.
</prevsent>
<prevsent>1the shared tasks involved 18 languages, including many mrls such as arabic, basque, czech, hungarian, and turkish.
</prevsent>
</prevsection>
<citsent citstr=" P05-1038 ">
3 for spanish and french, it was shown by cowan and collins (2005) <papid> H05-1100 </papid>and in (arun and keller, 2005; <papid> P05-1038 </papid>schluter and van genabith, 2007), that restructuring the treebanks?</citsent>
<aftsection>
<nextsent>native annotation scheme to match the ptb annotation style led to significant gain in parsing performance of head-driven models of the kind proposed in (collins, 1997).<papid> P97-1003 </papid></nextsent>
<nextsent>for german, alan guage with four different treebanks and two substantially different annotation schemes, it has been shown that pcfg parser is sensitive to the kind of representation employed in the treebank.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2080">
<title id=" W10-1401.xml">statistical parsing of morphologically rich languages spmrl what how and whither </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>model 1 on negra.
</prevsent>
<prevsent>they showed that using sister-head dependencies instead of head head dependencies improved parsing performance, and hypothesized that it is due to the flatness ofphrasal annotation.
</prevsent>
</prevsection>
<citsent citstr=" W05-0303 ">
kubler et al (2006) showed considerably lower parseval scores on negra (skutet al, 1998) relative to the more hierarchically structured tuba-d/z (hinrichs et al, 2005), <papid> W05-0303 </papid>again, hy pothesizing that this is due to annotation differences.</citsent>
<aftsection>
<nextsent>related to such comparisons is the question of the relevance of the parseval metrics for evaluating parsing results across languages and treebanks.
</nextsent>
<nextsent>rehbein and van genabith (2007) <papid> D07-1066 </papid>showed that parseval measures are sensitive to annotation scheme particularities (e.g. the internal node ratio).</nextsent>
<nextsent>it was further shown that different metrics (i.e. the leaf ancestor path (sampson and babarczy, 2003) and dependency based ones in (lin, 1995)) can lead to different performance ranking.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2081">
<title id=" W10-1401.xml">statistical parsing of morphologically rich languages spmrl what how and whither </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>kubler et al (2006) showed considerably lower parseval scores on negra (skutet al, 1998) relative to the more hierarchically structured tuba-d/z (hinrichs et al, 2005), <papid> W05-0303 </papid>again, hy pothesizing that this is due to annotation differences.</prevsent>
<prevsent>related to such comparisons is the question of the relevance of the parseval metrics for evaluating parsing results across languages and treebanks.</prevsent>
</prevsection>
<citsent citstr=" D07-1066 ">
rehbein and van genabith (2007) <papid> D07-1066 </papid>showed that parseval measures are sensitive to annotation scheme particularities (e.g. the internal node ratio).</citsent>
<aftsection>
<nextsent>it was further shown that different metrics (i.e. the leaf ancestor path (sampson and babarczy, 2003) and dependency based ones in (lin, 1995)) can lead to different performance ranking.
</nextsent>
<nextsent>this was confirmed also for french by seddah et al (2009).
</nextsent>
<nextsent>the questions of how to annotate treebanks for mrls and how to evaluate the performance of the different parsers on these different treebanks is crucial.
</nextsent>
<nextsent>for the mrl parsing community to be able to assess the difficulty of improving parsing results for french, german, arabic, korean, basque, hindi or hebrew, we ought to first address fundamental questions including: is the treebank sufficiently large to allow for proper grammar induction?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2085">
<title id=" W10-1401.xml">statistical parsing of morphologically rich languages spmrl what how and whither </title>
<section> primary research questions.  </section>
<citcontext>
<prevsection>
<prevsent>this is the case, for instance, for the arabic parsing at conll 2007 (nivre et al, 2007<papid> D07-1096 </papid>a).</prevsent>
<prevsent>this practice de ludes the community as to the validity of the parsing results reported for mrls in shared tasks.</prevsent>
</prevsection>
<citsent citstr=" E09-1038 ">
goldberg et al (2009), <papid> E09-1038 </papid>for instance, show gap of up to 6pt f1-score between performance on gold standard segmentation vs. raw text.</citsent>
<aftsection>
<nextsent>one way to overcome this is to devise joint morphological and syntactic disambiguation frameworks (cf.
</nextsent>
<nextsent>(goldberg and tsarfaty, 2008)).
</nextsent>
<nextsent>4 logical information should we include in the parsingmodel?
</nextsent>
<nextsent>inflectional and/or derivational?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2088">
<title id=" W10-1401.xml">statistical parsing of morphologically rich languages spmrl what how and whither </title>
<section> parsing mrls: recurring trends.  </section>
<citcontext>
<prevsection>
<prevsent>maier (2010) suggests the use of linear context-free rewriting systems (lcfrss) in order to make discontinuous structure transparent to the parsing process and yet preserve familiar notions from constituency.
</prevsent>
<prevsent>dependency representation uses non-projective dependencies to reflect discontinuities, which is problematic to parse with models that assume projectivity.
</prevsent>
</prevsection>
<citsent citstr=" P05-1013 ">
different ways have been proposed to deal with non-projectivity (nivre and nilsson, 2005; <papid> P05-1013 </papid>mcdonald et al, 2005; <papid> P05-1012 </papid>mcdonald and pereira, 2006; <papid> E06-1011 </papid>nivre, 2009).<papid> P09-1040 </papid></citsent>
<aftsection>
<nextsent>bengoetxea and gojenola (2010) discuss non-projective dependencies in basque and show that the pseudo-projective transformation of(nivre and nilsson, 2005) <papid> P05-1013 </papid>improves accuracy forde pendency parsing of basque.</nextsent>
<nextsent>moreover, they show that in combination with other transformations, it improves the utility of these other ones, too.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2090">
<title id=" W10-1401.xml">statistical parsing of morphologically rich languages spmrl what how and whither </title>
<section> parsing mrls: recurring trends.  </section>
<citcontext>
<prevsection>
<prevsent>maier (2010) suggests the use of linear context-free rewriting systems (lcfrss) in order to make discontinuous structure transparent to the parsing process and yet preserve familiar notions from constituency.
</prevsent>
<prevsent>dependency representation uses non-projective dependencies to reflect discontinuities, which is problematic to parse with models that assume projectivity.
</prevsent>
</prevsection>
<citsent citstr=" E06-1011 ">
different ways have been proposed to deal with non-projectivity (nivre and nilsson, 2005; <papid> P05-1013 </papid>mcdonald et al, 2005; <papid> P05-1012 </papid>mcdonald and pereira, 2006; <papid> E06-1011 </papid>nivre, 2009).<papid> P09-1040 </papid></citsent>
<aftsection>
<nextsent>bengoetxea and gojenola (2010) discuss non-projective dependencies in basque and show that the pseudo-projective transformation of(nivre and nilsson, 2005) <papid> P05-1013 </papid>improves accuracy forde pendency parsing of basque.</nextsent>
<nextsent>moreover, they show that in combination with other transformations, it improves the utility of these other ones, too.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2091">
<title id=" W10-1401.xml">statistical parsing of morphologically rich languages spmrl what how and whither </title>
<section> parsing mrls: recurring trends.  </section>
<citcontext>
<prevsection>
<prevsent>maier (2010) suggests the use of linear context-free rewriting systems (lcfrss) in order to make discontinuous structure transparent to the parsing process and yet preserve familiar notions from constituency.
</prevsent>
<prevsent>dependency representation uses non-projective dependencies to reflect discontinuities, which is problematic to parse with models that assume projectivity.
</prevsent>
</prevsection>
<citsent citstr=" P09-1040 ">
different ways have been proposed to deal with non-projectivity (nivre and nilsson, 2005; <papid> P05-1013 </papid>mcdonald et al, 2005; <papid> P05-1012 </papid>mcdonald and pereira, 2006; <papid> E06-1011 </papid>nivre, 2009).<papid> P09-1040 </papid></citsent>
<aftsection>
<nextsent>bengoetxea and gojenola (2010) discuss non-projective dependencies in basque and show that the pseudo-projective transformation of(nivre and nilsson, 2005) <papid> P05-1013 </papid>improves accuracy forde pendency parsing of basque.</nextsent>
<nextsent>moreover, they show that in combination with other transformations, it improves the utility of these other ones, too.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2093">
<title id=" W10-1401.xml">statistical parsing of morphologically rich languages spmrl what how and whither </title>
<section> parsing mrls: recurring trends.  </section>
<citcontext>
<prevsection>
<prevsent>one way to cope with the one of both aspects of this problem is through clustering, that is, providing an abstract representation over word forms that reflects their shared morphological and morphosyntactic aspects.
</prevsent>
<prevsent>this was done, for instance, in previous work on parsing german.
</prevsent>
</prevsection>
<citsent citstr=" W09-3820 ">
versley and rehbein (2009) <papid> W09-3820 </papid>cluster words according to linear context features.</citsent>
<aftsection>
<nextsent>these clusters include valency information added to verbs and morphological features such as case and number added to pre-terminal nodes.
</nextsent>
<nextsent>the clusters are then integrated as features in discriminative parsing model to cope with unknown words.
</nextsent>
<nextsent>their discriminative model thus obtains state-of-the-art results on parsing german.
</nextsent>
<nextsent>several contribution address similar challenges.for constituency-based generative parsers, the simple technique of replacing word forms with more abstract symbols is investigated by (seddah et al,2010; candito and seddah, 2010).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2095">
<title id=" W10-1741.xml">l1 regularized regression for reranking and system combination in machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we model system combination task as reranking problem among the competing translation models and present encouraging results with the tregmt system.
</prevsent>
<prevsent>related work: regression techniques can be used to model the relationship between strings (cortes et al, 2007).
</prevsent>
</prevsection>
<citsent citstr=" N07-2047 ">
wang et al (2007) <papid> N07-2047 </papid>applies string-to-string mapping approach to machine translation by using ordinary least squares regression and n-gram string kernels to small dataset.</citsent>
<aftsection>
<nextsent>later they use l2 regularized least squares regression (wang and shawe-taylor, 2008).
</nextsent>
<nextsent>although the translation quality they achieve is not better than moses (koehn et al, 2007), <papid> P07-2045 </papid>which is accepted to be the state-of-the-art,they show the feasibility of the approach.</nextsent>
<nextsent>serrano et al (2009) use kernel regression to find translation mappings from source to target feature vectors and experiment with translating hotel front desk requests.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2096">
<title id=" W10-1741.xml">l1 regularized regression for reranking and system combination in machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>wang et al (2007) <papid> N07-2047 </papid>applies string-to-string mapping approach to machine translation by using ordinary least squares regression and n-gram string kernels to small dataset.</prevsent>
<prevsent>later they use l2 regularized least squares regression (wang and shawe-taylor, 2008).</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
although the translation quality they achieve is not better than moses (koehn et al, 2007), <papid> P07-2045 </papid>which is accepted to be the state-of-the-art,they show the feasibility of the approach.</citsent>
<aftsection>
<nextsent>serrano et al (2009) use kernel regression to find translation mappings from source to target feature vectors and experiment with translating hotel front desk requests.
</nextsent>
<nextsent>ueffing (2007) approaches the transductive learning problem for smt by bootstrapping the training using the translations produced by the smt system that have scoring performance above some threshold as estimated by the smt system itself.
</nextsent>
<nextsent>282outline: section 2 gives an overview of regression based machine translation, which is used to find the mappings between the source and target features of the training set.
</nextsent>
<nextsent>in section 3 we presentl1 regularized transductive regression for alignment learning.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2098">
<title id=" W10-1741.xml">l1 regularized regression for reranking and system combination in machine translation </title>
<section> translation experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we add bp penalty to all of the reranking results given in the next section and qp results also use optimized ?.
</prevsent>
<prevsent>285 en-de de-en en-fr en-es en-cz score bleu nist bleu nist bleu nist bleu nist bleu nist baseline .1309 5.1417 .1556 5.4164 .2049 6.3194 .2106 6.3611 .1145 4.5008 oracle .1811 6.0252 .2101 6.2103 .2683 7.2409 .2770 7.3190 .1628 5.4501 l2 .1319 5.1680 .1555 5.4344 .2044 6.3370 .2132 6.4093 .1148 4.5187 fsr .1317* 5.1639 .1559 5.4383 .2053 6.3458 .2144 6.4168 .1150 4.5172 lp .1317 5.1695 .1561 5.4304 .2048 6.3245 .2109 6.4176 .1124 4.5143 qp .1309 5.1664 .1550 5.4553 .2033 6.3354* .2121 6.4271 .1150 4.5264 table 2: reranking results using tregmt, tm, and lm scores.
</prevsent>
</prevsection>
<citsent citstr=" W05-0908 ">
we use approximate randomization test (riezler and maxwell, 2005) <papid> W05-0908 </papid>with 1000 repetitions to determine score difference significance: results in bold are significant with ? 0.01 and italic results with (*) are significant with ? .05.</citsent>
<aftsection>
<nextsent>the difference of the remaining from the baseline are not statistically significant.
</nextsent>
<nextsent>4.4 reranking experiments.
</nextsent>
<nextsent>we rerank -best lists by using linear combinations of the following scoring functions: 1.
</nextsent>
<nextsent>tregmt: transductive regression based ma-.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2099">
<title id=" W10-1741.xml">l1 regularized regression for reranking and system combination in machine translation </title>
<section> translation experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the performance increase is important for two reasons.
</prevsent>
<prevsent>first of all, we are able to improve the performance using blended spectrum 3-gram features against translations obtained with 5-gramlanguage model and higher order features.
</prevsent>
</prevsection>
<citsent citstr=" P09-1087 ">
outperforming higher order n-gram models is known to be difficult task (galley and manning, 2009).<papid> P09-1087 </papid>secondly, increasing the performance with reranking itself is hard task since possible translations are already constrained by the ones observed inn best lists.</citsent>
<aftsection>
<nextsent>therefore, an increase in the -best list size may increase the score gaps.
</nextsent>
<nextsent>table 2 presents reranking results on all of the language pairs we considered, using tregmt, tm, and lm scores with the combination weights learned in the development set.
</nextsent>
<nextsent>we are able to achieve better bleu and nist scores on all of the listed systems.
</nextsent>
<nextsent>we are able to see up to .38 bleu points increase for the en-es pair.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2100">
<title id=" W10-1741.xml">l1 regularized regression for reranking and system combination in machine translation </title>
<section> system combination experiments.  </section>
<citcontext>
<prevsection>
<prevsent>by measuring the average bleu performance of each translation relative to the other translations in the -best list.
</prevsent>
<prevsent>thus, each possible translation in then -best list is bleu scored against other translations and the average of these scores is selected as the tm score for the sentence.
</prevsent>
</prevsection>
<citsent citstr=" D07-1105 ">
sentence level bleu score calculation avoids singularities ingram precis ions by taking the maximum of the match count and 12|si| for |si| denoting the length of the source sentence si as used in (macherey and och, 2007).<papid> D07-1105 </papid></citsent>
<aftsection>
<nextsent>table 3 presents reranking results on all of the language pairs we considered, using tregmt, tm, and lm scores with the same combination weights as above.
</nextsent>
<nextsent>random model score lists the random model performance selected among the competing translations randomly and it is used as baseline.
</nextsent>
<nextsent>best model score lists the performance of the best model performance.
</nextsent>
<nextsent>we are able to achieve better bleu and nist scores in all of the listed systems except for the de-en language pair when compared with the performance of the best competing translation system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2101">
<title id=" W10-3802.xml">a systematic comparison between inversion transduction grammar and linear transduction grammar for word alignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also present method for obtaining inversion transduction grammars from linear (inversion) transduction grammars, which can speed up grammar induction from parallel corpora dramatically.
</prevsent>
<prevsent>in this paper we introduce linear transduction grammars (ltgs), which are the bilingual case of linear grammars (lgs).
</prevsent>
</prevsection>
<citsent citstr=" N10-1050 ">
we also show that ltgs are equal to linear inversion transduction grammars (saers et al, 2010).<papid> N10-1050 </papid></citsent>
<aftsection>
<nextsent>to be able to induce transduction grammars directly from parallel corpora an approximate search for parses isneeded.
</nextsent>
<nextsent>the trade-off between speed and end-toend translation quality is investigated and compared to inversion transduction grammars (wu, 1997) <papid> J97-3002 </papid>and the standard tool for word alignment, giza++ (brown et al, 1993; <papid> J93-2003 </papid>vogel et al, 1996; <papid> C96-2141 </papid>och and ney, 2003).<papid> J03-1002 </papid></nextsent>
<nextsent>a heuristic for converting stochastic bracketing ltgs into stochastic bracketing itgs is presented, and fitted into the speed?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2103">
<title id=" W10-3802.xml">a systematic comparison between inversion transduction grammar and linear transduction grammar for word alignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also show that ltgs are equal to linear inversion transduction grammars (saers et al, 2010).<papid> N10-1050 </papid></prevsent>
<prevsent>to be able to induce transduction grammars directly from parallel corpora an approximate search for parses isneeded.</prevsent>
</prevsection>
<citsent citstr=" J97-3002 ">
the trade-off between speed and end-toend translation quality is investigated and compared to inversion transduction grammars (wu, 1997) <papid> J97-3002 </papid>and the standard tool for word alignment, giza++ (brown et al, 1993; <papid> J93-2003 </papid>vogel et al, 1996; <papid> C96-2141 </papid>och and ney, 2003).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>a heuristic for converting stochastic bracketing ltgs into stochastic bracketing itgs is presented, and fitted into the speed?
</nextsent>
<nextsent>quality trade-off.in section 3 we give an overview of transduction grammars, introduce ltgs and show that they are equal to litgs.
</nextsent>
<nextsent>in section 4 we givea short description of the rational for the transduction grammar pruning used.
</nextsent>
<nextsent>in section 5 we describe way of seeding stochastic bracketingitg with the rules and probabilities of stochastic bracketing ltg.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2105">
<title id=" W10-3802.xml">a systematic comparison between inversion transduction grammar and linear transduction grammar for word alignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also show that ltgs are equal to linear inversion transduction grammars (saers et al, 2010).<papid> N10-1050 </papid></prevsent>
<prevsent>to be able to induce transduction grammars directly from parallel corpora an approximate search for parses isneeded.</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
the trade-off between speed and end-toend translation quality is investigated and compared to inversion transduction grammars (wu, 1997) <papid> J97-3002 </papid>and the standard tool for word alignment, giza++ (brown et al, 1993; <papid> J93-2003 </papid>vogel et al, 1996; <papid> C96-2141 </papid>och and ney, 2003).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>a heuristic for converting stochastic bracketing ltgs into stochastic bracketing itgs is presented, and fitted into the speed?
</nextsent>
<nextsent>quality trade-off.in section 3 we give an overview of transduction grammars, introduce ltgs and show that they are equal to litgs.
</nextsent>
<nextsent>in section 4 we givea short description of the rational for the transduction grammar pruning used.
</nextsent>
<nextsent>in section 5 we describe way of seeding stochastic bracketingitg with the rules and probabilities of stochastic bracketing ltg.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2106">
<title id=" W10-3802.xml">a systematic comparison between inversion transduction grammar and linear transduction grammar for word alignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also show that ltgs are equal to linear inversion transduction grammars (saers et al, 2010).<papid> N10-1050 </papid></prevsent>
<prevsent>to be able to induce transduction grammars directly from parallel corpora an approximate search for parses isneeded.</prevsent>
</prevsection>
<citsent citstr=" C96-2141 ">
the trade-off between speed and end-toend translation quality is investigated and compared to inversion transduction grammars (wu, 1997) <papid> J97-3002 </papid>and the standard tool for word alignment, giza++ (brown et al, 1993; <papid> J93-2003 </papid>vogel et al, 1996; <papid> C96-2141 </papid>och and ney, 2003).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>a heuristic for converting stochastic bracketing ltgs into stochastic bracketing itgs is presented, and fitted into the speed?
</nextsent>
<nextsent>quality trade-off.in section 3 we give an overview of transduction grammars, introduce ltgs and show that they are equal to litgs.
</nextsent>
<nextsent>in section 4 we givea short description of the rational for the transduction grammar pruning used.
</nextsent>
<nextsent>in section 5 we describe way of seeding stochastic bracketingitg with the rules and probabilities of stochastic bracketing ltg.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2107">
<title id=" W10-3802.xml">a systematic comparison between inversion transduction grammar and linear transduction grammar for word alignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also show that ltgs are equal to linear inversion transduction grammars (saers et al, 2010).<papid> N10-1050 </papid></prevsent>
<prevsent>to be able to induce transduction grammars directly from parallel corpora an approximate search for parses isneeded.</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
the trade-off between speed and end-toend translation quality is investigated and compared to inversion transduction grammars (wu, 1997) <papid> J97-3002 </papid>and the standard tool for word alignment, giza++ (brown et al, 1993; <papid> J93-2003 </papid>vogel et al, 1996; <papid> C96-2141 </papid>och and ney, 2003).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>a heuristic for converting stochastic bracketing ltgs into stochastic bracketing itgs is presented, and fitted into the speed?
</nextsent>
<nextsent>quality trade-off.in section 3 we give an overview of transduction grammars, introduce ltgs and show that they are equal to litgs.
</nextsent>
<nextsent>in section 4 we givea short description of the rational for the transduction grammar pruning used.
</nextsent>
<nextsent>in section 5 we describe way of seeding stochastic bracketingitg with the rules and probabilities of stochastic bracketing ltg.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2110">
<title id=" W10-3802.xml">a systematic comparison between inversion transduction grammar and linear transduction grammar for word alignment </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>the simplest of these combinations are intersection and union, but usually, the intersection is heuristic ally extended.
</prevsent>
<prevsent>transduction grammars on the other hand, impose shared structure on the sentence pairs, thus forcing consistent alignment in both directions.
</prevsent>
</prevsection>
<citsent citstr=" P08-1012 ">
this method 10 has proved successful in the settings it has been tried (zhang et al, 2008; <papid> P08-1012 </papid>saers and wu, 2009; haghighi et al, 2009; <papid> P09-1104 </papid>saers et al, 2009; <papid> W09-3804 </papid>saers et al, 2010).<papid> N10-1050 </papid></citsent>
<aftsection>
<nextsent>most efforts focus on cutting downtime complexity so that larger datasets than toy examples can be processed.
</nextsent>
<nextsent>transduction grammars were first introduced inlewis and stearns (1968), and further developed in aho and ullman (1972).
</nextsent>
<nextsent>the original notation called for regular cfg-rules in language with rephrased productions, either incurly brackets, or comma separated.
</nextsent>
<nextsent>the bilingual version of cfgs is called syntax-directedtransduction grammars (sdtgs).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2111">
<title id=" W10-3802.xml">a systematic comparison between inversion transduction grammar and linear transduction grammar for word alignment </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>the simplest of these combinations are intersection and union, but usually, the intersection is heuristic ally extended.
</prevsent>
<prevsent>transduction grammars on the other hand, impose shared structure on the sentence pairs, thus forcing consistent alignment in both directions.
</prevsent>
</prevsection>
<citsent citstr=" P09-1104 ">
this method 10 has proved successful in the settings it has been tried (zhang et al, 2008; <papid> P08-1012 </papid>saers and wu, 2009; haghighi et al, 2009; <papid> P09-1104 </papid>saers et al, 2009; <papid> W09-3804 </papid>saers et al, 2010).<papid> N10-1050 </papid></citsent>
<aftsection>
<nextsent>most efforts focus on cutting downtime complexity so that larger datasets than toy examples can be processed.
</nextsent>
<nextsent>transduction grammars were first introduced inlewis and stearns (1968), and further developed in aho and ullman (1972).
</nextsent>
<nextsent>the original notation called for regular cfg-rules in language with rephrased productions, either incurly brackets, or comma separated.
</nextsent>
<nextsent>the bilingual version of cfgs is called syntax-directedtransduction grammars (sdtgs).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2112">
<title id=" W10-3802.xml">a systematic comparison between inversion transduction grammar and linear transduction grammar for word alignment </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>the simplest of these combinations are intersection and union, but usually, the intersection is heuristic ally extended.
</prevsent>
<prevsent>transduction grammars on the other hand, impose shared structure on the sentence pairs, thus forcing consistent alignment in both directions.
</prevsent>
</prevsection>
<citsent citstr=" W09-3804 ">
this method 10 has proved successful in the settings it has been tried (zhang et al, 2008; <papid> P08-1012 </papid>saers and wu, 2009; haghighi et al, 2009; <papid> P09-1104 </papid>saers et al, 2009; <papid> W09-3804 </papid>saers et al, 2010).<papid> N10-1050 </papid></citsent>
<aftsection>
<nextsent>most efforts focus on cutting downtime complexity so that larger datasets than toy examples can be processed.
</nextsent>
<nextsent>transduction grammars were first introduced inlewis and stearns (1968), and further developed in aho and ullman (1972).
</nextsent>
<nextsent>the original notation called for regular cfg-rules in language with rephrased productions, either incurly brackets, or comma separated.
</nextsent>
<nextsent>the bilingual version of cfgs is called syntax-directedtransduction grammars (sdtgs).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2116">
<title id=" W10-3802.xml">a systematic comparison between inversion transduction grammar and linear transduction grammar for word alignment </title>
<section> transduction grammars.  </section>
<citcontext>
<prevsection>
<prevsent>a ? xx xa ; 0, 1, 2, 3 xa ? a, ? xx ? ?, xlexical rules involving the empty string are referred to as singletons.
</prevsent>
<prevsent>whenever pre terminal is used to pair up two terminal symbols, we refer to that pair of terminals as biterminal, which will be written as e/f .any sdtg can be rephrased to contain permuted nonterminal productions and biterminalproductions only, and we will call this the normal form of sdtgs.
</prevsent>
</prevsection>
<citsent citstr=" J09-4009 ">
note that it is not possible to produce two-normal form for sdtgs, as there are some rules that are not binarizable (wu, 1997; <papid> J97-3002 </papid>huang et al, 2009).<papid> J09-4009 </papid></citsent>
<aftsection>
<nextsent>this is an important point to make, since efficient parsing for cfgs is based on either restricting parsing to only handle binary grammars (cocke, 1969;kasami, 1965; younger, 1967), or relyon onthe-fly binarization (earley, 1970).
</nextsent>
<nextsent>when translating with grammar, parsing only has to be done in , which is binarizable (since it is acfg), and can therefor be computed in polyno mial time (o(n3)).
</nextsent>
<nextsent>once there is parse treefor , the corresponding tree for can be easily constructed.
</nextsent>
<nextsent>when inducing grammar from examples, however, biparsing (finding an analysis that is consistent across sentence pair) is needed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2122">
<title id=" W10-3802.xml">a systematic comparison between inversion transduction grammar and linear transduction grammar for word alignment </title>
<section> setup.  </section>
<citcontext>
<prevsection>
<prevsent>out (see table 1).
</prevsent>
<prevsent>the giza++ system was built according to the instructions for creating base line system for the fifth workshop on statistical machine translation (wmt10),1 but the above corpora were used instead of those supplied by the workshop.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
this includes word alignment with giza++, 5-gram language model built with srilm (stolcke, 2002) and parameter tuning with mert (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>to carry out the actual translations, moses (koehn et al, 2007) <papid> P07-2045 </papid>was used.</nextsent>
<nextsent>the sbitg and sbltg systems were builtin exactly the same way, except that the alignments from giza++ were replaced by those from the respective grammars.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2123">
<title id=" W10-3802.xml">a systematic comparison between inversion transduction grammar and linear transduction grammar for word alignment </title>
<section> setup.  </section>
<citcontext>
<prevsection>
<prevsent>the giza++ system was built according to the instructions for creating base line system for the fifth workshop on statistical machine translation (wmt10),1 but the above corpora were used instead of those supplied by the workshop.
</prevsent>
<prevsent>this includes word alignment with giza++, 5-gram language model built with srilm (stolcke, 2002) and parameter tuning with mert (och, 2003).<papid> P03-1021 </papid></prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
to carry out the actual translations, moses (koehn et al, 2007) <papid> P07-2045 </papid>was used.</citsent>
<aftsection>
<nextsent>the sbitg and sbltg systems were builtin exactly the same way, except that the alignments from giza++ were replaced by those from the respective grammars.
</nextsent>
<nextsent>in addition to trying out exhaustive biparsing 1http://www.statmt.org/wmt10/for sbitgs and sbltgs on three different translation tasks, several different levels of pruning were tried (1, 10, 25, 50, 75 and 100).
</nextsent>
<nextsent>we also used the grammar induced from sbltgs with beam size of 25 to seed sbitgs (see section 5), which were then run for an additional iteration of em, also with beam size 25.all systems are evaluated with bleu (pap ineni et al, 2002) <papid> P02-1040 </papid>and nist (doddington, 2002).</nextsent>
<nextsent>the results for the three different translation tasks are presented in tables 2, 3 and 4.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2124">
<title id=" W10-3802.xml">a systematic comparison between inversion transduction grammar and linear transduction grammar for word alignment </title>
<section> setup.  </section>
<citcontext>
<prevsection>
<prevsent>the sbitg and sbltg systems were builtin exactly the same way, except that the alignments from giza++ were replaced by those from the respective grammars.
</prevsent>
<prevsent>in addition to trying out exhaustive biparsing 1http://www.statmt.org/wmt10/for sbitgs and sbltgs on three different translation tasks, several different levels of pruning were tried (1, 10, 25, 50, 75 and 100).
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
we also used the grammar induced from sbltgs with beam size of 25 to seed sbitgs (see section 5), which were then run for an additional iteration of em, also with beam size 25.all systems are evaluated with bleu (pap ineni et al, 2002) <papid> P02-1040 </papid>and nist (doddington, 2002).</citsent>
<aftsection>
<nextsent>the results for the three different translation tasks are presented in tables 2, 3 and 4.
</nextsent>
<nextsent>it is interesting to note that the trend they portray is quite similar.
</nextsent>
<nextsent>when the beam is very narrow, giza++ is better, but already at beam size 10,both transduction grammars are superior.
</nextsent>
<nextsent>con 15 beam size system 1 10 25 50 75 100 ? bleu sbitg 0.1268 0.2632 0.2654 0.2669 0.2668 0.2655 0.2663 sbltg 0.2600 0.2638 0.2651 0.2668 0.2672 0.2662 0.2649 giza++ 0.2603 0.2603 0.2603 0.2603 0.2603 0.2603 0.2603 nist sbitg 4.0849 6.7136 6.7913 6.8065 6.8068 6.8088 6.8151 sbltg 6.6814 6.7608 6.7656 6.7992 6.8020 6.7925 6.7784 giza++ 6.6907 6.6907 6.6907 6.6907 6.6907 6.6907 6.6907 training times sbitg 03:25 17:00 42:00 1:25:00 2:10:00 2:45:00 3:10:00 sbltg 31 1:41 3:25 7:06 9:35 13:56 10:52 table 3: results for the french english translation task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2126">
<title id=" W10-2408.xml">language independent transliteration mining system using finite state automata framework </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>this is done through searching for candidate documents pairs through an information retrieval system and then using named entity matching system which relies on the length-normalized phonetic based edit distance between the two words.
</prevsent>
<prevsent>they also usea phrase-based translation tables to measure similarity of extracted named entities.
</prevsent>
</prevsection>
<citsent citstr=" W09-3525 ">
noeman (2009)<papid> W09-3525 </papid>also used phrase based statistical machine translation (pbsmt) approach to create substring based transliteration system through the generated phrase table, thus creating language independent approach to transliteration.</citsent>
<aftsection>
<nextsent>other resources have been used to perform transliteration.
</nextsent>
<nextsent>chang (2009) et. al proposed the use of romanizationtable in conjunction with an unsupervised constraint driven learning algorithm in order to identify transliteration pairs without any labelled data.
</nextsent>
<nextsent>the approach consists of three main phases which are (1) transliteration model learning, (2) fi 57 figure 1: transliteration table learning in pbsmt nite state machine formalization of the generated transliteration model and (3) generating candidate transliterations.
</nextsent>
<nextsent>figure (1) illustrates transliteration table learning in pbsmt framework.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2127">
<title id=" W10-1605.xml">human language technology for text based analysis of psychotherapy sessions in the spanish language </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the liwc tool has been used to detect different types of personalities in written self-descriptions (chung and penne baker, 2008).
</prevsent>
<prevsent>this program counts meaningful words that express emotion, abstraction, verbal behavior,demographic variables, traditional personality measures, formal and informal settings, deception and honesty, emotional upheavals, social interaction, use of cognitive and emotion words, word analysis in psychotherapy, references to self and others.
</prevsent>
</prevsection>
<citsent citstr=" P07-1124 ">
for spanish (roussos and oconnell, 2005) have developed dictionary in the area of psychotherapy 33 to measure referential activity.early work on dictionaries in the area of psychology include the general inquirer psycho sociological dictionary (stone and hunt, 1963) which can be used in various applications; current work on lexical resources for identifying particular text variables ? such as measuring strong/weak opinions, sentiments, subjective/objective language, etc. ? include the sentiwordnet resource (esuli and sebastiani, 2006) derived from wordnet which has been used in various opinion mining works (devitt and ahmad, 2007); <papid> P07-1124 </papid>other lines of research include the derivation of word-lists (semi) automatically for opinion classification (turney, 2002).</citsent>
<aftsection>
<nextsent>to the best of our knowledge, little research has been carried outon natural language processing for discourse interpretation in psychology.
</nextsent>
<nextsent>liber mans theory identifies 7 drives (i.e., subset of freuds drives) which are introduced in table 1 we may associate these drives with emotional or affective states such as: strong emotions associated with il; ecstasy or trance with o1; sadness with o2; anger with a1; concrete language with a2; warnings, suspense, and premonition with uph ; and congratulation, adulation, and promises with gph.
</nextsent>
<nextsent>in diagnosis these variables are associated to pathologies such as addiction, schizophrenia, depression, paranoia, obsession, phobia, and hysteria;so their manifestation in text is of paramount importance for diagnosis.
</nextsent>
<nextsent>abbreviation drive name il intra-somatic libido o1 primary oral o2 secondary oral sadistic a1 primary anal sadistic a2 secondary anal sadistic uph urethrae phallic gph genital phallic table 1: drives in liberman and maldavsky theory the theory also associates lexicalizations to eachof the drives (maldavsky, 2003), thus creating semantic dictionary with 7 categories, the main work drive lexicalisationil verbs: to throw up, to break; nouns: hospital, throat; adjectives: sick, fat; ad verbs: fatally, greedily o1 verbs: to sip, to suck; nouns: enigma,research; adjectives: mystical, enlighten ing; adverbs: elliptically, enigmaticallyo2 verbs: to feel, to feel like; nouns: feeling, victim; adjectives: sensitive, happy, sad; adverbs: fondly, obedientlya1 verbs: to bother, to kick; nouns: violence, transgression; adjectives: angry, locked; adverbs: angrily,boldly, crossly a2 verbs: must, to know; nouns: vice, doubt; adjectives: good, bad; adverbs: but, although, however uph verbs: to be able, to dare; nouns: scar, precipice, wound; adjectives: coward, scared; adverbs: almost, bit gph verbs: to promise, to give; nouns: beauty, ugliness; adjectives: wavy, pretty; adverbs: more, even table 2: sample of drives and associated lexicalisationing hypothesis is that drives manifest through linguistic style, present at word level, phrase, and narrative.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2128">
<title id=" W10-1005.xml">search right and thou shalt find  using web queries for learner error detection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>preposition and determiner errors (most of which are article errors) are the second and third most frequent errors in the cambridge learner corpus (after the more intractable problem of content word choice).
</prevsent>
<prevsent>by targeting the ten most frequent prepositions involved in learner errors, more than 80% of preposition errors in the corpus are covered.
</prevsent>
</prevsection>
<citsent citstr=" I08-1059 ">
typically, data-driven approaches to learner errors use classifier trained on contextual information such as tokens and part-of-speech tags within window of the preposition/article (gamon et al 2008, <papid> I08-1059 </papid>2010, defelice and pulman 2007, 2008, han et al 2006, chodorow et al 2007, <papid> W07-1604 </papid>tetreault and chodorow 2008).<papid> C08-1109 </papid></citsent>
<aftsection>
<nextsent>language models are another source of evidence that can be used in error detection.
</nextsent>
<nextsent>using language models for this purpose is not new approach, it goes back to at least atwell (1987).<papid> E87-1007 </papid></nextsent>
<nextsent>gamon et al (2008) <papid> I08-1059 </papid>and gamon (2010) use combination of classification and language modeling.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2129">
<title id=" W10-1005.xml">search right and thou shalt find  using web queries for learner error detection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>preposition and determiner errors (most of which are article errors) are the second and third most frequent errors in the cambridge learner corpus (after the more intractable problem of content word choice).
</prevsent>
<prevsent>by targeting the ten most frequent prepositions involved in learner errors, more than 80% of preposition errors in the corpus are covered.
</prevsent>
</prevsection>
<citsent citstr=" W07-1604 ">
typically, data-driven approaches to learner errors use classifier trained on contextual information such as tokens and part-of-speech tags within window of the preposition/article (gamon et al 2008, <papid> I08-1059 </papid>2010, defelice and pulman 2007, 2008, han et al 2006, chodorow et al 2007, <papid> W07-1604 </papid>tetreault and chodorow 2008).<papid> C08-1109 </papid></citsent>
<aftsection>
<nextsent>language models are another source of evidence that can be used in error detection.
</nextsent>
<nextsent>using language models for this purpose is not new approach, it goes back to at least atwell (1987).<papid> E87-1007 </papid></nextsent>
<nextsent>gamon et al (2008) <papid> I08-1059 </papid>and gamon (2010) use combination of classification and language modeling.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2130">
<title id=" W10-1005.xml">search right and thou shalt find  using web queries for learner error detection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>preposition and determiner errors (most of which are article errors) are the second and third most frequent errors in the cambridge learner corpus (after the more intractable problem of content word choice).
</prevsent>
<prevsent>by targeting the ten most frequent prepositions involved in learner errors, more than 80% of preposition errors in the corpus are covered.
</prevsent>
</prevsection>
<citsent citstr=" C08-1109 ">
typically, data-driven approaches to learner errors use classifier trained on contextual information such as tokens and part-of-speech tags within window of the preposition/article (gamon et al 2008, <papid> I08-1059 </papid>2010, defelice and pulman 2007, 2008, han et al 2006, chodorow et al 2007, <papid> W07-1604 </papid>tetreault and chodorow 2008).<papid> C08-1109 </papid></citsent>
<aftsection>
<nextsent>language models are another source of evidence that can be used in error detection.
</nextsent>
<nextsent>using language models for this purpose is not new approach, it goes back to at least atwell (1987).<papid> E87-1007 </papid></nextsent>
<nextsent>gamon et al (2008) <papid> I08-1059 </papid>and gamon (2010) use combination of classification and language modeling.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2131">
<title id=" W10-1005.xml">search right and thou shalt find  using web queries for learner error detection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>typically, data-driven approaches to learner errors use classifier trained on contextual information such as tokens and part-of-speech tags within window of the preposition/article (gamon et al 2008, <papid> I08-1059 </papid>2010, defelice and pulman 2007, 2008, han et al 2006, chodorow et al 2007, <papid> W07-1604 </papid>tetreault and chodorow 2008).<papid> C08-1109 </papid></prevsent>
<prevsent>language models are another source of evidence that can be used in error detection.</prevsent>
</prevsection>
<citsent citstr=" E87-1007 ">
using language models for this purpose is not new approach, it goes back to at least atwell (1987).<papid> E87-1007 </papid></citsent>
<aftsection>
<nextsent>gamon et al (2008) <papid> I08-1059 </papid>and gamon (2010) use combination of classification and language modeling.</nextsent>
<nextsent>once language modeling comes into play, the quantity of the training data comes to the forefront.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2133">
<title id=" W10-1005.xml">search right and thou shalt find  using web queries for learner error detection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>gamon et al (2008) <papid> I08-1059 </papid>and gamon (2010) use combination of classification and language modeling.</prevsent>
<prevsent>once language modeling comes into play, the quantity of the training data comes to the forefront.</prevsent>
</prevsection>
<citsent citstr=" P01-1005 ">
it has been well-established that statistical models improve as the size of the training data increases (banko and brill 2001<papid> P01-1005 </papid>a, 2001b).</citsent>
<aftsection>
<nextsent>this is particularly true for language models: other statistical models such as classifier, for example, can be targeted towards specific decision/classification, reducing the appetite for data somewhat, while language models provide probabilities for any sequence of words - task that requires immense training data resources if the language model is to consider increasingly sparse longer n-grams.
</nextsent>
<nextsent>language models trained on data sources like the gigaword corpus have become commonplace, but of course there is one corpus that dwarfs any other resource in size: the world wide web.
</nextsent>
<nextsent>this has drawn the interest of many researchers in natural language processing over the past decade.
</nextsent>
<nextsent>to mention just few examples, zhu and rosenfeld (2001) combine trigram counts from the web with an existing language model where the estimates of the existing model are unreliable because of data sparseness.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2135">
<title id=" W10-1005.xml">search right and thou shalt find  using web queries for learner error detection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this has drawn the interest of many researchers in natural language processing over the past decade.
</prevsent>
<prevsent>to mention just few examples, zhu and rosenfeld (2001) combine trigram counts from the web with an existing language model where the estimates of the existing model are unreliable because of data sparseness.
</prevsent>
</prevsection>
<citsent citstr=" J03-3005 ">
keller and lapata (2003) <papid> J03-3005 </papid>advocate the use of the web as corpus to retrieve backoff probabilities for unseen bigrams.</citsent>
<aftsection>
<nextsent>lapata and keller (2005) extend this method to range of additional natural language processing tasks, but also caution that web counts have limitations and add noise.
</nextsent>
<nextsent>kilgariff (2007) points out the shortcomings of 37accessing the web as corpus through search que ries: (a) there is no lemmatization or part-of-speech tagging in search indices, so linguistically meaningful query can only be approximated, (b) search syntax, as implemented by search engine providers, is limited, (c) there is often limit on the number of automatic queries that are allowed by search engines, (c) hit count estimates are estimates of retrieved pages, not of retrieved words.
</nextsent>
<nextsent>we would like to add to that list that hit count estimates on the web are just that -- estimates.
</nextsent>
<nextsent>they are computed on the fly by proprietary algorithms, and apparently the algorithms also access different slices of the web index, which causes fluctuation over time, as tetrault and chodorow (2009) point out.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2136">
<title id=" W10-1005.xml">search right and thou shalt find  using web queries for learner error detection </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>what is the best query formulation strategy when using web search results for this task?
</prevsent>
<prevsent>how much context should be included in the query?
</prevsent>
</prevsection>
<citsent citstr=" L08-1322 ">
hermet et al (2008) <papid> L08-1322 </papid>use web search hit counts for preposition error detection and correction in french.</citsent>
<aftsection>
<nextsent>they use set of conf usable prepositions to create candidate set of alternative prepositional choices and generate queries for each of the candidates and the original.
</nextsent>
<nextsent>the queries are produced using linguistic analysis to identify both governing and governed element as minimum meaningful context.
</nextsent>
<nextsent>on small test set of 133 sentences, they report accuracy of 69.9% using the yahoo!
</nextsent>
<nextsent>search engine.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2137">
<title id=" W10-1005.xml">search right and thou shalt find  using web queries for learner error detection </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>on small test set of 133 sentences, they report accuracy of 69.9% using the yahoo!
</prevsent>
<prevsent>search engine.
</prevsent>
</prevsection>
<citsent citstr=" I08-2082 ">
yi et al (2008) <papid> I08-2082 </papid>target article use and collocation errors with similar approach.</citsent>
<aftsection>
<nextsent>their system first analyzes the input sentence using part-of-speech tagging and chunk parser.
</nextsent>
<nextsent>based on this analysis, potential error locations for determiners and verb noun collocation errors are identified.
</nextsent>
<nextsent>query generation is performed at three levels of granularity: the sentence (or clause) level, chunk level and word level.
</nextsent>
<nextsent>queries, in this approach, are not exact string searches but rather set of strings combined with the chunk containing the potential error through boolean operator.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2138">
<title id=" W10-3221.xml">a current status of thai categorial grammars and their applications </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also discuss about difficulty of building treebank and mention toolkit for assisting on thai cgs tree building and tree format representations.
</prevsent>
<prevsent>in this paper, we also give summary of applications related to thai cgs.
</prevsent>
</prevsection>
<citsent citstr=" W09-3414 ">
recently, cg formalism was applied to several thai nlp applications such as syntactic information for thai to english rbmt (ruangrajitpakorn et al, 2007), cg treebank (ruangrajitpakorn et al, 2009), <papid> W09-3414 </papid>and an automatic cg tagger (supnithi et al, 2010).</citsent>
<aftsection>
<nextsent>cg shows promises to handle thai syntax expeditiously since it can widely control utilisations of function words which are the main grammatical expression of thai.
</nextsent>
<nextsent>in the previous research, cg was employed as feature for an english to thai smt and it resulted better accuracy in term of bleu score for 1.05% (porkaew and supnithi, 2009).
</nextsent>
<nextsent>cg was also used in research of translation of noun phrase from english to thai using phrase based smt with cg reordering rules, and it returned 75% of better and smoother translation from human evaluation (porkaew et al, 2009).
</nextsent>
<nextsent>though cg has high potential in immediate constituency analysis for thai, it sill lacks of dependency analysis which is also important in syntactical parsing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2139">
<title id=" W10-3221.xml">a current status of thai categorial grammars and their applications </title>
<section> thai categorial grammars.  </section>
<citcontext>
<prevsection>
<prevsent>throughout this paper, constituent type of the syntactic category and the dependency structure is represented by c:d.let us exemplify dependency driven derivation of cdg of sentence  mary drinks fresh milk  in figure 2.
</prevsent>
<prevsent>in figure 2(a), each pair of constituents is combined to form larger constituent with its head word.
</prevsent>
</prevsection>
<citsent citstr=" E09-1053 ">
figure 2(b) shows dependency structure equivalent to the derivation in figure 2(a).comparing to pf-ccg (koller and kuhlmann, 2009), <papid> E09-1053 </papid>there is different in that their pfccg dependency markers are fixed to the direction of slashes while cdg dependency markers are customised based on behaviour of con stituent.cdg offers an efficient way to represent dependency structures alongside syntactic derivations.</citsent>
<aftsection>
<nextsent>apart from immediate constituency analysis, we can also investigate the correspondence between the syntactic derivations and the dependency structures.
</nextsent>
<nextsent>it benefits linguists in details grammar for specific language beargu ment category definition example np noun phrase ????
</nextsent>
<nextsent>(elephant), ??
</nextsent>
<nextsent>(i, me) num digit and spelled-out number ?????
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2140">
<title id=" W10-3203.xml">considerations on automatic mapping largescale heterogeneous language resources sejong semantic classes and korlex </title>
<section> related works.  </section>
<citcontext>
<prevsection>
<prevsent>because the concept items of sumo are much larger than those of pwn, it could be mapped between high level concepts of pwn and synonymy concepts of sumo easily.
</prevsent>
<prevsent>(ian niles et al 2003).
</prevsent>
</prevsection>
<citsent citstr=" L08-1125 ">
dennis spohr (2008) <papid> L08-1125 </papid>presented general methodology to mapping euro wordnet to the sumo forex traction of selectional preferences for french.</citsent>
<aftsection>
<nextsent>jan scheffczyk et al  (2006) introduced the connection of framenet to sumo.
</nextsent>
<nextsent>they presented general-domain links between framenet semantic types and sumo classes in suokif and developed semi-automatic, domain-specific approach for linking framenet frame elements to sumo classes (scheffczyk &amp; al. 2006).
</nextsent>
<nextsent>sara tonelli et al  (2009) presented supervised learning framework for the mapping of framenet lexical units onto pwn synsets to solve limited coverage of semantic phenomena for nlp applications.
</nextsent>
<nextsent>their best results were recall 0.613, precision 0.761 and f1 measure 0.679.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2141">
<title id=" W10-1715.xml">more linguistic annotation for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>on average we outperformed our submission from last year by 2.16 bleu points on the same newstest2009 test set.
</prevsent>
<prevsent>while the submitted system follows the factored phrase-based approach, we also built hierarchical and syntax-based models for the english german language pair and report on its performance on the development test sets.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
all our systems are based on the moses toolkit (koehn et al, 2007).<papid> P07-2045 </papid></citsent>
<aftsection>
<nextsent>we achieved gains over the systems from last year by consistently exploiting all available training data, using large-scale domain-interpolated, and consistent use of the factored translation model to integrate n-gram models over speech tags.
</nextsent>
<nextsent>we also experimented with novel domain adaptation methods, with mixed results.
</nextsent>
<nextsent>the baseline system uses all available training data, except for the large un and 109 corpora, as well as the optional ldc gigaword corpus.
</nextsent>
<nextsent>it uses straight-forward setup of the moses decoder.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2142">
<title id=" W10-1715.xml">more linguistic annotation for statistical machine translation </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>the baseline system uses all available training data, except for the large un and 109 corpora, as well as the optional ldc gigaword corpus.
</prevsent>
<prevsent>it uses straight-forward setup of the moses decoder.
</prevsent>
</prevsection>
<citsent citstr=" W09-0429 ">
some relevant parameter settings are: ? maximum sentence length 80 words ? tokenization with hyphen splitting ? true casing ? grow-diag-final-and alignment heuristic ? msd-bidirectional-fe lexicalized reordering ? interpolated 5-gram language model ? tuning on newsdev2009 ? testing during development on newstest2009 ? mbr decoding ? no reordering over punctuation ? cube pruning we used most of these setting in our submission last year (koehn and haddow, 2009).<papid> W09-0429 </papid></citsent>
<aftsection>
<nextsent>the main difference to our baseline system from the submission from last year is the use of additional training data: larger releases of the news commentary, europarl, czeng, and monolingual news corpora.
</nextsent>
<nextsent>the first two parallel corpora increased roughly 10-20% in size, while the czeng parallel corpus and the monolingual news corpora are five times and twice as big, respectively.
</nextsent>
<nextsent>we also handled some of the corpus preparation steps with more care to avoid some data inconsistency problems from last year (affecting mostly the french language pairs).
</nextsent>
<nextsent>an overview of the results is given in table 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2143">
<title id=" W10-1715.xml">more linguistic annotation for statistical machine translation </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>the wmt training data exhibits an increasing diversity of corpora: europarl, news commentary, un, 109, news ? and seven different sources within the czeng corpus.
</prevsent>
<prevsent>it is well known that domain adaptation is an important step in optimizing machine translation systems.
</prevsent>
</prevsection>
<citsent citstr=" W07-0733 ">
a relatively simple and straight-forward method is the linear interpolation of the language model, as we explored previously (koehn and schroeder, 2007; <papid> W07-0733 </papid>schwenk and koehn, 2008).<papid> I08-2089 </papid></citsent>
<aftsection>
<nextsent>we trained domain-specific language models separately and then linearly interpolated them using srilm toolkit (stolke, 2002) with weights op language pair cased uncased spanish-english 25.25 26.36 (+1.11) french-english 25.23 26.29 (+1.06) german-english 19.47 20.63 (+1.16) czech-english 20.74 21.76 (+1.02) english-spanish 24.20 25.47 (+1.27) english-french 23.83 25.02 (+1.19) english-german 14.68 15.18 (+0.50) english-czech 14.63 15.13 (+0.50) avg +0.98 table 3: effect of truecasing: cased and uncased bleu scores timized on the development set newsdev2009.
</nextsent>
<nextsent>see table 2 for numbers on perplexity, corpus sizes, and interpolation weights.
</nextsent>
<nextsent>note, for instance, the relatively high weight for the news commentary corpus (0.204) compared to the eu roparl corpus (0.105) in the english language model for the french-english system, despite the latter being about 25 times bigger.
</nextsent>
<nextsent>2.2 truecasing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2144">
<title id=" W10-1715.xml">more linguistic annotation for statistical machine translation </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>the wmt training data exhibits an increasing diversity of corpora: europarl, news commentary, un, 109, news ? and seven different sources within the czeng corpus.
</prevsent>
<prevsent>it is well known that domain adaptation is an important step in optimizing machine translation systems.
</prevsent>
</prevsection>
<citsent citstr=" I08-2089 ">
a relatively simple and straight-forward method is the linear interpolation of the language model, as we explored previously (koehn and schroeder, 2007; <papid> W07-0733 </papid>schwenk and koehn, 2008).<papid> I08-2089 </papid></citsent>
<aftsection>
<nextsent>we trained domain-specific language models separately and then linearly interpolated them using srilm toolkit (stolke, 2002) with weights op language pair cased uncased spanish-english 25.25 26.36 (+1.11) french-english 25.23 26.29 (+1.06) german-english 19.47 20.63 (+1.16) czech-english 20.74 21.76 (+1.02) english-spanish 24.20 25.47 (+1.27) english-french 23.83 25.02 (+1.19) english-german 14.68 15.18 (+0.50) english-czech 14.63 15.13 (+0.50) avg +0.98 table 3: effect of truecasing: cased and uncased bleu scores timized on the development set newsdev2009.
</nextsent>
<nextsent>see table 2 for numbers on perplexity, corpus sizes, and interpolation weights.
</nextsent>
<nextsent>note, for instance, the relatively high weight for the news commentary corpus (0.204) compared to the eu roparl corpus (0.105) in the english language model for the french-english system, despite the latter being about 25 times bigger.
</nextsent>
<nextsent>2.2 truecasing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2145">
<title id=" W10-1715.xml">more linguistic annotation for statistical machine translation </title>
<section> extensions.  </section>
<citcontext>
<prevsection>
<prevsent>how ever, this method gives dubious results for rarecounts.
</prevsent>
<prevsent>the most blatant case is the single occurrence of foreign phrase, whose sole english translation will receive the translation probability 1 1 = 1.
</prevsent>
</prevsection>
<citsent citstr=" W06-1607 ">
foster et al (2006) <papid> W06-1607 </papid>applied ideas from language model smoothing to the translation model.</citsent>
<aftsection>
<nextsent>good turing smoothing (good, 1953) uses counts of counts statistics to assess how likely we will see word (or, in our case, phrase) again, if we have seen it times in the training corpus.
</nextsent>
<nextsent>instead of using the raw counts, adapted (lower) counts areused in the estimation of the conditional probability distribution.
</nextsent>
<nextsent>the count of counts are collected for the phrasepairs.
</nextsent>
<nextsent>see table 4 for details on how this effects the french english model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2146">
<title id=" W10-1715.xml">more linguistic annotation for statistical machine translation </title>
<section> extensions.  </section>
<citcontext>
<prevsection>
<prevsent>for details refer back to table 1.
</prevsent>
<prevsent>3.3 pos n-gram model.
</prevsent>
</prevsection>
<citsent citstr=" D07-1091 ">
the factored model approach (koehn and hoang, 2007) <papid> D07-1091 </papid>allows us to integrate 7-gram models over part-of-speech tags.</citsent>
<aftsection>
<nextsent>the part-of-speech tags are produced during decoding by the phrase mapping of surface words on the source side to factored representation of surface words and their part-of speech tags on the target side in one translation step.we previously used this additional scoring component for the german english language pairs with success.
</nextsent>
<nextsent>thus we now applied to it all other language pairs (except for english czech due to the lack of czech part-of-speech tagger).
</nextsent>
<nextsent>we used the following part-of-speech taggers: ? english: mxpost1 ? german: lopar2 ? french: treetagger3 ? spanish: treetaggerfor english german, we also used morphological tags, which give better performance than just basic part-of-speech tags (+0.46 vs. +0.22, see table 5).
</nextsent>
<nextsent>we observe gains for all language pairs except for english spanish, possibly due to the 1www.inf.ed.ac.uk/resources/nlp/local doc/mxpost.html 2www.ims.uni-stuttgart.de/projekte/gramotron/software/ lopar.html 3www.ims.uni-stuttgart.de/projekte/corplex/treetagger/ 117 model bleu baseline 14.81 part-of-speech 15.03 (+0.22) morphogical 15.28 (+0.47) table 6: englishgerman: use of morphological and part-of-speech n-gram models language pair baseline with 109 french english 25.92 27.15 (+1.23) english french 24.70 24.80 (+0.10) table 7: use of large french english corpus faulty use of the spanish part-of-speech tagger.we gain +0.14 bleu points on average (includ ing the 0.28 drop for spanish).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2147">
<title id=" W10-1715.xml">more linguistic annotation for statistical machine translation </title>
<section> extensions.  </section>
<citcontext>
<prevsection>
<prevsent>for details refer back to table 1.
</prevsent>
<prevsent>3.5 109 corpus last year, due to time constraints, we were not able to use the billion word 109 corpus for the french english language pairs.
</prevsent>
</prevsection>
<citsent citstr=" W08-0509 ">
this is largest publicly available parallel corpus, and it does strain computing resources, for instance forcing us to use multi-threaded giza++ (gao and vogel, 2008).<papid> W08-0509 </papid>table 7 shows the gains obtained from using this corpus in both the translation model andthe language model opposed to baseline system trained with otherwise the same settings.</citsent>
<aftsection>
<nextsent>for french english we see large gains (+1.23), but not for english french (+0.10).
</nextsent>
<nextsent>our official submission for the frenchenglishlanguage pairs used these models.
</nextsent>
<nextsent>they did not include part-of-speech language model and bigger beam sizes.
</nextsent>
<nextsent>model bleu baseline 19.51 + compound splitting 20.09 (+0.58) + pre-reordering 20.03 (+0.52) + both 20.85 (+1.34) table 8: special handling of german english language pair baseline weighted tm spanish-english 26.20 26.15 (0.05) french-english 26.11 26.30 (+0.19) german-english 21.09 20.81 (0.28) czech-english 21.33 21.21 (0.12) english-german 15.28 15.01 (0.27) avg.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2148">
<title id=" W10-1715.xml">more linguistic annotation for statistical machine translation </title>
<section> extensions.  </section>
<citcontext>
<prevsection>
<prevsent>model bleu baseline 19.51 + compound splitting 20.09 (+0.58) + pre-reordering 20.03 (+0.52) + both 20.85 (+1.34) table 8: special handling of german english language pair baseline weighted tm spanish-english 26.20 26.15 (0.05) french-english 26.11 26.30 (+0.19) german-english 21.09 20.81 (0.28) czech-english 21.33 21.21 (0.12) english-german 15.28 15.01 (0.27) avg.
</prevsent>
<prevsent>0.11 table 9: interpol ating the translation model with language model weights 3.6 germanenglish.
</prevsent>
</prevsection>
<citsent citstr=" E03-1076 ">
for the german english language direction, we used two additional processing steps that have shown to be successful in the past, and again resulted insignificant gains.we split large words based on word frequencies to tackle the problem of word compounds in german (koehn and knight, 2003).<papid> E03-1076 </papid></citsent>
<aftsection>
<nextsent>secondly, we re-order the german input to the decoder (and the german side of the training data) to align more closely to the english target language (collins et al, 2005).<papid> P05-1066 </papid></nextsent>
<nextsent>the two methods improve +0.58 and +0.52 overthe baseline individually, and +1.34 when com bined.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2149">
<title id=" W10-1715.xml">more linguistic annotation for statistical machine translation </title>
<section> extensions.  </section>
<citcontext>
<prevsection>
<prevsent>0.11 table 9: interpol ating the translation model with language model weights 3.6 germanenglish.
</prevsent>
<prevsent>for the german english language direction, we used two additional processing steps that have shown to be successful in the past, and again resulted insignificant gains.we split large words based on word frequencies to tackle the problem of word compounds in german (koehn and knight, 2003).<papid> E03-1076 </papid></prevsent>
</prevsection>
<citsent citstr=" P05-1066 ">
secondly, we re-order the german input to the decoder (and the german side of the training data) to align more closely to the english target language (collins et al, 2005).<papid> P05-1066 </papid></citsent>
<aftsection>
<nextsent>the two methods improve +0.58 and +0.52 overthe baseline individually, and +1.34 when combined.
</nextsent>
<nextsent>see also table 8.
</nextsent>
<nextsent>3.7 translation model interpolation.
</nextsent>
<nextsent>finally, we explored novel domain adaption method for the translation model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2150">
<title id=" W10-1715.xml">more linguistic annotation for statistical machine translation </title>
<section> tree-based models.  </section>
<citcontext>
<prevsection>
<prevsent>a major extension of the capabilities of the moses system is the accommodation of tree-based models (hoang et al, 2009).
</prevsent>
<prevsent>while we have not yet carried out sufficient experimentation and optimization of the implementation, we took the occasion of the shared translation task as opportunity to build large-scale systems using such models.
</prevsent>
</prevsection>
<citsent citstr=" P05-1033 ">
we build two translation systems: one usingtree-based models without additional linguistic annotation, which are known as hierarchical phrase based models (chiang, 2005), <papid> P05-1033 </papid>and another system that uses linguistic annotation on the target side, which are known under many names such as string-to-tree models or syntactified target models (marcu et al, 2006).<papid> W06-1606 </papid></citsent>
<aftsection>
<nextsent>both models are trained using very similar pipeline as for the phrase model.
</nextsent>
<nextsent>the main difference is that the translation rules do not have to be contiguous phrases, but may contain gaps withare labeled and co-ordinated by non-terminal symbols.
</nextsent>
<nextsent>decoding with such models requires very different algorithm, which is related to syntactic chart parsing.
</nextsent>
<nextsent>in the target syntax model, the target gaps and the entire target phrase must map to constituents in the parse tree.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2151">
<title id=" W10-1715.xml">more linguistic annotation for statistical machine translation </title>
<section> tree-based models.  </section>
<citcontext>
<prevsection>
<prevsent>a major extension of the capabilities of the moses system is the accommodation of tree-based models (hoang et al, 2009).
</prevsent>
<prevsent>while we have not yet carried out sufficient experimentation and optimization of the implementation, we took the occasion of the shared translation task as opportunity to build large-scale systems using such models.
</prevsent>
</prevsection>
<citsent citstr=" W06-1606 ">
we build two translation systems: one usingtree-based models without additional linguistic annotation, which are known as hierarchical phrase based models (chiang, 2005), <papid> P05-1033 </papid>and another system that uses linguistic annotation on the target side, which are known under many names such as string-to-tree models or syntactified target models (marcu et al, 2006).<papid> W06-1606 </papid></citsent>
<aftsection>
<nextsent>both models are trained using very similar pipeline as for the phrase model.
</nextsent>
<nextsent>the main difference is that the translation rules do not have to be contiguous phrases, but may contain gaps withare labeled and co-ordinated by non-terminal symbols.
</nextsent>
<nextsent>decoding with such models requires very different algorithm, which is related to syntactic chart parsing.
</nextsent>
<nextsent>in the target syntax model, the target gaps and the entire target phrase must map to constituents in the parse tree.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2152">
<title id=" W10-1715.xml">more linguistic annotation for statistical machine translation </title>
<section> tree-based models.  </section>
<citcontext>
<prevsection>
<prevsent>decoding with such models requires very different algorithm, which is related to syntactic chart parsing.
</prevsent>
<prevsent>in the target syntax model, the target gaps and the entire target phrase must map to constituents in the parse tree.
</prevsent>
</prevsection>
<citsent citstr=" W06-3119 ">
this restriction may be relaxed by adding constituent labels such as det+adj ornp\det to group neighboring constituents or indicate constituents that lack an initial child, respectively (zollmann and venugopal, 2006).<papid> W06-3119 </papid></citsent>
<aftsection>
<nextsent>we applied these models to the english german language direction, which is of particular interest to us due to the rich target side morphology and large degree of reordering, resulting in relatively poor performance.
</nextsent>
<nextsent>see table 10 for experimental results with the two traditional models (phrase-based model and factored model that includes 7-gram morphological tag model) andthe two newer models (hierarchical and target syntax).
</nextsent>
<nextsent>the performance of the phrase-based, hierarchical, and target syntax model are close in terms of bleu.
</nextsent>
<nextsent>we obtained substantial gains over our systems from last year for all language pairs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2153">
<title id=" W10-1831.xml">challenges of cheap resource creation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>morphological analyzers usually relyon large manually created lexicons.
</prevsent>
<prevsent>for example, the czech analyzer (hajic?, 2004) uses lexicon with 300,000+ entries.
</prevsent>
</prevsection>
<citsent citstr=" W04-3229 ">
as result, most ofthe world languages and dialects have no realistic prospect for morphological taggers or analyzers created in this way.we have been developing method for creating morphological taggers and analyzers of fu sional languages1 without the need for large-scale knowledge- and labor-intensive resources (hana et al ., 2004; <papid> W04-3229 </papid>hana et al , 2006; <papid> W06-2005 </papid>feldman and hana, 2010) for the target language.</citsent>
<aftsection>
<nextsent>instead, we relyon (i) resources available for related language and (ii) limited amount of high-impact, low1fusional languages are languages in which several feature values are realized in one morpheme.
</nextsent>
<nextsent>for example indo european languages, including czech, german, romanian and farsi, are predominantly fusional.cost manually created resources.
</nextsent>
<nextsent>this greatly reduces cost, time requirements and the need for (language-specific) linguistic expertise.the focus of our paper is on the creation of resources for the system we developed.
</nextsent>
<nextsent>even though we have reduced the manual resource creation to the minimum, we have encountered number of problems, including training language annotators,documenting the reasoning behind the tagset design and morphological paradigms for specific language as well as creating support tools to facilitate and speed up the manual work.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2154">
<title id=" W10-1831.xml">challenges of cheap resource creation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>morphological analyzers usually relyon large manually created lexicons.
</prevsent>
<prevsent>for example, the czech analyzer (hajic?, 2004) uses lexicon with 300,000+ entries.
</prevsent>
</prevsection>
<citsent citstr=" W06-2005 ">
as result, most ofthe world languages and dialects have no realistic prospect for morphological taggers or analyzers created in this way.we have been developing method for creating morphological taggers and analyzers of fu sional languages1 without the need for large-scale knowledge- and labor-intensive resources (hana et al ., 2004; <papid> W04-3229 </papid>hana et al , 2006; <papid> W06-2005 </papid>feldman and hana, 2010) for the target language.</citsent>
<aftsection>
<nextsent>instead, we relyon (i) resources available for related language and (ii) limited amount of high-impact, low1fusional languages are languages in which several feature values are realized in one morpheme.
</nextsent>
<nextsent>for example indo european languages, including czech, german, romanian and farsi, are predominantly fusional.cost manually created resources.
</nextsent>
<nextsent>this greatly reduces cost, time requirements and the need for (language-specific) linguistic expertise.the focus of our paper is on the creation of resources for the system we developed.
</nextsent>
<nextsent>even though we have reduced the manual resource creation to the minimum, we have encountered number of problems, including training language annotators,documenting the reasoning behind the tagset design and morphological paradigms for specific language as well as creating support tools to facilitate and speed up the manual work.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2155">
<title id=" W10-1831.xml">challenges of cheap resource creation </title>
<section> resource-light morphology.  </section>
<citcontext>
<prevsection>
<prevsent>the details of our system are provided in (feld man and hana, 2010).
</prevsent>
<prevsent>our main assumption isthat model for the target language can be approximated by language models from one or more related source languages and that inclusion of limited amount of high-impact and/or low-cost manual resources is greatly beneficial and desirable.
</prevsent>
</prevsection>
<citsent citstr=" A00-1031 ">
we use tnt (brants, 2000), <papid> A00-1031 </papid>second order markov model tagger.</citsent>
<aftsection>
<nextsent>we approximate the target language emissions by combining the emissions from the (modified) source language corpus with information from the output of our resource-lightanalyzer (hana, 2008).
</nextsent>
<nextsent>the target-language transitions are approximated by the source language (feldman and hana, 2010).
</nextsent>
<nextsent>in this section we address the problem of collection, selection and creation of resources needed by our system.
</nextsent>
<nextsent>the following resources must be available: ? reference grammar book for information 197 about paradigms and closed class words,?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2156">
<title id=" W10-3306.xml">intrinsic property based taxonomic relation extraction from category structure </title>
<section> related works.  </section>
<citcontext>
<prevsection>
<prevsent>methods of taxonomic relation extraction can be divided into two broad categories depending onthe input: unstructured or structured data.
</prevsent>
<prevsent>the extraction of taxonomic relations from unstructured text is mainly carried out using lexical patterns on the text.
</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
the hearst pattern (hearst, 1992) <papid> C92-2082 </papid>is usedin many pattern-based approaches, such as cimiano (2005).in addition, there has been research that attempted to use existing structured data, like the wikipedia category structure or the contents of athesaurus.</citsent>
<aftsection>
<nextsent>the system of ponzetto (2007) determines whether or not the given wikipedia category link is an isa/instanceof relation by apply inga set of rules to the category names, while nastase (2008) defined lexical patterns on category names, in addition to ponzetto (2007).
</nextsent>
<nextsent>the yago system (suchanek et al, 2007) attempts to classify whether the given article-category link represents an instance of relation by checking the plurality of the upper category name.
</nextsent>
<nextsent>the algorithm proposed in this paper focuses on the structured data, mainly the category structure, to gather isa/instanceof relations.
</nextsent>
<nextsent>the system gets category structure as input, and classifies each category link inside the category structure according to whether it represents an isa/instanceof relation or not.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2157">
<title id=" W10-3306.xml">intrinsic property based taxonomic relation extraction from category structure </title>
<section> algorithm description.  </section>
<citcontext>
<prevsection>
<prevsent>constructing modifier graph modifier graph constructed here is defined as directed graph, in which each node represents each token inside u(b, n), and each edge represents co-occurrence as modifier-head relation inside each category name of u(b, n).
</prevsent>
<prevsent>using the subset of u(pioneer 11, 3), we get the modifier graph of figure 2.4 figure 2: modifier graph of the subset of u(pioneer 11, 3): {spacecraft escaping the solar system, jupiter spacecraft, 1973 in space exploration, nasa probes, saturn} calculating intrinsic score after constructing the modifier graph, we apply the hits algorithm to the modifier graph.
</prevsent>
</prevsection>
<citsent citstr=" I05-2004 ">
since the hits algorithm cannot reflect the weight of edges, modified version of the hits algorithm (mihalcea and tarau, 2005) <papid> I05-2004 </papid>is adopted: authority(vi) = ? vjin(vi) eji ? hub(vj) (1) hub(vi) = ? vjout(vi) eij ? authority(vj) (2) in(vi) represents the set of vertices which has the outgoing edge to vi, out(vi) represents the set of vertices which has the incoming edge from vi, and eij represents the weight of the edge from vi to vj . the algorithm for calculating the scores is as follows: 1.</citsent>
<aftsection>
<nextsent>initialize the authority and hub score of each.
</nextsent>
<nextsent>node to one.
</nextsent>
<nextsent>2.
</nextsent>
<nextsent>calculate hub score of each node using the.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2158">
<title id=" W10-3201.xml">a thesaurus of predicate argument structure for japanese verbs to deal with granularity of verb meanings </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the shared meaning of lend and give in the above sentences is that they are categorized to giving verbs, asin levins english verb classes and alternations (evca) (levin, 1993), while the different meaning will be that lend does not imply ownership of the theme, i.e., bicycle.
</prevsent>
<prevsent>one of the problematic issues with describing shared meaning among verbs is that semantic classes such as giving verbs should be dependent on the gran ularity of meanings we assumed.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
for example,the meaning of lend and give in the above sentences is not categorized into the same frame in framenet (baker et al, 1998).<papid> P98-1013 </papid></citsent>
<aftsection>
<nextsent>the reason for this different categorization can be considered to be that the granularity of the semantic class of giving verbs is larger than that of the giving frame in framenet1.
</nextsent>
<nextsent>from the view of natural language processing, especially dealing the with propositional meaning of verbs, all ofthe above classes, i.e., the wider class of giving verbs containing lend and give as well as the narrower class of giving frame containing give and donate, are needed.
</nextsent>
<nextsent>therefore, in this work, in order to describe verb meanings with several granularities of semantic classes, thesaurus form is adopted for our verb dictionary.
</nextsent>
<nextsent>based on the background, this paper presents thesaurus of predicate-argument structure for verbs on the basis of lexical decompositional framework such as lexical conceptual structure (jackendoff, 1990); thus our1we agree with the concept of frame and frame ele ments in framenet but what we propose in this paper is the necessity for granularities of frames and frameelements.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2159">
<title id=" W10-3214.xml">building nlp resources for dzongkha a tagset and a tagged corpus </title>
<section> the penn guidelines can be downloaded from:.  </section>
<citcontext>
<prevsection>
<prevsent>http://www.cis.upenn.edu/~treebank/ the penn treebank tags as basis for tagging.
</prevsent>
<prevsent>examining the similar features exhibited by both the languages (dzongkha and english), tags that were applicable to dzongkha were taken directly from the penn treebank.
</prevsent>
</prevsection>
<citsent citstr=" E09-1079 ">
in cases where these languages showed dissimilarities in their nature, new tags for dzongkha were assigned (based e.g. on the work on urdu of sajjad and schmid, 2009).<papid> E09-1079 </papid></citsent>
<aftsection>
<nextsent>as an example for such dissimilarity, dzongkha post positions are mentioned here, cf.
</nextsent>
<nextsent>(1); the respective tag (pp) only exist for dzongkha whereas in english the whole set of ad position tags (preposition and postpositions) exist.
</nextsent>
<nextsent>(1) ??????
</nextsent>
<nextsent>j ili shing-gi wlu -d?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2160">
<title id=" W10-3214.xml">building nlp resources for dzongkha a tagset and a tagged corpus </title>
<section> the penn guidelines can be downloaded from:.  </section>
<citcontext>
<prevsection>
<prevsent>these differentiate between dative (cdt) and ablative (ca): the cdt (dative case) labels e.g.???????/doen le/(for it) and ??????/doen lu/(for this).
</prevsent>
<prevsent>the ablative case 105 (ca) is used when the argument of the preposition describes source.
</prevsent>
</prevsection>
<citsent citstr=" W09-3404 ">
for example, in the phrase ?????????????/shing le kang thri/(from wood chair), ???/le/from/ will be labeled ca since the chair described is made from (the source) wood (muaz, et al. 2009).<papid> W09-3404 </papid></citsent>
<aftsection>
<nextsent>the tagset utilized in our experiment consists of total of 66 parts of speech as shown in appendix (a).
</nextsent>
<nextsent>4.2 collecting corpus and generating a. training dataset the corpus collection process.
</nextsent>
<nextsent>the process of collecting corpus should be based on its purpose.
</nextsent>
<nextsent>as our goal was the design dzongkha text corpus as balanced as possible in terms of its linguistic diversity, the text data was gathered from different sources like newspaper articles, samples from traditional books, and dictionaries, some text was added manually (poetry and songs).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2161">
<title id=" W10-3214.xml">building nlp resources for dzongkha a tagset and a tagged corpus </title>
<section> the penn guidelines can be downloaded from:.  </section>
<citcontext>
<prevsection>
<prevsent>parameter file: the file that was generated by step a) above.
</prevsent>
<prevsent>text file: file that is to be tagged; it is mandatory that the data in this file appears in one-token-per line format.
</prevsent>
</prevsection>
<citsent citstr=" A00-1031 ">
tnt (brants, 2000):<papid> A00-1031 </papid>the trigramsntags (tnt) tagger was developed by thorsten brants (brants, 2000).<papid> A00-1031 </papid></citsent>
<aftsection>
<nextsent>it is language independent and has been used widely for number of languages, often yielding an accuracy of +96% without utilizing an external lexicon or an open word class file.
</nextsent>
<nextsent>tnt is based on markov models, and takes not only distributional data of tokens, but also the final sequences of characters of token into account when guessing the pos of word.
</nextsent>
<nextsent>it can use the same format for training data as the tree tagger, therefore, in order to use tnt for comparison reasons, no additional preparations for tagging dzongkha are necessary.
</nextsent>
<nextsent>5 validation and results.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2164">
<title id=" W10-3812.xml">a discriminative syntactic model for source permutation via tree transduction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>finally, the translation performance of our learning model is shown to outperform thestate-of-the-art phrase-based system significantly.
</prevsent>
<prevsent>from its beginnings, statistical machine translation (smt) has faced word reordering challenge that has major impact on translation quality.while standard mechanisms embedded in phrase based smt systems, e.g.
</prevsent>
</prevsection>
<citsent citstr=" J04-4002 ">
(och and ney, 2004),<papid> J04-4002 </papid>deal efficiently with word reordering within limited window of words, they are still not expected to handle all possible reorderings that involve words beyond this relatively narrow window, e.g., (tillmann and ney, 2003; <papid> J03-1005 </papid>zens and ney, 2003; <papid> P03-1019 </papid>tillman, 2004).</citsent>
<aftsection>
<nextsent>more recent work handles word order differences between source and target languages using hierarchical methods that draw on inversion transduction grammar (itg), e.g., (wu and wong, 1998; <papid> P98-2230 </papid>chiang, 2005).<papid> P05-1033 </papid></nextsent>
<nextsent>in principle, the latter approach explores reordering defined bythe choice of swapping the order of sibling subtrees under each node in binary parse-tree of the source/target sentence.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2165">
<title id=" W10-3812.xml">a discriminative syntactic model for source permutation via tree transduction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>finally, the translation performance of our learning model is shown to outperform thestate-of-the-art phrase-based system significantly.
</prevsent>
<prevsent>from its beginnings, statistical machine translation (smt) has faced word reordering challenge that has major impact on translation quality.while standard mechanisms embedded in phrase based smt systems, e.g.
</prevsent>
</prevsection>
<citsent citstr=" J03-1005 ">
(och and ney, 2004),<papid> J04-4002 </papid>deal efficiently with word reordering within limited window of words, they are still not expected to handle all possible reorderings that involve words beyond this relatively narrow window, e.g., (tillmann and ney, 2003; <papid> J03-1005 </papid>zens and ney, 2003; <papid> P03-1019 </papid>tillman, 2004).</citsent>
<aftsection>
<nextsent>more recent work handles word order differences between source and target languages using hierarchical methods that draw on inversion transduction grammar (itg), e.g., (wu and wong, 1998; <papid> P98-2230 </papid>chiang, 2005).<papid> P05-1033 </papid></nextsent>
<nextsent>in principle, the latter approach explores reordering defined bythe choice of swapping the order of sibling subtrees under each node in binary parse-tree of the source/target sentence.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2166">
<title id=" W10-3812.xml">a discriminative syntactic model for source permutation via tree transduction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>finally, the translation performance of our learning model is shown to outperform thestate-of-the-art phrase-based system significantly.
</prevsent>
<prevsent>from its beginnings, statistical machine translation (smt) has faced word reordering challenge that has major impact on translation quality.while standard mechanisms embedded in phrase based smt systems, e.g.
</prevsent>
</prevsection>
<citsent citstr=" P03-1019 ">
(och and ney, 2004),<papid> J04-4002 </papid>deal efficiently with word reordering within limited window of words, they are still not expected to handle all possible reorderings that involve words beyond this relatively narrow window, e.g., (tillmann and ney, 2003; <papid> J03-1005 </papid>zens and ney, 2003; <papid> P03-1019 </papid>tillman, 2004).</citsent>
<aftsection>
<nextsent>more recent work handles word order differences between source and target languages using hierarchical methods that draw on inversion transduction grammar (itg), e.g., (wu and wong, 1998; <papid> P98-2230 </papid>chiang, 2005).<papid> P05-1033 </papid></nextsent>
<nextsent>in principle, the latter approach explores reordering defined bythe choice of swapping the order of sibling subtrees under each node in binary parse-tree of the source/target sentence.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2167">
<title id=" W10-3812.xml">a discriminative syntactic model for source permutation via tree transduction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>from its beginnings, statistical machine translation (smt) has faced word reordering challenge that has major impact on translation quality.while standard mechanisms embedded in phrase based smt systems, e.g.
</prevsent>
<prevsent>(och and ney, 2004),<papid> J04-4002 </papid>deal efficiently with word reordering within limited window of words, they are still not expected to handle all possible reorderings that involve words beyond this relatively narrow window, e.g., (tillmann and ney, 2003; <papid> J03-1005 </papid>zens and ney, 2003; <papid> P03-1019 </papid>tillman, 2004).</prevsent>
</prevsection>
<citsent citstr=" P98-2230 ">
more recent work handles word order differences between source and target languages using hierarchical methods that draw on inversion transduction grammar (itg), e.g., (wu and wong, 1998; <papid> P98-2230 </papid>chiang, 2005).<papid> P05-1033 </papid></citsent>
<aftsection>
<nextsent>in principle, the latter approach explores reordering defined bythe choice of swapping the order of sibling subtrees under each node in binary parse-tree of the source/target sentence.
</nextsent>
<nextsent>an alternative approach aims at minimizing theneed for reordering during translation by permut ing the source sentence as pre-translation step, e.g., (collins et al, 2005; <papid> P05-1066 </papid>xia and mccord, 2004; <papid> C04-1073 </papid>wang et al, 2007; <papid> D07-1077 </papid>khalilov, 2009).</nextsent>
<nextsent>in effect, the translation process works with model for source permutation (s ? s?) followed by translation model (s? ? t), where and are source and target strings and s?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2168">
<title id=" W10-3812.xml">a discriminative syntactic model for source permutation via tree transduction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>from its beginnings, statistical machine translation (smt) has faced word reordering challenge that has major impact on translation quality.while standard mechanisms embedded in phrase based smt systems, e.g.
</prevsent>
<prevsent>(och and ney, 2004),<papid> J04-4002 </papid>deal efficiently with word reordering within limited window of words, they are still not expected to handle all possible reorderings that involve words beyond this relatively narrow window, e.g., (tillmann and ney, 2003; <papid> J03-1005 </papid>zens and ney, 2003; <papid> P03-1019 </papid>tillman, 2004).</prevsent>
</prevsection>
<citsent citstr=" P05-1033 ">
more recent work handles word order differences between source and target languages using hierarchical methods that draw on inversion transduction grammar (itg), e.g., (wu and wong, 1998; <papid> P98-2230 </papid>chiang, 2005).<papid> P05-1033 </papid></citsent>
<aftsection>
<nextsent>in principle, the latter approach explores reordering defined bythe choice of swapping the order of sibling subtrees under each node in binary parse-tree of the source/target sentence.
</nextsent>
<nextsent>an alternative approach aims at minimizing theneed for reordering during translation by permut ing the source sentence as pre-translation step, e.g., (collins et al, 2005; <papid> P05-1066 </papid>xia and mccord, 2004; <papid> C04-1073 </papid>wang et al, 2007; <papid> D07-1077 </papid>khalilov, 2009).</nextsent>
<nextsent>in effect, the translation process works with model for source permutation (s ? s?) followed by translation model (s? ? t), where and are source and target strings and s?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2169">
<title id=" W10-3812.xml">a discriminative syntactic model for source permutation via tree transduction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>more recent work handles word order differences between source and target languages using hierarchical methods that draw on inversion transduction grammar (itg), e.g., (wu and wong, 1998; <papid> P98-2230 </papid>chiang, 2005).<papid> P05-1033 </papid></prevsent>
<prevsent>in principle, the latter approach explores reordering defined bythe choice of swapping the order of sibling subtrees under each node in binary parse-tree of the source/target sentence.</prevsent>
</prevsection>
<citsent citstr=" P05-1066 ">
an alternative approach aims at minimizing theneed for reordering during translation by permut ing the source sentence as pre-translation step, e.g., (collins et al, 2005; <papid> P05-1066 </papid>xia and mccord, 2004; <papid> C04-1073 </papid>wang et al, 2007; <papid> D07-1077 </papid>khalilov, 2009).</citsent>
<aftsection>
<nextsent>in effect, the translation process works with model for source permutation (s ? s?) followed by translation model (s? ? t), where and are source and target strings and s?
</nextsent>
<nextsent>is the target-like permuted source string.
</nextsent>
<nextsent>in how far can source permutation reduce the need for reordering in conjunction with translation is an empirical question.
</nextsent>
<nextsent>in this paper we define source permutation as the problem of learning how to transfer given source parse-tree into parse-tree that minimizes the divergence from target word-order.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2170">
<title id=" W10-3812.xml">a discriminative syntactic model for source permutation via tree transduction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>more recent work handles word order differences between source and target languages using hierarchical methods that draw on inversion transduction grammar (itg), e.g., (wu and wong, 1998; <papid> P98-2230 </papid>chiang, 2005).<papid> P05-1033 </papid></prevsent>
<prevsent>in principle, the latter approach explores reordering defined bythe choice of swapping the order of sibling subtrees under each node in binary parse-tree of the source/target sentence.</prevsent>
</prevsection>
<citsent citstr=" C04-1073 ">
an alternative approach aims at minimizing theneed for reordering during translation by permut ing the source sentence as pre-translation step, e.g., (collins et al, 2005; <papid> P05-1066 </papid>xia and mccord, 2004; <papid> C04-1073 </papid>wang et al, 2007; <papid> D07-1077 </papid>khalilov, 2009).</citsent>
<aftsection>
<nextsent>in effect, the translation process works with model for source permutation (s ? s?) followed by translation model (s? ? t), where and are source and target strings and s?
</nextsent>
<nextsent>is the target-like permuted source string.
</nextsent>
<nextsent>in how far can source permutation reduce the need for reordering in conjunction with translation is an empirical question.
</nextsent>
<nextsent>in this paper we define source permutation as the problem of learning how to transfer given source parse-tree into parse-tree that minimizes the divergence from target word-order.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2171">
<title id=" W10-3812.xml">a discriminative syntactic model for source permutation via tree transduction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>more recent work handles word order differences between source and target languages using hierarchical methods that draw on inversion transduction grammar (itg), e.g., (wu and wong, 1998; <papid> P98-2230 </papid>chiang, 2005).<papid> P05-1033 </papid></prevsent>
<prevsent>in principle, the latter approach explores reordering defined bythe choice of swapping the order of sibling subtrees under each node in binary parse-tree of the source/target sentence.</prevsent>
</prevsection>
<citsent citstr=" D07-1077 ">
an alternative approach aims at minimizing theneed for reordering during translation by permut ing the source sentence as pre-translation step, e.g., (collins et al, 2005; <papid> P05-1066 </papid>xia and mccord, 2004; <papid> C04-1073 </papid>wang et al, 2007; <papid> D07-1077 </papid>khalilov, 2009).</citsent>
<aftsection>
<nextsent>in effect, the translation process works with model for source permutation (s ? s?) followed by translation model (s? ? t), where and are source and target strings and s?
</nextsent>
<nextsent>is the target-like permuted source string.
</nextsent>
<nextsent>in how far can source permutation reduce the need for reordering in conjunction with translation is an empirical question.
</nextsent>
<nextsent>in this paper we define source permutation as the problem of learning how to transfer given source parse-tree into parse-tree that minimizes the divergence from target word-order.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2172">
<title id=" W10-3812.xml">a discriminative syntactic model for source permutation via tree transduction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper we define source permutation as the problem of learning how to transfer given source parse-tree into parse-tree that minimizes the divergence from target word-order.
</prevsent>
<prevsent>we mode lthe tree transfer ? s? as sequence of local,independent transduction operations, each transforming the current intermediate tree si into thenext intermediate tree si+1 , with s0 = and sn = s? . transduction operation merely per-mutes the sequence of   1 children of single node in an intermediate tree, i.e., unlike previous work, we do not binarize the trees.
</prevsent>
</prevsection>
<citsent citstr=" D09-1105 ">
the number of permutations is facto rial in n, and learning sequence of transductions for explaining source permutation can be computationally rather challenging (see (tromble and eisner, 2009)).<papid> D09-1105 </papid></citsent>
<aftsection>
<nextsent>yet, 92from the limited perspective of source string permutation (s ? s?), another challenge is to integrate figure of merit that measures in how far s?
</nextsent>
<nextsent>resembles plausible target word-order.
</nextsent>
<nextsent>we contribute solutions to these challenging problems.
</nextsent>
<nextsent>firstly, we learn the transduction operations using discriminative estimate ofp (pi(x) |nx, x, contextx), where nx is the label of node (address) x, nx ? is the context free production under x, pi(x) is permutation ofx and contextx represents surrounding syntactic context.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2174">
<title id=" W10-3812.xml">a discriminative syntactic model for source permutation via tree transduction </title>
<section> baseline: phrase-based smt.  </section>
<citcontext>
<prevsection>
<prevsent>our analysis shows that syntactic structure can provide important clues for reordering in translation, especially for dealing with long distance cases found in, e.g., english and dutch.
</prevsent>
<prevsent>yet, tree transduction by merely per muting the order of sister subtrees might turn out insufficient.
</prevsent>
</prevsection>
<citsent citstr=" P02-1038 ">
given word-aligned parallel corpus, phrase based systems (och and ney, 2002; <papid> P02-1038 </papid>koehn et al, 2003) <papid> N03-1017 </papid>work with (in principle) arbitrarily large phrase pairs (also called blocks) acquired fromword-aligned parallel data under simple definition of translational equivalence (zens et al, 2002).</citsent>
<aftsection>
<nextsent>the conditional probabilities of one phrase given its counterpart are interpolated log-linearly together with set of other model estimates: ei1 = argmaxei1 { m?
</nextsent>
<nextsent>m=1 mhm(ei1, fj1 ) } (1) where feature function hm refer to system model, and the corresponding refers to the relative weight given to this model.
</nextsent>
<nextsent>a phrase-based system employs feature functions for phrase pair translation model, language model, reordering model, and model to score translation hypothesis according to length.
</nextsent>
<nextsent>the weights are usually optimized for system performance (och, 2003) <papid> P03-1021 </papid>as measured by bleu (papineni et al, 2002).<papid> P02-1040 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2175">
<title id=" W10-3812.xml">a discriminative syntactic model for source permutation via tree transduction </title>
<section> baseline: phrase-based smt.  </section>
<citcontext>
<prevsection>
<prevsent>our analysis shows that syntactic structure can provide important clues for reordering in translation, especially for dealing with long distance cases found in, e.g., english and dutch.
</prevsent>
<prevsent>yet, tree transduction by merely per muting the order of sister subtrees might turn out insufficient.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
given word-aligned parallel corpus, phrase based systems (och and ney, 2002; <papid> P02-1038 </papid>koehn et al, 2003) <papid> N03-1017 </papid>work with (in principle) arbitrarily large phrase pairs (also called blocks) acquired fromword-aligned parallel data under simple definition of translational equivalence (zens et al, 2002).</citsent>
<aftsection>
<nextsent>the conditional probabilities of one phrase given its counterpart are interpolated log-linearly together with set of other model estimates: ei1 = argmaxei1 { m?
</nextsent>
<nextsent>m=1 mhm(ei1, fj1 ) } (1) where feature function hm refer to system model, and the corresponding refers to the relative weight given to this model.
</nextsent>
<nextsent>a phrase-based system employs feature functions for phrase pair translation model, language model, reordering model, and model to score translation hypothesis according to length.
</nextsent>
<nextsent>the weights are usually optimized for system performance (och, 2003) <papid> P03-1021 </papid>as measured by bleu (papineni et al, 2002).<papid> P02-1040 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2176">
<title id=" W10-3812.xml">a discriminative syntactic model for source permutation via tree transduction </title>
<section> baseline: phrase-based smt.  </section>
<citcontext>
<prevsection>
<prevsent>m=1 mhm(ei1, fj1 ) } (1) where feature function hm refer to system model, and the corresponding refers to the relative weight given to this model.
</prevsent>
<prevsent>a phrase-based system employs feature functions for phrase pair translation model, language model, reordering model, and model to score translation hypothesis according to length.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
the weights are usually optimized for system performance (och, 2003) <papid> P03-1021 </papid>as measured by bleu (papineni et al, 2002).<papid> P02-1040 </papid></citsent>
<aftsection>
<nextsent>two reordering methods are widely used in phrase based systems.distance-based simple distance-based reordering model default for moses system is the first reordering technique under consideration.this model provides the decoder with cost linear to the distance between words that should be reordered.
</nextsent>
<nextsent>msd lexicalized block-oriented data-driven reordering model (tillman, 2004) considers three different orientations: monotone (m), swap (s),and discontinuous (d).
</nextsent>
<nextsent>the reordering probabilities are conditioned on the lexical context of each phrase pair, and decoding works with block sequence generation process with the possibility of swapping pair of blocks.
</nextsent>
<nextsent>the integration of linguistic syntax into smt systems offers potential solution to reordering problem.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2177">
<title id=" W10-3812.xml">a discriminative syntactic model for source permutation via tree transduction </title>
<section> baseline: phrase-based smt.  </section>
<citcontext>
<prevsection>
<prevsent>m=1 mhm(ei1, fj1 ) } (1) where feature function hm refer to system model, and the corresponding refers to the relative weight given to this model.
</prevsent>
<prevsent>a phrase-based system employs feature functions for phrase pair translation model, language model, reordering model, and model to score translation hypothesis according to length.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
the weights are usually optimized for system performance (och, 2003) <papid> P03-1021 </papid>as measured by bleu (papineni et al, 2002).<papid> P02-1040 </papid></citsent>
<aftsection>
<nextsent>two reordering methods are widely used in phrase based systems.distance-based simple distance-based reordering model default for moses system is the first reordering technique under consideration.this model provides the decoder with cost linear to the distance between words that should be reordered.
</nextsent>
<nextsent>msd lexicalized block-oriented data-driven reordering model (tillman, 2004) considers three different orientations: monotone (m), swap (s),and discontinuous (d).
</nextsent>
<nextsent>the reordering probabilities are conditioned on the lexical context of each phrase pair, and decoding works with block sequence generation process with the possibility of swapping pair of blocks.
</nextsent>
<nextsent>the integration of linguistic syntax into smt systems offers potential solution to reordering problem.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2178">
<title id=" W10-3812.xml">a discriminative syntactic model for source permutation via tree transduction </title>
<section> related work on source permutation.  </section>
<citcontext>
<prevsection>
<prevsent>the integration of linguistic syntax into smt systems offers potential solution to reordering problem.
</prevsent>
<prevsent>for example, syntax is successfully integrated into hierarchical smt (zollmann and 93 venugopal, 2006).
</prevsent>
</prevsection>
<citsent citstr=" P06-1121 ">
similarly, the tree-to-stringsyntax-based transduction approach offers complete translation framework (galley et al, 2006).<papid> P06-1121 </papid></citsent>
<aftsection>
<nextsent>the idea of augmenting smt by reordering step prior to translation has often been shown to improve translation quality.
</nextsent>
<nextsent>clause restructuring performed with hand-crafted reordering rules for german-to-english and chinese-to-english tasks are presented in (collins et al, 2005) <papid> P05-1066 </papid>and (wang et al, 2007), <papid> D07-1077 </papid>respectively.</nextsent>
<nextsent>in (xia and mccord,2004; <papid> C04-1073 </papid>khalilov, 2009) word reordering is addressed by exploiting syntactic representations of source and target texts.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2183">
<title id=" W10-3812.xml">a discriminative syntactic model for source permutation via tree transduction </title>
<section> related work on source permutation.  </section>
<citcontext>
<prevsection>
<prevsent>in (xia and mccord,2004; <papid> C04-1073 </papid>khalilov, 2009) word reordering is addressed by exploiting syntactic representations of source and target texts.</prevsent>
<prevsent>other reordering models operate provide the decoder with multiple word orders.</prevsent>
</prevsection>
<citsent citstr=" P06-1066 ">
forex ample, the maxent reordering model described in (xiong et al, 2006) <papid> P06-1066 </papid>provides hierarchical phrasal reordering system integrated within cky-style decoder.</citsent>
<aftsection>
<nextsent>in (galley and manning,2008) <papid> D08-1089 </papid>the authors present an extension of the famous msd model (tillman, 2004) able to handle long-distance word-block permutations.</nextsent>
<nextsent>coming up-to-date, in (pvs, 2010) an effective application of data mining techniques to syntax-driven source reordering for mt is presented.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2184">
<title id=" W10-3812.xml">a discriminative syntactic model for source permutation via tree transduction </title>
<section> related work on source permutation.  </section>
<citcontext>
<prevsection>
<prevsent>other reordering models operate provide the decoder with multiple word orders.
</prevsent>
<prevsent>forex ample, the maxent reordering model described in (xiong et al, 2006) <papid> P06-1066 </papid>provides hierarchical phrasal reordering system integrated within cky-style decoder.</prevsent>
</prevsection>
<citsent citstr=" D08-1089 ">
in (galley and manning,2008) <papid> D08-1089 </papid>the authors present an extension of the famous msd model (tillman, 2004) able to handle long-distance word-block permutations.</citsent>
<aftsection>
<nextsent>coming up-to-date, in (pvs, 2010) an effective application of data mining techniques to syntax-driven source reordering for mt is presented.
</nextsent>
<nextsent>recently, tromble and eisner (2009) <papid> D09-1105 </papid>define source permutation as learning source permuta tions; the model works with preference matrix for word pairs, expressing preference for their two alternative orders, and corresponding weight matrix that is fit to the parallel data.</nextsent>
<nextsent>the huge space of permutations is then structured using binary synchronous context-free grammar (binaryitg) with o(n3) parsing complexity, and the permutation score is calculated recursively over the tree at every node as the accumulation of the relative differences between the word-pair scores taken from the preference matrix.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2192">
<title id=" W10-3812.xml">a discriminative syntactic model for source permutation via tree transduction </title>
<section> experiments and results.  </section>
<citcontext>
<prevsection>
<prevsent>standard training and weight tuning procedures which were used to build our system are explained in details on the moses web page1.
</prevsent>
<prevsent>the msd model was used together with distance-based reordering model.
</prevsent>
</prevsection>
<citsent citstr=" E99-1010 ">
word alignment was estimated withgiza++ tool2 (och, 2003), <papid> P03-1021 </papid>coupled with mk cls3 (och, 1999), <papid> E99-1010 </papid>which allows for statistical word clustering for better generalization.</citsent>
<aftsection>
<nextsent>an 5-gram target language model was estimated using the sri lm toolkit (stolcke, 2002) and smoothed with modified kneser-ney discounting.
</nextsent>
<nextsent>we use the stanford parser4 (klein and manning, 2003) <papid> P03-1054 </papid>as source-side parsing engine.</nextsent>
<nextsent>the parser was trained on the english treebank set provided with 14 syntactic categories and 48 pos tags.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2193">
<title id=" W10-3812.xml">a discriminative syntactic model for source permutation via tree transduction </title>
<section> experiments and results.  </section>
<citcontext>
<prevsection>
<prevsent>word alignment was estimated withgiza++ tool2 (och, 2003), <papid> P03-1021 </papid>coupled with mk cls3 (och, 1999), <papid> E99-1010 </papid>which allows for statistical word clustering for better generalization.</prevsent>
<prevsent>an 5-gram target language model was estimated using the sri lm toolkit (stolcke, 2002) and smoothed with modified kneser-ney discounting.</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
we use the stanford parser4 (klein and manning, 2003) <papid> P03-1054 </papid>as source-side parsing engine.</citsent>
<aftsection>
<nextsent>the parser was trained on the english treebank set provided with 14 syntactic categories and 48 pos tags.
</nextsent>
<nextsent>the evaluation conditions were case-sensitive and included punctuation marks.
</nextsent>
<nextsent>for maximum entropy modeling we used the maxent toolkit5.data the experiment results were obtained using the english-dutch corpus of the european parliament plenary session transcription (europarl).
</nextsent>
<nextsent>training corpus statistics can be found in table 2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2194">
<title id=" W10-3812.xml">a discriminative syntactic model for source permutation via tree transduction </title>
<section> conclusions and future work.  </section>
<citcontext>
<prevsection>
<prevsent>example figure 4 exemplifies the sentences that presumably benefits from the monotonizationof the source part of the parallel corpus.
</prevsent>
<prevsent>the example demonstrates pervading syntactic distinction between english and dutch: the reordering of verb-phrase sub constituents vp np pp within the relative clause into pp np vp.
</prevsent>
</prevsection>
<citsent citstr=" W04-3250 ">
we introduced tree-based reordering model that aims at monotonizing the word order of source 8all statistical significance calculations are done for 95% confidence interval and 1 000 re samples, following the guidelines from (koehn, 2004).<papid> W04-3250 </papid></citsent>
<aftsection>
<nextsent>and target languages as pre-translation step.
</nextsent>
<nextsent>our model avoids complete generalization of reordering instances by using tree contexts and limiting the permutations to data instances.
</nextsent>
<nextsent>from alearning perspective, our work shows that navigating large space of intermediate tree transformations can be conducted effectively using both the source-side syntactic tree and language modelof the idealized (target-like) source-permuted language.
</nextsent>
<nextsent>we have shown the potential for translation quality improvement when target sentences are created following the source language word order (3 bleu points over the standard phrase based smt) and under parse tree constraint (0.9bleu points).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2195">
<title id=" W10-2401.xml">report of news 2010 transliteration generation shared task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we believe that the shared task has successfully achieved its objective by providing common benchmarking platform for the research community to evaluate the state-of-the-art technologies that benefit the future research and development.
</prevsent>
<prevsent>names play significant role in many natural language processing (nlp) and information retrieval (ir) systems.
</prevsent>
</prevsection>
<citsent citstr=" P08-1045 ">
they are important in cross lingual information retrieval (clir) and machine translation (mt) as the system performance has been shown to positively correlate with the correct conversion of names between the languages in several studies (demner-fushman and oard, 2002; mandl and womser-hacker, 2005; hermjakob et al, 2008; <papid> P08-1045 </papid>udupa et al, 2009).</citsent>
<aftsection>
<nextsent>the traditional source for name equivalence, the bilingual dictionaries ? whether handcrafted or statistical ? offer only limited support because new names always emerge.all of the above point to the critical need for robust machine transliteration technology and systems.
</nextsent>
<nextsent>much research effort has been made to address the transliteration issue in the research community (knight and graehl, 1998; <papid> J98-4003 </papid>meng et al, 2001; li et al, 2004; <papid> P04-1021 </papid>zelenko and aone, 2006; <papid> W06-1672 </papid>sproat et al, 2006; <papid> P06-1010 </papid>sherif and kondrak, 2007; <papid> P07-1119 </papid>hermjakob et al, 2008; <papid> P08-1045 </papid>al-onaizan and knight, 2002; goldwasser and roth, 2008; <papid> D08-1037 </papid>goldberg and elhadad, 2008; klementiev and roth, 2006; <papid> P06-1103 </papid>oh and choi, 2002; <papid> C02-1099 </papid>virga and khudanpur, 2003; <papid> W03-1508 </papid>wan and verspoor, 1998; kang and choi, 2000; gao et al, 2004; zelenko and aone, 2006; <papid> W06-1672 </papid>li et al, 2009<papid> W09-3501 </papid>b; li et al, 2009<papid> W09-3501 </papid>a).</nextsent>
<nextsent>these previous work fall into three categories, i.e., grapheme-based,phoneme-based and hybrid methods.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2197">
<title id=" W10-2401.xml">report of news 2010 transliteration generation shared task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they are important in cross lingual information retrieval (clir) and machine translation (mt) as the system performance has been shown to positively correlate with the correct conversion of names between the languages in several studies (demner-fushman and oard, 2002; mandl and womser-hacker, 2005; hermjakob et al, 2008; <papid> P08-1045 </papid>udupa et al, 2009).</prevsent>
<prevsent>the traditional source for name equivalence, the bilingual dictionaries ? whether handcrafted or statistical ? offer only limited support because new names always emerge.all of the above point to the critical need for robust machine transliteration technology and systems.</prevsent>
</prevsection>
<citsent citstr=" J98-4003 ">
much research effort has been made to address the transliteration issue in the research community (knight and graehl, 1998; <papid> J98-4003 </papid>meng et al, 2001; li et al, 2004; <papid> P04-1021 </papid>zelenko and aone, 2006; <papid> W06-1672 </papid>sproat et al, 2006; <papid> P06-1010 </papid>sherif and kondrak, 2007; <papid> P07-1119 </papid>hermjakob et al, 2008; <papid> P08-1045 </papid>al-onaizan and knight, 2002; goldwasser and roth, 2008; <papid> D08-1037 </papid>goldberg and elhadad, 2008; klementiev and roth, 2006; <papid> P06-1103 </papid>oh and choi, 2002; <papid> C02-1099 </papid>virga and khudanpur, 2003; <papid> W03-1508 </papid>wan and verspoor, 1998; kang and choi, 2000; gao et al, 2004; zelenko and aone, 2006; <papid> W06-1672 </papid>li et al, 2009<papid> W09-3501 </papid>b; li et al, 2009<papid> W09-3501 </papid>a).</citsent>
<aftsection>
<nextsent>these previous work fall into three categories, i.e., grapheme-based,phoneme-based and hybrid methods.
</nextsent>
<nextsent>graphemebased method (li et al, 2004) <papid> P04-1021 </papid>treats transliteration as direct orthographic mapping and only uses orthography-related features while phoneme based method (knight and graehl, 1998) <papid> J98-4003 </papid>makes use of phonetic correspondence to generate thetransliteration.</nextsent>
<nextsent>hybrid method refers to the combination of several different models or knowledge sources to support the transliteration generation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2198">
<title id=" W10-2401.xml">report of news 2010 transliteration generation shared task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they are important in cross lingual information retrieval (clir) and machine translation (mt) as the system performance has been shown to positively correlate with the correct conversion of names between the languages in several studies (demner-fushman and oard, 2002; mandl and womser-hacker, 2005; hermjakob et al, 2008; <papid> P08-1045 </papid>udupa et al, 2009).</prevsent>
<prevsent>the traditional source for name equivalence, the bilingual dictionaries ? whether handcrafted or statistical ? offer only limited support because new names always emerge.all of the above point to the critical need for robust machine transliteration technology and systems.</prevsent>
</prevsection>
<citsent citstr=" P04-1021 ">
much research effort has been made to address the transliteration issue in the research community (knight and graehl, 1998; <papid> J98-4003 </papid>meng et al, 2001; li et al, 2004; <papid> P04-1021 </papid>zelenko and aone, 2006; <papid> W06-1672 </papid>sproat et al, 2006; <papid> P06-1010 </papid>sherif and kondrak, 2007; <papid> P07-1119 </papid>hermjakob et al, 2008; <papid> P08-1045 </papid>al-onaizan and knight, 2002; goldwasser and roth, 2008; <papid> D08-1037 </papid>goldberg and elhadad, 2008; klementiev and roth, 2006; <papid> P06-1103 </papid>oh and choi, 2002; <papid> C02-1099 </papid>virga and khudanpur, 2003; <papid> W03-1508 </papid>wan and verspoor, 1998; kang and choi, 2000; gao et al, 2004; zelenko and aone, 2006; <papid> W06-1672 </papid>li et al, 2009<papid> W09-3501 </papid>b; li et al, 2009<papid> W09-3501 </papid>a).</citsent>
<aftsection>
<nextsent>these previous work fall into three categories, i.e., grapheme-based,phoneme-based and hybrid methods.
</nextsent>
<nextsent>graphemebased method (li et al, 2004) <papid> P04-1021 </papid>treats transliteration as direct orthographic mapping and only uses orthography-related features while phoneme based method (knight and graehl, 1998) <papid> J98-4003 </papid>makes use of phonetic correspondence to generate thetransliteration.</nextsent>
<nextsent>hybrid method refers to the combination of several different models or knowledge sources to support the transliteration generation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2200">
<title id=" W10-2401.xml">report of news 2010 transliteration generation shared task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they are important in cross lingual information retrieval (clir) and machine translation (mt) as the system performance has been shown to positively correlate with the correct conversion of names between the languages in several studies (demner-fushman and oard, 2002; mandl and womser-hacker, 2005; hermjakob et al, 2008; <papid> P08-1045 </papid>udupa et al, 2009).</prevsent>
<prevsent>the traditional source for name equivalence, the bilingual dictionaries ? whether handcrafted or statistical ? offer only limited support because new names always emerge.all of the above point to the critical need for robust machine transliteration technology and systems.</prevsent>
</prevsection>
<citsent citstr=" W06-1672 ">
much research effort has been made to address the transliteration issue in the research community (knight and graehl, 1998; <papid> J98-4003 </papid>meng et al, 2001; li et al, 2004; <papid> P04-1021 </papid>zelenko and aone, 2006; <papid> W06-1672 </papid>sproat et al, 2006; <papid> P06-1010 </papid>sherif and kondrak, 2007; <papid> P07-1119 </papid>hermjakob et al, 2008; <papid> P08-1045 </papid>al-onaizan and knight, 2002; goldwasser and roth, 2008; <papid> D08-1037 </papid>goldberg and elhadad, 2008; klementiev and roth, 2006; <papid> P06-1103 </papid>oh and choi, 2002; <papid> C02-1099 </papid>virga and khudanpur, 2003; <papid> W03-1508 </papid>wan and verspoor, 1998; kang and choi, 2000; gao et al, 2004; zelenko and aone, 2006; <papid> W06-1672 </papid>li et al, 2009<papid> W09-3501 </papid>b; li et al, 2009<papid> W09-3501 </papid>a).</citsent>
<aftsection>
<nextsent>these previous work fall into three categories, i.e., grapheme-based,phoneme-based and hybrid methods.
</nextsent>
<nextsent>graphemebased method (li et al, 2004) <papid> P04-1021 </papid>treats transliteration as direct orthographic mapping and only uses orthography-related features while phoneme based method (knight and graehl, 1998) <papid> J98-4003 </papid>makes use of phonetic correspondence to generate thetransliteration.</nextsent>
<nextsent>hybrid method refers to the combination of several different models or knowledge sources to support the transliteration generation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2202">
<title id=" W10-2401.xml">report of news 2010 transliteration generation shared task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they are important in cross lingual information retrieval (clir) and machine translation (mt) as the system performance has been shown to positively correlate with the correct conversion of names between the languages in several studies (demner-fushman and oard, 2002; mandl and womser-hacker, 2005; hermjakob et al, 2008; <papid> P08-1045 </papid>udupa et al, 2009).</prevsent>
<prevsent>the traditional source for name equivalence, the bilingual dictionaries ? whether handcrafted or statistical ? offer only limited support because new names always emerge.all of the above point to the critical need for robust machine transliteration technology and systems.</prevsent>
</prevsection>
<citsent citstr=" P06-1010 ">
much research effort has been made to address the transliteration issue in the research community (knight and graehl, 1998; <papid> J98-4003 </papid>meng et al, 2001; li et al, 2004; <papid> P04-1021 </papid>zelenko and aone, 2006; <papid> W06-1672 </papid>sproat et al, 2006; <papid> P06-1010 </papid>sherif and kondrak, 2007; <papid> P07-1119 </papid>hermjakob et al, 2008; <papid> P08-1045 </papid>al-onaizan and knight, 2002; goldwasser and roth, 2008; <papid> D08-1037 </papid>goldberg and elhadad, 2008; klementiev and roth, 2006; <papid> P06-1103 </papid>oh and choi, 2002; <papid> C02-1099 </papid>virga and khudanpur, 2003; <papid> W03-1508 </papid>wan and verspoor, 1998; kang and choi, 2000; gao et al, 2004; zelenko and aone, 2006; <papid> W06-1672 </papid>li et al, 2009<papid> W09-3501 </papid>b; li et al, 2009<papid> W09-3501 </papid>a).</citsent>
<aftsection>
<nextsent>these previous work fall into three categories, i.e., grapheme-based,phoneme-based and hybrid methods.
</nextsent>
<nextsent>graphemebased method (li et al, 2004) <papid> P04-1021 </papid>treats transliteration as direct orthographic mapping and only uses orthography-related features while phoneme based method (knight and graehl, 1998) <papid> J98-4003 </papid>makes use of phonetic correspondence to generate thetransliteration.</nextsent>
<nextsent>hybrid method refers to the combination of several different models or knowledge sources to support the transliteration generation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2203">
<title id=" W10-2401.xml">report of news 2010 transliteration generation shared task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they are important in cross lingual information retrieval (clir) and machine translation (mt) as the system performance has been shown to positively correlate with the correct conversion of names between the languages in several studies (demner-fushman and oard, 2002; mandl and womser-hacker, 2005; hermjakob et al, 2008; <papid> P08-1045 </papid>udupa et al, 2009).</prevsent>
<prevsent>the traditional source for name equivalence, the bilingual dictionaries ? whether handcrafted or statistical ? offer only limited support because new names always emerge.all of the above point to the critical need for robust machine transliteration technology and systems.</prevsent>
</prevsection>
<citsent citstr=" P07-1119 ">
much research effort has been made to address the transliteration issue in the research community (knight and graehl, 1998; <papid> J98-4003 </papid>meng et al, 2001; li et al, 2004; <papid> P04-1021 </papid>zelenko and aone, 2006; <papid> W06-1672 </papid>sproat et al, 2006; <papid> P06-1010 </papid>sherif and kondrak, 2007; <papid> P07-1119 </papid>hermjakob et al, 2008; <papid> P08-1045 </papid>al-onaizan and knight, 2002; goldwasser and roth, 2008; <papid> D08-1037 </papid>goldberg and elhadad, 2008; klementiev and roth, 2006; <papid> P06-1103 </papid>oh and choi, 2002; <papid> C02-1099 </papid>virga and khudanpur, 2003; <papid> W03-1508 </papid>wan and verspoor, 1998; kang and choi, 2000; gao et al, 2004; zelenko and aone, 2006; <papid> W06-1672 </papid>li et al, 2009<papid> W09-3501 </papid>b; li et al, 2009<papid> W09-3501 </papid>a).</citsent>
<aftsection>
<nextsent>these previous work fall into three categories, i.e., grapheme-based,phoneme-based and hybrid methods.
</nextsent>
<nextsent>graphemebased method (li et al, 2004) <papid> P04-1021 </papid>treats transliteration as direct orthographic mapping and only uses orthography-related features while phoneme based method (knight and graehl, 1998) <papid> J98-4003 </papid>makes use of phonetic correspondence to generate thetransliteration.</nextsent>
<nextsent>hybrid method refers to the combination of several different models or knowledge sources to support the transliteration generation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2206">
<title id=" W10-2401.xml">report of news 2010 transliteration generation shared task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they are important in cross lingual information retrieval (clir) and machine translation (mt) as the system performance has been shown to positively correlate with the correct conversion of names between the languages in several studies (demner-fushman and oard, 2002; mandl and womser-hacker, 2005; hermjakob et al, 2008; <papid> P08-1045 </papid>udupa et al, 2009).</prevsent>
<prevsent>the traditional source for name equivalence, the bilingual dictionaries ? whether handcrafted or statistical ? offer only limited support because new names always emerge.all of the above point to the critical need for robust machine transliteration technology and systems.</prevsent>
</prevsection>
<citsent citstr=" D08-1037 ">
much research effort has been made to address the transliteration issue in the research community (knight and graehl, 1998; <papid> J98-4003 </papid>meng et al, 2001; li et al, 2004; <papid> P04-1021 </papid>zelenko and aone, 2006; <papid> W06-1672 </papid>sproat et al, 2006; <papid> P06-1010 </papid>sherif and kondrak, 2007; <papid> P07-1119 </papid>hermjakob et al, 2008; <papid> P08-1045 </papid>al-onaizan and knight, 2002; goldwasser and roth, 2008; <papid> D08-1037 </papid>goldberg and elhadad, 2008; klementiev and roth, 2006; <papid> P06-1103 </papid>oh and choi, 2002; <papid> C02-1099 </papid>virga and khudanpur, 2003; <papid> W03-1508 </papid>wan and verspoor, 1998; kang and choi, 2000; gao et al, 2004; zelenko and aone, 2006; <papid> W06-1672 </papid>li et al, 2009<papid> W09-3501 </papid>b; li et al, 2009<papid> W09-3501 </papid>a).</citsent>
<aftsection>
<nextsent>these previous work fall into three categories, i.e., grapheme-based,phoneme-based and hybrid methods.
</nextsent>
<nextsent>graphemebased method (li et al, 2004) <papid> P04-1021 </papid>treats transliteration as direct orthographic mapping and only uses orthography-related features while phoneme based method (knight and graehl, 1998) <papid> J98-4003 </papid>makes use of phonetic correspondence to generate thetransliteration.</nextsent>
<nextsent>hybrid method refers to the combination of several different models or knowledge sources to support the transliteration generation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2207">
<title id=" W10-2401.xml">report of news 2010 transliteration generation shared task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they are important in cross lingual information retrieval (clir) and machine translation (mt) as the system performance has been shown to positively correlate with the correct conversion of names between the languages in several studies (demner-fushman and oard, 2002; mandl and womser-hacker, 2005; hermjakob et al, 2008; <papid> P08-1045 </papid>udupa et al, 2009).</prevsent>
<prevsent>the traditional source for name equivalence, the bilingual dictionaries ? whether handcrafted or statistical ? offer only limited support because new names always emerge.all of the above point to the critical need for robust machine transliteration technology and systems.</prevsent>
</prevsection>
<citsent citstr=" P06-1103 ">
much research effort has been made to address the transliteration issue in the research community (knight and graehl, 1998; <papid> J98-4003 </papid>meng et al, 2001; li et al, 2004; <papid> P04-1021 </papid>zelenko and aone, 2006; <papid> W06-1672 </papid>sproat et al, 2006; <papid> P06-1010 </papid>sherif and kondrak, 2007; <papid> P07-1119 </papid>hermjakob et al, 2008; <papid> P08-1045 </papid>al-onaizan and knight, 2002; goldwasser and roth, 2008; <papid> D08-1037 </papid>goldberg and elhadad, 2008; klementiev and roth, 2006; <papid> P06-1103 </papid>oh and choi, 2002; <papid> C02-1099 </papid>virga and khudanpur, 2003; <papid> W03-1508 </papid>wan and verspoor, 1998; kang and choi, 2000; gao et al, 2004; zelenko and aone, 2006; <papid> W06-1672 </papid>li et al, 2009<papid> W09-3501 </papid>b; li et al, 2009<papid> W09-3501 </papid>a).</citsent>
<aftsection>
<nextsent>these previous work fall into three categories, i.e., grapheme-based,phoneme-based and hybrid methods.
</nextsent>
<nextsent>graphemebased method (li et al, 2004) <papid> P04-1021 </papid>treats transliteration as direct orthographic mapping and only uses orthography-related features while phoneme based method (knight and graehl, 1998) <papid> J98-4003 </papid>makes use of phonetic correspondence to generate thetransliteration.</nextsent>
<nextsent>hybrid method refers to the combination of several different models or knowledge sources to support the transliteration generation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2208">
<title id=" W10-2401.xml">report of news 2010 transliteration generation shared task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they are important in cross lingual information retrieval (clir) and machine translation (mt) as the system performance has been shown to positively correlate with the correct conversion of names between the languages in several studies (demner-fushman and oard, 2002; mandl and womser-hacker, 2005; hermjakob et al, 2008; <papid> P08-1045 </papid>udupa et al, 2009).</prevsent>
<prevsent>the traditional source for name equivalence, the bilingual dictionaries ? whether handcrafted or statistical ? offer only limited support because new names always emerge.all of the above point to the critical need for robust machine transliteration technology and systems.</prevsent>
</prevsection>
<citsent citstr=" C02-1099 ">
much research effort has been made to address the transliteration issue in the research community (knight and graehl, 1998; <papid> J98-4003 </papid>meng et al, 2001; li et al, 2004; <papid> P04-1021 </papid>zelenko and aone, 2006; <papid> W06-1672 </papid>sproat et al, 2006; <papid> P06-1010 </papid>sherif and kondrak, 2007; <papid> P07-1119 </papid>hermjakob et al, 2008; <papid> P08-1045 </papid>al-onaizan and knight, 2002; goldwasser and roth, 2008; <papid> D08-1037 </papid>goldberg and elhadad, 2008; klementiev and roth, 2006; <papid> P06-1103 </papid>oh and choi, 2002; <papid> C02-1099 </papid>virga and khudanpur, 2003; <papid> W03-1508 </papid>wan and verspoor, 1998; kang and choi, 2000; gao et al, 2004; zelenko and aone, 2006; <papid> W06-1672 </papid>li et al, 2009<papid> W09-3501 </papid>b; li et al, 2009<papid> W09-3501 </papid>a).</citsent>
<aftsection>
<nextsent>these previous work fall into three categories, i.e., grapheme-based,phoneme-based and hybrid methods.
</nextsent>
<nextsent>graphemebased method (li et al, 2004) <papid> P04-1021 </papid>treats transliteration as direct orthographic mapping and only uses orthography-related features while phoneme based method (knight and graehl, 1998) <papid> J98-4003 </papid>makes use of phonetic correspondence to generate thetransliteration.</nextsent>
<nextsent>hybrid method refers to the combination of several different models or knowledge sources to support the transliteration generation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2209">
<title id=" W10-2401.xml">report of news 2010 transliteration generation shared task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they are important in cross lingual information retrieval (clir) and machine translation (mt) as the system performance has been shown to positively correlate with the correct conversion of names between the languages in several studies (demner-fushman and oard, 2002; mandl and womser-hacker, 2005; hermjakob et al, 2008; <papid> P08-1045 </papid>udupa et al, 2009).</prevsent>
<prevsent>the traditional source for name equivalence, the bilingual dictionaries ? whether handcrafted or statistical ? offer only limited support because new names always emerge.all of the above point to the critical need for robust machine transliteration technology and systems.</prevsent>
</prevsection>
<citsent citstr=" W03-1508 ">
much research effort has been made to address the transliteration issue in the research community (knight and graehl, 1998; <papid> J98-4003 </papid>meng et al, 2001; li et al, 2004; <papid> P04-1021 </papid>zelenko and aone, 2006; <papid> W06-1672 </papid>sproat et al, 2006; <papid> P06-1010 </papid>sherif and kondrak, 2007; <papid> P07-1119 </papid>hermjakob et al, 2008; <papid> P08-1045 </papid>al-onaizan and knight, 2002; goldwasser and roth, 2008; <papid> D08-1037 </papid>goldberg and elhadad, 2008; klementiev and roth, 2006; <papid> P06-1103 </papid>oh and choi, 2002; <papid> C02-1099 </papid>virga and khudanpur, 2003; <papid> W03-1508 </papid>wan and verspoor, 1998; kang and choi, 2000; gao et al, 2004; zelenko and aone, 2006; <papid> W06-1672 </papid>li et al, 2009<papid> W09-3501 </papid>b; li et al, 2009<papid> W09-3501 </papid>a).</citsent>
<aftsection>
<nextsent>these previous work fall into three categories, i.e., grapheme-based,phoneme-based and hybrid methods.
</nextsent>
<nextsent>graphemebased method (li et al, 2004) <papid> P04-1021 </papid>treats transliteration as direct orthographic mapping and only uses orthography-related features while phoneme based method (knight and graehl, 1998) <papid> J98-4003 </papid>makes use of phonetic correspondence to generate thetransliteration.</nextsent>
<nextsent>hybrid method refers to the combination of several different models or knowledge sources to support the transliteration generation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2212">
<title id=" W10-2401.xml">report of news 2010 transliteration generation shared task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they are important in cross lingual information retrieval (clir) and machine translation (mt) as the system performance has been shown to positively correlate with the correct conversion of names between the languages in several studies (demner-fushman and oard, 2002; mandl and womser-hacker, 2005; hermjakob et al, 2008; <papid> P08-1045 </papid>udupa et al, 2009).</prevsent>
<prevsent>the traditional source for name equivalence, the bilingual dictionaries ? whether handcrafted or statistical ? offer only limited support because new names always emerge.all of the above point to the critical need for robust machine transliteration technology and systems.</prevsent>
</prevsection>
<citsent citstr=" W09-3501 ">
much research effort has been made to address the transliteration issue in the research community (knight and graehl, 1998; <papid> J98-4003 </papid>meng et al, 2001; li et al, 2004; <papid> P04-1021 </papid>zelenko and aone, 2006; <papid> W06-1672 </papid>sproat et al, 2006; <papid> P06-1010 </papid>sherif and kondrak, 2007; <papid> P07-1119 </papid>hermjakob et al, 2008; <papid> P08-1045 </papid>al-onaizan and knight, 2002; goldwasser and roth, 2008; <papid> D08-1037 </papid>goldberg and elhadad, 2008; klementiev and roth, 2006; <papid> P06-1103 </papid>oh and choi, 2002; <papid> C02-1099 </papid>virga and khudanpur, 2003; <papid> W03-1508 </papid>wan and verspoor, 1998; kang and choi, 2000; gao et al, 2004; zelenko and aone, 2006; <papid> W06-1672 </papid>li et al, 2009<papid> W09-3501 </papid>b; li et al, 2009<papid> W09-3501 </papid>a).</citsent>
<aftsection>
<nextsent>these previous work fall into three categories, i.e., grapheme-based,phoneme-based and hybrid methods.
</nextsent>
<nextsent>graphemebased method (li et al, 2004) <papid> P04-1021 </papid>treats transliteration as direct orthographic mapping and only uses orthography-related features while phoneme based method (knight and graehl, 1998) <papid> J98-4003 </papid>makes use of phonetic correspondence to generate thetransliteration.</nextsent>
<nextsent>hybrid method refers to the combination of several different models or knowledge sources to support the transliteration generation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2241">
<title id=" W10-2401.xml">report of news 2010 transliteration generation shared task </title>
<section> task results and analysis.  </section>
<citcontext>
<prevsection>
<prevsent>all the results are presented numerically in tables 415, for all evaluation metrics.
</prevsent>
<prevsent>these are the official evaluation results published for this edition of the transliteration shared task.
</prevsent>
</prevsection>
<citsent citstr=" I08-8003 ">
among the four submitted system papers1, song et al (2010) and finch and sumita (2010)adopt the approach of phrase-based statistical machine transliteration (finch and sumita, 2008),<papid> I08-8003 </papid>an approach initially developed for machine translation (koehn et al, 2003) <papid> N03-1017 </papid>while das et al(2010) adopts the approach of conditional random fields (crf) (lafferty et al, 2001).</citsent>
<aftsection>
<nextsent>jiampojamarn et al (2010) further develop directtl approach presented at the previous news work shop (jiampojamarn et al, 2009), achieving very good performance in the news 2010.an example of completely language1to maintain anonymity, papers of the teams that submitted anonymous results are not cited in this report.
</nextsent>
<nextsent>independent approach is (finch and sumita,2010).
</nextsent>
<nextsent>other participants used language independent approach but added language specific pre- or post-processing (jiampojamarn et al, 2010; das et al, 2010; song et al, 2010), including name origin recognition for english to hindi task (jiampojamarn et al, 2010).
</nextsent>
<nextsent>combination of different models via re-rankingof their outputs has been used in most of the systems (das et al, 2010; song et al, 2010; finch and sumita, 2010).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2242">
<title id=" W10-2401.xml">report of news 2010 transliteration generation shared task </title>
<section> task results and analysis.  </section>
<citcontext>
<prevsection>
<prevsent>all the results are presented numerically in tables 415, for all evaluation metrics.
</prevsent>
<prevsent>these are the official evaluation results published for this edition of the transliteration shared task.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
among the four submitted system papers1, song et al (2010) and finch and sumita (2010)adopt the approach of phrase-based statistical machine transliteration (finch and sumita, 2008),<papid> I08-8003 </papid>an approach initially developed for machine translation (koehn et al, 2003) <papid> N03-1017 </papid>while das et al(2010) adopts the approach of conditional random fields (crf) (lafferty et al, 2001).</citsent>
<aftsection>
<nextsent>jiampojamarn et al (2010) further develop directtl approach presented at the previous news work shop (jiampojamarn et al, 2009), achieving very good performance in the news 2010.an example of completely language1to maintain anonymity, papers of the teams that submitted anonymous results are not cited in this report.
</nextsent>
<nextsent>independent approach is (finch and sumita,2010).
</nextsent>
<nextsent>other participants used language independent approach but added language specific pre- or post-processing (jiampojamarn et al, 2010; das et al, 2010; song et al, 2010), including name origin recognition for english to hindi task (jiampojamarn et al, 2010).
</nextsent>
<nextsent>combination of different models via re-rankingof their outputs has been used in most of the systems (das et al, 2010; song et al, 2010; finch and sumita, 2010).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2245">
<title id=" W10-3107.xml">levels of certainty in knowledge intensive corpora an initial annotation study </title>
<section> related research.  </section>
<citcontext>
<prevsection>
<prevsent>speculative keywords and neg ations, along with their linguistic scopes, are annotated in the bio scope corpus by vincze et al (2008), which contains alarge collection of medical and biological text (sci entific articles and abstracts, as well as radiology reports).
</prevsent>
<prevsent>after several iterations of refining their guidelines, they report iaa values ranging from 77.6 to 92.37 1 -score for speculative keywords (62.5 and 95.54 1-score for full scope).
</prevsent>
</prevsection>
<citsent citstr=" W09-1304 ">
this corpus is freely available and has been used for training and evaluation of automatic classifiers, see e.g. morante and daelemans (2009).<papid> W09-1304 </papid></citsent>
<aftsection>
<nextsent>one of the main findings is that hedge cues are highly domaindependent.
</nextsent>
<nextsent>automatic identification of other private states, including opinions, represents similar task, see e.g. wiebe et al (2005).
</nextsent>
<nextsent>diab etal.
</nextsent>
<nextsent>(2009) study annotation of committed and non committed belief and show that automatic tagging of such classes is feasible.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2246">
<title id=" W10-3107.xml">levels of certainty in knowledge intensive corpora an initial annotation study </title>
<section> method.  </section>
<citcontext>
<prevsection>
<prevsent>the corpus is from slightly different domain to those previously targeted and represents an adequate alternative to knowledge documents internal to an organization by fulfilling the criterion of knowledge intensity.
</prevsent>
<prevsent>the process is carried out in aprotege?
</prevsent>
</prevsection>
<citsent citstr=" N06-4006 ">
plugin: knowtator (ogren, 2006).<papid> N06-4006 </papid></citsent>
<aftsection>
<nextsent>pairwise iaa, measured as 1 -score, is calculated to evaluate the feasibility of the approach.
</nextsent>
<nextsent>statements are annotated at the clause level, as sentences often contain subparts subject to different levels of certainty.
</nextsent>
<nextsent>these are not predefined and the span of classes is determined by the annotator.
</nextsent>
<nextsent>furthermore, distinction is made between different types of statement: statements that give an account of something, typically report of past events, and statements that express concrete knowledge claims.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2247">
<title id=" W10-3107.xml">levels of certainty in knowledge intensive corpora an initial annotation study </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>consider the words possibly and 43 probably.
</prevsent>
<prevsent>according to the guidelines, single occurrence of either of these hedging indicators would normally render statement quite uncertain.
</prevsent>
</prevsection>
<citsent citstr=" W08-0607 ">
giving freer hands to the annotator might be way to evade this problem; however, it is not likely to lead to any more consistent annotations.kilicoglu and bergler (2008) <papid> W08-0607 </papid>address this by assigning weights to hedging cues.</citsent>
<aftsection>
<nextsent>a constantly recurring bone of contention is presented by the relationship between certainty and precision.
</nextsent>
<nextsent>one of the hardest judgements to make is whether imprecision, or vagueness, is asign of uncertainty.
</nextsent>
<nextsent>consider the following example from the corpus:cape verde had virtually no private sector.
</nextsent>
<nextsent>clearly, this statement would be more certain if ithad said: cape verde had no private sector.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2248">
<title id=" W10-1110.xml">linking swefn with medical resources towards a med framenet for swedish </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>tools have to be developed for the automatic processing of the textual content in deeper, more semantically-oriented fashion having access to multilayered lexical and grammaticalinformation.
</prevsent>
<prevsent>the goal is then to enable rapid, effective and as far as possible accurate extraction of relationships, facts and events asserted and described in the data.
</prevsent>
</prevsection>
<citsent citstr=" W09-1401 ">
event extraction is understood here as an activity, that broadly follows the bionlp 2009 shared task view (kim et al, 2009),<papid> W09-1401 </papid>in which an event is considered to be an involvement of multiple entities in varying roles.</citsent>
<aftsection>
<nextsent>the taskis fundamental to the objective of language technology systems, such as question-answering and information extraction (ie), which have as theirhigher-level goal to identify instances of particular class of events (or relationships) in text and to extract their relevant arguments.
</nextsent>
<nextsent>we argue that such information has direct correlation with fra menets semantic frames, since templates in the context of ie are frame-like structures with slots representing the event basic information.
</nextsent>
<nextsent>our intention is to explore the applicability of sfn++ tothe clinical and scientific medical domain in swedish.
</nextsent>
<nextsent>therefore, relevant domain specific entities are explicitly annotated by automatic indexing of the texts by the swedish and english medical subject headings thesauri (mesh); cf.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2249">
<title id=" W10-1110.xml">linking swefn with medical resources towards a med framenet for swedish </title>
<section> conclusions and further research.  </section>
<citcontext>
<prevsection>
<prevsent>of course, there are several other issues that need to be worked on, such as devising ways to recognize negated and/or speculative language usage.
</prevsent>
<prevsent>mapping medical frame elements onto corresponding concepts in thesaurus-based lexicon turns relatively little lexical resource into more robust oneand hence more useful for semi-automatic semantic annotation of corpora; cf.
</prevsent>
</prevsection>
<citsent citstr=" W07-2018 ">
baker et al, 2007.<papid> W07-2018 </papid></citsent>
<aftsection>
<nextsent>for annotating the swedish corpus, we have usedour intern thematically sorted lexicons with medical vocabulary and the swedish data from mesh.
</nextsent>
<nextsent>core fes in fn mesh thesaurus nodes ailment, affliction disease body_parts anatomy medication chemicals and drugs treatment analytical, diagnostic and therapeutic techniques and equipment patient person table 1.
</nextsent>
<nextsent>example of mapping of core frame elements onto mesh top nodes the advantage of the pre-processing stage is very important and we believe that there is feasible way to proceed in order to aid the annotation of large textual samples.
</nextsent>
<nextsent>preliminary quantitative analysis of the examined instances has shown that many linguistically optional scheme elements need to be re-ranked whenever viewed from medical pragmatic perspective.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2250">
<title id=" W10-2418.xml">think globally apply locally using distributional characteristics for hindi named entity identification </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>machine translation needs identification of named entities, so that they can be transliterated.
</prevsent>
<prevsent>for indian languages, it is tough to identify named entities because of the lack of capitalization.
</prevsent>
</prevsection>
<citsent citstr=" I08-5004 ">
many approaches based on memm (saha et al., 2008<papid> I08-5004 </papid>b), crfs (li and mccallum, 2003) and hybrid models have been tried for hindi named entity recognition.</citsent>
<aftsection>
<nextsent>these approaches use onlythe local context for tagging the text.
</nextsent>
<nextsent>many applications need entity identification in large corpora.
</nextsent>
<nextsent>when such large corpus is to be tagged,one can use the global distributional characteristics of the words to identify the named entities.
</nextsent>
<nextsent>the state-of-the-art methods do not take advantage of these characteristics.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2252">
<title id=" W10-2418.xml">think globally apply locally using distributional characteristics for hindi named entity identification </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>ngi also outperforms the baseline, in the former case, when training and test corpus are from different genre.
</prevsent>
<prevsent>our contributions in this paper are: ? developing an approach of harnessing the global characteristics of the corpus for hindi named entity identification using information measures, distributional similarity, lexicon, term co-occurrence and language cues ? demonstrating that combining the global characteristics with the local contexts improves the accuracy; and with very significant amount when the train and test corpus are not from same domain or similar genre ? demonstrating that the system using only the 116global characteristics is also quite comparable with the existing systems and performs better than them, when train and test corpus are unrelated ? introducing new scoring function, which is quite competitive with the best measure and better than other well known information measures approach description s-memm (baseline) memm based statistical system without inserting global information ngi uses global distributional characteristics along with language information for ne identificationclgin combines the global characteristics derived using ngi with s-memm table 1: summary of approaches
</prevsent>
</prevsection>
<citsent citstr=" M98-1018 ">
there is plethora of work on ner for english ranging from supervised approaches like hmms(bikel et al, 1999), maximum entropy (borthwick, 1999) (borthwick et al, 1998), <papid> M98-1018 </papid>crf (lafferty et al, 2001) and svms to unsupervised (alfonseca and manandhar, 2002), (volker, 2005)and semi-supervised approaches (li and mccallum, 2005).</citsent>
<aftsection>
<nextsent>however, these approaches do not perform well for indian languages mainly due to lack of capitalization and unavailability of good gazetteer lists.
</nextsent>
<nextsent>the best score reported for hin diner using these approaches on standard corpus (ijcnlp) is 65.13% ((saha et al, 2008<papid> I08-5004 </papid>a)).</nextsent>
<nextsent>higher accuracies have been reported (81%) (sahaet al, 2008<papid> I08-5004 </papid>b), albeit, on non-standard corpus using rules and comprehensive gazetteers.current state-of-the-art systems (li and mccallum, 2003) (saha et al, 2008<papid> I08-5004 </papid>b) use various language independent and language specific features, like, context word information, pos tags, suffix and prefix information, gazetteer lists, common preceding and following words, etc. the performance of these systems is significantly hampered when the test corpus is not similar to the training corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2267">
<title id=" W10-2418.xml">think globally apply locally using distributional characteristics for hindi named entity identification </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the best score reported for hin diner using these approaches on standard corpus (ijcnlp) is 65.13% ((saha et al, 2008<papid> I08-5004 </papid>a)).</prevsent>
<prevsent>higher accuracies have been reported (81%) (sahaet al, 2008<papid> I08-5004 </papid>b), albeit, on non-standard corpus using rules and comprehensive gazetteers.current state-of-the-art systems (li and mccallum, 2003) (saha et al, 2008<papid> I08-5004 </papid>b) use various language independent and language specific features, like, context word information, pos tags, suffix and prefix information, gazetteer lists, common preceding and following words, etc. the performance of these systems is significantly hampered when the test corpus is not similar to the training corpus.</prevsent>
</prevsection>
<citsent citstr=" N09-1032 ">
few studies (guo et al, 2009), (<papid> N09-1032 </papid>poibeau and kosseim, 2001) have been performed towards genre/domain adaptation.</citsent>
<aftsection>
<nextsent>but this still remains anopen area.
</nextsent>
<nextsent>moreover, no work has been done towards this for indian languages.
</nextsent>
<nextsent>select words based on information measure applying pruning heuristics corpus neig tagged dataset applying augmenting heuristics threshold (set using development set step 1 tagging using global distribution (neig) trained model statistical system (memm) step 2 memm based statistical system(s-memm)final tagged dataset added as feature features (context words, pos tags, suffix info, gazette ers, lexicon, etc.) dataset to be tagged figure 1: block diagram of clgin approach one shortcoming of current approaches is that they do not leverage on global distributional characteristics of words (e.g., information content, term co-occurrence statistics, etc.) when large corpus needs nei.
</nextsent>
<nextsent>rennie and jaakkola (2005) introduced new information measure and used it for ne detection.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2268">
<title id=" W10-2418.xml">think globally apply locally using distributional characteristics for hindi named entity identification </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>rennie and jaakkola (2005) introduced new information measure and used it for ne detection.
</prevsent>
<prevsent>they used this approach only on un capitalized and ungrammatical english text, like blogs where spellings and pos tags are not correct.
</prevsent>
</prevsection>
<citsent citstr=" W99-0613 ">
some semi-supervised approaches (collins and singer, 1999), (<papid> W99-0613 </papid>riloff and jones, 1999), (pasca, 2007) have also used large available corpora to generate context patterns for named entities or for generating gazetteer lists and entity expansion using seed entities.</citsent>
<aftsection>
<nextsent>klementiev and roth (2006) <papid> N06-1011 </papid>use cooccurrence of sets of terms within documents to boost the certainty (in cross-lingual setting) that the terms in question were really transliterations of each other.</nextsent>
<nextsent>in this paper, we contend that using such global distributional characteristics improves the performance of hindi nei when applied to large cor pus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2269">
<title id=" W10-2418.xml">think globally apply locally using distributional characteristics for hindi named entity identification </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>they used this approach only on un capitalized and ungrammatical english text, like blogs where spellings and pos tags are not correct.
</prevsent>
<prevsent>some semi-supervised approaches (collins and singer, 1999), (<papid> W99-0613 </papid>riloff and jones, 1999), (pasca, 2007) have also used large available corpora to generate context patterns for named entities or for generating gazetteer lists and entity expansion using seed entities.</prevsent>
</prevsection>
<citsent citstr=" N06-1011 ">
klementiev and roth (2006) <papid> N06-1011 </papid>use cooccurrence of sets of terms within documents to boost the certainty (in cross-lingual setting) that the terms in question were really transliterations of each other.</citsent>
<aftsection>
<nextsent>in this paper, we contend that using such global distributional characteristics improves the performance of hindi nei when applied to large corpus.
</nextsent>
<nextsent>further, we show that the performance ofsuch systems which use global distribution characteristics is better than current state-of-the-art systems when the training and test corpus are not similar (different domain/genre) thereby being more suitable for domain adaptation.
</nextsent>
<nextsent>(s-memm) we implemented the maximum entropy markov model based system(saha et al, 2008<papid> I08-5004 </papid>b) for neidentification.</nextsent>
<nextsent>we use this system as our base line and compare our approaches ngi and clginwith this baseline.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2276">
<title id=" W10-2418.xml">think globally apply locally using distributional characteristics for hindi named entity identification </title>
<section> our approach-clgin.  </section>
<citcontext>
<prevsection>
<prevsent>the following sections describe this approach in detail.
</prevsent>
<prevsent>4.1 information measures/scoring functions.
</prevsent>
</prevsection>
<citsent citstr=" W95-0110 ">
various measures have been introduced forde termining the information content of the words.these include, idf (inverse document fre quency) (jones, 1972) , residual idf (church andgale, 1995), <papid> W95-0110 </papid>xi - measure (bookstein and swanson, 1974), gain (papineni, 2001), <papid> N01-1004 </papid>etc. we introduced our own information measure, rf (ratio of frequencies).</citsent>
<aftsection>
<nextsent>4.1.1 rf (ratio of frequencies) nes are highly relevant words in document (clifton et al, 2002) and are expected to have high information content (rennie and jaakkola, 2005).
</nextsent>
<nextsent>it has been found that words that appear frequently in set of documents and not so frequently in the rest of the documents are important with respect to that set of documents where they are frequent.
</nextsent>
<nextsent>we expected the nes to be concentrated in fewdocuments.
</nextsent>
<nextsent>we defined new criteria which measures the ratio of the total number of times theword appears in the corpus to the number of documents containing word.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2277">
<title id=" W10-2418.xml">think globally apply locally using distributional characteristics for hindi named entity identification </title>
<section> our approach-clgin.  </section>
<citcontext>
<prevsection>
<prevsent>the following sections describe this approach in detail.
</prevsent>
<prevsent>4.1 information measures/scoring functions.
</prevsent>
</prevsection>
<citsent citstr=" N01-1004 ">
various measures have been introduced forde termining the information content of the words.these include, idf (inverse document fre quency) (jones, 1972) , residual idf (church andgale, 1995), <papid> W95-0110 </papid>xi - measure (bookstein and swanson, 1974), gain (papineni, 2001), <papid> N01-1004 </papid>etc. we introduced our own information measure, rf (ratio of frequencies).</citsent>
<aftsection>
<nextsent>4.1.1 rf (ratio of frequencies) nes are highly relevant words in document (clifton et al, 2002) and are expected to have high information content (rennie and jaakkola, 2005).
</nextsent>
<nextsent>it has been found that words that appear frequently in set of documents and not so frequently in the rest of the documents are important with respect to that set of documents where they are frequent.
</nextsent>
<nextsent>we expected the nes to be concentrated in fewdocuments.
</nextsent>
<nextsent>we defined new criteria which measures the ratio of the total number of times theword appears in the corpus to the number of documents containing word.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2278">
<title id=" W10-2418.xml">think globally apply locally using distributional characteristics for hindi named entity identification </title>
<section> our approach-clgin.  </section>
<citcontext>
<prevsection>
<prevsent>such words can be identified using term co-occurrence.
</prevsent>
<prevsent>we use the given set of documents to find all word pairs.
</prevsent>
</prevsection>
<citsent citstr=" J90-1003 ">
we then calculate pointwise mutual information (pmi) (church and hanks, 1990) <papid> J90-1003 </papid>for each of these word pairs and order the pairs in descending order of their pmi values.</citsent>
<aftsection>
<nextsent>most of the word pairs belong to the following categories:?
</nextsent>
<nextsent>adjective noun combination (adjectives followed by noun): this was the most frequent combination.
</nextsent>
<nextsent>e.g. bfnf g\d (bheeni gandh sweet smell?)
</nextsent>
<nextsent>noun verb combination: edl dwkna (dil dhadakna, heart beating?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2279">
<title id=" W10-2316.xml">eliminating redundancy by spectral relaxation for multi document summarization </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>multi-document summarization is an issue to attack the problem.
</prevsent>
<prevsent>it differs from single document summarization in that it is important to identify differences and similarities across documents.
</prevsent>
</prevsection>
<citsent citstr=" W04-3247 ">
graph-based ranking methods, such as page rank (page et al , 1998) and hits (kleinberg, 1999) have recently applied and been successfully used for multi-document summarization (erkan and radev, 2004; <papid> W04-3247 </papid>mihalcea and tarau,2005).</citsent>
<aftsection>
<nextsent>given set of documents, the model constructs graph consisting vertices and edges where vertices are sentences and edges reflect the relationships between sentences.
</nextsent>
<nextsent>the model then applies graph-based ranking method to obtain therank scores for the sentences.
</nextsent>
<nextsent>finally, the sentences with large rank scores are chosen into thesummary.
</nextsent>
<nextsent>however, when they are strung together, the resulting summary still contains much overlapping information.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2280">
<title id=" W10-2316.xml">eliminating redundancy by spectral relaxation for multi document summarization </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>fessionals.
</prevsent>
<prevsent>as result, large number of wordsin candidate summary are extracted by our approaches.
</prevsent>
</prevsection>
<citsent citstr=" W08-1106 ">
for future work, it is necessary to extend our method to involve paraphrasing forex tracted key sentences to reduce the gap between automatically generated summaries and human written abstracts (barzilay et al , 1993; carenini and cheung, 2008).<papid> W08-1106 </papid></citsent>
<aftsection>
<nextsent>it is interesting to note how our approach affects for the number of sentences as an input.
</nextsent>
<nextsent>figure 1 illustrates the results of summary long?
</nextsent>
<nextsent>with evaluated rouge score.
</nextsent>
<nextsent>we can see from figure 1 that our approach is more robust than k-means and the mrw model, even for large number of input data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2281">
<title id=" W10-2316.xml">eliminating redundancy by spectral relaxation for multi document summarization </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>we have developed an approach to detect salient sentences from documents that discuss the same 0.175 0.18 0.185 0.19 0.195 0.2 0.205 0.21 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 vg . o g ratio of the # of mrw k-means spectral figure 2: long with rouge score measure vs. # of event.
</prevsent>
<prevsent>the results showed the effectiveness of themethod.
</prevsent>
</prevsection>
<citsent citstr=" N07-1013 ">
future work will include: (i) comparing other approaches that uses link analysis to reduce redundancy, such as (zhu et al , 2007), (<papid> N07-1013 </papid>ii) applying the method to the duc evaluation data for quantitative evaluation, and (iii) extending the method to classify sentences into more than one classes by using soft-clustering techniques such asem (dempster et al , 1977) and fuzzy c-means algorithms (zhang and wang, 2007).</citsent>
<aftsection>




</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2282">
<title id=" W10-1702.xml">fast consensus hypothesis regeneration for machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the first pass, decoding algorithms are applied to generate either translation n-best list or translation forest.
</prevsent>
<prevsent>then in the second pass, various re-ranking algorithms are adopted to compute the final translation.
</prevsent>
</prevsection>
<citsent citstr=" N04-1021 ">
the re-ranking algorithms include rescoring (och et al, 2004) <papid> N04-1021 </papid>and minimum bayes-risk (mbr) decoding (kumar and byrne, 2004; <papid> N04-1022 </papid>zhang and gildea, 2008; <papid> P08-1025 </papid>tromble et al, 2008).<papid> D08-1065 </papid></citsent>
<aftsection>
<nextsent>rescoring uses more sophisticated additional feature functions to score the hypotheses.
</nextsent>
<nextsent>mbr decoding directly incorporates the evaluation metrics (i.e., loss function), into the decision criterion, so it is effective in tuning the mt performance for specific loss function.
</nextsent>
<nextsent>in particular, sentence-level bleu loss function gives gains on bleu (kumar and byrne, 2004).<papid> N04-1022 </papid></nextsent>
<nextsent>the nave mbr algorithm computes the loss function between every pair of hypotheses, needing o(k2) comparisons.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2283">
<title id=" W10-1702.xml">fast consensus hypothesis regeneration for machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the first pass, decoding algorithms are applied to generate either translation n-best list or translation forest.
</prevsent>
<prevsent>then in the second pass, various re-ranking algorithms are adopted to compute the final translation.
</prevsent>
</prevsection>
<citsent citstr=" N04-1022 ">
the re-ranking algorithms include rescoring (och et al, 2004) <papid> N04-1021 </papid>and minimum bayes-risk (mbr) decoding (kumar and byrne, 2004; <papid> N04-1022 </papid>zhang and gildea, 2008; <papid> P08-1025 </papid>tromble et al, 2008).<papid> D08-1065 </papid></citsent>
<aftsection>
<nextsent>rescoring uses more sophisticated additional feature functions to score the hypotheses.
</nextsent>
<nextsent>mbr decoding directly incorporates the evaluation metrics (i.e., loss function), into the decision criterion, so it is effective in tuning the mt performance for specific loss function.
</nextsent>
<nextsent>in particular, sentence-level bleu loss function gives gains on bleu (kumar and byrne, 2004).<papid> N04-1022 </papid></nextsent>
<nextsent>the nave mbr algorithm computes the loss function between every pair of hypotheses, needing o(k2) comparisons.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2284">
<title id=" W10-1702.xml">fast consensus hypothesis regeneration for machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the first pass, decoding algorithms are applied to generate either translation n-best list or translation forest.
</prevsent>
<prevsent>then in the second pass, various re-ranking algorithms are adopted to compute the final translation.
</prevsent>
</prevsection>
<citsent citstr=" P08-1025 ">
the re-ranking algorithms include rescoring (och et al, 2004) <papid> N04-1021 </papid>and minimum bayes-risk (mbr) decoding (kumar and byrne, 2004; <papid> N04-1022 </papid>zhang and gildea, 2008; <papid> P08-1025 </papid>tromble et al, 2008).<papid> D08-1065 </papid></citsent>
<aftsection>
<nextsent>rescoring uses more sophisticated additional feature functions to score the hypotheses.
</nextsent>
<nextsent>mbr decoding directly incorporates the evaluation metrics (i.e., loss function), into the decision criterion, so it is effective in tuning the mt performance for specific loss function.
</nextsent>
<nextsent>in particular, sentence-level bleu loss function gives gains on bleu (kumar and byrne, 2004).<papid> N04-1022 </papid></nextsent>
<nextsent>the nave mbr algorithm computes the loss function between every pair of hypotheses, needing o(k2) comparisons.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2286">
<title id=" W10-1702.xml">fast consensus hypothesis regeneration for machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the first pass, decoding algorithms are applied to generate either translation n-best list or translation forest.
</prevsent>
<prevsent>then in the second pass, various re-ranking algorithms are adopted to compute the final translation.
</prevsent>
</prevsection>
<citsent citstr=" D08-1065 ">
the re-ranking algorithms include rescoring (och et al, 2004) <papid> N04-1021 </papid>and minimum bayes-risk (mbr) decoding (kumar and byrne, 2004; <papid> N04-1022 </papid>zhang and gildea, 2008; <papid> P08-1025 </papid>tromble et al, 2008).<papid> D08-1065 </papid></citsent>
<aftsection>
<nextsent>rescoring uses more sophisticated additional feature functions to score the hypotheses.
</nextsent>
<nextsent>mbr decoding directly incorporates the evaluation metrics (i.e., loss function), into the decision criterion, so it is effective in tuning the mt performance for specific loss function.
</nextsent>
<nextsent>in particular, sentence-level bleu loss function gives gains on bleu (kumar and byrne, 2004).<papid> N04-1022 </papid></nextsent>
<nextsent>the nave mbr algorithm computes the loss function between every pair of hypotheses, needing o(k2) comparisons.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2292">
<title id=" W10-1702.xml">fast consensus hypothesis regeneration for machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the nave mbr algorithm computes the loss function between every pair of hypotheses, needing o(k2) comparisons.
</prevsent>
<prevsent>therefore, only small number is applicable.
</prevsent>
</prevsection>
<citsent citstr=" P09-1064 ">
very recently, denero et al (2009) <papid> P09-1064 </papid>proposed fast consensus decoding (fcd) algorithm in which the similarity scores are computed based on the feature expectations over the translation n-best list or translation forest.</citsent>
<aftsection>
<nextsent>it is equivalent to mbr decoding when using linear similarity function, such as unigram precision.
</nextsent>
<nextsent>re-ranking approaches improve performance on an n-best list whose contents are fixed.
</nextsent>
<nextsent>a complementary strategy is to augment the contents of an n-best list in order to broaden the search space.
</nextsent>
<nextsent>chen et al(2008) <papid> C08-1014 </papid>have proposed three-pass smt process, in which hypothesis regeneration pass is added between the decoding and rescoring passes.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2294">
<title id=" W10-1702.xml">fast consensus hypothesis regeneration for machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>re-ranking approaches improve performance on an n-best list whose contents are fixed.
</prevsent>
<prevsent>a complementary strategy is to augment the contents of an n-best list in order to broaden the search space.
</prevsent>
</prevsection>
<citsent citstr=" C08-1014 ">
chen et al(2008) <papid> C08-1014 </papid>have proposed three-pass smt process, in which hypothesis regeneration pass is added between the decoding and rescoring passes.</citsent>
<aftsection>
<nextsent>new hypotheses are generated based on the original n-best hypotheses through n-gram expansion, confusion-network decoding or re-decoding.
</nextsent>
<nextsent>all three hypothesis regeneration methods obtained decent and comparable improvements in conjunction with the same rescoring model.
</nextsent>
<nextsent>however, since the final translation candidates in this approach are produced from different methods, local feature functions (such as translation models and reordering models) of each hypothesis are not directly comparable and rescoring must exploit rich global feature functions to compensate for the loss of local feature functions.
</nextsent>
<nextsent>thus this approach is dependent on the use of computationally expensive features for rescoring, which makes it inefficient.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2312">
<title id=" W10-1702.xml">fast consensus hypothesis regeneration for machine translation </title>
<section> fast consensus hypothesis regenera-.  </section>
<citcontext>
<prevsection>
<prevsent>given hypothesis set e, under the probability model )|( fep , mbr computes the translation e~ as follows: 12 )|(),(minarg~ fepeele eeee ??= ? ???
</prevsent>
<prevsent>(1) where is the source sentence, ),( eel ? is the loss function of two translations and e?
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
suppose that we are interested in maximizing the bleu score (papineni et al, 2002) <papid> P02-1040 </papid>to optimize the translation performance.</citsent>
<aftsection>
<nextsent>the loss function is defined as ),(1),( eebleueel ??=?
</nextsent>
<nextsent>, then the mbr objective can be re-written as )|(),(maxarg~ fepeebleue eeee ??= ? ???
</nextsent>
<nextsent>(2) represents the space of the translations.
</nextsent>
<nextsent>for n-best mbr decoding, this space is the n-best list produced by baseline decoder (kumar and byrne, 2004).<papid> N04-1022 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2323">
<title id=" W10-1702.xml">fast consensus hypothesis regeneration for machine translation </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>the original hypotheses are from the n-best list or extracted from the translation forest.
</prevsent>
<prevsent>the new hypotheses are generated by forward or backward n-gram expansion or are the union of both two new hypothesis lists (this is called bidirectional n-gram expansion?).
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
we carried out experiments based on translation n-best lists generated by state-of-the-art phrase-based statistical machine translation system, similar to (koehn et al, 2007).<papid> P07-2045 </papid></citsent>
<aftsection>
<nextsent>in detail, the phrase table is derived from merged counts of symmetrized ibm2 and hmm alignments; the system has both lexicalized and distance-based distortion components (there is 7-word distortion limit) and employs cube pruning (huang and chiang, 2007).<papid> P07-1019 </papid></nextsent>
<nextsent>the baseline is log-linear feature combination that includes language models, the distortion components, translation model, phrase and word penalties.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2324">
<title id=" W10-1702.xml">fast consensus hypothesis regeneration for machine translation </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>the new hypotheses are generated by forward or backward n-gram expansion or are the union of both two new hypothesis lists (this is called bidirectional n-gram expansion?).
</prevsent>
<prevsent>we carried out experiments based on translation n-best lists generated by state-of-the-art phrase-based statistical machine translation system, similar to (koehn et al, 2007).<papid> P07-2045 </papid></prevsent>
</prevsection>
<citsent citstr=" P07-1019 ">
in detail, the phrase table is derived from merged counts of symmetrized ibm2 and hmm alignments; the system has both lexicalized and distance-based distortion components (there is 7-word distortion limit) and employs cube pruning (huang and chiang, 2007).<papid> P07-1019 </papid></citsent>
<aftsection>
<nextsent>the baseline is log-linear feature combination that includes language models, the distortion components, translation model, phrase and word penalties.
</nextsent>
<nextsent>weights on feature functions are found by lattice mert (macherey et al, 2008).<papid> D08-1076 </papid></nextsent>
<nextsent>3.1 data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2325">
<title id=" W10-1702.xml">fast consensus hypothesis regeneration for machine translation </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>in detail, the phrase table is derived from merged counts of symmetrized ibm2 and hmm alignments; the system has both lexicalized and distance-based distortion components (there is 7-word distortion limit) and employs cube pruning (huang and chiang, 2007).<papid> P07-1019 </papid></prevsent>
<prevsent>the baseline is log-linear feature combination that includes language models, the distortion components, translation model, phrase and word penalties.</prevsent>
</prevsection>
<citsent citstr=" D08-1076 ">
weights on feature functions are found by lattice mert (macherey et al, 2008).<papid> D08-1076 </papid></citsent>
<aftsection>
<nextsent>3.1 data.
</nextsent>
<nextsent>we evaluated with different language pairs: chinese-to-english, and german-to-english.
</nextsent>
<nextsent>chi nese-to-english tasks are based on training data for the nist 1 2009 evaluation chinese-to english track.
</nextsent>
<nextsent>all the allowed bilingual corpora have been used for estimating the translation model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2328">
<title id=" W10-1702.xml">fast consensus hypothesis regeneration for machine translation </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>and three-pass?
</prevsent>
<prevsent>systems, we used the same rescoring model.
</prevsent>
</prevsection>
<citsent citstr=" W07-0724 ">
there are 21 rescoring features in total, mainly translation lexicon scores from ibm and hmm models, posterior probabilities for words, n-grams, and sentence length, and language models, etc. for complete description, please refer to (ueffing et al, 2007).<papid> W07-0724 </papid></citsent>
<aftsection>
<nextsent>the results in bleu-4 are reported in table 2.
</nextsent>
<nextsent>2 http://www.statmt.org/wmt06/ 14 testset nist06 nist08 baseline 35.70 28.60 rescoring 36.01 28.97 three-pass 35.98 28.99 fcd 36.00 29.10 fwd.
</nextsent>
<nextsent>36.13 29.19 bwd.
</nextsent>
<nextsent>36.11 29.20 bid.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2334">
<title id=" W10-1760.xml">integration of multiple bilinguallylearned segmentation schemes into statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>purely dictionary-based approaches like (chenget al, 1999) addressed these problems by maximum matching heuristics.
</prevsent>
<prevsent>recent research on unsupervised word segmentation focuses on approaches based on probabilistic methods.
</prevsent>
</prevsection>
<citsent citstr=" J01-3002 ">
for example, (brent, 1999) proposes probabilistic segmentation model based on unigram word distributions, whereas (venkataraman, 2001) <papid> J01-3002 </papid>uses standard n-gram language models.</citsent>
<aftsection>
<nextsent>an alternative non parametric bayesian inference approach based on the dirichlet process incorporating unigram and bigram word dependencies is introduced in (gold water et al, 2006).<papid> P06-1085 </papid></nextsent>
<nextsent>the focus of this paper, however, is to learn word segment ations that are consistent withphrasal segment ations of smt translation models.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2335">
<title id=" W10-1760.xml">integration of multiple bilinguallylearned segmentation schemes into statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recent research on unsupervised word segmentation focuses on approaches based on probabilistic methods.
</prevsent>
<prevsent>for example, (brent, 1999) proposes probabilistic segmentation model based on unigram word distributions, whereas (venkataraman, 2001) <papid> J01-3002 </papid>uses standard n-gram language models.</prevsent>
</prevsection>
<citsent citstr=" P06-1085 ">
an alternative non parametric bayesian inference approach based on the dirichlet process incorporating unigram and bigram word dependencies is introduced in (gold water et al, 2006).<papid> P06-1085 </papid></citsent>
<aftsection>
<nextsent>the focus of this paper, however, is to learn word segment ations that are consistent withphrasal segment ations of smt translation models.
</nextsent>
<nextsent>in case of small translation units, e.g. single chinese or japanese characters, it is likely that such tokens have been seen in the training corpus, thus these tokens can be translated byan smt engine.
</nextsent>
<nextsent>however, the contextual information provided by these tokens might not be enough to obtain good translation.
</nextsent>
<nextsent>for example, japanese-english smt engine might translate the two successive characters ?   ?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2336">
<title id=" W10-1760.xml">integration of multiple bilinguallylearned segmentation schemes into statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>therefore, word segmentation that is 400consistent with smt models?
</prevsent>
<prevsent>is one that identifies translation units that are small enough to be translatable, but large enough to be meaningful in the context of the given input sentence, achieving trade-off between the coverage and the translation task complexity of the statistical models in order to improve translation quality.
</prevsent>
</prevsection>
<citsent citstr=" W08-0336 ">
the use of monolingual probabilistic models does not necessarily yield better mt performance (chang et al, 2008).<papid> W08-0336 </papid></citsent>
<aftsection>
<nextsent>however, improvements have been reported for approaches taking into account not only monolingual, but also bilingual information, to derive word segmentation suitable for smt.
</nextsent>
<nextsent>due to the availability of language resources, most recent research has focused on optimizing chinese word segmentation (cws) for chinese-to-english smt.
</nextsent>
<nextsent>for example, (xu et al., 2008) <papid> C08-1128 </papid>proposes bayesian semi-supervised approach for cws that builds on (goldwater et al,2006).<papid> P06-1085 </papid></nextsent>
<nextsent>the generative model first segments chinese text using an off-the-shelf segmenter and then learns new word types and word distributions suitable for smt.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2337">
<title id=" W10-1760.xml">integration of multiple bilinguallylearned segmentation schemes into statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, improvements have been reported for approaches taking into account not only monolingual, but also bilingual information, to derive word segmentation suitable for smt.
</prevsent>
<prevsent>due to the availability of language resources, most recent research has focused on optimizing chinese word segmentation (cws) for chinese-to-english smt.
</prevsent>
</prevsection>
<citsent citstr=" C08-1128 ">
for example, (xu et al., 2008) <papid> C08-1128 </papid>proposes bayesian semi-supervised approach for cws that builds on (goldwater et al,2006).<papid> P06-1085 </papid></citsent>
<aftsection>
<nextsent>the generative model first segments chinese text using an off-the-shelf segmenter and then learns new word types and word distributions suitable for smt.
</nextsent>
<nextsent>similarly, dynamic programming based variational bayes approach using bilingual information to improve mt is proposed in (chung and gildea, 2009).<papid> D09-1075 </papid></nextsent>
<nextsent>concerning other languages,for example, (kikui and yamamoto, 2002) <papid> W02-0704 </papid>extended hidden-markov-models, where hidden gram probabilities were affected by co-occurring words in the target language part for japanese word segmentation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2339">
<title id=" W10-1760.xml">integration of multiple bilinguallylearned segmentation schemes into statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, (xu et al., 2008) <papid> C08-1128 </papid>proposes bayesian semi-supervised approach for cws that builds on (goldwater et al,2006).<papid> P06-1085 </papid></prevsent>
<prevsent>the generative model first segments chinese text using an off-the-shelf segmenter and then learns new word types and word distributions suitable for smt.</prevsent>
</prevsection>
<citsent citstr=" D09-1075 ">
similarly, dynamic programming based variational bayes approach using bilingual information to improve mt is proposed in (chung and gildea, 2009).<papid> D09-1075 </papid></citsent>
<aftsection>
<nextsent>concerning other languages,for example, (kikui and yamamoto, 2002) <papid> W02-0704 </papid>extended hidden-markov-models, where hidden gram probabilities were affected by co-occurring words in the target language part for japanese word segmentation.</nextsent>
<nextsent>recent research on smt is also focusing on the usage of multiple word segmentation schemes forthe source language to improve translation qual ity.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2340">
<title id=" W10-1760.xml">integration of multiple bilinguallylearned segmentation schemes into statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the generative model first segments chinese text using an off-the-shelf segmenter and then learns new word types and word distributions suitable for smt.
</prevsent>
<prevsent>similarly, dynamic programming based variational bayes approach using bilingual information to improve mt is proposed in (chung and gildea, 2009).<papid> D09-1075 </papid></prevsent>
</prevsection>
<citsent citstr=" W02-0704 ">
concerning other languages,for example, (kikui and yamamoto, 2002) <papid> W02-0704 </papid>extended hidden-markov-models, where hidden gram probabilities were affected by co-occurring words in the target language part for japanese word segmentation.</citsent>
<aftsection>
<nextsent>recent research on smt is also focusing on the usage of multiple word segmentation schemes forthe source language to improve translation quality.
</nextsent>
<nextsent>for example, (zhang et al, 2008) <papid> W08-0335 </papid>combines dictionary-based and crf-based approaches for chinese word segmentation in order to avoid outof-vocabulary (oov) words.</nextsent>
<nextsent>moreover, the combination of different morphological decomposition of highly inflected languages like arabic or finnish is proposed in (de gispert et al, 2009) <papid> N09-2019 </papid>to reduce the data sparseness problem of smt ap proaches.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2341">
<title id=" W10-1760.xml">integration of multiple bilinguallylearned segmentation schemes into statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>concerning other languages,for example, (kikui and yamamoto, 2002) <papid> W02-0704 </papid>extended hidden-markov-models, where hidden gram probabilities were affected by co-occurring words in the target language part for japanese word segmentation.</prevsent>
<prevsent>recent research on smt is also focusing on the usage of multiple word segmentation schemes forthe source language to improve translation qual ity.</prevsent>
</prevsection>
<citsent citstr=" W08-0335 ">
for example, (zhang et al, 2008) <papid> W08-0335 </papid>combines dictionary-based and crf-based approaches for chinese word segmentation in order to avoid outof-vocabulary (oov) words.</citsent>
<aftsection>
<nextsent>moreover, the combination of different morphological decomposition of highly inflected languages like arabic or finnish is proposed in (de gispert et al, 2009) <papid> N09-2019 </papid>to reduce the data sparseness problem of smt ap proaches.</nextsent>
<nextsent>similarly, (nakov et al, 2009) utilizes smt engines trained on different word segmentation schemes and combines the translation outputs using system combination techniques as post process to smt decoding.in order to integrate multiple word segmentation schemes into the smt decoder, (dyer et al, 2008) <papid> P08-1115 </papid>proposed to generate word lattices covering all possible segment ations of the input sentence and to decode the lattice input.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2342">
<title id=" W10-1760.xml">integration of multiple bilinguallylearned segmentation schemes into statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recent research on smt is also focusing on the usage of multiple word segmentation schemes forthe source language to improve translation quality.
</prevsent>
<prevsent>for example, (zhang et al, 2008) <papid> W08-0335 </papid>combines dictionary-based and crf-based approaches for chinese word segmentation in order to avoid outof-vocabulary (oov) words.</prevsent>
</prevsection>
<citsent citstr=" N09-2019 ">
moreover, the combination of different morphological decomposition of highly inflected languages like arabic or finnish is proposed in (de gispert et al, 2009) <papid> N09-2019 </papid>to reduce the data sparseness problem of smt ap proaches.</citsent>
<aftsection>
<nextsent>similarly, (nakov et al, 2009) utilizes smt engines trained on different word segmentation schemes and combines the translation outputs using system combination techniques as post process to smt decoding.in order to integrate multiple word segmentation schemes into the smt decoder, (dyer et al, 2008) <papid> P08-1115 </papid>proposed to generate word lattices covering all possible segment ations of the input sentence and to decode the lattice input.</nextsent>
<nextsent>an extended version of the lattice approach that does not require the use (and existence) of monolingual segmentation tools was proposed in (dyer, 2009) <papid> N09-1046 </papid>where amaximum entropy model is used to assign probabilities to the segment ations of an input word to generate diverse segmentation lattices from single automatically learned model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2343">
<title id=" W10-1760.xml">integration of multiple bilinguallylearned segmentation schemes into statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, (zhang et al, 2008) <papid> W08-0335 </papid>combines dictionary-based and crf-based approaches for chinese word segmentation in order to avoid outof-vocabulary (oov) words.</prevsent>
<prevsent>moreover, the combination of different morphological decomposition of highly inflected languages like arabic or finnish is proposed in (de gispert et al, 2009) <papid> N09-2019 </papid>to reduce the data sparseness problem of smt ap proaches.</prevsent>
</prevsection>
<citsent citstr=" P08-1115 ">
similarly, (nakov et al, 2009) utilizes smt engines trained on different word segmentation schemes and combines the translation outputs using system combination techniques as post process to smt decoding.in order to integrate multiple word segmentation schemes into the smt decoder, (dyer et al, 2008) <papid> P08-1115 </papid>proposed to generate word lattices covering all possible segment ations of the input sentence and to decode the lattice input.</citsent>
<aftsection>
<nextsent>an extended version of the lattice approach that does not require the use (and existence) of monolingual segmentation tools was proposed in (dyer, 2009) <papid> N09-1046 </papid>where amaximum entropy model is used to assign probabilities to the segment ations of an input word to generate diverse segmentation lattices from single automatically learned model.</nextsent>
<nextsent>the method of (ma and way, 2009) <papid> E09-1063 </papid>also usesa word lattice decoding approach, but they itera tively extract multiple word segmentation schemes from the training bitext.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2344">
<title id=" W10-1760.xml">integration of multiple bilinguallylearned segmentation schemes into statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>moreover, the combination of different morphological decomposition of highly inflected languages like arabic or finnish is proposed in (de gispert et al, 2009) <papid> N09-2019 </papid>to reduce the data sparseness problem of smt ap proaches.</prevsent>
<prevsent>similarly, (nakov et al, 2009) utilizes smt engines trained on different word segmentation schemes and combines the translation outputs using system combination techniques as post process to smt decoding.in order to integrate multiple word segmentation schemes into the smt decoder, (dyer et al, 2008) <papid> P08-1115 </papid>proposed to generate word lattices covering all possible segment ations of the input sentence and to decode the lattice input.</prevsent>
</prevsection>
<citsent citstr=" N09-1046 ">
an extended version of the lattice approach that does not require the use (and existence) of monolingual segmentation tools was proposed in (dyer, 2009) <papid> N09-1046 </papid>where amaximum entropy model is used to assign probabilities to the segment ations of an input word to generate diverse segmentation lattices from single automatically learned model.</citsent>
<aftsection>
<nextsent>the method of (ma and way, 2009) <papid> E09-1063 </papid>also usesa word lattice decoding approach, but they itera tively extract multiple word segmentation schemes from the training bitext.</nextsent>
<nextsent>this dictionary-based approach uses heuristics based on the maximum matching algorithm to obtain an agglomeration of segments that are covered by the dictionary.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2345">
<title id=" W10-1760.xml">integration of multiple bilinguallylearned segmentation schemes into statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>similarly, (nakov et al, 2009) utilizes smt engines trained on different word segmentation schemes and combines the translation outputs using system combination techniques as post process to smt decoding.in order to integrate multiple word segmentation schemes into the smt decoder, (dyer et al, 2008) <papid> P08-1115 </papid>proposed to generate word lattices covering all possible segment ations of the input sentence and to decode the lattice input.</prevsent>
<prevsent>an extended version of the lattice approach that does not require the use (and existence) of monolingual segmentation tools was proposed in (dyer, 2009) <papid> N09-1046 </papid>where amaximum entropy model is used to assign probabilities to the segment ations of an input word to generate diverse segmentation lattices from single automatically learned model.</prevsent>
</prevsection>
<citsent citstr=" E09-1063 ">
the method of (ma and way, 2009) <papid> E09-1063 </papid>also usesa word lattice decoding approach, but they itera tively extract multiple word segmentation schemes from the training bitext.</citsent>
<aftsection>
<nextsent>this dictionary-based approach uses heuristics based on the maximum matching algorithm to obtain an agglomeration of segments that are covered by the dictionary.
</nextsent>
<nextsent>it usesall possible source segment ations that are consistent with the extracted dictionary to create word lattice for decoding.
</nextsent>
<nextsent>the method proposed in this papers differs from previous approaches in the following points: ? it works for any language pair where the source language is unsegmented and the target language segmentation is known.
</nextsent>
<nextsent>it can be applied for the translation of asource language where no linguistically motivated word segmentation tools are available.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2347">
<title id=" W10-1760.xml">integration of multiple bilinguallylearned segmentation schemes into statistical machine translation </title>
<section> word segmentation.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 maximum-entropy tagging model.
</prevsent>
<prevsent>me models provide general purpose machine learning technique for classification and predic 402 lexical context features   t0, w2     t0, w1     t0, w0     t0, w+1     t0, w+2   tag context features   t0, t1     t0, t1, t2   table 1: feature set of me tagging model tion.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
they are versatile tools that can handle large numbers of features, and have shown themselves to be highly effective in broad range of nlp tasks including sentence boundary detection or part-of-speech tagging (berger et al, 1996).<papid> J96-1002 </papid></citsent>
<aftsection>
<nextsent>a maximum entropy classifier is an exponential model consisting of number of binary feature functions and their weights (pietra et al, 1997).
</nextsent>
<nextsent>the model is trained by adjusting the weights to maximize the entropy of the probabilistic model given constraints imposed by the training data.
</nextsent>
<nextsent>in our experiments, we use conditional maximum entropy model, where the conditional probability of the outcome given the set of features is modeled (ratnaparkhi, 1996).<papid> W96-0213 </papid></nextsent>
<nextsent>the model has the form: p(t, c) = ? ? k=0 fk(c,t)k ? p0 where: is the tag being predicted; is the context of t; ? is normalization coefficient; is the number of features in the model; fk are binary feature functions; ak is the weight of feature function fk; p0 is the default model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2348">
<title id=" W10-1760.xml">integration of multiple bilinguallylearned segmentation schemes into statistical machine translation </title>
<section> word segmentation.  </section>
<citcontext>
<prevsection>
<prevsent>a maximum entropy classifier is an exponential model consisting of number of binary feature functions and their weights (pietra et al, 1997).
</prevsent>
<prevsent>the model is trained by adjusting the weights to maximize the entropy of the probabilistic model given constraints imposed by the training data.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
in our experiments, we use conditional maximum entropy model, where the conditional probability of the outcome given the set of features is modeled (ratnaparkhi, 1996).<papid> W96-0213 </papid></citsent>
<aftsection>
<nextsent>the model has the form: p(t, c) = ? ? k=0 fk(c,t)k ? p0 where: is the tag being predicted; is the context of t; ? is normalization coefficient; is the number of features in the model; fk are binary feature functions; ak is the weight of feature function fk; p0 is the default model.
</nextsent>
<nextsent>the feature set is given in table 1.
</nextsent>
<nextsent>the lexical context features consist of target words annotated with tag t. w0 denotes the word being tagged and w2, . . .
</nextsent>
<nextsent>, w+2 the surrounding words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2350">
<title id=" W10-1760.xml">integration of multiple bilinguallylearned segmentation schemes into statistical machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the given statistics are obtained using commonly-used linguistic segmentation tools available for the respective language, i.e., chasen (ja), wordcut (th), ictclas(zh), han tagger (ko).
</prevsent>
<prevsent>no segmentation was available for taiwanese mandarin and therefore no meaningful statistics could be obtained.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
for the training of the smt models, standard word alignment (och and ney, 2003) <papid> J03-1002 </papid>and language modeling (stolcke, 2002) tools were used.</citsent>
<aftsection>
<nextsent>minimum error rate training (mert) was used to tune the decoders parameters and performed on the dev set using the technique proposed in (och and ney, 2003).<papid> J03-1002 </papid></nextsent>
<nextsent>for the translation, multi-stack phrase-based decoder was used.for the evaluation of translation quality, we applied standard automatic metrics, i.e., bleu (papineni et al, 2002) <papid> P02-1040 </papid>and meteor (lavie and agarwal, 2007).<papid> W07-0734 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2352">
<title id=" W10-1760.xml">integration of multiple bilinguallylearned segmentation schemes into statistical machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>for the training of the smt models, standard word alignment (och and ney, 2003) <papid> J03-1002 </papid>and language modeling (stolcke, 2002) tools were used.</prevsent>
<prevsent>minimum error rate training (mert) was used to tune the decoders parameters and performed on the dev set using the technique proposed in (och and ney, 2003).<papid> J03-1002 </papid></prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
for the translation, multi-stack phrase-based decoder was used.for the evaluation of translation quality, we applied standard automatic metrics, i.e., bleu (papineni et al, 2002) <papid> P02-1040 </papid>and meteor (lavie and agarwal, 2007).<papid> W07-0734 </papid></citsent>
<aftsection>
<nextsent>we have tested the statistical signif cance of our results2 using the bootstrap method reported in (zhang et al, 2004) that (1) performs arandom sampling with replacement from the evaluation dataset, (2) calculates the evaluation metric score of each engine for the sampled test sentences and the difference between the two mt system scores, (3) repeats the sampling/scoring step itera22000 iterations were used for the analysis of the automatic evaluation results in this paper.
</nextsent>
<nextsent>all reported differences in evaluation scores are statistically significant.
</nextsent>
<nextsent>404tively, and (4) applies the students t-test at significance level of 95% confidence to test whether the score differences are significant.
</nextsent>
<nextsent>in addition, human assessment of translation quality was carried out using the ranking metrics.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2353">
<title id=" W10-1760.xml">integration of multiple bilinguallylearned segmentation schemes into statistical machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>for the training of the smt models, standard word alignment (och and ney, 2003) <papid> J03-1002 </papid>and language modeling (stolcke, 2002) tools were used.</prevsent>
<prevsent>minimum error rate training (mert) was used to tune the decoders parameters and performed on the dev set using the technique proposed in (och and ney, 2003).<papid> J03-1002 </papid></prevsent>
</prevsection>
<citsent citstr=" W07-0734 ">
for the translation, multi-stack phrase-based decoder was used.for the evaluation of translation quality, we applied standard automatic metrics, i.e., bleu (papineni et al, 2002) <papid> P02-1040 </papid>and meteor (lavie and agarwal, 2007).<papid> W07-0734 </papid></citsent>
<aftsection>
<nextsent>we have tested the statistical signif cance of our results2 using the bootstrap method reported in (zhang et al, 2004) that (1) performs arandom sampling with replacement from the evaluation dataset, (2) calculates the evaluation metric score of each engine for the sampled test sentences and the difference between the two mt system scores, (3) repeats the sampling/scoring step itera22000 iterations were used for the analysis of the automatic evaluation results in this paper.
</nextsent>
<nextsent>all reported differences in evaluation scores are statistically significant.
</nextsent>
<nextsent>404tively, and (4) applies the students t-test at significance level of 95% confidence to test whether the score differences are significant.
</nextsent>
<nextsent>in addition, human assessment of translation quality was carried out using the ranking metrics.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2356">
<title id=" W10-1905.xml">a comparative study of syntactic parsers for event extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the results show that the parsers with domain models using dependency formats provide very similar performance, and that an ensemble of different parsers in different formats can im prove the event extraction system.
</prevsent>
<prevsent>bio-molecular events are useful for modeling and understanding biological systems, and their automatic extraction from text is one of the key tasks in biomedical natural language processing (bionlp).
</prevsent>
</prevsection>
<citsent citstr=" W09-1401 ">
in the bionlp 2009 shared task on event extraction, participants constructed event extraction systems using variety of different parsers, and the results indicated that the use of parser was correlated with high ranking in the task (kim et al, 2009)<papid> W09-1401 </papid></citsent>
<aftsection>
<nextsent>by contrast, the results did not indicate clear preference for particular parser, and there has so far been no direct comparison of different parsers for event extraction.
</nextsent>
<nextsent>while the outputs of parsers applying the same out format can be compared using gold standard corpus, it is difficult to perform meaningful comparison of parsers applying different frameworks.additionally, it is still an open question to what extent high performance on gold standard treebank correlates with usefulness at practical tasks.
</nextsent>
<nextsent>task based comparisons of parsers provide not only way to asses parsers across frameworks but also necessary measure of their practical applicability.in this paper, five different parsers are compared on the bio-molecular event extraction task defined in the bionlp 2009 shared task using state-of-the-art event extraction system.
</nextsent>
<nextsent>the datasets share abstracts with genia treebank, and the treebank is used as an evaluation standard.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2361">
<title id=" W10-1905.xml">a comparative study of syntactic parsers for event extraction </title>
<section> bio-molecular event extraction with.  </section>
<citcontext>
<prevsection>
<prevsent>2.2 parsers and formats.
</prevsent>
<prevsent>five parsers and three formats are adopted for the evaluation.
</prevsent>
</prevsection>
<citsent citstr=" D07-1111 ">
the parsers are gdep (sagae and tsujii, 2007)<papid> D07-1111 </papid>2, the bikel parser (bikel) (bikel, 2004)<papid> W04-3224 </papid>3, the charniak-johnson reranking parser,using david mccloskys self-trained biomedical parsing model (mc) (mcclosky, 2009)4, the c&c; ccg parser, adapted to biomedical text 1http://www-tsujii.is.s.u-tokyo.ac.jp/ genia/sharedtask/ 2http://www.cs.cmu.edu/sagae/parser/ gdep/ 3http://www.cis.upenn.edu/dbikel/ software.html 4http://www.cs.brown.edu/dmcc/ biomedical.html</citsent>
<aftsection>
<nextsent>  figure 1: stanford basic dependency tree
</nextsent>
<nextsent>      figure 2: conll-x dependency tree
</nextsent>
<nextsent>          figure 3: predicate argument structure
</nextsent>
<nextsent>     figure 4: format conversion dependencies in five parsers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2362">
<title id=" W10-1905.xml">a comparative study of syntactic parsers for event extraction </title>
<section> bio-molecular event extraction with.  </section>
<citcontext>
<prevsection>
<prevsent>2.2 parsers and formats.
</prevsent>
<prevsent>five parsers and three formats are adopted for the evaluation.
</prevsent>
</prevsection>
<citsent citstr=" W04-3224 ">
the parsers are gdep (sagae and tsujii, 2007)<papid> D07-1111 </papid>2, the bikel parser (bikel) (bikel, 2004)<papid> W04-3224 </papid>3, the charniak-johnson reranking parser,using david mccloskys self-trained biomedical parsing model (mc) (mcclosky, 2009)4, the c&c; ccg parser, adapted to biomedical text 1http://www-tsujii.is.s.u-tokyo.ac.jp/ genia/sharedtask/ 2http://www.cs.cmu.edu/sagae/parser/ gdep/ 3http://www.cis.upenn.edu/dbikel/ software.html 4http://www.cs.brown.edu/dmcc/ biomedical.html</citsent>
<aftsection>
<nextsent>  figure 1: stanford basic dependency tree
</nextsent>
<nextsent>      figure 2: conll-x dependency tree
</nextsent>
<nextsent>          figure 3: predicate argument structure
</nextsent>
<nextsent>     figure 4: format conversion dependencies in five parsers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2365">
<title id=" W10-1905.xml">a comparative study of syntactic parsers for event extraction </title>
<section> bio-molecular event extraction with.  </section>
<citcontext>
<prevsection>
<prevsent>we note that all of these conversions can introduce some errors in the conversion process.
</prevsent>
<prevsent>with the exception of bikel, all the applied parsers have models specifically adapted for biomedical text.
</prevsent>
</prevsection>
<citsent citstr=" I05-2038 ">
further, all of the biomedical do main models have been created with reference and for many parsers with direct training on the data of (a subset of) the genia treebank (tateisi etal., 2005).<papid> I05-2038 </papid></citsent>
<aftsection>
<nextsent>the results of parsing with these models as provided for the bionlp shared task are used in this comparison.
</nextsent>
<nextsent>however, we note that the shared task data, drawn from the genia event corpus (kim et al, 2008), contains abstracts that are also in the genia treebank.
</nextsent>
<nextsent>this implies that the parsers are likely to perform better on the texts used in the shared task than on other biomedical domain text, and similarly that systems building on their output are expected to achieve best per 7http://www-nlp.stanford.edu/software/ lex-parser.shtml 8http://nlp.cs.lth.se/software/ treebank converter/formance on this data.
</nextsent>
<nextsent>however, it does not invalidate comparison within the dataset.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2366">
<title id=" W10-1905.xml">a comparative study of syntactic parsers for event extraction </title>
<section> bio-molecular event extraction with.  </section>
<citcontext>
<prevsection>
<prevsent>one modification is removing two classes of features from the original features (for details of the original feature representation, we refer to (miwa et al, 2010));specifically the features representing governor dependent relationships from the target word, and the features representing each event edges in the complex event detector are removed.
</prevsent>
<prevsent>the other modification is to use headwords in trigger expression as gold trigger word.
</prevsent>
</prevsection>
<citsent citstr=" W09-1418 ">
this modification is inspired by the part-of-speech (pos) based selection proposed by kilicoglu and bergler (2009).<papid> W09-1418 </papid></citsent>
<aftsection>
<nextsent>39 the system uses head word in?
</nextsent>
<nextsent>as trigger word in trigger expression in the presence of?
</nextsent>
<nextsent>instead of using all the words of the expression.
</nextsent>
<nextsent>in cases where there is no head word information in parser output, headwords are selected heuris tically: if word does not modify another word in the trigger expression, the word is selected as head word.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2367">
<title id=" W10-1905.xml">a comparative study of syntactic parsers for event extraction </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>mc with conll-x format and enju with predicate argument structure in enju format are used for the evaluation.
</prevsent>
<prevsent>results on simple, binding, regulation, and all events are shown.
</prevsent>
</prevsection>
<citsent citstr=" W09-1406 ">
results by miwa et al (2010) (miwa), bjorne et al (2009) (bjorne), and riedel et al (2009) (<papid> W09-1406 </papid>riedel) for task 1 and task 2 are shown for comparison.</citsent>
<aftsection>
<nextsent>the best score in each result is shown in bold.
</nextsent>
<nextsent>ple, is good for extracting regulation events, but produced weaker results for simple events.
</nextsent>
<nextsent>the ensembles of two parser outputs inherit both the strengths and weaknesses of the outputs in most cases, and the strengths and weaknesses of the ensembles vary depending on the combined parser outputs.
</nextsent>
<nextsent>the differences in performance between ensembles of the outputs of two parsers to the ensemble of the three parser outputs are +0.01 fortask 1, and -0.26 for task 2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2369">
<title id=" W10-1905.xml">a comparative study of syntactic parsers for event extraction </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>this result also shows that the system originally developed only for core events extraction can be easily extended for other arguments simply by treating the other arguments as additional arguments.
</prevsent>
<prevsent>many approaches for parser comparison have been proposed in the bionlp field.
</prevsent>
</prevsection>
<citsent citstr=" W07-1004 ">
most comparisons have used gold treebanks with intermediate formats (clegg and shepherd, 2007; pyysalo etal., 2007).<papid> W07-1004 </papid></citsent>
<aftsection>
<nextsent>application-oriented parser comparison across several formats was first introduced by miyao et al (2009), who compared eight parsers and five formats for the protein-protein interaction(ppi) extraction task.
</nextsent>
<nextsent>ppi extraction, the recognition of binary relations of between proteins, is one of the most basic information extraction tasksin the bionlp field.
</nextsent>
<nextsent>our findings do not conflict with those of miyao et al event extraction can be viewed as an additional extrinsic evaluation task for syntactic parsers, providing more reliable and evaluation and broader perspective into parser performance.
</nextsent>
<nextsent>an additional advantage of application-oriented evaluation on bionlp shared task data is the availability of manually annotated gold standard treebank, the genia treebank, that covers the same set of abstracts as the taskdata.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2370">
<title id=" W10-3906.xml">even un associated features can improve lexical distributional similarity </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this fact implies that the conventional calculation methods are far enough to the goal and are expected to improve further.the basic framework for computing distributional similarity is same; for each of two input words context (i.e., surrounding words) is extracted from corpus, vector is made in which an element of the vector is value or weight, and two vectors are compared with formula to compute similarity.
</prevsent>
<prevsent>among these processes we have focused on features, that are elements of 32 the vector, some of which, we think, adversely affect the performance.
</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
that is, traditional approaches such as lin (1998) <papid> P98-2127 </papid>basically use all of observed words as context, that causes noise in feature vector comparison.</citsent>
<aftsection>
<nextsent>one may agree thatthe number of the characteristic words to determine the meaning of word is some, not all, of words around the target word.
</nextsent>
<nextsent>thus our goal is to detect and reduce such noisy features.
</nextsent>
<nextsent>zhitomirsky-geffet and dagan (2009) have same motivation with us and introduced bootstrapping strategy that changes the original features weights.
</nextsent>
<nextsent>the general idea here is to promote the weights of features that are common for associated words, since these features are likely to be most characteristic for determining the words meaning.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2372">
<title id=" W10-3906.xml">even un associated features can improve lexical distributional similarity </title>
<section> conclusion and future work.  </section>
<citcontext>
<prevsection>
<prevsent>similarly, in our task we use features of not only associated but un associated to make computation of similarity(or distance in semantic space) clearer.
</prevsent>
<prevsent>we as 38 sert in this work that feature that has similar weight to two given words also plays important role, regardless of how much it is associated to the given words.among several future works we need to further explore reduction of features.
</prevsent>
</prevsection>
<citsent citstr=" P06-1045 ">
it is reported by some literature such as hagiwara et al (2006)<papid> P06-1045 </papid>that we can reduce so many features while preserving the same accuracy in distributional similarity calculation.</citsent>
<aftsection>
<nextsent>this implies that, some ofthem are still harmful and are expected to be reduced further.
</nextsent>
<nextsent>list of tools and resources 1.
</nextsent>
<nextsent>chasen, morphological analyzer,.
</nextsent>
<nextsent>ver.2.3.3.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2373">
<title id=" W10-3018.xml">exploiting ccg structures with tree kernels for speculation detection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>speculation and its impact on argumentation has been studied by linguists and logic ians since at least as far back as aristotle (trans 1991, 1407a, 1407b), and under the category of linguistichedges?
</prevsent>
<prevsent>since lakoff (1973).
</prevsent>
</prevsection>
<citsent citstr=" W08-0606 ">
practical application of this research has emerged due to the efforts to create biomedical database of sentences tagged with speculation information: bio scope (szarvas et al, 2008) <papid> W08-0606 </papid>and because of the association of some kinds of wikipedia data with the speculation phenomenon (ganter and strube,2009).<papid> P09-2044 </papid></citsent>
<aftsection>
<nextsent>it is clear that specific words can be considered as clues that can qualify sentence asspeculative.
</nextsent>
<nextsent>however, the presence of speculative keyword not always conveys speculation assertion which makes the speculation detection tough problem.
</nextsent>
<nextsent>for instance, the sentences below contain the speculative keyword may?, but only the sentence (a) is speculative.
</nextsent>
<nextsent>(a) these effects may be reversible.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2374">
<title id=" W10-3018.xml">exploiting ccg structures with tree kernels for speculation detection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>speculation and its impact on argumentation has been studied by linguists and logic ians since at least as far back as aristotle (trans 1991, 1407a, 1407b), and under the category of linguistichedges?
</prevsent>
<prevsent>since lakoff (1973).
</prevsent>
</prevsection>
<citsent citstr=" P09-2044 ">
practical application of this research has emerged due to the efforts to create biomedical database of sentences tagged with speculation information: bio scope (szarvas et al, 2008) <papid> W08-0606 </papid>and because of the association of some kinds of wikipedia data with the speculation phenomenon (ganter and strube,2009).<papid> P09-2044 </papid></citsent>
<aftsection>
<nextsent>it is clear that specific words can be considered as clues that can qualify sentence asspeculative.
</nextsent>
<nextsent>however, the presence of speculative keyword not always conveys speculation assertion which makes the speculation detection tough problem.
</nextsent>
<nextsent>for instance, the sentences below contain the speculative keyword may?, but only the sentence (a) is speculative.
</nextsent>
<nextsent>(a) these effects may be reversible.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2375">
<title id=" W10-3018.xml">exploiting ccg structures with tree kernels for speculation detection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, in this paper we include results in the biomedical domain as well.the bio scope corpus is linguistically hand annotated corpus of negation and speculation phenomena for medical free texts, biomedical article abstracts and full biomedical articles.
</prevsent>
<prevsent>the aforesaid phenomena have been annotated at sentence level with keyword tags and linguistic scope tags.
</prevsent>
</prevsection>
<citsent citstr=" P07-1125 ">
some previous research on speculation detection and boundary determination over biomedical data has been done by medlock &amp; briscoe (2007) <papid> P07-1125 </papid>and ozgur &amp; radev (2009) from computational view using machine learning methods.the wikipedia speculation dataset was generated by exploiting weasel word marking.</citsent>
<aftsection>
<nextsent>as weasel words convey vagueness and ambiguity by providing an unsupported opinion, they are discouraged by wikipedia editors.
</nextsent>
<nextsent>ganter &amp; strube (2009) <papid> P09-2044 </papid>proposed system to detect hedges based on frequency measures and shallow information, achieving f-score of 0.691.we formulate the speculation detection problem as word disambiguation problem and developed system as pipe lined set of natural 1they used different wikipedia data.</nextsent>
<nextsent>126language processing tools and procedures to pre process the datasets.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2377">
<title id=" W10-3018.xml">exploiting ccg structures with tree kernels for speculation detection </title>
<section> speculation detection system.  </section>
<citcontext>
<prevsection>
<prevsent>in the ml module two types of dataset are built:one used by tk classifier and other one by bag of-features based maximum entropy classifier.
</prevsent>
<prevsent>as the first one processes only those sentences that contain speculative words, we use the second classifier, which is able to process samples of all the sentences.the models built by these classifiers are combined in order to provide better performance and coverage for the speculation problem in the classification module which finally outputs sentences labeled as speculative or non-speculative.
</prevsent>
</prevsection>
<citsent citstr=" P04-1014 ">
used tools are the genia tagger (tsuruoka et al, 2005) for tokenization and lemmatization, and the c&cparser; (clark and curran, 2004).<papid> P04-1014 </papid></citsent>
<aftsection>
<nextsent>the next sections explain in detail the main system components.
</nextsent>
<nextsent>2extraction of keywords for the training stage.
</nextsent>
<nextsent>extraction the pre-processing module extracts keywords, sentences and document information.all sentences are processed by the tokenizer/lemmatizer and at the same time specific information about the keywords is extracted.
</nextsent>
<nextsent>speculative keywords speculative sentences are evidenced by the presence of speculation keywords.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2378">
<title id=" W10-3018.xml">exploiting ccg structures with tree kernels for speculation detection </title>
<section> dataset pre-processing for rich feature.  </section>
<citcontext>
<prevsection>
<prevsent>127 figure 1: block diagram for the speculation detection system.
</prevsent>
<prevsent>hand, ccg derivations or dependencies provide deeper information, in form of predicate-argumentrelations.
</prevsent>
</prevsection>
<citsent citstr=" W03-1008 ">
previous works on semantic role labeling (gildea and hockenmaier, 2003; <papid> W03-1008 </papid>boxwell et al., 2009) <papid> P09-1005 </papid>have used features derived from ccg par sings and obtained better results.</citsent>
<aftsection>
<nextsent>c&c; parser provides ccg predicate-argument dependencies and briscoe and carroll (2006) <papid> P06-2006 </papid>style grammatical relations.</nextsent>
<nextsent>we parsed the tokenized sentences to obtain ccg derivations which are binary trees as shown in the figure 2.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2379">
<title id=" W10-3018.xml">exploiting ccg structures with tree kernels for speculation detection </title>
<section> dataset pre-processing for rich feature.  </section>
<citcontext>
<prevsection>
<prevsent>127 figure 1: block diagram for the speculation detection system.
</prevsent>
<prevsent>hand, ccg derivations or dependencies provide deeper information, in form of predicate-argumentrelations.
</prevsent>
</prevsection>
<citsent citstr=" P09-1005 ">
previous works on semantic role labeling (gildea and hockenmaier, 2003; <papid> W03-1008 </papid>boxwell et al., 2009) <papid> P09-1005 </papid>have used features derived from ccg par sings and obtained better results.</citsent>
<aftsection>
<nextsent>c&c; parser provides ccg predicate-argument dependencies and briscoe and carroll (2006) <papid> P06-2006 </papid>style grammatical relations.</nextsent>
<nextsent>we parsed the tokenized sentences to obtain ccg derivations which are binary trees as shown in the figure 2.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2380">
<title id=" W10-3018.xml">exploiting ccg structures with tree kernels for speculation detection </title>
<section> dataset pre-processing for rich feature.  </section>
<citcontext>
<prevsection>
<prevsent>hand, ccg derivations or dependencies provide deeper information, in form of predicate-argumentrelations.
</prevsent>
<prevsent>previous works on semantic role labeling (gildea and hockenmaier, 2003; <papid> W03-1008 </papid>boxwell et al., 2009) <papid> P09-1005 </papid>have used features derived from ccg par sings and obtained better results.</prevsent>
</prevsection>
<citsent citstr=" P06-2006 ">
c&c; parser provides ccg predicate-argument dependencies and briscoe and carroll (2006) <papid> P06-2006 </papid>style grammatical relations.</citsent>
<aftsection>
<nextsent>we parsed the tokenized sentences to obtain ccg derivations which are binary trees as shown in the figure 2.
</nextsent>
<nextsent>the ccg derivation trees contain function category and part-of-speech labels; this information is contained in the tree structures to be used in building subtree dataset for the tk classifier.
</nextsent>
<nextsent>4.1 tree kernel classification.
</nextsent>
<nextsent>the subtree dataset is processed by tree kernel classifier (moschitti, 2006) based on support vector machines.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2381">
<title id=" W10-2803.xml">what is word meaning really and how can distributional models help us describe it </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we argue that distributional models provide flexible framework for experimenting with alternative models of word meanings, and discuss example models.
</prevsent>
<prevsent>word sense disambiguation (wsd) is one ofthe oldest problems in computational linguistics (weaver, 1949) and still remains challenging today.
</prevsent>
</prevsection>
<citsent citstr=" W04-0807 ">
state-of-the-art performance on wsd for wordnet senses is at only around 70-80% accuracy (edmonds and cotton, 2001; mihalcea et al, 2004).<papid> W04-0807 </papid></citsent>
<aftsection>
<nextsent>the use of coarse-grained sense groups (palmer et al, 2007) has led to considerable advances in wsd performance, with accuracies of around 90% (pradhan et al, 2007).<papid> W07-2016 </papid></nextsent>
<nextsent>but this figure averages over lemmas, and the problem remains that while wsd works well for some lem mas, others continue to be tough.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2383">
<title id=" W10-2803.xml">what is word meaning really and how can distributional models help us describe it </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>word sense disambiguation (wsd) is one ofthe oldest problems in computational linguistics (weaver, 1949) and still remains challenging today.
</prevsent>
<prevsent>state-of-the-art performance on wsd for wordnet senses is at only around 70-80% accuracy (edmonds and cotton, 2001; mihalcea et al, 2004).<papid> W04-0807 </papid></prevsent>
</prevsection>
<citsent citstr=" W07-2016 ">
the use of coarse-grained sense groups (palmer et al, 2007) has led to considerable advances in wsd performance, with accuracies of around 90% (pradhan et al, 2007).<papid> W07-2016 </papid></citsent>
<aftsection>
<nextsent>but this figure averages over lemmas, and the problem remains that while wsd works well for some lem mas, others continue to be tough.
</nextsent>
<nextsent>in wsd, polysemy is typically modeled through list of dictionary senses thought to be mutually disjoint, such that each occurrence of word is characterized through one best-fitting dictionary sense.
</nextsent>
<nextsent>accordingly, wsd is typically framed as classification task.
</nextsent>
<nextsent>interestingly, the task of assigning single best word sense is very hard for human annotators, not just machines (kil garriff and rosenzweig, 2000).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2390">
<title id=" W10-2803.xml">what is word meaning really and how can distributional models help us describe it </title>
<section> computational and cognitive models of.  </section>
<citcontext>
<prevsection>
<prevsent>a recent analysis of factors influencing ita differences between lemmas (passonneau et al, 2010) found three main factors: sense concrete ness, specificity of the context in which target word occurs, and similarity between senses.
</prevsent>
<prevsent>it is interesting to note that only one of those factors, the third, can be addressed through change of dictionary.
</prevsent>
</prevsection>
<citsent citstr=" P04-1036 ">
more radical solutions than sense grouping that have been proposed are to restrict the task to determining predominant sense in given domain (mccarthy et al, 2004), <papid> P04-1036 </papid>or to work directly with paraphrases (mccarthy and navigli, 2009).</citsent>
<aftsection>
<nextsent>(a) graded sense membership.
</nextsent>
<nextsent>research on the human concept representation (murphy, 2002; hampton, 2007) shows that categories in the human mind are not simply sets with clear-cut boundaries.
</nextsent>
<nextsent>some items are perceived as more typical than others (rosch, 1975; rosch andmervis, 1975).
</nextsent>
<nextsent>also, some items are clear members, others are rated as borderline (hampton, 1979).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2391">
<title id=" W10-2803.xml">what is word meaning really and how can distributional models help us describe it </title>
<section> computational and cognitive models of.  </section>
<citcontext>
<prevsection>
<prevsent>(b) multiple senses per occurrence.
</prevsent>
<prevsent>while most manual word sense annotation efforts allow annotators to assign more than one dictionary sense to an occurrence, this is typically phrase das an exception rather than the default.
</prevsent>
</prevsection>
<citsent citstr=" W09-0208 ">
in there cent wssim annotation study (erk et al, 2009), <papid> W09-0208 </papid>18 senses sentence 1 2 3 4 5 6 7 annotator this question provoked arguments in america about the norton anthology of literature by women, some of the contents of which were said to have had little value as literature.</citsent>
<aftsection>
<nextsent>1 4 4 2 1 1 3 ann.
</nextsent>
<nextsent>1 4 5 4 2 1 1 4 ann.
</nextsent>
<nextsent>2 1 4 5 1 1 1 1 ann.
</nextsent>
<nextsent>3table 1: from (erk et al, 2009): <papid> W09-0208 </papid>sample annotation from the wssim dataset.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2403">
<title id=" W10-2803.xml">what is word meaning really and how can distributional models help us describe it </title>
<section> computational and cognitive models of.  </section>
<citcontext>
<prevsection>
<prevsent>2) eleven cira members have been convicted of criminal charges and others are awaiting trial.
</prevsent>
<prevsent>figure 1: from (erk et al, 2009): <papid> W09-0208 </papid>sense pair from the usim dataset, for the target charge.n. annotator judgments: 2,3,4 and varies strongly with the experimental setting.some studies found evidence for separate representation (klein and murphy, 2001; pylkkanen et al, 2006).</prevsent>
</prevsection>
<citsent citstr=" P08-2063 ">
brown (2008) <papid> P08-2063 </papid>finds linear change in semantic similarity effects with sense distance,which could possibly point to continuous representation of word meaning without clear sense boundaries.</citsent>
<aftsection>
<nextsent>but while there is no definitive answer yet on the question of the mental representation of polysemy, computational model that does not relyon distinct senses has the advantage of making fewer assumptions.
</nextsent>
<nextsent>it also avoids the tough lexicographic problem mentioned above, of deciding on best set of senses forgiven domain.
</nextsent>
<nextsent>in the recent usim annotation study (erk et al, 2009), <papid> W09-0208 </papid>we tested whether human annotators could reliably and consistently provide word meaning judgments without the use of dictionary senses.three annotators rated the similarity of pairs of occurrences (usages) of common target word, again on scale of 1-5.</nextsent>
<nextsent>figure 1 shows an example, with the corresponding annotator judgments.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2408">
<title id=" W10-2803.xml">what is word meaning really and how can distributional models help us describe it </title>
<section> computational and cognitive models of.  </section>
<citcontext>
<prevsection>
<prevsent>one group of models computes single vector for whole sentence, encoding both the words and the syntactic structure (smolensky, 1990; b. coecke and clark, 2010).
</prevsent>
<prevsent>in this case, the dimensionality of the vectors varies with the syntactic complexity of the sentence in question.
</prevsent>
</prevsection>
<citsent citstr=" P08-1028 ">
a second group also computes single vector for whole expression,but the vector for larger expression is combination of the word vectors for the words occurring in the expression (landauer and dumais, 1997; mitchell and lapata, 2008).<papid> P08-1028 </papid></citsent>
<aftsection>
<nextsent>syntactic structure is not encoded.
</nextsent>
<nextsent>the resulting vector, of the same dimensionality as the word vectors, is then combination of the contexts in which the words of the sentence occur.
</nextsent>
<nextsent>a third group of approaches derives separate vector for each word in given sentence (erk and pado?, 2008; thater et al, 2009; <papid> W09-2506 </papid>erk and pado?, 2010).</nextsent>
<nextsent>while an approach of the second type would derive single, joint vector for, say, the expression catch ball, an approach from the third group would derive two vectors, one for the word catch in the context of ball, and one for the word ball in the context of catch.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2409">
<title id=" W10-2803.xml">what is word meaning really and how can distributional models help us describe it </title>
<section> computational and cognitive models of.  </section>
<citcontext>
<prevsection>
<prevsent>syntactic structure is not encoded.
</prevsent>
<prevsent>the resulting vector, of the same dimensionality as the word vectors, is then combination of the contexts in which the words of the sentence occur.
</prevsent>
</prevsection>
<citsent citstr=" W09-2506 ">
a third group of approaches derives separate vector for each word in given sentence (erk and pado?, 2008; thater et al, 2009; <papid> W09-2506 </papid>erk and pado?, 2010).</citsent>
<aftsection>
<nextsent>while an approach of the second type would derive single, joint vector for, say, the expression catch ball, an approach from the third group would derive two vectors, one for the word catch in the context of ball, and one for the word ball in the context of catch.
</nextsent>
<nextsent>in this third group, the dimensionality of vector for word in context is the same as for word in isolation.in this paper, we focus on the third type of approaches.
</nextsent>
<nextsent>our aim is to study alternatives to dictionary senses for characterizing word meaning.
</nextsent>
<nextsent>so we need meaning characterization for each individual word in given sentence context, rather than single vector for larger expression.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2426">
<title id=" W10-2803.xml">what is word meaning really and how can distributional models help us describe it </title>
<section> computational and cognitive models of.  </section>
<citcontext>
<prevsection>
<prevsent>note that when we use dictionaries as source for inference rules, for example by creating an inference rule like (2) for each two words that share synset and for each direct hy ponym/hypernym pair, we do know the wordnet sense to which each inference rule attaches.
</prevsent>
<prevsent>mapping dictionary senses to regions in vector space.
</prevsent>
</prevsection>
<citsent citstr=" W09-1109 ">
in erk (2009) <papid> W09-1109 </papid>we expand on the idea oftying inference rules to attachment sites by representing word sense not as point but as region in vector space.</citsent>
<aftsection>
<nextsent>the extent of the regions is estimated through the use of both positive exemplars (occurrences of the word sense in question), and negative exemplars (occurrences of other words).
</nextsent>
<nextsent>the computational models we use are inspired by cognitive models of concept representation that represent concepts as regions (smith et al, 1988; hampton, 1991), in particular adopting shepards law (shepard, 1987), which states that perceived similarity to an exemplar decreases exponentially with distance from its vector.
</nextsent>
<nextsent>in the longer term, the goal for the association of inference rules with attachment sites is to obtaina principled framework for reasoning with partially applicable inference rules in vector space.
</nextsent>
<nextsent>6 conclusion and outlook.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2427">
<title id=" W10-1412.xml">easy first dependency parsing of modern hebrew </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>how ever, it abandons the strict left-to-right processing order, replacing it with an alternative order, which attempts to make easier attachments decisions prior to harder ones.
</prevsent>
<prevsent>the model was applied to english dependency parsing.
</prevsent>
</prevsection>
<citsent citstr=" P05-1012 ">
it was shown to be more accurate than malt parser, state-of-the-art transition based parser (nivre et al, 2006), and near the performance of the first-order mst parser, graph based parser which decomposes its score over tree edges (mcdonald et al, 2005), <papid> P05-1012 </papid>while being more efficient.the easy-first parser works by making easier decisions before harder ones.</citsent>
<aftsection>
<nextsent>each decision can be conditioned by structures created by previous decisions, allowing harder decisions to be based on relatively rich syntactic structure.
</nextsent>
<nextsent>this is in contrast to the globally optimized parsers, which cannot utilize such rich syntactic structures.
</nextsent>
<nextsent>it was hypothesized in (goldberg and elhadad, 2010) that this rich conditioning can be especially beneficial in situations where informative structural information is available, such as in morphologically rich languages.
</nextsent>
<nextsent>in this paper, we investigate the non-directional easy-first parser performance on modern hebrew, semitic language with rich morphology, relatively free constituent order, and small treebank compared to english.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2428">
<title id=" W10-1412.xml">easy first dependency parsing of modern hebrew </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we are interested in two main questions: (a) how well does the non-directional parser perform on hebrew data?
</prevsent>
<prevsent>and (b) can the parser make effective use of morphological features, such as agreement?
</prevsent>
</prevsection>
<citsent citstr=" W09-3819 ">
in (goldberg and elhadad, 2009), <papid> W09-3819 </papid>we describe newly created hebrew dependency treebank, and 103 report results on parsing this corpus with bothmaltparser and first- and second- order variants of mstparser.</citsent>
<aftsection>
<nextsent>we find that the second order mst parser outperforms the first order mst parser, which in turn outperforms the transition based maltparser.
</nextsent>
<nextsent>in addition, adding morphological information to the default configurations of these parsers does not improve parsing accuracy.
</nextsent>
<nextsent>interestingly, when using automatically induced (rather than gold-standard) morphological information, the transition based malt parsers accuracy improves with the addition of the morphological information, while the scores of both globally optimized parsers drop with the addition of the morphological information.our experiments in this paper show that the accuracy of the non-directional parser on the same dataset outperforms the first-order mstparser.with the addition of morphological agreement features, the parser accuracy improves even further, and is on-par with the performance of the second-ordermstparser.
</nextsent>
<nextsent>the improvement due to the morphological information persists also when automatically induced morphological information is used.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2438">
<title id=" W10-1412.xml">easy first dependency parsing of modern hebrew </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>when evaluating the parsing models, we perform two setsof evaluations.
</prevsent>
<prevsent>the first one is an oracle experiment, assuming gold segmentation and tagging isavailable.
</prevsent>
</prevsection>
<citsent citstr=" P08-1085 ">
the second one is real-world experiment, in which we segment and pos-tag the testset sentences using the morphological disambigua tor described in (adler, 2007; goldberg et al, 2008) <papid> P08-1085 </papid>prior to parsing.</citsent>
<aftsection>
<nextsent>parsers and parsing models we use our freely available implementation3 of the non-directional parser.
</nextsent>
<nextsent>evaluation measure we evaluate the resulting parses in terms of unlabeled accuracy ? the percent of correctly identified (child,parent) pairs4.
</nextsent>
<nextsent>to be precise, we calculate: number of correctly identified pairs number of pairs in gold parse for the oracle case in which the gold-standard token segmentation is available for the parser, this isthe same as the traditional unlabeled-accuracy evaluation metric.
</nextsent>
<nextsent>however, in the real-word setting in which the token segmentation is done automatically, the yields of the gold-standard and the automatic parse may differ, and one needs to decide how to handle the cases in which one or more elements in the identified (child,parent) pair are not present inthe gold-standard parse.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2442">
<title id=" W10-2413.xml">phrase based transliteration with simple heuristics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>most significantly it is used in machine translation (mt) systems, information retrieval systems where large portion of unknown words(out of vocabulary) are observed.
</prevsent>
<prevsent>named entities (ne), technical words, borrowed words and loan words constitute the majority of the unknown words.
</prevsent>
</prevsection>
<citsent citstr=" W09-3507 ">
so, transliteration can also be termed as the process of obtaining the phonetic translation of names across various languages (shishtla et al, 2009).<papid> W09-3507 </papid></citsent>
<aftsection>
<nextsent>transcribing the words from one language to another without the help of bilingual dictionary is challenging task.
</nextsent>
<nextsent>previous work in transliteration include(surana and singh, 2009) who propose transliteration system using two different approaches of transliterating the named entities based on their origin.
</nextsent>
<nextsent>(sherif and kondrak, 2007) <papid> P07-1119 </papid>use the viterbi based monotone search algorithm for searching possible candidate sub-string tran slit erations.</nextsent>
<nextsent>(malik, 2006) <papid> P06-1143 </papid>solved some special cases of transliteration for punjabi using set of transliteration rules.in the recent years statistical machine translation (smt) systems (brown et al, 1990), (<papid> J90-2002 </papid>yamada and knight, 2001), (<papid> P01-1067 </papid>chiang, 2005), (<papid> P05-1033 </papid>charniak et al, 2003) have been in focus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2443">
<title id=" W10-2413.xml">phrase based transliteration with simple heuristics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>transcribing the words from one language to another without the help of bilingual dictionary is challenging task.
</prevsent>
<prevsent>previous work in transliteration include(surana and singh, 2009) who propose transliteration system using two different approaches of transliterating the named entities based on their origin.
</prevsent>
</prevsection>
<citsent citstr=" P07-1119 ">
(sherif and kondrak, 2007) <papid> P07-1119 </papid>use the viterbi based monotone search algorithm for searching possible candidate sub-string tran slit erations.</citsent>
<aftsection>
<nextsent>(malik, 2006) <papid> P06-1143 </papid>solved some special cases of transliteration for punjabi using set of transliteration rules.in the recent years statistical machine translation (smt) systems (brown et al, 1990), (<papid> J90-2002 </papid>yamada and knight, 2001), (<papid> P01-1067 </papid>chiang, 2005), (<papid> P05-1033 </papid>charniak et al, 2003) have been in focus.</nextsent>
<nextsent>it is easyto developmt system for new pair of language using an existing smt system and parallel corpora.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2444">
<title id=" W10-2413.xml">phrase based transliteration with simple heuristics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>previous work in transliteration include(surana and singh, 2009) who propose transliteration system using two different approaches of transliterating the named entities based on their origin.
</prevsent>
<prevsent>(sherif and kondrak, 2007) <papid> P07-1119 </papid>use the viterbi based monotone search algorithm for searching possible candidate sub-string tran slit erations.</prevsent>
</prevsection>
<citsent citstr=" P06-1143 ">
(malik, 2006) <papid> P06-1143 </papid>solved some special cases of transliteration for punjabi using set of transliteration rules.in the recent years statistical machine translation (smt) systems (brown et al, 1990), (<papid> J90-2002 </papid>yamada and knight, 2001), (<papid> P01-1067 </papid>chiang, 2005), (<papid> P05-1033 </papid>charniak et al, 2003) have been in focus.</citsent>
<aftsection>
<nextsent>it is easyto developmt system for new pair of language using an existing smt system and parallel corpora.
</nextsent>
<nextsent>it isnt surprise to see smt being attractive in terms of less human labour ascom pared to other traditional systems.
</nextsent>
<nextsent>these smt systems have also become popular in the transliteration field (finch and sumita, 2008), (<papid> I08-8003 </papid>finch and sumita, 2009), (<papid> W09-3510 </papid>rama and gali, 2009).<papid> W09-3528 </papid></nextsent>
<nextsent>(finch and sumita, 2008) <papid> I08-8003 </papid>use bi-directional decoder whereas (finch and sumita, 2009) <papid> W09-3510 </papid>use machine translation system comprising of two phrase-based decoders.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2445">
<title id=" W10-2413.xml">phrase based transliteration with simple heuristics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>previous work in transliteration include(surana and singh, 2009) who propose transliteration system using two different approaches of transliterating the named entities based on their origin.
</prevsent>
<prevsent>(sherif and kondrak, 2007) <papid> P07-1119 </papid>use the viterbi based monotone search algorithm for searching possible candidate sub-string tran slit erations.</prevsent>
</prevsection>
<citsent citstr=" J90-2002 ">
(malik, 2006) <papid> P06-1143 </papid>solved some special cases of transliteration for punjabi using set of transliteration rules.in the recent years statistical machine translation (smt) systems (brown et al, 1990), (<papid> J90-2002 </papid>yamada and knight, 2001), (<papid> P01-1067 </papid>chiang, 2005), (<papid> P05-1033 </papid>charniak et al, 2003) have been in focus.</citsent>
<aftsection>
<nextsent>it is easyto developmt system for new pair of language using an existing smt system and parallel corpora.
</nextsent>
<nextsent>it isnt surprise to see smt being attractive in terms of less human labour ascom pared to other traditional systems.
</nextsent>
<nextsent>these smt systems have also become popular in the transliteration field (finch and sumita, 2008), (<papid> I08-8003 </papid>finch and sumita, 2009), (<papid> W09-3510 </papid>rama and gali, 2009).<papid> W09-3528 </papid></nextsent>
<nextsent>(finch and sumita, 2008) <papid> I08-8003 </papid>use bi-directional decoder whereas (finch and sumita, 2009) <papid> W09-3510 </papid>use machine translation system comprising of two phrase-based decoders.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2446">
<title id=" W10-2413.xml">phrase based transliteration with simple heuristics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>previous work in transliteration include(surana and singh, 2009) who propose transliteration system using two different approaches of transliterating the named entities based on their origin.
</prevsent>
<prevsent>(sherif and kondrak, 2007) <papid> P07-1119 </papid>use the viterbi based monotone search algorithm for searching possible candidate sub-string tran slit erations.</prevsent>
</prevsection>
<citsent citstr=" P01-1067 ">
(malik, 2006) <papid> P06-1143 </papid>solved some special cases of transliteration for punjabi using set of transliteration rules.in the recent years statistical machine translation (smt) systems (brown et al, 1990), (<papid> J90-2002 </papid>yamada and knight, 2001), (<papid> P01-1067 </papid>chiang, 2005), (<papid> P05-1033 </papid>charniak et al, 2003) have been in focus.</citsent>
<aftsection>
<nextsent>it is easyto developmt system for new pair of language using an existing smt system and parallel corpora.
</nextsent>
<nextsent>it isnt surprise to see smt being attractive in terms of less human labour ascom pared to other traditional systems.
</nextsent>
<nextsent>these smt systems have also become popular in the transliteration field (finch and sumita, 2008), (<papid> I08-8003 </papid>finch and sumita, 2009), (<papid> W09-3510 </papid>rama and gali, 2009).<papid> W09-3528 </papid></nextsent>
<nextsent>(finch and sumita, 2008) <papid> I08-8003 </papid>use bi-directional decoder whereas (finch and sumita, 2009) <papid> W09-3510 </papid>use machine translation system comprising of two phrase-based decoders.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2447">
<title id=" W10-2413.xml">phrase based transliteration with simple heuristics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>previous work in transliteration include(surana and singh, 2009) who propose transliteration system using two different approaches of transliterating the named entities based on their origin.
</prevsent>
<prevsent>(sherif and kondrak, 2007) <papid> P07-1119 </papid>use the viterbi based monotone search algorithm for searching possible candidate sub-string tran slit erations.</prevsent>
</prevsection>
<citsent citstr=" P05-1033 ">
(malik, 2006) <papid> P06-1143 </papid>solved some special cases of transliteration for punjabi using set of transliteration rules.in the recent years statistical machine translation (smt) systems (brown et al, 1990), (<papid> J90-2002 </papid>yamada and knight, 2001), (<papid> P01-1067 </papid>chiang, 2005), (<papid> P05-1033 </papid>charniak et al, 2003) have been in focus.</citsent>
<aftsection>
<nextsent>it is easyto developmt system for new pair of language using an existing smt system and parallel corpora.
</nextsent>
<nextsent>it isnt surprise to see smt being attractive in terms of less human labour ascom pared to other traditional systems.
</nextsent>
<nextsent>these smt systems have also become popular in the transliteration field (finch and sumita, 2008), (<papid> I08-8003 </papid>finch and sumita, 2009), (<papid> W09-3510 </papid>rama and gali, 2009).<papid> W09-3528 </papid></nextsent>
<nextsent>(finch and sumita, 2008) <papid> I08-8003 </papid>use bi-directional decoder whereas (finch and sumita, 2009) <papid> W09-3510 </papid>use machine translation system comprising of two phrase-based decoders.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2448">
<title id=" W10-2413.xml">phrase based transliteration with simple heuristics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it is easyto developmt system for new pair of language using an existing smt system and parallel corpora.
</prevsent>
<prevsent>it isnt surprise to see smt being attractive in terms of less human labour ascom pared to other traditional systems.
</prevsent>
</prevsection>
<citsent citstr=" I08-8003 ">
these smt systems have also become popular in the transliteration field (finch and sumita, 2008), (<papid> I08-8003 </papid>finch and sumita, 2009), (<papid> W09-3510 </papid>rama and gali, 2009).<papid> W09-3528 </papid></citsent>
<aftsection>
<nextsent>(finch and sumita, 2008) <papid> I08-8003 </papid>use bi-directional decoder whereas (finch and sumita, 2009) <papid> W09-3510 </papid>use machine translation system comprising of two phrase-based decoders.</nextsent>
<nextsent>the first decoder generated from first token of the target to the last.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2449">
<title id=" W10-2413.xml">phrase based transliteration with simple heuristics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it is easyto developmt system for new pair of language using an existing smt system and parallel corpora.
</prevsent>
<prevsent>it isnt surprise to see smt being attractive in terms of less human labour ascom pared to other traditional systems.
</prevsent>
</prevsection>
<citsent citstr=" W09-3510 ">
these smt systems have also become popular in the transliteration field (finch and sumita, 2008), (<papid> I08-8003 </papid>finch and sumita, 2009), (<papid> W09-3510 </papid>rama and gali, 2009).<papid> W09-3528 </papid></citsent>
<aftsection>
<nextsent>(finch and sumita, 2008) <papid> I08-8003 </papid>use bi-directional decoder whereas (finch and sumita, 2009) <papid> W09-3510 </papid>use machine translation system comprising of two phrase-based decoders.</nextsent>
<nextsent>the first decoder generated from first token of the target to the last.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2450">
<title id=" W10-2413.xml">phrase based transliteration with simple heuristics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it is easyto developmt system for new pair of language using an existing smt system and parallel corpora.
</prevsent>
<prevsent>it isnt surprise to see smt being attractive in terms of less human labour ascom pared to other traditional systems.
</prevsent>
</prevsection>
<citsent citstr=" W09-3528 ">
these smt systems have also become popular in the transliteration field (finch and sumita, 2008), (<papid> I08-8003 </papid>finch and sumita, 2009), (<papid> W09-3510 </papid>rama and gali, 2009).<papid> W09-3528 </papid></citsent>
<aftsection>
<nextsent>(finch and sumita, 2008) <papid> I08-8003 </papid>use bi-directional decoder whereas (finch and sumita, 2009) <papid> W09-3510 </papid>use machine translation system comprising of two phrase-based decoders.</nextsent>
<nextsent>the first decoder generated from first token of the target to the last.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2456">
<title id=" W10-2413.xml">phrase based transliteration with simple heuristics </title>
<section> method.  </section>
<citcontext>
<prevsection>
<prevsent>it is obvious that the system would perform better if it was trained on the combined data.
</prevsent>
<prevsent>8-gram language model and maximum phrase length of 7 is used during training.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
the transliteration systems were modeled using the minimum error rate training procedure introduced by (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>we used blue score as aevaluation metric for our convenience during tuning.
</nextsent>
<nextsent>blue score is commonly used to evaluate machine translation systems and it is function of geometric mean of n-gram precision.
</nextsent>
<nextsent>it was observed that improvement of the blue score also showed improvements in acc.
</nextsent>
<nextsent>training data of 9975 words is used to build the system models, while the development data of 1974 words is used for tuning the log-linear weights for the translation engines.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2457">
<title id=" W10-1313.xml">automated skimming system in response to questions for non visual readers </title>
<section> developing natural language processing (nlp).  </section>
<citcontext>
<prevsection>
<prevsent>intuitively, we do seem to make this connection.
</prevsent>
<prevsent>yet the connection being made is not straightforward and cannot be replicated using the direct se 101 mantic connections that are available via wordnet.
</prevsent>
</prevsection>
<citsent citstr=" W97-0704 ">
indeed, the relationships made are more similar to hovy and lins (1997) <papid> W97-0704 </papid>concept signatures created by clustering words in articles with the same edi tor-defined classification from the wall street journal.</citsent>
<aftsection>
<nextsent>our system must be able to replicate these connections automatically.
</nextsent>
<nextsent>upon further examination, we found other paragraphs that were focused on by subjects for reasons other than their physical appearance or location, yet their semantic connection to the question was even more tenuous.
</nextsent>
<nextsent>for instance, when skimming for the answer to the question, how does marijuana affect the brain??
</nextsent>
<nextsent>the second most frequently focused on paragraph (second to the paragraph with the answer) was, the main active chemical in marijuana is thc (delta-9-tetrahydrocannabinol).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2458">
<title id=" W10-1313.xml">automated skimming system in response to questions for non visual readers </title>
<section> nlp techniques.  </section>
<citcontext>
<prevsection>
<prevsent>a common technique is to determine question type (e.g., how many ???
</prevsent>
<prevsent>would be classified as numerical?, whereas who was ???
</prevsent>
</prevsection>
<citsent citstr=" A00-1041 ">
would be classified as person?, etc.) and then locate answers of the correct type (abney et al, 2000; <papid> A00-1041 </papid>kwok et al, 2001; srihari and li, 2000; galea, 2003).</citsent>
<aftsection>
<nextsent>questions are also frequently reformulated for pattern matching (e.g., who was the first american astronaut in space??
</nextsent>
<nextsent>becomes, the first american astronaut in space was?
</nextsent>
<nextsent>(kwok et al, 2001; brill et al, 2002)).
</nextsent>
<nextsent>many systems submit multiple queries to document corpus, relying on redundancy of the answer to handle incorrect answers, poorly constructed answers or documents that dont contain the answer (e.g., brill et al, 2002; kwok et al, 102 2001).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2459">
<title id=" W10-1313.xml">automated skimming system in response to questions for non visual readers </title>
<section> nlp techniques.  </section>
<citcontext>
<prevsection>
<prevsent>these word clusters, along with the expanded baseline words, are used to locate and rank paragraphs in our question document.
</prevsent>
<prevsent>our approach is similar in spirit to other researchers using the web to identify semantic relations.
</prevsent>
</prevsection>
<citsent citstr=" W06-1664 ">
matsuo et al (2006) <papid> W06-1664 </papid>looked at the number of hits of each of two words as single keyword versus the number of hits using both words as keywords to rate the semantic similarity of two words.</citsent>
<aftsection>
<nextsent>chen et al (2006) <papid> P06-1127 </papid>used similar approach to determine the semantic similarity between two words: with web search using word as the query term, they counted the number of times word occurred in the snippet of text returned, and vice versa.</nextsent>
<nextsent>bollegala et al (2007) determined semantic relationships by extracting lexico-syntactic patterns from the snippets returned from search on two keywords (e.g.,x? is y??)</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2460">
<title id=" W10-1313.xml">automated skimming system in response to questions for non visual readers </title>
<section> nlp techniques.  </section>
<citcontext>
<prevsection>
<prevsent>our approach is similar in spirit to other researchers using the web to identify semantic relations.
</prevsent>
<prevsent>matsuo et al (2006) <papid> W06-1664 </papid>looked at the number of hits of each of two words as single keyword versus the number of hits using both words as keywords to rate the semantic similarity of two words.</prevsent>
</prevsection>
<citsent citstr=" P06-1127 ">
chen et al (2006) <papid> P06-1127 </papid>used similar approach to determine the semantic similarity between two words: with web search using word as the query term, they counted the number of times word occurred in the snippet of text returned, and vice versa.</citsent>
<aftsection>
<nextsent>bollegala et al (2007) determined semantic relationships by extracting lexico-syntactic patterns from the snippets returned from search on two keywords (e.g.,x? is y??)
</nextsent>
<nextsent>and extracting the relationship of the two words based on the pattern.
</nextsent>
<nextsent>sahami and heilman (2006) used the snippets from word search to form set of words weighted using tf/idf, and then determined the semantic similarity of two keywords by the similarity of two word sets returned in those snippets.
</nextsent>
<nextsent>preliminary results from our approach have been encouraging.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2461">
<title id=" W10-1313.xml">automated skimming system in response to questions for non visual readers </title>
<section> future work.  </section>
<citcontext>
<prevsection>
<prevsent>while the system only allows us to define aois as rectangular areas (and thus we cant do sentence-by sentence analysis), we may wish to define aois as small as 2 lines of text to narrow in on exactly where subjects chose to focus.
</prevsent>
<prevsent>4.2 ranking system refinement.
</prevsent>
</prevsection>
<citsent citstr=" N03-1020 ">
it is worth mentioning that, while good deal of research has been done on evaluating the goodness of automatically generated text summaries (mani et al,2002; lin and hovy, 2003; <papid> N03-1020 </papid>santos et al, 2004) <papid> W04-1012 </papid>our system is intended to mimic the actions of skimmers when answering questions, and thus our measure of goodness will be our systems ability to recreate the retrieval of text focused on by our visual skimmers.</citsent>
<aftsection>
<nextsent>this gives us distinct advantage over other systems in measuring goodness, as defining measure of goodness can prove difficult.
</nextsent>
<nextsent>in future work, we will be exploring different methods of ranking text such that the system returns results most similar to the results obtained from the visual skimming studies.
</nextsent>
<nextsent>the system will then be used on other questions and documents and compared to data to be collected of visual skimmers skimming for answers to those questions.
</nextsent>
<nextsent>many variations on the ranking system are possible.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2462">
<title id=" W10-1313.xml">automated skimming system in response to questions for non visual readers </title>
<section> future work.  </section>
<citcontext>
<prevsection>
<prevsent>while the system only allows us to define aois as rectangular areas (and thus we cant do sentence-by sentence analysis), we may wish to define aois as small as 2 lines of text to narrow in on exactly where subjects chose to focus.
</prevsent>
<prevsent>4.2 ranking system refinement.
</prevsent>
</prevsection>
<citsent citstr=" W04-1012 ">
it is worth mentioning that, while good deal of research has been done on evaluating the goodness of automatically generated text summaries (mani et al,2002; lin and hovy, 2003; <papid> N03-1020 </papid>santos et al, 2004) <papid> W04-1012 </papid>our system is intended to mimic the actions of skimmers when answering questions, and thus our measure of goodness will be our systems ability to recreate the retrieval of text focused on by our visual skimmers.</citsent>
<aftsection>
<nextsent>this gives us distinct advantage over other systems in measuring goodness, as defining measure of goodness can prove difficult.
</nextsent>
<nextsent>in future work, we will be exploring different methods of ranking text such that the system returns results most similar to the results obtained from the visual skimming studies.
</nextsent>
<nextsent>the system will then be used on other questions and documents and compared to data to be collected of visual skimmers skimming for answers to those questions.
</nextsent>
<nextsent>many variations on the ranking system are possible.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2463">
<title id=" W10-2921.xml">improved natural language learning via variance regularization support vector machines </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>variance regularization is shown to enable dramatic improvement sin the learning rates of svms on three lexical disambiguation tasks.
</prevsent>
<prevsent>discriminative training is commonly used in nlp and speech to scale the contribution of different models or systems in combined predictor.
</prevsent>
</prevsection>
<citsent citstr=" P02-1038 ">
for example, discriminative training can be used to scale the contribution of the language model and translation model in machine translation (och andney, 2002).<papid> P02-1038 </papid></citsent>
<aftsection>
<nextsent>without training data, it is often reasonable to weight the different models equally.
</nextsent>
<nextsent>we propose simple technique that exploits this intuition for better learning with fewer training examples.
</nextsent>
<nextsent>we regularize the feature weights in support vector machine (cortes and vapnik, 1995) toward low-variance solution.
</nextsent>
<nextsent>since the new svm quadratic program is convex, it is no harder to optimize than the standard svm objective.when training data is generated through human effort, faster learning saves time and money.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2464">
<title id=" W10-2921.xml">improved natural language learning via variance regularization support vector machines </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we regularize the feature weights in support vector machine (cortes and vapnik, 1995) toward low-variance solution.
</prevsent>
<prevsent>since the new svm quadratic program is convex, it is no harder to optimize than the standard svm objective.when training data is generated through human effort, faster learning saves time and money.
</prevsent>
</prevsection>
<citsent citstr=" P05-1044 ">
when examples are labeled automatically, through user feedback (joachims, 2002) or from textual pseudo-examples (smith and eisner, 2005; <papid> P05-1044 </papid>okanohara and tsujii, 2007), <papid> P07-1010 </papid>faster learning can reduce the lag before new system is useful.we demonstrate faster learning on lexical disambiguation tasks.</citsent>
<aftsection>
<nextsent>for these tasks, system predicts label for word in text, based on the words context.
</nextsent>
<nextsent>possible labels include part-of speech tags, named-entity types, and word senses.a number of disambiguation systems make predictions with the help of n-gram counts from aweb-scale auxiliary corpus, typically via search engine (lapata and keller, 2005) or n-gram corpus (bergsma et al, 2009).
</nextsent>
<nextsent>when discriminative training is used to weigh the counts for classification, many of the learned feature weights have similar values.
</nextsent>
<nextsent>good weights have low variance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2465">
<title id=" W10-2921.xml">improved natural language learning via variance regularization support vector machines </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we regularize the feature weights in support vector machine (cortes and vapnik, 1995) toward low-variance solution.
</prevsent>
<prevsent>since the new svm quadratic program is convex, it is no harder to optimize than the standard svm objective.when training data is generated through human effort, faster learning saves time and money.
</prevsent>
</prevsection>
<citsent citstr=" P07-1010 ">
when examples are labeled automatically, through user feedback (joachims, 2002) or from textual pseudo-examples (smith and eisner, 2005; <papid> P05-1044 </papid>okanohara and tsujii, 2007), <papid> P07-1010 </papid>faster learning can reduce the lag before new system is useful.we demonstrate faster learning on lexical disambiguation tasks.</citsent>
<aftsection>
<nextsent>for these tasks, system predicts label for word in text, based on the words context.
</nextsent>
<nextsent>possible labels include part-of speech tags, named-entity types, and word senses.a number of disambiguation systems make predictions with the help of n-gram counts from aweb-scale auxiliary corpus, typically via search engine (lapata and keller, 2005) or n-gram corpus (bergsma et al, 2009).
</nextsent>
<nextsent>when discriminative training is used to weigh the counts for classification, many of the learned feature weights have similar values.
</nextsent>
<nextsent>good weights have low variance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2466">
<title id=" W10-2921.xml">improved natural language learning via variance regularization support vector machines </title>
<section> applications.  </section>
<citcontext>
<prevsection>
<prevsent>we denote these augmented systems with + as in k-svm+ and cs-svm+.
</prevsent>
<prevsent>4.1 preposition selection.
</prevsent>
</prevsection>
<citsent citstr=" W07-1604 ">
preposition errors are common among new english speakers (chodorow et al, 2007).<papid> W07-1604 </papid></citsent>
<aftsection>
<nextsent>systems that can reliably identify these errors are needed in wordprocessing and educational software.
</nextsent>
<nextsent>176 training examples system 10 100 1k 10k 100k ova-svm 16.0 50.6 66.1 71.1 73.5 k-svm 13.7 50.0 65.8 72.0 74.7 k-svm+ 22.2 56.8 70.5 73.7 75.2 cs-svm 27.1 58.8 69.0 73.5 74.2 cs-svm+ 39.6 64.8 71.5 74.0 74.4 var-svm 73.8 74.2 74.7 74.9 74.9 table 1: accuracy (%) of preposition-selection svms.
</nextsent>
<nextsent>unsupervised accuracy is 73.7%.
</nextsent>
<nextsent>in our experiments, classifier must choose the correct preposition among 34 candidates, using counts for filled 2-to-5-gram patterns.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2468">
<title id=" W10-2921.xml">improved natural language learning via variance regularization support vector machines </title>
<section> applications.  </section>
<citcontext>
<prevsection>
<prevsent>4.1.1 results the majority-class is the preposition of; it occur sin 20.3% of test examples.
</prevsent>
<prevsent>the unsupervised system scores 73.7%.
</prevsent>
</prevsection>
<citsent citstr=" C08-1109 ">
for further perspective on these results, note chodorow et al (2007) <papid> W07-1604 </papid>achieved 69% with 7m training examples, while tetreault and chodorow (2008) <papid> C08-1109 </papid>found the human performance was around 75%.</citsent>
<aftsection>
<nextsent>however, these results are not directly comparable as they are on different data.
</nextsent>
<nextsent>table 1 gives the accuracy for different amounts of training data.
</nextsent>
<nextsent>here, as in the other tasks, k-svm mirrors the learning rate in bergsma et al (2009).there are several distinct phases among the relative ranking of the systems.
</nextsent>
<nextsent>for smaller amounts of training data (1000 examples) k-svm performs worst, while var-svm is statistically significantly better than all other systems, and always exceeds the performance of the unsupervised approach.5 augmenting the attributes with sum counts (the + systems) strongly helps with fewer examples, especially in conjunction with the more efficient cs-svm.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2469">
<title id=" W10-2921.xml">improved natural language learning via variance regularization support vector machines </title>
<section> applications.  </section>
<citcontext>
<prevsection>
<prevsent>4.2 context-sensitive spelling correction.
</prevsent>
<prevsent>context-sensitive spelling correction, or real-word error/malapropism detection (golding and roth, 1999; hirst and budanitsky, 2005), is the task of identifying errors when misspelling results in real word in the lexicon, e.g., using site when sight or cite was intended.
</prevsent>
</prevsection>
<citsent citstr=" D07-1021 ">
contextual spell checkers are among the most widely-used nlp technology, as they are included in commercial wordprocessing software (church et al, 2007).<papid> D07-1021 </papid></citsent>
<aftsection>
<nextsent>for every occurrence of word in pre-definedconfusion set (e.g. {cite, sight, cite}), the classifier selects the most likely word from the set.
</nextsent>
<nextsent>we use the five confusion sets from bergsma et al(2009); four are binary and one is 3-way classification.
</nextsent>
<nextsent>we use 100k training, 10k development,and 10k test examples for each, and average accuracy across the sets.
</nextsent>
<nextsent>all 2-to-5 gram counts are used in the unsupervised system, so the variance of all weights is regularized in var-svm.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2470">
<title id=" W10-2921.xml">improved natural language learning via variance regularization support vector machines </title>
<section> applications.  </section>
<citcontext>
<prevsection>
<prevsent>non-referential detection predicts whether the english pronoun it refers to preceding noun (itlost money?)
</prevsent>
<prevsent>or is used as grammatical place holder (it is important to...?).
</prevsent>
</prevsection>
<citsent citstr=" P08-1002 ">
this binary classification is necessary but often neglected step for noun phrase coreference resolution (paice and husk, 1987; bergsma et al, 2008; <papid> P08-1002 </papid>ng, 2009).<papid> N09-1065 </papid></citsent>
<aftsection>
<nextsent>bergsma et al (2008) <papid> P08-1002 </papid>use features for the counts of various fillers in the pronouns context patterns.</nextsent>
<nextsent>if it is the most common filler, the pronoun is likely non-referential.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2471">
<title id=" W10-2921.xml">improved natural language learning via variance regularization support vector machines </title>
<section> applications.  </section>
<citcontext>
<prevsection>
<prevsent>non-referential detection predicts whether the english pronoun it refers to preceding noun (itlost money?)
</prevsent>
<prevsent>or is used as grammatical place holder (it is important to...?).
</prevsent>
</prevsection>
<citsent citstr=" N09-1065 ">
this binary classification is necessary but often neglected step for noun phrase coreference resolution (paice and husk, 1987; bergsma et al, 2008; <papid> P08-1002 </papid>ng, 2009).<papid> N09-1065 </papid></citsent>
<aftsection>
<nextsent>bergsma et al (2008) <papid> P08-1002 </papid>use features for the counts of various fillers in the pronouns context patterns.</nextsent>
<nextsent>if it is the most common filler, the pronoun is likely non-referential.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2473">
<title id=" W10-2921.xml">improved natural language learning via variance regularization support vector machines </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the graph laplacian has been used to encourage geometrically-similar feature vectors tobe classified similarly (belkin et al, 2006).
</prevsent>
<prevsent>an appealing property of these approaches is that they incorporate information from unlabeled examples.
</prevsent>
</prevsection>
<citsent citstr=" W06-2904 ">
wang et al (2006) <papid> W06-2904 </papid>use laplacian regularization for the task of dependency parsing.</citsent>
<aftsection>
<nextsent>they regularize such that features for distributionally-similarwords have similar weights.
</nextsent>
<nextsent>rather than penalize pairwise differences proportional to similarity function, we simply penalize weight variance.
</nextsent>
<nextsent>in the field of computervision, tefas et al(2001) (binary) and kotsia et al (2009) (multiclass) also regularize weights with respect to co variance matrix.
</nextsent>
<nextsent>they use labeled data to find the sum of the sample co variance matrices from each class, similar to linear discriminant analysis.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2474">
<title id=" W10-2921.xml">improved natural language learning via variance regularization support vector machines </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>dredze et al (2008) maintain the variance of each weight and use this to guide the online updates.
</prevsent>
<prevsent>however, co variance between weights is not considered.we believe new svm regularizations in general, and variance regularization in particular, will increasingly be used in combination with related nlp strategies that learn better when labeled data is scarce.
</prevsent>
</prevsection>
<citsent citstr=" N04-1043 ">
these may include: using more-general features, e.g. ones generated from raw text (milleret al, 2004; <papid> N04-1043 </papid>koo et al, 2008), <papid> P08-1068 </papid>leveraging out-ofdomain examples to improve in-domain classification (blitzer et al, 2007; <papid> P07-1056 </papid>daume?</citsent>
<aftsection>
<nextsent>iii, 2007), active learning (cohn et al, 1994; tong and koller, 2002), and approaches that treat unlabeled data as labeled, such as bootstrapping (yarowsky, 1995),<papid> P95-1026 </papid>co-training (blum and mitchell, 1998), and self training (mcclosky et al, 2006).<papid> N06-1020 </papid></nextsent>
<nextsent>the primary direction of future research will be to apply the var-svm to new problems and tasks.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2475">
<title id=" W10-2921.xml">improved natural language learning via variance regularization support vector machines </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>dredze et al (2008) maintain the variance of each weight and use this to guide the online updates.
</prevsent>
<prevsent>however, co variance between weights is not considered.we believe new svm regularizations in general, and variance regularization in particular, will increasingly be used in combination with related nlp strategies that learn better when labeled data is scarce.
</prevsent>
</prevsection>
<citsent citstr=" P08-1068 ">
these may include: using more-general features, e.g. ones generated from raw text (milleret al, 2004; <papid> N04-1043 </papid>koo et al, 2008), <papid> P08-1068 </papid>leveraging out-ofdomain examples to improve in-domain classification (blitzer et al, 2007; <papid> P07-1056 </papid>daume?</citsent>
<aftsection>
<nextsent>iii, 2007), active learning (cohn et al, 1994; tong and koller, 2002), and approaches that treat unlabeled data as labeled, such as bootstrapping (yarowsky, 1995),<papid> P95-1026 </papid>co-training (blum and mitchell, 1998), and self training (mcclosky et al, 2006).<papid> N06-1020 </papid></nextsent>
<nextsent>the primary direction of future research will be to apply the var-svm to new problems and tasks.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2476">
<title id=" W10-2921.xml">improved natural language learning via variance regularization support vector machines </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>dredze et al (2008) maintain the variance of each weight and use this to guide the online updates.
</prevsent>
<prevsent>however, co variance between weights is not considered.we believe new svm regularizations in general, and variance regularization in particular, will increasingly be used in combination with related nlp strategies that learn better when labeled data is scarce.
</prevsent>
</prevsection>
<citsent citstr=" P07-1056 ">
these may include: using more-general features, e.g. ones generated from raw text (milleret al, 2004; <papid> N04-1043 </papid>koo et al, 2008), <papid> P08-1068 </papid>leveraging out-ofdomain examples to improve in-domain classification (blitzer et al, 2007; <papid> P07-1056 </papid>daume?</citsent>
<aftsection>
<nextsent>iii, 2007), active learning (cohn et al, 1994; tong and koller, 2002), and approaches that treat unlabeled data as labeled, such as bootstrapping (yarowsky, 1995),<papid> P95-1026 </papid>co-training (blum and mitchell, 1998), and self training (mcclosky et al, 2006).<papid> N06-1020 </papid></nextsent>
<nextsent>the primary direction of future research will be to apply the var-svm to new problems and tasks.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2477">
<title id=" W10-2921.xml">improved natural language learning via variance regularization support vector machines </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, co variance between weights is not considered.we believe new svm regularizations in general, and variance regularization in particular, will increasingly be used in combination with related nlp strategies that learn better when labeled data is scarce.
</prevsent>
<prevsent>these may include: using more-general features, e.g. ones generated from raw text (milleret al, 2004; <papid> N04-1043 </papid>koo et al, 2008), <papid> P08-1068 </papid>leveraging out-ofdomain examples to improve in-domain classification (blitzer et al, 2007; <papid> P07-1056 </papid>daume?</prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
iii, 2007), active learning (cohn et al, 1994; tong and koller, 2002), and approaches that treat unlabeled data as labeled, such as bootstrapping (yarowsky, 1995),<papid> P95-1026 </papid>co-training (blum and mitchell, 1998), and self training (mcclosky et al, 2006).<papid> N06-1020 </papid></citsent>
<aftsection>
<nextsent>the primary direction of future research will be to apply the var-svm to new problems and tasks.
</nextsent>
<nextsent>there are many situations where system designer has an intuition about the role feature will play in prediction; the feature was perhaps added with this role in mind.
</nextsent>
<nextsent>by biasing the svm to use features as intended, var-svm may learn better with fewer training examples.
</nextsent>
<nextsent>the relationship between attributes and classes may be explicit when, e.g.,a rule-based system is optimized via discriminative learning, or annotators justify their decisions by indicating the relevant attributes (zaidan et al, 2007).<papid> N07-1033 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2478">
<title id=" W10-2921.xml">improved natural language learning via variance regularization support vector machines </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, co variance between weights is not considered.we believe new svm regularizations in general, and variance regularization in particular, will increasingly be used in combination with related nlp strategies that learn better when labeled data is scarce.
</prevsent>
<prevsent>these may include: using more-general features, e.g. ones generated from raw text (milleret al, 2004; <papid> N04-1043 </papid>koo et al, 2008), <papid> P08-1068 </papid>leveraging out-ofdomain examples to improve in-domain classification (blitzer et al, 2007; <papid> P07-1056 </papid>daume?</prevsent>
</prevsection>
<citsent citstr=" N06-1020 ">
iii, 2007), active learning (cohn et al, 1994; tong and koller, 2002), and approaches that treat unlabeled data as labeled, such as bootstrapping (yarowsky, 1995),<papid> P95-1026 </papid>co-training (blum and mitchell, 1998), and self training (mcclosky et al, 2006).<papid> N06-1020 </papid></citsent>
<aftsection>
<nextsent>the primary direction of future research will be to apply the var-svm to new problems and tasks.
</nextsent>
<nextsent>there are many situations where system designer has an intuition about the role feature will play in prediction; the feature was perhaps added with this role in mind.
</nextsent>
<nextsent>by biasing the svm to use features as intended, var-svm may learn better with fewer training examples.
</nextsent>
<nextsent>the relationship between attributes and classes may be explicit when, e.g.,a rule-based system is optimized via discriminative learning, or annotators justify their decisions by indicating the relevant attributes (zaidan et al, 2007).<papid> N07-1033 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2479">
<title id=" W10-2921.xml">improved natural language learning via variance regularization support vector machines </title>
<section> future work.  </section>
<citcontext>
<prevsection>
<prevsent>there are many situations where system designer has an intuition about the role feature will play in prediction; the feature was perhaps added with this role in mind.
</prevsent>
<prevsent>by biasing the svm to use features as intended, var-svm may learn better with fewer training examples.
</prevsent>
</prevsection>
<citsent citstr=" N07-1033 ">
the relationship between attributes and classes may be explicit when, e.g.,a rule-based system is optimized via discriminative learning, or annotators justify their decisions by indicating the relevant attributes (zaidan et al, 2007).<papid> N07-1033 </papid></citsent>
<aftsection>
<nextsent>also, if features are priori thought tohave different predictive worth, the attribute values could be scaled such that variance regularization, as we formulated it, has the desired effect.
</nextsent>
<nextsent>other avenues of future work will be to extend the var-svm in three directions: efficiency, representational power, and problem domain.
</nextsent>
<nextsent>while we optimized the var-svm objective incplex, general purpose qp-solvers do not exploit the special structure of [the svm optimiza tion] problem,?
</nextsent>
<nextsent>and consequently often train intime super-linear with the number of training examples (joachims et al, 2009).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2480">
<title id=" W10-1102.xml">extracting information for generating a diabetes report card from free text in physicians notes </title>
<section> method.  </section>
<citcontext>
<prevsection>
<prevsent>all formatting information is stripped except for bold and italic font information and paragraph boundaries the paragraphs in the document are further broken down into sentences and tokens.
</prevsent>
<prevsent>we use opennlp maxent1 library to do sentence boundary detection and tokenization.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
opennlp max ent is based on maximum entropy algorithms described in ratnaparkhi (1998) and berger et al (1996).<papid> J96-1002 </papid></citsent>
<aftsection>
<nextsent>the opennlp statistical tagger is used to assign syntactic tags to the tokens.
</nextsent>
<nextsent>data extraction: in this phase the system extracts all potential numerical values and assigns them labels.
</nextsent>
<nextsent>the system loops through all of the tokens in the document, testing for numerical values.
</nextsent>
<nextsent>it tests each numerical token against set of regular expressions and assigns them list of potential labels based on the regular expression it matches.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2481">
<title id=" W10-2926.xml">on reverse feature engineering of syntactic tree kernels </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>comparative experiments on three interesting and very diverse classification tasks, i.e.question classification, relation extraction and semantic role labeling, support our theoretical findings and demonstrate the algorithm performance.
</prevsent>
<prevsent>kernel functions are very effective at modeling diverse linguistic phenomena by implicitly representing data in high dimensional spaces, e.g.
</prevsent>
</prevsection>
<citsent citstr=" P04-1054 ">
(cumby and roth, 2003; culotta and sorensen, 2004; <papid> P04-1054 </papid>kudo et al, 2005; <papid> P05-1024 </papid>moschitti et al, 2008).<papid> J08-2003 </papid></citsent>
<aftsection>
<nextsent>however, the implicit nature of the kernel space causes two major drawbacks: (1) high computational costs for learning and classification, and (2) the impossibility to identify the most importantfeatures.
</nextsent>
<nextsent>a solution to both problems is the application of feature selection techniques.
</nextsent>
<nextsent>in particular, the problem of feature selection in tree kernel (tk) spaces has already been addressed by previous work in nlp, e.g.
</nextsent>
<nextsent>(kudo and matsumoto, 2003; <papid> P03-1004 </papid>suzuki and isozaki, 2005).however, these approaches lack theoretical characterization of the problem that could support and justify the design of more effective algorithms.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2482">
<title id=" W10-2926.xml">on reverse feature engineering of syntactic tree kernels </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>comparative experiments on three interesting and very diverse classification tasks, i.e.question classification, relation extraction and semantic role labeling, support our theoretical findings and demonstrate the algorithm performance.
</prevsent>
<prevsent>kernel functions are very effective at modeling diverse linguistic phenomena by implicitly representing data in high dimensional spaces, e.g.
</prevsent>
</prevsection>
<citsent citstr=" P05-1024 ">
(cumby and roth, 2003; culotta and sorensen, 2004; <papid> P04-1054 </papid>kudo et al, 2005; <papid> P05-1024 </papid>moschitti et al, 2008).<papid> J08-2003 </papid></citsent>
<aftsection>
<nextsent>however, the implicit nature of the kernel space causes two major drawbacks: (1) high computational costs for learning and classification, and (2) the impossibility to identify the most importantfeatures.
</nextsent>
<nextsent>a solution to both problems is the application of feature selection techniques.
</nextsent>
<nextsent>in particular, the problem of feature selection in tree kernel (tk) spaces has already been addressed by previous work in nlp, e.g.
</nextsent>
<nextsent>(kudo and matsumoto, 2003; <papid> P03-1004 </papid>suzuki and isozaki, 2005).however, these approaches lack theoretical characterization of the problem that could support and justify the design of more effective algorithms.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2483">
<title id=" W10-2926.xml">on reverse feature engineering of syntactic tree kernels </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>comparative experiments on three interesting and very diverse classification tasks, i.e.question classification, relation extraction and semantic role labeling, support our theoretical findings and demonstrate the algorithm performance.
</prevsent>
<prevsent>kernel functions are very effective at modeling diverse linguistic phenomena by implicitly representing data in high dimensional spaces, e.g.
</prevsent>
</prevsection>
<citsent citstr=" J08-2003 ">
(cumby and roth, 2003; culotta and sorensen, 2004; <papid> P04-1054 </papid>kudo et al, 2005; <papid> P05-1024 </papid>moschitti et al, 2008).<papid> J08-2003 </papid></citsent>
<aftsection>
<nextsent>however, the implicit nature of the kernel space causes two major drawbacks: (1) high computational costs for learning and classification, and (2) the impossibility to identify the most importantfeatures.
</nextsent>
<nextsent>a solution to both problems is the application of feature selection techniques.
</nextsent>
<nextsent>in particular, the problem of feature selection in tree kernel (tk) spaces has already been addressed by previous work in nlp, e.g.
</nextsent>
<nextsent>(kudo and matsumoto, 2003; <papid> P03-1004 </papid>suzuki and isozaki, 2005).however, these approaches lack theoretical characterization of the problem that could support and justify the design of more effective algorithms.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2484">
<title id=" W10-2926.xml">on reverse feature engineering of syntactic tree kernels </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a solution to both problems is the application of feature selection techniques.
</prevsent>
<prevsent>in particular, the problem of feature selection in tree kernel (tk) spaces has already been addressed by previous work in nlp, e.g.
</prevsent>
</prevsection>
<citsent citstr=" P03-1004 ">
(kudo and matsumoto, 2003; <papid> P03-1004 </papid>suzuki and isozaki, 2005).however, these approaches lack theoretical characterization of the problem that could support and justify the design of more effective algorithms.</citsent>
<aftsection>
<nextsent>in (pighin and moschitti, 2009<papid> W09-1106 </papid>a) and (pighin and moschitti, 2009<papid> W09-1106 </papid>b) (p&m;), we presented heuristic framework for feature selection in kernel spaces that selects features based on the components of the weight vector, ~w, optimized by support vector machines (svms).</nextsent>
<nextsent>this method appears to be very effective, as the model accuracy does not significantly decrease even when large number of features are filtered out.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2485">
<title id=" W10-2926.xml">on reverse feature engineering of syntactic tree kernels </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in particular, the problem of feature selection in tree kernel (tk) spaces has already been addressed by previous work in nlp, e.g.
</prevsent>
<prevsent>(kudo and matsumoto, 2003; <papid> P03-1004 </papid>suzuki and isozaki, 2005).however, these approaches lack theoretical characterization of the problem that could support and justify the design of more effective algorithms.</prevsent>
</prevsection>
<citsent citstr=" W09-1106 ">
in (pighin and moschitti, 2009<papid> W09-1106 </papid>a) and (pighin and moschitti, 2009<papid> W09-1106 </papid>b) (p&m;), we presented heuristic framework for feature selection in kernel spaces that selects features based on the components of the weight vector, ~w, optimized by support vector machines (svms).</citsent>
<aftsection>
<nextsent>this method appears to be very effective, as the model accuracy does not significantly decrease even when large number of features are filtered out.
</nextsent>
<nextsent>unfortunately,we could not provide theoretical or intuitive motivations to justify our proposed apporach.in this paper, we present and empirically validate theory which aims at filling the abovementioned gaps.
</nextsent>
<nextsent>in particular we provide: (i) proof of the equation for the exact computation of feature weights induced by tk functions (collinsand duffy, 2002); (<papid> P02-1034 </papid>ii) theoretical characterization of feature selection based on ?~w?.</nextsent>
<nextsent>we show that if feature selection does not sensibly reduces?~w?, the margin associated with ~w does not sensibly decrease as well.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2501">
<title id=" W10-2926.xml">on reverse feature engineering of syntactic tree kernels </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this method appears to be very effective, as the model accuracy does not significantly decrease even when large number of features are filtered out.
</prevsent>
<prevsent>unfortunately,we could not provide theoretical or intuitive motivations to justify our proposed apporach.in this paper, we present and empirically validate theory which aims at filling the abovementioned gaps.
</prevsent>
</prevsection>
<citsent citstr=" P02-1034 ">
in particular we provide: (i) proof of the equation for the exact computation of feature weights induced by tk functions (collinsand duffy, 2002); (<papid> P02-1034 </papid>ii) theoretical characterization of feature selection based on ?~w?.</citsent>
<aftsection>
<nextsent>we show that if feature selection does not sensibly reduces?~w?, the margin associated with ~w does not sensibly decrease as well.
</nextsent>
<nextsent>consequently, the theoretical upper bound to the probability error does not sensibly increases; (iii) proof that the convolutive nature of tk allows for filtering out an exponential number of features with small ?~w? decrease.
</nextsent>
<nextsent>the combination of (ii) with (iii) suggests that an extremely aggressive feature selection can be applied.
</nextsent>
<nextsent>we describe greedy algorithm that exploits these results.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2510">
<title id=" W10-2926.xml">on reverse feature engineering of syntactic tree kernels </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>suzuki and isozaki (2005) present an embedded approach to feature selection for convolution kernels based on 2 driven relevance assessment.
</prevsent>
<prevsent>with respect to their work, the main differences in the approach that we propose are that we want to exploit the svm op timizer to select the most relevant features, and to be able to observe the relevant fragments.
</prevsent>
</prevsection>
<citsent citstr=" W03-1012 ">
regarding work that may directly benefit from reverse kernel engineering is worthwhile mention ing: (cancedda et al, 2003; shen et al, 2003;<papid> W03-1012 </papid>daume?</citsent>
<aftsection>
<nextsent>iii and marcu, 2004; giuglea and moschitti, 2004; toutanova et al, 2004; <papid> W04-3222 </papid>kazama and torisawa, 2005; <papid> H05-1018 </papid>titov and henderson, 2006; <papid> W06-2902 </papid>kate and mooney, 2006; <papid> P06-1115 </papid>zhang et al, 2006; <papid> N06-1037 </papid>bloehdornet al, 2006; bloehdorn and moschitti, 2007; moschitti and zanzotto, 2007; surdeanu et al, 2008; <papid> P08-1082 </papid>moschitti, 2008; moschitti and quarteroni, 2008; <papid> P08-2029 </papid>martins et al, 2009; nguyen et al, 2009<papid> D09-1143 </papid>a)</nextsent>
<nextsent>the high-level description of our feature selection technique is as follows: we start by learning an stk model and we greedily explore the support vectors in search for the most relevant fragments.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2511">
<title id=" W10-2926.xml">on reverse feature engineering of syntactic tree kernels </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>with respect to their work, the main differences in the approach that we propose are that we want to exploit the svm op timizer to select the most relevant features, and to be able to observe the relevant fragments.
</prevsent>
<prevsent>regarding work that may directly benefit from reverse kernel engineering is worthwhile mention ing: (cancedda et al, 2003; shen et al, 2003;<papid> W03-1012 </papid>daume?</prevsent>
</prevsection>
<citsent citstr=" W04-3222 ">
iii and marcu, 2004; giuglea and moschitti, 2004; toutanova et al, 2004; <papid> W04-3222 </papid>kazama and torisawa, 2005; <papid> H05-1018 </papid>titov and henderson, 2006; <papid> W06-2902 </papid>kate and mooney, 2006; <papid> P06-1115 </papid>zhang et al, 2006; <papid> N06-1037 </papid>bloehdornet al, 2006; bloehdorn and moschitti, 2007; moschitti and zanzotto, 2007; surdeanu et al, 2008; <papid> P08-1082 </papid>moschitti, 2008; moschitti and quarteroni, 2008; <papid> P08-2029 </papid>martins et al, 2009; nguyen et al, 2009<papid> D09-1143 </papid>a)</citsent>
<aftsection>
<nextsent>the high-level description of our feature selection technique is as follows: we start by learning an stk model and we greedily explore the support vectors in search for the most relevant fragments.
</nextsent>
<nextsent>we store them in an index, and then we decode (orlinearize) all the trees in the dataset, i.e. we represent them as vectors in linear space where only very small subset of the fragments in the original space are accounted for.
</nextsent>
<nextsent>these vectors are then employed for learning and classification in the linear space.
</nextsent>
<nextsent>to explore the fragment space defined by set of support vectors, we adopt the greedy strategy described in algorithm 5.1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2512">
<title id=" W10-2926.xml">on reverse feature engineering of syntactic tree kernels </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>with respect to their work, the main differences in the approach that we propose are that we want to exploit the svm op timizer to select the most relevant features, and to be able to observe the relevant fragments.
</prevsent>
<prevsent>regarding work that may directly benefit from reverse kernel engineering is worthwhile mention ing: (cancedda et al, 2003; shen et al, 2003;<papid> W03-1012 </papid>daume?</prevsent>
</prevsection>
<citsent citstr=" H05-1018 ">
iii and marcu, 2004; giuglea and moschitti, 2004; toutanova et al, 2004; <papid> W04-3222 </papid>kazama and torisawa, 2005; <papid> H05-1018 </papid>titov and henderson, 2006; <papid> W06-2902 </papid>kate and mooney, 2006; <papid> P06-1115 </papid>zhang et al, 2006; <papid> N06-1037 </papid>bloehdornet al, 2006; bloehdorn and moschitti, 2007; moschitti and zanzotto, 2007; surdeanu et al, 2008; <papid> P08-1082 </papid>moschitti, 2008; moschitti and quarteroni, 2008; <papid> P08-2029 </papid>martins et al, 2009; nguyen et al, 2009<papid> D09-1143 </papid>a)</citsent>
<aftsection>
<nextsent>the high-level description of our feature selection technique is as follows: we start by learning an stk model and we greedily explore the support vectors in search for the most relevant fragments.
</nextsent>
<nextsent>we store them in an index, and then we decode (orlinearize) all the trees in the dataset, i.e. we represent them as vectors in linear space where only very small subset of the fragments in the original space are accounted for.
</nextsent>
<nextsent>these vectors are then employed for learning and classification in the linear space.
</nextsent>
<nextsent>to explore the fragment space defined by set of support vectors, we adopt the greedy strategy described in algorithm 5.1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2513">
<title id=" W10-2926.xml">on reverse feature engineering of syntactic tree kernels </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>with respect to their work, the main differences in the approach that we propose are that we want to exploit the svm op timizer to select the most relevant features, and to be able to observe the relevant fragments.
</prevsent>
<prevsent>regarding work that may directly benefit from reverse kernel engineering is worthwhile mention ing: (cancedda et al, 2003; shen et al, 2003;<papid> W03-1012 </papid>daume?</prevsent>
</prevsection>
<citsent citstr=" W06-2902 ">
iii and marcu, 2004; giuglea and moschitti, 2004; toutanova et al, 2004; <papid> W04-3222 </papid>kazama and torisawa, 2005; <papid> H05-1018 </papid>titov and henderson, 2006; <papid> W06-2902 </papid>kate and mooney, 2006; <papid> P06-1115 </papid>zhang et al, 2006; <papid> N06-1037 </papid>bloehdornet al, 2006; bloehdorn and moschitti, 2007; moschitti and zanzotto, 2007; surdeanu et al, 2008; <papid> P08-1082 </papid>moschitti, 2008; moschitti and quarteroni, 2008; <papid> P08-2029 </papid>martins et al, 2009; nguyen et al, 2009<papid> D09-1143 </papid>a)</citsent>
<aftsection>
<nextsent>the high-level description of our feature selection technique is as follows: we start by learning an stk model and we greedily explore the support vectors in search for the most relevant fragments.
</nextsent>
<nextsent>we store them in an index, and then we decode (orlinearize) all the trees in the dataset, i.e. we represent them as vectors in linear space where only very small subset of the fragments in the original space are accounted for.
</nextsent>
<nextsent>these vectors are then employed for learning and classification in the linear space.
</nextsent>
<nextsent>to explore the fragment space defined by set of support vectors, we adopt the greedy strategy described in algorithm 5.1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2514">
<title id=" W10-2926.xml">on reverse feature engineering of syntactic tree kernels </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>with respect to their work, the main differences in the approach that we propose are that we want to exploit the svm op timizer to select the most relevant features, and to be able to observe the relevant fragments.
</prevsent>
<prevsent>regarding work that may directly benefit from reverse kernel engineering is worthwhile mention ing: (cancedda et al, 2003; shen et al, 2003;<papid> W03-1012 </papid>daume?</prevsent>
</prevsection>
<citsent citstr=" P06-1115 ">
iii and marcu, 2004; giuglea and moschitti, 2004; toutanova et al, 2004; <papid> W04-3222 </papid>kazama and torisawa, 2005; <papid> H05-1018 </papid>titov and henderson, 2006; <papid> W06-2902 </papid>kate and mooney, 2006; <papid> P06-1115 </papid>zhang et al, 2006; <papid> N06-1037 </papid>bloehdornet al, 2006; bloehdorn and moschitti, 2007; moschitti and zanzotto, 2007; surdeanu et al, 2008; <papid> P08-1082 </papid>moschitti, 2008; moschitti and quarteroni, 2008; <papid> P08-2029 </papid>martins et al, 2009; nguyen et al, 2009<papid> D09-1143 </papid>a)</citsent>
<aftsection>
<nextsent>the high-level description of our feature selection technique is as follows: we start by learning an stk model and we greedily explore the support vectors in search for the most relevant fragments.
</nextsent>
<nextsent>we store them in an index, and then we decode (orlinearize) all the trees in the dataset, i.e. we represent them as vectors in linear space where only very small subset of the fragments in the original space are accounted for.
</nextsent>
<nextsent>these vectors are then employed for learning and classification in the linear space.
</nextsent>
<nextsent>to explore the fragment space defined by set of support vectors, we adopt the greedy strategy described in algorithm 5.1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2515">
<title id=" W10-2926.xml">on reverse feature engineering of syntactic tree kernels </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>with respect to their work, the main differences in the approach that we propose are that we want to exploit the svm op timizer to select the most relevant features, and to be able to observe the relevant fragments.
</prevsent>
<prevsent>regarding work that may directly benefit from reverse kernel engineering is worthwhile mention ing: (cancedda et al, 2003; shen et al, 2003;<papid> W03-1012 </papid>daume?</prevsent>
</prevsection>
<citsent citstr=" N06-1037 ">
iii and marcu, 2004; giuglea and moschitti, 2004; toutanova et al, 2004; <papid> W04-3222 </papid>kazama and torisawa, 2005; <papid> H05-1018 </papid>titov and henderson, 2006; <papid> W06-2902 </papid>kate and mooney, 2006; <papid> P06-1115 </papid>zhang et al, 2006; <papid> N06-1037 </papid>bloehdornet al, 2006; bloehdorn and moschitti, 2007; moschitti and zanzotto, 2007; surdeanu et al, 2008; <papid> P08-1082 </papid>moschitti, 2008; moschitti and quarteroni, 2008; <papid> P08-2029 </papid>martins et al, 2009; nguyen et al, 2009<papid> D09-1143 </papid>a)</citsent>
<aftsection>
<nextsent>the high-level description of our feature selection technique is as follows: we start by learning an stk model and we greedily explore the support vectors in search for the most relevant fragments.
</nextsent>
<nextsent>we store them in an index, and then we decode (orlinearize) all the trees in the dataset, i.e. we represent them as vectors in linear space where only very small subset of the fragments in the original space are accounted for.
</nextsent>
<nextsent>these vectors are then employed for learning and classification in the linear space.
</nextsent>
<nextsent>to explore the fragment space defined by set of support vectors, we adopt the greedy strategy described in algorithm 5.1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2516">
<title id=" W10-2926.xml">on reverse feature engineering of syntactic tree kernels </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>with respect to their work, the main differences in the approach that we propose are that we want to exploit the svm op timizer to select the most relevant features, and to be able to observe the relevant fragments.
</prevsent>
<prevsent>regarding work that may directly benefit from reverse kernel engineering is worthwhile mention ing: (cancedda et al, 2003; shen et al, 2003;<papid> W03-1012 </papid>daume?</prevsent>
</prevsection>
<citsent citstr=" P08-1082 ">
iii and marcu, 2004; giuglea and moschitti, 2004; toutanova et al, 2004; <papid> W04-3222 </papid>kazama and torisawa, 2005; <papid> H05-1018 </papid>titov and henderson, 2006; <papid> W06-2902 </papid>kate and mooney, 2006; <papid> P06-1115 </papid>zhang et al, 2006; <papid> N06-1037 </papid>bloehdornet al, 2006; bloehdorn and moschitti, 2007; moschitti and zanzotto, 2007; surdeanu et al, 2008; <papid> P08-1082 </papid>moschitti, 2008; moschitti and quarteroni, 2008; <papid> P08-2029 </papid>martins et al, 2009; nguyen et al, 2009<papid> D09-1143 </papid>a)</citsent>
<aftsection>
<nextsent>the high-level description of our feature selection technique is as follows: we start by learning an stk model and we greedily explore the support vectors in search for the most relevant fragments.
</nextsent>
<nextsent>we store them in an index, and then we decode (orlinearize) all the trees in the dataset, i.e. we represent them as vectors in linear space where only very small subset of the fragments in the original space are accounted for.
</nextsent>
<nextsent>these vectors are then employed for learning and classification in the linear space.
</nextsent>
<nextsent>to explore the fragment space defined by set of support vectors, we adopt the greedy strategy described in algorithm 5.1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2517">
<title id=" W10-2926.xml">on reverse feature engineering of syntactic tree kernels </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>with respect to their work, the main differences in the approach that we propose are that we want to exploit the svm op timizer to select the most relevant features, and to be able to observe the relevant fragments.
</prevsent>
<prevsent>regarding work that may directly benefit from reverse kernel engineering is worthwhile mention ing: (cancedda et al, 2003; shen et al, 2003;<papid> W03-1012 </papid>daume?</prevsent>
</prevsection>
<citsent citstr=" P08-2029 ">
iii and marcu, 2004; giuglea and moschitti, 2004; toutanova et al, 2004; <papid> W04-3222 </papid>kazama and torisawa, 2005; <papid> H05-1018 </papid>titov and henderson, 2006; <papid> W06-2902 </papid>kate and mooney, 2006; <papid> P06-1115 </papid>zhang et al, 2006; <papid> N06-1037 </papid>bloehdornet al, 2006; bloehdorn and moschitti, 2007; moschitti and zanzotto, 2007; surdeanu et al, 2008; <papid> P08-1082 </papid>moschitti, 2008; moschitti and quarteroni, 2008; <papid> P08-2029 </papid>martins et al, 2009; nguyen et al, 2009<papid> D09-1143 </papid>a)</citsent>
<aftsection>
<nextsent>the high-level description of our feature selection technique is as follows: we start by learning an stk model and we greedily explore the support vectors in search for the most relevant fragments.
</nextsent>
<nextsent>we store them in an index, and then we decode (orlinearize) all the trees in the dataset, i.e. we represent them as vectors in linear space where only very small subset of the fragments in the original space are accounted for.
</nextsent>
<nextsent>these vectors are then employed for learning and classification in the linear space.
</nextsent>
<nextsent>to explore the fragment space defined by set of support vectors, we adopt the greedy strategy described in algorithm 5.1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2518">
<title id=" W10-2926.xml">on reverse feature engineering of syntactic tree kernels </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>with respect to their work, the main differences in the approach that we propose are that we want to exploit the svm op timizer to select the most relevant features, and to be able to observe the relevant fragments.
</prevsent>
<prevsent>regarding work that may directly benefit from reverse kernel engineering is worthwhile mention ing: (cancedda et al, 2003; shen et al, 2003;<papid> W03-1012 </papid>daume?</prevsent>
</prevsection>
<citsent citstr=" D09-1143 ">
iii and marcu, 2004; giuglea and moschitti, 2004; toutanova et al, 2004; <papid> W04-3222 </papid>kazama and torisawa, 2005; <papid> H05-1018 </papid>titov and henderson, 2006; <papid> W06-2902 </papid>kate and mooney, 2006; <papid> P06-1115 </papid>zhang et al, 2006; <papid> N06-1037 </papid>bloehdornet al, 2006; bloehdorn and moschitti, 2007; moschitti and zanzotto, 2007; surdeanu et al, 2008; <papid> P08-1082 </papid>moschitti, 2008; moschitti and quarteroni, 2008; <papid> P08-2029 </papid>martins et al, 2009; nguyen et al, 2009<papid> D09-1143 </papid>a)</citsent>
<aftsection>
<nextsent>the high-level description of our feature selection technique is as follows: we start by learning an stk model and we greedily explore the support vectors in search for the most relevant fragments.
</nextsent>
<nextsent>we store them in an index, and then we decode (orlinearize) all the trees in the dataset, i.e. we represent them as vectors in linear space where only very small subset of the fragments in the original space are accounted for.
</nextsent>
<nextsent>these vectors are then employed for learning and classification in the linear space.
</nextsent>
<nextsent>to explore the fragment space defined by set of support vectors, we adopt the greedy strategy described in algorithm 5.1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2520">
<title id=" W10-2926.xml">on reverse feature engineering of syntactic tree kernels </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the trec 10 qa dataset accounts for 6,000 questions.
</prevsent>
<prevsent>for each question, we generate the full parse of the sentence and use it to train our models.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
automatic parses are obtained with the stanford parser6 (klein and manning, 2003), <papid> P03-1054 </papid>and we actually have only 5,953 sentences in our dataset due to parsing issues.</citsent>
<aftsection>
<nextsent>during preliminary experiments, we observed an uneven distribution of examples in the traditional training/test split (thesame used in p&m;).
</nextsent>
<nextsent>therefore, we used random selection to generate an unbiased split, with 5,468 sentences for training and 485 for testing.
</nextsent>
<nextsent>the resulting dataset is available for download at http://danielepighin.net/cms/research/ qc_dataset.tgz.
</nextsent>
<nextsent>relation extraction (re) the corpus consists of 348 documents, and contains seven relation classes defined over pairs ofmentions: physical, person/social, employ ment/membership/subsidiary, agent-artifact, per/org affiliation, gpe affiliation, and discourse.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2522">
<title id=" W10-2926.xml">on reverse feature engineering of syntactic tree kernels </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>overall, we used the setting and data defined in (nguyen et al., 2009<papid> D09-1143 </papid>b).</prevsent>
<prevsent>6 http://nlp.stanford.edu/software/lex-parser.shtml 228semantic role labeling (srl) srl can be decomposed into two tasks: boundary detection, where the word sequences that are arguments ofa predicate word are identified, and role classification, where each argument is assigned the proper role.</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
for these experiments we concentrated on this latter task and used exactly the same setup as p&amp;m.; we considered all the argument nodes of any of the six propbank (palmer et al, 2005) <papid> J05-1004 </papid>core roles7 (i.e. a0, . . .</citsent>
<aftsection>
<nextsent>, a5) from all the available training sections, i.e. 2 through 21, for total of 179,091 training instances.
</nextsent>
<nextsent>similarly, we collected 9,277 test instances from the annotations of section 23.
</nextsent>
<nextsent>6.1 model comparison.
</nextsent>
<nextsent>to show the validity of lemma 1 in practical scenarios, we compare the accuracy of our linearizedmodels against vanilla stk classifiers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2541">
<title id=" W10-2407.xml">transliteration mining with phonetic conflation and iterative training </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>for language pair, base set of 1,000 transliteration pairs were available for training.
</prevsent>
<prevsent>the rest of the paper is organized as follows: section 2 surveys prior work on transliteration mining; section 3 describes the tm approach and the proposed improvements; section 4 describes the experimental setup including the evaluation sets; section 5 reports on experimental results; and section 6 concludes the paper.
</prevsent>
</prevsection>
<citsent citstr=" P06-1142 ">
much work has been done on tm for different language pairs such as english-chinese (kuo et al, 2006; <papid> P06-1142 </papid>kuo et al, 2007; kuo et al, 2008; <papid> I08-4003 </papid>jin et al 2008;), <papid> I08-4002 </papid>english-tamil (saravanan and kumaran, 2008; <papid> I08-6004 </papid>udupa and khapra, 2010), english-korean (oh and isahara, 2006; oh and choi, 2006), eng lish-japanese (brill et al, 2001; oh and isahara, 2006), english-hindi (fei et al, 2003; mahesh and sinha, 2009), <papid> W09-3407 </papid>and english-russian (klementiev and roth, 2006).<papid> N06-1011 </papid></citsent>
<aftsection>
<nextsent>the most common approach for determining letter sequence mapping between two languages is using automatic letter alignment of training set of transliteration pairs.
</nextsent>
<nextsent>automatic alignment can be performed using different algorithms such as the em algorithm (kuo et al, 2008; <papid> I08-4003 </papid>lee and chang, 2003) <papid> W03-0317 </papid>or using an hmm aligner (udupa et al, 2009<papid> E09-1091 </papid>a; udupa et al, 2009<papid> E09-1091 </papid>b).</nextsent>
<nextsent>another method is to use automatic speech recognition confusion tables to extract phonetic ally equivalent character sequences to discover monolingual and cross lingual pronunciation variations (kuo and yang, 2005).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2542">
<title id=" W10-2407.xml">transliteration mining with phonetic conflation and iterative training </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>for language pair, base set of 1,000 transliteration pairs were available for training.
</prevsent>
<prevsent>the rest of the paper is organized as follows: section 2 surveys prior work on transliteration mining; section 3 describes the tm approach and the proposed improvements; section 4 describes the experimental setup including the evaluation sets; section 5 reports on experimental results; and section 6 concludes the paper.
</prevsent>
</prevsection>
<citsent citstr=" I08-4003 ">
much work has been done on tm for different language pairs such as english-chinese (kuo et al, 2006; <papid> P06-1142 </papid>kuo et al, 2007; kuo et al, 2008; <papid> I08-4003 </papid>jin et al 2008;), <papid> I08-4002 </papid>english-tamil (saravanan and kumaran, 2008; <papid> I08-6004 </papid>udupa and khapra, 2010), english-korean (oh and isahara, 2006; oh and choi, 2006), eng lish-japanese (brill et al, 2001; oh and isahara, 2006), english-hindi (fei et al, 2003; mahesh and sinha, 2009), <papid> W09-3407 </papid>and english-russian (klementiev and roth, 2006).<papid> N06-1011 </papid></citsent>
<aftsection>
<nextsent>the most common approach for determining letter sequence mapping between two languages is using automatic letter alignment of training set of transliteration pairs.
</nextsent>
<nextsent>automatic alignment can be performed using different algorithms such as the em algorithm (kuo et al, 2008; <papid> I08-4003 </papid>lee and chang, 2003) <papid> W03-0317 </papid>or using an hmm aligner (udupa et al, 2009<papid> E09-1091 </papid>a; udupa et al, 2009<papid> E09-1091 </papid>b).</nextsent>
<nextsent>another method is to use automatic speech recognition confusion tables to extract phonetic ally equivalent character sequences to discover monolingual and cross lingual pronunciation variations (kuo and yang, 2005).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2544">
<title id=" W10-2407.xml">transliteration mining with phonetic conflation and iterative training </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>for language pair, base set of 1,000 transliteration pairs were available for training.
</prevsent>
<prevsent>the rest of the paper is organized as follows: section 2 surveys prior work on transliteration mining; section 3 describes the tm approach and the proposed improvements; section 4 describes the experimental setup including the evaluation sets; section 5 reports on experimental results; and section 6 concludes the paper.
</prevsent>
</prevsection>
<citsent citstr=" I08-4002 ">
much work has been done on tm for different language pairs such as english-chinese (kuo et al, 2006; <papid> P06-1142 </papid>kuo et al, 2007; kuo et al, 2008; <papid> I08-4003 </papid>jin et al 2008;), <papid> I08-4002 </papid>english-tamil (saravanan and kumaran, 2008; <papid> I08-6004 </papid>udupa and khapra, 2010), english-korean (oh and isahara, 2006; oh and choi, 2006), eng lish-japanese (brill et al, 2001; oh and isahara, 2006), english-hindi (fei et al, 2003; mahesh and sinha, 2009), <papid> W09-3407 </papid>and english-russian (klementiev and roth, 2006).<papid> N06-1011 </papid></citsent>
<aftsection>
<nextsent>the most common approach for determining letter sequence mapping between two languages is using automatic letter alignment of training set of transliteration pairs.
</nextsent>
<nextsent>automatic alignment can be performed using different algorithms such as the em algorithm (kuo et al, 2008; <papid> I08-4003 </papid>lee and chang, 2003) <papid> W03-0317 </papid>or using an hmm aligner (udupa et al, 2009<papid> E09-1091 </papid>a; udupa et al, 2009<papid> E09-1091 </papid>b).</nextsent>
<nextsent>another method is to use automatic speech recognition confusion tables to extract phonetic ally equivalent character sequences to discover monolingual and cross lingual pronunciation variations (kuo and yang, 2005).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2545">
<title id=" W10-2407.xml">transliteration mining with phonetic conflation and iterative training </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>for language pair, base set of 1,000 transliteration pairs were available for training.
</prevsent>
<prevsent>the rest of the paper is organized as follows: section 2 surveys prior work on transliteration mining; section 3 describes the tm approach and the proposed improvements; section 4 describes the experimental setup including the evaluation sets; section 5 reports on experimental results; and section 6 concludes the paper.
</prevsent>
</prevsection>
<citsent citstr=" I08-6004 ">
much work has been done on tm for different language pairs such as english-chinese (kuo et al, 2006; <papid> P06-1142 </papid>kuo et al, 2007; kuo et al, 2008; <papid> I08-4003 </papid>jin et al 2008;), <papid> I08-4002 </papid>english-tamil (saravanan and kumaran, 2008; <papid> I08-6004 </papid>udupa and khapra, 2010), english-korean (oh and isahara, 2006; oh and choi, 2006), eng lish-japanese (brill et al, 2001; oh and isahara, 2006), english-hindi (fei et al, 2003; mahesh and sinha, 2009), <papid> W09-3407 </papid>and english-russian (klementiev and roth, 2006).<papid> N06-1011 </papid></citsent>
<aftsection>
<nextsent>the most common approach for determining letter sequence mapping between two languages is using automatic letter alignment of training set of transliteration pairs.
</nextsent>
<nextsent>automatic alignment can be performed using different algorithms such as the em algorithm (kuo et al, 2008; <papid> I08-4003 </papid>lee and chang, 2003) <papid> W03-0317 </papid>or using an hmm aligner (udupa et al, 2009<papid> E09-1091 </papid>a; udupa et al, 2009<papid> E09-1091 </papid>b).</nextsent>
<nextsent>another method is to use automatic speech recognition confusion tables to extract phonetic ally equivalent character sequences to discover monolingual and cross lingual pronunciation variations (kuo and yang, 2005).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2546">
<title id=" W10-2407.xml">transliteration mining with phonetic conflation and iterative training </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>for language pair, base set of 1,000 transliteration pairs were available for training.
</prevsent>
<prevsent>the rest of the paper is organized as follows: section 2 surveys prior work on transliteration mining; section 3 describes the tm approach and the proposed improvements; section 4 describes the experimental setup including the evaluation sets; section 5 reports on experimental results; and section 6 concludes the paper.
</prevsent>
</prevsection>
<citsent citstr=" W09-3407 ">
much work has been done on tm for different language pairs such as english-chinese (kuo et al, 2006; <papid> P06-1142 </papid>kuo et al, 2007; kuo et al, 2008; <papid> I08-4003 </papid>jin et al 2008;), <papid> I08-4002 </papid>english-tamil (saravanan and kumaran, 2008; <papid> I08-6004 </papid>udupa and khapra, 2010), english-korean (oh and isahara, 2006; oh and choi, 2006), eng lish-japanese (brill et al, 2001; oh and isahara, 2006), english-hindi (fei et al, 2003; mahesh and sinha, 2009), <papid> W09-3407 </papid>and english-russian (klementiev and roth, 2006).<papid> N06-1011 </papid></citsent>
<aftsection>
<nextsent>the most common approach for determining letter sequence mapping between two languages is using automatic letter alignment of training set of transliteration pairs.
</nextsent>
<nextsent>automatic alignment can be performed using different algorithms such as the em algorithm (kuo et al, 2008; <papid> I08-4003 </papid>lee and chang, 2003) <papid> W03-0317 </papid>or using an hmm aligner (udupa et al, 2009<papid> E09-1091 </papid>a; udupa et al, 2009<papid> E09-1091 </papid>b).</nextsent>
<nextsent>another method is to use automatic speech recognition confusion tables to extract phonetic ally equivalent character sequences to discover monolingual and cross lingual pronunciation variations (kuo and yang, 2005).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2547">
<title id=" W10-2407.xml">transliteration mining with phonetic conflation and iterative training </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>for language pair, base set of 1,000 transliteration pairs were available for training.
</prevsent>
<prevsent>the rest of the paper is organized as follows: section 2 surveys prior work on transliteration mining; section 3 describes the tm approach and the proposed improvements; section 4 describes the experimental setup including the evaluation sets; section 5 reports on experimental results; and section 6 concludes the paper.
</prevsent>
</prevsection>
<citsent citstr=" N06-1011 ">
much work has been done on tm for different language pairs such as english-chinese (kuo et al, 2006; <papid> P06-1142 </papid>kuo et al, 2007; kuo et al, 2008; <papid> I08-4003 </papid>jin et al 2008;), <papid> I08-4002 </papid>english-tamil (saravanan and kumaran, 2008; <papid> I08-6004 </papid>udupa and khapra, 2010), english-korean (oh and isahara, 2006; oh and choi, 2006), eng lish-japanese (brill et al, 2001; oh and isahara, 2006), english-hindi (fei et al, 2003; mahesh and sinha, 2009), <papid> W09-3407 </papid>and english-russian (klementiev and roth, 2006).<papid> N06-1011 </papid></citsent>
<aftsection>
<nextsent>the most common approach for determining letter sequence mapping between two languages is using automatic letter alignment of training set of transliteration pairs.
</nextsent>
<nextsent>automatic alignment can be performed using different algorithms such as the em algorithm (kuo et al, 2008; <papid> I08-4003 </papid>lee and chang, 2003) <papid> W03-0317 </papid>or using an hmm aligner (udupa et al, 2009<papid> E09-1091 </papid>a; udupa et al, 2009<papid> E09-1091 </papid>b).</nextsent>
<nextsent>another method is to use automatic speech recognition confusion tables to extract phonetic ally equivalent character sequences to discover monolingual and cross lingual pronunciation variations (kuo and yang, 2005).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2550">
<title id=" W10-2407.xml">transliteration mining with phonetic conflation and iterative training </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>much work has been done on tm for different language pairs such as english-chinese (kuo et al, 2006; <papid> P06-1142 </papid>kuo et al, 2007; kuo et al, 2008; <papid> I08-4003 </papid>jin et al 2008;), <papid> I08-4002 </papid>english-tamil (saravanan and kumaran, 2008; <papid> I08-6004 </papid>udupa and khapra, 2010), english-korean (oh and isahara, 2006; oh and choi, 2006), eng lish-japanese (brill et al, 2001; oh and isahara, 2006), english-hindi (fei et al, 2003; mahesh and sinha, 2009), <papid> W09-3407 </papid>and english-russian (klementiev and roth, 2006).<papid> N06-1011 </papid></prevsent>
<prevsent>the most common approach for determining letter sequence mapping between two languages is using automatic letter alignment of training set of transliteration pairs.</prevsent>
</prevsection>
<citsent citstr=" W03-0317 ">
automatic alignment can be performed using different algorithms such as the em algorithm (kuo et al, 2008; <papid> I08-4003 </papid>lee and chang, 2003) <papid> W03-0317 </papid>or using an hmm aligner (udupa et al, 2009<papid> E09-1091 </papid>a; udupa et al, 2009<papid> E09-1091 </papid>b).</citsent>
<aftsection>
<nextsent>another method is to use automatic speech recognition confusion tables to extract phonetic ally equivalent character sequences to discover monolingual and cross lingual pronunciation variations (kuo and yang, 2005).
</nextsent>
<nextsent>alternatively, letters can be mapped into common character set.
</nextsent>
<nextsent>one example of that is to use predefined transliteration scheme to trans literate word in one character set into another character set (oh and choi, 2006).
</nextsent>
<nextsent>different methods were proposed to ascertain if two words can be transliterations of each other.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2551">
<title id=" W10-2407.xml">transliteration mining with phonetic conflation and iterative training </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>much work has been done on tm for different language pairs such as english-chinese (kuo et al, 2006; <papid> P06-1142 </papid>kuo et al, 2007; kuo et al, 2008; <papid> I08-4003 </papid>jin et al 2008;), <papid> I08-4002 </papid>english-tamil (saravanan and kumaran, 2008; <papid> I08-6004 </papid>udupa and khapra, 2010), english-korean (oh and isahara, 2006; oh and choi, 2006), eng lish-japanese (brill et al, 2001; oh and isahara, 2006), english-hindi (fei et al, 2003; mahesh and sinha, 2009), <papid> W09-3407 </papid>and english-russian (klementiev and roth, 2006).<papid> N06-1011 </papid></prevsent>
<prevsent>the most common approach for determining letter sequence mapping between two languages is using automatic letter alignment of training set of transliteration pairs.</prevsent>
</prevsection>
<citsent citstr=" E09-1091 ">
automatic alignment can be performed using different algorithms such as the em algorithm (kuo et al, 2008; <papid> I08-4003 </papid>lee and chang, 2003) <papid> W03-0317 </papid>or using an hmm aligner (udupa et al, 2009<papid> E09-1091 </papid>a; udupa et al, 2009<papid> E09-1091 </papid>b).</citsent>
<aftsection>
<nextsent>another method is to use automatic speech recognition confusion tables to extract phonetic ally equivalent character sequences to discover monolingual and cross lingual pronunciation variations (kuo and yang, 2005).
</nextsent>
<nextsent>alternatively, letters can be mapped into common character set.
</nextsent>
<nextsent>one example of that is to use predefined transliteration scheme to trans literate word in one character set into another character set (oh and choi, 2006).
</nextsent>
<nextsent>different methods were proposed to ascertain if two words can be transliterations of each other.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2562">
<title id=" W10-2407.xml">transliteration mining with phonetic conflation and iterative training </title>
<section> transliteration mining.  </section>
<citcontext>
<prevsection>
<prevsent>soundex like letter conflation and iterative transliterator training was used to improve recall.
</prevsent>
<prevsent>akin to phrasal alignment in machine translation, character sequence alignment was treated as word alignment problem between parallel sentences, where transliterations were treated as if they were sentences and the characters from which they were composed were treated as if they were words.
</prevsent>
</prevsection>
<citsent citstr=" W07-0711 ">
the alignment was performed using bayesian learner that trained on word dependent transition models for hmm based word alignment (he, 2007).<papid> W07-0711 </papid></citsent>
<aftsection>
<nextsent>alignment produced mapping of source character sequence to target character sequence along with the probability of source given target.
</nextsent>
<nextsent>for all the work reported herein, given an english- foreign language transliteration candidate pair, english was treated as the target language and the foreign language as the source.
</nextsent>
<nextsent>given foreign source language word sequence and an english target word sequence , is potential transliteration of . given fi, composed of the character sequence f1 ? fo, and ej, composed of the character sequence e1 ? ep, p(fi|ej) is calculated using the trained model, as follows: ( | ) ? the non-overlapping segments fx ? fy are generated by finding all possible 2 n-1 segment ations of the word fi.
</nextsent>
<nextsent>for example, given man? then all possible segment ations are (m,a,n), (ma,n), (m,an), and (man).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2563">
<title id=" W10-3503.xml">extending english ace 2005 corpus annotation with ground truth links to wikipedia </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>inthis paper we will illustrate an on-going annotation effort which aims at adding manual annotation layer connecting an existing annotated corpus such as the english ace-2005 dataset1 to ccr such as wikipedia.
</prevsent>
<prevsent>this effort will produce new integrated resource which can be useful for the coreference resolution task.coreference resolution is the task of identifying which mentions, i.e. individual textual descriptions usually realized as noun phrases or pronouns, refer to the same entity.
</prevsent>
</prevsection>
<citsent citstr=" N06-1025 ">
to solve this task, especially in the case of non-pronominal coreference, researchers have recently started to exploit semantic knowledge, e.g. trying to calculate 1http://projects.ldc.upenn.edu/ace/ the semantic similarity of mentions (ponzetto and strube, 2006) <papid> N06-1025 </papid>or their semantic classes (ng, 2007; <papid> P07-1068 </papid>soon et al, 2001).<papid> J01-4004 </papid></citsent>
<aftsection>
<nextsent>up to now, wordnet has beenone of the most frequently used sources of semantic knowledge for the coreference resolution task (soon et al, 2001; <papid> J01-4004 </papid>ng and cardie, 2002).<papid> P02-1014 </papid></nextsent>
<nextsent>researchers have shown, however, that wordnet has some limits.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2564">
<title id=" W10-3503.xml">extending english ace 2005 corpus annotation with ground truth links to wikipedia </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>inthis paper we will illustrate an on-going annotation effort which aims at adding manual annotation layer connecting an existing annotated corpus such as the english ace-2005 dataset1 to ccr such as wikipedia.
</prevsent>
<prevsent>this effort will produce new integrated resource which can be useful for the coreference resolution task.coreference resolution is the task of identifying which mentions, i.e. individual textual descriptions usually realized as noun phrases or pronouns, refer to the same entity.
</prevsent>
</prevsection>
<citsent citstr=" P07-1068 ">
to solve this task, especially in the case of non-pronominal coreference, researchers have recently started to exploit semantic knowledge, e.g. trying to calculate 1http://projects.ldc.upenn.edu/ace/ the semantic similarity of mentions (ponzetto and strube, 2006) <papid> N06-1025 </papid>or their semantic classes (ng, 2007; <papid> P07-1068 </papid>soon et al, 2001).<papid> J01-4004 </papid></citsent>
<aftsection>
<nextsent>up to now, wordnet has beenone of the most frequently used sources of semantic knowledge for the coreference resolution task (soon et al, 2001; <papid> J01-4004 </papid>ng and cardie, 2002).<papid> P02-1014 </papid></nextsent>
<nextsent>researchers have shown, however, that wordnet has some limits.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2566">
<title id=" W10-3503.xml">extending english ace 2005 corpus annotation with ground truth links to wikipedia </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>inthis paper we will illustrate an on-going annotation effort which aims at adding manual annotation layer connecting an existing annotated corpus such as the english ace-2005 dataset1 to ccr such as wikipedia.
</prevsent>
<prevsent>this effort will produce new integrated resource which can be useful for the coreference resolution task.coreference resolution is the task of identifying which mentions, i.e. individual textual descriptions usually realized as noun phrases or pronouns, refer to the same entity.
</prevsent>
</prevsection>
<citsent citstr=" J01-4004 ">
to solve this task, especially in the case of non-pronominal coreference, researchers have recently started to exploit semantic knowledge, e.g. trying to calculate 1http://projects.ldc.upenn.edu/ace/ the semantic similarity of mentions (ponzetto and strube, 2006) <papid> N06-1025 </papid>or their semantic classes (ng, 2007; <papid> P07-1068 </papid>soon et al, 2001).<papid> J01-4004 </papid></citsent>
<aftsection>
<nextsent>up to now, wordnet has beenone of the most frequently used sources of semantic knowledge for the coreference resolution task (soon et al, 2001; <papid> J01-4004 </papid>ng and cardie, 2002).<papid> P02-1014 </papid></nextsent>
<nextsent>researchers have shown, however, that wordnet has some limits.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2568">
<title id=" W10-3503.xml">extending english ace 2005 corpus annotation with ground truth links to wikipedia </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this effort will produce new integrated resource which can be useful for the coreference resolution task.coreference resolution is the task of identifying which mentions, i.e. individual textual descriptions usually realized as noun phrases or pronouns, refer to the same entity.
</prevsent>
<prevsent>to solve this task, especially in the case of non-pronominal coreference, researchers have recently started to exploit semantic knowledge, e.g. trying to calculate 1http://projects.ldc.upenn.edu/ace/ the semantic similarity of mentions (ponzetto and strube, 2006) <papid> N06-1025 </papid>or their semantic classes (ng, 2007; <papid> P07-1068 </papid>soon et al, 2001).<papid> J01-4004 </papid></prevsent>
</prevsection>
<citsent citstr=" P02-1014 ">
up to now, wordnet has beenone of the most frequently used sources of semantic knowledge for the coreference resolution task (soon et al, 2001; <papid> J01-4004 </papid>ng and cardie, 2002).<papid> P02-1014 </papid></citsent>
<aftsection>
<nextsent>researchers have shown, however, that wordnet has some limits.
</nextsent>
<nextsent>on one hand, although wordnet has big coverage of the english language in terms of common nouns, it still has limited coverage of proper nouns (e.g. barack obama is not available in the on-line version) and entity descriptions (e.g. president of india).
</nextsent>
<nextsent>on the other hand wordnet sense inventory is considered too fine grained (ponzetto and strube, 2006; <papid> N06-1025 </papid>mihalcea and moldovan, 2001).</nextsent>
<nextsent>in alternative, it has been recently shown that wikipedia can be promising source of semantic knowledge for coreference resolution between nominals (ponzetto and strube, 2006).<papid> N06-1025 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2574">
<title id=" W10-3503.xml">extending english ace 2005 corpus annotation with ground truth links to wikipedia </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, such linking is astep of the approach to coreference resolution described in (bryl et al, 2010).
</prevsent>
<prevsent>in order to evaluate this accuracy in the framework of coreference resolution system, corpus of documents, where entity mentions are annotated with ground-truth links to wikipedia, is required.the possible solution of this problem is to extend the annotation of entity mentions in coreference resolution corpus.
</prevsent>
</prevsection>
<citsent citstr=" L08-1328 ">
in the recent years, coreference resolution systems have been evaluated on various versions of the english automatic content extraction (ace) corpus (ponzetto and strube, 2006; <papid> N06-1025 </papid>versley et al, 2008; <papid> L08-1328 </papid>ng, 2007; <papid> P07-1068 </papid>culotta et al., 2007; <papid> N07-1011 </papid>bryl et al, 2010).</citsent>
<aftsection>
<nextsent>the latest publicly available version is ace 20053.
</nextsent>
<nextsent>in this paper we present an extension of ace 2005 non-pronominal entity mention annotations with ground-truth links to wikipedia.
</nextsent>
<nextsent>this extension is intended for evaluation of accuracy of linking entity mentions to wikipedia pages.
</nextsent>
<nextsent>the annotation is currently in progress.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2577">
<title id=" W10-3503.xml">extending english ace 2005 corpus annotation with ground truth links to wikipedia </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, such linking is astep of the approach to coreference resolution described in (bryl et al, 2010).
</prevsent>
<prevsent>in order to evaluate this accuracy in the framework of coreference resolution system, corpus of documents, where entity mentions are annotated with ground-truth links to wikipedia, is required.the possible solution of this problem is to extend the annotation of entity mentions in coreference resolution corpus.
</prevsent>
</prevsection>
<citsent citstr=" N07-1011 ">
in the recent years, coreference resolution systems have been evaluated on various versions of the english automatic content extraction (ace) corpus (ponzetto and strube, 2006; <papid> N06-1025 </papid>versley et al, 2008; <papid> L08-1328 </papid>ng, 2007; <papid> P07-1068 </papid>culotta et al., 2007; <papid> N07-1011 </papid>bryl et al, 2010).</citsent>
<aftsection>
<nextsent>the latest publicly available version is ace 20053.
</nextsent>
<nextsent>in this paper we present an extension of ace 2005 non-pronominal entity mention annotations with ground-truth links to wikipedia.
</nextsent>
<nextsent>this extension is intended for evaluation of accuracy of linking entity mentions to wikipedia pages.
</nextsent>
<nextsent>the annotation is currently in progress.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2578">
<title id=" W10-3503.xml">extending english ace 2005 corpus annotation with ground truth links to wikipedia </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in section 3 we describe some characteristics of the english ace 2005 corpus, which are relevant to the creation of the extension.next, we describe the general annotation princi 3http://www.ldc.upenn.edu/catalog/ catalogentry.jspcatalogid=ldc2006t06 ples and the procedure adopted to carry out theannotation.
</prevsent>
<prevsent>in section 4 we present some analyses of the annotation and statistics about inter annotator agreement.
</prevsent>
</prevsection>
<citsent citstr=" D07-1074 ">
recent approaches to linking terms to wikipedia pages (cucerzan, 2007; <papid> D07-1074 </papid>csomai and mihalcea, 2008; milne and witten, 2008; kulkarni et al,2009) have used two kinds of corpora for evaluation of accuracy: (i) sets of wikipedia pages and (ii) manually annotated corpora.</citsent>
<aftsection>
<nextsent>in wikipedia pages links are added to terms only where they are relevant to the context4.
</nextsent>
<nextsent>therefore, wikipedia pages do not contain the full annotation of all entity mentions.
</nextsent>
<nextsent>this observation applies equally to the corpus used by (milne and wit ten, 2008), which includes 50 documents from the aquaint corpus annotated following the same strategy5.
</nextsent>
<nextsent>the corpus created by (cucerzan, 2007) <papid> D07-1074 </papid>contains annotation of named entities only6.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2580">
<title id=" W10-2806.xml">semantic composition with quotient algebras </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the tensor product has been proposed asa method of composition, but has theun desirable property that strings of different length are incomparable.
</prevsent>
<prevsent>we consider how quotient algebra of the tensor algebra can allow such comparisons to be made, offering the possibility of data-driven models of semantic composition.
</prevsent>
</prevsection>
<citsent citstr=" P04-1036 ">
vector based techniques have been exploited in awide array of natural language processing applications (schutze, 1998; mccarthy et al, 2004; <papid> P04-1036 </papid>grefenstette, 1994; lin, 1998; <papid> P98-2127 </papid>bellegarda, 2000;choi et al, 2001).<papid> W01-0514 </papid></citsent>
<aftsection>
<nextsent>techniques such as latent semantic analysis and distributional similarity analyse contexts in which terms occur, building up vector of features which incorporate aspects of the meaning of the term.
</nextsent>
<nextsent>this idea has its origins in the distributional hypothesis of harris (1968), that words with similar meanings will occur in similar contexts, and vice-versa.
</nextsent>
<nextsent>however, there has been limited attention paid to extending this idea beyond individual words, so that the distributional meaning of phrases and whole sentences can be represented as vectors.
</nextsent>
<nextsent>while these techniques work well at the word level, for longer strings, data becomes extremelysparse.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2581">
<title id=" W10-2806.xml">semantic composition with quotient algebras </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the tensor product has been proposed asa method of composition, but has theun desirable property that strings of different length are incomparable.
</prevsent>
<prevsent>we consider how quotient algebra of the tensor algebra can allow such comparisons to be made, offering the possibility of data-driven models of semantic composition.
</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
vector based techniques have been exploited in awide array of natural language processing applications (schutze, 1998; mccarthy et al, 2004; <papid> P04-1036 </papid>grefenstette, 1994; lin, 1998; <papid> P98-2127 </papid>bellegarda, 2000;choi et al, 2001).<papid> W01-0514 </papid></citsent>
<aftsection>
<nextsent>techniques such as latent semantic analysis and distributional similarity analyse contexts in which terms occur, building up vector of features which incorporate aspects of the meaning of the term.
</nextsent>
<nextsent>this idea has its origins in the distributional hypothesis of harris (1968), that words with similar meanings will occur in similar contexts, and vice-versa.
</nextsent>
<nextsent>however, there has been limited attention paid to extending this idea beyond individual words, so that the distributional meaning of phrases and whole sentences can be represented as vectors.
</nextsent>
<nextsent>while these techniques work well at the word level, for longer strings, data becomes extremelysparse.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2582">
<title id=" W10-2806.xml">semantic composition with quotient algebras </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the tensor product has been proposed asa method of composition, but has theun desirable property that strings of different length are incomparable.
</prevsent>
<prevsent>we consider how quotient algebra of the tensor algebra can allow such comparisons to be made, offering the possibility of data-driven models of semantic composition.
</prevsent>
</prevsection>
<citsent citstr=" W01-0514 ">
vector based techniques have been exploited in awide array of natural language processing applications (schutze, 1998; mccarthy et al, 2004; <papid> P04-1036 </papid>grefenstette, 1994; lin, 1998; <papid> P98-2127 </papid>bellegarda, 2000;choi et al, 2001).<papid> W01-0514 </papid></citsent>
<aftsection>
<nextsent>techniques such as latent semantic analysis and distributional similarity analyse contexts in which terms occur, building up vector of features which incorporate aspects of the meaning of the term.
</nextsent>
<nextsent>this idea has its origins in the distributional hypothesis of harris (1968), that words with similar meanings will occur in similar contexts, and vice-versa.
</nextsent>
<nextsent>however, there has been limited attention paid to extending this idea beyond individual words, so that the distributional meaning of phrases and whole sentences can be represented as vectors.
</nextsent>
<nextsent>while these techniques work well at the word level, for longer strings, data becomes extremelysparse.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2583">
<title id=" W10-2806.xml">semantic composition with quotient algebras </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, there has been limited attention paid to extending this idea beyond individual words, so that the distributional meaning of phrases and whole sentences can be represented as vectors.
</prevsent>
<prevsent>while these techniques work well at the word level, for longer strings, data becomes extremelysparse.
</prevsent>
</prevsection>
<citsent citstr=" P08-1028 ">
this has led to various proposals exploring methods for composing vectors, rather than deriving them directly from the data (landauer and dumais, 1997; foltz et al, 1998; kintsch, 2001; widdows, 2008; clark et al, 2008; mitchell and lapata, 2008; <papid> P08-1028 </papid>erk and pado, 2009; preller and sadrzadeh, 2009).</citsent>
<aftsection>
<nextsent>many of these approaches usea pre-defined composition operation such as addition (landauer and dumais, 1997; foltz et al, 1998) or the tensor product (smolensky, 1990; clark and pulman, 2007; widdows, 2008) which contrasts with the data-driven definition of composition developed here.
</nextsent>
<nextsent>following the context-theoretic semantics of clarke (2007), we take the meaning of strings as being described by multiplication on vector space that is bilinear with respect to the addition of the vector space, i.e. x(y + z) = xy + xz (x+ y)z = xz + yz it is assumed that the multiplication is associative, but not commutative.
</nextsent>
<nextsent>the resulting structure is an associative algebra over field ? or simply an algebra when there is no ambiguity.one commonly used bilinear multiplication operator on vector spaces is the tensor product (de noted ?), whose use as method of combining meaning was first proposed by smolensky (1990), and has been considered more recently by clark and pulman (2007) and widdows (2008), who also looked at the direct sum (which widdows calls the direct product, denoted ?).we give very brief account of the tensor product and direct sum in the finite-dimensional case;see (halmos, 1974) for formal and complete definitions.
</nextsent>
<nextsent>roughly speaking, if u1, u2, . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2584">
<title id=" W10-1731.xml">uchupv englishx2013spanish system for wmt10 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in statistical machine translation (smt), the goalis to translate sentence from given source language into an equivalent sentence e?
</prevsent>
<prevsent>from certain target language.
</prevsent>
</prevsection>
<citsent citstr=" P02-1038 ">
such statement is typically formalised by means of the so-called log-linear models (papineni et al, 1998; och and ney, 2002) <papid> P02-1038 </papid>as follows: e?</citsent>
<aftsection>
<nextsent>= argmax k?
</nextsent>
<nextsent>k=1 khk(f , e) (1) where hk(f , e) is score function representing an important feature for the translation of into e, is the number of models (or features) and are the weights of the log-linear combination.
</nextsent>
<nextsent>typically, the weights are optimised during the tuning stage with the use of developmentset.
</nextsent>
<nextsent>such features typically include the target language model p(e), which is one of the core components of an smt system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2585">
<title id=" W10-1731.xml">uchupv englishx2013spanish system for wmt10 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the present work, we present system which follows coherent and natural evolution of probabilistic language models.
</prevsent>
<prevsent>specifically, we propose the use of continuous space language model trained in the form of neural network language model (nn lm).
</prevsent>
</prevsection>
<citsent citstr=" P06-2093 ">
the use of continuous space representation of language has been successfully applied in recent nn approaches to language modelling (bengio etal., 2003; schwenk and gauvain, 2002; castro bleda and prat, 2003; schwenk et al, 2006).<papid> P06-2093 </papid></citsent>
<aftsection>
<nextsent>however, the use of neural network language models (nn lms) (bengio, 2008) in state-of-theart smt systems is not so popular.
</nextsent>
<nextsent>the only comprehensive work refers to (schwenk, 2010), where the target lm is presented in the form of fully connected multilayer perceptron.
</nextsent>
<nextsent>the presented system combines standard, state-of-the-art smt system with nn lm vialog-linear combination and -best output rescoring.
</nextsent>
<nextsent>we chose to participate in the english spanish direction.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2586">
<title id=" W10-1731.xml">uchupv englishx2013spanish system for wmt10 </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>for this reason, in this paper we will be restricting vocabulary size.
</prevsent>
<prevsent>3.1 baseline system.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
for building the baseline smt system, we used the open-source smt toolkit moses (koehn etal., 2007), <papid> P07-2045 </papid>in its standard setup.</citsent>
<aftsection>
<nextsent>the decoder includes log-linear model comprising phrase based translation model, language model, lexicalised distortion model and word and phrasepenalties.
</nextsent>
<nextsent>the weights of the log-linear interpolation were optimised by means of mert (och, 2003).<papid> P03-1021 </papid></nextsent>
<nextsent>for the baseline lm, we computed regular n-gram lm with kneser-ney smoothing (kneser 208 and ney, 1995) and interpolation by means of the srilm (stolcke, 2002) toolkit.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2587">
<title id=" W10-1731.xml">uchupv englishx2013spanish system for wmt10 </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>for building the baseline smt system, we used the open-source smt toolkit moses (koehn etal., 2007), <papid> P07-2045 </papid>in its standard setup.</prevsent>
<prevsent>the decoder includes log-linear model comprising phrase based translation model, language model, lexicalised distortion model and word and phrasepenalties.</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
the weights of the log-linear interpolation were optimised by means of mert (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>for the baseline lm, we computed regular n-gram lm with kneser-ney smoothing (kneser 208 and ney, 1995) and interpolation by means of the srilm (stolcke, 2002) toolkit.
</nextsent>
<nextsent>specifically, we trained 6-gram lm on the larger spanish corpora available (i.e. un, news-shuffled and europarl),and 5-gram lm on the news-commentary corpus.
</nextsent>
<nextsent>once these lms had been built, they were finally interpolated so as to maximise the perplexity of the news-commentary test set of the 2008shared task.
</nextsent>
<nextsent>this was done so according to preliminary investigation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2589">
<title id=" W10-1731.xml">uchupv englishx2013spanish system for wmt10 </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>this was done so according to preliminary investigation.
</prevsent>
<prevsent>3.2 nn lm system architecture.
</prevsent>
</prevsection>
<citsent citstr=" I08-2089 ">
the presented systems follow previous works of (schwenk et al, 2006; <papid> P06-2093 </papid>khalilov et al, 2008; schwenk and koehn, 2008; <papid> I08-2089 </papid>schwenk, 2010) where the use of nn lm helps achieving better performance in the final system.</citsent>
<aftsection>
<nextsent>the nn lm was incorporated to the baseline system via log-linear combination, adding new feature to the output -best list generated by the baseline system (in this case = 1 000).
</nextsent>
<nextsent>specifically, the nn lm was used to compute the log probability of each sentence within then -best list.
</nextsent>
<nextsent>then, the scores of such list were extended with our new, nn lm-based feature.
</nextsent>
<nextsent>this being done,we optimised the coefficients of the log-linear interpolation by means of mert, taking into account the newly introduced feature.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2590">
<title id=" W10-1731.xml">uchupv englishx2013spanish system for wmt10 </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the number of sentences in the -best list was set to 1 000 unique output sentences.
</prevsent>
<prevsent>results can be seen in table 2.
</prevsent>
</prevsection>
<citsent citstr=" W04-3250 ">
in order to assess the reliability of such results, we computed pairwise improvement intervals as described in (koehn, 2004), <papid> W04-3250 </papid>bymeans of bootstrapping with 1000 bootstrap iterations and at 95% confidence level.</citsent>
<aftsection>
<nextsent>such confidence test reported the improvements to be statistically significant.
</nextsent>
<nextsent>four more experiments have done in order to study the influence of the -best list size in the 209 figure 2: architecture of the system.
</nextsent>
<nextsent>table 2: english-spanish translation quality for development and official test set.
</nextsent>
<nextsent>results are given in bleu/ter.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2591">
<title id=" W10-3813.xml">hmm wordtophrase alignment with dependency constraints </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our experimental results on variety of chineseenglishdata show that our syntactically constrained model can lead to as much as 3.24% relative improvement in bleu score over current hmm word-to-phrase alignment models on phrase-based statistical machine translation system when the training data is small, and comparable performance compared to ibm model 4 on hiero-style system with larger training data.
</prevsent>
<prevsent>an intrinsic alignment quality evaluation shows that our alignment model with dependency constraints leads to improvements in both precision (by 1.74% relative) and recall (by 1.75% relative) over the model without dependency information.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
generative word alignment models including ibm models (brown et al, 1993) <papid> J93-2003 </papid>and hmm word alignment models (vogel et al, 1996) <papid> C96-2141 </papid>have been widely used in various types of statistical machine translation (smt) systems.</citsent>
<aftsection>
<nextsent>this widespread use can be attributed to their robustness and high performance particularly on large scale translation tasks.
</nextsent>
<nextsent>however, the quality of the alignment yielded from these models is still far from satisfactory even with significant amounts of training data; this is particularly true for radically different languages such as chinese and english.the weakness of most generative models of ten lies in the incapability of addressing one to many (1-to-n), many to one (n-to-1) and manyto many (m-to-n) alignments.
</nextsent>
<nextsent>some research directly addresses m-to-n alignment with phrase alignment models (marcu and wong, 2002).<papid> W02-1018 </papid></nextsent>
<nextsent>however, these models are unsuccessful largely due to intractable estimation (denero and klein,2008).<papid> P08-2007 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2593">
<title id=" W10-3813.xml">hmm wordtophrase alignment with dependency constraints </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our experimental results on variety of chineseenglishdata show that our syntactically constrained model can lead to as much as 3.24% relative improvement in bleu score over current hmm word-to-phrase alignment models on phrase-based statistical machine translation system when the training data is small, and comparable performance compared to ibm model 4 on hiero-style system with larger training data.
</prevsent>
<prevsent>an intrinsic alignment quality evaluation shows that our alignment model with dependency constraints leads to improvements in both precision (by 1.74% relative) and recall (by 1.75% relative) over the model without dependency information.
</prevsent>
</prevsection>
<citsent citstr=" C96-2141 ">
generative word alignment models including ibm models (brown et al, 1993) <papid> J93-2003 </papid>and hmm word alignment models (vogel et al, 1996) <papid> C96-2141 </papid>have been widely used in various types of statistical machine translation (smt) systems.</citsent>
<aftsection>
<nextsent>this widespread use can be attributed to their robustness and high performance particularly on large scale translation tasks.
</nextsent>
<nextsent>however, the quality of the alignment yielded from these models is still far from satisfactory even with significant amounts of training data; this is particularly true for radically different languages such as chinese and english.the weakness of most generative models of ten lies in the incapability of addressing one to many (1-to-n), many to one (n-to-1) and manyto many (m-to-n) alignments.
</nextsent>
<nextsent>some research directly addresses m-to-n alignment with phrase alignment models (marcu and wong, 2002).<papid> W02-1018 </papid></nextsent>
<nextsent>however, these models are unsuccessful largely due to intractable estimation (denero and klein,2008).<papid> P08-2007 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2594">
<title id=" W10-3813.xml">hmm wordtophrase alignment with dependency constraints </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this widespread use can be attributed to their robustness and high performance particularly on large scale translation tasks.
</prevsent>
<prevsent>however, the quality of the alignment yielded from these models is still far from satisfactory even with significant amounts of training data; this is particularly true for radically different languages such as chinese and english.the weakness of most generative models of ten lies in the incapability of addressing one to many (1-to-n), many to one (n-to-1) and manyto many (m-to-n) alignments.
</prevsent>
</prevsection>
<citsent citstr=" W02-1018 ">
some research directly addresses m-to-n alignment with phrase alignment models (marcu and wong, 2002).<papid> W02-1018 </papid></citsent>
<aftsection>
<nextsent>however, these models are unsuccessful largely due to intractable estimation (denero and klein,2008).<papid> P08-2007 </papid></nextsent>
<nextsent>recent progress in better parameteri sation and approximate inference (blunsom et al., 2009) <papid> P09-1088 </papid>can only augment the performance of these models to similar level as the baseline where bidirectional word alignments are combined with heuristics and subsequently used to induce translation equivalence (e.g.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2595">
<title id=" W10-3813.xml">hmm wordtophrase alignment with dependency constraints </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, the quality of the alignment yielded from these models is still far from satisfactory even with significant amounts of training data; this is particularly true for radically different languages such as chinese and english.the weakness of most generative models of ten lies in the incapability of addressing one to many (1-to-n), many to one (n-to-1) and manyto many (m-to-n) alignments.
</prevsent>
<prevsent>some research directly addresses m-to-n alignment with phrase alignment models (marcu and wong, 2002).<papid> W02-1018 </papid></prevsent>
</prevsection>
<citsent citstr=" P08-2007 ">
however, these models are unsuccessful largely due to intractable estimation (denero and klein,2008).<papid> P08-2007 </papid></citsent>
<aftsection>
<nextsent>recent progress in better parameteri sation and approximate inference (blunsom et al., 2009) <papid> P09-1088 </papid>can only augment the performance of these models to similar level as the baseline where bidirectional word alignments are combined with heuristics and subsequently used to induce translation equivalence (e.g.</nextsent>
<nextsent>(koehn etal., 2003)).<papid> N03-1017 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2596">
<title id=" W10-3813.xml">hmm wordtophrase alignment with dependency constraints </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>some research directly addresses m-to-n alignment with phrase alignment models (marcu and wong, 2002).<papid> W02-1018 </papid></prevsent>
<prevsent>however, these models are unsuccessful largely due to intractable estimation (denero and klein,2008).<papid> P08-2007 </papid></prevsent>
</prevsection>
<citsent citstr=" P09-1088 ">
recent progress in better parameteri sation and approximate inference (blunsom et al., 2009) <papid> P09-1088 </papid>can only augment the performance of these models to similar level as the baseline where bidirectional word alignments are combined with heuristics and subsequently used to induce translation equivalence (e.g.</citsent>
<aftsection>
<nextsent>(koehn etal., 2003)).<papid> N03-1017 </papid></nextsent>
<nextsent>the most widely used word alignment models, such as ibm models 3 and 4, can only model 1-to-n alignment; these models are often called asymmetric?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2597">
<title id=" W10-3813.xml">hmm wordtophrase alignment with dependency constraints </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, these models are unsuccessful largely due to intractable estimation (denero and klein,2008).<papid> P08-2007 </papid></prevsent>
<prevsent>recent progress in better parameteri sation and approximate inference (blunsom et al., 2009) <papid> P09-1088 </papid>can only augment the performance of these models to similar level as the baseline where bidirectional word alignments are combined with heuristics and subsequently used to induce translation equivalence (e.g.</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
(koehn etal., 2003)).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>the most widely used word alignment models, such as ibm models 3 and 4, can only model 1-to-n alignment; these models are often called asymmetric?
</nextsent>
<nextsent>models.
</nextsent>
<nextsent>ibm models 3 and 4 model 1-to-n alignments using the notion of fertility?, which is associated with defi ciency?
</nextsent>
<nextsent>problem despite its high performance in practice.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2599">
<title id=" W10-3813.xml">hmm wordtophrase alignment with dependency constraints </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>on the other hand, the hmm word-to-phrasealignment model tackles 1-to-n alignment problems with simultaneous segmentation and alignment while maintaining the efficiency of themodels.
</prevsent>
<prevsent>therefore, this model sets good example of addressing the tradeoffs between modelling power and modelling complexity.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
this model can also be seen as more generalised 101 case of the hmm word-to-word model (vogel et al., 1996; <papid> C96-2141 </papid>och and ney, 2003), <papid> J03-1002 </papid>since this model can be reduced to an hmm word-to-word model by restricting the generated target phrase length to one.</citsent>
<aftsection>
<nextsent>one can further refine existing word alignment models with syntactic constraints (e.g.(cherry and lin, 2006)).<papid> P06-2014 </papid></nextsent>
<nextsent>however, most research focuses on the incorporation of syntactic constraints into discriminative alignment models.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2600">
<title id=" W10-3813.xml">hmm wordtophrase alignment with dependency constraints </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>therefore, this model sets good example of addressing the tradeoffs between modelling power and modelling complexity.
</prevsent>
<prevsent>this model can also be seen as more generalised 101 case of the hmm word-to-word model (vogel et al., 1996; <papid> C96-2141 </papid>och and ney, 2003), <papid> J03-1002 </papid>since this model can be reduced to an hmm word-to-word model by restricting the generated target phrase length to one.</prevsent>
</prevsection>
<citsent citstr=" P06-2014 ">
one can further refine existing word alignment models with syntactic constraints (e.g.(cherry and lin, 2006)).<papid> P06-2014 </papid></citsent>
<aftsection>
<nextsent>however, most research focuses on the incorporation of syntactic constraints into discriminative alignment models.
</nextsent>
<nextsent>introducing syntactic information into generative alignment models is shown to be more challenging mainly due to the absence of appropriate modelling of syntactic constraints and the inflexibility?
</nextsent>
<nextsent>of these generative models.in this paper, we extend the hmm word-tophrase alignment model with syntactic dependencies by presenting model that can incorporate syntactic information while maintaining the efficiency of the model.
</nextsent>
<nextsent>this model is based on the observation that in 1-to-n alignments, the words bear some syntactic dependencies.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2601">
<title id=" W10-3813.xml">hmm wordtophrase alignment with dependency constraints </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this model is based on the observation that in 1-to-n alignments, the words bear some syntactic dependencies.
</prevsent>
<prevsent>leveraging such information in the model can potentially further aid the model in producing more fine-grained word alignments.
</prevsent>
</prevsection>
<citsent citstr=" W02-1039 ">
the syntactic constraints are specifically imposed on the words involved in 1-to-n alignments, which is different from the cohesion constraints (fox, 2002) <papid> W02-1039 </papid>as explored by cherry and lin (2006),<papid> P06-2014 </papid>where knowledge of cross-lingual syntactic projection is used.</citsent>
<aftsection>
<nextsent>as syntactic extension of the open-source mttk implementation (deng and byrne, 2006) <papid> N06-4004 </papid>of the hmm word-to-phrase alignment model, its source code will also be released as open source in the near future.the remainder of the paper is organised as follows.</nextsent>
<nextsent>section 2 describes the hmm word-to phrase alignment model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2603">
<title id=" W10-3813.xml">hmm wordtophrase alignment with dependency constraints </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>leveraging such information in the model can potentially further aid the model in producing more fine-grained word alignments.
</prevsent>
<prevsent>the syntactic constraints are specifically imposed on the words involved in 1-to-n alignments, which is different from the cohesion constraints (fox, 2002) <papid> W02-1039 </papid>as explored by cherry and lin (2006),<papid> P06-2014 </papid>where knowledge of cross-lingual syntactic projection is used.</prevsent>
</prevsection>
<citsent citstr=" N06-4004 ">
as syntactic extension of the open-source mttk implementation (deng and byrne, 2006) <papid> N06-4004 </papid>of the hmm word-to-phrase alignment model, its source code will also be released as open source in the near future.the remainder of the paper is organised as follows.</citsent>
<aftsection>
<nextsent>section 2 describes the hmm word-to phrase alignment model.
</nextsent>
<nextsent>in section 3, we present the details of the incorporation of syntactic dependencies.
</nextsent>
<nextsent>section 4 presents the experimental setup, and section 5 reports the experimental results.
</nextsent>
<nextsent>in section 6, we draw our conclusions and point out some avenues for future work.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2604">
<title id=" W10-3813.xml">hmm wordtophrase alignment with dependency constraints </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>and medium?
</prevsent>
<prevsent>scale experiments.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
multiple-translation chinese part 1 (mtc1) from ldc was used for minimum error-rate training (mert) (och, 2003), <papid> P03-1021 </papid>and mtc2, 3 and 4 were used as development test sets.</citsent>
<aftsection>
<nextsent>finally the test set from nist 2006 evaluation campaign was used as the final test set.
</nextsent>
<nextsent>the chinese data was segmented using theldc word segmenter.
</nextsent>
<nextsent>the maximum-entropy based pos tagger mxpost (ratnaparkhi, 1996) <papid> W96-0213 </papid>was used to tag both english and chinese texts.</nextsent>
<nextsent>the syntactic dependencies for both english and chinese were obtained using the state-of-the-art malt parser dependency parser, which achieved 84% and 88% labelled attachment scores for chinese and english respectively.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2605">
<title id=" W10-3813.xml">hmm wordtophrase alignment with dependency constraints </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>finally the test set from nist 2006 evaluation campaign was used as the final test set.
</prevsent>
<prevsent>the chinese data was segmented using theldc word segmenter.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
the maximum-entropy based pos tagger mxpost (ratnaparkhi, 1996) <papid> W96-0213 </papid>was used to tag both english and chinese texts.</citsent>
<aftsection>
<nextsent>the syntactic dependencies for both english and chinese were obtained using the state-of-the-art malt parser dependency parser, which achieved 84% and 88% labelled attachment scores for chinese and english respectively.
</nextsent>
<nextsent>4.2 word alignment.
</nextsent>
<nextsent>the giza++ (och and ney, 2003) <papid> J03-1002 </papid>implementation of ibm model 4 (brown et al, 1993) <papid> J93-2003 </papid>is used as the baseline for word alignment.</nextsent>
<nextsent>model 4 is incrementally trained by performing 5 iterations of model 1, 5 iterations of hmm, 3 iterations of model 3, and 3 iterations of model 4.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2613">
<title id=" W10-3813.xml">hmm wordtophrase alignment with dependency constraints </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>4.3 mt system.
</prevsent>
<prevsent>the baseline in our experiments is standardlog-linear pb-smt system.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
with the word alignment obtained using the method described in 105 section 4.2, we perform phrase-extraction using heuristics described in (koehn et al, 2003), <papid> N03-1017 </papid>minimum error-rate training (mert) (och, 2003) <papid> P03-1021 </papid>optimising the bleu metric, 5-gram language model with kneser-ney smoothing (kneser and ney, 1995) trained with srilm (stolcke, 2002) on the english side of the training data, and moses (koehn et al, 2007) <papid> P07-2045 </papid>for decoding.</citsent>
<aftsection>
<nextsent>a hiero-style decoder joshua (li et al, 2009) <papid> W09-0424 </papid>is also used in our experiments.</nextsent>
<nextsent>all significance tests are performed using approximate randomi sation (noreen, 1989) at = 0.05.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2614">
<title id=" W10-3813.xml">hmm wordtophrase alignment with dependency constraints </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>the baseline in our experiments is standardlog-linear pb-smt system.
</prevsent>
<prevsent>with the word alignment obtained using the method described in 105 section 4.2, we perform phrase-extraction using heuristics described in (koehn et al, 2003), <papid> N03-1017 </papid>minimum error-rate training (mert) (och, 2003) <papid> P03-1021 </papid>optimising the bleu metric, 5-gram language model with kneser-ney smoothing (kneser and ney, 1995) trained with srilm (stolcke, 2002) on the english side of the training data, and moses (koehn et al, 2007) <papid> P07-2045 </papid>for decoding.</prevsent>
</prevsection>
<citsent citstr=" W09-0424 ">
a hiero-style decoder joshua (li et al, 2009) <papid> W09-0424 </papid>is also used in our experiments.</citsent>
<aftsection>
<nextsent>all significance tests are performed using approximate randomi sation (noreen, 1989) at = 0.05.
</nextsent>
<nextsent>5.1 alignment model tuning.
</nextsent>
<nextsent>in order to find the value of ? in the ssh model that yields the best mt performance, we used three development test sets using pb-smt system trained on the small data condition.
</nextsent>
<nextsent>figure 1 shows the results on each development test set using different configurations of the alignment models.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2615">
<title id=" W10-3813.xml">hmm wordtophrase alignment with dependency constraints </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>in order to find the value of ? in the ssh model that yields the best mt performance, we used three development test sets using pb-smt system trained on the small data condition.
</prevsent>
<prevsent>figure 1 shows the results on each development test set using different configurations of the alignment models.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
for each system, we obtain the mean of the bleu scores (papineni et al, 2002) <papid> P02-1040 </papid>on the three development test sets, and derive the optimal value for ? of 0.4, which we use here after for final testing.</citsent>
<aftsection>
<nextsent>it is worth mentioning that while ibm model 4 (m4) outperforms other models including the hmm word-to-word (h) and word-to-phrase (sh) alignment model in our current setup, using the default ibm model 4 setting (maximum fertility 9) yields an inferior performance (as much as 8.5% relative) compared to other models.
</nextsent>
<nextsent>0.11 0.115 0.12 0.125 0.13 0.135 0.14 m4 sh ssh-0.05 ssh-0.1 ssh-0.2 ssh-0.3 ssh-0.4 ssh-0.5 ssh-0.6 bl eu co realignment systems mtc2 mtc3 mtc4 figure 1: bleu score on development test set using pb-smt system pb-smt hiero small medium small medium 0.1440 0.2591 0.1373 0.2595 sh 0.1418 0.2517 0.1372 0.2609 ssh 0.1464 0.2518 0.1356 0.2624 m4 0.1566 0.2627 0.1486 0.2660 table 1: performance of pb-smt using different alignment models on nist06 test set 5.2 translation results.
</nextsent>
<nextsent>table 1 shows the performance of pb-smt and hiero systems using small amount of data for alignment model training on the nist06 test set.
</nextsent>
<nextsent>for the pb-smt system trained on the small dataset, using ssh word alignment leads to 3.24%relative improvement over sh, which is statistically significant.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2616">
<title id=" W10-3813.xml">hmm wordtophrase alignment with dependency constraints </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>ibm model 4 achieves significantly higher over other models while the gap in is narrow.
</prevsent>
<prevsent>relating table 2 to table 1, we observe that the hmm word-to-word alignment model (h) can still achieve good mt performance despite the lower and compared to other models.
</prevsent>
</prevsection>
<citsent citstr=" D07-1006 ">
this provides additional support to previous findings (fraser and marcu, 2007<papid> D07-1006 </papid>b) that the intrinsic quality of word alignment does not necessarily correlate with the performance of there sulted mt system.</citsent>
<aftsection>
<nextsent>5.4 alignment characteristics.
</nextsent>
<nextsent>in order to further understand the characteristics of the alignment that each model produces, we investigated several statistics of the alignment results which can hopefully reveal the capabilities and limitations of each model.
</nextsent>
<nextsent>5.4.1 pairwise comparison given the asymmetric property of these alignment models, we can evaluate the quality of the links for each word and compare the alignment links across different models.
</nextsent>
<nextsent>for example, in zhen word alignment, we can compute the links for each chinese word and compare those links across different models.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2620">
<title id=" W10-1725.xml">upvprhlt englishx2013spanish system for wmt10 </title>
<section> similar sentences selection.  </section>
<citcontext>
<prevsection>
<prevsent>as similarity measure, we have chosen the alignment score.
</prevsent>
<prevsent>alignment scores have already been used as 172 filter for noisy corpora (khadivi and ney, 2005).
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
we trained an ibm model 4 using giza++ (och and ney, 2003) <papid> J03-1002 </papid>with the in-domain corpus and computed the alignment scores over the united nations sentences.</citsent>
<aftsection>
<nextsent>we assume that the alignment score is good measure of similarity.
</nextsent>
<nextsent>an important factor in the alignment score is the length of the sentences, so we clustered the bilingual sentences in groups with the same sum of source and target language sentence sizes.
</nextsent>
<nextsent>in each of the groups, the higher the alignment score is, the more similar the sentence is to the in-domaincorpus sentences.
</nextsent>
<nextsent>hence, we computed the average alignment score for each one of the clusters obtained for the corpus considered in-domain (i.e. the news-commentary corpus).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2621">
<title id=" W10-1725.xml">upvprhlt englishx2013spanish system for wmt10 </title>
<section> walls and zones.  </section>
<citcontext>
<prevsection>
<prevsent>they also indicate pauses, hierarchies and emphasis.
</prevsent>
<prevsent>in our system, punctuation marks have been taken into account during decoding.
</prevsent>
</prevsection>
<citsent citstr=" W09-0429 ">
traditionally, in smt punctuation marks are treated as word sand this has undesirable effects (koehn and had dow, 2009).<papid> W09-0429 </papid></citsent>
<aftsection>
<nextsent>for example, commas have high probability of occurrence and many possible translations are generated.
</nextsent>
<nextsent>most of them are not consistent across languages.
</nextsent>
<nextsent>this introduces too much noise to the phrase tables.
</nextsent>
<nextsent>(koehn and haddow, 2009) <papid> W09-0429 </papid>established framework to specify reordering constraints with walls and zones, where commas and end of sentence are not mixed with various clauses.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2623">
<title id=" W10-1725.xml">upvprhlt englishx2013spanish system for wmt10 </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>when using walls, gain of 0.1 bleu is obtained in our best model.
</prevsent>
<prevsent>6.1 experimental setup.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
for building our smt systems, the open-source smt toolkit moses (koehn et al, 2007) <papid> P07-2045 </papid>was usedin its standard setup.</citsent>
<aftsection>
<nextsent>the decoder includes loglinear model comprising phrase-based translation model, language model, lexicalised distortion model and word and phrase penalties.
</nextsent>
<nextsent>the weights of the log-linear interpolation were optimised by means of mert (och, 2003).<papid> P03-1021 </papid></nextsent>
<nextsent>in addition, 5-gram lm with kneser-ney (kneser and ney, 1995) smoothing and interpolation was built by means of the srilm (stolcke, 2002) toolkit.for building our baseline system, the news commentary and europarl v5 (koehn, 2005) data were employed, with maximum sentence length set to 40 in the case of the data used to build the translation models, and without restriction in the case of the lm.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2624">
<title id=" W10-1725.xml">upvprhlt englishx2013spanish system for wmt10 </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>for building our smt systems, the open-source smt toolkit moses (koehn et al, 2007) <papid> P07-2045 </papid>was usedin its standard setup.</prevsent>
<prevsent>the decoder includes loglinear model comprising phrase-based translation model, language model, lexicalised distortion model and word and phrase penalties.</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
the weights of the log-linear interpolation were optimised by means of mert (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>in addition, 5-gram lm with kneser-ney (kneser and ney, 1995) smoothing and interpolation was built by means of the srilm (stolcke, 2002) toolkit.for building our baseline system, the news commentary and europarl v5 (koehn, 2005) data were employed, with maximum sentence length set to 40 in the case of the data used to build the translation models, and without restriction in the case of the lm.
</nextsent>
<nextsent>statistics of the bilingual data can be seen in table 1.
</nextsent>
<nextsent>in all the experiments reported, mert was run on the 2008 test set, whereas the test set 2009 was considered as test set as such.
</nextsent>
<nextsent>in addition, all the experiments described below were performed in lowercase and token ised conditions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2625">
<title id=" W10-2502.xml">a decoder for probabilistic synchronous tree insertion grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>tree adjoining grammars (tag) were invented in(joshi et al 1975) in order to better characterize the string sets of natural languages1.
</prevsent>
<prevsent>one of tags important features is the ability to introduce two related syntactic units in single rule, then push those two units arbitrarily far apart in subsequent derivation steps.
</prevsent>
</prevsection>
<citsent citstr=" C90-3001 ">
for machine translation (mt) between two natural languages, each being generated by tag, the derivations of the two tag may be synchronized (abeille et al, 1990;<papid> C90-3001 </papid>shieber and shabes, 1990) <papid> C90-3045 </papid>in the spirit of syntax directed transductions (lewis and stearns, 1968); this results in synchronous tag (stag).</citsent>
<aftsection>
<nextsent>recently,in (nesson et al, 2005, 2006) probabilistic synchronous tree insertion grammars (pstig) were discussed as model of mt; tree insertion grammar is particular tag in which the parsing problem is solvable in cubic-time (schabes and waters, 1994).
</nextsent>
<nextsent>in (deneefe, 2009; deneefe and knight 2009) <papid> D09-1076 </papid>decoder for pstig has been proposed which transforms source-language strings into (modifications of) derivation trees of the pstig.</nextsent>
<nextsent>nowadays, large-scale linguistic stag rule bases are available.in an independent tradition, the automata theoretic investigation of the translation of trees ? financially supported by nsf stages project, grant #iis-0908532.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2626">
<title id=" W10-2502.xml">a decoder for probabilistic synchronous tree insertion grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>tree adjoining grammars (tag) were invented in(joshi et al 1975) in order to better characterize the string sets of natural languages1.
</prevsent>
<prevsent>one of tags important features is the ability to introduce two related syntactic units in single rule, then push those two units arbitrarily far apart in subsequent derivation steps.
</prevsent>
</prevsection>
<citsent citstr=" C90-3045 ">
for machine translation (mt) between two natural languages, each being generated by tag, the derivations of the two tag may be synchronized (abeille et al, 1990;<papid> C90-3001 </papid>shieber and shabes, 1990) <papid> C90-3045 </papid>in the spirit of syntax directed transductions (lewis and stearns, 1968); this results in synchronous tag (stag).</citsent>
<aftsection>
<nextsent>recently,in (nesson et al, 2005, 2006) probabilistic synchronous tree insertion grammars (pstig) were discussed as model of mt; tree insertion grammar is particular tag in which the parsing problem is solvable in cubic-time (schabes and waters, 1994).
</nextsent>
<nextsent>in (deneefe, 2009; deneefe and knight 2009) <papid> D09-1076 </papid>decoder for pstig has been proposed which transforms source-language strings into (modifications of) derivation trees of the pstig.</nextsent>
<nextsent>nowadays, large-scale linguistic stag rule bases are available.in an independent tradition, the automata theoretic investigation of the translation of trees ? financially supported by nsf stages project, grant #iis-0908532.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2627">
<title id=" W10-2502.xml">a decoder for probabilistic synchronous tree insertion grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for machine translation (mt) between two natural languages, each being generated by tag, the derivations of the two tag may be synchronized (abeille et al, 1990;<papid> C90-3001 </papid>shieber and shabes, 1990) <papid> C90-3045 </papid>in the spirit of syntax directed transductions (lewis and stearns, 1968); this results in synchronous tag (stag).</prevsent>
<prevsent>recently,in (nesson et al, 2005, 2006) probabilistic synchronous tree insertion grammars (pstig) were discussed as model of mt; tree insertion grammar is particular tag in which the parsing problem is solvable in cubic-time (schabes and waters, 1994).</prevsent>
</prevsection>
<citsent citstr=" D09-1076 ">
in (deneefe, 2009; deneefe and knight 2009) <papid> D09-1076 </papid>decoder for pstig has been proposed which transforms source-language strings into (modifications of) derivation trees of the pstig.</citsent>
<aftsection>
<nextsent>nowadays, large-scale linguistic stag rule bases are available.in an independent tradition, the automata theoretic investigation of the translation of trees ? financially supported by nsf stages project, grant #iis-0908532.
</nextsent>
<nextsent>financially supported by dfg vo 1011/5-1.
</nextsent>
<nextsent>1see (joshi and shabes, 1997) for survey led to the rich theory of tree transducers (gecseg and steinby, 1984, 1997).
</nextsent>
<nextsent>roughly speaking, tree transducer is finite term rewriting system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2628">
<title id=" W10-2502.xml">a decoder for probabilistic synchronous tree insertion grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>roughly speaking, tree transducer is finite term rewriting system.
</prevsent>
<prevsent>ifeach rewrite rule carries probablity or, in general, weight from some semi ring, then they are weighted tree transducers (maletti, 2006, 2006a; fulop and vogler, 2009).
</prevsent>
</prevsection>
<citsent citstr=" P01-1067 ">
such weighted tree transducers have also been used for the specification of mt of natural languages (yamada and knight, 2001; <papid> P01-1067 </papid>knight and graehl, 2005; graehl et al., 2008; knight and may 2009).</citsent>
<aftsection>
<nextsent>martin and vere (1970) and schreiber (1975) established the first connections between the two traditions; also shieber (2004),  also shieber (2006) <papid> E06-1048 </papid>and maletti (2008),  and maletti (2010) investigated their relationship.</nextsent>
<nextsent>the problem addressed in this paper is the decoding of source-language strings into target language trees where the transformation is described by pstig.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2629">
<title id=" W10-2502.xml">a decoder for probabilistic synchronous tree insertion grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>ifeach rewrite rule carries probablity or, in general, weight from some semi ring, then they are weighted tree transducers (maletti, 2006, 2006a; fulop and vogler, 2009).
</prevsent>
<prevsent>such weighted tree transducers have also been used for the specification of mt of natural languages (yamada and knight, 2001; <papid> P01-1067 </papid>knight and graehl, 2005; graehl et al., 2008; knight and may 2009).</prevsent>
</prevsection>
<citsent citstr=" E06-1048 ">
martin and vere (1970) and schreiber (1975) established the first connections between the two traditions; also shieber (2004),  also shieber (2006) <papid> E06-1048 </papid>and maletti (2008),  and maletti (2010) investigated their relationship.</citsent>
<aftsection>
<nextsent>the problem addressed in this paper is the decoding of source-language strings into target language trees where the transformation is described by pstig.
</nextsent>
<nextsent>currently, this decoding requires two steps: first, every source string is translated into derivation tree of the underlying pstig (deneefe, 2009; deneefe and knight2009), <papid> D09-1076 </papid>and second, the derivation tree is transformed into the target tree using an embedded tree transducer (shieber, 2006).<papid> E06-1048 </papid></nextsent>
<nextsent>we propose transducer model, called bottom-up tree adjoining transducer, which performs this decoding in single step and, simultaneously, computes the probabilities of its derivations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2637">
<title id=" W10-1304.xml">scanning methods and language modeling for binary switch typing </title>
<section> 4y 1z </section>
<citcontext>
<prevsection>
<prevsent>the cell layouts are configurable, but typically one cell contains set of likely word completions; others are allocated to space and backspace; and around half of the cells are allocated to the most likely single character continuation of the input string, based on language model predictions.
</prevsent>
<prevsent>hansen et al (2003) report that users produced more words per minute with static keyboard than with the predictive grid interface, illustrating the impact of the cognitive overhead that goes along with this sort of scanning.the likely word completions in the gaze talk system illustrates another common way in which language modeling is integrated into aac typing systems.
</prevsent>
</prevsection>
<citsent citstr=" N07-2044 ">
much of the language modeling research within the context of aac has been for word com pletion/prediction for keystroke reduction (darragh et al, 1990; li and hirst, 2005; trost et al, 2005; trnka et al, 2006; trnka et al, 2007; <papid> N07-2044 </papid>wandmacher and antoine, 2007).<papid> D07-1053 </papid></citsent>
<aftsection>
<nextsent>the typical scenario for this is allocating region of the interface to contain set of suggested words that complete what the user has be gun typing.
</nextsent>
<nextsent>the expectation is to derive keystroke savings when the user selects one of the alternatives rather than typing the rest of the letters.
</nextsent>
<nextsent>the cognitive load of monitoring list of possible completion shas made the claim that this speeds typing controversial (anson et al, 2004); yet some results have shown this to speed typing under certain conditions (trnka et al, 2007).<papid> N07-2044 </papid>one innovative language-model-driven aac typing interface is dasher (ward et al, 2002), which uses language models and arithmetic coding to present alternative letter targets on the screen with size relative to their likelihood given the history.</nextsent>
<nextsent>users can type by continuous motion, such as eyegaze or mouse cursor movement, targeting their cursor at the intended letter and moving the cursor from left-to-right through the interface, while its movements are tracked.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2638">
<title id=" W10-1304.xml">scanning methods and language modeling for binary switch typing </title>
<section> 4y 1z </section>
<citcontext>
<prevsection>
<prevsent>the cell layouts are configurable, but typically one cell contains set of likely word completions; others are allocated to space and backspace; and around half of the cells are allocated to the most likely single character continuation of the input string, based on language model predictions.
</prevsent>
<prevsent>hansen et al (2003) report that users produced more words per minute with static keyboard than with the predictive grid interface, illustrating the impact of the cognitive overhead that goes along with this sort of scanning.the likely word completions in the gaze talk system illustrates another common way in which language modeling is integrated into aac typing systems.
</prevsent>
</prevsection>
<citsent citstr=" D07-1053 ">
much of the language modeling research within the context of aac has been for word com pletion/prediction for keystroke reduction (darragh et al, 1990; li and hirst, 2005; trost et al, 2005; trnka et al, 2006; trnka et al, 2007; <papid> N07-2044 </papid>wandmacher and antoine, 2007).<papid> D07-1053 </papid></citsent>
<aftsection>
<nextsent>the typical scenario for this is allocating region of the interface to contain set of suggested words that complete what the user has be gun typing.
</nextsent>
<nextsent>the expectation is to derive keystroke savings when the user selects one of the alternatives rather than typing the rest of the letters.
</nextsent>
<nextsent>the cognitive load of monitoring list of possible completion shas made the claim that this speeds typing controversial (anson et al, 2004); yet some results have shown this to speed typing under certain conditions (trnka et al, 2007).<papid> N07-2044 </papid>one innovative language-model-driven aac typing interface is dasher (ward et al, 2002), which uses language models and arithmetic coding to present alternative letter targets on the screen with size relative to their likelihood given the history.</nextsent>
<nextsent>users can type by continuous motion, such as eyegaze or mouse cursor movement, targeting their cursor at the intended letter and moving the cursor from left-to-right through the interface, while its movements are tracked.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2640">
<title id=" W10-1304.xml">scanning methods and language modeling for binary switch typing </title>
<section> 4y 1z </section>
<citcontext>
<prevsection>
<prevsent>3.1 character-based language models.
</prevsent>
<prevsent>for this paper, we use character n-gram models.
</prevsent>
</prevsection>
<citsent citstr=" W05-1107 ">
carpenter (2005) <papid> W05-1107 </papid>has an extensive comparison of large scale character-based language models, and we adopt smoothing methods from that paper.</citsent>
<aftsection>
<nextsent>it presents version of witten-bell smoothing (witten and bell, 1991) with an optimized hyperparameter k, which is shown to be as effective as kneser ney smoothing (kneser and ney, 1995) for higher order n-grams.
</nextsent>
<nextsent>we refer readers to that paper for details on this standard n-gram language modeling approach.
</nextsent>
<nextsent>for the experimental results presented here, we trained unigram and 8-gram models from the ny times portion of the english gigaword corpus.
</nextsent>
<nextsent>we performed extensive normalization of this corpus, detailed in roark (2009).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2644">
<title id=" W10-3712.xml">a hybrid approach for functional expression identification in a japanese reading assistant </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>sentence 3 shows an example of the?????????
</prevsent>
<prevsent>(nakerebanari masen) functional expression which has very common functional meaning of must or have to.?
</prevsent>
</prevsection>
<citsent citstr=" W06-2404 ">
tsuchiya et al (2006)<papid> W06-2404 </papid>have proposed method based on machine learning to identify functional expressions.</citsent>
<aftsection>
<nextsent>however, this method only covers functional expressions which have balanced functional vs. content usage ratios.
</nextsent>
<nextsent>in order to boost coverage of current methods, we propose hybrid approach for functional expression identification which uses combination of the machine learning method proposed by tsuchiya et al (2006)<papid> W06-2404 </papid>and simple patterns.</nextsent>
<nextsent>coverage analysis and empirical evaluations show that our method doubles the coverage of previous approaches while still maintaining high level of performance.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2675">
<title id=" W10-1914.xml">reconstruction of semantic relationships from their projections in biomolecular domain </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the viability of the method is shown by successfully extracting nested relationships in bio infer and the corpus of the bionlp09 shared task on event extraction.
</prevsent>
<prevsent>the reported results, to the best of our knowledge, are the first for the nested relationships in bio infer on task in which only named entities are given.
</prevsent>
</prevsection>
<citsent citstr=" W09-1401 ">
a recent shared task in biomedical text mining,the bionlp09 shared task on event extraction (kim et al, 2009), <papid> W09-1401 </papid>showed that the biomedical natural language processing (bionlp) community is greatly interested in heading towards the extraction of deep, semantically rich relationships.</citsent>
<aftsection>
<nextsent>the shared task focused on biomolecular events involving proteins and called for methods that are capable of identifying nested structures.
</nextsent>
<nextsent>biomolecular events are major category of relationships in the biomedical domain inwhich, among others, relationships involving non molecular entities such as diseases and static relations such as protein family memberships are also of interest.
</nextsent>
<nextsent>earlier, well-studied extraction tasks typically cast the problem in such manner that relationships can be considered as mutually independent atomic units.
</nextsent>
<nextsent>however, as nested semantic structure grows in its depth and in the total number of relationship arguments, its simultaneous extraction becomes difficult, if not impossible.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2676">
<title id=" W10-1914.xml">reconstruction of semantic relationships from their projections in biomolecular domain </title>
<section> method.  </section>
<citcontext>
<prevsection>
<prevsent>for example, in the sentence and regulate c?, the entities and share both the argument type (agent) and the syntactic role (subject) relative to the relationshipregulate.
</prevsent>
<prevsent>they form group and are mutually exclusive (distributive) while this group forms single relationship (collective) together with c. as a1given that, in the deprojected graph, token can be referred to by multiple nodes only if they are of the same type result, ac and bc pairs of regulation are generated.
</prevsent>
</prevsection>
<citsent citstr=" P88-1003 ">
this approach relates to the collectivity and distributivity of plurals which have been studied, among others, by scha and stallard (1988) <papid> P88-1003 </papid>and brisson (2003).technically, the grouping is series of transformations in each of which set of successor sis replaced with single, newly-created successor and the original successors become the successors of this node.</citsent>
<aftsection>
<nextsent>the successors are first trivially grouped by the corresponding edge type.
</nextsent>
<nextsent>finally,they are recursively grouped by syntactic similarity until they form single group or multiple singleton groups.
</nextsent>
<nextsent>as result, nested groups are generated.
</nextsent>
<nextsent>the groups by syntax are determined by first mapping both the predecessor and the successors into the referred tokens in the syntactic graph.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2677">
<title id=" W10-1914.xml">reconstruction of semantic relationships from their projections in biomolecular domain </title>
<section> resources and experiments.  </section>
<citcontext>
<prevsection>
<prevsent>as result, the differences to the bionlp09 shared task dataset were minimised to additional node and edge types reflecting the wider selection of primary arguments.
</prevsent>
<prevsent>all employed parses follow the sd scheme.
</prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
bio infer contains un collapsed gold-standard parses while the bionlp09 shared task corpus includes parses, in the collapsed representation, generated by the parser of charniak and johnson(2005) <papid> P05-1022 </papid>using the model of mcclosky and charniak (2008).<papid> P08-2026 </papid></citsent>
<aftsection>
<nextsent>for both corpora, additional parses were produced with the improved version of the aforementioned system created by mcclosky (2009).
</nextsent>
<nextsent>these parses were transformed into both the collapsed and the conjunct dependency propagated representations with the tools provided by de marneffe et al (2006).
</nextsent>
<nextsent>all parses were further augmented by splitting tokens at non-alphanumeric characters that border named entities and connecting the newly-created tokens with dependencies denoting the character.
</nextsent>
<nextsent>3.1.1 predicted graphs the predicted semantic graphs were obtained as result of an extraction task adopted from thebionlp09 shared task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2678">
<title id=" W10-1914.xml">reconstruction of semantic relationships from their projections in biomolecular domain </title>
<section> resources and experiments.  </section>
<citcontext>
<prevsection>
<prevsent>as result, the differences to the bionlp09 shared task dataset were minimised to additional node and edge types reflecting the wider selection of primary arguments.
</prevsent>
<prevsent>all employed parses follow the sd scheme.
</prevsent>
</prevsection>
<citsent citstr=" P08-2026 ">
bio infer contains un collapsed gold-standard parses while the bionlp09 shared task corpus includes parses, in the collapsed representation, generated by the parser of charniak and johnson(2005) <papid> P05-1022 </papid>using the model of mcclosky and charniak (2008).<papid> P08-2026 </papid></citsent>
<aftsection>
<nextsent>for both corpora, additional parses were produced with the improved version of the aforementioned system created by mcclosky (2009).
</nextsent>
<nextsent>these parses were transformed into both the collapsed and the conjunct dependency propagated representations with the tools provided by de marneffe et al (2006).
</nextsent>
<nextsent>all parses were further augmented by splitting tokens at non-alphanumeric characters that border named entities and connecting the newly-created tokens with dependencies denoting the character.
</nextsent>
<nextsent>3.1.1 predicted graphs the predicted semantic graphs were obtained as result of an extraction task adopted from thebionlp09 shared task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2679">
<title id=" W10-1914.xml">reconstruction of semantic relationships from their projections in biomolecular domain </title>
<section> results and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>in the future, the proposed method will be studied and further improved with two other corpora, genia event annotation (kim et al, 2008) and gene regulation event corpus (thompson et al,2009), which are similar in their purpose compared to the already-analysed corpora.
</prevsent>
<prevsent>the former corpus is interesting because of the co-operativity of event participants which relaxes the restriction son asymmetric relationships while the latter contains an extensive annotation for non-primary arguments.
</prevsent>
</prevsection>
<citsent citstr=" W09-1301 ">
the method could also be examined with the static relation extraction task recently introduced by pyysalo et al (2009).<papid> W09-1301 </papid>in addition to improving the method and extending it to non-primary arguments, embedding 114 the presented approach to joint inference system, such as markov logic network (mln), will be studied.</citsent>
<aftsection>
<nextsent>deprojection is likely to greatly benefit methods based on markov logic which is not yetable to deal with cases where the number and identity of entities is unknown, while relations/links between known objects can be readily modelled?
</nextsent>
<nextsent>(riedel et al, 2009).<papid> W09-1406 </papid></nextsent>
<nextsent>the objective is to combine the graph prediction and the deprojection steps as well as to simultaneously enforce task-specificconstraints and adapt to the presence of false positive nodes and edges.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2680">
<title id=" W10-1914.xml">reconstruction of semantic relationships from their projections in biomolecular domain </title>
<section> results and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>the method could also be examined with the static relation extraction task recently introduced by pyysalo et al (2009).<papid> W09-1301 </papid>in addition to improving the method and extending it to non-primary arguments, embedding 114 the presented approach to joint inference system, such as markov logic network (mln), will be studied.</prevsent>
<prevsent>deprojection is likely to greatly benefit methods based on markov logic which is not yetable to deal with cases where the number and identity of entities is unknown, while relations/links between known objects can be readily modelled?</prevsent>
</prevsection>
<citsent citstr=" W09-1406 ">
(riedel et al, 2009).<papid> W09-1406 </papid></citsent>
<aftsection>
<nextsent>the objective is to combine the graph prediction and the deprojection steps as well as to simultaneously enforce task-specificconstraints and adapt to the presence of false positive nodes and edges.
</nextsent>
<nextsent>this should be achievable by extending the methods developed for the bionlp09 shared task corpus by riedel et al (2009) <papid> W09-1406 </papid>or by poon and vanderwende (2010), bothof which determine the correct argument combinations outside of the markov logic framework.semantic role labelling (srl) is task similar to the graph-based relationship extraction applied in this paper although the former typically only concerns shallow predicate argument structures (hacioglu, 2004; <papid> C04-1186 </papid>surdeanu et al, 2008).<papid> W08-2121 </papid></nextsent>
<nextsent>the similarities between the tasks suggest that exploring them jointly may benefit the development of information extraction methods.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2682">
<title id=" W10-1914.xml">reconstruction of semantic relationships from their projections in biomolecular domain </title>
<section> results and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>(riedel et al, 2009).<papid> W09-1406 </papid></prevsent>
<prevsent>the objective is to combine the graph prediction and the deprojection steps as well as to simultaneously enforce task-specificconstraints and adapt to the presence of false positive nodes and edges.</prevsent>
</prevsection>
<citsent citstr=" C04-1186 ">
this should be achievable by extending the methods developed for the bionlp09 shared task corpus by riedel et al (2009) <papid> W09-1406 </papid>or by poon and vanderwende (2010), bothof which determine the correct argument combinations outside of the markov logic framework.semantic role labelling (srl) is task similar to the graph-based relationship extraction applied in this paper although the former typically only concerns shallow predicate argument structures (hacioglu, 2004; <papid> C04-1186 </papid>surdeanu et al, 2008).<papid> W08-2121 </papid></citsent>
<aftsection>
<nextsent>the similarities between the tasks suggest that exploring them jointly may benefit the development of information extraction methods.
</nextsent>
<nextsent>in the long term, semantic schemes should be developed such that, ideally, all syntactic tokens are considered for their semantics and semantic relationships readily follow from their dependencies.
</nextsent>
<nextsent>such schemes, closely following the syntax, could improve both the graph prediction andthe deprojection.
</nextsent>
<nextsent>in this research direction, graph based knowledge representations such as conceptual graphs (sowa, 1976; chein and mugnier, 2008) or graphical logical forms such as the one proposed by allen et al (2008) <papid> W08-2227 </papid>could be adopted.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2683">
<title id=" W10-1914.xml">reconstruction of semantic relationships from their projections in biomolecular domain </title>
<section> results and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>(riedel et al, 2009).<papid> W09-1406 </papid></prevsent>
<prevsent>the objective is to combine the graph prediction and the deprojection steps as well as to simultaneously enforce task-specificconstraints and adapt to the presence of false positive nodes and edges.</prevsent>
</prevsection>
<citsent citstr=" W08-2121 ">
this should be achievable by extending the methods developed for the bionlp09 shared task corpus by riedel et al (2009) <papid> W09-1406 </papid>or by poon and vanderwende (2010), bothof which determine the correct argument combinations outside of the markov logic framework.semantic role labelling (srl) is task similar to the graph-based relationship extraction applied in this paper although the former typically only concerns shallow predicate argument structures (hacioglu, 2004; <papid> C04-1186 </papid>surdeanu et al, 2008).<papid> W08-2121 </papid></citsent>
<aftsection>
<nextsent>the similarities between the tasks suggest that exploring them jointly may benefit the development of information extraction methods.
</nextsent>
<nextsent>in the long term, semantic schemes should be developed such that, ideally, all syntactic tokens are considered for their semantics and semantic relationships readily follow from their dependencies.
</nextsent>
<nextsent>such schemes, closely following the syntax, could improve both the graph prediction andthe deprojection.
</nextsent>
<nextsent>in this research direction, graph based knowledge representations such as conceptual graphs (sowa, 1976; chein and mugnier, 2008) or graphical logical forms such as the one proposed by allen et al (2008) <papid> W08-2227 </papid>could be adopted.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2684">
<title id=" W10-1914.xml">reconstruction of semantic relationships from their projections in biomolecular domain </title>
<section> results and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>in the long term, semantic schemes should be developed such that, ideally, all syntactic tokens are considered for their semantics and semantic relationships readily follow from their dependencies.
</prevsent>
<prevsent>such schemes, closely following the syntax, could improve both the graph prediction andthe deprojection.
</prevsent>
</prevsection>
<citsent citstr=" W08-2227 ">
in this research direction, graph based knowledge representations such as conceptual graphs (sowa, 1976; chein and mugnier, 2008) or graphical logical forms such as the one proposed by allen et al (2008) <papid> W08-2227 </papid>could be adopted.</citsent>
<aftsection>
<nextsent>given the frequency of coordinations in the biomedical domain, deprojection may prove to be useful in the development of deep semantic parsing in the biomedical domain.
</nextsent>
<nextsent>for example, with improved semantic schemes, it could provide means to generate complete, detailed semantic graphs directly from deep dependency analyses in single-step by applying joint inference to achieve simultaneous node/edge re labelling and graph de projection.
</nextsent>
<nextsent>this study presents method for reconstructing the original semantic graphs from their projections by determining the correct combinations of relationship arguments.
</nextsent>
<nextsent>it generali ses the postprocessing step of the system described by bjorne et al (2010) and extends the extraction capability of this system to arbitrary graphs of nested biomolecular relationships.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2685">
<title id=" W10-0905.xml">mining script like structures from the web </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this knowledge is shared among large part of the population andlets us predict the next step in sequence in familiar situation, allows us to act appropriately, and enables us to omit details when communicating with others while ensuring common ground is maintained between communication partners.
</prevsent>
<prevsent>it seems we have such knowledge for vast variety of situations and scenarios, and thus natural language processing systems need access to equivalent information if they are to understand, converse, or reason about these situations.
</prevsent>
</prevsection>
<citsent citstr=" P08-1090 ">
these knowledge structures, comparable to scripts (schank and abelson, 1977) or narrative chains (chambers and jurafsky, 2008), <papid> P08-1090 </papid>describe typical sequences of events in particular context.given the number of potential scripts, their development by hand becomes resource intensive process.in the past, some work has been devoted to automatically construct script-like structures from compiled corpora (fujiki et al, 2003) <papid> E03-1061 </papid>chambers and jurafsky, 2008).<papid> P08-1090 </papid></citsent>
<aftsection>
<nextsent>such approaches, however, only produce scripts that are directly related to the topics represented in such corpora.
</nextsent>
<nextsent>therefore, newspaper corpora (e.g., the reuters corpus) are likely to contain scripts relating to government, crime and financials, but neglect other subject areas.
</nextsent>
<nextsent>we present system that extracts scripts from the web and removes the constraints of specialized corpora and domain limitations.
</nextsent>
<nextsent>we hope our iterative technique will produce scripts for vast variety of topics, and has the potential to produce more complete scripts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2686">
<title id=" W10-0905.xml">mining script like structures from the web </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this knowledge is shared among large part of the population andlets us predict the next step in sequence in familiar situation, allows us to act appropriately, and enables us to omit details when communicating with others while ensuring common ground is maintained between communication partners.
</prevsent>
<prevsent>it seems we have such knowledge for vast variety of situations and scenarios, and thus natural language processing systems need access to equivalent information if they are to understand, converse, or reason about these situations.
</prevsent>
</prevsection>
<citsent citstr=" E03-1061 ">
these knowledge structures, comparable to scripts (schank and abelson, 1977) or narrative chains (chambers and jurafsky, 2008), <papid> P08-1090 </papid>describe typical sequences of events in particular context.given the number of potential scripts, their development by hand becomes resource intensive process.in the past, some work has been devoted to automatically construct script-like structures from compiled corpora (fujiki et al, 2003) <papid> E03-1061 </papid>chambers and jurafsky, 2008).<papid> P08-1090 </papid></citsent>
<aftsection>
<nextsent>such approaches, however, only produce scripts that are directly related to the topics represented in such corpora.
</nextsent>
<nextsent>therefore, newspaper corpora (e.g., the reuters corpus) are likely to contain scripts relating to government, crime and financials, but neglect other subject areas.
</nextsent>
<nextsent>we present system that extracts scripts from the web and removes the constraints of specialized corpora and domain limitations.
</nextsent>
<nextsent>we hope our iterative technique will produce scripts for vast variety of topics, and has the potential to produce more complete scripts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2703">
<title id=" W10-3301.xml">kyoto an open platform for mining facts </title>
<section> kyoto overview.  </section>
<citcontext>
<prevsection>
<prevsent>the semantic processing involves the detection of named-entities (persons, organizations, places, time-expressions) and determining the meaning of words in the text according to the given wordnet.
</prevsent>
<prevsent>the output of the linguistic processors is stored in an xml annotation format that is the same for all the languages, called the kyoto annotation format (kaf, bosma et al  2009).
</prevsent>
</prevsection>
<citsent citstr=" W03-1901 ">
this format incorporates standardized proposals for the linguistic annotation of text and represents them in an easy-to-use layered structure, which is compatible with the linguistic annotation framework (laf, ide and romary 2003).<papid> W03-1901 </papid></citsent>
<aftsection>
<nextsent>in kaf, words, terms, constituents and syntactic dependencies are stored in separate layers with references across the structures.
</nextsent>
<nextsent>this makes it easier to harmonize the output of linguistic processors 2 http://www.kyoto-project.eu.
</nextsent>
<nextsent>for different languages and to add new semantic layers to the basic output, when needed (bosma et al  2009, vossen et al  2010).
</nextsent>
<nextsent>all modules in kyoto draw their input from these structures.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2704">
<title id=" W10-1838.xml">a proposal for a configurable silver standard </title>
<section> experimental setting.  </section>
<citcontext>
<prevsection>
<prevsent>the calbc partners?
</prevsent>
<prevsent>data do not necessarily come with tokenization information and, moreover, different partners/systems might have different tokenizations.
</prevsent>
</prevsection>
<citsent citstr=" D07-1051 ">
since common ground for comparison is thus lacking we added new, consistent tokenization based on the julie lab tok enizer (tomanek et al, 2007<papid> D07-1051 </papid>b).</citsent>
<aftsection>
<nextsent>this tokenizer is optimized for biomedical documents with intrinsic focus to keep complex biological terminological units (such as il-2?)
</nextsent>
<nextsent>unsegmented, but to split up tokens that are not terminologically connected (such as dividing il-2-related?
</nextsent>
<nextsent>up into il-2?, ?-?
</nextsent>
<nextsent>and related?).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2705">
<title id=" W10-1838.xml">a proposal for a configurable silver standard </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>the results are displayed in table 5.
</prevsent>
<prevsent>interestingly, the highest recall, precision, andf-score values (both for the exact and overlap condition) are shared by the same parameter combinations which also performed best in section 4.1.
</prevsent>
</prevsection>
<citsent citstr=" W04-1221 ">
hence, the use of named entity tagger supports the evaluation results when comparing the various biomedical entity recognition (settles, 2004).<papid> W04-1221 </papid></citsent>
<aftsection>
<nextsent>240 acc exactr exactp exactf overlapr over lapp overlapf systems threshold 0.95 0.62 0.69 0.65 0.76 0.85 0.81 sys-1 + sys-3 0.20 0.92 0.22 0.69 0.34 0.26 0.81 0.39 sys-2 + sys-5 0.60 0.95 0.55 0.75 0.63 0.67 0.91 0.78 sys-3 + sys-4 0.20 0.92 0.30 0.85 0.45 0.34 0.94 0.50 sys-4 + sys-5 0.60 table 4: twin pairs of taggers, contrasting the two best (in bold face) and the two worst performing pairs obtained by the confidence method.
</nextsent>
<nextsent>method acc exactr exactp exactf overlapr over lapp overlapf threshold agr.
</nextsent>
<nextsent>systems cosine 0.94 0.46 0.69 0.56 0.58 0.86 0.69 0.70 2.00 cosine 0.93 0.32 0.77 0.45 0.39 0.94 0.55 0.70 3.00 cosine 0.94 0.46 0.69 0.56 0.57 0.86 0.69 0.80 2.00 cosine 0.93 0.32 0.78 0.46 0.39 0.94 0.55 0.80 3.00 cosine 0.94 0.46 0.70 0.56 0.57 0.85 0.68 0.90 2.00 cosine 0.93 0.32 0.79 0.46 0.38 0.93 0.54 0.90 3.00 cosine 0.94 0.47 0.71 0.56 0.56 0.85 0.68 0.95 2.00 cosine 0.93 0.33 0.80 0.47 0.38 0.93 0.54 0.95 3.00 cosine 0.94 0.47 0.73 0.57 0.56 0.85 0.67 0.97 2.00 cosine 0.93 0.33 0.82 0.47 0.38 0.93 0.54 0.97 3.00 confidence 0.94 0.50 0.72 0.59 0.60 0.85 0.70 0.20 confidence 0.93 0.36 0.82 0.50 0.41 0.93 0.56 0.40 confidence 0.92 0.25 0.87 0.39 0.28 0.95 0.43 0.60 confidence 0.91 0.12 0.89 0.20 0.12 0.96 0.22 0.80 table 5: performance of an ner tagger trained on an ssc, 10-fold cross validation, and all systems.
</nextsent>
<nextsent>parameters: threshold (confidence or cosine) and number of agreeing systems (agr.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2707">
<title id=" W10-3805.xml">phrase based decoding using a discriminative model </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we present an approach to statistical machine translation that combines the power of discriminative model(for training model for machine transla tion), and the standard beam-search based decoding technique (for the translation ofan input sentence).
</prevsent>
<prevsent>a discriminative approach for learning lexical selection and reordering utilizes large set of feature functions (thereby providing the power to incorporate greater contextual and linguistic information), which leads to an effective training of these models.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
this model is then used by the standard state-of-art moses decoder (koehn et al, 2007) <papid> P07-2045 </papid>for the translation of an input sentence.</citsent>
<aftsection>
<nextsent>we conducted our experiments on spanish-english language pair.
</nextsent>
<nextsent>we used maximum entropy model in our experiments.
</nextsent>
<nextsent>we show that the performance of our approach (using simple lexical features) is comparable to that of the state-of-art statistical mt system (koehn et al, 2007).<papid> P07-2045 </papid></nextsent>
<nextsent>when additional syntactic features (pos tags in this paper) are used, there is boost in the performance which is likely to improve when richer syntactic features are incorporated in the model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2710">
<title id=" W10-3805.xml">phrase based decoding using a discriminative model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we show that the performance of our approach (using simple lexical features) is comparable to that of the state-of-art statistical mt system (koehn et al, 2007).<papid> P07-2045 </papid></prevsent>
<prevsent>when additional syntactic features (pos tags in this paper) are used, there is boost in the performance which is likely to improve when richer syntactic features are incorporated in the model.</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
the popular approaches to machine translation use the generative ibm models for training(brown et al, 1993; <papid> J93-2003 </papid>och et al, 1999).<papid> W99-0604 </papid></citsent>
<aftsection>
<nextsent>the parameters for these models are learnt using the standard em algorithm.
</nextsent>
<nextsent>the parameters used in these models are extremely restrictive, that is, simple, small and closed set of feature functions is used to represent the translation process.
</nextsent>
<nextsent>also, these feature functions are local and are word based.
</nextsent>
<nextsent>inspite of these limitations, these models perform very well for the task of word-alignment because of the restricted search space.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2711">
<title id=" W10-3805.xml">phrase based decoding using a discriminative model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we show that the performance of our approach (using simple lexical features) is comparable to that of the state-of-art statistical mt system (koehn et al, 2007).<papid> P07-2045 </papid></prevsent>
<prevsent>when additional syntactic features (pos tags in this paper) are used, there is boost in the performance which is likely to improve when richer syntactic features are incorporated in the model.</prevsent>
</prevsection>
<citsent citstr=" W99-0604 ">
the popular approaches to machine translation use the generative ibm models for training(brown et al, 1993; <papid> J93-2003 </papid>och et al, 1999).<papid> W99-0604 </papid></citsent>
<aftsection>
<nextsent>the parameters for these models are learnt using the standard em algorithm.
</nextsent>
<nextsent>the parameters used in these models are extremely restrictive, that is, simple, small and closed set of feature functions is used to represent the translation process.
</nextsent>
<nextsent>also, these feature functions are local and are word based.
</nextsent>
<nextsent>inspite of these limitations, these models perform very well for the task of word-alignment because of the restricted search space.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2712">
<title id=" W10-3805.xml">phrase based decoding using a discriminative model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>also, these feature functions are local and are word based.
</prevsent>
<prevsent>inspite of these limitations, these models perform very well for the task of word-alignment because of the restricted search space.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
however, they perform poorly during decoding (or translation) be cause of their limitations in the context of much larger search space.to handle the contextual information, phrase based models were introduced (koehn et al, 2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>the phrase-based models use the word alignment information from the ibm models and train source-target phrase pairs for lexical selection (phrase-table) and distortions of source phrases (reordering-table).
</nextsent>
<nextsent>these models are still relatively local, as the target phrases are tightly associated with their corresponding source phrases.in contrast to phrase-based model, discriminative model has the power to integrate much richer contextual information into the trainingmodel.
</nextsent>
<nextsent>contextual information is extremely useful in making lexical selections of higher quality,as illustrated by the models for global lexical selection (bangalore et al, 2007; <papid> P07-1020 </papid>venkatapathy and 34 bangalore, 2009).however, the limitation of global lexical selection models has been sentence construction.in global lexical selection models, lattice construction and scoring (lcs) is used for the purpose of sentence construction (bangalore et al, 2007; <papid> P07-1020 </papid>venkatapathy and bangalore, 2009).</nextsent>
<nextsent>in ourwork, we address this limitation of global lexical selection models by using an existing state-of art decoder (koehn et al, 2007) <papid> P07-2045 </papid>for the purpose of sentence construction.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2713">
<title id=" W10-3805.xml">phrase based decoding using a discriminative model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the phrase-based models use the word alignment information from the ibm models and train source-target phrase pairs for lexical selection (phrase-table) and distortions of source phrases (reordering-table).
</prevsent>
<prevsent>these models are still relatively local, as the target phrases are tightly associated with their corresponding source phrases.in contrast to phrase-based model, discriminative model has the power to integrate much richer contextual information into the trainingmodel.
</prevsent>
</prevsection>
<citsent citstr=" P07-1020 ">
contextual information is extremely useful in making lexical selections of higher quality,as illustrated by the models for global lexical selection (bangalore et al, 2007; <papid> P07-1020 </papid>venkatapathy and 34 bangalore, 2009).however, the limitation of global lexical selection models has been sentence construction.in global lexical selection models, lattice construction and scoring (lcs) is used for the purpose of sentence construction (bangalore et al, 2007; <papid> P07-1020 </papid>venkatapathy and bangalore, 2009).</citsent>
<aftsection>
<nextsent>in ourwork, we address this limitation of global lexical selection models by using an existing state-of art decoder (koehn et al, 2007) <papid> P07-2045 </papid>for the purpose of sentence construction.</nextsent>
<nextsent>the translation model used by this decoder is derived from discriminative model, instead of the usual phrase-table andreordering-table construction algorithms.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2723">
<title id=" W10-3805.xml">phrase based decoding using a discriminative model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we compare the sentence construction accuracies of lattice construction and scoring approach (seesection 4.1 for lcs decoding) and the phrase based decoding approach (see section 4.2).another advantage of using discriminative approach to construct the phrase table and the reordering table is the flexibility it provides to incorporate linguistic knowledge in the form of additional feature functions.
</prevsent>
<prevsent>in the past, factored phrase-based approaches for machine translation have allowed the use of linguistic feature functions.
</prevsent>
</prevsection>
<citsent citstr=" D07-1091 ">
but, they are still bound by the locality of context, and definition of fixed structure of dependencies between the factors (koehnand hoang, 2007).<papid> D07-1091 </papid></citsent>
<aftsection>
<nextsent>furthermore, factored phrase based approaches place constraints both on thetype and number of factors that can be incorporated into the training.
</nextsent>
<nextsent>in this paper, though we donot extensively test this aspect, we show that using syntactic feature functions does improve the performance of our approach, which is likely to improve when much richer syntactic feature functions (such as information about the parse struc ture) are incorporated in the model.as the training model in standard phrase based system is relatively impoverished with respect to contextual/linguistic information, integration of the discriminative model in the form ofphrase-table and reordering-table with the phrase based decoder is highly desirable.
</nextsent>
<nextsent>we propose to do this by defining sentence specific tables.
</nextsent>
<nextsent>for example, given source sentence s, the phrase table contains all the possible phrase-pairs conditioned on the context of the source sentence s. in this paper, the key contributions are, 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2724">
<title id=" W10-3805.xml">phrase based decoding using a discriminative model </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>finally we conclude the paper in section 7.
</prevsent>
<prevsent>in this section, we present approaches that are directly related to our approach.
</prevsent>
</prevsection>
<citsent citstr=" P02-1038 ">
in direct translation model (dtm) proposed for statistical machine translation by (papineni et al, 1998; ochand ney, 2002), <papid> P02-1038 </papid>the authors present discriminative set-up for natural language understanding (and mt).</citsent>
<aftsection>
<nextsent>they use slightly modified equation(in comparison to ibm models) as shown in equation 1.
</nextsent>
<nextsent>in equation 1, they consider the translation model from ? (p(e|f)), instead of the theoretically sound (after the application of bayesrule), ? (p(f |e)) and use grammatical features such as the presence of equal number of 35 verbs forms etc. e? = argmax ptm (e|f) ? plm (e) (1)in their model, they use generic feature functions such as language model, co occurence features such as presence of lexical relationship in the lexicon.
</nextsent>
<nextsent>their search algorithm limited the use of complex features.direct translation model 2 (dtm2) (ittycheriah and roukos, 2007) <papid> N07-1008 </papid>expresses the phrase based translation task in unified log-linear probabilistic framework consisting of three compo nents: 1.</nextsent>
<nextsent>a prior conditional distribution p02.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2725">
<title id=" W10-3805.xml">phrase based decoding using a discriminative model </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>they use slightly modified equation(in comparison to ibm models) as shown in equation 1.
</prevsent>
<prevsent>in equation 1, they consider the translation model from ? (p(e|f)), instead of the theoretically sound (after the application of bayesrule), ? (p(f |e)) and use grammatical features such as the presence of equal number of 35 verbs forms etc. e? = argmax ptm (e|f) ? plm (e) (1)in their model, they use generic feature functions such as language model, co occurence features such as presence of lexical relationship in the lexicon.
</prevsent>
</prevsection>
<citsent citstr=" N07-1008 ">
their search algorithm limited the use of complex features.direct translation model 2 (dtm2) (ittycheriah and roukos, 2007) <papid> N07-1008 </papid>expresses the phrase based translation task in unified log-linear probabilistic framework consisting of three compo nents: 1.</citsent>
<aftsection>
<nextsent>a prior conditional distribution p02.
</nextsent>
<nextsent>a number of feature functions i() that capture the effects of translation and language model3.
</nextsent>
<nextsent>the weights of the features that are estimated using maxent training (berger et al, 1996) <papid> J96-1002 </papid>as shown in equation 2.</nextsent>
<nextsent>pr(e|f) = p0(e, j|f)z exp ? ii(e, j, f) (2) in the above equation, is the skip reordering factor for the phrase pair captured byi() and represents the jump from the previous source word.z represents the per source sentence normalization term (hassan et al, 2009).<papid> D09-1123 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2726">
<title id=" W10-3805.xml">phrase based decoding using a discriminative model </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>a prior conditional distribution p02.
</prevsent>
<prevsent>a number of feature functions i() that capture the effects of translation and language model3.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
the weights of the features that are estimated using maxent training (berger et al, 1996) <papid> J96-1002 </papid>as shown in equation 2.</citsent>
<aftsection>
<nextsent>pr(e|f) = p0(e, j|f)z exp ? ii(e, j, f) (2) in the above equation, is the skip reordering factor for the phrase pair captured byi() and represents the jump from the previous source word.z represents the per source sentence normalization term (hassan et al, 2009).<papid> D09-1123 </papid></nextsent>
<nextsent>while uniform prior on the set of futures results in maximum entropy model, choosing other priors out put minimum divergence models.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2727">
<title id=" W10-3805.xml">phrase based decoding using a discriminative model </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>a number of feature functions i() that capture the effects of translation and language model3.
</prevsent>
<prevsent>the weights of the features that are estimated using maxent training (berger et al, 1996) <papid> J96-1002 </papid>as shown in equation 2.</prevsent>
</prevsection>
<citsent citstr=" D09-1123 ">
pr(e|f) = p0(e, j|f)z exp ? ii(e, j, f) (2) in the above equation, is the skip reordering factor for the phrase pair captured byi() and represents the jump from the previous source word.z represents the per source sentence normalization term (hassan et al, 2009).<papid> D09-1123 </papid></citsent>
<aftsection>
<nextsent>while uniform prior on the set of futures results in maximum entropy model, choosing other priors out put minimum divergence models.
</nextsent>
<nextsent>normalized phrase count has been used as the prior p0 in the dtm2 model.the following decision rule is used to obtain optimal translation.
</nextsent>
<nextsent>e? = argmax pr(e|f) = argmax m?
</nextsent>
<nextsent>m=1 mm(f, e) (3)the dtm2 model differs from other phrase based smt models in that it avoids the redundancy present in other systems by extracting from word aligned parallel corpora set of minimal phrases such that no two phrases overlap with each other (hassan et al, 2009).<papid> D09-1123 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2732">
<title id=" W10-3805.xml">phrase based decoding using a discriminative model </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in our approach, instead of providing the complete scoring function ourselves, we compute the parameters needed by phrase based decoder, which inturn uses these parameters appropriately.
</prevsent>
<prevsent>in comparison with the dtm2, we also use minimal nonoverlapping blocks as the entries in the phrase table that we generate.
</prevsent>
</prevsection>
<citsent citstr=" P06-1066 ">
xiong et al (2006) <papid> P06-1066 </papid>present phrase reordering model under the itg constraint using maximum entropy framework.</citsent>
<aftsection>
<nextsent>they model the reordering problem as two-class classification problem, the classes being straight and inverted.
</nextsent>
<nextsent>the model isused to merge the phrases obtained from translating the segments in source sentence.
</nextsent>
<nextsent>the decoder used is hierarchical decoder motivated from the cyk parsing algorithm employing beam search algorithm.
</nextsent>
<nextsent>the maximum entropy model is presented with features extracted fromthe blocks being merged and probabilities are estimated using the log-linear equation shown in (4).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2743">
<title id=" W10-3805.xml">phrase based decoding using a discriminative model </title>
<section> experiments and results.  </section>
<citcontext>
<prevsection>
<prevsent>corpus no.
</prevsent>
<prevsent>of sentences source target training 200000 59591 36886 testing 2525 10629 8905 development 2051 8888 7750 monolingual 200000 n.a 36886 english (lm)table 1: corpus statistics for spanish-english corpus.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
the output of our experiments was evaluated using two metrics, (1) bleu (papineni et al, 2002),<papid> P02-1040 </papid>and (2) lexical accuracy (lexacc).</citsent>
<aftsection>
<nextsent>lexical accuracy measures the similarity between theun ordered bag of words in the reference sentence 39against the unordered bag of words in the hypothesized translation.
</nextsent>
<nextsent>lexical accuracy is measure of the fidelity of lexical transfer from the source to the target sentence, independent of the syntax of the target language (venkatapathy and bangalore, 2009).
</nextsent>
<nextsent>we report lexical accuracies to show the performance of lcs decoding in comparison with the baseline system.
</nextsent>
<nextsent>we first present the results of the state-of-artphrase-based model (moses) trained on parallel corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2744">
<title id=" W10-3805.xml">phrase based decoding using a discriminative model </title>
<section> conclusions and future work.  </section>
<citcontext>
<prevsection>
<prevsent>3.
</prevsent>
<prevsent>improving lcs decoding algorithm using.
</prevsent>
</prevsection>
<citsent citstr=" W07-0413 ">
syntactic cues in the target (venkatapathy and bangalore, 2007) <papid> W07-0413 </papid>such as supertags.</citsent>
<aftsection>




</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2745">
<title id=" W10-1408.xml">handling unknown words in statistical latent variable parsing models for arabic english and french </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the language to be parsed is heavily inflected.
</prevsent>
<prevsent>we concentrate on the latter case, and examine the problem of unknown words for two languages which lieon opposite ends of the spectrum of morphological expressiveness and for one language which lies somewhere in between: arabic, english and french.in our experiments we use berkeley-style latent variable pcfg parser and we contrast two techniques for handling unknown words within the generative parsing model: one in which no language specific information is employed and one in which morphological clues (or signatures) are exploited.we find that the improvement accrued from looking at words morphology is greater for arabic and french than for english.
</prevsent>
</prevsection>
<citsent citstr=" P06-1055 ">
the morphological clues we use for english are taken directly from the berkeley parser (petrov et al, 2006) <papid> P06-1055 </papid>and those for french from recent work on french statistical parsing with the berkeley parser (crabbe?</citsent>
<aftsection>
<nextsent>and candito, 2008; candito et al, 2009).<papid> W09-3821 </papid></nextsent>
<nextsent>for arabic, we present our own set of heuristics to extract these signature sand demonstrate statistically significant improvement of 3.25% over the baseline model which does not employ morphological information.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2746">
<title id=" W10-1408.xml">handling unknown words in statistical latent variable parsing models for arabic english and french </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we concentrate on the latter case, and examine the problem of unknown words for two languages which lieon opposite ends of the spectrum of morphological expressiveness and for one language which lies somewhere in between: arabic, english and french.in our experiments we use berkeley-style latent variable pcfg parser and we contrast two techniques for handling unknown words within the generative parsing model: one in which no language specific information is employed and one in which morphological clues (or signatures) are exploited.we find that the improvement accrued from looking at words morphology is greater for arabic and french than for english.
</prevsent>
<prevsent>the morphological clues we use for english are taken directly from the berkeley parser (petrov et al, 2006) <papid> P06-1055 </papid>and those for french from recent work on french statistical parsing with the berkeley parser (crabbe?</prevsent>
</prevsection>
<citsent citstr=" W09-3821 ">
and candito, 2008; candito et al, 2009).<papid> W09-3821 </papid></citsent>
<aftsection>
<nextsent>for arabic, we present our own set of heuristics to extract these signature sand demonstrate statistically significant improvement of 3.25% over the baseline model which does not employ morphological information.
</nextsent>
<nextsent>we next try to establish to what extent these clues can be learnt automatically by extracting affixes from the words in the training data and ranking these using information gain.
</nextsent>
<nextsent>we show that this automatic method performs quite well for all three languages.
</nextsent>
<nextsent>the paper is organised as follows: in section 2 we describe latent variable pcfg parsing models.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2748">
<title id=" W10-1408.xml">handling unknown words in statistical latent variable parsing models for arabic english and french </title>
<section> latent variable pcfg parsing.  </section>
<citcontext>
<prevsection>
<prevsent>in section 7, we describe our attempt sto automatically determine the signatures for language and present parsing results for the three languages.
</prevsent>
<prevsent>finally, in section 8, we discuss how this work might be fruitfully extended.
</prevsent>
</prevsection>
<citsent citstr=" J98-4004 ">
johnson (1998) <papid> J98-4004 </papid>showed that refining treebank categories with parent information leads to more accurate grammars.</citsent>
<aftsection>
<nextsent>this was followed by collection of linguistically motivated propositions for manual orsemi-automatic modifications of categories in treebanks (klein and manning, 2003).<papid> P03-1054 </papid></nextsent>
<nextsent>in pcfg-las,first introduced by matsuzaki et al (2005), <papid> P05-1010 </papid>the refined categories are learnt from the treebank using unsupervised techniques.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2749">
<title id=" W10-1408.xml">handling unknown words in statistical latent variable parsing models for arabic english and french </title>
<section> latent variable pcfg parsing.  </section>
<citcontext>
<prevsection>
<prevsent>finally, in section 8, we discuss how this work might be fruitfully extended.
</prevsent>
<prevsent>johnson (1998) <papid> J98-4004 </papid>showed that refining treebank categories with parent information leads to more accurate grammars.</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
this was followed by collection of linguistically motivated propositions for manual orsemi-automatic modifications of categories in treebanks (klein and manning, 2003).<papid> P03-1054 </papid></citsent>
<aftsection>
<nextsent>in pcfg-las,first introduced by matsuzaki et al (2005), <papid> P05-1010 </papid>the refined categories are learnt from the treebank using unsupervised techniques.</nextsent>
<nextsent>each base category?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2750">
<title id=" W10-1408.xml">handling unknown words in statistical latent variable parsing models for arabic english and french </title>
<section> latent variable pcfg parsing.  </section>
<citcontext>
<prevsection>
<prevsent>johnson (1998) <papid> J98-4004 </papid>showed that refining treebank categories with parent information leads to more accurate grammars.</prevsent>
<prevsent>this was followed by collection of linguistically motivated propositions for manual orsemi-automatic modifications of categories in treebanks (klein and manning, 2003).<papid> P03-1054 </papid></prevsent>
</prevsection>
<citsent citstr=" P05-1010 ">
in pcfg-las,first introduced by matsuzaki et al (2005), <papid> P05-1010 </papid>the refined categories are learnt from the treebank using unsupervised techniques.</citsent>
<aftsection>
<nextsent>each base category?
</nextsent>
<nextsent>and this includes part-of-speech tags ? is augmented with an annotation that refines its distributional properties.
</nextsent>
<nextsent>following petrov et al (2006) <papid> P06-1055 </papid>latent annotations and probabilities for the associated rules are learnt incrementally following an iterative process consisting of the repetition of three steps.</nextsent>
<nextsent>1.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2753">
<title id=" W10-1408.xml">handling unknown words in statistical latent variable parsing models for arabic english and french </title>
<section> latent variable pcfg parsing.  </section>
<citcontext>
<prevsection>
<prevsent>tations and discard the least useful ones.
</prevsent>
<prevsent>re estimate probabilities with the new set of anno tations.we use our own parser which trains pcfg-la using the above procedure and parses using the max1estimation of the parameters is performed by running ex pectation/maximisation on the training corpus.
</prevsent>
</prevsection>
<citsent citstr=" N07-1051 ">
rule parsing algorithm (petrov et al, 2006; <papid> P06-1055 </papid>petrov and klein, 2007).<papid> N07-1051 </papid></citsent>
<aftsection>
<nextsent>pcfg-la parsing is relatively language-independent but has been shown to be very effective on several languages (petrov, 2009).
</nextsent>
<nextsent>for our experiments, we set the number of iterations to be 5 and we test on sentences less than or equal to 40 words in length.
</nextsent>
<nextsent>all our experiments, apart from the final one, are carried out on the development sets of our three languages.
</nextsent>
<nextsent>arabic we use the the penn arabic treebank (atb) (bies and maamouri, 2003; maamouri and bies., 2004).<papid> W04-1602 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2754">
<title id=" W10-1408.xml">handling unknown words in statistical latent variable parsing models for arabic english and french </title>
<section> the datasets.  </section>
<citcontext>
<prevsection>
<prevsent>for our experiments, we set the number of iterations to be 5 and we test on sentences less than or equal to 40 words in length.
</prevsent>
<prevsent>all our experiments, apart from the final one, are carried out on the development sets of our three languages.
</prevsent>
</prevsection>
<citsent citstr=" W04-1602 ">
arabic we use the the penn arabic treebank (atb) (bies and maamouri, 2003; maamouri and bies., 2004).<papid> W04-1602 </papid></citsent>
<aftsection>
<nextsent>the atb describes written modern standard arabic newswire and follows the style and guidelines of the english penn-ii treebank.
</nextsent>
<nextsent>we use the part-of-speech tagset defined by bikel and bies (bikel, 2004).
</nextsent>
<nextsent>we employ the usual treebank split (80% training, 10% development and 10% test).
</nextsent>
<nextsent>english we use the wall street journal section of the penn-ii treebank (marcus et al, 1994).<papid> H94-1020 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2755">
<title id=" W10-1408.xml">handling unknown words in statistical latent variable parsing models for arabic english and french </title>
<section> the datasets.  </section>
<citcontext>
<prevsection>
<prevsent>we use the part-of-speech tagset defined by bikel and bies (bikel, 2004).
</prevsent>
<prevsent>we employ the usual treebank split (80% training, 10% development and 10% test).
</prevsent>
</prevsection>
<citsent citstr=" H94-1020 ">
english we use the wall street journal section of the penn-ii treebank (marcus et al, 1994).<papid> H94-1020 </papid></citsent>
<aftsection>
<nextsent>we train our parser on sections 2-21 and use section 22 con catenated with section 24 as our development set.
</nextsent>
<nextsent>final testing is carried out on section 23.
</nextsent>
<nextsent>french we use the french treebank (abeille?
</nextsent>
<nextsent>et al., 2003) and divide it into 80% for training, 10%for development and 10% for final results.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2756">
<title id=" W10-1408.xml">handling unknown words in statistical latent variable parsing models for arabic english and french </title>
<section> making use of morphology.  </section>
<citcontext>
<prevsection>
<prevsent>unknown words are not all the same.
</prevsent>
<prevsent>we exploit this fact by examining the effect on parsing accuracy of clustering rare training set words using cues from the words morphological structure.
</prevsent>
</prevsection>
<citsent citstr=" I05-3005 ">
affixes have been shown to be useful in part-of-speech tagging (schmid, 1994; tseng et al, 2005) <papid> I05-3005 </papid>and have been used in the charniak (charniak, 2000), <papid> A00-2018 </papid>stanford (klein and manning, 2003) <papid> P03-1054 </papid>and berkeley (petrov et al., 2006) <papid> P06-1055 </papid>parsers.</citsent>
<aftsection>
<nextsent>in this section, we contrast the effect on parsing accuracy of making use of such information for our three languages of interest.
</nextsent>
<nextsent>returning to our toy english example in figures 1and 2, and given the input sentence the shares recovered, we would like to use the fact that theun known word recovered ends with the past tense suffix -ed to boost the probability of the lexical rule bd ? unknown.
</nextsent>
<nextsent>if we specialise the unknown terminal using information from english morphology, we can do just that, resulting in the grammar in figure 3.
</nextsent>
<nextsent>now the word recovered is mapped to the symbol unk-ed and the only edge which is added to the chart at this position is the one corresponding to the rule bd ? unk-ed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2757">
<title id=" W10-1408.xml">handling unknown words in statistical latent variable parsing models for arabic english and french </title>
<section> making use of morphology.  </section>
<citcontext>
<prevsection>
<prevsent>unknown words are not all the same.
</prevsent>
<prevsent>we exploit this fact by examining the effect on parsing accuracy of clustering rare training set words using cues from the words morphological structure.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
affixes have been shown to be useful in part-of-speech tagging (schmid, 1994; tseng et al, 2005) <papid> I05-3005 </papid>and have been used in the charniak (charniak, 2000), <papid> A00-2018 </papid>stanford (klein and manning, 2003) <papid> P03-1054 </papid>and berkeley (petrov et al., 2006) <papid> P06-1055 </papid>parsers.</citsent>
<aftsection>
<nextsent>in this section, we contrast the effect on parsing accuracy of making use of such information for our three languages of interest.
</nextsent>
<nextsent>returning to our toy english example in figures 1and 2, and given the input sentence the shares recovered, we would like to use the fact that theun known word recovered ends with the past tense suffix -ed to boost the probability of the lexical rule bd ? unknown.
</nextsent>
<nextsent>if we specialise the unknown terminal using information from english morphology, we can do just that, resulting in the grammar in figure 3.
</nextsent>
<nextsent>now the word recovered is mapped to the symbol unk-ed and the only edge which is added to the chart at this position is the one corresponding to the rule bd ? unk-ed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2760">
<title id=" W10-1408.xml">handling unknown words in statistical latent variable parsing models for arabic english and french </title>
<section> making use of morphology.  </section>
<citcontext>
<prevsection>
<prevsent>for our english experiments we use the unknown word classes (or signatures) which are used in the berkeley parser.
</prevsent>
<prevsent>a signature indicates whether words contains digit or hyphen, if word starts with capital letter or ends with one of the following english suffixes (both derivational and inflectional): -s, -ed, -ing, -ion, -er, -est, -ly, -ity, -y and -al. for our french experiments we employ the same signature list as crabbe?
</prevsent>
</prevsection>
<citsent citstr=" P05-1038 ">
and candito (2008), which itself was adapted from arun and keller (2005).<papid> P05-1038 </papid>this list consists of (a) conjugation suffixes of regu 70 lar verbs for common tenses (eg.</citsent>
<aftsection>
<nextsent>-ons, -ez, -ent.
</nextsent>
<nextsent>) and (b) derivational suffixes for nouns, adverbs and adjectives (eg.
</nextsent>
<nextsent>-tion, -ment, -able.
</nextsent>
<nextsent>the result of employing signature information for french and english is shown in table 3.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2761">
<title id=" W10-1408.xml">handling unknown words in statistical latent variable parsing models for arabic english and french </title>
<section> arabic signatures.  </section>
<citcontext>
<prevsection>
<prevsent>we exploit all the richness of the morphology of this language which can be expressed through morphotactics.
</prevsent>
<prevsent>6.1 handling arabic morphotactics.
</prevsent>
</prevsection>
<citsent citstr=" W98-1007 ">
morpho tactics refers to the way morphemes combine together to form words (beesley, 1998; <papid> W98-1007 </papid>beesley and karttunen, 2003).</citsent>
<aftsection>
<nextsent>generally speaking, morpho tactics can be concatenative, with morphemes either prefixed or suffixed to stems, or non-concatenative,with stems undergoing internal alternations to convey morphosyntactic information.
</nextsent>
<nextsent>arabic is considered typical example of language that employs non-concatenative morphotactics.
</nextsent>
<nextsent>arabic words are traditionally classified into three types: verbs, nouns and particles.
</nextsent>
<nextsent>adjectives take almost all the morphological forms of, and share the same templatic structures with, nouns.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2762">
<title id=" W10-1408.xml">handling unknown words in statistical latent variable parsing models for arabic english and french </title>
<section> arabic signatures.  </section>
<citcontext>
<prevsection>
<prevsent>whether as a6the heuristics we developed are designed to work on diacritized texts.
</prevsent>
<prevsent>although diacritics are generally ignored in modern writing, the issue of restoring diacritics has been satisfactorily addressed by different researchers.
</prevsent>
</prevsection>
<citsent citstr=" W05-0711 ">
for example, nelkenand shieber (2005) <papid> W05-0711 </papid>presented an algorithm for restoring diacritics to undiacritized msa texts with an accuracy of over 90% and habasah et al (2009) reported on freely-available toolkit (mada-tokan) an accuracy of over 96%.</citsent>
<aftsection>
<nextsent>71 unknown threshold recall precision f-score tagging accuracy arabic 1 80.67 82.19 *81.42 (+ 1.89) 96.32 5 80.66 82.81 *81.72 (+ 3.25) 95.15 10 79.86 82.49 *81.15 (+ 4.18) 94.38 english 1 ***89.64 89.95 89.79 (+ 0.32) 96.44 5 89.16 89.80 89.48 (+ 0.15) 96.32 10 89.14 89.78 **89.46 (+ 0.98) 96.21 french 1 85.15 85.77 *85.46 (+ 1.58) 96.13 5 84.08 84.80 *84.44 (+ 1.74) 95.54 10 84.21 84.78 *84.49 (+ 3.04) 94.68 table 3: baseline signatures for arabic, french and english statistically significant with *:p   104, **:   103, ***:   0.004, template name regular specification arabic buckwalter expression  ? ?
</nextsent>
<nextsent>k   {inofieal {ino.i.a. verbal noun (masdar)  ? ??
</nextsent>
<nextsent>mifoeal mi.o.a. noun instrument ??
</nextsent>
<nextsent>?   j?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2763">
<title id=" W10-1408.xml">handling unknown words in statistical latent variable parsing models for arabic english and french </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>token isation is an issue particularly for arabic, but also for french (since the treebank contains merged compounds) and to much lesser extent for english (unedited text with missing apostrophes).
</prevsent>
<prevsent>itis important that the experiments in this paper are repeated on untokenised text using automatic tokeni sation methods (e.g. mada-tokan).the performance improvements that we demonstrate for arabic unknown-word handling are obviously just the tip of the iceberg in terms of what canbe done to improve performance on morphologically rich language.
</prevsent>
</prevsection>
<citsent citstr=" D09-1087 ">
the simple generative lexical probability model we use can be improved by adopting more sophisticated approach in which known and unknown word counts are combined when estimating lexical rule probabilities for rare words (seehuang and harper (2009) <papid> D09-1087 </papid>and the berkeley sophis ticatedlexicon training option).</citsent>
<aftsection>
<nextsent>further work will also include making use of lexical resource external to the treebank (goldberg et al, 2009; <papid> E09-1038 </papid>habash,2008) <papid> P08-2015 </papid>and investigating clustering techniques to reduce data sparseness (candito and crabbe?, 2009).</nextsent>
<nextsent>acknowledgements this research is funded by enterprise ireland(cftd/07/229 and pc/09/037) and the irish research council for science engineering and technology (ircset).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2764">
<title id=" W10-1408.xml">handling unknown words in statistical latent variable parsing models for arabic english and french </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>itis important that the experiments in this paper are repeated on untokenised text using automatic tokeni sation methods (e.g. mada-tokan).the performance improvements that we demonstrate for arabic unknown-word handling are obviously just the tip of the iceberg in terms of what canbe done to improve performance on morphologically rich language.
</prevsent>
<prevsent>the simple generative lexical probability model we use can be improved by adopting more sophisticated approach in which known and unknown word counts are combined when estimating lexical rule probabilities for rare words (seehuang and harper (2009) <papid> D09-1087 </papid>and the berkeley sophis ticatedlexicon training option).</prevsent>
</prevsection>
<citsent citstr=" E09-1038 ">
further work will also include making use of lexical resource external to the treebank (goldberg et al, 2009; <papid> E09-1038 </papid>habash,2008) <papid> P08-2015 </papid>and investigating clustering techniques to reduce data sparseness (candito and crabbe?, 2009).</citsent>
<aftsection>
<nextsent>acknowledgements this research is funded by enterprise ireland(cftd/07/229 and pc/09/037) and the irish research council for science engineering and technology (ircset).
</nextsent>
<nextsent>we thank marie candito and our three reviewers for their very helpful suggestions.
</nextsent>
<nextsent>74
</nextsent>

</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2765">
<title id=" W10-1408.xml">handling unknown words in statistical latent variable parsing models for arabic english and french </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>itis important that the experiments in this paper are repeated on untokenised text using automatic tokeni sation methods (e.g. mada-tokan).the performance improvements that we demonstrate for arabic unknown-word handling are obviously just the tip of the iceberg in terms of what canbe done to improve performance on morphologically rich language.
</prevsent>
<prevsent>the simple generative lexical probability model we use can be improved by adopting more sophisticated approach in which known and unknown word counts are combined when estimating lexical rule probabilities for rare words (seehuang and harper (2009) <papid> D09-1087 </papid>and the berkeley sophis ticatedlexicon training option).</prevsent>
</prevsection>
<citsent citstr=" P08-2015 ">
further work will also include making use of lexical resource external to the treebank (goldberg et al, 2009; <papid> E09-1038 </papid>habash,2008) <papid> P08-2015 </papid>and investigating clustering techniques to reduce data sparseness (candito and crabbe?, 2009).</citsent>
<aftsection>
<nextsent>acknowledgements this research is funded by enterprise ireland(cftd/07/229 and pc/09/037) and the irish research council for science engineering and technology (ircset).
</nextsent>
<nextsent>we thank marie candito and our three reviewers for their very helpful suggestions.
</nextsent>
<nextsent>74
</nextsent>

</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2766">
<title id=" W10-0915.xml">prismatic inducing knowledge from a large scale lexicalized relation resource </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>we believe there are many potential applications that can utilize prismatic,such as type inference, relation extraction textual entailment, etc. we discuss some of these applications in details in section 8.
</prevsent>
<prevsent>2.1 manually created resources.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
several lexical resources have been built manually, most notably wordnet (fellbaum, 1998), framenet(baker et al, 1998) <papid> P98-1013 </papid>and verbnet(baker et 122al., 1998).</citsent>
<aftsection>
<nextsent>wordnet is lexical resource that contains individual word synset information, such as definition, synonyms, antonyms, etc. however, the amount of predicate knowledge in wordnet is limited.
</nextsent>
<nextsent>framenet is lexical database that describes the frame structure of selected words.
</nextsent>
<nextsent>each frame represents predicate (e.g. eat, remove) with list offrame elements that constitutes the semantic arguments of the predicate.
</nextsent>
<nextsent>different words may map to the same frame, and one word may map to multiple frames based on different word senses.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2767">
<title id=" W10-0915.xml">prismatic inducing knowledge from a large scale lexicalized relation resource </title>
<section> potential applications.  </section>
<citcontext>
<prevsection>
<prevsent>frame data, especially extensional data involving named entities, captured over large corpus can be used as factual evidence in tasks such as question answering.
</prevsent>
<prevsent>8.3 relation extraction.
</prevsent>
</prevsection>
<citsent citstr=" H05-1091 ">
traditional relation extraction approach (zelenko et al., 2003; bunescu and mooney, 2005) <papid> H05-1091 </papid>relies on the correct identification of the types of the argument.</citsent>
<aftsection>
<nextsent>for example, to identify employs?
</nextsent>
<nextsent>relation between john doe?
</nextsent>
<nextsent>and xyz corporation?, relation extractor heavily relies on john doe?
</nextsent>
<nextsent>being annotated 126as person?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2768">
<title id=" W10-3021.xml">a simple ensemble method for hedge identification </title>
<section> background </section>
<citcontext>
<prevsection>
<prevsent>if aiming at high accuracy, it is therefore crucial to be able to classify assertions to avoid such false positives.
</prevsent>
<prevsent>the importance of assertion classification has been recently recognized by the text mining community,which yielded several text-mining challenges covering this task.
</prevsent>
</prevsection>
<citsent citstr=" W09-1401 ">
for example, the main task of obesity challenge (uzuner, 2008) was to identify based on free text medical record whether patient is known to, speculated to or known not to have disease; in the bionlp 09 shared task (kim et al, 2009), <papid> W09-1401 </papid>mentions of bio-molecularevents had to be classified as either positive or negative statements or speculations.</citsent>
<aftsection>
<nextsent>approaches to tackle assertion classification can be roughly organized into following classes:rule based models (chapman et al, 2001), statistical models (szarvas, 2008), machine learning(medlock and briscoe, 2007), <papid> P07-1125 </papid>though most contributions can be seen as combination of these(uzuner et al, 2009).</nextsent>
<nextsent>even when classifying sentences, the most common approach is to look for cues below the sentence-level (ozgur and radev, 2009).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2769">
<title id=" W10-3021.xml">a simple ensemble method for hedge identification </title>
<section> background </section>
<citcontext>
<prevsection>
<prevsent>the importance of assertion classification has been recently recognized by the text mining community,which yielded several text-mining challenges covering this task.
</prevsent>
<prevsent>for example, the main task of obesity challenge (uzuner, 2008) was to identify based on free text medical record whether patient is known to, speculated to or known not to have disease; in the bionlp 09 shared task (kim et al, 2009), <papid> W09-1401 </papid>mentions of bio-molecularevents had to be classified as either positive or negative statements or speculations.</prevsent>
</prevsection>
<citsent citstr=" P07-1125 ">
approaches to tackle assertion classification can be roughly organized into following classes:rule based models (chapman et al, 2001), statistical models (szarvas, 2008), machine learning(medlock and briscoe, 2007), <papid> P07-1125 </papid>though most contributions can be seen as combination of these(uzuner et al, 2009).</citsent>
<aftsection>
<nextsent>even when classifying sentences, the most common approach is to look for cues below the sentence-level (ozgur and radev, 2009).
</nextsent>
<nextsent>the common in these approaches is that they use text representation richer than bag-of words, usually tokens from fixed-width window with additional surface features.
</nextsent>
<nextsent>evaluation of assertion classification is mostly performed at the sentence level, where state-of the-art systems have been reported to achieve an f-measure of 8385% for hedge detection in 144 biomedical literature (medlock and briscoe, 2007; <papid> P07-1125 </papid>szarvas, 2008).</nextsent>
<nextsent>3 methods.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2771">
<title id=" W10-3014.xml">learning to detect hedges and their scope using crf </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>hedge detection is paid attention to in the biomedical nlp field.
</prevsent>
<prevsent>some researchers regard the problem as text classification problem (a sentence is speculative or not) using simple machine learning techniques.
</prevsent>
</prevsection>
<citsent citstr=" W04-3103 ">
light et al (2004) <papid> W04-3103 </papid>use substring matching to annotate speculation in biomedical text.</citsent>
<aftsection>
<nextsent>medlock and briscoe (2007) <papid> P07-1125 </papid>create hedging dataset and use an svm classifier and get to recall/precision break even point (bep) of 0.76.</nextsent>
<nextsent>they report that the pos feature performs badly, while lemma feature works well.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2772">
<title id=" W10-3014.xml">learning to detect hedges and their scope using crf </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>some researchers regard the problem as text classification problem (a sentence is speculative or not) using simple machine learning techniques.
</prevsent>
<prevsent>light et al (2004) <papid> W04-3103 </papid>use substring matching to annotate speculation in biomedical text.</prevsent>
</prevsection>
<citsent citstr=" P07-1125 ">
medlock and briscoe (2007) <papid> P07-1125 </papid>create hedging dataset and use an svm classifier and get to recall/precision break even point (bep) of 0.76.</citsent>
<aftsection>
<nextsent>they report that the pos feature performs badly, while lemma feature works well.
</nextsent>
<nextsent>szarvas (2008) extends the work of medlock and briscoe with feature selection, and further improves the result to bep of 0.85 by using an external dictionary.
</nextsent>
<nextsent>szarvas concludes that scientific articles contain multiword hedging cues more commonly, and the portability of hedge classifiers is limited.
</nextsent>
<nextsent>halil kilicoglu and sabine bergler (2008) propose an algorithm to weight hedge cues, which are used to evaluate the speculative strength of sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2773">
<title id=" W10-3014.xml">learning to detect hedges and their scope using crf </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>szarvas concludes that scientific articles contain multiword hedging cues more commonly, and the portability of hedge classifiers is limited.
</prevsent>
<prevsent>halil kilicoglu and sabine bergler (2008) propose an algorithm to weight hedge cues, which are used to evaluate the speculative strength of sentences.
</prevsent>
</prevsection>
<citsent citstr=" W09-1304 ">
roser morante and walter daelemans (2009) <papid> W09-1304 </papid>introduce meta learning approach to process the scope of negation, and they identify the hedge cues and their scope with crf classifier based on the original work.</citsent>
<aftsection>
<nextsent>they extract hedge cues dictionary as well, but do not combine it with the crf model.
</nextsent>
<nextsent>in the conll-2010 shared task (farkas et al, 2010), there are two subtasks for worldwide participants to choose: ? task 1: learning to detect sentences contain-ing uncertainty.
</nextsent>
<nextsent>task 2: learning to resolve the in sentence scope of hedge cues.
</nextsent>
<nextsent>this paper describes system using crf model for the task, which is partly based on roser morante and walter daelemans?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2775">
<title id=" W10-3703.xml">construction of chinese idiom knowledge base and its applications </title>
<section> related work on idiom knowledge.  </section>
<citcontext>
<prevsection>
<prevsent>as far as idiom identification is concerned, the work is classified into two kinds : one is for idiom types and the other is for idiom tokens.
</prevsent>
<prevsent>with the former, phrases that can be interpreted as idioms are found in text corpora, typically for lexicographers to compile idiom dictionaries.
</prevsent>
</prevsection>
<citsent citstr=" P99-1041 ">
previous studies have mostly focused on the idiom type identification (lin, 1999; <papid> P99-1041 </papid>baldwin et al., 2003; <papid> W03-1812 </papid>shudo et al, 2004).<papid> W04-0405 </papid></citsent>
<aftsection>
<nextsent>however, there has been growing interest in idiom token identification recently (katz and giesbrecht, 2006; <papid> W06-1203 </papid>hashimoto et al, 2006; <papid> P06-2046 </papid>cook et al , 2007).<papid> W07-1106 </papid></nextsent>
<nextsent>our work elaborated in section 4 is also an attempt in this regard.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2776">
<title id=" W10-3703.xml">construction of chinese idiom knowledge base and its applications </title>
<section> related work on idiom knowledge.  </section>
<citcontext>
<prevsection>
<prevsent>as far as idiom identification is concerned, the work is classified into two kinds : one is for idiom types and the other is for idiom tokens.
</prevsent>
<prevsent>with the former, phrases that can be interpreted as idioms are found in text corpora, typically for lexicographers to compile idiom dictionaries.
</prevsent>
</prevsection>
<citsent citstr=" W03-1812 ">
previous studies have mostly focused on the idiom type identification (lin, 1999; <papid> P99-1041 </papid>baldwin et al., 2003; <papid> W03-1812 </papid>shudo et al, 2004).<papid> W04-0405 </papid></citsent>
<aftsection>
<nextsent>however, there has been growing interest in idiom token identification recently (katz and giesbrecht, 2006; <papid> W06-1203 </papid>hashimoto et al, 2006; <papid> P06-2046 </papid>cook et al , 2007).<papid> W07-1106 </papid></nextsent>
<nextsent>our work elaborated in section 4 is also an attempt in this regard.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2777">
<title id=" W10-3703.xml">construction of chinese idiom knowledge base and its applications </title>
<section> related work on idiom knowledge.  </section>
<citcontext>
<prevsection>
<prevsent>as far as idiom identification is concerned, the work is classified into two kinds : one is for idiom types and the other is for idiom tokens.
</prevsent>
<prevsent>with the former, phrases that can be interpreted as idioms are found in text corpora, typically for lexicographers to compile idiom dictionaries.
</prevsent>
</prevsection>
<citsent citstr=" W04-0405 ">
previous studies have mostly focused on the idiom type identification (lin, 1999; <papid> P99-1041 </papid>baldwin et al., 2003; <papid> W03-1812 </papid>shudo et al, 2004).<papid> W04-0405 </papid></citsent>
<aftsection>
<nextsent>however, there has been growing interest in idiom token identification recently (katz and giesbrecht, 2006; <papid> W06-1203 </papid>hashimoto et al, 2006; <papid> P06-2046 </papid>cook et al , 2007).<papid> W07-1106 </papid></nextsent>
<nextsent>our work elaborated in section 4 is also an attempt in this regard.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2778">
<title id=" W10-3703.xml">construction of chinese idiom knowledge base and its applications </title>
<section> related work on idiom knowledge.  </section>
<citcontext>
<prevsection>
<prevsent>with the former, phrases that can be interpreted as idioms are found in text corpora, typically for lexicographers to compile idiom dictionaries.
</prevsent>
<prevsent>previous studies have mostly focused on the idiom type identification (lin, 1999; <papid> P99-1041 </papid>baldwin et al., 2003; <papid> W03-1812 </papid>shudo et al, 2004).<papid> W04-0405 </papid></prevsent>
</prevsection>
<citsent citstr=" W06-1203 ">
however, there has been growing interest in idiom token identification recently (katz and giesbrecht, 2006; <papid> W06-1203 </papid>hashimoto et al, 2006; <papid> P06-2046 </papid>cook et al , 2007).<papid> W07-1106 </papid></citsent>
<aftsection>
<nextsent>our work elaborated in section 4 is also an attempt in this regard.
</nextsent>
<nextsent>despite the recent enthusiasm for multiword expressions, the idiom token identification is in an early stage of its development.
</nextsent>
<nextsent>given that many language teaching and learning tasks like tcfl have been developed as result of the availability of language resources, idiom token identification should also be developed when adequate idiom resources are provided.
</nextsent>
<nextsent>to this end, we have constructed the cikb and hope to find applications of value, for example, emotion classification, event classification and text analysis based on idiom usage and its context.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2779">
<title id=" W10-3703.xml">construction of chinese idiom knowledge base and its applications </title>
<section> related work on idiom knowledge.  </section>
<citcontext>
<prevsection>
<prevsent>with the former, phrases that can be interpreted as idioms are found in text corpora, typically for lexicographers to compile idiom dictionaries.
</prevsent>
<prevsent>previous studies have mostly focused on the idiom type identification (lin, 1999; <papid> P99-1041 </papid>baldwin et al., 2003; <papid> W03-1812 </papid>shudo et al, 2004).<papid> W04-0405 </papid></prevsent>
</prevsection>
<citsent citstr=" P06-2046 ">
however, there has been growing interest in idiom token identification recently (katz and giesbrecht, 2006; <papid> W06-1203 </papid>hashimoto et al, 2006; <papid> P06-2046 </papid>cook et al , 2007).<papid> W07-1106 </papid></citsent>
<aftsection>
<nextsent>our work elaborated in section 4 is also an attempt in this regard.
</nextsent>
<nextsent>despite the recent enthusiasm for multiword expressions, the idiom token identification is in an early stage of its development.
</nextsent>
<nextsent>given that many language teaching and learning tasks like tcfl have been developed as result of the availability of language resources, idiom token identification should also be developed when adequate idiom resources are provided.
</nextsent>
<nextsent>to this end, we have constructed the cikb and hope to find applications of value, for example, emotion classification, event classification and text analysis based on idiom usage and its context.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2780">
<title id=" W10-3703.xml">construction of chinese idiom knowledge base and its applications </title>
<section> related work on idiom knowledge.  </section>
<citcontext>
<prevsection>
<prevsent>with the former, phrases that can be interpreted as idioms are found in text corpora, typically for lexicographers to compile idiom dictionaries.
</prevsent>
<prevsent>previous studies have mostly focused on the idiom type identification (lin, 1999; <papid> P99-1041 </papid>baldwin et al., 2003; <papid> W03-1812 </papid>shudo et al, 2004).<papid> W04-0405 </papid></prevsent>
</prevsection>
<citsent citstr=" W07-1106 ">
however, there has been growing interest in idiom token identification recently (katz and giesbrecht, 2006; <papid> W06-1203 </papid>hashimoto et al, 2006; <papid> P06-2046 </papid>cook et al , 2007).<papid> W07-1106 </papid></citsent>
<aftsection>
<nextsent>our work elaborated in section 4 is also an attempt in this regard.
</nextsent>
<nextsent>despite the recent enthusiasm for multiword expressions, the idiom token identification is in an early stage of its development.
</nextsent>
<nextsent>given that many language teaching and learning tasks like tcfl have been developed as result of the availability of language resources, idiom token identification should also be developed when adequate idiom resources are provided.
</nextsent>
<nextsent>to this end, we have constructed the cikb and hope to find applications of value, for example, emotion classification, event classification and text analysis based on idiom usage and its context.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2781">
<title id=" W10-3703.xml">construction of chinese idiom knowledge base and its applications </title>
<section> related work on idiom knowledge.  </section>
<citcontext>
<prevsection>
<prevsent>given that many language teaching and learning tasks like tcfl have been developed as result of the availability of language resources, idiom token identification should also be developed when adequate idiom resources are provided.
</prevsent>
<prevsent>to this end, we have constructed the cikb and hope to find applications of value, for example, emotion classification, event classification and text analysis based on idiom usage and its context.
</prevsent>
</prevsection>
<citsent citstr=" W02-1011 ">
according to the granularity of text, emotion analysis of texts can be divided into three levels: text (pang et al, 2002; <papid> W02-1011 </papid>cui et al, 2006), sentence (pang et al, 2004), word (hatzivassiloglou et al, 1997; wiebe 2000).</citsent>
<aftsection>
<nextsent>according to the sources of emotion prediction, classification methods can be divided into knowledge based methods and machine learning based methods.
</nextsent>
<nextsent>the former uses lexicons or knowledge bases to build new lexicon that contains emotion words.
</nextsent>
<nextsent>wordnet is often used to compute the emotion prediction of words (hatzivassiloglou et al, 1997; andrea 2005).
</nextsent>
<nextsent>meanwhile, incorporating knowledge into the machine learning architecture as features is popular trend and untagged copra are often used to do emotion classification research (turney et al., 2002; akkaya et al, 2009).<papid> D09-1020 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2782">
<title id=" W10-3703.xml">construction of chinese idiom knowledge base and its applications </title>
<section> related work on idiom knowledge.  </section>
<citcontext>
<prevsection>
<prevsent>the former uses lexicons or knowledge bases to build new lexicon that contains emotion words.
</prevsent>
<prevsent>wordnet is often used to compute the emotion prediction of words (hatzivassiloglou et al, 1997; andrea 2005).
</prevsent>
</prevsection>
<citsent citstr=" D09-1020 ">
meanwhile, incorporating knowledge into the machine learning architecture as features is popular trend and untagged copra are often used to do emotion classification research (turney et al., 2002; akkaya et al, 2009).<papid> D09-1020 </papid></citsent>
<aftsection>
<nextsent>14
</nextsent>
<nextsent>classification on cikb in this paper, we focus on the emotion prediction of idioms conducted by machine learning method.
</nextsent>
<nextsent>to do this, we aim to investigate how the compositional constituents of an idiom affect its emotion orientation from the token level, especially for multi-word expressions with so obvious an exaggerative and descriptive nature like idioms.
</nextsent>
<nextsent>from cikb, 20,000 idioms are selected as the training corpus and 3,000 idioms as the test corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2783">
<title id=" W10-3703.xml">construction of chinese idiom knowledge base and its applications </title>
<section> an nlp application of emotion.  </section>
<citcontext>
<prevsection>
<prevsent>detailed features and related abbreviations are shown as in table 4.
</prevsent>
<prevsent>because chinese sentences are written in consecutive string of characters, we need to segment sentence into individual words to obtain the word feature.
</prevsent>
</prevsection>
<citsent citstr=" W03-1730 ">
ictclas (zhang et al., 2003), <papid> W03-1730 </papid>tool developed by the institute of computing technology of chinese academy of sciences (ict), is used for word segmentation and part-of-speech tagging.</citsent>
<aftsection>
<nextsent>we adopt precision, recall and f-score (?=1) as the evaluation parameters.
</nextsent>
<nextsent>from table 5 we can see that i_cb has better performance than i_cu, which indicates that bigram model usually performs better than unigram model.
</nextsent>
<nextsent>but when we segment the idioms and use i_wu, we find that the performance gets bad.
</nextsent>
<nextsent>this may be because the compositionality of chinese idioms is quite fossilized and the errors caused by segmentation introduce some noise.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2784">
<title id=" W10-2001.xml">using sentence type information for syntactic category acquisition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in other domains, intonation hasbeen used to identify sentence types as means of improving speech recognition language models.
</prevsent>
<prevsent>specifically, (taylor et al, 1998) found that using intonation to recognize dialogue acts (which to significant extent correspond to sentence types) and then using specialized language model for each type of dialogue act led to significant decrease in word error rate.
</prevsent>
</prevsection>
<citsent citstr=" P07-1094 ">
in the remainder of this paper, we first present the bayesian hidden markov model (bhmm; goldwater and griffiths (2007)) <papid> P07-1094 </papid>that is used as the baseline model of category acquisition, as well as our extensions tothe model, which incorporate sentence type informa tion.</citsent>
<aftsection>
<nextsent>we then discuss the distinctions in sentence type that we used and our evaluation measures, and finally our experimental results.
</nextsent>
<nextsent>we perform experiments on corpora in four different languages: english, spanish, cantonese, and dutch.
</nextsent>
<nextsent>our results on spanish show no difference between the baseline and the models incorporating sentence type, possibly due to the small size of the spanish corpus.
</nextsent>
<nextsent>results on all other corpora show small improvement in performance when sentence type is included as cueto the learner.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2796">
<title id=" W10-2001.xml">using sentence type information for syntactic category acquisition </title>
<section> evaluation measures.  </section>
<citcontext>
<prevsection>
<prevsent>more precisely: i(c,k) = h(c)+h(k)2i(c,k) = h(c|k)+h(k|c) lower score implies closer clusterings, since each clustering has less information not shared with theother: two identical clusterings have vi of zero.
</prevsent>
<prevsent>how ever, vis upper bound is dependent on the maximum number of clusters in or k, making it difficult to compare clustering results with different numbers of clusters.
</prevsent>
</prevsection>
<citsent citstr=" D07-1043 ">
as third, and, in our view, most informative measure, we use v-measure (vm; rosenberg and hirschberg (2007)).<papid> D07-1043 </papid></citsent>
<aftsection>
<nextsent>like vi, vm uses the conditional entropy of clusters and categories to evaluate cluster ings.
</nextsent>
<nextsent>however, it also has the useful characteristic of being analogous to the precision and recall measures commonly used in nlp.
</nextsent>
<nextsent>homogeneity, the precision analogue, is defined as h = 1?
</nextsent>
<nextsent>h(c|k) h(c) . vh is highest when the distribution of categories within each cluster is highly skewed towards small number of categories, such that the conditional entropy is low.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2797">
<title id=" W10-3806.xml">seeding statistical machine translation with translation memory output through tree based structural alignment </title>
<section> 4 5 </section>
<citcontext>
<prevsection>
<prevsent>15 13 10 4 6 3 1 2 5 36 34 8 1 32 2 24 7 18 6
</prevsent>
<prevsent>6 4 1 2 3 i i input match ttrans lation 1 2 3 sender email address 1 2 3 4 5 sender email address . 1 2 3 4 5 6 7 8 adresselectro nique de lexp? diteur dumes sage . figure 1.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
example of sub-tree alignment between an input sentence, tm match and tm translation we decided to use sub-tree-based alignment, rather than plain word alignment (e.g. giza++ ? och and ney, 2003), <papid> J03-1002 </papid>due to number of factors.</citsent>
<aftsection>
<nextsent>first, sub-tree-based alignment provides much better handling of long-distance reorderings, while word?
</nextsent>
<nextsent>and phrase-based alignment models always have fixed limit on reordering distance that tends to be relatively low to allow efficient computation.the alignments produced by sub-tree alignment model are also precision-oriented, rather than recall-oriented (cf.
</nextsent>
<nextsent>tinsley, 2010).
</nextsent>
<nextsent>this is important in our case, where we want to only extract those parts of the translation suggested by the tm for which we are most certain that they are good translations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2798">
<title id=" W10-3806.xml">seeding statistical machine translation with translation memory output through tree based structural alignment </title>
<section> 4 5 </section>
<citcontext>
<prevsection>
<prevsent>once the matching step is completed, we have identified and marked-up the parts of the input sentence for which translations will be extracted from the tm suggestions, as well as the parts that need to be translated from scratch.
</prevsent>
<prevsent>the lengths of the non-translated segments vary depending on the fms, but are in general relatively short (one to three tokens).
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
the further processing of the input relies on specific feature of the smt backend we use, namely the moses system (koehn et al, 2007).<papid> P07-2045 </papid></citsent>
<aftsection>
<nextsent>we decided to use this particular system as it is the most widely adopted open-source smt system, both for academic and commercial purposes.
</nextsent>
<nextsent>in this approach, we annotate the segments of the input sentence for which translations have been found from the tm suggestion using xml tags with the translation corresponding to each segment given as an attribute to the encapsulating xml tag, similarly to the system described in (smith and clark, 2009).
</nextsent>
<nextsent>the smt backend is supplied with marked-up input in the form of string consisting of the concatenation of the xml-enclosed translated segments and the plain non-translated segments in the target language word order, as established by the alignment process.
</nextsent>
<nextsent>the smt backend is instructed to translate this input, while keeping the translations supplied via the xml annotation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2799">
<title id=" W10-3806.xml">seeding statistical machine translation with translation memory output through tree based structural alignment </title>
<section> evaluation results.  </section>
<citcontext>
<prevsection>
<prevsent>this results in much smaller models than the ones usually used in mainstream smt applications.
</prevsent>
<prevsent>(the standard for some tools goes as far as 7-token phase length limit and 7-gram language models)
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
for the evaluation of our system, we used number of widely accepted automatic metrics, namely bleu (papineni et al, 2002), <papid> P02-1040 </papid>meteor (banerjee and lavie, 2005), <papid> W05-0909 </papid>ter (snover et al, 2006) and inverse f-score based on token-level precision and recall.we setup our system to only fully process in put sentences for which tm match with an fms over 50% was found, although all sentences were translated directly using the smt backend to check the overall pure smt perform ance.</citsent>
<aftsection>
<nextsent>the tm-suggested translations were also output for all input sentences.the results of the evaluation are given in figure 4, where the tm and direct scores are also given for the fms range [0%; 50%)?{100%}.
</nextsent>
<nextsent>across all metrics we see uniform drop in the quality of tm-suggested translations, which is what we expected, given that these translations contain one or more wrong words.
</nextsent>
<nextsent>we believe that the relatively high scores recorded for the tm-suggested translations at the high end of the fms scale are result of the otherwise perfect word order and lexical choice.
</nextsent>
<nextsent>for n-gram match-based metrics like the ones we used such result is expected and predictable.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2800">
<title id=" W10-3806.xml">seeding statistical machine translation with translation memory output through tree based structural alignment </title>
<section> evaluation results.  </section>
<citcontext>
<prevsection>
<prevsent>this results in much smaller models than the ones usually used in mainstream smt applications.
</prevsent>
<prevsent>(the standard for some tools goes as far as 7-token phase length limit and 7-gram language models)
</prevsent>
</prevsection>
<citsent citstr=" W05-0909 ">
for the evaluation of our system, we used number of widely accepted automatic metrics, namely bleu (papineni et al, 2002), <papid> P02-1040 </papid>meteor (banerjee and lavie, 2005), <papid> W05-0909 </papid>ter (snover et al, 2006) and inverse f-score based on token-level precision and recall.we setup our system to only fully process in put sentences for which tm match with an fms over 50% was found, although all sentences were translated directly using the smt backend to check the overall pure smt perform ance.</citsent>
<aftsection>
<nextsent>the tm-suggested translations were also output for all input sentences.the results of the evaluation are given in figure 4, where the tm and direct scores are also given for the fms range [0%; 50%)?{100%}.
</nextsent>
<nextsent>across all metrics we see uniform drop in the quality of tm-suggested translations, which is what we expected, given that these translations contain one or more wrong words.
</nextsent>
<nextsent>we believe that the relatively high scores recorded for the tm-suggested translations at the high end of the fms scale are result of the otherwise perfect word order and lexical choice.
</nextsent>
<nextsent>for n-gram match-based metrics like the ones we used such result is expected and predictable.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2801">
<title id=" W10-1003.xml">autolearnrsquos authoring tool a piece of cake for teachers </title>
<section> concluding remarks.  </section>
<citcontext>
<prevsection>
<prevsent>there is room for improvement in the way to reduce false positives related with poor specifications.
</prevsent>
<prevsent>it is quite some work for exercise designers to foresee reasonable range of linguistic alternatives for each answer.
</prevsent>
</prevsection>
<citsent citstr=" W08-0913 ">
one could further support them in the design of materials with added functional ities using strategies such as shallow semantic parsing, as in (bailey and meurers, 2008), <papid> W08-0913 </papid>or adding functional ities on the user interface that allow teachers to easily feed exercise models or specific feedback messages using learner answers.</citsent>
<aftsection>
<nextsent>the architecture presented allows for portability into other languages (english and german already available), with relative simplicity provided that the lexicon for the language exists and contains basic morpho-syntactic information.
</nextsent>
<nextsent>moreover, having developed it as moodle extension makes it available to wide community of teachers and learners.
</nextsent>
<nextsent>the modularity of atack and atap makes them easy to integrate in other learning management systems.
</nextsent>
<nextsent>in the longer term we plan to improve autotu tors configurability so that its behaviour can be defined following pedagogical criteria.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2802">
<title id=" W10-2206.xml">exploring dialect phonetic variation using parafac </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>all segments found in the data are translated into vectors of numerical features and analyzed using pca.
</prevsent>
<prevsent>based on the component scores for features, different groups of varieties (in which certain group of features is present) are identified.
</prevsent>
</prevsection>
<citsent citstr=" W09-3203 ">
we note that the main drawback of this approach is the subjectivity of the feature selection and segment quantification.wieling and nerbonne (2009) <papid> W09-3203 </papid>used bipartite spectral graph partitioning method to simultaneously cluster dialect varieties and sound cor respondences.</citsent>
<aftsection>
<nextsent>although promising, this method compares the pronunciation of every site only to the reference site, rather than comparing it to all other sites.
</nextsent>
<nextsent>another drawback of this method isthat it does not use any information on the frequencies of sound correspondences, but instead employs binary features to represent whether certain correspondence is present at certain site or not.
</nextsent>
<nextsent>in this paper we present an approach that tries to overcome some of the problems described inthe previous approaches.
</nextsent>
<nextsent>it proceeds from automatically aligned phonetic transcriptions, where pronunciations of every site are compared to the corresponding pronunciations for all other sites.extracted sound correspondences are analyzed using the multi-way decomposition method parafac.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2803">
<title id=" W10-1721.xml">the cunei machine translation platform for wmt rsquo10 </title>
<section> the cunei machine translation.  </section>
<citcontext>
<prevsection>
<prevsent>platform the cunei machine translation platform (phillips and brown, 2009) is open-source software and freely available at http://www.cunei.
</prevsent>
<prevsent>org/.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
like moses (koehn et al, 2007) <papid> P07-2045 </papid>and joshua (li et al, 2009), <papid> W09-0424 </papid>cunei provides statistical decoder that combines partial translations (either phase pairs or grammar rules) in order to compose coherent sentence in the target language.</citsent>
<aftsection>
<nextsent>what makes cunei unique is that it models the translation task with non-parametric model that assesses the relevance of each translation instance.
</nextsent>
<nextsent>the process begins by encoding in lattice all possible contiguous phrases from the input.1 foreach source phrase in the lattice, cunei locates instances of it in the corpus and then identifies the aligned target phrase(s).
</nextsent>
<nextsent>this much is standard to most data-driven mt systems.
</nextsent>
<nextsent>the typical step at this stage is to model phrase pair by computing relative frequencies over the collection of translation instances.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2804">
<title id=" W10-1721.xml">the cunei machine translation platform for wmt rsquo10 </title>
<section> the cunei machine translation.  </section>
<citcontext>
<prevsection>
<prevsent>platform the cunei machine translation platform (phillips and brown, 2009) is open-source software and freely available at http://www.cunei.
</prevsent>
<prevsent>org/.
</prevsent>
</prevsection>
<citsent citstr=" W09-0424 ">
like moses (koehn et al, 2007) <papid> P07-2045 </papid>and joshua (li et al, 2009), <papid> W09-0424 </papid>cunei provides statistical decoder that combines partial translations (either phase pairs or grammar rules) in order to compose coherent sentence in the target language.</citsent>
<aftsection>
<nextsent>what makes cunei unique is that it models the translation task with non-parametric model that assesses the relevance of each translation instance.
</nextsent>
<nextsent>the process begins by encoding in lattice all possible contiguous phrases from the input.1 foreach source phrase in the lattice, cunei locates instances of it in the corpus and then identifies the aligned target phrase(s).
</nextsent>
<nextsent>this much is standard to most data-driven mt systems.
</nextsent>
<nextsent>the typical step at this stage is to model phrase pair by computing relative frequencies over the collection of translation instances.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2805">
<title id=" W10-1721.xml">the cunei machine translation platform for wmt rsquo10 </title>
<section> the cunei machine translation.  </section>
<citcontext>
<prevsection>
<prevsent>while the calculations are not exactly thesame, conceptually this work is modeled after (vo gel, 2005).
</prevsent>
<prevsent>for each source-side match in the corpus, an alignment matrix is loaded for the complete sentence in which the match resides.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
this alignment matrix contains scores for all word correspondences in the sentence pair and can be created using giza++ (och and ney, 2003) <papid> J03-1002 </papid>or the berkeley aligner (liang et al, 2006).<papid> N06-1014 </papid></citsent>
<aftsection>
<nextsent>intuitively, when asource phrase is aligned to target phrase, this implies that the remainder of the source sentence that is not specified by the source phrase is aligned to the remainder of the target sentence not specified by the target phrase.
</nextsent>
<nextsent>separate features compute the probability that the word alignments for tokens within the phrase are concentrated within the phrase boundaries and that the word alignments for tokens outside the phrase are concentrated out side the phrase boundaries.
</nextsent>
<nextsent>in addition, words with no alignment links or weak alignments links demonstrate uncertainty in modeling.
</nextsent>
<nextsent>to capture this effect, we incorporate two more features that count the number of uncertain alignments present in the source phrase and the target phrase.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2806">
<title id=" W10-1721.xml">the cunei machine translation platform for wmt rsquo10 </title>
<section> the cunei machine translation.  </section>
<citcontext>
<prevsection>
<prevsent>while the calculations are not exactly thesame, conceptually this work is modeled after (vo gel, 2005).
</prevsent>
<prevsent>for each source-side match in the corpus, an alignment matrix is loaded for the complete sentence in which the match resides.
</prevsent>
</prevsection>
<citsent citstr=" N06-1014 ">
this alignment matrix contains scores for all word correspondences in the sentence pair and can be created using giza++ (och and ney, 2003) <papid> J03-1002 </papid>or the berkeley aligner (liang et al, 2006).<papid> N06-1014 </papid></citsent>
<aftsection>
<nextsent>intuitively, when asource phrase is aligned to target phrase, this implies that the remainder of the source sentence that is not specified by the source phrase is aligned to the remainder of the target sentence not specified by the target phrase.
</nextsent>
<nextsent>separate features compute the probability that the word alignments for tokens within the phrase are concentrated within the phrase boundaries and that the word alignments for tokens outside the phrase are concentrated out side the phrase boundaries.
</nextsent>
<nextsent>in addition, words with no alignment links or weak alignments links demonstrate uncertainty in modeling.
</nextsent>
<nextsent>to capture this effect, we incorporate two more features that count the number of uncertain alignments present in the source phrase and the target phrase.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2807">
<title id=" W10-1721.xml">the cunei machine translation platform for wmt rsquo10 </title>
<section> the cunei machine translation.  </section>
<citcontext>
<prevsection>
<prevsent>however, it is not practical to compute all possible phrase alignments, so we extract translation instances using only afew high-scoring phrase alignments for each occurrence of source phrase in the corpus.2 as discussed previously, these extracted translation instances form the basic modeling unit in cunei.
</prevsent>
<prevsent>1.4 optimization.
</prevsent>
</prevsection>
<citsent citstr=" P06-2101 ">
cuneis built-in optimization code closely follows the approach of (smith and eisner, 2006), <papid> P06-2101 </papid>which minimizes the expectation of the loss function overthe distribution of translations present in the best list.</citsent>
<aftsection>
<nextsent>following (smith and eisner, 2006), <papid> P06-2101 </papid>we implemented log(bleu) as the loss function such that the objective function can be decomposed as the expected value of bleus brevity penalty and the expected value of bleus precision score.the optimization process slowly anneals the distribution of the n-best list in order to avoid localminima.</nextsent>
<nextsent>this begins with near uniform distribution of translations and eventually reaches distribution where, for each sentence, nearly all of the probability mass resides on the top translation (and corresponds closely with the actual 1-best bleu score).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2812">
<title id=" W10-1721.xml">the cunei machine translation platform for wmt rsquo10 </title>
<section> the wmt 10 translation task.  </section>
<citcontext>
<prevsection>
<prevsent>636 sentences were sampled from wmt 09 for tuning and all 2,051 sentences from wmt 08 were reserved for testing.
</prevsent>
<prevsent>finally, blind evaluation was also performed with the new wmt 10 test set.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
all systems were tuned toward bleu (papineni et al, 2002) <papid> P02-1040 </papid>and all evaluation metrics were run on lower cased, tokenized text.the results in table 2 and table 3 show the performance of cunei3 against the moses system wealso built with the same data.</citsent>
<aftsection>
<nextsent>the first cunei system we built included all the alignment features discussed in 1.3.
</nextsent>
<nextsent>these per-instance alignment features are essential to cuneis run-time phrase extraction and cannot be disabled.
</nextsent>
<nextsent>the second, and complete, system added to this all the context features described in 1.2.
</nextsent>
<nextsent>cunei, in general, performs significantly better than moses in german and is competitive with moses in czech.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2813">
<title id=" W10-1721.xml">the cunei machine translation platform for wmt rsquo10 </title>
<section> the wmt 10 translation task.  </section>
<citcontext>
<prevsection>
<prevsent>theoretically adding new features should only improve system as feature can always by ignored by assigning it weight of zero.
</prevsent>
<prevsent>how ever, new features expand the hypothesis space and provide the model with more degrees of freedom which may make it easier to get stuck in local minima.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
while the gradient-based, annealing method for optimization that we use tends work better than mert (och, 2003), <papid> P03-1021 </papid>it is still susceptible to these issues.</citsent>
<aftsection>
<nextsent>indeed, the variation on the tuning set while relatively inconsequential is evidence that this is occurring and that we have not found the global optimum.
</nextsent>
<nextsent>further investigation is necessary into the interaction between the context features and techniques for robust optimization.
</nextsent>
<nextsent>3these results have been updated since the official wmt 10 submission as result of minor bug-fixes and code improvements to cunei.
</nextsent>
<nextsent>152 german english czech english tokens 41,245,188 43,064,069 63,776,164 72,325,831 sentences 1574044 6181270 table 1: corpus statistics 2.4 conclusion.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2814">
<title id=" W10-1911.xml">disease mention recognition with specific features </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>named entity recognition (ner) is the task of locating boundaries of the entity mentions in textand tagging them with their corresponding semantic types (e.g. person, location, gene and so on).
</prevsent>
<prevsent>although several disease annotated corpora have been released in the last few years, they have been annotated primarily to serve the purpose of relation extraction and, for different reasons, they 1the source code of our system is available for download at http://hlt.fbk.eu/people/chowdhury/research 83 are not suitable for the development of ml based disease mention recognition systems (leaman et al., 2009).
</prevsent>
</prevsection>
<citsent citstr=" P04-1055 ">
for example, the biotext (rosarioand hearst, 2004) <papid> P04-1055 </papid>corpus has no specific annotation guideline and contains several inconsistencies, while pennbioie (kulick et al, 2004) <papid> W04-3111 </papid>is very specific to particular sub-domain of diseases.among other disease annotated corpora, ebi disease corpus (jimeno et al, 2008) is not annotated with disease mention boundaries which makes it unsuitable for bner evaluation for diseases.</citsent>
<aftsection>
<nextsent>recently, an annotated corpus, named as arizona disease corpus (azdc) (leaman et al, 2009), has been released which has adequate and suitable annotation of disease mentions following specific annotation guidelines.there has been some work on identifying diseases in clinical texts, especially in the context of cmc medical nlp challenge2 and i2b2 chal lenge3.
</nextsent>
<nextsent>however, as noted by meystre et al (2008), there are number of reasons that make clinical texts different from texts of biomedical literature, e.g. composition of short, telegraphic phrases, use of implicit templates and pseudo tables and so on.
</nextsent>
<nextsent>hence, the strategies adopted for ner on clinical texts are not the same as the ones practiced for ner on biomedical literature.
</nextsent>
<nextsent>as mentioned before, most of the work todate on bner is focused on gene/protein mention recognition.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2815">
<title id=" W10-1911.xml">disease mention recognition with specific features </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>named entity recognition (ner) is the task of locating boundaries of the entity mentions in textand tagging them with their corresponding semantic types (e.g. person, location, gene and so on).
</prevsent>
<prevsent>although several disease annotated corpora have been released in the last few years, they have been annotated primarily to serve the purpose of relation extraction and, for different reasons, they 1the source code of our system is available for download at http://hlt.fbk.eu/people/chowdhury/research 83 are not suitable for the development of ml based disease mention recognition systems (leaman et al., 2009).
</prevsent>
</prevsection>
<citsent citstr=" W04-3111 ">
for example, the biotext (rosarioand hearst, 2004) <papid> P04-1055 </papid>corpus has no specific annotation guideline and contains several inconsistencies, while pennbioie (kulick et al, 2004) <papid> W04-3111 </papid>is very specific to particular sub-domain of diseases.among other disease annotated corpora, ebi disease corpus (jimeno et al, 2008) is not annotated with disease mention boundaries which makes it unsuitable for bner evaluation for diseases.</citsent>
<aftsection>
<nextsent>recently, an annotated corpus, named as arizona disease corpus (azdc) (leaman et al, 2009), has been released which has adequate and suitable annotation of disease mentions following specific annotation guidelines.there has been some work on identifying diseases in clinical texts, especially in the context of cmc medical nlp challenge2 and i2b2 chal lenge3.
</nextsent>
<nextsent>however, as noted by meystre et al (2008), there are number of reasons that make clinical texts different from texts of biomedical literature, e.g. composition of short, telegraphic phrases, use of implicit templates and pseudo tables and so on.
</nextsent>
<nextsent>hence, the strategies adopted for ner on clinical texts are not the same as the ones practiced for ner on biomedical literature.
</nextsent>
<nextsent>as mentioned before, most of the work todate on bner is focused on gene/protein mention recognition.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2816">
<title id=" W10-1911.xml">disease mention recognition with specific features </title>
<section> description of our system.  </section>
<citcontext>
<prevsection>
<prevsent>3.1 pre-processing.
</prevsent>
<prevsent>at first, the system uses geniatagger7 to tokenizetexts and provide pos tagging.
</prevsent>
</prevsection>
<citsent citstr=" W09-1319 ">
after that, it corrects some common inconsistencies introduced bygeniatagger inside the tokenized data (e.g. ge nia tagger replaces double inverted commas with 4however, there are some work on disease recognition in biomedical literature using other techniques such as morphosyntactic heuristic based approach (e.g. metamap (aronson, 2001)), dictionary look-up method and statistical approach (neveol et al, 2009; <papid> W09-1319 </papid>jimeno et al, 2008; leaman et al, 2009).</citsent>
<aftsection>
<nextsent>5as mentioned in http://banner.sourceforge.net/ 6http://biotext.berkeley.edu/data/dis treat data.html 7http://www-tsujii.is.s.u-tokyo.ac.jp/genia/tagger/ 84 two single inverted commas).
</nextsent>
<nextsent>these pos tagged tokized data are parsed using stanford parser8.
</nextsent>
<nextsent>the dependency relations provided as output by the parser are used later as features.
</nextsent>
<nextsent>the tokens are further processed using the following generalization and normalization steps: ? each number (both integer and real) inside token is replaced with 9?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2817">
<title id=" W10-1911.xml">disease mention recognition with specific features </title>
<section> why features for diseases and.  </section>
<citcontext>
<prevsection>
<prevsent>the major source of errors, however, concerns abbreviated disease names (e.g. pnh?).
</prevsent>
<prevsent>we believe one way to reduce this specific error type is to generate list of possible abbreviated disease names from the long forms of disease names available in databases such as umls metathesaurus.
</prevsent>
</prevsection>
<citsent citstr=" W04-1221 ">
genes/proteins are not the same many of the existing bner systems, which are mainly tuned for gene/protein identification, use features such as token shape (also known as word class and brief word class (settles, 2004)), <papid> W04-1221 </papid>greek alphabet matching, roman number matching andso forth.</citsent>
<aftsection>
<nextsent>as mentioned earlier, we have done extensive experiments with various feature combinations for the selection of disease specific features.
</nextsent>
<nextsent>we have observed that many of the features usedfor gene/protein identification are not equally effective for disease identification.
</nextsent>
<nextsent>table 7 shows some of the results of those experiments.
</nextsent>
<nextsent>this observation is reasonable because gene/protein names are much more complex than entities such as diseases.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2818">
<title id=" W10-1403.xml">two methods to incorporate rsquolocal morphosyntacticrsquo features in hindi dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper is also the first attempt at complete sentence level parsing for hindi.
</prevsent>
<prevsent>the dependency parsing community has since few years shown considerable interest in parsing morphologically rich languages with flexible word order.
</prevsent>
</prevsection>
<citsent citstr=" D07-1096 ">
this is partly due to the increasing availability of dependency treebanks for such languages, but it is also motivated by the observation that the performance obtained for these languages have not been very high (nivre et al, 2007<papid> D07-1096 </papid>a).</citsent>
<aftsection>
<nextsent>attempts at handling various non-configurational aspects in these languages have pointed towards shortcomings in traditional parsing methodologies (tsarfaty and sima an, 2008; eryigit et al, 2008; seddah et al., 2009; <papid> W09-3824 </papid>husain et al, 2009; gadde et al, 2010).</nextsent>
<nextsent>among other things, it has been pointed out that the use of language specific features may play crucial role in improving the overall parsing performance.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2821">
<title id=" W10-1403.xml">two methods to incorporate rsquolocal morphosyntacticrsquo features in hindi dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the dependency parsing community has since few years shown considerable interest in parsing morphologically rich languages with flexible word order.
</prevsent>
<prevsent>this is partly due to the increasing availability of dependency treebanks for such languages, but it is also motivated by the observation that the performance obtained for these languages have not been very high (nivre et al, 2007<papid> D07-1096 </papid>a).</prevsent>
</prevsection>
<citsent citstr=" W09-3824 ">
attempts at handling various non-configurational aspects in these languages have pointed towards shortcomings in traditional parsing methodologies (tsarfaty and sima an, 2008; eryigit et al, 2008; seddah et al., 2009; <papid> W09-3824 </papid>husain et al, 2009; gadde et al, 2010).</citsent>
<aftsection>
<nextsent>among other things, it has been pointed out that the use of language specific features may play crucial role in improving the overall parsing performance.
</nextsent>
<nextsent>different languages tend to encode syntactically relevant information in different ways, and it has been hypothesized that the integration of morphological and syntactic information could be key to better accuracy.
</nextsent>
<nextsent>however, it has also been noted that incorporating these language specific features in parsing is not always straightforward and many intuitive features do not always work in expected ways.
</nextsent>
<nextsent>in this paper we explore various strategies to incorporate local morphosyntactic features in hindi dependency parsing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2823">
<title id=" W10-1403.xml">two methods to incorporate rsquolocal morphosyntacticrsquo features in hindi dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper we explore various strategies to incorporate local morphosyntactic features in hindi dependency parsing.
</prevsent>
<prevsent>these features are obtained using shallow parser.
</prevsent>
</prevsection>
<citsent citstr=" W06-2932 ">
we conducted experiments with two data-driven parsers, malt parser (nivre et al., 2007<papid> D07-1096 </papid>b) and mst parser (mcdonald et al, 2006).<papid> W06-2932 </papid></citsent>
<aftsection>
<nextsent>we first explore which information provided by the shallow parser is most beneficial and show that local morphosyntactic features in the form of chunk type, head/non-head information, chunk boundary information, distance to the end of the chunk and suffix concatenation are very crucial in hindi dependency parsing.
</nextsent>
<nextsent>we then investigate the best way to incorporate this information during dependency parsing.
</nextsent>
<nextsent>all the experiments were done on part of multi-layered and multi representational hindi treebank (bhatt et al, 2009)1.
</nextsent>
<nextsent>the shallow parser performs three tasks, (a) it gives the pos tags for each lexical item, (b) provides morphological features for each lexical item, and (c) performs chunking.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2826">
<title id=" W10-1403.xml">two methods to incorporate rsquolocal morphosyntacticrsquo features in hindi dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, when we explore the effect of chunk information, all the relevant morph information from previous set of experiments is taken into account.
</prevsent>
<prevsent>this paper is also the first attempt at complete sentence level parsing for hindi.
</prevsent>
</prevsection>
<citsent citstr=" I08-2099 ">
due to the availability of dependency treebank for hindi (begum et al., 2008), <papid> I08-2099 </papid>there have been some previous attempts at hindi data-driven dependency parsing (bharati et al, 2008; mannem et al, 2009; husain et al, 2009).</citsent>
<aftsection>
<nextsent>recently in icon-09 nlp tools contest (husain, 2009; and the references therein), rule based, constraint based, statistical and hybrid approaches were explored for dependency parsing.
</nextsent>
<nextsent>previously, constraint based approaches to indian language (il) dependency parsing have also been explored (bharati et al, 1993, 1995, 2009b, 2009c).
</nextsent>
<nextsent>all these attempts, however, were finding inter-chunk dependency relations, given gold standard pos and chunk tags.
</nextsent>
<nextsent>unlike these previous parsers, the dependencies in this work are between lexical items, i.e. the dependency tree is complete.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2827">
<title id=" W10-1403.xml">two methods to incorporate rsquolocal morphosyntacticrsquo features in hindi dependency parsing </title>
<section> inside, outside, beginning of the chunk..  </section>
<citcontext>
<prevsection>
<prevsent>in particular, we divide the task of parsing into: ? intra-chunk dependency parsing ? inter-chunk dependency parsing we still use pos, best morphological features (case, suffix, root) information as regular features during parsing.
</prevsent>
<prevsent>but unlike lmsaf mentioned in section 2.3, where we gave local morphosyntactic information as feature, we divided the task of parsing into sub-tasks.
</prevsent>
</prevsection>
<citsent citstr=" W09-3812 ">
a similar approach was also proposed by bharati et al (2009<papid> W09-3812 </papid>c).</citsent>
<aftsection>
<nextsent>during intra chunk dependency parsing, we try to find the dependency relations of the words within chunk.
</nextsent>
<nextsent>following which, chunk heads of each chunk with in sentence are extracted.
</nextsent>
<nextsent>on these chunk heads we run an inter-chunk dependency parser.
</nextsent>
<nextsent>for each chunk head, in addition to pos tag, useful morphological features, any useful intra-chunk information in the form of lexical item, suffix concatenation, dependency relation are also given as feature.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2835">
<title id=" W10-1403.xml">two methods to incorporate rsquolocal morphosyntacticrsquo features in hindi dependency parsing </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>it provides option for six parsing algorithms, namely, arc-eager, arc-standard, convington projective, covington non-projective, stack projective, stack eager and stack lazy.
</prevsent>
<prevsent>the parser also provides option for libsvm and liblinear learning model.
</prevsent>
</prevsection>
<citsent citstr=" P05-1013 ">
it uses graph transformation to handle non-projective trees (nivre and nilsson, 2005).<papid> P05-1013 </papid></citsent>
<aftsection>
<nextsent>mst uses chu-liu edmonds (chu and liu, 1965; edmonds, 1967) maximum spanning tree algorithm for non projective parsing and eisner algorithm for projective parsing (eisner, 1996).<papid> C96-1058 </papid></nextsent>
<nextsent>it uses online large margin learning as the learning algorithm (mcdo nald et al, 2005).<papid> P05-1012 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2836">
<title id=" W10-1403.xml">two methods to incorporate rsquolocal morphosyntacticrsquo features in hindi dependency parsing </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>the parser also provides option for libsvm and liblinear learning model.
</prevsent>
<prevsent>it uses graph transformation to handle non-projective trees (nivre and nilsson, 2005).<papid> P05-1013 </papid></prevsent>
</prevsection>
<citsent citstr=" C96-1058 ">
mst uses chu-liu edmonds (chu and liu, 1965; edmonds, 1967) maximum spanning tree algorithm for non projective parsing and eisner algorithm for projective parsing (eisner, 1996).<papid> C96-1058 </papid></citsent>
<aftsection>
<nextsent>it uses online large margin learning as the learning algorithm (mcdo nald et al, 2005).<papid> P05-1012 </papid></nextsent>
<nextsent>in this paper, we use mst only for unlabeled dependency tree and use separate maximum entropy model8 (maxent) for labeling.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2837">
<title id=" W10-1403.xml">two methods to incorporate rsquolocal morphosyntacticrsquo features in hindi dependency parsing </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>it uses graph transformation to handle non-projective trees (nivre and nilsson, 2005).<papid> P05-1013 </papid></prevsent>
<prevsent>mst uses chu-liu edmonds (chu and liu, 1965; edmonds, 1967) maximum spanning tree algorithm for non projective parsing and eisner algorithm for projective parsing (eisner, 1996).<papid> C96-1058 </papid></prevsent>
</prevsection>
<citsent citstr=" P05-1012 ">
it uses online large margin learning as the learning algorithm (mcdo nald et al, 2005).<papid> P05-1012 </papid></citsent>
<aftsection>
<nextsent>in this paper, we use mst only for unlabeled dependency tree and use separate maximum entropy model8 (maxent) for labeling.
</nextsent>
<nextsent>various combination of features such as node, its parent, siblings and children were tried out before arriving at the best results.
</nextsent>
<nextsent>as the training data size is small we did 5-fold cross validation on the training data for tuning the parameters of the parsers and for feature selection.
</nextsent>
<nextsent>best settings obtained using cross-validated data are applied on test set.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2838">
<title id=" W10-1403.xml">two methods to incorporate rsquolocal morphosyntacticrsquo features in hindi dependency parsing </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>for the malt parser, arc-eager algorithm gave better performance over others in all the approaches.
</prevsent>
<prevsent>libsvm consistently gave better performance over liblinear in all the experiments.
</prevsent>
</prevsection>
<citsent citstr=" D07-1097 ">
for svm settings, we tried out different combinations of best svm settings of the same parser on different languages in conll-2007 shared task (hall et al, 2007) <papid> D07-1097 </papid>and applied the best settings.</citsent>
<aftsection>
<nextsent>for feature model, apart from trying best feature settings of the same parser on different languages in conll 2007 shared task (hall et al, 2007), <papid> D07-1097 </papid>we also tried out different combinations of linguistically intuitive features and applied the best feature model.</nextsent>
<nextsent>the best feature model is same as the feature model used in ambati et al (2009a), which is the best 8 http://maxent.sourceforge.net/ performing system in the icon-2009 nlp tools contest (husain, 2009).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2847">
<title id=" W10-1403.xml">two methods to incorporate rsquolocal morphosyntacticrsquo features in hindi dependency parsing </title>
<section> results and analysis.  </section>
<citcontext>
<prevsection>
<prevsent>5.3 parser comparison: mst vs. malt.
</prevsent>
<prevsent>in all the experiments, results of malt parser are consistently better than mst+maxent.
</prevsent>
</prevsection>
<citsent citstr=" D07-1013 ">
we know that malt parser is good at short distance labeling and mst is good at long distance labeling (mcdo nald and nivre, 2007).<papid> D07-1013 </papid></citsent>
<aftsection>
<nextsent>the root of the sentence is better identified by mst parser than maltparser.
</nextsent>
<nextsent>our results also confirm this.
</nextsent>
<nextsent>mst+maxent and malt could identify the root of the sentence with an f-measure of 89.7% and 72.3% respectively.
</nextsent>
<nextsent>presence of more short distance labels helped malt to outperform mst.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2848">
<title id=" W10-0805.xml">syntactic construct  an aid for translating english nominal compound into hindi </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(law can be made by anyone, not by the hindus necessarily).
</prevsent>
<prevsent>such resolution of meaning is not possible from preposition paraphrase?.
</prevsent>
</prevsection>
<citsent citstr=" I05-1082 ">
the paper argues that this is not an issue from the point of view of trans 1kim and baldwin (2005) <papid> I05-1082 </papid>reports that the bnc corpus (84 million words: burnard (2000)) has 2.6% and the reuters has (108m words: rose et al (2002)) 3.9% of bigram nominal compound.</citsent>
<aftsection>
<nextsent>32lation at least.
</nextsent>
<nextsent>it is because the hindi correspondent of of?, which is ka?, is equally ambiguous.
</nextsent>
<nextsent>the translation of hindu law?
</nextsent>
<nextsent>is hinduom kakanun?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2849">
<title id=" W10-1004.xml">annotating esl errors challenges and rewards </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>work on automated methods for detecting and correcting context dependent mistakes (e.g., (golding and roth, 1996; golding and roth, 1999; carlson et al, 2001)) has taken an interesting turn over thelast few years, and has focused on correcting mistakes made by non-native speakers of english.
</prevsent>
<prevsent>nonnative writers make variety of errors in grammar and word usage.
</prevsent>
</prevsection>
<citsent citstr=" I08-1059 ">
recently, there has been lot of effort on building systems for detecting mistakes in article and preposition usage (defelice, 2008; eeg olofsson, 2003; gamon et al, 2008; <papid> I08-1059 </papid>han et al, 2006; tetreault and chodorow, 2008<papid> W08-1205 </papid>b).</citsent>
<aftsection>
<nextsent>izumi et al (2003) <papid> P03-2026 </papid>consider several error types, including article and preposition mistakes, made by japanese learners of english, and nagata et al (2006) <papid> P06-1031 </papid>focus on the errors in mass/count noun distinctions with an application to detecting article mistakes also made by japanese speakers.</nextsent>
<nextsent>article and preposition mistakes have been shown to be very common mistakes for learners of different first language (l1) backgrounds (dagneaux et al, 1998; gamon et al, 2008; <papid> I08-1059 </papid>izumi et al, 2004; tetreault and chodorow, 2008<papid> W08-1205 </papid>a), but there is no systematic study of whole range of errors non-native writers produce, nor is it clear what the distribution of different types of mistakes is in learner language.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2851">
<title id=" W10-1004.xml">annotating esl errors challenges and rewards </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>work on automated methods for detecting and correcting context dependent mistakes (e.g., (golding and roth, 1996; golding and roth, 1999; carlson et al, 2001)) has taken an interesting turn over thelast few years, and has focused on correcting mistakes made by non-native speakers of english.
</prevsent>
<prevsent>nonnative writers make variety of errors in grammar and word usage.
</prevsent>
</prevsection>
<citsent citstr=" W08-1205 ">
recently, there has been lot of effort on building systems for detecting mistakes in article and preposition usage (defelice, 2008; eeg olofsson, 2003; gamon et al, 2008; <papid> I08-1059 </papid>han et al, 2006; tetreault and chodorow, 2008<papid> W08-1205 </papid>b).</citsent>
<aftsection>
<nextsent>izumi et al (2003) <papid> P03-2026 </papid>consider several error types, including article and preposition mistakes, made by japanese learners of english, and nagata et al (2006) <papid> P06-1031 </papid>focus on the errors in mass/count noun distinctions with an application to detecting article mistakes also made by japanese speakers.</nextsent>
<nextsent>article and preposition mistakes have been shown to be very common mistakes for learners of different first language (l1) backgrounds (dagneaux et al, 1998; gamon et al, 2008; <papid> I08-1059 </papid>izumi et al, 2004; tetreault and chodorow, 2008<papid> W08-1205 </papid>a), but there is no systematic study of whole range of errors non-native writers produce, nor is it clear what the distribution of different types of mistakes is in learner language.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2861">
<title id=" W10-1004.xml">annotating esl errors challenges and rewards </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>nonnative writers make variety of errors in grammar and word usage.
</prevsent>
<prevsent>recently, there has been lot of effort on building systems for detecting mistakes in article and preposition usage (defelice, 2008; eeg olofsson, 2003; gamon et al, 2008; <papid> I08-1059 </papid>han et al, 2006; tetreault and chodorow, 2008<papid> W08-1205 </papid>b).</prevsent>
</prevsection>
<citsent citstr=" P03-2026 ">
izumi et al (2003) <papid> P03-2026 </papid>consider several error types, including article and preposition mistakes, made by japanese learners of english, and nagata et al (2006) <papid> P06-1031 </papid>focus on the errors in mass/count noun distinctions with an application to detecting article mistakes also made by japanese speakers.</citsent>
<aftsection>
<nextsent>article and preposition mistakes have been shown to be very common mistakes for learners of different first language (l1) backgrounds (dagneaux et al, 1998; gamon et al, 2008; <papid> I08-1059 </papid>izumi et al, 2004; tetreault and chodorow, 2008<papid> W08-1205 </papid>a), but there is no systematic study of whole range of errors non-native writers produce, nor is it clear what the distribution of different types of mistakes is in learner language.</nextsent>
<nextsent>in this paper, we describe corpus of sentences written by english as second language (esl) speakers, annotated for the purposes of developing an automated system for correcting mistakes in text.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2862">
<title id=" W10-1004.xml">annotating esl errors challenges and rewards </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>nonnative writers make variety of errors in grammar and word usage.
</prevsent>
<prevsent>recently, there has been lot of effort on building systems for detecting mistakes in article and preposition usage (defelice, 2008; eeg olofsson, 2003; gamon et al, 2008; <papid> I08-1059 </papid>han et al, 2006; tetreault and chodorow, 2008<papid> W08-1205 </papid>b).</prevsent>
</prevsection>
<citsent citstr=" P06-1031 ">
izumi et al (2003) <papid> P03-2026 </papid>consider several error types, including article and preposition mistakes, made by japanese learners of english, and nagata et al (2006) <papid> P06-1031 </papid>focus on the errors in mass/count noun distinctions with an application to detecting article mistakes also made by japanese speakers.</citsent>
<aftsection>
<nextsent>article and preposition mistakes have been shown to be very common mistakes for learners of different first language (l1) backgrounds (dagneaux et al, 1998; gamon et al, 2008; <papid> I08-1059 </papid>izumi et al, 2004; tetreault and chodorow, 2008<papid> W08-1205 </papid>a), but there is no systematic study of whole range of errors non-native writers produce, nor is it clear what the distribution of different types of mistakes is in learner language.</nextsent>
<nextsent>in this paper, we describe corpus of sentences written by english as second language (esl) speakers, annotated for the purposes of developing an automated system for correcting mistakes in text.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2909">
<title id=" W10-3102.xml">creating and evaluating a consensus for negated and speculative words in a swedish clinical corpus </title>
<section> related research.  </section>
<citcontext>
<prevsection>
<prevsent>in the cases where they did not agree, an annotation made by the chief annotator was chosen.
</prevsent>
<prevsent>2.3 the stanford ner based on crf.
</prevsent>
</prevsection>
<citsent citstr=" P05-1045 ">
the stanford named entity recognizer (ner) isbased on the machine learning algorithm conditional random fields (finkel et al, 2005) <papid> P05-1045 </papid>and hasbeen used extensively for identifying named entities in news text.</citsent>
<aftsection>
<nextsent>for example in the conll-2003, where the topic was language-independent named entity recognition, stanford ner crf was used both on english and german news text for training and evaluation.
</nextsent>
<nextsent>where the best results for english with stanford ner crf gave precision of 86.1 percent, recall of 86.5 percent and f-score of 86.3 percent, for german the best results hada precision of 80.4 percent, recall of 65.0 percent and an f-score of 71.9 percent, (klein et al, 2003).<papid> W03-0428 </papid></nextsent>
<nextsent>we have used the stanford ner crf for training and evaluation of our consensus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2911">
<title id=" W10-3102.xml">creating and evaluating a consensus for negated and speculative words in a swedish clinical corpus </title>
<section> related research.  </section>
<citcontext>
<prevsection>
<prevsent>the stanford named entity recognizer (ner) isbased on the machine learning algorithm conditional random fields (finkel et al, 2005) <papid> P05-1045 </papid>and hasbeen used extensively for identifying named entities in news text.</prevsent>
<prevsent>for example in the conll-2003, where the topic was language-independent named entity recognition, stanford ner crf was used both on english and german news text for training and evaluation.</prevsent>
</prevsection>
<citsent citstr=" W03-0428 ">
where the best results for english with stanford ner crf gave precision of 86.1 percent, recall of 86.5 percent and f-score of 86.3 percent, for german the best results hada precision of 80.4 percent, recall of 65.0 percent and an f-score of 71.9 percent, (klein et al, 2003).<papid> W03-0428 </papid></citsent>
<aftsection>
<nextsent>we have used the stanford ner crf for training and evaluation of our consensus.
</nextsent>
<nextsent>2.4 the annotated swedish clinical corpus.
</nextsent>
<nextsent>for negation and speculation process to create an annotated clinical corpus for negation and speculation is described in dalianis and velupillai (2010).
</nextsent>
<nextsent>a total of 6 740 randomly extracted sentences from very large clinical corpus in swedish were annotated by threenon-clinical annotators.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2912">
<title id=" W10-3102.xml">creating and evaluating a consensus for negated and speculative words in a swedish clinical corpus </title>
<section> method for constructing the consensus.  </section>
<citcontext>
<prevsection>
<prevsent>in light of the discussion above, the question towhat extent the annotations in the constructed consensus capture general perception of certainty or uncertainty must be posed.
</prevsent>
<prevsent>since it is constructed using majority method with three annotators, who had relatively low pairwise agreement, the corpus could probably not be said to be precise capture of what is certainty or uncertainty.
</prevsent>
</prevsection>
<citsent citstr=" J08-4004 ">
how ever, as artstein and poesio (2008) <papid> J08-4004 </papid>point out, it cannot be said that there is fixed level of agreement that is valid for all purposes of corpus, but the agreement must be high enough for certain purpose.</citsent>
<aftsection>
<nextsent>therefore, if the information on whether there was unanimous annotation of sentence ornot is retained, serving as an indicator of how typical an expression of certainty or uncertainty is, the constructed corpus can be useful resource.
</nextsent>
<nextsent>both for studying how uncertainty in clinical textis constructed and perceived, and as one of there sources that is used for learning to automatically detect certainty and uncertainty in clinical text.
</nextsent>
<nextsent>crf as first indication of whether it is possible to usethe annotated consensus corpus for finding negation and speculation in clinical text, we trained the stanford ner crf, (finkel et al, 2005) <papid> P05-1045 </papid>on the annotated data.</nextsent>
<nextsent>artstein and poesio (2008) <papid> J08-4004 </papid>write that the fact that annotated data can be generalized and learnt by machine learning system is not an indication that the annotations capture some kind of reality.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2918">
<title id=" W10-2904.xml">efficient correct unsupervised learning for context sensitive languages </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>both from engineering and cog nitive/linguistic angles, it is central challenge for computational linguistics.
</prevsent>
<prevsent>however good algorithms for this task are thin on the ground.
</prevsent>
</prevsection>
<citsent citstr=" P04-1061 ">
there are numerous heuristic algorithms, some of which have had significant success in inducing constituent structure (klein and manning, 2004).<papid> P04-1061 </papid></citsent>
<aftsection>
<nextsent>there are algorithms with theoretical guarantees as to their correctness ? such as for example bayesian algorithms for inducing pcfgs (john son, 2008), but such algorithms are inefficient: an exponential search algorithm is hidden in the convergence of the mcmc samplers.
</nextsent>
<nextsent>the efficient algorithms that are actually used are heuristic approximations to the true posteriors.
</nextsent>
<nextsent>there areal gorithms like the inside-outside algorithm (lariand young, 1990) which are guaranteed to converge efficiently, but not necessarily to the right answer: they converge to local optimum that may be, and in practice nearly always is very far from the optimum.
</nextsent>
<nextsent>there are naive enumerativealgorithms that are correct, but involve exhaustively enumerating all representations below certain size (horning, 1969).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2919">
<title id=" W10-2904.xml">efficient correct unsupervised learning for context sensitive languages </title>
<section> basic definitions.  </section>
<citcontext>
<prevsection>
<prevsent>chomsky (2006) says (p. 172, footnote 15): the concept of phrase structuregrammar?
</prevsent>
<prevsent>was explicitly designed to express the richest system that could reasonably be expected to result from the application of harris-type procedures to corpus.
</prevsent>
</prevsection>
<citsent citstr=" W01-0714 ">
second, empirically we know they work well atleast for lexical induction, (schutze, 1993; curran, 2003) and are component of some implemented unsupervised learning systems (klein and manning, 2001).<papid> W01-0714 </papid></citsent>
<aftsection>
<nextsent>linguists use them as one of the key tests for constituent structure (carnie, 2008), and finally there is some psycho linguistic evidence that children are sensitive to distributional structure, at least in artificial grammar learning tasks (saffran et al, 1996).
</nextsent>
<nextsent>these arguments together suggest that distributional learning has some what privileged status.
</nextsent>
<nextsent>clark (2009) presents the theory of lattice based formalisms starting algebraic ally from the theory of residuated lattices.
</nextsent>
<nextsent>here we will largely ignore this, and start from straightforward computational treatment.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2920">
<title id=" W10-2904.xml">efficient correct unsupervised learning for context sensitive languages </title>
<section> learning model.  </section>
<citcontext>
<prevsection>
<prevsent>there are two problems with learning ? the information theoretic problems studied under vc-dimension etc., and the computational complexity issues of constructing hypothesis from the data.
</prevsent>
<prevsent>in ourview, the latter problems are the key ones.
</prevsent>
</prevsection>
<citsent citstr=" W09-0904 ">
accordingly, we focus entirely on the efficiency issue, and allow ourself slightly unrealistic model; see (clark and lappin, 2009) <papid> W09-0904 </papid>for arguments that this is plausible model.we assume that we have sequence of positive examples, and that we can query examples for membership.</citsent>
<aftsection>
<nextsent>given language a presentation for is an infinite sequence of strings w1, w2, . . .
</nextsent>
<nextsent>such that {wi|i ? n} = l. an algorithm receives sequence and an oracle, and must produce ahypothesis at every step, using only polyno mial number of queries to the membership oracle ? polynomial in the total size of the presentation.it identifies in the limit the language iff for every presentation of there is n such that for all   hn = hn , and l(hn ) = l. we say it identifies in the limit class of languages iff it identifies in the limit all in l. we say that it identifies the class in polynomial update time iff there is polynomial p, such that at each step the model uses an amount of computation (and thus also number of queries) that is less than p(n, l),where is the number of strings and is the maximum length of string in the observed data.
</nextsent>
<nextsent>we note that this is slightly too weak.
</nextsent>
<nextsent>it is possible to produce vacuous enumerative algorithms that 34can learn anything by only processing logarith mically small prefix of the string (pitt, 1989).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2921">
<title id=" W10-3212.xml">word segmentation for urdu ocr system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in urdu, space is not used to separate two consecutive words in sentence; instead readers themselves identify the boundaries of words, as the sequence of ligatures, as they read along the text.
</prevsent>
<prevsent>space is used to get appropriate character shapes and thus it may even be used within word to break the word into constituent ligatures (naseem 2007, durrani 2008).
</prevsent>
</prevsection>
<citsent citstr=" H01-1057 ">
therefore, like other languages (theeramunkong &amp; usanavasin, 2001; <papid> H01-1057 </papid>wan and liu, 2007; khanka sikam &amp; muansuwan, 2005; haruechaiyasak et al., 2008; haizhou &amp; bao sheng, 1998), word segmentation or word tokenization is preliminary task for urdu language processing.</citsent>
<aftsection>
<nextsent>it has applications in many areas like spell checking, pos tagging, speech synthesis, information retrieval etc. this paper focuses on the word segmentation problem from the point of view of optical character recognition (ocr) system.
</nextsent>
<nextsent>as space is not visible in typed and scanned text, spacing cues are not available to the ocr for word separation and therefore segmentation has to be done more explicitly.
</nextsent>
<nextsent>this word segmentation model for urdu ocr system takes input in the form of sequence of ligatures recognized by an ocr to construct sequence of words from them.
</nextsent>
<nextsent>many languages, e.g., english, french, hindi, nepali, sinhala, bengali, greek, russian, etc. segment text into sequence of words using delimiters such as space, comma and semicolon etc., but on the other hand many asian languages like urdu, persian, arabic, chinese, dzongkha, lao and thai have no explicit word boundaries.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2922">
<title id=" W10-3212.xml">word segmentation for urdu ocr system </title>
<section> literature review.  </section>
<citcontext>
<prevsection>
<prevsent>this word segmentation model for urdu ocr system takes input in the form of sequence of ligatures recognized by an ocr to construct sequence of words from them.
</prevsent>
<prevsent>many languages, e.g., english, french, hindi, nepali, sinhala, bengali, greek, russian, etc. segment text into sequence of words using delimiters such as space, comma and semicolon etc., but on the other hand many asian languages like urdu, persian, arabic, chinese, dzongkha, lao and thai have no explicit word boundaries.
</prevsent>
</prevsection>
<citsent citstr=" J96-3004 ">
in such languages, words are segmented using more advanced techniques, which can be categorized into three methods: (i) dictionary/lexicon based approaches (ii) linguistic knowledge based approaches (iii) machine learning based approach es/statistical approaches (haruechaiyasak et al, 2008) longest matching (poowarawan, 1986; richard sproat, 1996) and maximum matching (sproat et al, 1996; <papid> J96-3004 </papid>haizhou &amp; bao sheng, 1998) are examples of lexicon based approaches.</citsent>
<aftsection>
<nextsent>these techniques segment text using the lexicon.
</nextsent>
<nextsent>their 88 accuracy depends on the quality and size of the dictionary.
</nextsent>
<nextsent>n-grams (chang et al, 1992; li haizhou et al, 1997; richard sproat, 1996; dai &amp; lee, 1994; aroonmanakun, 2002) and maximum collocation (aroonmanakun, 2002) are linguistic knowledge based approaches, which also rely very much on the lexicon.
</nextsent>
<nextsent>these approaches select most likely segmentation from the set of possible segment ations using probabilistic or cost-based scoring mechanism.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2923">
<title id=" W10-3212.xml">word segmentation for urdu ocr system </title>
<section> literature review.  </section>
<citcontext>
<prevsection>
<prevsent>n-grams (chang et al, 1992; li haizhou et al, 1997; richard sproat, 1996; dai &amp; lee, 1994; aroonmanakun, 2002) and maximum collocation (aroonmanakun, 2002) are linguistic knowledge based approaches, which also rely very much on the lexicon.
</prevsent>
<prevsent>these approaches select most likely segmentation from the set of possible segment ations using probabilistic or cost-based scoring mechanism.
</prevsent>
</prevsection>
<citsent citstr=" C00-2116 ">
word segmentation using decision trees (sornlertlamvanich et al, 2000; <papid> C00-2116 </papid>theeramunkong &amp; usanavasin, 2001) <papid> H01-1057 </papid>and similar other techniques fall in the third category of word segmentation techniques.</citsent>
<aftsection>
<nextsent>these approaches use corpus in which word boundaries are explicitly marked.
</nextsent>
<nextsent>these approaches do not require dictionaries.
</nextsent>
<nextsent>in these approaches ambiguity problems are handled by providing sufficiently large set of training examples to enable accurate classification.
</nextsent>
<nextsent>a knowledge based approach has been adopted for earlier work on urdu word segmentation (durrani 2007; also see durrani and hussain 2010).<papid> N10-1077 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2925">
<title id=" W10-3212.xml">word segmentation for urdu ocr system </title>
<section> literature review.  </section>
<citcontext>
<prevsection>
<prevsent>these approaches do not require dictionaries.
</prevsent>
<prevsent>in these approaches ambiguity problems are handled by providing sufficiently large set of training examples to enable accurate classification.
</prevsent>
</prevsection>
<citsent citstr=" N10-1077 ">
a knowledge based approach has been adopted for earlier work on urdu word segmentation (durrani 2007; also see durrani and hussain 2010).<papid> N10-1077 </papid></citsent>
<aftsection>
<nextsent>in this technique word segmentation of urdu text is achieved by employing know ledge based on the urdu linguistics and script.
</nextsent>
<nextsent>the initial segment ations are ranked using min word, unigram and bigram techniques.
</nextsent>
<nextsent>it reports 95.8 % overall accuracy for word segmentation of urdu text.
</nextsent>
<nextsent>mukund et al (2009) propose using character model along with linguistic rules and report 83% precision.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2926">
<title id=" W10-3212.xml">word segmentation for urdu ocr system </title>
<section> methodology.  </section>
<citcontext>
<prevsection>
<prevsent>same procedure is performed if trigram word matches with an affix.
</prevsent>
<prevsent>after cleaning, unigram, bigram and trigram counts for both words and ligatures are calculated.
</prevsent>
</prevsection>
<citsent citstr=" P96-1041 ">
to avoid data sparseness one count smoothing (chen &amp; goodman, 1996) <papid> P96-1041 </papid>is applied.</citsent>
<aftsection>
<nextsent>3.3 word sequences generation from input.
</nextsent>
<nextsent>the input, in the form of sequence of liga tures is used to generate all possible words.
</nextsent>
<nextsent>these sequences are then ranked based on real words.
</nextsent>
<nextsent>for this purpose, tree of these sequences is incrementally built.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2927">
<title id=" W10-1842.xml">design and evaluation of shared prosodic annotation for spontaneous french speech from expert knowledge to non expert annotation </title>
<section> pilot experiment one.  </section>
<citcontext>
<prevsection>
<prevsent>the empty segments correspond to any prosodic events detected in which the comment points out an incorrect sylla bic labelling.
</prevsent>
<prevsent>2.2 results of the coding: inter-annotator.
</prevsent>
</prevsection>
<citsent citstr=" J96-2004 ">
agreement in pilot experiment one ? agreement measure the kappa statistic has been widely used in the past decade to assess inter-annotator agreement in prosodic labelling tasks (syrdal and mcgory, 2000), and in particular the reliability of inter annotator agreement in the case of categorical rating, (carletta, 1996).<papid> J96-2004 </papid></citsent>
<aftsection>
<nextsent>among the many versions proposed in the literature, we selected the fleiss?
</nextsent>
<nextsent>kappa (fleiss, 1971), which provides an overall agreement measure over fixed number of annotators in the case of categorical rating (unlike cohen kappa which only provides measure of pairwise agreement).
</nextsent>
<nextsent>results figure 2 presents the fleiss?
</nextsent>
<nextsent>kappa agreement for each prosodic label.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2928">
<title id=" W10-1730.xml">maximum entropy translation model in dependency based mt framework </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>when integrated into english-toczech dependency-based translation scenario implemented in the tectomt framework, the new translation model significantly outperforms the baseline model(mle) in terms of bleu.
</prevsent>
<prevsent>the performance is further boosted in configuration inspired by hidden tree markov models which combines the maximum entropy translation model with the target-language dependency tree model.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
the principle of maximum entropy states that,given known constraints, the probability distribution which best represents the current state of knowledge is the one with the largest entropy.maximum entropy models based on this principle have been widely used in natural language processing, e.g. for tagging (ratnaparkhi, 1996),<papid> W96-0213 </papid>parsing (charniak, 2000), and named entity recognition (bender et al, 2003).<papid> W03-0420 </papid></citsent>
<aftsection>
<nextsent>maximum entropy models have the following form p(y|x) = 1 z(x) exp ? ifi(x, y) where fi is feature function, is its weight, and z(x) is the normalizing factor z(x) = ? exp ? ifi(x, y)in statistical machine translation (smt), translation model (tm) p(t|s) is the probability that the string from the target language is the translation of the string from the source language.
</nextsent>
<nextsent>typical approach in smt is to use backward translation model p(s|t) according to bayes?
</nextsent>
<nextsent>rule and noisy channel model.
</nextsent>
<nextsent>however, in this paper we deal only with the forward (direct) model.1the idea of using maximum entropy for constructing forward translation models is not new.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2929">
<title id=" W10-1730.xml">maximum entropy translation model in dependency based mt framework </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>when integrated into english-toczech dependency-based translation scenario implemented in the tectomt framework, the new translation model significantly outperforms the baseline model(mle) in terms of bleu.
</prevsent>
<prevsent>the performance is further boosted in configuration inspired by hidden tree markov models which combines the maximum entropy translation model with the target-language dependency tree model.
</prevsent>
</prevsection>
<citsent citstr=" W03-0420 ">
the principle of maximum entropy states that,given known constraints, the probability distribution which best represents the current state of knowledge is the one with the largest entropy.maximum entropy models based on this principle have been widely used in natural language processing, e.g. for tagging (ratnaparkhi, 1996),<papid> W96-0213 </papid>parsing (charniak, 2000), and named entity recognition (bender et al, 2003).<papid> W03-0420 </papid></citsent>
<aftsection>
<nextsent>maximum entropy models have the following form p(y|x) = 1 z(x) exp ? ifi(x, y) where fi is feature function, is its weight, and z(x) is the normalizing factor z(x) = ? exp ? ifi(x, y)in statistical machine translation (smt), translation model (tm) p(t|s) is the probability that the string from the target language is the translation of the string from the source language.
</nextsent>
<nextsent>typical approach in smt is to use backward translation model p(s|t) according to bayes?
</nextsent>
<nextsent>rule and noisy channel model.
</nextsent>
<nextsent>however, in this paper we deal only with the forward (direct) model.1the idea of using maximum entropy for constructing forward translation models is not new.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2930">
<title id=" W10-1730.xml">maximum entropy translation model in dependency based mt framework </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, in this paper we deal only with the forward (direct) model.1the idea of using maximum entropy for constructing forward translation models is not new.
</prevsent>
<prevsent>it naturally allows to make use of various features potentially important for correct choice of target language expressions.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
let us adopt motivating example of such feature from (berger et al, 1996) (<papid> J96-1002 </papid>which contains the first usage of maxenttranslation model we are aware of): if house appears within the next three words (e.g., the phrases in the house and in the red house), then dans might be more likely [french] translation [of in].?</citsent>
<aftsection>
<nextsent>incorporating non-local features extracted fromthe source sentence into the standard noisy channel model in which only the backward translation model is available, is not possible.
</nextsent>
<nextsent>this drawback of the noisy-channel approach is typically compensated by using large target-language n-gram models, which can ? in result ? play arole similar to that of more elaborate (more context sensitive) forward translation model.
</nextsent>
<nextsent>how ever, we expect that it would be more beneficial to exploit both the parallel data and the monolingual data in more balance fashion, rather than extract only reduced amount of information from the parallel data and compensate it by large language model on the target side.
</nextsent>
<nextsent>1a backward translation model is used only for pruning training data in this paper.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2931">
<title id=" W10-1730.xml">maximum entropy translation model in dependency based mt framework </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>how ever, we expect that it would be more beneficial to exploit both the parallel data and the monolingual data in more balance fashion, rather than extract only reduced amount of information from the parallel data and compensate it by large language model on the target side.
</prevsent>
<prevsent>1a backward translation model is used only for pruning training data in this paper.
</prevsent>
</prevsection>
<citsent citstr=" P00-1006 ">
201 deeper discussion on the potential advantages of maximum entropy approach over the noisy channel approach can be found in (foster, 2000)<papid> P00-1006 </papid>and (och and ney, 2002), <papid> P02-1038 </papid>in which another successful applications of maxent translation models are shown.</citsent>
<aftsection>
<nextsent>log-linear translation models (instead of mle) with rich feature sets are used also in (ittycheriah and roukos, 2007) <papid> N07-1008 </papid>and (gimpel and smith, 2009); <papid> D09-1023 </papid>the idea can be traced back to (pap ineni et al, 1997).</nextsent>
<nextsent>what makes our approach different from the previously published works is that1.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2932">
<title id=" W10-1730.xml">maximum entropy translation model in dependency based mt framework </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>how ever, we expect that it would be more beneficial to exploit both the parallel data and the monolingual data in more balance fashion, rather than extract only reduced amount of information from the parallel data and compensate it by large language model on the target side.
</prevsent>
<prevsent>1a backward translation model is used only for pruning training data in this paper.
</prevsent>
</prevsection>
<citsent citstr=" P02-1038 ">
201 deeper discussion on the potential advantages of maximum entropy approach over the noisy channel approach can be found in (foster, 2000)<papid> P00-1006 </papid>and (och and ney, 2002), <papid> P02-1038 </papid>in which another successful applications of maxent translation models are shown.</citsent>
<aftsection>
<nextsent>log-linear translation models (instead of mle) with rich feature sets are used also in (ittycheriah and roukos, 2007) <papid> N07-1008 </papid>and (gimpel and smith, 2009); <papid> D09-1023 </papid>the idea can be traced back to (pap ineni et al, 1997).</nextsent>
<nextsent>what makes our approach different from the previously published works is that1.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2933">
<title id=" W10-1730.xml">maximum entropy translation model in dependency based mt framework </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>1a backward translation model is used only for pruning training data in this paper.
</prevsent>
<prevsent>201 deeper discussion on the potential advantages of maximum entropy approach over the noisy channel approach can be found in (foster, 2000)<papid> P00-1006 </papid>and (och and ney, 2002), <papid> P02-1038 </papid>in which another successful applications of maxent translation models are shown.</prevsent>
</prevsection>
<citsent citstr=" N07-1008 ">
log-linear translation models (instead of mle) with rich feature sets are used also in (ittycheriah and roukos, 2007) <papid> N07-1008 </papid>and (gimpel and smith, 2009); <papid> D09-1023 </papid>the idea can be traced back to (pap ineni et al, 1997).</citsent>
<aftsection>
<nextsent>what makes our approach different from the previously published works is that1.
</nextsent>
<nextsent>we show how the maximum entropy translation model can be used in dependencyframework; we use deep-syntactic dependency trees (as defined in the prague dependency treebank (hajic?
</nextsent>
<nextsent>et al, 2006)) as the transfer layer,2.
</nextsent>
<nextsent>we combine the maximum entropy translation model with target-language dependency tree model and use tree-modified viterbisearch for finding the optimal lemmas labeling of the target-tree nodes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2934">
<title id=" W10-1730.xml">maximum entropy translation model in dependency based mt framework </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>1a backward translation model is used only for pruning training data in this paper.
</prevsent>
<prevsent>201 deeper discussion on the potential advantages of maximum entropy approach over the noisy channel approach can be found in (foster, 2000)<papid> P00-1006 </papid>and (och and ney, 2002), <papid> P02-1038 </papid>in which another successful applications of maxent translation models are shown.</prevsent>
</prevsection>
<citsent citstr=" D09-1023 ">
log-linear translation models (instead of mle) with rich feature sets are used also in (ittycheriah and roukos, 2007) <papid> N07-1008 </papid>and (gimpel and smith, 2009); <papid> D09-1023 </papid>the idea can be traced back to (pap ineni et al, 1997).</citsent>
<aftsection>
<nextsent>what makes our approach different from the previously published works is that1.
</nextsent>
<nextsent>we show how the maximum entropy translation model can be used in dependencyframework; we use deep-syntactic dependency trees (as defined in the prague dependency treebank (hajic?
</nextsent>
<nextsent>et al, 2006)) as the transfer layer,2.
</nextsent>
<nextsent>we combine the maximum entropy translation model with target-language dependency tree model and use tree-modified viterbisearch for finding the optimal lemmas labeling of the target-tree nodes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2935">
<title id=" W10-1730.xml">maximum entropy translation model in dependency based mt framework </title>
<section> then the maximum spanning tree parser.  </section>
<citcontext>
<prevsection>
<prevsent>tyden snazil najt utociste?
</prevsent>
<prevsent>v brazlii.?.
</prevsent>
</prevsection>
<citsent citstr=" H05-1066 ">
(mcdonald et al, 2005) <papid> H05-1066 </papid>is applied and surface-syntax dependency tree (analytical tree in the pdt terminology) is created for each sentence (figure 1a).</citsent>
<aftsection>
<nextsent>tree (figure 1b).
</nextsent>
<nextsent>each auto semantic word with its associated functional words is collapsed into single tectogrammatical node,labeled with lemma, formeme, and semantically indispensable morphologically categories; coreference is also resolved.
</nextsent>
<nextsent>collapsing edges are depicted by wider lines in the figure 1a.
</nextsent>
<nextsent>5.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2936">
<title id=" W10-1730.xml">maximum entropy translation model in dependency based mt framework </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>when included into the above described translation scenario, the maxent tm outperforms the baseline tm, be it used together with or without treelm.
</prevsent>
<prevsent>the results are summarized in table 1.
</prevsent>
</prevsection>
<citsent citstr=" W04-3250 ">
the improvement is statistically significant according to paired bootstrap re sampling test (koehn, 2004).<papid> W04-3250 </papid></citsent>
<aftsection>
<nextsent>in the configuration without treelm the improvement is greater (1.33 bleu) than with treelm (0.81 bleu), which confirms our hypothesis that maxent tm captures some of the contextual dependencies resolved otherwise by language models.
</nextsent>
<nextsent>205
</nextsent>
<nextsent>we have introduced maximum entropy translation model in dependency-based mt which enables exploiting large number of feature functions in order to obtain more accurate translations.the bleu evaluation proved significant improvement over the baseline solution based on the translation model with maximum likelihood estimates.however, the performance of this system still be low the state of the art (which is around bleu 16 for the english-to-czech direction).
</nextsent>
<nextsent>acknowledgments this research was supported by the grantsmsm0021620838, msmt cr lc536, fp7-ict 2009-4-247762 (faust), fp7-ict-2007-3-231720 (euromatrix plus), ga201/09/h057, and gauk 116310.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2937">
<title id=" W10-3019.xml">uncertainty learning using svms and crfs </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>our approach was to explore the use of deep syntactic features in this tagging task.
</prevsent>
<prevsent>deep syntactic features had been proven useful in many similar tagging tasks before.
</prevsent>
</prevsection>
<citsent citstr=" N09-2047 ">
we used the dependency parser mica (bangalore et al, 2009) <papid> N09-2047 </papid>based ontree adjoining grammar (joshi et al, 1975) to extract these deep syntactic features.we classified the features into three classes lexical (l), syntactic (s) and wordlist-based (w).</citsent>
<aftsection>
<nextsent>lexical features are those which could be found atthe token level without using any word lists or dictionaries and can be extracted without any parsing with relatively high accuracy.
</nextsent>
<nextsent>for example, is numeric, which denotes whether the word is number or alphabetic, is lexical feature.
</nextsent>
<nextsent>under this definition, pos tag will be considered as lexical feature.
</nextsent>
<nextsent>syntactic features of token access its syntactic context in the dependency tree.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2938">
<title id=" W10-3803.xml">source side syntactic reordering patterns with functional words for improved phrase based smt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>furthermore, system with just 61.88% of the patterns filtered by functional words obtains comparable performance with the unfiltered one on the randomly selected testset, and achieves 1.74% relative improvements on the nist 2008 testset.
</prevsent>
<prevsent>previous work has shown that the problem of structural differences between language pairs in smt can be alleviated by source-side syntactic reordering.
</prevsent>
</prevsection>
<citsent citstr=" W08-0406 ">
taking account for the integration with smt systems, these methods can be divided into two different kinds of approaches (elming,2008): <papid> W08-0406 </papid>the deterministic reordering and the non deterministic reordering approach.to carry out the deterministic approach, syntactic reordering is performed uniformly on the training, devset and testset before being fed into the smt systems, so that only the reordered source sentences are dealt with while building during the smt system.</citsent>
<aftsection>
<nextsent>in this case, most work is focused on methods to extract and to apply syntactic reordering patterns which come from manually created rules (collins et al, 2005;<papid> P05-1066 </papid>wang et al,2007<papid> D07-1077 </papid>a), or via an automatic extraction process taking advantage of parse trees (collins et al, 2005;<papid> P05-1066 </papid>habash, 2007).</nextsent>
<nextsent>because reordered source sentence cannot be undone by the smt decoders (al onaizan et al, 2006), which implies systematic error for this approach, classifiers (chang et al, 2009<papid> W09-2307 </papid>b; du &amp; way, 2010) are utilized to obtain high-performance reordering for some specialized syntactic structures (e.g. deconstruction in chi nese).on the other hand, the non-deterministic approach leaves the decisions to the decoders to choose appropriate source-side reorderings.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2939">
<title id=" W10-3803.xml">source side syntactic reordering patterns with functional words for improved phrase based smt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>previous work has shown that the problem of structural differences between language pairs in smt can be alleviated by source-side syntactic reordering.
</prevsent>
<prevsent>taking account for the integration with smt systems, these methods can be divided into two different kinds of approaches (elming,2008): <papid> W08-0406 </papid>the deterministic reordering and the non deterministic reordering approach.to carry out the deterministic approach, syntactic reordering is performed uniformly on the training, devset and testset before being fed into the smt systems, so that only the reordered source sentences are dealt with while building during the smt system.</prevsent>
</prevsection>
<citsent citstr=" P05-1066 ">
in this case, most work is focused on methods to extract and to apply syntactic reordering patterns which come from manually created rules (collins et al, 2005;<papid> P05-1066 </papid>wang et al,2007<papid> D07-1077 </papid>a), or via an automatic extraction process taking advantage of parse trees (collins et al, 2005;<papid> P05-1066 </papid>habash, 2007).</citsent>
<aftsection>
<nextsent>because reordered source sentence cannot be undone by the smt decoders (al onaizan et al, 2006), which implies systematic error for this approach, classifiers (chang et al, 2009<papid> W09-2307 </papid>b; du &amp; way, 2010) are utilized to obtain high-performance reordering for some specialized syntactic structures (e.g. deconstruction in chi nese).on the other hand, the non-deterministic approach leaves the decisions to the decoders to choose appropriate source-side reorderings.</nextsent>
<nextsent>this is more flexible because both the original and reordered source sentences are presented in the inputs.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2941">
<title id=" W10-3803.xml">source side syntactic reordering patterns with functional words for improved phrase based smt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>previous work has shown that the problem of structural differences between language pairs in smt can be alleviated by source-side syntactic reordering.
</prevsent>
<prevsent>taking account for the integration with smt systems, these methods can be divided into two different kinds of approaches (elming,2008): <papid> W08-0406 </papid>the deterministic reordering and the non deterministic reordering approach.to carry out the deterministic approach, syntactic reordering is performed uniformly on the training, devset and testset before being fed into the smt systems, so that only the reordered source sentences are dealt with while building during the smt system.</prevsent>
</prevsection>
<citsent citstr=" D07-1077 ">
in this case, most work is focused on methods to extract and to apply syntactic reordering patterns which come from manually created rules (collins et al, 2005;<papid> P05-1066 </papid>wang et al,2007<papid> D07-1077 </papid>a), or via an automatic extraction process taking advantage of parse trees (collins et al, 2005;<papid> P05-1066 </papid>habash, 2007).</citsent>
<aftsection>
<nextsent>because reordered source sentence cannot be undone by the smt decoders (al onaizan et al, 2006), which implies systematic error for this approach, classifiers (chang et al, 2009<papid> W09-2307 </papid>b; du &amp; way, 2010) are utilized to obtain high-performance reordering for some specialized syntactic structures (e.g. deconstruction in chi nese).on the other hand, the non-deterministic approach leaves the decisions to the decoders to choose appropriate source-side reorderings.</nextsent>
<nextsent>this is more flexible because both the original and reordered source sentences are presented in the inputs.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2943">
<title id=" W10-3803.xml">source side syntactic reordering patterns with functional words for improved phrase based smt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>taking account for the integration with smt systems, these methods can be divided into two different kinds of approaches (elming,2008): <papid> W08-0406 </papid>the deterministic reordering and the non deterministic reordering approach.to carry out the deterministic approach, syntactic reordering is performed uniformly on the training, devset and testset before being fed into the smt systems, so that only the reordered source sentences are dealt with while building during the smt system.</prevsent>
<prevsent>in this case, most work is focused on methods to extract and to apply syntactic reordering patterns which come from manually created rules (collins et al, 2005;<papid> P05-1066 </papid>wang et al,2007<papid> D07-1077 </papid>a), or via an automatic extraction process taking advantage of parse trees (collins et al, 2005;<papid> P05-1066 </papid>habash, 2007).</prevsent>
</prevsection>
<citsent citstr=" W09-2307 ">
because reordered source sentence cannot be undone by the smt decoders (al onaizan et al, 2006), which implies systematic error for this approach, classifiers (chang et al, 2009<papid> W09-2307 </papid>b; du &amp; way, 2010) are utilized to obtain high-performance reordering for some specialized syntactic structures (e.g. deconstruction in chi nese).on the other hand, the non-deterministic approach leaves the decisions to the decoders to choose appropriate source-side reorderings.</citsent>
<aftsection>
<nextsent>this is more flexible because both the original and reordered source sentences are presented in the inputs.
</nextsent>
<nextsent>word lattices generated from syntactic structures for n-gram-based smt is presented in (crego et al, 2007).
</nextsent>
<nextsent>in (zhang et al, 2007<papid> W07-0401 </papid>a; zhang et al, 2007<papid> W07-0401 </papid>b), chunks and pos tags areused to extract reordering rules, while the generated word lattices are weighted by language models and reordering models.</nextsent>
<nextsent>rules created from syntactic parser are also utilized to form weighted n-best lists which are fed into the decoder (li etal., 2007).<papid> P07-1091 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2959">
<title id=" W10-3803.xml">source side syntactic reordering patterns with functional words for improved phrase based smt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this is more flexible because both the original and reordered source sentences are presented in the inputs.
</prevsent>
<prevsent>word lattices generated from syntactic structures for n-gram-based smt is presented in (crego et al, 2007).
</prevsent>
</prevsection>
<citsent citstr=" W07-0401 ">
in (zhang et al, 2007<papid> W07-0401 </papid>a; zhang et al, 2007<papid> W07-0401 </papid>b), chunks and pos tags areused to extract reordering rules, while the generated word lattices are weighted by language models and reordering models.</citsent>
<aftsection>
<nextsent>rules created from syntactic parser are also utilized to form weighted n-best lists which are fed into the decoder (li etal., 2007).<papid> P07-1091 </papid></nextsent>
<nextsent>furthermore, (elming, 2008; <papid> W08-0406 </papid>elm 19 ing, 2009) uses syntactic rules to score the output word order, both on english danish and english?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG2963">
<title id=" W10-3803.xml">source side syntactic reordering patterns with functional words for improved phrase based smt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>word lattices generated from syntactic structures for n-gram-based smt is presented in (crego et al, 2007).
</prevsent>
<prevsent>in (zhang et al, 2007<papid> W07-0401 </papid>a; zhang et al, 2007<papid> W07-0401 </papid>b), chunks and pos tags areused to extract reordering rules, while the generated word lattices are weighted by language models and reordering models.</prevsent>
</prevsection>
<citsent citstr=" P07-1091 ">
rules created from syntactic parser are also utilized to form weighted n-best lists which are fed into the decoder (li etal., 2007).<papid> P07-1091 </papid></citsent>
<aftsection>
<nextsent>furthermore, (elming, 2008; <papid> W08-0406 </papid>elm 19 ing, 2009) uses syntactic rules to score the output word order, both on english danish and english?</nextsent>
<nextsent>arabic tasks.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3017">
<title id=" W10-3803.xml">source side syntactic reordering patterns with functional words for improved phrase based smt </title>
<section> syntactic reordering patterns.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 lattice scoring for phrase alignments.
</prevsent>
<prevsent>the lattice scoring approach is proposed in (jiang et al, 2010) for the smt data cleaning task.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
20 to clean the training corpus, word alignments are used to obtain approximate decoding results, which are then used to calculate bleu (papineniet al, 2002) <papid> P02-1040 </papid>scores to filter out low-scoring sentences pairs.</citsent>
<aftsection>
<nextsent>the following steps are taken in the lattice scoring approach: 1) train an initialpbsmt model; 2) collect anchor pairs containing source and target phrase positions from word alignments generated in the training phase; 3) build source-side lattices from the anchor pair sand the translation model; 4) search on the source side lattices to obtain approximate decoding re sults; 5) calculate bleu scores for the purpose of data cleaning.
</nextsent>
<nextsent>note that the source-side lattices in step 3 come from anchor pairs, so each edge in the lattices contain both the source and target phrase positions.thus the outputs of step 4 contain phrase alignments on the training corpus.
</nextsent>
<nextsent>these phrase alignments are used to identify non-monotonic areas for the extraction of reordering patterns.
</nextsent>
<nextsent>2.2 reordering patterns.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3050">
<title id=" W10-3803.xml">source side syntactic reordering patterns with functional words for improved phrase based smt </title>
<section> experiments and results.  </section>
<citcontext>
<prevsection>
<prevsent>a total number of 256,911 sentence pairs are obtained, while 2,000 pairs fordevset and 2,000 pairs for testset are randomly selected, which we call fbis set.
</prevsent>
<prevsent>the rest of the data is used as the training corpus.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
the baseline system is moses (koehn et al., 2007), <papid> P07-2045 </papid>and giza++1 is used to perform word alignment.</citsent>
<aftsection>
<nextsent>minimum error rate training (mert) (och, 2003) <papid> P03-1021 </papid>is carried out for tuning.</nextsent>
<nextsent>a 5-gram language model built via srilm2 is used for all the experiments in this paper.experiments results are reported on two different sets: the fbis set and the nist set.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3051">
<title id=" W10-3803.xml">source side syntactic reordering patterns with functional words for improved phrase based smt </title>
<section> experiments and results.  </section>
<citcontext>
<prevsection>
<prevsent>the rest of the data is used as the training corpus.
</prevsent>
<prevsent>the baseline system is moses (koehn et al., 2007), <papid> P07-2045 </papid>and giza++1 is used to perform word alignment.</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
minimum error rate training (mert) (och, 2003) <papid> P03-1021 </papid>is carried out for tuning.</citsent>
<aftsection>
<nextsent>a 5-gram language model built via srilm2 is used for all the experiments in this paper.experiments results are reported on two different sets: the fbis set and the nist set.
</nextsent>
<nextsent>for the nist set, the nist 2005 testset (1,082 sentences)is used as the devset, and the nist 2008 test set (1,357 sentences) is used as the testset.
</nextsent>
<nextsent>the fbis set contains only one reference translation for both devset and testset, while nist set has four references.
</nextsent>
<nextsent>5.1 pattern extraction and filtering with.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3084">
<title id=" W10-2902.xml">viterbi training improves unsupervised dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a typical approach is to attempt maximizing the likelihood of unlabeled data, in accordance with probabilistic model.sadly, such functions are riddled with local optima (charniak, 1993, ch.
</prevsent>
<prevsent>7, inter alia), since their number of peaks grows exponentially with instances of hidden variables.
</prevsent>
</prevsection>
<citsent citstr=" A94-1009 ">
furthermore, higher likelihood does not always translate into superior task-specific accuracy (elworthy, 1994; <papid> A94-1009 </papid>merialdo, 1994).<papid> J94-2001 </papid></citsent>
<aftsection>
<nextsent>both complications are real, but we will discuss perhaps more significant shortcomings.
</nextsent>
<nextsent>we prove that learning can be error-prone evenin cases when likelihood is an appropriate measure of extrinsic performance and where global optimization is feasible.
</nextsent>
<nextsent>this is because key challenge in unsupervised learning is that the desired likelihood is unknown.
</nextsent>
<nextsent>its absence renders tasks like structure discovery inherently underconstrained.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3086">
<title id=" W10-2902.xml">viterbi training improves unsupervised dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a typical approach is to attempt maximizing the likelihood of unlabeled data, in accordance with probabilistic model.sadly, such functions are riddled with local optima (charniak, 1993, ch.
</prevsent>
<prevsent>7, inter alia), since their number of peaks grows exponentially with instances of hidden variables.
</prevsent>
</prevsection>
<citsent citstr=" J94-2001 ">
furthermore, higher likelihood does not always translate into superior task-specific accuracy (elworthy, 1994; <papid> A94-1009 </papid>merialdo, 1994).<papid> J94-2001 </papid></citsent>
<aftsection>
<nextsent>both complications are real, but we will discuss perhaps more significant shortcomings.
</nextsent>
<nextsent>we prove that learning can be error-prone evenin cases when likelihood is an appropriate measure of extrinsic performance and where global optimization is feasible.
</nextsent>
<nextsent>this is because key challenge in unsupervised learning is that the desired likelihood is unknown.
</nextsent>
<nextsent>its absence renders tasks like structure discovery inherently underconstrained.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3088">
<title id=" W10-2902.xml">viterbi training improves unsupervised dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>regularities in data.
</prevsent>
<prevsent>their wrong objectives create cases in which both efficiency and performance improve when expensive exact learning techniques are replaced by cheap approximations.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
we propose using viterbi training (brownet al , 1993), <papid> J93-2003 </papid>instead of inside-outside reestimation (baker, 1979), to induce hierarchical syntactic structure from natural language text.</citsent>
<aftsection>
<nextsent>our experiments with klein and mannings (2004) <papid> P04-1061 </papid>dependency model with valence (dmv), popularstate-of-the-art model (headden et al , 2009; <papid> N09-1012 </papid>cohen and smith, 2009; <papid> N09-1009 </papid>spitkovsky et al , 2009), beat previous benchmark accuracies by 3.8% (on section 23 of wsj) and 7.5% (on parsed brown).</nextsent>
<nextsent>since objective functions used in unsupervised grammar induction are prov ably wrong, advantages of exact inference may not apply.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3089">
<title id=" W10-2902.xml">viterbi training improves unsupervised dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>their wrong objectives create cases in which both efficiency and performance improve when expensive exact learning techniques are replaced by cheap approximations.
</prevsent>
<prevsent>we propose using viterbi training (brownet al , 1993), <papid> J93-2003 </papid>instead of inside-outside reestimation (baker, 1979), to induce hierarchical syntactic structure from natural language text.</prevsent>
</prevsection>
<citsent citstr=" P04-1061 ">
our experiments with klein and mannings (2004) <papid> P04-1061 </papid>dependency model with valence (dmv), popularstate-of-the-art model (headden et al , 2009; <papid> N09-1012 </papid>cohen and smith, 2009; <papid> N09-1009 </papid>spitkovsky et al , 2009), beat previous benchmark accuracies by 3.8% (on section 23 of wsj) and 7.5% (on parsed brown).</citsent>
<aftsection>
<nextsent>since objective functions used in unsupervised grammar induction are prov ably wrong, advantages of exact inference may not apply.
</nextsent>
<nextsent>it makes sense to try the viterbi approximation ? it is also wrong, only simpler and cheaper than classic em.
</nextsent>
<nextsent>as it turns out, viterbi em is not only faster but also more accurate, consistent with hypotheses of de marcken (1995) and spitkovsky et al  (2009).
</nextsent>
<nextsent>we begin by reviewing the model, standard datasets and metrics, and our experimental results.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3091">
<title id=" W10-2902.xml">viterbi training improves unsupervised dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>their wrong objectives create cases in which both efficiency and performance improve when expensive exact learning techniques are replaced by cheap approximations.
</prevsent>
<prevsent>we propose using viterbi training (brownet al , 1993), <papid> J93-2003 </papid>instead of inside-outside reestimation (baker, 1979), to induce hierarchical syntactic structure from natural language text.</prevsent>
</prevsection>
<citsent citstr=" N09-1012 ">
our experiments with klein and mannings (2004) <papid> P04-1061 </papid>dependency model with valence (dmv), popularstate-of-the-art model (headden et al , 2009; <papid> N09-1012 </papid>cohen and smith, 2009; <papid> N09-1009 </papid>spitkovsky et al , 2009), beat previous benchmark accuracies by 3.8% (on section 23 of wsj) and 7.5% (on parsed brown).</citsent>
<aftsection>
<nextsent>since objective functions used in unsupervised grammar induction are prov ably wrong, advantages of exact inference may not apply.
</nextsent>
<nextsent>it makes sense to try the viterbi approximation ? it is also wrong, only simpler and cheaper than classic em.
</nextsent>
<nextsent>as it turns out, viterbi em is not only faster but also more accurate, consistent with hypotheses of de marcken (1995) and spitkovsky et al  (2009).
</nextsent>
<nextsent>we begin by reviewing the model, standard datasets and metrics, and our experimental results.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3092">
<title id=" W10-2902.xml">viterbi training improves unsupervised dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>their wrong objectives create cases in which both efficiency and performance improve when expensive exact learning techniques are replaced by cheap approximations.
</prevsent>
<prevsent>we propose using viterbi training (brownet al , 1993), <papid> J93-2003 </papid>instead of inside-outside reestimation (baker, 1979), to induce hierarchical syntactic structure from natural language text.</prevsent>
</prevsection>
<citsent citstr=" N09-1009 ">
our experiments with klein and mannings (2004) <papid> P04-1061 </papid>dependency model with valence (dmv), popularstate-of-the-art model (headden et al , 2009; <papid> N09-1012 </papid>cohen and smith, 2009; <papid> N09-1009 </papid>spitkovsky et al , 2009), beat previous benchmark accuracies by 3.8% (on section 23 of wsj) and 7.5% (on parsed brown).</citsent>
<aftsection>
<nextsent>since objective functions used in unsupervised grammar induction are prov ably wrong, advantages of exact inference may not apply.
</nextsent>
<nextsent>it makes sense to try the viterbi approximation ? it is also wrong, only simpler and cheaper than classic em.
</nextsent>
<nextsent>as it turns out, viterbi em is not only faster but also more accurate, consistent with hypotheses of de marcken (1995) and spitkovsky et al  (2009).
</nextsent>
<nextsent>we begin by reviewing the model, standard datasets and metrics, and our experimental results.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3095">
<title id=" W10-2902.xml">viterbi training improves unsupervised dependency parsing </title>
<section> standard datasets and evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>viterbi training (brown et al , 1993) <papid> J93-2003 </papid>re-estimates each next model as if supervised by the previous best parse trees.</prevsent>
<prevsent>and supervised learning from reference parse trees is straight-forward, sincemaximum-likelihood estimation reduces to count ing: pattach(ch, dir, ca) is the fraction of children ? those of class ca ? attached on the dir side of ahead of class ch; pstop(ch, dir, adj = t), the fraction of words of class ch with no children on the dir side; and pstop(ch, dir, adj = f), the ratio1 of the number of words of class ch having child on the dir side to their total number of such children.</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
the dmv is traditionally trained and tested on customized subsets of penn english treebanks wall street journal portion (marcus et al , 1993).<papid> J93-2004 </papid>following klein and manning (2004), <papid> P04-1061 </papid>we begin with reference constituent parses and compare against deterministically derived dependencies: after pruning out all empty sub-trees, punctuation and terminals (tagged # and $) not pronounced where they appear, we drop all sentences with more than prescribed number of tokens remaining and use automatic head-percolationrules (collins, 1999) to convert the rest, as is standard practice.</citsent>
<aftsection>
<nextsent>we experiment with wsjk (sen tences with at most tokens), for 1 ? ? 45, and section 23 of wsj?
</nextsent>
<nextsent>(all sentence lengths).
</nextsent>
<nextsent>we also evaluate on brown100, similarly derived from the parsed portion of the brown corpus (francis and kucera, 1979), as our held-out set.
</nextsent>
<nextsent>figure 1 shows these corporas sentence and token counts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3101">
<title id=" W10-2902.xml">viterbi training improves unsupervised dependency parsing </title>
<section> related work on improper objectives.  </section>
<citcontext>
<prevsection>
<prevsent>both algorithms abandon good solutions and make no guarantees with respect to extrinsic performance.
</prevsent>
<prevsent>unfortunately, these two approaches share deep flaw.
</prevsent>
</prevsection>
<citsent citstr=" P92-1017 ">
it is well-known that maximizing likelihood may, in fact, degrade accuracy (pereira and schabes,1992; <papid> P92-1017 </papid>elworthy, 1994; <papid> A94-1009 </papid>merialdo, 1994).<papid> J94-2001 </papid></citsent>
<aftsection>
<nextsent>de marcken (1995) showed that classic em suffers from fatal attraction towards deterministic grammar sand suggested viterbi training scheme as remedy.
</nextsent>
<nextsent>liang and kleins (2008) <papid> P08-1100 </papid>analysis of error sin unsupervised learning began with the inappropriateness of the likelihood objective (approximation), explored problems of data sparsity (estima tion) and focused on em-specific issues related to non-convexity (identifiability and optimization).previous literature primarily relied on experimental evidence.</nextsent>
<nextsent>de marc kens analytical result isan exception but pertains only to em-specific local attractors.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3106">
<title id=" W10-2902.xml">viterbi training improves unsupervised dependency parsing </title>
<section> related work on improper objectives.  </section>
<citcontext>
<prevsection>
<prevsent>it is well-known that maximizing likelihood may, in fact, degrade accuracy (pereira and schabes,1992; <papid> P92-1017 </papid>elworthy, 1994; <papid> A94-1009 </papid>merialdo, 1994).<papid> J94-2001 </papid></prevsent>
<prevsent>de marcken (1995) showed that classic em suffers from fatal attraction towards deterministic grammar sand suggested viterbi training scheme as rem edy.</prevsent>
</prevsection>
<citsent citstr=" P08-1100 ">
liang and kleins (2008) <papid> P08-1100 </papid>analysis of error sin unsupervised learning began with the inappropriateness of the likelihood objective (approximation), explored problems of data sparsity (estima tion) and focused on em-specific issues related to non-convexity (identifiability and optimization).previous literature primarily relied on experimental evidence.</citsent>
<aftsection>
<nextsent>de marc kens analytical result isan exception but pertains only to em-specific local attractors.
</nextsent>
<nextsent>our analysis confirms his intuition sand moreover shows that there can be global preferences for deterministic grammars ? problems that would persist with tractable optimization.
</nextsent>
<nextsent>weprove that there is fundamental disconnect between objective functions even when likelihood is reasonable metric and training data are infinite.
</nextsent>
<nextsent>6klein and manning (2004) <papid> P04-1061 </papid>originally trained the dmvon wsj10 and gillenwater et al  (2009) found it useful to discard data from wsj3, which is mostly incomplete sentences.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3108">
<title id=" W10-2902.xml">viterbi training improves unsupervised dependency parsing </title>
<section> discussion of theoretical results.  </section>
<citcontext>
<prevsection>
<prevsent>wainwright (2006) provided strong theoretical and empirical arguments for using the same approximate inference method in training as in performing predictions for learned model.he showed that if inference involves an approximation, then using the same approximate method to train the model gives even better performance guarantees than exact training methods.
</prevsent>
<prevsent>if our task were not parsing but language modeling, where the relevant score is the sum of the probabilities over individual derivations, perhaps classic em would not be doing as badly, compared to viterbi.viterbi training is not only faster and more accurate but also free of inside-outsides recur sion constraints.
</prevsent>
</prevsection>
<citsent citstr=" W03-0407 ">
it therefore invites more flexible modeling techniques, including discriminative, feature rich approaches that target conditional likelihoods, essentially via (unsupervised) self-training (clark et al , 2003; <papid> W03-0407 </papid>ng and cardie, 2003; <papid> N03-1023 </papid>mcclosky et al ., 2006<papid> P06-1043 </papid>a; mcclosky et al , 2006<papid> P06-1043 </papid>b, inter alia).</citsent>
<aftsection>
<nextsent>such learning by doing?
</nextsent>
<nextsent>approaches may be relevant to understanding human language acquisition, as children frequently find themselves forced to interpret sentence in order to interact with the world.
</nextsent>
<nextsent>since most models of human probabilistic parsing are massively pruned (juraf sky, 1996; chater et al , 1998; lewis and vasishth, 2005, inter alia), the serial nature of viterbi em ? or the very limited parallelism of k-best viterbi ? may be more appropriate in modeling this task than the fully-integrated inside-outside solution.
</nextsent>
<nextsent>without known objective, as in unsupervised learning, correct exact optimization becomes im possible.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3109">
<title id=" W10-2902.xml">viterbi training improves unsupervised dependency parsing </title>
<section> discussion of theoretical results.  </section>
<citcontext>
<prevsection>
<prevsent>wainwright (2006) provided strong theoretical and empirical arguments for using the same approximate inference method in training as in performing predictions for learned model.he showed that if inference involves an approximation, then using the same approximate method to train the model gives even better performance guarantees than exact training methods.
</prevsent>
<prevsent>if our task were not parsing but language modeling, where the relevant score is the sum of the probabilities over individual derivations, perhaps classic em would not be doing as badly, compared to viterbi.viterbi training is not only faster and more accurate but also free of inside-outsides recur sion constraints.
</prevsent>
</prevsection>
<citsent citstr=" N03-1023 ">
it therefore invites more flexible modeling techniques, including discriminative, feature rich approaches that target conditional likelihoods, essentially via (unsupervised) self-training (clark et al , 2003; <papid> W03-0407 </papid>ng and cardie, 2003; <papid> N03-1023 </papid>mcclosky et al ., 2006<papid> P06-1043 </papid>a; mcclosky et al , 2006<papid> P06-1043 </papid>b, inter alia).</citsent>
<aftsection>
<nextsent>such learning by doing?
</nextsent>
<nextsent>approaches may be relevant to understanding human language acquisition, as children frequently find themselves forced to interpret sentence in order to interact with the world.
</nextsent>
<nextsent>since most models of human probabilistic parsing are massively pruned (juraf sky, 1996; chater et al , 1998; lewis and vasishth, 2005, inter alia), the serial nature of viterbi em ? or the very limited parallelism of k-best viterbi ? may be more appropriate in modeling this task than the fully-integrated inside-outside solution.
</nextsent>
<nextsent>without known objective, as in unsupervised learning, correct exact optimization becomes im possible.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3110">
<title id=" W10-2902.xml">viterbi training improves unsupervised dependency parsing </title>
<section> discussion of theoretical results.  </section>
<citcontext>
<prevsection>
<prevsent>wainwright (2006) provided strong theoretical and empirical arguments for using the same approximate inference method in training as in performing predictions for learned model.he showed that if inference involves an approximation, then using the same approximate method to train the model gives even better performance guarantees than exact training methods.
</prevsent>
<prevsent>if our task were not parsing but language modeling, where the relevant score is the sum of the probabilities over individual derivations, perhaps classic em would not be doing as badly, compared to viterbi.viterbi training is not only faster and more accurate but also free of inside-outsides recur sion constraints.
</prevsent>
</prevsection>
<citsent citstr=" P06-1043 ">
it therefore invites more flexible modeling techniques, including discriminative, feature rich approaches that target conditional likelihoods, essentially via (unsupervised) self-training (clark et al , 2003; <papid> W03-0407 </papid>ng and cardie, 2003; <papid> N03-1023 </papid>mcclosky et al ., 2006<papid> P06-1043 </papid>a; mcclosky et al , 2006<papid> P06-1043 </papid>b, inter alia).</citsent>
<aftsection>
<nextsent>such learning by doing?
</nextsent>
<nextsent>approaches may be relevant to understanding human language acquisition, as children frequently find themselves forced to interpret sentence in order to interact with the world.
</nextsent>
<nextsent>since most models of human probabilistic parsing are massively pruned (juraf sky, 1996; chater et al , 1998; lewis and vasishth, 2005, inter alia), the serial nature of viterbi em ? or the very limited parallelism of k-best viterbi ? may be more appropriate in modeling this task than the fully-integrated inside-outside solution.
</nextsent>
<nextsent>without known objective, as in unsupervised learning, correct exact optimization becomes im possible.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3115">
<title id=" W10-3017.xml">hedge hunter a system for hedge detection and uncertainty classification </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>inorder to maximize the usefulness of extracted relations an information extraction (ie) system needs the ability to separate the factual and reliable relationships from the uncertain and unreliable relationships.
</prevsent>
<prevsent>most work on this problem has focused on the task of hedge detection where the goal isto classify span of text as hedged or as non hedged with the goal of facilitating sentence level classification of certain or uncertain.
</prevsent>
</prevsection>
<citsent citstr=" W09-1401 ">
much of the work was conducted within the framework of the bionlp 2009 shared task sub task on uncertainty detection focusing on biomedical datasets (kim etal., 2009) <papid> W09-1401 </papid>motivating further work in the biomedical nlp field (aramaki et al, 2009; <papid> W09-1324 </papid>conway et al,2009).<papid> W09-1318 </papid></citsent>
<aftsection>
<nextsent>other work has focused on creating annotated datasets from both linguistically sophisticated perspective (saur??
</nextsent>
<nextsent>and pustejovsky, 2009) or from language engineering perspective (vincze et al, 2008).
</nextsent>
<nextsent>early work by light et al (2004) framed the task as determining the degree of speculation or uncertainty at the sentence level.
</nextsent>
<nextsent>the presence of hedge cue, phrase indicating that authors cannot back up their opinions or statements with facts, is high precision feature of sentence leveluncertainty.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3116">
<title id=" W10-3017.xml">hedge hunter a system for hedge detection and uncertainty classification </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>inorder to maximize the usefulness of extracted relations an information extraction (ie) system needs the ability to separate the factual and reliable relationships from the uncertain and unreliable relationships.
</prevsent>
<prevsent>most work on this problem has focused on the task of hedge detection where the goal isto classify span of text as hedged or as non hedged with the goal of facilitating sentence level classification of certain or uncertain.
</prevsent>
</prevsection>
<citsent citstr=" W09-1324 ">
much of the work was conducted within the framework of the bionlp 2009 shared task sub task on uncertainty detection focusing on biomedical datasets (kim etal., 2009) <papid> W09-1401 </papid>motivating further work in the biomedical nlp field (aramaki et al, 2009; <papid> W09-1324 </papid>conway et al,2009).<papid> W09-1318 </papid></citsent>
<aftsection>
<nextsent>other work has focused on creating annotated datasets from both linguistically sophisticated perspective (saur??
</nextsent>
<nextsent>and pustejovsky, 2009) or from language engineering perspective (vincze et al, 2008).
</nextsent>
<nextsent>early work by light et al (2004) framed the task as determining the degree of speculation or uncertainty at the sentence level.
</nextsent>
<nextsent>the presence of hedge cue, phrase indicating that authors cannot back up their opinions or statements with facts, is high precision feature of sentence leveluncertainty.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3117">
<title id=" W10-3017.xml">hedge hunter a system for hedge detection and uncertainty classification </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>inorder to maximize the usefulness of extracted relations an information extraction (ie) system needs the ability to separate the factual and reliable relationships from the uncertain and unreliable relationships.
</prevsent>
<prevsent>most work on this problem has focused on the task of hedge detection where the goal isto classify span of text as hedged or as non hedged with the goal of facilitating sentence level classification of certain or uncertain.
</prevsent>
</prevsection>
<citsent citstr=" W09-1318 ">
much of the work was conducted within the framework of the bionlp 2009 shared task sub task on uncertainty detection focusing on biomedical datasets (kim etal., 2009) <papid> W09-1401 </papid>motivating further work in the biomedical nlp field (aramaki et al, 2009; <papid> W09-1324 </papid>conway et al,2009).<papid> W09-1318 </papid></citsent>
<aftsection>
<nextsent>other work has focused on creating annotated datasets from both linguistically sophisticated perspective (saur??
</nextsent>
<nextsent>and pustejovsky, 2009) or from language engineering perspective (vincze et al, 2008).
</nextsent>
<nextsent>early work by light et al (2004) framed the task as determining the degree of speculation or uncertainty at the sentence level.
</nextsent>
<nextsent>the presence of hedge cue, phrase indicating that authors cannot back up their opinions or statements with facts, is high precision feature of sentence leveluncertainty.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3118">
<title id=" W10-3017.xml">hedge hunter a system for hedge detection and uncertainty classification </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>early work by light et al (2004) framed the task as determining the degree of speculation or uncertainty at the sentence level.
</prevsent>
<prevsent>the presence of hedge cue, phrase indicating that authors cannot back up their opinions or statements with facts, is high precision feature of sentence leveluncertainty.
</prevsent>
</prevsection>
<citsent citstr=" P07-1125 ">
other early work focused on semi supervised learning due to lack of annotated datasets (medlock and briscoe, 2007).<papid> P07-1125 </papid></citsent>
<aftsection>
<nextsent>linguistically motivated approaches achieved robust baseline on the sentence classification task (kil icoglu and bergler, 2008) <papid> W08-0607 </papid>although their training methods are hand tuned.</nextsent>
<nextsent>morante and daelemans (2009) <papid> W09-1304 </papid>cast the problem as sequence labeling task and show that performance is highly do main dependent and requires high precision hedge detection in order to perform the complex taskof hedge scope labeling.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3119">
<title id=" W10-3017.xml">hedge hunter a system for hedge detection and uncertainty classification </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the presence of hedge cue, phrase indicating that authors cannot back up their opinions or statements with facts, is high precision feature of sentence leveluncertainty.
</prevsent>
<prevsent>other early work focused on semi supervised learning due to lack of annotated datasets (medlock and briscoe, 2007).<papid> P07-1125 </papid></prevsent>
</prevsection>
<citsent citstr=" W08-0607 ">
linguistically motivated approaches achieved robust baseline on the sentence classification task (kil icoglu and bergler, 2008) <papid> W08-0607 </papid>although their training methods are hand tuned.</citsent>
<aftsection>
<nextsent>morante and daelemans (2009) <papid> W09-1304 </papid>cast the problem as sequence labeling task and show that performance is highly do main dependent and requires high precision hedge detection in order to perform the complex taskof hedge scope labeling.</nextsent>
<nextsent>szarvas (2008) demonstrates that semi-supervised learning is even more effective with more labeled training data and sophisticated feature selection.hedgehunter is built to perform the conll 2010 sentence uncertainty classification task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3120">
<title id=" W10-3017.xml">hedge hunter a system for hedge detection and uncertainty classification </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>other early work focused on semi supervised learning due to lack of annotated datasets (medlock and briscoe, 2007).<papid> P07-1125 </papid></prevsent>
<prevsent>linguistically motivated approaches achieved robust baseline on the sentence classification task (kil icoglu and bergler, 2008) <papid> W08-0607 </papid>although their training methods are hand tuned.</prevsent>
</prevsection>
<citsent citstr=" W09-1304 ">
morante and daelemans (2009) <papid> W09-1304 </papid>cast the problem as sequence labeling task and show that performance is highly do main dependent and requires high precision hedge detection in order to perform the complex taskof hedge scope labeling.</citsent>
<aftsection>
<nextsent>szarvas (2008) demonstrates that semi-supervised learning is even more effective with more labeled training data and sophisticated feature selection.hedgehunter is built to perform the conll 2010 sentence uncertainty classification task.
</nextsent>
<nextsent>the task is supervised learning task with training data drawn from wikipedia and biomolecular articles and abstracts.
</nextsent>
<nextsent>each training sentence is la 120 beled as certain or uncertain and every hedge cue is also labeled.
</nextsent>
<nextsent>hedge hunter separates the task into two stages: hedge detection and uncertainty classification, with the goal of producing an independent high precision hedge detection system for use in other tasks such as hedge scope detection.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3125">
<title id=" W10-1001.xml">readability assessment for text simplification </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>with our readability assessment tool, the author is able to automatically check the complexi ty/readability level of the original text, as well as modified versions of such text produced as he/she applies simplification operations offered by simplifica, until the text reaches the expected level, adequate for the target reader.
</prevsent>
<prevsent>in this paper we present such readability assessment tool, developed as part of the porsimples project, and discuss its application within the authoring tool.
</prevsent>
</prevsection>
<citsent citstr=" W08-0909 ">
different from previous work, the tool does not model text difficulty according to linear grade levels (e.g., heilman et al, 2008), <papid> W08-0909 </papid>but instead maps the text into the three levels of literacy defined by inaf: rudimentary, basic or advanced.</citsent>
<aftsection>
<nextsent>moreover, it uses more comprehensive set of features, different learning techniques and targets new language and application, as we discuss in section 4.
</nextsent>
<nextsent>more specifically, we address the following research questions: 1.
</nextsent>
<nextsent>given some training material, is it possible to.
</nextsent>
<nextsent>detect the complexity level of portuguese texts, which corresponds to the different literacy levels defined by inaf?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3126">
<title id=" W10-1001.xml">readability assessment for text simplification </title>
<section> readability assessment.  </section>
<citcontext>
<prevsection>
<prevsent>simplification options available for the first sentence of the text presented in figure 1
</prevsent>
<prevsent>recent work on readability assessment for the english language focus on: (i) the feature set used to capture the various aspects of readability, to evaluate the contribution of lexical, syntactic, semantic and discursive features; (ii) the audience of the texts the readability measurement is intended to; (iii) the genre effects on the calculation of text difficult; (iv) the type of learning technique which is more appropriate: those producing nominal, ordinal or interval scales of measurement, and (v) providing an application for the automatic assessment of reading difficulty.
</prevsent>
</prevsection>
<citsent citstr=" D08-1020 ">
pitler and nenkova (2008) <papid> D08-1020 </papid>propose unified framework composed of vocabulary, syntactic, elements of lexical cohesion, entity coherence and discourse relations to measure text quality, which resembles the composition of rubrics in the area of essay scoring (burstein et al, 2003).</citsent>
<aftsection>
<nextsent>the following studies address readability assessment for specific audiences: learners of english as second language (schwarm and ostendorf, 2005; <papid> P05-1065 </papid>heilman et al, 2007), <papid> N07-1058 </papid>people with intellectual disabilities (feng et al, 2009), <papid> E09-1027 </papid>and people with cognitive impairment caused by alzheimer (roark at al, 2007).</nextsent>
<nextsent>sheehan et al (2007) focus on models for literary and expository texts, given that traditional metrics like flesch-kincaid level score tend to over predict the difficulty of literary texts and under predict the difficulty of expository texts.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3127">
<title id=" W10-1001.xml">readability assessment for text simplification </title>
<section> readability assessment.  </section>
<citcontext>
<prevsection>
<prevsent>recent work on readability assessment for the english language focus on: (i) the feature set used to capture the various aspects of readability, to evaluate the contribution of lexical, syntactic, semantic and discursive features; (ii) the audience of the texts the readability measurement is intended to; (iii) the genre effects on the calculation of text difficult; (iv) the type of learning technique which is more appropriate: those producing nominal, ordinal or interval scales of measurement, and (v) providing an application for the automatic assessment of reading difficulty.
</prevsent>
<prevsent>pitler and nenkova (2008) <papid> D08-1020 </papid>propose unified framework composed of vocabulary, syntactic, elements of lexical cohesion, entity coherence and discourse relations to measure text quality, which resembles the composition of rubrics in the area of essay scoring (burstein et al, 2003).</prevsent>
</prevsection>
<citsent citstr=" P05-1065 ">
the following studies address readability assessment for specific audiences: learners of english as second language (schwarm and ostendorf, 2005; <papid> P05-1065 </papid>heilman et al, 2007), <papid> N07-1058 </papid>people with intellectual disabilities (feng et al, 2009), <papid> E09-1027 </papid>and people with cognitive impairment caused by alzheimer (roark at al, 2007).</citsent>
<aftsection>
<nextsent>sheehan et al (2007) focus on models for literary and expository texts, given that traditional metrics like flesch-kincaid level score tend to over predict the difficulty of literary texts and under predict the difficulty of expository texts.
</nextsent>
<nextsent>heilman et al (2008) <papid> W08-0909 </papid>investigate an appropriate scale of measurement for reading difficulty ? nominal, ordinal, or interval ? by comparing the effectiveness of statistical models for each type of data.</nextsent>
<nextsent>petersen and ostendorf (2009) use classification and regression techniques to predict readability score.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3128">
<title id=" W10-1001.xml">readability assessment for text simplification </title>
<section> readability assessment.  </section>
<citcontext>
<prevsection>
<prevsent>recent work on readability assessment for the english language focus on: (i) the feature set used to capture the various aspects of readability, to evaluate the contribution of lexical, syntactic, semantic and discursive features; (ii) the audience of the texts the readability measurement is intended to; (iii) the genre effects on the calculation of text difficult; (iv) the type of learning technique which is more appropriate: those producing nominal, ordinal or interval scales of measurement, and (v) providing an application for the automatic assessment of reading difficulty.
</prevsent>
<prevsent>pitler and nenkova (2008) <papid> D08-1020 </papid>propose unified framework composed of vocabulary, syntactic, elements of lexical cohesion, entity coherence and discourse relations to measure text quality, which resembles the composition of rubrics in the area of essay scoring (burstein et al, 2003).</prevsent>
</prevsection>
<citsent citstr=" N07-1058 ">
the following studies address readability assessment for specific audiences: learners of english as second language (schwarm and ostendorf, 2005; <papid> P05-1065 </papid>heilman et al, 2007), <papid> N07-1058 </papid>people with intellectual disabilities (feng et al, 2009), <papid> E09-1027 </papid>and people with cognitive impairment caused by alzheimer (roark at al, 2007).</citsent>
<aftsection>
<nextsent>sheehan et al (2007) focus on models for literary and expository texts, given that traditional metrics like flesch-kincaid level score tend to over predict the difficulty of literary texts and under predict the difficulty of expository texts.
</nextsent>
<nextsent>heilman et al (2008) <papid> W08-0909 </papid>investigate an appropriate scale of measurement for reading difficulty ? nominal, ordinal, or interval ? by comparing the effectiveness of statistical models for each type of data.</nextsent>
<nextsent>petersen and ostendorf (2009) use classification and regression techniques to predict readability score.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3129">
<title id=" W10-1001.xml">readability assessment for text simplification </title>
<section> readability assessment.  </section>
<citcontext>
<prevsection>
<prevsent>recent work on readability assessment for the english language focus on: (i) the feature set used to capture the various aspects of readability, to evaluate the contribution of lexical, syntactic, semantic and discursive features; (ii) the audience of the texts the readability measurement is intended to; (iii) the genre effects on the calculation of text difficult; (iv) the type of learning technique which is more appropriate: those producing nominal, ordinal or interval scales of measurement, and (v) providing an application for the automatic assessment of reading difficulty.
</prevsent>
<prevsent>pitler and nenkova (2008) <papid> D08-1020 </papid>propose unified framework composed of vocabulary, syntactic, elements of lexical cohesion, entity coherence and discourse relations to measure text quality, which resembles the composition of rubrics in the area of essay scoring (burstein et al, 2003).</prevsent>
</prevsection>
<citsent citstr=" E09-1027 ">
the following studies address readability assessment for specific audiences: learners of english as second language (schwarm and ostendorf, 2005; <papid> P05-1065 </papid>heilman et al, 2007), <papid> N07-1058 </papid>people with intellectual disabilities (feng et al, 2009), <papid> E09-1027 </papid>and people with cognitive impairment caused by alzheimer (roark at al, 2007).</citsent>
<aftsection>
<nextsent>sheehan et al (2007) focus on models for literary and expository texts, given that traditional metrics like flesch-kincaid level score tend to over predict the difficulty of literary texts and under predict the difficulty of expository texts.
</nextsent>
<nextsent>heilman et al (2008) <papid> W08-0909 </papid>investigate an appropriate scale of measurement for reading difficulty ? nominal, ordinal, or interval ? by comparing the effectiveness of statistical models for each type of data.</nextsent>
<nextsent>petersen and ostendorf (2009) use classification and regression techniques to predict readability score.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3132">
<title id=" W10-2505.xml">transforming lexica as trees </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our work is motivated by the problem of merging one ormore lexica into one lexicon.
</prevsent>
<prevsent>lexica, lexicon schemas, and lexicon transformations are all seen as particular kinds of trees.
</prevsent>
</prevsection>
<citsent citstr=" W06-1001 ">
a standard for lexical resources, called lexical markup framework (lmf), has been developed under the auspices of iso (francopoulo et al, 2006).<papid> W06-1001 </papid></citsent>
<aftsection>
<nextsent>at its core is the understanding that most information represented in lexicon is hierarchical in nature, so that it can be represented as atree.
</nextsent>
<nextsent>although lmf also includes relations between nodes orthogonal to the tree structure, we will in this paper simplify the presentation by treating only purely tree-shaped lexica.
</nextsent>
<nextsent>there is high demand for tools supporting the merger of number of lexica.
</nextsent>
<nextsent>a few examples of papers that express this demand are chan kaleung and wu (1999), jing et al (2000), <papid> W00-1428 </papid>monachini et al (2004) and ruimy (2006).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3133">
<title id=" W10-2505.xml">transforming lexica as trees </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>although lmf also includes relations between nodes orthogonal to the tree structure, we will in this paper simplify the presentation by treating only purely tree-shaped lexica.
</prevsent>
<prevsent>there is high demand for tools supporting the merger of number of lexica.
</prevsent>
</prevsection>
<citsent citstr=" W00-1428 ">
a few examples of papers that express this demand are chan kaleung and wu (1999), jing et al (2000), <papid> W00-1428 </papid>monachini et al (2004) and ruimy (2006).</citsent>
<aftsection>
<nextsent>a typical scenario is the following.
</nextsent>
<nextsent>the ultimate goal of project is the creation of single lexicon forgiven language.
</nextsent>
<nextsent>in order to obtain the necessary data, several field linguists independently gather lexical resources.
</nextsent>
<nextsent>despite efforts to come to agreements before the start of the field work, there will generally be overlap in the scope of the respective resources and there are frequently inconsistencies both in the lexical information itself and in the form in which information is represented.in the latter case, the information needs to be restructured as part of the process of creating single lexicon.we have developed model of the merging process, and experiments with an implementation are underway.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3134">
<title id=" W10-0734.xml">creating a bilingual entailment corpus through translations with mechanical turk 100 for a 10day rush </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our first step in this direction takes advantage of an already available monolingual corpus, casting the problem as translation one.
</prevsent>
<prevsent>the challenge consists in taking publicly available rte dataset of english t-h pairs (i.e. the pascal-rte3 dataset1), and create its english-spanish clte equivalent by translating the hypotheses into spanish.
</prevsent>
</prevsection>
<citsent citstr=" D08-1027 ">
to this aim non-expert workers have been hired through the crowdflower2 channel to amazon mechanicalturk3 (mturk), crowdsourcing marketplace recently used with success for variety of nlp tasks (snow et al, 2008; <papid> D08-1027 </papid>callison-burch, 2009; mihalcea and strapparava, 2009; marge et al, 2010; ambati et al, 2010).</citsent>
<aftsection>
<nextsent>the following sections overview our experiments, carried out under strict time (10 days) and cost ($100) limitations.
</nextsent>
<nextsent>in particular, section 2 describes our data acquisition process; section 3 summarizes 1available at: http://www.nist.gov/tac/data/rte/index.html 2http://crowdflower.com/ 3https://www.mturk.com/mturk/ 212the successive approximations that led to the definition of our methodology, and the lessons learned ateach step; section 4 concludes the paper and provides directions for future work.
</nextsent>
<nextsent>starting from the rte3 development set (800 english t-h pairs), our corpus creation process has been organized in sentence translation-validationcycles, defined as separate jobs?
</nextsent>
<nextsent>routed to crowd fowers workforce.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3136">
<title id=" W10-1812.xml">complex predicates annotation in a corpus of portuguese </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>their objective is however not corpus annotation, but the creation of computational lexicon of mwes with both syntactic and semantic information.also the field of semantic or thematic role labeling investigates constructions of verb+noun, but it focuses on predicate-argument structures in general, while we focus on specific type of relations.
</prevsent>
<prevsent>framenet uses frame semantics theory to represent such predicate-argument structures which also includes handling complex predicates(e.g.
</prevsent>
</prevsection>
<citsent citstr=" A00-2008 ">
(johnson and fillmore, 2000)).<papid> A00-2008 </papid></citsent>
<aftsection>
<nextsent>forger man, there exists fully annotated corpus with semantic frames (erk et al, 2003).<papid> P03-1068 </papid></nextsent>
<nextsent>the basis of the framenet semantic annotation are conceptual frames expressing an event or object and the semantic arguments (frame elements) that are (oblig atory or optional) parts of the frames.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3137">
<title id=" W10-1812.xml">complex predicates annotation in a corpus of portuguese </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>framenet uses frame semantics theory to represent such predicate-argument structures which also includes handling complex predicates(e.g.
</prevsent>
<prevsent>(johnson and fillmore, 2000)).<papid> A00-2008 </papid></prevsent>
</prevsection>
<citsent citstr=" P03-1068 ">
forger man, there exists fully annotated corpus with semantic frames (erk et al, 2003).<papid> P03-1068 </papid></citsent>
<aftsection>
<nextsent>the basis of the framenet semantic annotation are conceptual frames expressing an event or object and the semantic arguments (frame elements) that are (oblig atory or optional) parts of the frames.
</nextsent>
<nextsent>they also specifically address support verbs and observe that support verbs often occur with nouns expressing an event (johansson and nugues, 2006).<papid> E06-2013 </papid></nextsent>
<nextsent>in framenet semantic annotation, support verbs are not considered as parts of frames or as part of the frame elements, they are annotated with specific support verb?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3138">
<title id=" W10-1812.xml">complex predicates annotation in a corpus of portuguese </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>forger man, there exists fully annotated corpus with semantic frames (erk et al, 2003).<papid> P03-1068 </papid></prevsent>
<prevsent>the basis of the framenet semantic annotation are conceptual frames expressing an event or object and the semantic arguments (frame elements) that are (oblig atory or optional) parts of the frames.</prevsent>
</prevsection>
<citsent citstr=" E06-2013 ">
they also specifically address support verbs and observe that support verbs often occur with nouns expressing an event (johansson and nugues, 2006).<papid> E06-2013 </papid></citsent>
<aftsection>
<nextsent>in framenet semantic annotation, support verbs are not considered as parts of frames or as part of the frame elements, they are annotated with specific support verb?
</nextsent>
<nextsent>label.
</nextsent>
<nextsent>we, on the contrary, view cp as one semantic and syntactic unit.in nombank, distinction is made between idioms (which in principle are not marked) and light verb plus noun combinations, which are to be annotated, and criteria are given to make such distinction (english (meyers, 2007), chinese (xue, 2006)).
</nextsent>
<nextsent>in (1) we show nombank annotation example of the sentence with complex predicate.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3139">
<title id=" W10-2103.xml">on the role of nlp in linguistics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the recent success of data-driven approaches in nlp has raised important questions as to what role linguistics must now seek to play in further advancing the field.
</prevsent>
<prevsent>perhaps, it is also time to pose the same question from the other direction: as to how nlp techniques can help linguists make informed decisions?
</prevsent>
</prevsection>
<citsent citstr=" J09-3007 ">
and how can the advances made in one field be applied to the other although, there has been some work on incorporating nlp techniques for linguistic field work and language documentation (bird, 2009), <papid> J09-3007 </papid>the wider use of nlp in linguistic studies is still fairly limited.</citsent>
<aftsection>
<nextsent>however, it is possible to deepen the engagement between the two fields in number of possible areas (as we shall see in the following sections), and gain new insights even during the formulation of linguistic theories and frameworks.
</nextsent>
<nextsent>typology computational techniques have been successfully used to classify languages and to generate phylo genetic trees.
</nextsent>
<nextsent>this has been tried not just with handcrafted word lists (atkinson et al, 2005; atkinson and gray, 2006; huelsenbeck et al, 2001) or syntactic data (barbacon et al, 2007) butwith lists extracted from written corpus with comparable results (rama and singh, 2009; singh and surana, 2007).<papid> W07-1306 </papid></nextsent>
<nextsent>these techniques are inspired from the work in computational phylogenetics, which was aimed at constructing evolutionary trees of figure 1: phylogenetic tree using feature n-grams biological species.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3140">
<title id=" W10-2103.xml">on the role of nlp in linguistics </title>
<section> historical linguistics and linguistic.  </section>
<citcontext>
<prevsection>
<prevsent>however, it is possible to deepen the engagement between the two fields in number of possible areas (as we shall see in the following sections), and gain new insights even during the formulation of linguistic theories and frameworks.
</prevsent>
<prevsent>typology computational techniques have been successfully used to classify languages and to generate phylo genetic trees.
</prevsent>
</prevsection>
<citsent citstr=" W07-1306 ">
this has been tried not just with handcrafted word lists (atkinson et al, 2005; atkinson and gray, 2006; huelsenbeck et al, 2001) or syntactic data (barbacon et al, 2007) butwith lists extracted from written corpus with comparable results (rama and singh, 2009; singh and surana, 2007).<papid> W07-1306 </papid></citsent>
<aftsection>
<nextsent>these techniques are inspired from the work in computational phylogenetics, which was aimed at constructing evolutionary trees of figure 1: phylogenetic tree using feature n-grams biological species.
</nextsent>
<nextsent>constructing phylogenetictree for languages usually requires the calculation of distances between pairs of languages (usu ally based on word lists).
</nextsent>
<nextsent>these distances arethen given as input to computational phylogenetic algorithm.
</nextsent>
<nextsent>their successful use for languages has opened the possibility of using computational techniques for studying historical linguistics.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3141">
<title id=" W10-2905.xml">identifying patterns for unsupervised grammar induction </title>
<section> state of the art.  </section>
<citcontext>
<prevsection>
<prevsent>alignment based learning (abl) (van zaanen and leeds, 2000) is the only em system applied directly to raw text.
</prevsent>
<prevsent>however, abl is relatively inefficient and has only been applied to small corpora.
</prevsent>
</prevsection>
<citsent citstr=" W06-2916 ">
brooks (brooks, 2006) <papid> W06-2916 </papid>reverses the notion of distributional approaches: if we can identify surrounding context?</citsent>
<aftsection>
<nextsent>by observation, we can hypothesize that word sequences occurring in that context will be constituents of the same type.
</nextsent>
<nextsent>he describes simplified model of distributional analysis (for raw test) which uses heuristics to reduce the number of candidate constituents under consideration.
</nextsent>
<nextsent>this is an interesting idea inspite that brook showed that the system was only capable of learning small subset of constituent structures in large test corpus.
</nextsent>
<nextsent>the second category is that of incremental learning systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3142">
<title id=" W10-2905.xml">identifying patterns for unsupervised grammar induction </title>
<section> state of the art.  </section>
<citcontext>
<prevsection>
<prevsent>bilingual experiments have been also conducted with the aim to exploit information from one language to disambiguate another.
</prevsent>
<prevsent>usually such asetting requires parallel corpus or another annotated data that ties the two languages.
</prevsent>
</prevsection>
<citsent citstr=" N09-1009 ">
cohen and smith (2009) <papid> N09-1009 </papid>use the english and chinese treebanks, which are not parallel corpora, totrain parsers for both languages jointly.</citsent>
<aftsection>
<nextsent>their results shown that the performance on english improved in the bilingual setting.
</nextsent>
<nextsent>another related work (snyder et al, 2009) <papid> P09-1009 </papid>uses three corpora of parallel text.</nextsent>
<nextsent>their approach is closer to theun supervised bilingual parsing model developed by kuhn (2004), <papid> P04-1060 </papid>which aims to improve monolingual performance.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3143">
<title id=" W10-2905.xml">identifying patterns for unsupervised grammar induction </title>
<section> state of the art.  </section>
<citcontext>
<prevsection>
<prevsent>cohen and smith (2009) <papid> N09-1009 </papid>use the english and chinese treebanks, which are not parallel corpora, totrain parsers for both languages jointly.</prevsent>
<prevsent>their results shown that the performance on english improved in the bilingual setting.</prevsent>
</prevsection>
<citsent citstr=" P09-1009 ">
another related work (snyder et al, 2009) <papid> P09-1009 </papid>uses three corpora of parallel text.</citsent>
<aftsection>
<nextsent>their approach is closer to theun supervised bilingual parsing model developed by kuhn (2004), <papid> P04-1060 </papid>which aims to improve monolingual performance.</nextsent>
<nextsent>the approach considered in this work follows adifferent direction, trying to identify certain patterns that can determine the structure of the parse trees.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3144">
<title id=" W10-2905.xml">identifying patterns for unsupervised grammar induction </title>
<section> state of the art.  </section>
<citcontext>
<prevsection>
<prevsent>their results shown that the performance on english improved in the bilingual setting.
</prevsent>
<prevsent>another related work (snyder et al, 2009) <papid> P09-1009 </papid>uses three corpora of parallel text.</prevsent>
</prevsection>
<citsent citstr=" P04-1060 ">
their approach is closer to theun supervised bilingual parsing model developed by kuhn (2004), <papid> P04-1060 </papid>which aims to improve monolingual performance.</citsent>
<aftsection>
<nextsent>the approach considered in this work follows adifferent direction, trying to identify certain patterns that can determine the structure of the parse trees.
</nextsent>
<nextsent>to automatically extract the set of separators andsub-separators from corpus of pos tagged sentences we start from some assumptions: ? the most frequent sequence (of any length) of pos tags in the corpus is constituent, that we call safe constituent (sc).
</nextsent>
<nextsent>it is quite sensible assumption, since we can expect that at least for the most frequent constituent the number of occurrences overwhelms the number of sequences appearing by chance.
</nextsent>
<nextsent>we also assume that the pos tag on the left,lsc, and on the right, rsc, of the safe constituent are kind of context for other sequences that play the same role.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3145">
<title id=" W10-0909.xml">learning rules from incomplete examples a pragmatic approach </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>thus, the goal of the system is to learn asufficiently large set of rules to infer all the missing information as accurately as possible.
</prevsent>
<prevsent>to effectively bootstrap the learning process, the learned rules are used on the incomplete training data to impute new facts, which are then used to induce more rules in subsequent iterations.
</prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
this approach is most similar to the coupled semi-supervised learning of(carlson et al, 2010) and general bootstrapping approaches in natural language processing (yarowsky,1995).<papid> P95-1026 </papid></citsent>
<aftsection>
<nextsent>since this is in the context of multiple predicate learning in inductive logic programming(ilp) (deraedt and lavrac, 1996), we call this approach multiple-predicate bootstrapping.one problem with multiple-predicate bootstrapping is potentially large variance.
</nextsent>
<nextsent>to mitigae this,we consider the bagging approach, where multiple rule sets are learned from bootstrap samples of the training data with an implicit mention model to score the rules.
</nextsent>
<nextsent>we then use these sets of rules as an ensemble to impute new facts, and repeat the process.
</nextsent>
<nextsent>we evaluate both of these approaches on real world data processed through synthetic observationmodels.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3147">
<title id=" W10-0910.xml">unsupervised techniques for discovering ontology elements from wikipedia article links </title>
<section> approach.  </section>
<citcontext>
<prevsection>
<prevsent>the article on michael jordan, for example, has 36 categories associated with it.
</prevsent>
<prevsent>in order to select an individual wordnet synset as label for the concepts type, we use two heuris tics: ? category label extraction.
</prevsent>
</prevsection>
<citsent citstr=" D07-1073 ">
since the first sentence in wikipedia articles usually defines the concept, we extract category label from the first sentence using patterns based on pos tags similar to kazama and torisawa (2007).<papid> D07-1073 </papid></citsent>
<aftsection>
<nextsent>assign matching wordnet synset.
</nextsent>
<nextsent>we consider all the wordnet synsets associated with the categories of the article using the category to wordnet mapping (ponzetto and navigli, 2009) and assign the wordnet synset if any of the words in the synset matches with the extracted category label.
</nextsent>
<nextsent>we repeat the process with hypernyms and hyponyms of the synset up to three levels.
</nextsent>
<nextsent>2.2 slot ranking.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3148">
<title id=" W10-0910.xml">unsupervised techniques for discovering ontology elements from wikipedia article links </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>one way to incorporate generalized slots in the hierarchy is to consider all slots for class members (without slot selection) and recursively propagate the common slots present at any level to the level above it.
</prevsent>
<prevsent>for example, if we find the slot team to be common for different types of athletes such as basketball players, soccer players etc. we can propagate it to the athlete class, which is one level higher in the hierarchy.
</prevsent>
</prevsection>
<citsent citstr=" P04-1053 ">
unsupervised relation discovery was initially introduced by hasegawa et al (2004).<papid> P04-1053 </papid></citsent>
<aftsection>
<nextsent>they developed an approach to discover relations by clustering pairs of entities based on intervening words represented as context vectors.
</nextsent>
<nextsent>shinyama and se kine (2006) <papid> N06-1039 </papid>generated basic patterns using parts of text syntactically connected to the entity and then similarity function (l=2) (l=2) (l=1) (l=1) simslot 56 0.61 13 0.55 simcom_slot 74 0.61 15 0.65 sim label 50 0.63 10 0.76 simhyb wc=wl=0.5 59 0.63 10 0.76 simhyb wc=0.2, wl=0.8 61 0.63 8 0.79 table 4: evaluation results for class hierarchy prediction using different similarity functions.</nextsent>
<nextsent>84 generated basic cluster composed of set of events having the same relation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3149">
<title id=" W10-0910.xml">unsupervised techniques for discovering ontology elements from wikipedia article links </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>unsupervised relation discovery was initially introduced by hasegawa et al (2004).<papid> P04-1053 </papid></prevsent>
<prevsent>they developed an approach to discover relations by clustering pairs of entities based on intervening words represented as context vectors.</prevsent>
</prevsection>
<citsent citstr=" N06-1039 ">
shinyama and se kine (2006) <papid> N06-1039 </papid>generated basic patterns using parts of text syntactically connected to the entity and then similarity function (l=2) (l=2) (l=1) (l=1) simslot 56 0.61 13 0.55 simcom_slot 74 0.61 15 0.65 sim label 50 0.63 10 0.76 simhyb wc=wl=0.5 59 0.63 10 0.76 simhyb wc=0.2, wl=0.8 61 0.63 8 0.79 table 4: evaluation results for class hierarchy prediction using different similarity functions.</citsent>
<aftsection>
<nextsent>84 generated basic cluster composed of set of events having the same relation.
</nextsent>
<nextsent>several approaches have used linguistic analysis to generate features for supervised or unsupervised relation extraction (nguyen et al, 2007; <papid> N07-2032 </papid>etzioni et al, 2008; yan et al, 2009).<papid> P09-1115 </papid></nextsent>
<nextsent>our approach mainly exploits the heavily linked structure of wikipedia and demonstrates that there are several relations that can be discovered with high accuracy without the need of features generated from linguistic analysis of the wikipedia article text.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3150">
<title id=" W10-0910.xml">unsupervised techniques for discovering ontology elements from wikipedia article links </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>shinyama and se kine (2006) <papid> N06-1039 </papid>generated basic patterns using parts of text syntactically connected to the entity and then similarity function (l=2) (l=2) (l=1) (l=1) simslot 56 0.61 13 0.55 simcom_slot 74 0.61 15 0.65 sim label 50 0.63 10 0.76 simhyb wc=wl=0.5 59 0.63 10 0.76 simhyb wc=0.2, wl=0.8 61 0.63 8 0.79 table 4: evaluation results for class hierarchy prediction using different similarity functions.</prevsent>
<prevsent>84 generated basic cluster composed of set of events having the same relation.</prevsent>
</prevsection>
<citsent citstr=" N07-2032 ">
several approaches have used linguistic analysis to generate features for supervised or unsupervised relation extraction (nguyen et al, 2007; <papid> N07-2032 </papid>etzioni et al, 2008; yan et al, 2009).<papid> P09-1115 </papid></citsent>
<aftsection>
<nextsent>our approach mainly exploits the heavily linked structure of wikipedia and demonstrates that there are several relations that can be discovered with high accuracy without the need of features generated from linguistic analysis of the wikipedia article text.
</nextsent>
<nextsent>suchanek et al (2008) used wikipedia categories and info boxes to extract 92 relations by applying specialized heuristics for each relation and incorporated the relations in their yago ontology, whereas our techniques do not use specialized heuristics based on the type of relation.
</nextsent>
<nextsent>kylin (weld et al, 2008) generated info boxes for articles by learning from existing info boxes, whereas we can discover new fillers for several existing slots and also discover new slots for infoboxes.
</nextsent>
<nextsent>kog (wu and weld, 2008) automatically refined the wikipedia infobox ontology and integrated wikipedias infobox-class schemata with wordnet.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3151">
<title id=" W10-0910.xml">unsupervised techniques for discovering ontology elements from wikipedia article links </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>shinyama and se kine (2006) <papid> N06-1039 </papid>generated basic patterns using parts of text syntactically connected to the entity and then similarity function (l=2) (l=2) (l=1) (l=1) simslot 56 0.61 13 0.55 simcom_slot 74 0.61 15 0.65 sim label 50 0.63 10 0.76 simhyb wc=wl=0.5 59 0.63 10 0.76 simhyb wc=0.2, wl=0.8 61 0.63 8 0.79 table 4: evaluation results for class hierarchy prediction using different similarity functions.</prevsent>
<prevsent>84 generated basic cluster composed of set of events having the same relation.</prevsent>
</prevsection>
<citsent citstr=" P09-1115 ">
several approaches have used linguistic analysis to generate features for supervised or unsupervised relation extraction (nguyen et al, 2007; <papid> N07-2032 </papid>etzioni et al, 2008; yan et al, 2009).<papid> P09-1115 </papid></citsent>
<aftsection>
<nextsent>our approach mainly exploits the heavily linked structure of wikipedia and demonstrates that there are several relations that can be discovered with high accuracy without the need of features generated from linguistic analysis of the wikipedia article text.
</nextsent>
<nextsent>suchanek et al (2008) used wikipedia categories and info boxes to extract 92 relations by applying specialized heuristics for each relation and incorporated the relations in their yago ontology, whereas our techniques do not use specialized heuristics based on the type of relation.
</nextsent>
<nextsent>kylin (weld et al, 2008) generated info boxes for articles by learning from existing info boxes, whereas we can discover new fillers for several existing slots and also discover new slots for infoboxes.
</nextsent>
<nextsent>kog (wu and weld, 2008) automatically refined the wikipedia infobox ontology and integrated wikipedias infobox-class schemata with wordnet.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3152">
<title id=" W10-3005.xml">detecting hedge cues and their scopes with average perceptron </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>on the biomedical corpus, our methods achieved f-measurewith 77.86% in detecting in-domain uncertain sentences, 77.44% in recognizing hedge cues, and 19.27% in identifying the scopes.
</prevsent>
<prevsent>detecting hedged information in biomedical literatures has received considerable interest in the biomedical natural language processing (nlp) community recently.
</prevsent>
</prevsection>
<citsent citstr=" W08-0606 ">
hedge information indicates that authors do not or cannot back up their opinions or statements with facts (szarvas et al, 2008), <papid> W08-0606 </papid>which exists in many natural language texts, suchas web pages or blogs, as well as biomedical liter atures.</citsent>
<aftsection>
<nextsent>for many nlp applications, such as question answering and information extraction, the information extracted from hedge sentences would be harmful to their final performances.
</nextsent>
<nextsent>therefore, the hedge or speculative information should be detected in advance, and dealt with different approaches or discarded directly.
</nextsent>
<nextsent>in conll-2010 shared task (farkas et al,2010), there are two different level subtasks: detecting sentences containing uncertainty and identifying the in-sentence scopes of hedge cues.
</nextsent>
<nextsent>for example, in the following sentence: these results suggest that the ire motif in the alas mrna is functional and imply that translation of the mrna is controlled by cellular iron availability during erythropoiesis.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3153">
<title id=" W10-3005.xml">detecting hedge cues and their scopes with average perceptron </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the words suggest and imply indicate that the statements are not supported with facts.
</prevsent>
<prevsent>in the first subtask, the sentence is considered as uncertainty.
</prevsent>
</prevsection>
<citsent citstr=" W02-1001 ">
in the second subtask, suggest and imply are identified as hedge cues, while the consecutive blocks suggest that the ire motif in the alas mrna is functional and imply that translation ofthe mrna is controlled by cellular iron availability during erythropoiesis are recognized as their corresponding scopes.in this paper, we proposed hedge detection method with average perceptron (collins, 2002), <papid> W02-1001 </papid>which was used in the closed challenges in conll-2010 shared task (farkas et al, 2010).our motivation is to use unified model to detect two level hedge information (word-level and sentence-level) and the model is easily expanded to joint learning of two subtasks.</citsent>
<aftsection>
<nextsent>since that the hedge score of sentence can be decomposed into scores of the words, especially the hedge words, we chosen linear classifier in our method and used average perceptron as the training algorithm.
</nextsent>
<nextsent>the rest of the paper is organized as follows.
</nextsent>
<nextsent>in section 2, brief review of related works is presented.
</nextsent>
<nextsent>then, we describe our method in section 3.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3154">
<title id=" W10-3005.xml">detecting hedge cues and their scopes with average perceptron </title>
<section> related works.  </section>
<citcontext>
<prevsection>
<prevsent>although the concept of hedge information has been introduced in linguistic community for along time, researches on automatic hedge detection emerged from machine learning or compu 32 tat ional linguistic perspective in recent years.
</prevsent>
<prevsent>in this section, we give brief review on the related works.
</prevsent>
</prevsection>
<citsent citstr=" P07-1125 ">
for speculative sentences detection, medlock and briscoe (2007) <papid> P07-1125 </papid>report their approach based on weakly supervised learning.</citsent>
<aftsection>
<nextsent>in their method, statistical model is initially derived from seed corpus, and then iteratively modified by augmenting the training dataset with unlabeled samples according the posterior probability.
</nextsent>
<nextsent>they only employ bag-of-words features.
</nextsent>
<nextsent>on the public biomedical dataset1, their experiments achieve the performance of 0.76 in bep (break even point).although they also introduced more linguistic features, such as part-of-speech (pos), lemma and bigram (medlock, 2008), there are no significant improvements.
</nextsent>
<nextsent>in ganter and strube (2009), <papid> P09-2044 </papid>the same task on wikipedia is presented.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3155">
<title id=" W10-3005.xml">detecting hedge cues and their scopes with average perceptron </title>
<section> related works.  </section>
<citcontext>
<prevsection>
<prevsent>they only employ bag-of-words features.
</prevsent>
<prevsent>on the public biomedical dataset1, their experiments achieve the performance of 0.76 in bep (break even point).although they also introduced more linguistic features, such as part-of-speech (pos), lemma and bigram (medlock, 2008), there are no significant improvements.
</prevsent>
</prevsection>
<citsent citstr=" P09-2044 ">
in ganter and strube (2009), <papid> P09-2044 </papid>the same task on wikipedia is presented.</citsent>
<aftsection>
<nextsent>in their system, score of sentence is defined as normalized tangent value of the sum of scores over all words in the sentence.
</nextsent>
<nextsent>shallow linguistic features are introduced in their experiments.morante and daelemans (2009) <papid> W09-1304 </papid>present their research on identifying hedge cues and their scopes.</nextsent>
<nextsent>their system consists of several classifiers and works in two phases, first identifying the hedge cues in sentence and secondly finding the full scope for each hedge cue.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3156">
<title id=" W10-3005.xml">detecting hedge cues and their scopes with average perceptron </title>
<section> related works.  </section>
<citcontext>
<prevsection>
<prevsent>in ganter and strube (2009), <papid> P09-2044 </papid>the same task on wikipedia is presented.</prevsent>
<prevsent>in their system, score of sentence is defined as normalized tangent value of the sum of scores over all words in the sentence.</prevsent>
</prevsection>
<citsent citstr=" W09-1304 ">
shallow linguistic features are introduced in their experiments.morante and daelemans (2009) <papid> W09-1304 </papid>present their research on identifying hedge cues and their scopes.</citsent>
<aftsection>
<nextsent>their system consists of several classifiers and works in two phases, first identifying the hedge cues in sentence and secondly finding the full scope for each hedge cue.
</nextsent>
<nextsent>in the first phase, they use igtree algorithm to train classifier with 3 categories.
</nextsent>
<nextsent>in the second phase, three different classifiers are trained to find the first token and last token of in-sentence scope and finally combined into meta classifier.
</nextsent>
<nextsent>the experiments shown that their system achieves an f1 of nearly 0.85of identifying hedge cues in the abstracts sub corpus, while nearly 0.79 of finding the scopes with predicted hedge cues.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3162">
<title id=" W10-3005.xml">detecting hedge cues and their scopes with average perceptron </title>
<section> hedge detection with average.  </section>
<citcontext>
<prevsection>
<prevsent>we consider this problem as word-cue pair classification problem, where word is any word in sentence and cue is the identified hedge cue word.
</prevsent>
<prevsent>similar to the previous phase, word-level linear classifier is trained to predict whether each 34 word-cue pair in sentence is in the scope of the hedge cue.besides base context features used in the previous phase, we introduce additional syntactic dependency features.
</prevsent>
</prevsection>
<citsent citstr=" P05-1012 ">
these features are generated by first-order projective dependency parser (mc donald et al, 2005), <papid> P05-1012 </papid>and listed in figure 3.</citsent>
<aftsection>
<nextsent>the scopes of hedge cues are always covering consecutive block of words including the hedge cue itself.
</nextsent>
<nextsent>the ideal method should recognize onlyone consecutive block for each hedge cue.
</nextsent>
<nextsent>how ever, our classifier cannot work so well.
</nextsent>
<nextsent>therefore, we apply simple strategy to process the output of the classifier.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3163">
<title id=" W10-3005.xml">detecting hedge cues and their scopes with average perceptron </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>on average, the scope of hedge cue covers 15.42 words.
</prevsent>
<prevsent>4.2 corpus preprocess.
</prevsent>
</prevsection>
<citsent citstr=" N03-1033 ">
the sentence are processed with maximum entropy part-of-speech tagger4 (toutanova et al, 2003), <papid> N03-1033 </papid>in which rule-based tokenzier is used to separate punctuations or other symbols from regular words.</citsent>
<aftsection>
<nextsent>moreover, we train first-order projective dependency parser with mstparser5 (mc donald et al, 2005) <papid> P05-1012 </papid>on the standard wsj training corpus, which is converted from constituent trees to dependency trees by several heuristic rules6.</nextsent>
<nextsent>4http://nlp.stanford.edu/software/ tagger.shtml 5http://www.seas.upenn.edu/strctlrn/ mstparser/mstparser.html 6http://w3.msi.vxu.se/nivre/research/ penn2malt.html 35 ? word-cue pair: current word and the hedge cue word pair, ? word-cue pos pair: pos pair of current word and the hedge cue word, ? path of pos: path of pos from current word to the hedge cue word along dependency tree, ? path of dependency: relation path of dependency from current word to the hedge cue word along dependency tree, ? pos of hedge cue word+direction: pos of hedge cue word with the direction to the current word.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3165">
<title id=" W10-2309.xml">cooccurrence cluster features for lexical substitutions in context </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it requires, however, semantic resource of sufficient detail and size and sense-labeled corpus to estimate priors from the sense distribution.
</prevsent>
<prevsent>here, similar approach is described that uses an unlabeled 55corpus alone for unsupervised topic signature acquisition using graph clustering, not relying on the existence of wordnet.
</prevsent>
</prevsection>
<citsent citstr=" W06-3814 ">
unlike in previous evaluations like (agirre et al, 2006), <papid> W06-3814 </papid>parameters for word sense induction are not optimized globally, but instead several parameter settings are offered as features to machine learning setup.</citsent>
<aftsection>
<nextsent>experimental results are provided for two datasets: the semeval-2007 lexical sample task (pradhan etal., 2007) <papid> W07-2016 </papid>and the turk bootstrap word sense inventory (twsi1, (biemann and nygaard, 2010) ).</nextsent>
<nextsent>2.1 graph prep eration and parameterization.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3167">
<title id=" W10-2309.xml">cooccurrence cluster features for lexical substitutions in context </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>here, similar approach is described that uses an unlabeled 55corpus alone for unsupervised topic signature acquisition using graph clustering, not relying on the existence of wordnet.
</prevsent>
<prevsent>unlike in previous evaluations like (agirre et al, 2006), <papid> W06-3814 </papid>parameters for word sense induction are not optimized globally, but instead several parameter settings are offered as features to machine learning setup.</prevsent>
</prevsection>
<citsent citstr=" W07-2016 ">
experimental results are provided for two datasets: the semeval-2007 lexical sample task (pradhan etal., 2007) <papid> W07-2016 </papid>and the turk bootstrap word sense inventory (twsi1, (biemann and nygaard, 2010) ).</citsent>
<aftsection>
<nextsent>2.1 graph prep eration and parameterization.
</nextsent>
<nextsent>similar to the approach in (widdows and dorow, 2002), <papid> C02-1114 </papid>word graph around each target word is constructed.</nextsent>
<nextsent>in this work, sentence-based co-occurrence statistics from large corpus are used as basis to to construct several word graphs for different parameterizations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3168">
<title id=" W10-2309.xml">cooccurrence cluster features for lexical substitutions in context </title>
<section> cluster co-occurrence features.  </section>
<citcontext>
<prevsection>
<prevsent>experimental results are provided for two datasets: the semeval-2007 lexical sample task (pradhan etal., 2007) <papid> W07-2016 </papid>and the turk bootstrap word sense inventory (twsi1, (biemann and nygaard, 2010) ).</prevsent>
<prevsent>2.1 graph prep eration and parameterization.</prevsent>
</prevsection>
<citsent citstr=" C02-1114 ">
similar to the approach in (widdows and dorow, 2002), <papid> C02-1114 </papid>word graph around each target word is constructed.</citsent>
<aftsection>
<nextsent>in this work, sentence-based co-occurrence statistics from large corpus are used as basis to to construct several word graphs for different parameterizations.
</nextsent>
<nextsent>significant co-occurrences between all content words (nouns, verbs, adjectives as identified by pos tagging) are computed from large corpus using the tinycc2tool.
</nextsent>
<nextsent>the full word graph for target word is defined as all words significantly co-occurring with the target as nodes, with edge weights set to the log-likelihood significance of the co-occurrence between the words corresponding to nodes.
</nextsent>
<nextsent>edges between words that co-occur only once or with significance smaller than 6.63 (1% confidence level) are omitted.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3169">
<title id=" W10-2309.xml">cooccurrence cluster features for lexical substitutions in context </title>
<section> cluster co-occurrence features.  </section>
<citcontext>
<prevsection>
<prevsent>aiming at different granularities of usage clusters, the graph is parameterized by size parameter and density parameter n: only the most significant co-occurrences of the target enter the graph as nodes, and an edge between nodes is drawn only if one of the corresponding words is contained in the most significant co-occurrences of the other.
</prevsent>
<prevsent>2.2 graph clustering parameterization.
</prevsent>
</prevsection>
<citsent citstr=" W06-3812 ">
as described in (biemann, 2006), <papid> W06-3812 </papid>the neighborhood graph is clustered with chinese whispers.</citsent>
<aftsection>
<nextsent>this efficient graph clustering algorithm finds the numbers of clusters automatically and returns partition of the nodes.
</nextsent>
<nextsent>it is initial ized by assigning different classes to all nodes in the graph.
</nextsent>
<nextsent>then, 1full dataset available for download at http://aclweb.org/aclwiki/index.phptitle=image:twsi397.zip 2http://beam.to/biem/software/tinycc2.html number of local update steps are performed, in which node inherits the predominant class in its neighborhood.
</nextsent>
<nextsent>at this, classes of adjacent nodes are weighted by edge weight and down weighted by the degree (number of adjacent nodes) of the neighboring node.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3173">
<title id=" W10-1915.xml">towards internet age pharmacovigilance extracting adverse drug reactions from user posts in health related social networks </title>
<section> text mining.  </section>
<citcontext>
<prevsection>
<prevsent>to extract the adverse drug reactions from the user comments, we implemented primarily lexical method, utilizing the lexicon discussed in section 3.2.
</prevsent>
<prevsent>5.1 methods used.
</prevsent>
</prevsection>
<citsent citstr=" P00-1036 ">
each user comment was split into sentences using the java sentence breaker, tokenized by splitting atwhitespace and punctuation, and tagged for part of-speech using the hepple tagger (hepple, 2000).<papid> P00-1036 </papid>stop-words were removed from both user comments and lexical terms5.</citsent>
<aftsection>
<nextsent>tokens were stemmed using the snowball implementation of the porter2 stemmer6.
</nextsent>
<nextsent>terms from the lexicon were found in the user comments by comparing sliding window of tokens from the comment to each token in the lexical term.
</nextsent>
<nextsent>the size of the window is configurable and set to 5 for this study since that is the number of tokens in the longest term found by the annotators.
</nextsent>
<nextsent>using sliding window allows the tokens to be indifferent orders and for there to be irrelevant tokens between the relevant ones, as in weight gain and gained lot of weight.since user comments contain many spelling errors, we used the jaro-winkler measurement of string similarity to compare the individual tokens 5http://ir.dcs.gla.ac.uk/resources/linguistic utils/stop words 6http://snowball.tartarus.org (winkler, 1999).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3174">
<title id=" W10-1823.xml">a feature type classification for therapeutic purposes a preliminary evaluation with non expert speakers </title>
<section> related works.  </section>
<citcontext>
<prevsection>
<prevsent>in the psychological tradition, collection of feature norms is typically built by asking to group of speakers to generate short phrases (i.e. fea tures) to describe given set of concepts.
</prevsent>
<prevsent>even if normative data have been collected and employed for addressing wide range of issues on the nature of the semantic memory, the only freely available resources are, to our know ledge, those by garrard et al (2001), those by mcrae et al (2005), those by vinson and vigliocco (2008), all in english, and the dutch norms available in the leuven database (de deyne et al  2008).
</prevsent>
</prevsection>
<citsent citstr=" W08-1913 ">
moving out of the psychological domain, the only collection built in the lexicographic tradition is that by kremer et al (2008), <papid> W08-1913 </papid>collected from italian and german speakers 157 2.2 related classifications.</citsent>
<aftsection>
<nextsent>the proposals that constitute our theoretical framework have been chosen for their being either implemented in an extensive semantic resource, motivated by well specified theoretical explanations (on which there is consensus) or effectively used in specific therapeutic context.
</nextsent>
<nextsent>they have originated in research fields as distant as lexicography, theoretical linguistics, ontology building, (clinical) neuro psychology and cognitive psychology.
</nextsent>
<nextsent>specifically, the works we moved from have been: ? type classification adopted for clinical purposes in the cimecs center for neurocogni tive rehabilitation (personal communication); ? the knowledge-type taxonomy proposed by wu &amp; barsalou (2009), and the modified version adopted by cree &amp; mcrae (2003); ? the brain region taxonomy proposed by cree &amp; mcrae (2003); ? the semantic (but not lexical) relations implemented in wordnet 3.0 (fellbaum, 1998) and in euro wordnet (alonge et al  1998); ? the classification of part/whole relations by winston et al (1987); ? the simple-parole-clips extended qua lia structures (ruimy et al  2002).
</nextsent>
<nextsent>the properties of our classification follow from the practical use scenario of stars.sys.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3177">
<title id=" W10-1823.xml">a feature type classification for therapeutic purposes a preliminary evaluation with non expert speakers </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>any type of ours, indeed, has parallel type or relation in at least one of the other proposals.
</prevsent>
<prevsent>such remark shows what is the third major advantage of our classification, together with its usability and its cognitive plausibility: its compatibility with wide range of well known theoretical and experimental frameworks, that allows it to serve as common ground for the interplay of theories, insights and ideas originated from the abovementioned research areas.
</prevsent>
</prevsection>
<citsent citstr=" J08-4004 ">
given the aims of our classification, and of stars.sys in general, we choose to evaluate our coding scheme by asking to group of non experts to label subset of the non-normalized kremer et al (2008) <papid> W08-1913 </papid>norms and measuring the 158 inter-coder agreement between them (artstein and poesio, 2008), <papid> J08-4004 </papid>adhering to the krippen dorffs (2004), the krippen dorffs (2008) recommendations.</citsent>
<aftsection>
<nextsent>the choice to recruit only naive subjects has the positive consequence of allowing us to draw inferences also on the usability of our proposal.
</nextsent>
<nextsent>that is, such an evaluation can be additionally seen as measure of how easily minimally trained user can understand the oppositions isolated in our classification.
</nextsent>
<nextsent>4.1 experimental setup.
</nextsent>
<nextsent>participants: 5 italian speakers with university degree were recruited for this evaluation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3181">
<title id=" W10-1723.xml">the lig machine translation system for wmt 2010 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we participated, for the first time, to the shared news translation task of the fifth workshop on machine translation (wmt 2010) for the french english language pair.
</prevsent>
<prevsent>the submission was performed using standard phrase-based translation system with appropriate setups and preprocessings in order to deal with systems unknown words.
</prevsent>
</prevsection>
<citsent citstr=" W09-0427 ">
indeed, as shown in (carpuat,2009), (<papid> W09-0427 </papid>habash, 2008) <papid> P08-2015 </papid>and (niessen, 2004), handling ou-of-vocabulary words with techniques like lemmatization, phrase table extension or morphological pre-processing is way to improve translation quality.</citsent>
<aftsection>
<nextsent>after short presentation of our baseline system setups we discuss the effect of out-of-vocabulary words in the system and introduce some ideas we chose to implement.
</nextsent>
<nextsent>in the last part, we evaluate their impact on translation quality using automatic and human evaluations.
</nextsent>
<nextsent>2.1 used resources.
</nextsent>
<nextsent>we used the provided europarl and news parallel corpora (total 1,638,440 sentences) to tra inthe translation model and the news monolingual corpora (48,653,884 sentences) to train the language model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3182">
<title id=" W10-1723.xml">the lig machine translation system for wmt 2010 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we participated, for the first time, to the shared news translation task of the fifth workshop on machine translation (wmt 2010) for the french english language pair.
</prevsent>
<prevsent>the submission was performed using standard phrase-based translation system with appropriate setups and preprocessings in order to deal with systems unknown words.
</prevsent>
</prevsection>
<citsent citstr=" P08-2015 ">
indeed, as shown in (carpuat,2009), (<papid> W09-0427 </papid>habash, 2008) <papid> P08-2015 </papid>and (niessen, 2004), handling ou-of-vocabulary words with techniques like lemmatization, phrase table extension or morphological pre-processing is way to improve translation quality.</citsent>
<aftsection>
<nextsent>after short presentation of our baseline system setups we discuss the effect of out-of-vocabulary words in the system and introduce some ideas we chose to implement.
</nextsent>
<nextsent>in the last part, we evaluate their impact on translation quality using automatic and human evaluations.
</nextsent>
<nextsent>2.1 used resources.
</nextsent>
<nextsent>we used the provided europarl and news parallel corpora (total 1,638,440 sentences) to tra inthe translation model and the news monolingual corpora (48,653,884 sentences) to train the language model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3183">
<title id=" W10-1723.xml">the lig machine translation system for wmt 2010 </title>
<section> baseline system setup.  </section>
<citcontext>
<prevsection>
<prevsent>2.3 translation modeling.
</prevsent>
<prevsent>the translation model was trained using the parallel corpus described earlier (europarl+news).
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
first, the corpus was word aligned and then, the pairs of source and corresponding target phrases were extracted from the word-aligned bilingual training corpus using the scripts provided withthe moses decoder (koehn et al, 2007).<papid> P07-2045 </papid></citsent>
<aftsection>
<nextsent>there sult is phrase-table containing all the alignedphrases.
</nextsent>
<nextsent>this phrase-table, produced by the translation modeling, is used to extract several translations models.
</nextsent>
<nextsent>in our experiment we used thirteen standard translation models: six distortion models,a lexicon word-based and phrase-based translation model for both direction, and phrase, word and distortion penalty.
</nextsent>
<nextsent>161 2.4 tuning and decoding.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3184">
<title id=" W10-1723.xml">the lig machine translation system for wmt 2010 </title>
<section> baseline system setup.  </section>
<citcontext>
<prevsection>
<prevsent>161 2.4 tuning and decoding.
</prevsent>
<prevsent>for the decoding (i.e. translation of the test set), the system uses log-linear combination ofthe previous target language model and the thirteen translation models extracted from the phrase table.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
as the system can be beforehand tuned by adjusting log-linear combination weights on de velopement corpus, we used the minimum error rate training (mert) method, by (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>3.1 discussion about out-of-vocabulary.
</nextsent>
<nextsent>words in pbmt systems phrase-based statistical machine translation (pbmt) use phrases as units in the translation process.
</nextsent>
<nextsent>a phrase is sequence of consecutive words known by the system.
</nextsent>
<nextsent>during the training, these phrases are automatic aly learned and each source phrase is mapped with its corresponding target phrase.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3185">
<title id=" W10-1723.xml">the lig machine translation system for wmt 2010 </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>in addition to the 5-gram language model, we trained and tested 3-gram and 4-gramlanguage models with two different kinds of vocabularies : - the first one (conventional, refered to as n-gram in table 3) contains an open-vocabulary extracted from the monolingual english training data, and - the second one (refered to as n-gramvocab in table 3) contains closed-vocabulary extracted from the english part of the bilingual training data.
</prevsent>
<prevsent>in both cases, language model probabilities are trained from the monolingual lm training data but, in the second case, the lexicon is restricted to the one of the phrase-table.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
in the automatic evaluation, the reported evaluation metric is the bleu score (papineni et al,2002) <papid> P02-1040 </papid>computed by mteval version 13a.</citsent>
<aftsection>
<nextsent>the results are reported in table 1.
</nextsent>
<nextsent>note that in our experiments, according to the re sampling method of (koehn, 2004), <papid> W04-3250 </papid>there are significative variations(improvement or deterioration), with 95% certainty, only if the difference between two bleu scores represent, at least, 0.33 points.</nextsent>
<nextsent>to complete this automatic evaluation, we performed human analysis of the systems outputs.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3186">
<title id=" W10-1723.xml">the lig machine translation system for wmt 2010 </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>in the automatic evaluation, the reported evaluation metric is the bleu score (papineni et al,2002) <papid> P02-1040 </papid>computed by mteval version 13a.</prevsent>
<prevsent>the results are reported in table 1.</prevsent>
</prevsection>
<citsent citstr=" W04-3250 ">
note that in our experiments, according to the re sampling method of (koehn, 2004), <papid> W04-3250 </papid>there are significative variations(improvement or deterioration), with 95% certainty, only if the difference between two bleu scores represent, at least, 0.33 points.</citsent>
<aftsection>
<nextsent>to complete this automatic evaluation, we performed human analysis of the systems outputs.
</nextsent>
<nextsent>4.1 standard systems.
</nextsent>
<nextsent>4.1.1 term expansion with dictionary regarding the results of automatic evaluation (ta ble 1, system (2)), adding the dictionary do not leads to significant improvement.
</nextsent>
<nextsent>the oovrate and system perplexity are reduced but, ignoring the tuned system which presents lower performance, the bleu score decreases significatly on the test set.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3187">
<title id=" W10-1810.xml">propbank annotation of multilingual light verb constructions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one of the aims in natural language processing, specifically the task of semantic role labeling (srl), is to correctly identify and extract the different semantic relationships between words in given text.
</prevsent>
<prevsent>in such tasks, verbs are considered important, as they are responsible for assigning and controlling the semantic roles of the arguments and adjuncts around it.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
thus, the goal of the srl task is to identify the arguments of the predicate and label them according to their semantic relationship to the predicate (gildea and jurafsky, 2002; <papid> J02-3001 </papid>pradhan et al , 2003).</citsent>
<aftsection>
<nextsent>to this end, propbank (palmer et. al., 2005) has developed semantic role labels and labeled large corpora for training and testing of supervised systems.
</nextsent>
<nextsent>propbank identifies and labels the semantic arguments of the verb on verb-by-verb basis, creating separate frame file that includes verb specific semantic roles to account for each subcategorization frame of the verb.
</nextsent>
<nextsent>it has been shown that training supervised systems with prop banks semantic roles for shallow semantic analysis yield good results (see conll 2005 and 2008).
</nextsent>
<nextsent>however, semantic role labeling tasks are often complicated by multiword expressions (mwes) such as idiomatic expressions (e.g., stop pulling my leg!?), verb particle constructions (e.g., you must get over your shyness.?), light verb constructions (e.g., take walk?, give lecture?), and other complex predicates (e.g., v+v predicates such as hindis ????
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3188">
<title id=" W10-1810.xml">propbank annotation of multilingual light verb constructions </title>
<section> standard propbank.  </section>
<citcontext>
<prevsection>
<prevsent>linguistic knowledge and native-speaker intuition.
</prevsent>
<prevsent>at 83 times, we also make use of the syntactic and semantic behavior of the verb as described by certain lexical resources.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
these resources include verbnet (kipper et. al., 2006) and framenet (baker et. al., 1998) <papid> P98-1013 </papid>for english, number of monolingual and bilingual dictionaries for arabic, and hindi wordnet and ds parses (palmer et. al., 2009) for hindi.</citsent>
<aftsection>
<nextsent>additionally, if available, we consult existing frame sets of words with similar meanings across different languages.
</nextsent>
<nextsent>the data awaiting annotation are passed onto the annotators for double-blind annotation process using the previously created framesets.
</nextsent>
<nextsent>the double annotated data is then adjudicated by third annotator, during which time the differences of the two annotations are resolved to produce the gold standard.
</nextsent>
<nextsent>two major guiding considerations during the framing and annotating process are data consistency and annotator productivity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3189">
<title id=" W10-1810.xml">propbank annotation of multilingual light verb constructions </title>
<section> distinguishing lvcs from mwes.  </section>
<citcontext>
<prevsection>
<prevsent>this can be done by focusing on the argument structures of predicating complements rather than focusing on the verbs themselves.
</prevsent>
<prevsent>grimshaw &amp; mester (1988) suggest that the formation of lvcs involves argument transfer from the predicating complement to the verb, which is semantically bleached and thematically incomplete and assigns no thematic roles itself.
</prevsent>
</prevsection>
<citsent citstr=" W04-0401 ">
similarly, stevenson et al  (2004) <papid> W04-0401 </papid>suggest that the acceptability of potential lvc depends on the semantic properties of the complement.</citsent>
<aftsection>
<nextsent>thus, atypical lvcs, such as the english construction issue complaint,?
</nextsent>
<nextsent>can potentially be detected during the annotation of even tive nouns, planned for all propbank languages.
</nextsent>
<nextsent>this process will make our treatment of lvcs more comprehensive.
</nextsent>
<nextsent>used with our language specific semantic and syntactic criteria relating to both the verb and the predicating complement, it will help us to more effectively capture as many types of lvcs as possible, including those of the v+adj and v+v varieties.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3190">
<title id=" W10-1902.xml">recognizing biomedical named entities using skip chain conditional random fields </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>to evaluate biomedical ner systems, several challenge competitions had been held, such as bionlp/nlpba in 20041, bio creative in ? corresponding author 1http://research.nii.ac.jp/collier/ workshops/jnlpba04st.htm 2004 and bio creative ii in 20062.
</prevsent>
<prevsent>the overview reports from these competitions, presenting state of-the-art of biomedical ner studies, show that linear-chain conditional random fields (crf) is one of the most commonly used models and has the most competitive results (yeh et al, 2005; smith et al, 2008).
</prevsent>
</prevsection>
<citsent citstr=" N03-1028 ">
linear-chain crf has also been successfully applied to other nlp tasks suchas pos-tagging (lafferty et al, 2001) and sentence chunking (sha and pereira, 2003).<papid> N03-1028 </papid></citsent>
<aftsection>
<nextsent>however, in most of these applications, only linear-chaincrf was fully exploited, assuming that only adjacent words are inter-dependent.
</nextsent>
<nextsent>the dependency between distant words, which occurs frequently in the biomedical literature, is yet to be captured.in the biomedical literature, the repeated appearance of same or similar words in one sentence is common type of long distance dependencies.this phenomenon is due to the complicated syntactic structures and the various biomedical termi nologies in nature.
</nextsent>
<nextsent>see the following example: both gh deficiency and impaired spinal growth may result in short stature, whereas the occurrence of early puberty in association with gh deficiency reduces the time available for gh therapy.?
</nextsent>
<nextsent>the mentions of gh are repeated three times.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3191">
<title id=" W10-1902.xml">recognizing biomedical named entities using skip chain conditional random fields </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the automated learning process can induce patterns for recognizing biomedical name sand rules for pre- and post-processing.
</prevsent>
<prevsent>generally speaking, there are two categories of machine learning based methods: one treats ner as classification task, while the other treats neras sequence labeling task.
</prevsent>
</prevsection>
<citsent citstr=" W02-0301 ">
for the first category, support vector machine (svm) was commonly adopted model (kazama et al, 2002; <papid> W02-0301 </papid>zhouet al, 2004).</citsent>
<aftsection>
<nextsent>lee et al (2004) proposed two step framework to perform biomedical ner using svm: firstly detecting the boundaries of named entities using classifiers; secondly classifying each named entity into predefined target types.
</nextsent>
<nextsent>for the second category, sentence was treated as sequence of tokens and the objective was to find the optimal label sequence for these tokens.
</nextsent>
<nextsent>the label space was often defined as {b,i,o}, where indicates the beginning token of an entity, denotes the continuing token and represents the token outside an entity.
</nextsent>
<nextsent>the sequence labeling task can be approached by hidden markov model (hmm),conditional random field (crf) , or combination of different models (zhou et al, 2005; tatar and cicekli, 2009).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3192">
<title id=" W10-1902.xml">recognizing biomedical named entities using skip chain conditional random fields </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>for example, in (kuo et al, 2007) labeling was performed in forward and backward directions on the same sentence and results were combined fromthe two directions.
</prevsent>
<prevsent>huang et al (2007) combines linear-chain crf and two svm models 11 to enhance the recall.
</prevsent>
</prevsection>
<citsent citstr=" P05-1045 ">
finkel et al (2005) <papid> P05-1045 </papid>used gibbs sampling to add non-local dependencies into linear-chain crf model for information ex traction.</citsent>
<aftsection>
<nextsent>however, the crf models used in these systems were all linear-chain crfs.
</nextsent>
<nextsent>to the best of our knowledge, no previous work has been done on using non-linear-chain crf in the biomedical ner task.
</nextsent>
<nextsent>beyond the biomedical domain, skip-chain crf has been used in several studies to model long distance dependency.
</nextsent>
<nextsent>in (galley, 2006), <papid> W06-1643 </papid>skip edges were linked between sentences with non local pragmatic dependencies to rank meetings.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3193">
<title id=" W10-1902.xml">recognizing biomedical named entities using skip chain conditional random fields </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>to the best of our knowledge, no previous work has been done on using non-linear-chain crf in the biomedical ner task.
</prevsent>
<prevsent>beyond the biomedical domain, skip-chain crf has been used in several studies to model long distance dependency.
</prevsent>
</prevsection>
<citsent citstr=" W06-1643 ">
in (galley, 2006), <papid> W06-1643 </papid>skip edges were linked between sentences with non local pragmatic dependencies to rank meetings.</citsent>
<aftsection>
<nextsent>in (ding et al, 2008), <papid> P08-1081 </papid>skip-chain crf was usedto detect the context and answers from online forums.</nextsent>
<nextsent>the most close work to ours was in (sut ton and mccallum, 2004), which used skip-chain crf to extract information from email messages announcing seminars.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3194">
<title id=" W10-1902.xml">recognizing biomedical named entities using skip chain conditional random fields </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>beyond the biomedical domain, skip-chain crf has been used in several studies to model long distance dependency.
</prevsent>
<prevsent>in (galley, 2006), <papid> W06-1643 </papid>skip edges were linked between sentences with non local pragmatic dependencies to rank meetings.</prevsent>
</prevsection>
<citsent citstr=" P08-1081 ">
in (ding et al, 2008), <papid> P08-1081 </papid>skip-chain crf was usedto detect the context and answers from online forums.</citsent>
<aftsection>
<nextsent>the most close work to ours was in (sut ton and mccallum, 2004), which used skip-chain crf to extract information from email messages announcing seminars.
</nextsent>
<nextsent>by linking the same words whose initial letter is capital, the method obtained improvements on extracting speakers?
</nextsent>
<nextsent>name.
</nextsent>
<nextsent>our work is in the spirit of this idea, but we approach it in different way.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3195">
<title id=" W10-3908.xml">utilizing citations of foreign words in corpus based dictionary generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the advantage of this pro-cedure is that the sentences retrieved this way are correct sentences as they were produced by hu-mans, whereas the sentences translated by ma-chine tend to be garbled and of lower quality.
</prevsent>
<prevsent>however, the big problem with this approach is to ensure that the retrieved sentence pairs are indeed translations of each other.
</prevsent>
</prevsection>
<citsent citstr=" J05-4003 ">
while there is no perfect solution to this problem, several stud-ies have shown that such data can be useful for building or supplementing translation models in smt (see e. g. munteanu &amp; marcu, 2005; <papid> J05-4003 </papid>wu &amp; fung, 2005).<papid> I05-1023 </papid></citsent>
<aftsection>
<nextsent>another approach for exploiting comparable corpora in dictionary generation is based on the observation that word co-occurrence patterns between languages tend to be similar (fung &amp; mckeown, 1997; <papid> W97-0119 </papid>rapp, 1995; <papid> P95-1050 </papid>chiao et al, 2004).</nextsent>
<nextsent>if, for example, two words and co-occur more often than expected by chance in corpus of language a, then their translated equi 2 there is also the approach of identifying orthograph-ically similar words (koehn &amp; knight, 2002) <papid> W02-0902 </papid>which does not even require corpus as simple word lists will suffice.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3196">
<title id=" W10-3908.xml">utilizing citations of foreign words in corpus based dictionary generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the advantage of this pro-cedure is that the sentences retrieved this way are correct sentences as they were produced by hu-mans, whereas the sentences translated by ma-chine tend to be garbled and of lower quality.
</prevsent>
<prevsent>however, the big problem with this approach is to ensure that the retrieved sentence pairs are indeed translations of each other.
</prevsent>
</prevsection>
<citsent citstr=" I05-1023 ">
while there is no perfect solution to this problem, several stud-ies have shown that such data can be useful for building or supplementing translation models in smt (see e. g. munteanu &amp; marcu, 2005; <papid> J05-4003 </papid>wu &amp; fung, 2005).<papid> I05-1023 </papid></citsent>
<aftsection>
<nextsent>another approach for exploiting comparable corpora in dictionary generation is based on the observation that word co-occurrence patterns between languages tend to be similar (fung &amp; mckeown, 1997; <papid> W97-0119 </papid>rapp, 1995; <papid> P95-1050 </papid>chiao et al, 2004).</nextsent>
<nextsent>if, for example, two words and co-occur more often than expected by chance in corpus of language a, then their translated equi 2 there is also the approach of identifying orthograph-ically similar words (koehn &amp; knight, 2002) <papid> W02-0902 </papid>which does not even require corpus as simple word lists will suffice.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3197">
<title id=" W10-3908.xml">utilizing citations of foreign words in corpus based dictionary generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, the big problem with this approach is to ensure that the retrieved sentence pairs are indeed translations of each other.
</prevsent>
<prevsent>while there is no perfect solution to this problem, several stud-ies have shown that such data can be useful for building or supplementing translation models in smt (see e. g. munteanu &amp; marcu, 2005; <papid> J05-4003 </papid>wu &amp; fung, 2005).<papid> I05-1023 </papid></prevsent>
</prevsection>
<citsent citstr=" W97-0119 ">
another approach for exploiting comparable corpora in dictionary generation is based on the observation that word co-occurrence patterns between languages tend to be similar (fung &amp; mckeown, 1997; <papid> W97-0119 </papid>rapp, 1995; <papid> P95-1050 </papid>chiao et al, 2004).</citsent>
<aftsection>
<nextsent>if, for example, two words and co-occur more often than expected by chance in corpus of language a, then their translated equi 2 there is also the approach of identifying orthograph-ically similar words (koehn &amp; knight, 2002) <papid> W02-0902 </papid>which does not even require corpus as simple word lists will suffice.</nextsent>
<nextsent>however, this approach is promising only for closely related languages but appears to have lim-ited scope otherwise.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3198">
<title id=" W10-3908.xml">utilizing citations of foreign words in corpus based dictionary generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, the big problem with this approach is to ensure that the retrieved sentence pairs are indeed translations of each other.
</prevsent>
<prevsent>while there is no perfect solution to this problem, several stud-ies have shown that such data can be useful for building or supplementing translation models in smt (see e. g. munteanu &amp; marcu, 2005; <papid> J05-4003 </papid>wu &amp; fung, 2005).<papid> I05-1023 </papid></prevsent>
</prevsection>
<citsent citstr=" P95-1050 ">
another approach for exploiting comparable corpora in dictionary generation is based on the observation that word co-occurrence patterns between languages tend to be similar (fung &amp; mckeown, 1997; <papid> W97-0119 </papid>rapp, 1995; <papid> P95-1050 </papid>chiao et al, 2004).</citsent>
<aftsection>
<nextsent>if, for example, two words and co-occur more often than expected by chance in corpus of language a, then their translated equi 2 there is also the approach of identifying orthograph-ically similar words (koehn &amp; knight, 2002) <papid> W02-0902 </papid>which does not even require corpus as simple word lists will suffice.</nextsent>
<nextsent>however, this approach is promising only for closely related languages but appears to have lim-ited scope otherwise.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3199">
<title id=" W10-3908.xml">utilizing citations of foreign words in corpus based dictionary generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>while there is no perfect solution to this problem, several stud-ies have shown that such data can be useful for building or supplementing translation models in smt (see e. g. munteanu &amp; marcu, 2005; <papid> J05-4003 </papid>wu &amp; fung, 2005).<papid> I05-1023 </papid></prevsent>
<prevsent>another approach for exploiting comparable corpora in dictionary generation is based on the observation that word co-occurrence patterns between languages tend to be similar (fung &amp; mckeown, 1997; <papid> W97-0119 </papid>rapp, 1995; <papid> P95-1050 </papid>chiao et al, 2004).</prevsent>
</prevsection>
<citsent citstr=" W02-0902 ">
if, for example, two words and co-occur more often than expected by chance in corpus of language a, then their translated equi 2 there is also the approach of identifying orthograph-ically similar words (koehn &amp; knight, 2002) <papid> W02-0902 </papid>which does not even require corpus as simple word lists will suffice.</citsent>
<aftsection>
<nextsent>however, this approach is promising only for closely related languages but appears to have lim-ited scope otherwise.
</nextsent>
<nextsent>for this reason we will not fur-ther discuss it here.
</nextsent>
<nextsent>valents should also co-occur more frequently than expected in corpus of language b. great number of variants of this approach has been proposed, e.g. emphasizing aspects of corpus selection or expanding it to collocations or short phrases (babych et al, 2007).<papid> P07-1018 </papid></nextsent>
<nextsent>what is common to these studies is that they consider the source and the target language as two distinct semantic spaces, without any links at the beginning.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3200">
<title id=" W10-3908.xml">utilizing citations of foreign words in corpus based dictionary generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, this approach is promising only for closely related languages but appears to have lim-ited scope otherwise.
</prevsent>
<prevsent>for this reason we will not fur-ther discuss it here.
</prevsent>
</prevsection>
<citsent citstr=" P07-1018 ">
valents should also co-occur more frequently than expected in corpus of language b. great number of variants of this approach has been proposed, e.g. emphasizing aspects of corpus selection or expanding it to collocations or short phrases (babych et al, 2007).<papid> P07-1018 </papid></citsent>
<aftsection>
<nextsent>what is common to these studies is that they consider the source and the target language as two distinct semantic spaces, without any links at the beginning.
</nextsent>
<nextsent>therefore, in order to connect the two, base dictionary is required, and the pur-pose of the system is to expand this base diction-ary.
</nextsent>
<nextsent>building dictionary from scratch is not possible this way or at least computationally un-feasible (see rapp, 1995).<papid> P95-1050 </papid></nextsent>
<nextsent>whether the assumption of two completely distinct semantic spaces is realistic remains an open issue.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3202">
<title id=" W10-3908.xml">utilizing citations of foreign words in corpus based dictionary generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the reason is probably the following: many words of the basic dictionary assumed above correspond to items of the physical world.
</prevsent>
<prevsent>these items generally have names in natural languages which can serve as mediators.
</prevsent>
</prevsection>
<citsent citstr=" P99-1067 ">
that the extrapolation to more ab-stract notions is possible has been claimed by rapp (1999).<papid> P99-1067 </papid></citsent>
<aftsection>
<nextsent>still, although persons proceeding this way can easily understand and, after some years, even think in each of the two languages, experience shows that they tend to have some difficulties when making translations, especially literal translations.
</nextsent>
<nextsent>so, although the above scenario is possible, we do not think that it is typical one for our modern times.
</nextsent>
<nextsent>there are certainly good reasons why there are so many language courses, and why there is such an abundance of dictionaries.
</nextsent>
<nextsent>it is matter of commonsense that the person try-ing to acquire new language will look at mul-tilingual dictionary.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3203">
<title id=" W10-3908.xml">utilizing citations of foreign words in corpus based dictionary generation </title>
<section> approach and language resources.  </section>
<citcontext>
<prevsection>
<prevsent>this is something we leave for future work.
</prevsent>
<prevsent>52order to count the co-occurrences between pairs of words, text window comprising the ten words preceding and following given foreign word is considered.
</prevsent>
</prevsection>
<citsent citstr=" J93-1003 ">
on the resulting co-occur-rence counts standard association metric like the log-likelihood ratio (dunning, 1993) <papid> J93-1003 </papid>is ap-plied.</citsent>
<aftsection>
<nextsent>note that the abovementioned window size of 10 words from the given word relates to the preprocessed corpus from which function words have already been removed.
</nextsent>
<nextsent>since in english roughly every second word tends to be function word, the effective window size is about 20 words.
</nextsent>
<nextsent>this window size is somewhat larger than what we typically find in other studies.
</nextsent>
<nextsent>however, the reason for this is quite obvious: as citations of foreign words are rare, we have severe prob-lem of data sparseness, and by looking at rela-tively large window we try to somewhat com-pensate for this.4 despite its simplicity, this procedure of com-puting associations to foreign words already works well for identifying word translations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3208">
<title id=" W10-3601.xml">boosting ngram coverage for unsegmented languages using multiple text segmentation approach </title>
<section> multiple text segmentation.  </section>
<citcontext>
<prevsection>
<prevsent>in our previous paper (seng et al, 2009) we have indicated the problems of existing text segmentation approaches and introduced weighted finite state transducer (wfst) based multiple text segmentation algorithm.
</prevsent>
<prevsent>our approach is implemented using the at &amp; fsm toolkit (mohri et al, 1998).
</prevsent>
</prevsection>
<citsent citstr=" P03-1051 ">
the algorithm is inspired with the work on the segmentation of arabic words (lee et al, 2003).<papid> P03-1051 </papid></citsent>
<aftsection>
<nextsent>the multiple segmentation of sequence of characters is made using the composition of three controllers.
</nextsent>
<nextsent>given finite list of words we can build finite state transducer (or word trans ducer) that, once composed with an acceptor of the input string that represent single character with each arc, generates lattice of the words that represent all of the possible segmen tations.
</nextsent>
<nextsent>to handle out-of-vocabulary entries, we make model of any string of characters by star closure operation over all the possible characters.
</nextsent>
<nextsent>thus, the unknown word wfst can parse any sequence of characters and generate unique unk word symbol.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3209">
<title id=" W10-3710.xml">identification of reduplication in bengali corpus and their semantic analysis a rule based approach </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>experimental results are presented in section 6 and conclusions are drawn in section 7.
</prevsent>
<prevsent>the works on mwe identification and extraction have been continuing in english (fillmore, 2003; sag et. al, 2002).
</prevsent>
</prevsection>
<citsent citstr=" W09-2903 ">
after tokenization, multiword expressions are important in understanding the meaning in applications like machine translation, information retrieval system etc. some of the mwe extraction tasks in english can be seen in (diab and bhutada, 2009; <papid> W09-2903 </papid>enivre and nilson, 2004).</citsent>
<aftsection>
<nextsent>among indian languages, hindi compound noun mwe extraction has been studied in (kunchukuttan and damani, 2008).
</nextsent>
<nextsent>mani puri re duplicated mwe identification is discussed in (nongmeikapam and bandyopadhyay, 2010).
</nextsent>
<nextsent>there are no published works on re duplicated mwe identification in bengali.
</nextsent>
<nextsent>identification of mwes is done during the tokenization phase and is absolutely necessary 73 during pos tagging as is outlined in (thoudam and bandyopadhyay, 2008).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3210">
<title id=" W10-3216.xml">a preliminary work on hindi causatives </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>in the classification we show how different types of hindi verbs have different types of causative forms.
</prevsent>
<prevsent>it will be linguistic resource for hindi causative verbs which can be used in various nlp applications.
</prevsent>
</prevsection>
<citsent citstr=" L08-1079 ">
this resource enriches the already available linguistic resource on hindi verb frames (begum et al, 2008<papid> L08-1079 </papid>b).</citsent>
<aftsection>
<nextsent>this resource will be helpful in getting proper insight into hindi verbs.
</nextsent>
<nextsent>in this paper, we present the morphology, semantics and syntax of the causative verbs.
</nextsent>
<nextsent>the morphology is captured by the word generation process; semantics is captured by the linguistic model followed for classifying the verbs and the syntax has been captured by the verb frames using relations given by panini.
</nextsent>
<nextsent>verbs play major role in expressing the meaning of sentence and its syntactic behavior.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3230">
<title id=" W10-3216.xml">a preliminary work on hindi causatives </title>
<section> conclusion and future work.  </section>
<citcontext>
<prevsection>
<prevsent>we have also given the verb frames of the causative verbs.
</prevsent>
<prevsent>these insights have been incorporated in the hindi dependency treebank (bhatt et al, 2009).
</prevsent>
</prevsection>
<citsent citstr=" W09-3812 ">
we also plan to use the verb frames in hindi dependency parser (bharati et al, 2009) <papid> W09-3812 </papid>to im prove its performance.</citsent>
<aftsection>
<nextsent>127
</nextsent>



</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3231">
<title id=" W10-3809.xml">a discriminative approach for dependency based statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>and, discriminative training allows us to use rich feature sets, including linguistic features that are useful in the machine translation task.
</prevsent>
<prevsent>we present results of the experimental implementation of the system in this paper.
</prevsent>
</prevsection>
<citsent citstr=" J97-3002 ">
syntax based approaches for machine translation(mt) have gained popularity in recent times because of their ability to handle long distance reorderings (wu, 1997; <papid> J97-3002 </papid>yamada and knight, 2002; <papid> P02-1039 </papid>quirk et al, 2005; <papid> P05-1034 </papid>chiang, 2005), <papid> P05-1033 </papid>especially for divergent language pairs such as english-hindi (or english-urdu).</citsent>
<aftsection>
<nextsent>languages such as hindi are also known for their rich morphology and long distance agreement of features of syntactically related units.
</nextsent>
<nextsent>the morphological richness can be handled by employing techniques that factor the lexical items into morphological factors.
</nextsent>
<nextsent>this strategy is also useful in the context of english hindi mt (bharati et al, 1997; bharati et al, 1this work was done at ltrc, iiit-hyderabad, when he was masters student, till july 2008 2002; ananthakrishnan et al, 2008; ramanathan et al, 2009) <papid> P09-1090 </papid>where there is very limited parallel corpora available, and breaking words into smaller units helps in reducing sparsity.</nextsent>
<nextsent>in order to handle phenomenon such as long-distance word agreement to achieve accurate generation of target language words, the inter-dependence between the factors of syntactically related words need to be modelled effectively.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3232">
<title id=" W10-3809.xml">a discriminative approach for dependency based statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>and, discriminative training allows us to use rich feature sets, including linguistic features that are useful in the machine translation task.
</prevsent>
<prevsent>we present results of the experimental implementation of the system in this paper.
</prevsent>
</prevsection>
<citsent citstr=" P02-1039 ">
syntax based approaches for machine translation(mt) have gained popularity in recent times because of their ability to handle long distance reorderings (wu, 1997; <papid> J97-3002 </papid>yamada and knight, 2002; <papid> P02-1039 </papid>quirk et al, 2005; <papid> P05-1034 </papid>chiang, 2005), <papid> P05-1033 </papid>especially for divergent language pairs such as english-hindi (or english-urdu).</citsent>
<aftsection>
<nextsent>languages such as hindi are also known for their rich morphology and long distance agreement of features of syntactically related units.
</nextsent>
<nextsent>the morphological richness can be handled by employing techniques that factor the lexical items into morphological factors.
</nextsent>
<nextsent>this strategy is also useful in the context of english hindi mt (bharati et al, 1997; bharati et al, 1this work was done at ltrc, iiit-hyderabad, when he was masters student, till july 2008 2002; ananthakrishnan et al, 2008; ramanathan et al, 2009) <papid> P09-1090 </papid>where there is very limited parallel corpora available, and breaking words into smaller units helps in reducing sparsity.</nextsent>
<nextsent>in order to handle phenomenon such as long-distance word agreement to achieve accurate generation of target language words, the inter-dependence between the factors of syntactically related words need to be modelled effectively.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3234">
<title id=" W10-3809.xml">a discriminative approach for dependency based statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>and, discriminative training allows us to use rich feature sets, including linguistic features that are useful in the machine translation task.
</prevsent>
<prevsent>we present results of the experimental implementation of the system in this paper.
</prevsent>
</prevsection>
<citsent citstr=" P05-1034 ">
syntax based approaches for machine translation(mt) have gained popularity in recent times because of their ability to handle long distance reorderings (wu, 1997; <papid> J97-3002 </papid>yamada and knight, 2002; <papid> P02-1039 </papid>quirk et al, 2005; <papid> P05-1034 </papid>chiang, 2005), <papid> P05-1033 </papid>especially for divergent language pairs such as english-hindi (or english-urdu).</citsent>
<aftsection>
<nextsent>languages such as hindi are also known for their rich morphology and long distance agreement of features of syntactically related units.
</nextsent>
<nextsent>the morphological richness can be handled by employing techniques that factor the lexical items into morphological factors.
</nextsent>
<nextsent>this strategy is also useful in the context of english hindi mt (bharati et al, 1997; bharati et al, 1this work was done at ltrc, iiit-hyderabad, when he was masters student, till july 2008 2002; ananthakrishnan et al, 2008; ramanathan et al, 2009) <papid> P09-1090 </papid>where there is very limited parallel corpora available, and breaking words into smaller units helps in reducing sparsity.</nextsent>
<nextsent>in order to handle phenomenon such as long-distance word agreement to achieve accurate generation of target language words, the inter-dependence between the factors of syntactically related words need to be modelled effectively.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3236">
<title id=" W10-3809.xml">a discriminative approach for dependency based statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>and, discriminative training allows us to use rich feature sets, including linguistic features that are useful in the machine translation task.
</prevsent>
<prevsent>we present results of the experimental implementation of the system in this paper.
</prevsent>
</prevsection>
<citsent citstr=" P05-1033 ">
syntax based approaches for machine translation(mt) have gained popularity in recent times because of their ability to handle long distance reorderings (wu, 1997; <papid> J97-3002 </papid>yamada and knight, 2002; <papid> P02-1039 </papid>quirk et al, 2005; <papid> P05-1034 </papid>chiang, 2005), <papid> P05-1033 </papid>especially for divergent language pairs such as english-hindi (or english-urdu).</citsent>
<aftsection>
<nextsent>languages such as hindi are also known for their rich morphology and long distance agreement of features of syntactically related units.
</nextsent>
<nextsent>the morphological richness can be handled by employing techniques that factor the lexical items into morphological factors.
</nextsent>
<nextsent>this strategy is also useful in the context of english hindi mt (bharati et al, 1997; bharati et al, 1this work was done at ltrc, iiit-hyderabad, when he was masters student, till july 2008 2002; ananthakrishnan et al, 2008; ramanathan et al, 2009) <papid> P09-1090 </papid>where there is very limited parallel corpora available, and breaking words into smaller units helps in reducing sparsity.</nextsent>
<nextsent>in order to handle phenomenon such as long-distance word agreement to achieve accurate generation of target language words, the inter-dependence between the factors of syntactically related words need to be modelled effectively.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3237">
<title id=" W10-3809.xml">a discriminative approach for dependency based statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>languages such as hindi are also known for their rich morphology and long distance agreement of features of syntactically related units.
</prevsent>
<prevsent>the morphological richness can be handled by employing techniques that factor the lexical items into morphological factors.
</prevsent>
</prevsection>
<citsent citstr=" P09-1090 ">
this strategy is also useful in the context of english hindi mt (bharati et al, 1997; bharati et al, 1this work was done at ltrc, iiit-hyderabad, when he was masters student, till july 2008 2002; ananthakrishnan et al, 2008; ramanathan et al, 2009) <papid> P09-1090 </papid>where there is very limited parallel corpora available, and breaking words into smaller units helps in reducing sparsity.</citsent>
<aftsection>
<nextsent>in order to handle phenomenon such as long-distance word agreement to achieve accurate generation of target language words, the inter-dependence between the factors of syntactically related words need to be modelled effectively.
</nextsent>
<nextsent>some of the limitations with the syntax based approaches such as (yamada and knight, 2002; <papid> P02-1039 </papid>quirk et al, 2005; <papid> P05-1034 </papid>chiang, 2005) <papid> P05-1033 </papid>are, (1) they do not offer flexibility for adding linguistically motivated features, and (2) it is not possible touse morphological factors in the syntax based approaches.</nextsent>
<nextsent>in recent work (shen et al, 2009), <papid> D09-1008 </papid>linguistic and contextual information was effectively used in the framework of hierarchical machine translation system.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3243">
<title id=" W10-3809.xml">a discriminative approach for dependency based statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in order to handle phenomenon such as long-distance word agreement to achieve accurate generation of target language words, the inter-dependence between the factors of syntactically related words need to be modelled effectively.
</prevsent>
<prevsent>some of the limitations with the syntax based approaches such as (yamada and knight, 2002; <papid> P02-1039 </papid>quirk et al, 2005; <papid> P05-1034 </papid>chiang, 2005) <papid> P05-1033 </papid>are, (1) they do not offer flexibility for adding linguistically motivated features, and (2) it is not possible touse morphological factors in the syntax based approaches.</prevsent>
</prevsection>
<citsent citstr=" D09-1008 ">
in recent work (shen et al, 2009), <papid> D09-1008 </papid>linguistic and contextual information was effectively used in the framework of hierarchical machine translation system.</citsent>
<aftsection>
<nextsent>in their work, four linguistic and contextual features are used for accurate selection of translation rules.
</nextsent>
<nextsent>in our approach in contrast, linguistically motivated features can be defined that directly effect the prediction of various elements in the target during the translationprocess.
</nextsent>
<nextsent>this features use syntactic labels and collocation statistics in order to allow effective training of the model.
</nextsent>
<nextsent>some of the other approaches related to our model are the direct translation model 2 (dtm2)(ittycheriah and roukos, 2007), <papid> N07-1008 </papid>end-to-end discriminative approach to mt (liang et al, 2006) <papid> P06-1096 </papid>and factored translation models (koehn and hoang, 2007).<papid> D07-1091 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3244">
<title id=" W10-3809.xml">a discriminative approach for dependency based statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in our approach in contrast, linguistically motivated features can be defined that directly effect the prediction of various elements in the target during the translationprocess.
</prevsent>
<prevsent>this features use syntactic labels and collocation statistics in order to allow effective training of the model.
</prevsent>
</prevsection>
<citsent citstr=" N07-1008 ">
some of the other approaches related to our model are the direct translation model 2 (dtm2)(ittycheriah and roukos, 2007), <papid> N07-1008 </papid>end-to-end discriminative approach to mt (liang et al, 2006) <papid> P06-1096 </papid>and factored translation models (koehn and hoang, 2007).<papid> D07-1091 </papid></citsent>
<aftsection>
<nextsent>in dtm2, discriminative trans 66 lation model is defined in the setting of phrase based translation system.
</nextsent>
<nextsent>in their approach, the features are optimized globally.
</nextsent>
<nextsent>in contrast to their approach, we define discriminative model for translation in the setting of syntax based machine translation system.
</nextsent>
<nextsent>this allows us to use both the power of syntax based approach, as well as, the power of large feature space duringtranslation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3245">
<title id=" W10-3809.xml">a discriminative approach for dependency based statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in our approach in contrast, linguistically motivated features can be defined that directly effect the prediction of various elements in the target during the translationprocess.
</prevsent>
<prevsent>this features use syntactic labels and collocation statistics in order to allow effective training of the model.
</prevsent>
</prevsection>
<citsent citstr=" P06-1096 ">
some of the other approaches related to our model are the direct translation model 2 (dtm2)(ittycheriah and roukos, 2007), <papid> N07-1008 </papid>end-to-end discriminative approach to mt (liang et al, 2006) <papid> P06-1096 </papid>and factored translation models (koehn and hoang, 2007).<papid> D07-1091 </papid></citsent>
<aftsection>
<nextsent>in dtm2, discriminative trans 66 lation model is defined in the setting of phrase based translation system.
</nextsent>
<nextsent>in their approach, the features are optimized globally.
</nextsent>
<nextsent>in contrast to their approach, we define discriminative model for translation in the setting of syntax based machine translation system.
</nextsent>
<nextsent>this allows us to use both the power of syntax based approach, as well as, the power of large feature space duringtranslation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3246">
<title id=" W10-3809.xml">a discriminative approach for dependency based statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in our approach in contrast, linguistically motivated features can be defined that directly effect the prediction of various elements in the target during the translationprocess.
</prevsent>
<prevsent>this features use syntactic labels and collocation statistics in order to allow effective training of the model.
</prevsent>
</prevsection>
<citsent citstr=" D07-1091 ">
some of the other approaches related to our model are the direct translation model 2 (dtm2)(ittycheriah and roukos, 2007), <papid> N07-1008 </papid>end-to-end discriminative approach to mt (liang et al, 2006) <papid> P06-1096 </papid>and factored translation models (koehn and hoang, 2007).<papid> D07-1091 </papid></citsent>
<aftsection>
<nextsent>in dtm2, discriminative trans 66 lation model is defined in the setting of phrase based translation system.
</nextsent>
<nextsent>in their approach, the features are optimized globally.
</nextsent>
<nextsent>in contrast to their approach, we define discriminative model for translation in the setting of syntax based machine translation system.
</nextsent>
<nextsent>this allows us to use both the power of syntax based approach, as well as, the power of large feature space duringtranslation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3247">
<title id=" W10-3809.xml">a discriminative approach for dependency based statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the weights are locally updated at every source node during the bottom-up traversal of the source structure.
</prevsent>
<prevsent>for training the translation model, automatically obtained word-aligned parallel corpus is used.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
we used giza++ (och and ney, 2003) <papid> J03-1002 </papid>along with the growing heuristics to word-align the training cor pus.the basic factors of the word used in our experiments are root, part-of-speech, gender, number and person.</citsent>
<aftsection>
<nextsent>in hindi, common nouns and verbs have gender information whereas, english doesnt contain that information.
</nextsent>
<nextsent>apart from the basic factors, we also consider the role information provided by labelled dependency parsers.
</nextsent>
<nextsent>for computing the dependency tree on the source side, we used stanford parser (klein and manning, 2003) <papid> P03-1054 </papid>in the experiments presented in this chapter3.</nextsent>
<nextsent>3stanford parser gives both the phrase-structure tree as well as dependency relations for sentence.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3249">
<title id=" W10-3809.xml">a discriminative approach for dependency based statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in hindi, common nouns and verbs have gender information whereas, english doesnt contain that information.
</prevsent>
<prevsent>apart from the basic factors, we also consider the role information provided by labelled dependency parsers.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
for computing the dependency tree on the source side, we used stanford parser (klein and manning, 2003) <papid> P03-1054 </papid>in the experiments presented in this chapter3.</citsent>
<aftsection>
<nextsent>3stanford parser gives both the phrase-structure tree as well as dependency relations for sentence.
</nextsent>
<nextsent>67 root=mila, tense=past gnp=m3sg root=se gnp=x3sgroot=raamgnp=m1sg root=shyaam gnp=m1sg root=pay, tense=past gnp=x3sg, role=x paid/vbd root=ram, gnp=x1sg ram/nnp role=subj visit/nn root=visit, gnp=x3sg role=obj role=vmodroot=to, gnp=x3sg to/to root=shyam, gnp=x1sg role=pmod shyam/nnp root=a, gnp=x3sg role=nmod a/dt figure 1: transformation from source structure to target language the function words such as prepositions and auxiliary verbs largely express the grammaticalroles/functions of the content words in the sentence.
</nextsent>
<nextsent>in fact, in many agglutinative languages,these words are commonly attached to the content word to form one word form.
</nextsent>
<nextsent>in this paper, we also conduct experiments where we beginby grouping the function words with their corresponding function words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3250">
<title id=" W10-3809.xml">a discriminative approach for dependency based statistical machine translation </title>
<section> features.  </section>
<citcontext>
<prevsection>
<prevsent>does not match the syntactic structure of the source tree, the simpler feature functions are used to qualify various reorderings.
</prevsent>
<prevsent>instead of using pos tags, feature functions can be defined that use syntactic roles.
</prevsent>
</prevsection>
<citsent citstr=" N09-3004 ">
apart from the above feature functions, we canalso have features that compute the score of particular order of children using syntactic language models (gali and venkatapathy, 2009; <papid> N09-3004 </papid>guo et al, 2008).<papid> C08-1038 </papid></citsent>
<aftsection>
<nextsent>different features can be defined that use different levels of information pertaining to the atomic treelet and its children.
</nextsent>
<nextsent>3.3 contextual features.
</nextsent>
<nextsent>contextual features model the inter-dependence of factors of nodes connected by dependency arcs.
</nextsent>
<nextsent>these features are used to enable access to global information for prediction of target nodes (words and its factors).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3251">
<title id=" W10-3809.xml">a discriminative approach for dependency based statistical machine translation </title>
<section> features.  </section>
<citcontext>
<prevsection>
<prevsent>does not match the syntactic structure of the source tree, the simpler feature functions are used to qualify various reorderings.
</prevsent>
<prevsent>instead of using pos tags, feature functions can be defined that use syntactic roles.
</prevsent>
</prevsection>
<citsent citstr=" C08-1038 ">
apart from the above feature functions, we canalso have features that compute the score of particular order of children using syntactic language models (gali and venkatapathy, 2009; <papid> N09-3004 </papid>guo et al, 2008).<papid> C08-1038 </papid></citsent>
<aftsection>
<nextsent>different features can be defined that use different levels of information pertaining to the atomic treelet and its children.
</nextsent>
<nextsent>3.3 contextual features.
</nextsent>
<nextsent>contextual features model the inter-dependence of factors of nodes connected by dependency arcs.
</nextsent>
<nextsent>these features are used to enable access to global information for prediction of target nodes (words and its factors).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3252">
<title id=" W10-3809.xml">a discriminative approach for dependency based statistical machine translation </title>
<section> training algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>|s) (3)
</prevsent>
<prevsent>the goal of the training algorithm is to learn the feature weights from the word aligned corpus.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
forword-alignment, we used the ibm model 5 implemented in giza++ along with the growing heuristics (koehn et al, 2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>the gold atomic tree lets in the source and their transformation is obtained by mapping the source node to the target using the word-alignment information.
</nextsent>
<nextsent>this information is stored in the form of transformation tables that is used for the prediction of target atomic tree lets, prepositions and other factors.
</nextsent>
<nextsent>the transformation tables are pruned in order to limit the search and eliminate redundant information.
</nextsent>
<nextsent>for each source element, only the top few entries are retained in the table.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3253">
<title id=" W10-3809.xml">a discriminative approach for dependency based statistical machine translation </title>
<section> training algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>for each source element, only the top few entries are retained in the table.
</prevsent>
<prevsent>this limit ranges from 3 to 20.
</prevsent>
</prevsection>
<citsent citstr=" E06-1011 ">
we used an online-large margin algorithm, mira (mcdonald and pereira, 2006; <papid> E06-1011 </papid>crammer et al, 2005), for updating the weights.</citsent>
<aftsection>
<nextsent>during parameter optimization, it is sometimes impossible to achieve the gold transformation for node because the pruned transformation tables may not lead to the target gold prediction for the sourcenode.
</nextsent>
<nextsent>in such cases where the gold transformation is unreachable, the weights are not update dat all for the source node as it might cause erroneous weight updates.
</nextsent>
<nextsent>we conducted our experiments by considering both the cases, (1) identifying source nodes with unreachable transformations, and (2) updating weights for all the source nodes (till maximum iteration limit).
</nextsent>
<nextsent>the number of iterations on the entire corpus can also be fixed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3256">
<title id=" W10-3809.xml">a discriminative approach for dependency based statistical machine translation </title>
<section> experiments and results.  </section>
<citcontext>
<prevsection>
<prevsent>is at the left of head word with pos tag nn?.
</prevsent>
<prevsent>feature weight relpos:amod-nn 6.70 relpos:nn-appos 1.62 relpos:lrb-nn 1.62 table 7: top weights of relpos feature 6.3 decoding.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
we computed the translation accuracies using two metrics, (1) bleu score (papineni et al, 2002), <papid> P02-1040 </papid>and (2) lexical accuracy (or f-score) on test set of 30 sentences.</citsent>
<aftsection>
<nextsent>we compared the accuracy of the experimental system (vaanee) presented in this paper, with moses (state-of-the-art translation system) and shakti (rule-based translation system7) under similar conditions (with using development set to tune the models).
</nextsent>
<nextsent>the rule-based system considered is general domain system tuned to the tourism domain.
</nextsent>
<nextsent>the best bleu score for moses on the test set is 0.118, and the best lexical accuracy is 0.512.
</nextsent>
<nextsent>the best bleu score for shakti is 0.054, and the best lexical accuracy is 0.369.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3257">
<title id=" W10-3705.xml">sentence analysis and collocation identification </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>again, this solution is not fully appropriate, and the reason lies with the important observation that prior collocational knowledge is highly relevant for parsing.
</prevsent>
<prevsent>collocational restrictions are, along with other types of information like selectional preferences and subcategorization frames, major means of structural disambiguation.
</prevsent>
</prevsection>
<citsent citstr=" J93-1005 ">
collocational relations between the words in sentence proved very helpful in selecting the most plausible among all the possible parse trees for sentence (hindleand rooth, 1993; <papid> J93-1005 </papid>alshawi and carter, 1994; <papid> J94-4005 </papid>berthouzoz and merlo, 1997; wehrli, 2000).</citsent>
<aftsection>
<nextsent>hence,the question whether collocations should be identified in sentence before or after parsing is not an easy one.
</nextsent>
<nextsent>the previous literature on parsing and collocations fails to provide insightful details on how this circular issue is (or can be) solved.
</nextsent>
<nextsent>in this paper, we argue that the identification of collocations and the construction of parse tree are interrelated processes, that must be accounted for simultaneously.
</nextsent>
<nextsent>we present processing model in which collocations, if present in lexicon,are identified in the input sentence during the analysis of that sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3258">
<title id=" W10-3705.xml">sentence analysis and collocation identification </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>again, this solution is not fully appropriate, and the reason lies with the important observation that prior collocational knowledge is highly relevant for parsing.
</prevsent>
<prevsent>collocational restrictions are, along with other types of information like selectional preferences and subcategorization frames, major means of structural disambiguation.
</prevsent>
</prevsection>
<citsent citstr=" J94-4005 ">
collocational relations between the words in sentence proved very helpful in selecting the most plausible among all the possible parse trees for sentence (hindleand rooth, 1993; <papid> J93-1005 </papid>alshawi and carter, 1994; <papid> J94-4005 </papid>berthouzoz and merlo, 1997; wehrli, 2000).</citsent>
<aftsection>
<nextsent>hence,the question whether collocations should be identified in sentence before or after parsing is not an easy one.
</nextsent>
<nextsent>the previous literature on parsing and collocations fails to provide insightful details on how this circular issue is (or can be) solved.
</nextsent>
<nextsent>in this paper, we argue that the identification of collocations and the construction of parse tree are interrelated processes, that must be accounted for simultaneously.
</nextsent>
<nextsent>we present processing model in which collocations, if present in lexicon,are identified in the input sentence during the analysis of that sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3260">
<title id=" W10-3705.xml">sentence analysis and collocation identification </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>section 5 provides concluding remarks and presents directions for future work.
</prevsent>
<prevsent>extending the lexical component of parser with mwes was proved to contribute to significant improvement of the coverage and accuracy of parsing results.
</prevsent>
</prevsection>
<citsent citstr=" P98-1030 ">
for instance, brun (1998) <papid> P98-1030 </papid>compared the coverage of french parser with and without terminology recognition in the preprocessing stage.</citsent>
<aftsection>
<nextsent>she found that the integration of 210 nominal terms in the preprocessing components of the parser resulted insignificant reduction of the number of alternative parses (from an average of 4.21 to 2.79).
</nextsent>
<nextsent>the eliminated parses were foundto be semantically undesirable.
</nextsent>
<nextsent>no valid analysis were ruled out.
</nextsent>
<nextsent>similarly, zhang and kordoni (2006) extended lexicon with 373 additional mwe lexical entries and obtained significant increase in the coverage of an english grammar (14.4%, from 4.3% to 18.7%).in the cases mentioned above, words-withspaces?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3261">
<title id=" W10-3705.xml">sentence analysis and collocation identification </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>similarly, zhang and kordoni (2006) extended lexicon with 373 additional mwe lexical entries and obtained significant increase in the coverage of an english grammar (14.4%, from 4.3% to 18.7%).in the cases mentioned above, words-withspaces?
</prevsent>
<prevsent>approach was used.
</prevsent>
</prevsection>
<citsent citstr=" W04-0407 ">
in contrast, alegria et al (2004) <papid> W04-0407 </papid>and villavicencio et al (2007)<papid> D07-1110 </papid>adopted compositional approach to the encoding of mwes, able to capture more morpho syntactically flexible mwes.</citsent>
<aftsection>
<nextsent>alegria et al (2004)<papid> W04-0407 </papid>showed that by using mwe processor in the preprocessing stage of their parser (in development)for basque, significant improvement in the pos tagging precision is obtained.</nextsent>
<nextsent>villavicencio et al (2007)<papid> D07-1110 </papid> found that the addition of 21 new mwes to the lexicon led to significant increase in the grammar coverage (from 7.1% to 22.7%), without altering the grammar accuracy.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3262">
<title id=" W10-3705.xml">sentence analysis and collocation identification </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>similarly, zhang and kordoni (2006) extended lexicon with 373 additional mwe lexical entries and obtained significant increase in the coverage of an english grammar (14.4%, from 4.3% to 18.7%).in the cases mentioned above, words-withspaces?
</prevsent>
<prevsent>approach was used.
</prevsent>
</prevsection>
<citsent citstr=" D07-1110 ">
in contrast, alegria et al (2004) <papid> W04-0407 </papid>and villavicencio et al (2007)<papid> D07-1110 </papid>adopted compositional approach to the encoding of mwes, able to capture more morpho syntactically flexible mwes.</citsent>
<aftsection>
<nextsent>alegria et al (2004)<papid> W04-0407 </papid>showed that by using mwe processor in the preprocessing stage of their parser (in development)for basque, significant improvement in the pos tagging precision is obtained.</nextsent>
<nextsent>villavicencio et al (2007)<papid> D07-1110 </papid> found that the addition of 21 new mwes to the lexicon led to significant increase in the grammar coverage (from 7.1% to 22.7%), without altering the grammar accuracy.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3266">
<title id=" W10-3705.xml">sentence analysis and collocation identification </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>villavicencio et al (2007)<papid> D07-1110 </papid> found that the addition of 21 new mwes to the lexicon led to significant increase in the grammar coverage (from 7.1% to 22.7%), without altering the grammar accuracy.</prevsent>
<prevsent>an area of intensive research in parsing is concerned with the use of lexical preferences, cooccurrence frequencies, collocations, and contextually similar words for pp attachment disambiguation.</prevsent>
</prevsection>
<citsent citstr=" P98-2177 ">
thus, an important number of unsupervised (hindle and rooth, 1993; <papid> J93-1005 </papid>ratnaparkhi, 1998; <papid> P98-2177 </papid>pantel and lin, 2000), <papid> P00-1014 </papid>supervised (alshawi and carter, 1994; <papid> J94-4005 </papid>berthouzoz and merlo, 1997), and combined (volk, 2002) <papid> C02-1004 </papid>methods have been developed to this end.</citsent>
<aftsection>
<nextsent>however, as hindle and rooth (1993) <papid> J93-1005 </papid>pointed out, the parsers used by such methods lack precisely the kind of corpus-based information that is required to resolve ambiguity, because many of the existing attachments may be missing orwrong.</nextsent>
<nextsent>the current literature provides no indication about the manner in which this circular problem can be circumvented, and on whether flexible mwes should be processed before, during or after the sentence analysis takes place.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3267">
<title id=" W10-3705.xml">sentence analysis and collocation identification </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>villavicencio et al (2007)<papid> D07-1110 </papid> found that the addition of 21 new mwes to the lexicon led to significant increase in the grammar coverage (from 7.1% to 22.7%), without altering the grammar accuracy.</prevsent>
<prevsent>an area of intensive research in parsing is concerned with the use of lexical preferences, cooccurrence frequencies, collocations, and contextually similar words for pp attachment disambiguation.</prevsent>
</prevsection>
<citsent citstr=" P00-1014 ">
thus, an important number of unsupervised (hindle and rooth, 1993; <papid> J93-1005 </papid>ratnaparkhi, 1998; <papid> P98-2177 </papid>pantel and lin, 2000), <papid> P00-1014 </papid>supervised (alshawi and carter, 1994; <papid> J94-4005 </papid>berthouzoz and merlo, 1997), and combined (volk, 2002) <papid> C02-1004 </papid>methods have been developed to this end.</citsent>
<aftsection>
<nextsent>however, as hindle and rooth (1993) <papid> J93-1005 </papid>pointed out, the parsers used by such methods lack precisely the kind of corpus-based information that is required to resolve ambiguity, because many of the existing attachments may be missing orwrong.</nextsent>
<nextsent>the current literature provides no indication about the manner in which this circular problem can be circumvented, and on whether flexible mwes should be processed before, during or after the sentence analysis takes place.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3270">
<title id=" W10-3705.xml">sentence analysis and collocation identification </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>villavicencio et al (2007)<papid> D07-1110 </papid> found that the addition of 21 new mwes to the lexicon led to significant increase in the grammar coverage (from 7.1% to 22.7%), without altering the grammar accuracy.</prevsent>
<prevsent>an area of intensive research in parsing is concerned with the use of lexical preferences, cooccurrence frequencies, collocations, and contextually similar words for pp attachment disambiguation.</prevsent>
</prevsection>
<citsent citstr=" C02-1004 ">
thus, an important number of unsupervised (hindle and rooth, 1993; <papid> J93-1005 </papid>ratnaparkhi, 1998; <papid> P98-2177 </papid>pantel and lin, 2000), <papid> P00-1014 </papid>supervised (alshawi and carter, 1994; <papid> J94-4005 </papid>berthouzoz and merlo, 1997), and combined (volk, 2002) <papid> C02-1004 </papid>methods have been developed to this end.</citsent>
<aftsection>
<nextsent>however, as hindle and rooth (1993) <papid> J93-1005 </papid>pointed out, the parsers used by such methods lack precisely the kind of corpus-based information that is required to resolve ambiguity, because many of the existing attachments may be missing orwrong.</nextsent>
<nextsent>the current literature provides no indication about the manner in which this circular problem can be circumvented, and on whether flexible mwes should be processed before, during or after the sentence analysis takes place.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3272">
<title id=" W10-3705.xml">sentence analysis and collocation identification </title>
<section> parsing and collocations.  </section>
<citcontext>
<prevsection>
<prevsent>this is due to thefact that collocations are co-occurrences of lexical items in specific syntactic configuration.
</prevsent>
<prevsent>the collocation break record, for instance, is obtained only in the configurations where break is verb whose direct object is (semantically) headed bythe lexical item record.
</prevsent>
</prevsection>
<citsent citstr=" W07-1216 ">
in other words, the collocation is not defined in terms of linear proximity, but in terms of specific grammatical relation.as the examples in this section show, the relative order of the two items is not relevant, nor isthe distance between the two terms, which is unlimited as long as the grammatical relation holds4.in our system, the grammatical relations are computed by syntactic parser, namely, fips (wehrli, 2007; <papid> W07-1216 </papid>wehrli and nerima, 2009).</citsent>
<aftsection>
<nextsent>until now, the collocation identification process took place at the end of the parse in so-called interpretation procedure applied to the complete parse trees.
</nextsent>
<nextsent>although quite successful, this way of doing presents major drawback: it happens too late to help the parser.
</nextsent>
<nextsent>this section discusses this point and describes the alternative that we are currently developing, which consists in identifying collocations as soon as possible during the parse.
</nextsent>
<nextsent>one of the major hurdles for non-deterministic parsers is the huge number of alternatives that must be considered.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3275">
<title id=" W10-3705.xml">sentence analysis and collocation identification </title>
<section> evaluation experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the search succeeds with the verb tomber, and the collocation tomber en panne dessence (run out of gas?)
</prevsent>
<prevsent>is identified.
</prevsent>
</prevsection>
<citsent citstr=" W09-0415 ">
in this section, we describe the experiments we performed in order to evaluate the precision and recall of the method introduced in section 3, and to compare it against the previous method (fully described in wehrli et al (2009<papid> W09-0415 </papid>b)).</citsent>
<aftsection>
<nextsent>we extend this comparison by performing task-based evaluation, which investigates the impact that the new method has on the quality of translations produced by machine translation system relying on our parser (wehrli et al, 2009<papid> W09-0415 </papid>a).</nextsent>
<nextsent>4.1 precision evaluation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3277">
<title id=" W10-2420.xml">cone metrics for automatic evaluation of named entity coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one of the most important problems in crr is the evaluation of crr results.
</prevsent>
<prevsent>different evaluation metrics have been proposed for this task.
</prevsent>
</prevsection>
<citsent citstr=" H05-1004 ">
b cubed (bagga and baldwin, 1998) and ceaf (luo, 2005) <papid> H05-1004 </papid>are the two most popular metrics; they compute precision, recall and f1 measure between matched equivalent classes and use weighted sums of precision, recall and f1 to produce global score.</citsent>
<aftsection>
<nextsent>like all metrics, b3 and ceaf require gold standard annotations; however, gold standard crr annotations are scarce, because producing such annotations involves substantial amount of human effort since it requires an in-depth knowledge of linguistics and high level of understanding of the particular text.
</nextsent>
<nextsent>consequently, very few corpora with gold standard crr annotations are available (nist, 2003; muc-6, 1995; agirre, 2007).
</nextsent>
<nextsent>by contrast, gold standard named entity (ne) annotations are easy to produce; indeed, there are many ne annotated corpora of different sizes and genres.
</nextsent>
<nextsent>similarly, there are few crr systems and even the best scores obtained by them are only in the region of f1 = 0.5 - 0.6.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3279">
<title id=" W10-2420.xml">cone metrics for automatic evaluation of named entity coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>similarly, there are few crr systems and even the best scores obtained by them are only in the region of f1 = 0.5 - 0.6.
</prevsent>
<prevsent>there are only four such crr systems freely available, to the best of our know ledge (bengston and roth, 2007; versley et al, 2008; baldridge and torton, 2004; baldwin and carpenter, 2003).
</prevsent>
</prevsection>
<citsent citstr=" W09-1119 ">
in comparison, there are numerous named entity recognition (ner) systems, both general-purpose and specialized, and many of them achieve scores better than f1 = 0.95 (ratinov and roth, 2009; <papid> W09-1119 </papid>finkel et al, 1362005).</citsent>
<aftsection>
<nextsent>although these facts can be partly attributed to the hardness?
</nextsent>
<nextsent>of crr compared toner, they also reflect the substantial gap between ner and crr research.
</nextsent>
<nextsent>in this paper, we present set of metrics, collectively called cone, that leverage widely available ner systems and resources and tools for the task of evaluating co-reference resolution systems.
</nextsent>
<nextsent>the basic idea behind cone is to predict crr systems performance for the task of full ne-crr on some dataset using its performance for the subtask of named mentions extraction and grouping (nmeg) on that dataset.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3281">
<title id=" W10-2420.xml">cone metrics for automatic evaluation of named entity coreference resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>finally, in section 7 we present our conclusions and ideas for future work.
</prevsent>
<prevsent>there has been substantial amount of research devoted to automatic evaluation for natural language processing, especially tasks involving language generation.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
the bleu score (papineni et al., 2002) <papid> P02-1040 </papid>proposed for evaluating machine translation results is the best known example of this.</citsent>
<aftsection>
<nextsent>it uses n-gram statistics between machine generated results and references.
</nextsent>
<nextsent>it inspired the rouge metric (lin and hovy, 2003) <papid> N03-1020 </papid>and other methods (louis and nenkova, 2009) <papid> D09-1032 </papid>to perform automatic evaluation of text summarization.</nextsent>
<nextsent>both these metrics have show strong correlation between automatic evaluation results and human judgments.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3282">
<title id=" W10-2420.xml">cone metrics for automatic evaluation of named entity coreference resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the bleu score (papineni et al., 2002) <papid> P02-1040 </papid>proposed for evaluating machine translation results is the best known example of this.</prevsent>
<prevsent>it uses n-gram statistics between machine generated results and references.</prevsent>
</prevsection>
<citsent citstr=" N03-1020 ">
it inspired the rouge metric (lin and hovy, 2003) <papid> N03-1020 </papid>and other methods (louis and nenkova, 2009) <papid> D09-1032 </papid>to perform automatic evaluation of text summarization.</citsent>
<aftsection>
<nextsent>both these metrics have show strong correlation between automatic evaluation results and human judgments.
</nextsent>
<nextsent>the two metrics successfully reduce the need for human judgment and help speed up research by allowing large-scale evaluation.
</nextsent>
<nextsent>another example is the alignment entropy (pervouchine et al, 2009) <papid> P09-1016 </papid>for evaluating transliteration alignment.</nextsent>
<nextsent>it reduces the need for alignment gold standard and highly correlates with transliteration system performance.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3283">
<title id=" W10-2420.xml">cone metrics for automatic evaluation of named entity coreference resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the bleu score (papineni et al., 2002) <papid> P02-1040 </papid>proposed for evaluating machine translation results is the best known example of this.</prevsent>
<prevsent>it uses n-gram statistics between machine generated results and references.</prevsent>
</prevsection>
<citsent citstr=" D09-1032 ">
it inspired the rouge metric (lin and hovy, 2003) <papid> N03-1020 </papid>and other methods (louis and nenkova, 2009) <papid> D09-1032 </papid>to perform automatic evaluation of text summarization.</citsent>
<aftsection>
<nextsent>both these metrics have show strong correlation between automatic evaluation results and human judgments.
</nextsent>
<nextsent>the two metrics successfully reduce the need for human judgment and help speed up research by allowing large-scale evaluation.
</nextsent>
<nextsent>another example is the alignment entropy (pervouchine et al, 2009) <papid> P09-1016 </papid>for evaluating transliteration alignment.</nextsent>
<nextsent>it reduces the need for alignment gold standard and highly correlates with transliteration system performance.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3284">
<title id=" W10-2420.xml">cone metrics for automatic evaluation of named entity coreference resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>both these metrics have show strong correlation between automatic evaluation results and human judgments.
</prevsent>
<prevsent>the two metrics successfully reduce the need for human judgment and help speed up research by allowing large-scale evaluation.
</prevsent>
</prevsection>
<citsent citstr=" P09-1016 ">
another example is the alignment entropy (pervouchine et al, 2009) <papid> P09-1016 </papid>for evaluating transliteration alignment.</citsent>
<aftsection>
<nextsent>it reduces the need for alignment gold standard and highly correlates with transliteration system performance.
</nextsent>
<nextsent>thus it is able to 137serve as good metric for transliteration alignment.
</nextsent>
<nextsent>we contrast our work with (stoyanov et al, 2009), <papid> P09-1074 </papid>who show that the co-reference resolution problem can be separated into different parts according to the type of the mention.</nextsent>
<nextsent>some parts are relatively easy to solve.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3285">
<title id=" W10-2420.xml">cone metrics for automatic evaluation of named entity coreference resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>it reduces the need for alignment gold standard and highly correlates with transliteration system performance.
</prevsent>
<prevsent>thus it is able to 137serve as good metric for transliteration alignment.
</prevsent>
</prevsection>
<citsent citstr=" P09-1074 ">
we contrast our work with (stoyanov et al, 2009), <papid> P09-1074 </papid>who show that the co-reference resolution problem can be separated into different parts according to the type of the mention.</citsent>
<aftsection>
<nextsent>some parts are relatively easy to solve.
</nextsent>
<nextsent>the re solver performs equally well in each part across datasets.
</nextsent>
<nextsent>they use the statistics of mentions in different parts with test results on other datasets as predictor for unseen datasets, and obtain promising results with good correlations.
</nextsent>
<nextsent>we approach the problem from different perspective.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3289">
<title id=" W10-2420.xml">cone metrics for automatic evaluation of named entity coreference resolution </title>
<section> cone b3 and cone ceaf metrics:.  </section>
<citcontext>
<prevsection>
<prevsent>we find that score(gnm, onm) is highly correlated with score(g, o) for all the freely available ne crr systems over various datasets.
</prevsent>
<prevsent>this provides the neccessary justification for the use of score(gnm, onm).
</prevsent>
</prevsection>
<citsent citstr=" P05-1045 ">
we use synergy (shah et al, 2010), an ensemble ner system that combines the uiuc ner (ritanov and roth, 2009) and stanford ner (finkel et al, 2005) <papid> P05-1045 </papid>systems, to produce gnm and onm from and by selecting named mentions.</citsent>
<aftsection>
<nextsent>however, any other good ner system would serve the same purpose.
</nextsent>
<nextsent>we see that while standard evaluation metrics require the use of g, i.e. the full set of ne-crr gold standard annotations including named, nominal and pronimal mentions, cone metrics require only gnm, i.e. gold standard annotations consisting of named mentions only.
</nextsent>
<nextsent>the key advantage of using cone metrics is that gnm can be automatically approximated using an ner system with good degree of accuracy.
</nextsent>
<nextsent>this is because state-of-the-art ner systems achieve near-optimal performance, exceeding f1 = 0.95 in many cases, and after obtaining their output, the task of estimating gnm reduces to simply clustering it to seperate mentions of diffrerent real-world entities.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3290">
<title id=" W10-1713.xml">the rali machine translation system for wmt 2010 </title>
<section> system architecture.  </section>
<citcontext>
<prevsection>
<prevsent>memory needs during decoding, lms were pruned using the srilm prune option.
</prevsent>
<prevsent>2.3 alignment and translation models.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
all parallel corpora were aligned withgiza++ (och and ney, 2003).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>our translation models are phrase-based models (pbms) built with moses (koehn et al, 2007) <papid> P07-2045 </papid>with the following non-default settings: ? maximum sentence length of 80 words, ? limit on the number of phrase translations loaded for each phrase fixed to 30.</nextsent>
<nextsent>weights of lm, phrase table and lexicalized reordering model scores were optimized on the development corpus thanks to the mert algorithm (och, 2003).<papid> P03-1021 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3291">
<title id=" W10-1713.xml">the rali machine translation system for wmt 2010 </title>
<section> system architecture.  </section>
<citcontext>
<prevsection>
<prevsent>2.3 alignment and translation models.
</prevsent>
<prevsent>all parallel corpora were aligned withgiza++ (och and ney, 2003).<papid> J03-1002 </papid></prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
our translation models are phrase-based models (pbms) built with moses (koehn et al, 2007) <papid> P07-2045 </papid>with the following non-default settings: ? maximum sentence length of 80 words, ? limit on the number of phrase translations loaded for each phrase fixed to 30.</citsent>
<aftsection>
<nextsent>weights of lm, phrase table and lexicalized reordering model scores were optimized on the development corpus thanks to the mert algorithm (och, 2003).<papid> P03-1021 </papid></nextsent>
<nextsent>2.4 experiments.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3292">
<title id=" W10-1713.xml">the rali machine translation system for wmt 2010 </title>
<section> system architecture.  </section>
<citcontext>
<prevsection>
<prevsent>all parallel corpora were aligned withgiza++ (och and ney, 2003).<papid> J03-1002 </papid></prevsent>
<prevsent>our translation models are phrase-based models (pbms) built with moses (koehn et al, 2007) <papid> P07-2045 </papid>with the following non-default settings: ? maximum sentence length of 80 words, ? limit on the number of phrase translations loaded for each phrase fixed to 30.</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
weights of lm, phrase table and lexicalized reordering model scores were optimized on the development corpus thanks to the mert algorithm (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>2.4 experiments.
</nextsent>
<nextsent>this section reports experiments done on thenews-test2009 corpus for testing various configurations.
</nextsent>
<nextsent>in these first experiments, we trained lms and translation models on the europarl corpus.
</nextsent>
<nextsent>case we tested two methods to handle case.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3293">
<title id=" W10-1713.xml">the rali machine translation system for wmt 2010 </title>
<section> domain adaptation.  </section>
<citcontext>
<prevsection>
<prevsent>translation models used here were trained on nc and europarl.
</prevsent>
<prevsent>as the only news parallel corpus provided for the workshop contains 85k sentence pairs, wemust resort to other parallel out-of-domain corpora in order to build reliable translation models.
</prevsent>
</prevsection>
<citsent citstr=" W07-0717 ">
if in-domain and out-of-domain lms are usually mixed with the well-studied interpolation techniques, training translation models from data of different domains has received less attention (fos ter and kuhn, 2007; <papid> W07-0717 </papid>bertoldi and federico, 2009).<papid> W09-0432 </papid>therefore, there is still no widely accepted technique for this last purpose.</citsent>
<aftsection>
<nextsent>3.1 effects of the training data size.
</nextsent>
<nextsent>we investigated how increasing training data acts upon bleu score.
</nextsent>
<nextsent>table 3 shows high increase of 2.7 points w.r.t. the use of nc alone (line 1) when building the phrase table and the reordering model from nc and either the 1.7 m-sentence-paireuroparl (line 2) or 1.7 m-sentence-pair corpus extracted from the 3 out-of-domain corpora: europarl, un and gw (line 3).
</nextsent>
<nextsent>training pbm on merged parallel corpora is not necessarily the best way to combine data from different domains.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3294">
<title id=" W10-1713.xml">the rali machine translation system for wmt 2010 </title>
<section> domain adaptation.  </section>
<citcontext>
<prevsection>
<prevsent>translation models used here were trained on nc and europarl.
</prevsent>
<prevsent>as the only news parallel corpus provided for the workshop contains 85k sentence pairs, wemust resort to other parallel out-of-domain corpora in order to build reliable translation models.
</prevsent>
</prevsection>
<citsent citstr=" W09-0432 ">
if in-domain and out-of-domain lms are usually mixed with the well-studied interpolation techniques, training translation models from data of different domains has received less attention (fos ter and kuhn, 2007; <papid> W07-0717 </papid>bertoldi and federico, 2009).<papid> W09-0432 </papid>therefore, there is still no widely accepted technique for this last purpose.</citsent>
<aftsection>
<nextsent>3.1 effects of the training data size.
</nextsent>
<nextsent>we investigated how increasing training data acts upon bleu score.
</nextsent>
<nextsent>table 3 shows high increase of 2.7 points w.r.t. the use of nc alone (line 1) when building the phrase table and the reordering model from nc and either the 1.7 m-sentence-paireuroparl (line 2) or 1.7 m-sentence-pair corpus extracted from the 3 out-of-domain corpora: europarl, un and gw (line 3).
</nextsent>
<nextsent>training pbm on merged parallel corpora is not necessarily the best way to combine data from different domains.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3295">
<title id=" W10-1713.xml">the rali machine translation system for wmt 2010 </title>
<section> domain adaptation.  </section>
<citcontext>
<prevsection>
<prevsent>unknown words the main interest of adding new training material relies on the finding of words missing in the phrase table.
</prevsent>
<prevsent>according to 105 this principle, nc was extended with new sentence pairs containing an unknown word (table 4, line 2) or word that belongs to our lm vocabulary andthat occurs less than 3 times in the current corpus (line 3).
</prevsent>
</prevsection>
<citsent citstr=" W09-0424 ">
this resulted in adding 400 pairs in the first case and 950 in the second one, with bleu scores close or even better than those obtained with 1.7 m. corpora enfr fren nc + 1.7 random pairs 26.02 26.68nc + 400k pairs (occ = 1) 25.67 nc + 950k pairs (occ = 3) 26.13 nc + joshua sub-sampling 26.98 27.68nc + ir (1-g q, w/ repet) 25.81 nc + ir (1-g q, no repet) 26.56 27.54nc + ir (1,2-g q, w/ repet) 26.26 nc + ir (1,2-g q, no repet) 26.53 nc + 8.7 pairs 26.68 27.65 + ir score (1g q, no repet) 26.93 27.65 3 large models merged 26.86 27.56 + ir score (1g q, no repet) 26.98 27.74 table 4: bleu measured on news-test2009 forenglish-french and french-english using translation models trained on nc and subset of out-of domain corpora.unknown n-grams we applied the sub sampling method available in the joshua toolkit (li et al, 2009).<papid> W09-0424 </papid></citsent>
<aftsection>
<nextsent>this method adds new sentence pair when it contains new n-grams (with 1 ? ? 12) occurring less than 20 times in the current corpus, which led us to add 1.5 pairs for english-french and 1.4 for french-english.
</nextsent>
<nextsent>a significant improvement of bleu is observed using this method (0.8 for english-french and 1.0 for french-english) w.r.t. the use of 1.7 randomly selected pairs.
</nextsent>
<nextsent>however, this method has the major drawback of needing to build new phrase table for each document to translate.
</nextsent>
<nextsent>information retrieval information retrieval(ir) methods have been used in the past to sub sample parallel corpora (hildebrand et al, 2005; lu?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3296">
<title id=" W10-3801.xml">intersecting hierarchical and phrase based models of translation formal aspects and algorithms </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we model the phrase-based component by introducing variant of weighted finite-state automata, called ?-automata, provide self-contained description of general algorithm for intersecting weighted synchronous context-free grammars with finite-state automata, and extend these constructs to ?-automata.
</prevsent>
<prevsent>we end by briefly discussing complexity properties of the presented algorithms.
</prevsent>
</prevsection>
<citsent citstr=" J04-4002 ">
phrase-based (och and ney, 2004; <papid> J04-4002 </papid>koehn etal., 2007) <papid> P07-2045 </papid>and hierarchical (hiero-style) (chiang, 2007) <papid> J07-2003 </papid>models are two mainstream approaches for building statistical machine translation systems, with different characteristics.while phrase-based systems allow direct capture of correspondences between surface-level lexical patterns, but at the cost of simplistic handling of re-ordering, hierarchical systems are better able to constrain re-ordering, especially for distant language pairs, but tend to produce sparser rules and often lag behind phrase-based systems for less distant language pairs.</citsent>
<aftsection>
<nextsent>it might therefore make sense to capitalize on the complementary advantages of the two approaches by combining them in some way.
</nextsent>
<nextsent>this paper attempts to lay out the formal prerequisites for doing so, by developing techniques for intersecting hierarchical model and phrase-based model.
</nextsent>
<nextsent>in order to do so, one first difficulty has to be overcome: while hierarchical systems are based on the mathematically well understood formalism of weighted synchronous cfgs, phrase-based systems do not correspond to any classical formal model, although they are loosely connected to weighted finite state transducers, but crucially go beyond these by allowing phrase re-orderings.
</nextsent>
<nextsent>one might try to address this issue by limiting priori the amount of re-ordering, in the spirit of (kumar and byrne, 2005), <papid> H05-1021 </papid>which would allowto approximate phrase-based model by standard transducer, but this would introduce furtherissues.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3297">
<title id=" W10-3801.xml">intersecting hierarchical and phrase based models of translation formal aspects and algorithms </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we model the phrase-based component by introducing variant of weighted finite-state automata, called ?-automata, provide self-contained description of general algorithm for intersecting weighted synchronous context-free grammars with finite-state automata, and extend these constructs to ?-automata.
</prevsent>
<prevsent>we end by briefly discussing complexity properties of the presented algorithms.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
phrase-based (och and ney, 2004; <papid> J04-4002 </papid>koehn etal., 2007) <papid> P07-2045 </papid>and hierarchical (hiero-style) (chiang, 2007) <papid> J07-2003 </papid>models are two mainstream approaches for building statistical machine translation systems, with different characteristics.while phrase-based systems allow direct capture of correspondences between surface-level lexical patterns, but at the cost of simplistic handling of re-ordering, hierarchical systems are better able to constrain re-ordering, especially for distant language pairs, but tend to produce sparser rules and often lag behind phrase-based systems for less distant language pairs.</citsent>
<aftsection>
<nextsent>it might therefore make sense to capitalize on the complementary advantages of the two approaches by combining them in some way.
</nextsent>
<nextsent>this paper attempts to lay out the formal prerequisites for doing so, by developing techniques for intersecting hierarchical model and phrase-based model.
</nextsent>
<nextsent>in order to do so, one first difficulty has to be overcome: while hierarchical systems are based on the mathematically well understood formalism of weighted synchronous cfgs, phrase-based systems do not correspond to any classical formal model, although they are loosely connected to weighted finite state transducers, but crucially go beyond these by allowing phrase re-orderings.
</nextsent>
<nextsent>one might try to address this issue by limiting priori the amount of re-ordering, in the spirit of (kumar and byrne, 2005), <papid> H05-1021 </papid>which would allowto approximate phrase-based model by standard transducer, but this would introduce furtherissues.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3298">
<title id=" W10-3801.xml">intersecting hierarchical and phrase based models of translation formal aspects and algorithms </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we model the phrase-based component by introducing variant of weighted finite-state automata, called ?-automata, provide self-contained description of general algorithm for intersecting weighted synchronous context-free grammars with finite-state automata, and extend these constructs to ?-automata.
</prevsent>
<prevsent>we end by briefly discussing complexity properties of the presented algorithms.
</prevsent>
</prevsection>
<citsent citstr=" J07-2003 ">
phrase-based (och and ney, 2004; <papid> J04-4002 </papid>koehn etal., 2007) <papid> P07-2045 </papid>and hierarchical (hiero-style) (chiang, 2007) <papid> J07-2003 </papid>models are two mainstream approaches for building statistical machine translation systems, with different characteristics.while phrase-based systems allow direct capture of correspondences between surface-level lexical patterns, but at the cost of simplistic handling of re-ordering, hierarchical systems are better able to constrain re-ordering, especially for distant language pairs, but tend to produce sparser rules and often lag behind phrase-based systems for less distant language pairs.</citsent>
<aftsection>
<nextsent>it might therefore make sense to capitalize on the complementary advantages of the two approaches by combining them in some way.
</nextsent>
<nextsent>this paper attempts to lay out the formal prerequisites for doing so, by developing techniques for intersecting hierarchical model and phrase-based model.
</nextsent>
<nextsent>in order to do so, one first difficulty has to be overcome: while hierarchical systems are based on the mathematically well understood formalism of weighted synchronous cfgs, phrase-based systems do not correspond to any classical formal model, although they are loosely connected to weighted finite state transducers, but crucially go beyond these by allowing phrase re-orderings.
</nextsent>
<nextsent>one might try to address this issue by limiting priori the amount of re-ordering, in the spirit of (kumar and byrne, 2005), <papid> H05-1021 </papid>which would allowto approximate phrase-based model by standard transducer, but this would introduce furtherissues.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3299">
<title id=" W10-3801.xml">intersecting hierarchical and phrase based models of translation formal aspects and algorithms </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper attempts to lay out the formal prerequisites for doing so, by developing techniques for intersecting hierarchical model and phrase-based model.
</prevsent>
<prevsent>in order to do so, one first difficulty has to be overcome: while hierarchical systems are based on the mathematically well understood formalism of weighted synchronous cfgs, phrase-based systems do not correspond to any classical formal model, although they are loosely connected to weighted finite state transducers, but crucially go beyond these by allowing phrase re-orderings.
</prevsent>
</prevsection>
<citsent citstr=" H05-1021 ">
one might try to address this issue by limiting priori the amount of re-ordering, in the spirit of (kumar and byrne, 2005), <papid> H05-1021 </papid>which would allowto approximate phrase-based model by standard transducer, but this would introduce furtherissues.</citsent>
<aftsection>
<nextsent>first, limiting the amount of reordering in the phrase-based model runs contrary to the underlying intuitions behind the intersection, namely that the hierarchical model should be mainly responsible for controlling re-ordering, and the phrase-based model mainly responsible for lexical choice.
</nextsent>
<nextsent>second, the transducer resulting from the operation could be large.
</nextsent>
<nextsent>third, even if we could represent the phrase-basedmodel through finite-state transducer, intersecting this transducer with the synchronous cfg would actually be intractable in the general case, as we indicate later.
</nextsent>
<nextsent>we then take another route.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3301">
<title id=" W10-3801.xml">intersecting hierarchical and phrase based models of translation formal aspects and algorithms </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the resulting weighted synchronous grammar represents, as in hiero, the parse forest?
</prevsent>
<prevsent>(or hy pergraph?)
</prevsent>
</prevsection>
<citsent citstr=" D08-1023 ">
of all weighted derivations (that is of all translations) that can be built over x, but where the weights incorporate knowledge of the phrase-based component; it can therefore form the basis of variety of dynamic programming or sampling algorithms (chiang, 2007; <papid> J07-2003 </papid>blunsom and osborne, 2008), <papid> D08-1023 </papid>as is the case with standard hiero-type representations.</citsent>
<aftsection>
<nextsent>while in the worst case the intersected grammar can contain an exponential number of nonterminals, we argue that such combinatorial explosion will not happen in practice, and we also briefly indicate formal conditions under which it will not be allowed to happen.
</nextsent>
<nextsent>cfgs with weighted automata we assume that the notions of weighted finite state automaton [w-fsa] and weighted synchronous grammar [w-scfg] are known (for short descriptions see (mohri et al, 1996) and (chiang, 2006)), and we consider: 1.
</nextsent>
<nextsent>a w-scfg g, with associated source grammar gs (resp.
</nextsent>
<nextsent>target grammar gt); the terminals of gs (resp.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3304">
<title id=" W10-3801.xml">intersecting hierarchical and phrase based models of translation formal aspects and algorithms </title>
<section> intersecting synchronous grammar.  </section>
<citcontext>
<prevsection>
<prevsent>suppose that the source sen 13if this condition is removed, and for the simpler case where the source (resp.
</prevsent>
<prevsent>target) automaton encodes single sentence (resp.
</prevsent>
</prevsection>
<citsent citstr=" H05-1101 ">
y), (satta and peserico, 2005) <papid> H05-1101 </papid>have shown that the problem of deciding whether (x, y) is recognized by is np-hard relative to the sum of the sizes.</citsent>
<aftsection>
<nextsent>a consequence is then that the grammar g?
</nextsent>
<nextsent>cannot be constructed in polynomial time unless = np . 8 tence contains the two tokens person nes andgens between positions i, + 1 and j, + 1 respectively, with and far from each other, that the phrase table contains the two phrase pairs (personnes, persons) and (gens, people), but that the synchronous grammar only contains the two rules ? personnes/people and gens/persons, with these phrases and rules exhausting the possibilities for translating gens and personnes; then the intersected grammar will contain such nonterminals as tixt ?,{gens} i+1 and jy r?,{personnes} j+1 , where in the first case the token set {gens} in the first nonterminal is unrelated tothe tokens appearing between i, + 1, and similarly in the second case.
</nextsent>
<nextsent>without experimentation on real cases, it is impossible to say whether such phenomena would empirically lead to combinatorial explosion or whether the synchronous grammar would sufficiently constrain the phrase-base component (whose re-ordering capabilities are responsible in fine for the potential np-hardness of the translation process) to avoid it.
</nextsent>
<nextsent>another possible approach is to prevent priori possible combinatorial explosion by adding formal constraint sto the intersection mechanism.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3305">
<title id=" W10-1303.xml">implications of pragmatic and cognitive theories on the design of utterance based aac systems </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>our hypothesis is the structure used there does not impose enough organization over the utterances, especially in the type of situations we envision for use.
</prevsent>
<prevsent>the contact system is system that combines notions from both talk and the frame talker projects.
</prevsent>
</prevsection>
<citsent citstr=" W97-0502 ">
finally, langer &amp; hickey (1997) <papid> W97-0502 </papid>describe whole utterance system that retrieved utterances related to keywords via keyword search on large database of utterances.</citsent>
<aftsection>
<nextsent>in contrast, our system would provide access to presumably series of utterances relevant to the current situation.
</nextsent>
<nextsent>aac systems that use pre stored text have great deal of potential to speed communication rate and improve attitudes of unfamiliar speaking partners towards aac users in public goal-oriented situations.
</nextsent>
<nextsent>in this work we applied empirical evidence summarized in hierarchy of conversational rule violations (bedrosian et al 2000) to identify important principles of successful interaction with aac text.
</nextsent>
<nextsent>we then attempted to match appropriate nlp technologies with these principles in order to develop different viewpoint for an aac system that used pre stored text.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3306">
<title id=" W10-1707.xml">the university of maryland statistical machine translation system for the fifth workshop on machine translation </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>the rest of this paper is structured as follows.
</prevsent>
<prevsent>after brief description of the baseline system in section 2, we detail the steps taken to improve upon it in section 3, followed by experimental results and analysis of decoder performance metrics.
</prevsent>
</prevsection>
<citsent citstr=" J07-2003 ">
as our baseline system, we employ hierarchical phrase-based translation model, which is formally based on the notion of synchronous context-freegrammar (scfg) (chiang, 2007).<papid> J07-2003 </papid></citsent>
<aftsection>
<nextsent>these grammars contain pairs of cfg rules with aligned nonterminals, and by introducing these nonterminals into the grammar, such system is able to utilize both word and phrase level reordering to capture the hierarchical structure of language.
</nextsent>
<nextsent>scfg translation models have been shown to be well suited for german-english translation, as they areable to both exploit lexical information for and efficiently compute all possible reorderings using cky-based decoder (dyer et al, 2009).<papid> W09-0426 </papid>our system is implemented within cdec, an efficient and modular open source framework for aligning, training, and decoding with number of different translation models, including scfgs (dyer et al, 2010).1 cdecs modular framework facilitates seamless integration of translation model with different language models, pruning strategies and inference algorithms.</nextsent>
<nextsent>as input, cdec expects string, lattice, or context-freeforest, and uses it to generate hypergraph representation, which represents the full translation forest without any pruning.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3307">
<title id=" W10-1707.xml">the university of maryland statistical machine translation system for the fifth workshop on machine translation </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>as our baseline system, we employ hierarchical phrase-based translation model, which is formally based on the notion of synchronous context-freegrammar (scfg) (chiang, 2007).<papid> J07-2003 </papid></prevsent>
<prevsent>these grammars contain pairs of cfg rules with aligned nonterminals, and by introducing these nonterminals into the grammar, such system is able to utilize both word and phrase level reordering to capture the hierarchical structure of language.</prevsent>
</prevsection>
<citsent citstr=" W09-0426 ">
scfg translation models have been shown to be well suited for german-english translation, as they areable to both exploit lexical information for and efficiently compute all possible reorderings using cky-based decoder (dyer et al, 2009).<papid> W09-0426 </papid>our system is implemented within cdec, an efficient and modular open source framework for aligning, training, and decoding with number of different translation models, including scfgs (dyer et al, 2010).1 cdecs modular framework facilitates seamless integration of translation model with different language models, pruning strategies and inference algorithms.</citsent>
<aftsection>
<nextsent>as input, cdec expects string, lattice, or context-freeforest, and uses it to generate hypergraph representation, which represents the full translation forest without any pruning.
</nextsent>
<nextsent>the forest can now be rescored, by intersecting it with language model for instance, to obtain output translations.
</nextsent>
<nextsent>the above capabilities of cdec allow us to perform the experiments described below, which would otherwise be quite cumbersome to carry out in another system.
</nextsent>
<nextsent>the set of features used in our model were the rule translation relative frequency (e|f), target n-gram language model (e), pass-through?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3308">
<title id=" W10-1707.xml">the university of maryland statistical machine translation system for the fifth workshop on machine translation </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>the set of features used in our model were the rule translation relative frequency (e|f), target n-gram language model (e), pass-through?
</prevsent>
<prevsent>penalty when passing source language word to the target side without translating it, lexical translation probabilities plex(e|f) and plex(f |e), 1http://cdec-decoder.org 72 count of the number of times that arity-0,1, or 2scfg rules were used, count of the total number of rules used, source word penalty, target word penalty, the segmentation model cost, and count of the number of times the glue rule is used.the number of non-terminals allowed in synchronous grammar rule was restricted to two, and the non-terminal span limit was 12 for non-gluegrammars.
</prevsent>
</prevsection>
<citsent citstr=" D07-1104 ">
the hierarchical phrase-base translation grammar was extracted using suffix array rule extractor (lopez, 2007).<papid> D07-1104 </papid></citsent>
<aftsection>
<nextsent>2.1 data preparation.
</nextsent>
<nextsent>in order to extract the translation grammar necessary for our model, we used the provided eu roparl and news commentary parallel training data.
</nextsent>
<nextsent>the lower cased and tokenized training data was then filtered for length and aligned using the giza++ implementation of ibm model 4 (och and ney, 2003) <papid> J03-1002 </papid>to obtain one-to-many alignments in both directions and symmetrized by combining both into single alignment using the grow-diagfinal-and method (koehn et al, 2003).<papid> N03-1017 </papid></nextsent>
<nextsent>we constructed 5-gram language model using the sri language modeling toolkit (stolcke, 2002) from the provided english monolingual training data and the non-europarl portions of the parallel data with modified kneser-ney smoothing (chen and goodman, 1996).<papid> P96-1041 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3310">
<title id=" W10-1707.xml">the university of maryland statistical machine translation system for the fifth workshop on machine translation </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 data preparation.
</prevsent>
<prevsent>in order to extract the translation grammar necessary for our model, we used the provided eu roparl and news commentary parallel training data.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
the lower cased and tokenized training data was then filtered for length and aligned using the giza++ implementation of ibm model 4 (och and ney, 2003) <papid> J03-1002 </papid>to obtain one-to-many alignments in both directions and symmetrized by combining both into single alignment using the grow-diagfinal-and method (koehn et al, 2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>we constructed 5-gram language model using the sri language modeling toolkit (stolcke, 2002) from the provided english monolingual training data and the non-europarl portions of the parallel data with modified kneser-ney smoothing (chen and goodman, 1996).<papid> P96-1041 </papid></nextsent>
<nextsent>since the beginnings and ends of sentences often display unique characteristics that are not easily captured within the context of the model, and have previously been demonstrated to significantly improve performance (dyer et al, 2009), <papid> W09-0426 </papid>we explicitly annotate beginning and end of sentence markers as part of our translationprocess.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3311">
<title id=" W10-1707.xml">the university of maryland statistical machine translation system for the fifth workshop on machine translation </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 data preparation.
</prevsent>
<prevsent>in order to extract the translation grammar necessary for our model, we used the provided eu roparl and news commentary parallel training data.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
the lower cased and tokenized training data was then filtered for length and aligned using the giza++ implementation of ibm model 4 (och and ney, 2003) <papid> J03-1002 </papid>to obtain one-to-many alignments in both directions and symmetrized by combining both into single alignment using the grow-diagfinal-and method (koehn et al, 2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>we constructed 5-gram language model using the sri language modeling toolkit (stolcke, 2002) from the provided english monolingual training data and the non-europarl portions of the parallel data with modified kneser-ney smoothing (chen and goodman, 1996).<papid> P96-1041 </papid></nextsent>
<nextsent>since the beginnings and ends of sentences often display unique characteristics that are not easily captured within the context of the model, and have previously been demonstrated to significantly improve performance (dyer et al, 2009), <papid> W09-0426 </papid>we explicitly annotate beginning and end of sentence markers as part of our translationprocess.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3312">
<title id=" W10-1707.xml">the university of maryland statistical machine translation system for the fifth workshop on machine translation </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>in order to extract the translation grammar necessary for our model, we used the provided eu roparl and news commentary parallel training data.
</prevsent>
<prevsent>the lower cased and tokenized training data was then filtered for length and aligned using the giza++ implementation of ibm model 4 (och and ney, 2003) <papid> J03-1002 </papid>to obtain one-to-many alignments in both directions and symmetrized by combining both into single alignment using the grow-diagfinal-and method (koehn et al, 2003).<papid> N03-1017 </papid></prevsent>
</prevsection>
<citsent citstr=" P96-1041 ">
we constructed 5-gram language model using the sri language modeling toolkit (stolcke, 2002) from the provided english monolingual training data and the non-europarl portions of the parallel data with modified kneser-ney smoothing (chen and goodman, 1996).<papid> P96-1041 </papid></citsent>
<aftsection>
<nextsent>since the beginnings and ends of sentences often display unique characteristics that are not easily captured within the context of the model, and have previously been demonstrated to significantly improve performance (dyer et al, 2009), <papid> W09-0426 </papid>we explicitly annotate beginning and end of sentence markers as part of our translationprocess.</nextsent>
<nextsent>we used the 2525 sentences in newstest2009 as our dev set on which we tuned the feature weights, and report results on the 2489 sentences of the news-test2010 test set.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3314">
<title id=" W10-1707.xml">the university of maryland statistical machine translation system for the fifth workshop on machine translation </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>we used the 2525 sentences in newstest2009 as our dev set on which we tuned the feature weights, and report results on the 2489 sentences of the news-test2010 test set.
</prevsent>
<prevsent>2.2 viterbi envelope semi ring training.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
to optimize the feature weights for our model, we use viterbi envelope semi ring training (vest),which is an implementation of the minimum error rate training (mert) algorithm (dyer et al, 2010; och, 2003) <papid> P03-1021 </papid>for training with an arbitrary loss function.</citsent>
<aftsection>
<nextsent>vest re interprets mert withina semi ring framework, which is useful mathematical abstraction for defining two general operations, addition (?)
</nextsent>
<nextsent>and multiplication (?)
</nextsent>
<nextsent>over set of values.
</nextsent>
<nextsent>formally, semi ring is 5-tuple(k,?,?, 0, 1), where addition must be communicative and associative, multiplication must be associative and must distribute over addition, and an identity element exists for both.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3315">
<title id=" W10-1707.xml">the university of maryland statistical machine translation system for the fifth workshop on machine translation </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>formally, semi ring is 5-tuple(k,?,?, 0, 1), where addition must be communicative and associative, multiplication must be associative and must distribute over addition, and an identity element exists for both.
</prevsent>
<prevsent>for vest, having be the set of line segments, ? be the union of them, and?
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
be minkowski addition of the lines represented as points in the dual plane, allows us to compute the necessary mert line search with the inside algorithm.2 the error function we use is bleu (papineni et al, 2002), <papid> P02-1040 </papid>and the decoder is configured to use cube pruning (huang and chiang, 2007) <papid> P07-1019 </papid>with limit of 100 candidates at each node.</citsent>
<aftsection>
<nextsent>during decoding of the test set, we raise the cube pruning limit to 1000 candidates at each node.
</nextsent>
<nextsent>2.3 compound segmentation lattices.
</nextsent>
<nextsent>to deal with the aforementioned problem inger man of productive compounding, where words are formed by the concatenation of several morphemes and the orthography does not delineate the morpheme boundaries, we utilize word segmentation lattices.
</nextsent>
<nextsent>these lattices serve to encode alternative ways of segmenting compound words, and as such, when presented as the input to the system allow the decoder to automatically choose which segmentation is best for translation, leading to markedly improved results (dyer, 2009).<papid> N09-1046 </papid>in order to construct diverse and accurate segmentation lattices, we built maximum entropy model of compound word splitting which makes use of small number of dense features, suchas frequency of hypothesized morphemes as separate units in monolingual corpus, number of predicted morphemes, and number of letters in predicted morpheme.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3316">
<title id=" W10-1707.xml">the university of maryland statistical machine translation system for the fifth workshop on machine translation </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>formally, semi ring is 5-tuple(k,?,?, 0, 1), where addition must be communicative and associative, multiplication must be associative and must distribute over addition, and an identity element exists for both.
</prevsent>
<prevsent>for vest, having be the set of line segments, ? be the union of them, and?
</prevsent>
</prevsection>
<citsent citstr=" P07-1019 ">
be minkowski addition of the lines represented as points in the dual plane, allows us to compute the necessary mert line search with the inside algorithm.2 the error function we use is bleu (papineni et al, 2002), <papid> P02-1040 </papid>and the decoder is configured to use cube pruning (huang and chiang, 2007) <papid> P07-1019 </papid>with limit of 100 candidates at each node.</citsent>
<aftsection>
<nextsent>during decoding of the test set, we raise the cube pruning limit to 1000 candidates at each node.
</nextsent>
<nextsent>2.3 compound segmentation lattices.
</nextsent>
<nextsent>to deal with the aforementioned problem inger man of productive compounding, where words are formed by the concatenation of several morphemes and the orthography does not delineate the morpheme boundaries, we utilize word segmentation lattices.
</nextsent>
<nextsent>these lattices serve to encode alternative ways of segmenting compound words, and as such, when presented as the input to the system allow the decoder to automatically choose which segmentation is best for translation, leading to markedly improved results (dyer, 2009).<papid> N09-1046 </papid>in order to construct diverse and accurate segmentation lattices, we built maximum entropy model of compound word splitting which makes use of small number of dense features, suchas frequency of hypothesized morphemes as separate units in monolingual corpus, number of predicted morphemes, and number of letters in predicted morpheme.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3318">
<title id=" W10-1707.xml">the university of maryland statistical machine translation system for the fifth workshop on machine translation </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>2.3 compound segmentation lattices.
</prevsent>
<prevsent>to deal with the aforementioned problem inger man of productive compounding, where words are formed by the concatenation of several morphemes and the orthography does not delineate the morpheme boundaries, we utilize word segmentation lattices.
</prevsent>
</prevsection>
<citsent citstr=" N09-1046 ">
these lattices serve to encode alternative ways of segmenting compound words, and as such, when presented as the input to the system allow the decoder to automatically choose which segmentation is best for translation, leading to markedly improved results (dyer, 2009).<papid> N09-1046 </papid>in order to construct diverse and accurate segmentation lattices, we built maximum entropy model of compound word splitting which makes use of small number of dense features, suchas frequency of hypothesized morphemes as separate units in monolingual corpus, number of predicted morphemes, and number of letters in predicted morpheme.</citsent>
<aftsection>
<nextsent>the feature weights are tuned to maximize conditional log-likelihood using small amount of manually created reference lattices which encode linguistically plausible seg ment ations for selected set of compound words.3to create lattices for the dev and test sets, lattice consisting of all possible segment ations for every word consisting of more than 6 letters was created, and the paths were weighted by the posterior probability assigned by the segmentationmodel.
</nextsent>
<nextsent>then, max-marginals were computed using the forward-backward algorithm and used to prune out paths that were greater than factor of 2.3 from the best path, as recommended by dyer2this algorithm is equivalent to the hypergraph mert algorithm described by kumar et al (2009).<papid> P09-1019 </papid></nextsent>
<nextsent>3the reference segmentation lattices used for training are available in the cdec distribution.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3319">
<title id=" W10-1707.xml">the university of maryland statistical machine translation system for the fifth workshop on machine translation </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>these lattices serve to encode alternative ways of segmenting compound words, and as such, when presented as the input to the system allow the decoder to automatically choose which segmentation is best for translation, leading to markedly improved results (dyer, 2009).<papid> N09-1046 </papid>in order to construct diverse and accurate segmentation lattices, we built maximum entropy model of compound word splitting which makes use of small number of dense features, suchas frequency of hypothesized morphemes as separate units in monolingual corpus, number of predicted morphemes, and number of letters in predicted morpheme.</prevsent>
<prevsent>the feature weights are tuned to maximize conditional log-likelihood using small amount of manually created reference lattices which encode linguistically plausible seg ment ations for selected set of compound words.3to create lattices for the dev and test sets, lattice consisting of all possible segment ations for every word consisting of more than 6 letters was created, and the paths were weighted by the posterior probability assigned by the segmentationmodel.</prevsent>
</prevsection>
<citsent citstr=" P09-1019 ">
then, max-marginals were computed using the forward-backward algorithm and used to prune out paths that were greater than factor of 2.3 from the best path, as recommended by dyer2this algorithm is equivalent to the hypergraph mert algorithm described by kumar et al (2009).<papid> P09-1019 </papid></citsent>
<aftsection>
<nextsent>3the reference segmentation lattices used for training are available in the cdec distribution.
</nextsent>
<nextsent>73 (2009).4 to create the translation model for lattice input, we segmented the training data using the1-best segmentation predicted by the segmentation model, and word aligned this with the englishside.
</nextsent>
<nextsent>this version of the parallel corpus was concatenated with the original training parallel corpus.
</nextsent>
<nextsent>this section describes the experiments we performed in attempting to assess the challenges posed by current methods and our exploration of new ones.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3320">
<title id=" W10-1707.xml">the university of maryland statistical machine translation system for the fifth workshop on machine translation </title>
<section> experimental variation.  </section>
<citcontext>
<prevsection>
<prevsent>language models play crucial role in translation performance, both in terms of quality, and in terms of practical aspects such as decoder memory usage and speed.
</prevsent>
<prevsent>unfortunately, these two concerns tend to trade-off one another, as increasing to higher-order more complex language model improves performance, but comes at the cost of increased size and difficulty in deployment.
</prevsent>
</prevsection>
<citsent citstr=" P07-1065 ">
ideally, the language model will be loaded into memory locally by the decoder, but given memory constraints, it is entirely possible that the only option is to resort to remote language model server that needs to be queried, thus introducing significant decoding speed delays.one possible alternative is randomized language model (randlm) (talbot and osborne,2007).<papid> P07-1065 </papid></citsent>
<aftsection>
<nextsent>using bloom filters, which are randomized data structure for set representation, wecan construct language models which significantly decrease space requirements, thus becoming amenable to being stored locally in memory, while only introducing quantifiable number offalse positives.
</nextsent>
<nextsent>in order to assess what the impact on translation quality would be, we train eda system identical to the one described above, except using randlm.
</nextsent>
<nextsent>conveniently, it is possible to construct randlm directly from an existing srilm, which is the route we followed in using the srilm described in section 2.1 to create our randlm.5 table 1 shows the comparison of srilm and randlm with respect to performance on bleu and ter (snover et al, 2006) on the test set.4while normally the forward-backward algorithm computes sum-marginals, by changing the addition operator to max, we can obtain max-marginals.
</nextsent>
<nextsent>5default settings were used for constructing the randlm.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3321">
<title id=" W10-1707.xml">the university of maryland statistical machine translation system for the fifth workshop on machine translation </title>
<section> experimental variation.  </section>
<citcontext>
<prevsection>
<prevsent>5default settings were used for constructing the randlm.
</prevsent>
<prevsent>language model bleu ter randlm 22.4 69.1 srilm 23.1 68.0 table 1: impact of language model on translation 3.2 minimum bayes risk decoding.
</prevsent>
</prevsection>
<citsent citstr=" N04-1022 ">
during minimum error rate training, the decoder employs maximum derivation decision rule.however, upon exploration of alternative strategies, we have found benefits to using minimum risk decision rule (kumar and byrne, 2004), <papid> N04-1022 </papid>wherein we want the translation of the input that has the least expected loss, again as measured by some loss function l: e?</citsent>
<aftsection>
<nextsent>= argmin e?
</nextsent>
<nextsent>ep (e|f )[l(e,e ?)] = argmin e?
</nextsent>
<nextsent>e (e|f )l(e,e?)using our system, we generate unique 500best list of translations to approximate the posterior distribution (e|f ) and the set of possible translations.
</nextsent>
<nextsent>assuming h(e,f ) is the weight of the decoders current path, this can be written as: (e|f ) ? exph(e,f ) where ? is free parameter which depends on the models feature functions and weights as well as pruning method employed, and thus needs to be separately empirically optimized on held out development set.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3324">
<title id=" W10-1707.xml">the university of maryland statistical machine translation system for the fifth workshop on machine translation </title>
<section> experimental variation.  </section>
<citcontext>
<prevsection>
<prevsent>the randlm provides median between the two extremes: reduced memory and (relatively) fast decoding at the price of somewhat decreased translation quality.
</prevsent>
<prevsent>since we are usinga relatively large beam of 1000 candidates for decoding, the time presented in table 3 does not represent an accurate basis for comparison of cdec to other decoders, which should be done using the results presented in dyer et al (2010).
</prevsent>
</prevsection>
<citsent citstr=" P06-1002 ">
we also tried one other grammar extraction configuration, which was with so-called loose phrase extraction heuristics, which permit unaligned words at the edges of phrases (ayan and dorr, 2006).<papid> P06-1002 </papid></citsent>
<aftsection>
<nextsent>when decoded using the srilm and mbr, this achieved the best performance for our system, with bleu score of 23.6 and ter of 67.7.
</nextsent>
<nextsent>we presented the university of maryland hierarchical phrase-based system for the wmt2010shared translation task.
</nextsent>
<nextsent>using cdec, we experimented with number of methods that are shown above to lead to improved german-to-english translation quality over our baseline according to bleu and ter evaluation.
</nextsent>
<nextsent>these include method sto directly address german morphological complexity, such as appropriate feature functions, segmentation lattices, and model for automatically constructing the lattices, as well as alternative decoding strategies, such asmbr.we also presented 75 several language model configuration alternatives,as well as grammar extraction methods, and emphasized the trade-off that must be made between decoding time, memory overhead, and translation quality in current statistical machine translation systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3325">
<title id=" W10-1602.xml">data driven computational linguistics at famafunc argentina </title>
<section> natural language parsing and.  </section>
<citcontext>
<prevsection>
<prevsent>it turns out that the resulting class of languages is more general than unts grammars: they are pac learn able, they can be learned with the same learning algorithm as unts and, moreover, their upper bound for performance is much higher thanfor unts.
</prevsent>
<prevsent>still, it might be the case that the existing algorithm for finding unts is not the right one for learning the structure of treebank, it might bethe case that strings in the ptb have not been produced by k-l-unts grammar.
</prevsent>
</prevsection>
<citsent citstr=" P04-1061 ">
we are currently investigating how to produce an algorithm that fits better the structure given in treebank.learning structure using probabilistic automata dmv+ccm (klein and manning, 2004; <papid> P04-1061 </papid>klein and manning, 2002) <papid> P02-1017 </papid>is probabilistic model for unsupervised parsing, that can be successfully trained with the em algorithm to achieve state of the art performance.</citsent>
<aftsection>
<nextsent>it is the combination of the constituent-context model, that models unlabeled constituent parsing, and the dependency model with valence, that models projective dependency parsing.
</nextsent>
<nextsent>on the other hand, ccm encodes the probability that given string of pos tags is constituent.
</nextsent>
<nextsent>dmv is more of our interest in this work, because it encodesa top-down generative process where the heads generate their dependents to both directions until thereis decision to stop, in way that resembles successful supervised dependency models such as in (collins, 1999).
</nextsent>
<nextsent>the generation of dependents ofa head on specific direction can be seen as an implicit probabilistic regular language generated by probabilistic deterministic finite automaton.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3326">
<title id=" W10-1602.xml">data driven computational linguistics at famafunc argentina </title>
<section> natural language parsing and.  </section>
<citcontext>
<prevsection>
<prevsent>it turns out that the resulting class of languages is more general than unts grammars: they are pac learn able, they can be learned with the same learning algorithm as unts and, moreover, their upper bound for performance is much higher thanfor unts.
</prevsent>
<prevsent>still, it might be the case that the existing algorithm for finding unts is not the right one for learning the structure of treebank, it might bethe case that strings in the ptb have not been produced by k-l-unts grammar.
</prevsent>
</prevsection>
<citsent citstr=" P02-1017 ">
we are currently investigating how to produce an algorithm that fits better the structure given in treebank.learning structure using probabilistic automata dmv+ccm (klein and manning, 2004; <papid> P04-1061 </papid>klein and manning, 2002) <papid> P02-1017 </papid>is probabilistic model for unsupervised parsing, that can be successfully trained with the em algorithm to achieve state of the art performance.</citsent>
<aftsection>
<nextsent>it is the combination of the constituent-context model, that models unlabeled constituent parsing, and the dependency model with valence, that models projective dependency parsing.
</nextsent>
<nextsent>on the other hand, ccm encodes the probability that given string of pos tags is constituent.
</nextsent>
<nextsent>dmv is more of our interest in this work, because it encodesa top-down generative process where the heads generate their dependents to both directions until thereis decision to stop, in way that resembles successful supervised dependency models such as in (collins, 1999).
</nextsent>
<nextsent>the generation of dependents ofa head on specific direction can be seen as an implicit probabilistic regular language generated by probabilistic deterministic finite automaton.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3327">
<title id=" W10-1602.xml">data driven computational linguistics at famafunc argentina </title>
<section> data-driven characterisation of.  </section>
<citcontext>
<prevsection>
<prevsent>a corpus of news paper advertisements and corpus of short text messages are underway.normalization of text bringing ortographic variants of word (mostly abbreviations) to canonical form.
</prevsent>
<prevsent>to do that, we apply machine learning techniques to learn the parameters for edit distances, as in (gomez-ballester et al, 1997; ristad and yanilos, 1998; bilenko and mooney, 2003; mccallum et al, 2005; oncina and sebban, 2006).
</prevsent>
</prevsection>
<citsent citstr=" C08-1083 ">
we build upon previous work on normalization by (choudhury et al,2007; okazaki et al, 2008; <papid> C08-1083 </papid>cook and stevenson, 2009; <papid> W09-2010 </papid>stevenson et al, 2009).</citsent>
<aftsection>
<nextsent>preliminary results show significant improvement of learned distances over standard distances.
</nextsent>
<nextsent>11syntactic analysis applying robust shallow parsing approach aimed to identify entities and their modifiers.
</nextsent>
<nextsent>ontology induction from very restricted domains, to aid generalization in the step of information extraction.
</nextsent>
<nextsent>we will be following the approach presented in (michelson and knob lock, 2009).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3328">
<title id=" W10-1602.xml">data driven computational linguistics at famafunc argentina </title>
<section> data-driven characterisation of.  </section>
<citcontext>
<prevsection>
<prevsent>a corpus of news paper advertisements and corpus of short text messages are underway.normalization of text bringing ortographic variants of word (mostly abbreviations) to canonical form.
</prevsent>
<prevsent>to do that, we apply machine learning techniques to learn the parameters for edit distances, as in (gomez-ballester et al, 1997; ristad and yanilos, 1998; bilenko and mooney, 2003; mccallum et al, 2005; oncina and sebban, 2006).
</prevsent>
</prevsection>
<citsent citstr=" W09-2010 ">
we build upon previous work on normalization by (choudhury et al,2007; okazaki et al, 2008; <papid> C08-1083 </papid>cook and stevenson, 2009; <papid> W09-2010 </papid>stevenson et al, 2009).</citsent>
<aftsection>
<nextsent>preliminary results show significant improvement of learned distances over standard distances.
</nextsent>
<nextsent>11syntactic analysis applying robust shallow parsing approach aimed to identify entities and their modifiers.
</nextsent>
<nextsent>ontology induction from very restricted domains, to aid generalization in the step of information extraction.
</nextsent>
<nextsent>we will be following the approach presented in (michelson and knob lock, 2009).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3329">
<title id=" W10-2106.xml">a cross lingual induction technique for german adverbial participles </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>since adverbs are often overtly marked in other languages (i.e. the ly-suffix inenglish), adverbial participles can be straight for wadly detected on word-aligned parallel text.
</prevsent>
<prevsent>we describe the ingretation of the automatically induced resource of adverbial participles into the german lfg, and provide detailed evaluation of its effect on the grammar, see section 5.
</prevsent>
</prevsection>
<citsent citstr=" H01-1035 ">
while the use of parallel resources is rather familiar in wide range of nlp domains, such as statistical machine translation (koehn, 2005) or annotation projection (yarowsky et al, 2001), <papid> H01-1035 </papid>our work shows that they can be exploited forvery specific problems that arise in deep linguistic analysis (see section 4).</citsent>
<aftsection>
<nextsent>in this way, high precision, data-oriented induction techniques can clearly improve rule-based system development through combining the benefits of high empirical accuracy and little manual effort.
</nextsent>
<nextsent>lexical functional grammar (lfg) (bresnan, 2000) is constraint-based theory of grammar.
</nextsent>
<nextsent>it posits two levels of representation, c(onstituent) structure and f(unctional)- structure.
</nextsent>
<nextsent>c-structure is represented by context free phrase-structuretrees, and captures surface grammatical configurations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3330">
<title id=" W10-2106.xml">a cross lingual induction technique for german adverbial participles </title>
<section> a broad-coverage lfg for german </section>
<citcontext>
<prevsection>
<prevsent>c-structure is represented by context free phrase-structuretrees, and captures surface grammatical configurations.
</prevsent>
<prevsent>f-structures approximate basic predicate argument and adjunct structures.
</prevsent>
</prevsection>
<citsent citstr=" W02-1503 ">
the experiments reported in this paper use the german lfg grammar constructed as part of the pargram project (butt et al, 2002).<papid> W02-1503 </papid></citsent>
<aftsection>
<nextsent>the gram maris implemented in the xle, grammar development environment which includes very efficient lfg parser.
</nextsent>
<nextsent>within the spectrum of appraochesto natural language parsing, xle can be considered hybrid system combining hand-crafted grammar with number of automatic ambiguity management techniques: (i) c-structure pruning where, based on information from statstically obtained parses, some trees are ruled out before structure unification (cahill et al, 2007), (ii) an optimaly theory-style constraint mechanism for filtering and ranking competing analyses (frank et al, 2001), and (iii) stochastic disambiguation component which is based on log-linear probability model (riezler et al, 2002) <papid> P02-1035 </papid>and works on the packed representations.the german lfg grammar integrates morphological component which is variant ofdmor1 (becker, 2001).</nextsent>
<nextsent>this means that the (internal) lexicon does not comprise entries for surface word forms, but entries for specific morphological tags, see (dipper, 2003).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3331">
<title id=" W10-2106.xml">a cross lingual induction technique for german adverbial participles </title>
<section> a broad-coverage lfg for german </section>
<citcontext>
<prevsection>
<prevsent>the experiments reported in this paper use the german lfg grammar constructed as part of the pargram project (butt et al, 2002).<papid> W02-1503 </papid></prevsent>
<prevsent>the gram maris implemented in the xle, grammar development environment which includes very efficient lfg parser.</prevsent>
</prevsection>
<citsent citstr=" P02-1035 ">
within the spectrum of appraochesto natural language parsing, xle can be considered hybrid system combining hand-crafted grammar with number of automatic ambiguity management techniques: (i) c-structure pruning where, based on information from statstically obtained parses, some trees are ruled out before structure unification (cahill et al, 2007), (ii) an optimaly theory-style constraint mechanism for filtering and ranking competing analyses (frank et al, 2001), and (iii) stochastic disambiguation component which is based on log-linear probability model (riezler et al, 2002) <papid> P02-1035 </papid>and works on the packed representations.the german lfg grammar integrates morphological component which is variant ofdmor1 (becker, 2001).</citsent>
<aftsection>
<nextsent>this means that the (internal) lexicon does not comprise entries for surface word forms, but entries for specific morphological tags, see (dipper, 2003).
</nextsent>
<nextsent>3.1 analysis.
</nextsent>
<nextsent>the morphosyntactic ambiguity of german participles presents notorious difficulty for theoretical and computational analysis.
</nextsent>
<nextsent>the reason is that adjectives (i.e. adjectival participles) do not only occur as attributive modifiers (shown in (1-a)), but can also be used as predicatives (see (2-b)).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3332">
<title id=" W10-2106.xml">a cross lingual induction technique for german adverbial participles </title>
<section> cross-lingual induction of adverbial.  </section>
<citcontext>
<prevsection>
<prevsent>4.1 data.
</prevsent>
<prevsent>we base our experiments on the german, english, french and dutch part of the europarl corpus.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
we automatically word-aligned the german part to each of the others with the giza++ tool(och and ney, 2003).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>note that, due to divergences in sentence alignment and tokenisation,the three word-alignments are not completely synchronised.
</nextsent>
<nextsent>moreover, each of the 4 languages hasbeen automatically pos tagged using the treetag ger (schmid, 1994).
</nextsent>
<nextsent>in addition, the german and english parts have been parsed with malt parser (nivre et al, 2006).
</nextsent>
<nextsent>since we want to limit our investigation to thoseparticiples that are not already recorded as lexicalised adjective or adverb in the dmor morphology, we first have to generate the set of participlecandidates from the tagged europarl data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3333">
<title id=" W10-2211.xml">morpho challenge 20052010 evaluations and results </title>
<section> definition of the challenge.  </section>
<citcontext>
<prevsection>
<prevsent>moreover, while there exists fair amount of research and now even books on semi-supervised learning (zhu, 2005; abney, 2007; zhu, 2010), it has not been as widely studied for structured classification problems like sequence segmentation and labeling (cf.
</prevsent>
<prevsent>e.g.
</prevsent>
</prevsection>
<citsent citstr=" P06-1027 ">
(jiao et al, 2006)).<papid> P06-1027 </papid></citsent>
<aftsection>
<nextsent>the semi-supervised learning challenge introduced for morpho challenge 2010 can thus be viewed as an opportunity to strengthen research in both morphology modeling as well as in semi-supervised learning for sequence segmentation and labeling in general.
</nextsent>
<nextsent>competitions so far 3.1 evaluation tasks, metrics, and languages.
</nextsent>
<nextsent>the evaluation tasks and languages selected for morpho challenge evaluations are shown in figure 1.
</nextsent>
<nextsent>the languages where evaluations have been prepared are finnish (fin), turkish (tur), english (eng), german (ger), and arabic (ara).first the morphemes are compared to linguistic gold standards in direct morpheme segmentation (2005) and full morpheme analysis (since2007).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3334">
<title id=" W10-2211.xml">morpho challenge 20052010 evaluations and results </title>
<section> review of morpho challenge.  </section>
<citcontext>
<prevsection>
<prevsent>in the machine translation tasks used in the morpho challenge, the focus has so far been inthe alignment problem.
</prevsent>
<prevsent>in the evaluation tasks introduced in 2009 the language-pairs were finnish english and german-english.
</prevsent>
</prevsection>
<citsent citstr=" N09-2019 ">
to obtain state-of the-art results, the evaluation consists of minimum bayes risk (mbr) combination of two translation systems trained on the same data, one using words and the other morphemes as the basic modeling units (de gispert et al, 2009).<papid> N09-2019 </papid></citsent>
<aftsection>
<nextsent>the various morpheme analysis algorithms are compared by measuring the translation performance for different two-model combinations where the word-based model is always the same, but the morpheme-based model is trained based on units from each of the algorithms in turns.
</nextsent>
<nextsent>because the machine translation evaluation has yet been tried only in 2009, it is difficult to draw conclusions about the results yet.
</nextsent>
<nextsent>however, themorfessor baseline algorithm seems to be particularly difficult to beat both in finnish-german and german-english task.
</nextsent>
<nextsent>the differences between the best results are small, but the ranking in both tasks was the same: 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3335">
<title id=" W10-2211.xml">morpho challenge 20052010 evaluations and results </title>
<section> review of morpho challenge.  </section>
<citcontext>
<prevsection>
<prevsent>3.2 evaluated algorithms.
</prevsent>
<prevsent>this section attempts to describe very briefly some of the individual morpheme analysis algorithms that have been most successful in the evaluations.
</prevsent>
</prevsection>
<citsent citstr=" W02-0603 ">
morfessor baseline (creutz and lagus, 2002): <papid> W02-0603 </papid>this is public baseline algorithm based on jointly minimizing the size of the morph code book and the encoded size of the all the word forms using the minimum description length mdl cost func tion.</citsent>
<aftsection>
<nextsent>the performance is above average for all evaluated tasks in most languages.allomorfessor (kohonen et al, 2009; virpioja and kohonen, 2009): the development of this method was based on the observation that the 92 finnish german english 0.25 0.3 0.35 0.4 0.45 0.5 0.55 morfessor baseline 2007 bernhard.
</nextsent>
<nextsent>2008 mcnamee 4gram.
</nextsent>
<nextsent>2008 monson p+m. 2009 monson pmu.
</nextsent>
<nextsent>2009 lignos.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3336">
<title id=" W10-2918.xml">a comparative study of bayesian models for unsupervised sentiment detection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>driven by the demand of gleaning insights of such great amounts of user-generated data, work on new methodologies for automated sentiment analysis has bloomed splendidly.
</prevsent>
<prevsent>compared to the traditional topic-based text classification, sentiment classification is deemed to be more challenging as sentiment is often embodied in subtle linguistic mechanisms such as the use of sarcasm or incorporated with highly domain-specific information.
</prevsent>
</prevsection>
<citsent citstr=" W02-1011 ">
although the task of identifying the overall sentiment polarity of document has been well studied, most of the work is highly domain dependent and favoured in supervised learning (pang et al , 2002; <papid> W02-1011 </papid>pang and lee, 2004; <papid> P04-1035 </papid>whitelaw et al , 2005; kennedy and inkpen, 2006; mcdonald et al , 2007), <papid> P07-1055 </papid>requiring annotated corpora for every possible do main of interest, which is impractical for realapplications.</citsent>
<aftsection>
<nextsent>also, it is well-known that sentiment classifiers trained on one domain often failto produce satisfactory results when shifted to an other domain, since sentiment expression can bequite different in different domains (aue and ga mon, 2005).
</nextsent>
<nextsent>moreover, aside from the diversity of genres and large-scale size of web corpora, user-generated contents evolve rapidly over time, which demands much more efficient algorithms for sentiment analysis than the current approaches can offer.
</nextsent>
<nextsent>these observations have thus motivated the problem of using unsupervised approaches fordomain-independent joint sentiment topic detection.
</nextsent>
<nextsent>some recent research efforts have been made to adapt sentiment classifiers trained on one domain to another domain (aue and gamon, 2005; blitzer et al , 2007; <papid> P07-1056 </papid>li and zong, 2008; <papid> P08-2065 </papid>andreevskaia and bergler, 2008).<papid> P08-1034 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3338">
<title id=" W10-2918.xml">a comparative study of bayesian models for unsupervised sentiment detection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>driven by the demand of gleaning insights of such great amounts of user-generated data, work on new methodologies for automated sentiment analysis has bloomed splendidly.
</prevsent>
<prevsent>compared to the traditional topic-based text classification, sentiment classification is deemed to be more challenging as sentiment is often embodied in subtle linguistic mechanisms such as the use of sarcasm or incorporated with highly domain-specific information.
</prevsent>
</prevsection>
<citsent citstr=" P04-1035 ">
although the task of identifying the overall sentiment polarity of document has been well studied, most of the work is highly domain dependent and favoured in supervised learning (pang et al , 2002; <papid> W02-1011 </papid>pang and lee, 2004; <papid> P04-1035 </papid>whitelaw et al , 2005; kennedy and inkpen, 2006; mcdonald et al , 2007), <papid> P07-1055 </papid>requiring annotated corpora for every possible do main of interest, which is impractical for realapplications.</citsent>
<aftsection>
<nextsent>also, it is well-known that sentiment classifiers trained on one domain often failto produce satisfactory results when shifted to an other domain, since sentiment expression can bequite different in different domains (aue and ga mon, 2005).
</nextsent>
<nextsent>moreover, aside from the diversity of genres and large-scale size of web corpora, user-generated contents evolve rapidly over time, which demands much more efficient algorithms for sentiment analysis than the current approaches can offer.
</nextsent>
<nextsent>these observations have thus motivated the problem of using unsupervised approaches fordomain-independent joint sentiment topic detection.
</nextsent>
<nextsent>some recent research efforts have been made to adapt sentiment classifiers trained on one domain to another domain (aue and gamon, 2005; blitzer et al , 2007; <papid> P07-1056 </papid>li and zong, 2008; <papid> P08-2065 </papid>andreevskaia and bergler, 2008).<papid> P08-1034 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3340">
<title id=" W10-2918.xml">a comparative study of bayesian models for unsupervised sentiment detection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>driven by the demand of gleaning insights of such great amounts of user-generated data, work on new methodologies for automated sentiment analysis has bloomed splendidly.
</prevsent>
<prevsent>compared to the traditional topic-based text classification, sentiment classification is deemed to be more challenging as sentiment is often embodied in subtle linguistic mechanisms such as the use of sarcasm or incorporated with highly domain-specific information.
</prevsent>
</prevsection>
<citsent citstr=" P07-1055 ">
although the task of identifying the overall sentiment polarity of document has been well studied, most of the work is highly domain dependent and favoured in supervised learning (pang et al , 2002; <papid> W02-1011 </papid>pang and lee, 2004; <papid> P04-1035 </papid>whitelaw et al , 2005; kennedy and inkpen, 2006; mcdonald et al , 2007), <papid> P07-1055 </papid>requiring annotated corpora for every possible do main of interest, which is impractical for realapplications.</citsent>
<aftsection>
<nextsent>also, it is well-known that sentiment classifiers trained on one domain often failto produce satisfactory results when shifted to an other domain, since sentiment expression can bequite different in different domains (aue and ga mon, 2005).
</nextsent>
<nextsent>moreover, aside from the diversity of genres and large-scale size of web corpora, user-generated contents evolve rapidly over time, which demands much more efficient algorithms for sentiment analysis than the current approaches can offer.
</nextsent>
<nextsent>these observations have thus motivated the problem of using unsupervised approaches fordomain-independent joint sentiment topic detection.
</nextsent>
<nextsent>some recent research efforts have been made to adapt sentiment classifiers trained on one domain to another domain (aue and gamon, 2005; blitzer et al , 2007; <papid> P07-1056 </papid>li and zong, 2008; <papid> P08-2065 </papid>andreevskaia and bergler, 2008).<papid> P08-1034 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3341">
<title id=" W10-2918.xml">a comparative study of bayesian models for unsupervised sentiment detection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>moreover, aside from the diversity of genres and large-scale size of web corpora, user-generated contents evolve rapidly over time, which demands much more efficient algorithms for sentiment analysis than the current approaches can offer.
</prevsent>
<prevsent>these observations have thus motivated the problem of using unsupervised approaches fordomain-independent joint sentiment topic detection.
</prevsent>
</prevsection>
<citsent citstr=" P07-1056 ">
some recent research efforts have been made to adapt sentiment classifiers trained on one domain to another domain (aue and gamon, 2005; blitzer et al , 2007; <papid> P07-1056 </papid>li and zong, 2008; <papid> P08-2065 </papid>andreevskaia and bergler, 2008).<papid> P08-1034 </papid></citsent>
<aftsection>
<nextsent>however, the adaption performance of these lines of work pretty much depends on the distribution similarity between the source and target domain, and considerable effort is still required to obtain labelled data for training.
</nextsent>
<nextsent>intuitively, sentiment polarities are dependent on contextual information, such as topics or domains.
</nextsent>
<nextsent>in this regard, some recent work (mei et al ., 2007; titov and mcdonald, 2008<papid> P08-1036 </papid>a) has tried to model both sentiment and topics.</nextsent>
<nextsent>however, these two models either require postprocessing to calculate the positive/negative coverage in document for polarity identification (mei et al , 2007) or re 144 quire some kind of supervised setting in which review text should contain ratings for aspects of interest (titov and mcdonald, 2008<papid> P08-1036 </papid>a).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3342">
<title id=" W10-2918.xml">a comparative study of bayesian models for unsupervised sentiment detection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>moreover, aside from the diversity of genres and large-scale size of web corpora, user-generated contents evolve rapidly over time, which demands much more efficient algorithms for sentiment analysis than the current approaches can offer.
</prevsent>
<prevsent>these observations have thus motivated the problem of using unsupervised approaches fordomain-independent joint sentiment topic detection.
</prevsent>
</prevsection>
<citsent citstr=" P08-2065 ">
some recent research efforts have been made to adapt sentiment classifiers trained on one domain to another domain (aue and gamon, 2005; blitzer et al , 2007; <papid> P07-1056 </papid>li and zong, 2008; <papid> P08-2065 </papid>andreevskaia and bergler, 2008).<papid> P08-1034 </papid></citsent>
<aftsection>
<nextsent>however, the adaption performance of these lines of work pretty much depends on the distribution similarity between the source and target domain, and considerable effort is still required to obtain labelled data for training.
</nextsent>
<nextsent>intuitively, sentiment polarities are dependent on contextual information, such as topics or domains.
</nextsent>
<nextsent>in this regard, some recent work (mei et al ., 2007; titov and mcdonald, 2008<papid> P08-1036 </papid>a) has tried to model both sentiment and topics.</nextsent>
<nextsent>however, these two models either require postprocessing to calculate the positive/negative coverage in document for polarity identification (mei et al , 2007) or re 144 quire some kind of supervised setting in which review text should contain ratings for aspects of interest (titov and mcdonald, 2008<papid> P08-1036 </papid>a).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3343">
<title id=" W10-2918.xml">a comparative study of bayesian models for unsupervised sentiment detection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>moreover, aside from the diversity of genres and large-scale size of web corpora, user-generated contents evolve rapidly over time, which demands much more efficient algorithms for sentiment analysis than the current approaches can offer.
</prevsent>
<prevsent>these observations have thus motivated the problem of using unsupervised approaches fordomain-independent joint sentiment topic detection.
</prevsent>
</prevsection>
<citsent citstr=" P08-1034 ">
some recent research efforts have been made to adapt sentiment classifiers trained on one domain to another domain (aue and gamon, 2005; blitzer et al , 2007; <papid> P07-1056 </papid>li and zong, 2008; <papid> P08-2065 </papid>andreevskaia and bergler, 2008).<papid> P08-1034 </papid></citsent>
<aftsection>
<nextsent>however, the adaption performance of these lines of work pretty much depends on the distribution similarity between the source and target domain, and considerable effort is still required to obtain labelled data for training.
</nextsent>
<nextsent>intuitively, sentiment polarities are dependent on contextual information, such as topics or domains.
</nextsent>
<nextsent>in this regard, some recent work (mei et al ., 2007; titov and mcdonald, 2008<papid> P08-1036 </papid>a) has tried to model both sentiment and topics.</nextsent>
<nextsent>however, these two models either require postprocessing to calculate the positive/negative coverage in document for polarity identification (mei et al , 2007) or re 144 quire some kind of supervised setting in which review text should contain ratings for aspects of interest (titov and mcdonald, 2008<papid> P08-1036 </papid>a).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3344">
<title id=" W10-2918.xml">a comparative study of bayesian models for unsupervised sentiment detection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, the adaption performance of these lines of work pretty much depends on the distribution similarity between the source and target domain, and considerable effort is still required to obtain labelled data for training.
</prevsent>
<prevsent>intuitively, sentiment polarities are dependent on contextual information, such as topics or domains.
</prevsent>
</prevsection>
<citsent citstr=" P08-1036 ">
in this regard, some recent work (mei et al ., 2007; titov and mcdonald, 2008<papid> P08-1036 </papid>a) has tried to model both sentiment and topics.</citsent>
<aftsection>
<nextsent>however, these two models either require postprocessing to calculate the positive/negative coverage in document for polarity identification (mei et al , 2007) or re 144 quire some kind of supervised setting in which review text should contain ratings for aspects of interest (titov and mcdonald, 2008<papid> P08-1036 </papid>a).</nextsent>
<nextsent>more recently, dasgupta and ng (2009) <papid> D09-1061 </papid>proposed an unsupervised sentiment classification algorithm by integrating user feed backs into spectral clustering algorithm.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3352">
<title id=" W10-2918.xml">a comparative study of bayesian models for unsupervised sentiment detection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this regard, some recent work (mei et al ., 2007; titov and mcdonald, 2008<papid> P08-1036 </papid>a) has tried to model both sentiment and topics.</prevsent>
<prevsent>however, these two models either require postprocessing to calculate the positive/negative coverage in document for polarity identification (mei et al , 2007) or re 144 quire some kind of supervised setting in which review text should contain ratings for aspects of interest (titov and mcdonald, 2008<papid> P08-1036 </papid>a).</prevsent>
</prevsection>
<citsent citstr=" D09-1061 ">
more recently, dasgupta and ng (2009) <papid> D09-1061 </papid>proposed an unsupervised sentiment classification algorithm by integrating user feed backs into spectral clustering algorithm.</citsent>
<aftsection>
<nextsent>features induced for each dimension of spectral clustering can be considered as sentiment oriented topics.
</nextsent>
<nextsent>nevertheless, human judgement of identifying the most important dimensions during spectral clustering is required.lin and he (2009) proposed joint sentiment topic (jst) model for unsupervised joint sentiment topic detection.
</nextsent>
<nextsent>they assumed that topics are generated dependent on sentiment distributions and then words are generated conditioned on sentiment-topic pairs.
</nextsent>
<nextsent>while this is reasonable design choice, one may argue that the reverse is also true that sentiments may vary according to topics.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3378">
<title id=" W10-2918.xml">a comparative study of bayesian models for unsupervised sentiment detection </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>features induced for each dimension of spectral clustering can be considered as sentiment-oriented topics.
</prevsent>
<prevsent>nevertheless, human judgement of identifying the most important dimensions during spectral clustering is required.among various efforts for improving sentiment detection accuracy, one direction is to incorporate prior information or subjectivity lexicon (i.e., words bearing positive or negative sentiment) into the sentiment model.
</prevsent>
</prevsection>
<citsent citstr=" P06-2059 ">
such sentiment lexicons can be acquired from domain independent sources in many different ways, from manually built appraisal groups (whitelaw et al ., 2005), to semi-automatically (abbasi et al ,2008) and fully automatically (kaji and kitsuregawa, 2006) <papid> P06-2059 </papid>constructed lexicons.</citsent>
<aftsection>
<nextsent>when incorporating lexical knowledge as prior information into sentiment-topic model, andreevskaia and bergler (2008) <papid> P08-1034 </papid>integrated the lexicon-based andcorpus-based approaches for sentence-level sentiment annotation across different domains; li et al .</nextsent>
<nextsent>(2009) employed lexical prior knowledge for semi-supervised sentiment classification based on non-negative matrix tri-factorization, where thedomain-independent prior knowledge was incorporated in conjunction with domain-dependent un labelled data and few labelled documents.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3386">
<title id=" W10-2918.xml">a comparative study of bayesian models for unsupervised sentiment detection </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>aaccuracy (%) mds mr subjmr book dvd electronic kitchen mds overall lsm (without prior info.)
</prevsent>
<prevsent>61.7 57.9 51.6 53.5 58.4 56.8 55.1 lsm (with prior info.)
</prevsent>
</prevsection>
<citsent citstr=" P09-1028 ">
74.1 76.1 64.2 66.3 72.5 74.1 69.3 dasgupta and ng (2009) <papid> D09-1061 </papid>70.9 n/a 69.5 70.8 65.8 69.7 68.9 li et al (2009) <papid> P09-1028 </papid>with 10% doc.</citsent>
<aftsection>
<nextsent>label 60 n/a n/a 62li et al (2009) <papid> P09-1028 </papid>with 40% doc.</nextsent>
<nextsent>label 73.5 n/a 73</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3394">
<title id=" W10-3013.xml">hedge detection and scope finding by sequence labeling with procedural feature selection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>furthermore, post-deadline experiments show that the performance can be much further improved using sufficient feature selection.
</prevsent>
<prevsent>hedges are linguistic devices representing speculative parts of articles.
</prevsent>
</prevsection>
<citsent citstr=" W04-3103 ">
previous works such as (hyland, 1996; marco and mercer, 2004; light et al., 2004; <papid> W04-3103 </papid>thompson et al, 2008) present research on hedge mainly as linguistic phenomenon.meanwhile, detecting hedges and their scopes automatically are increasingly important tasks in natural language processing and information extraction, especially in biomedical community.</citsent>
<aftsection>
<nextsent>the shared task of conll-2010 described in farkas et al (2010) aims at detecting hedges (task 1) and finding their scopes (task 2) for the literature ? this work is partially supported by the national natural science foundation of china (grants 60903119,60773090, 90820018 and 90920004), the national basic research program of china (grant no. 2009cb320901), and the national high-tech research program of china (grant no.2008aa02z315).
</nextsent>
<nextsent>corresponding author from bio scope corpus (szarvas et al, 2008) andwikipedia.
</nextsent>
<nextsent>this paper describes system adopting sequence labeling which performs competitive in the official evaluation, as well as further test.in addition, large-scale feature selection procedure is applied in training and development.
</nextsent>
<nextsent>considering that bio scope corpus is annotated by two independent linguists according to formal guide line (szarvas, 2008), while wikipedia weasels are tagged by netizens who are diverse in background and various in evaluation criterion, it is needed to handle them separately.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3396">
<title id=" W10-3013.xml">hedge detection and scope finding by sequence labeling with procedural feature selection </title>
<section> feature selection.  </section>
<citcontext>
<prevsection>
<prevsent>a) hedge cue labeling b) scope labeling the first one is the same as hedge detection task in strategy, but quite distinct in target of feature set, because hedge detection is task of sentence classification while the first step of scope finding aims at high accuracy of labeling hedge cues.therefore, three independent procedures of feature selection are conducted for bio scope corpus dataset.
</prevsent>
<prevsent>as wikipedia is not involved in the task of scope finding, it only needs one final feature set.about 200 feature templates are initially considered for each task.
</prevsent>
</prevsection>
<citsent citstr=" W08-0607 ">
we mainly borrow ideas andare enlightened by following sources while initial izing feature template sets: a) previous papers on hedge detection and scope finding (light et al, 2004; <papid> W04-3103 </papid>medlock, 2008; medlock and briscoe, 2008; kilicoglu and bergler, 2008; <papid> W08-0607 </papid>szarvas, 2008; ganter and strube, 2009; <papid> P09-2044 </papid>morante and daelemans, 2009); 94b) related works such as named entity recognition (collins, 1999) and text chunking (zhang et al, 2001); c) some literature on dependency parsing (nivre and scholz, 2004; mcdonald et al, 2005; <papid> H05-1066 </papid>nivre, 2009; zhao et al, 2009c; zhao et al, 2009a); 3.1 notations of feature template.</citsent>
<aftsection>
<nextsent>a large amount of advanced syntactic features including syntactic connections, paths, families and their concatenations are introduced.
</nextsent>
<nextsent>many of these features come from dependency parsing, which aims at building syntactic tree expressed by dependencies between words.
</nextsent>
<nextsent>more details about dependency parsing are given in nivre and scholz (2004) and mcdonald et al (2005).<papid> H05-1066 </papid></nextsent>
<nextsent>the pars erin zhao et al (2009a) is used to construct dependency structures in our system, and some of the notations in this paper adopt those presented in zhao et al (2009c).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3397">
<title id=" W10-3013.xml">hedge detection and scope finding by sequence labeling with procedural feature selection </title>
<section> feature selection.  </section>
<citcontext>
<prevsection>
<prevsent>a) hedge cue labeling b) scope labeling the first one is the same as hedge detection task in strategy, but quite distinct in target of feature set, because hedge detection is task of sentence classification while the first step of scope finding aims at high accuracy of labeling hedge cues.therefore, three independent procedures of feature selection are conducted for bio scope corpus dataset.
</prevsent>
<prevsent>as wikipedia is not involved in the task of scope finding, it only needs one final feature set.about 200 feature templates are initially considered for each task.
</prevsent>
</prevsection>
<citsent citstr=" P09-2044 ">
we mainly borrow ideas andare enlightened by following sources while initial izing feature template sets: a) previous papers on hedge detection and scope finding (light et al, 2004; <papid> W04-3103 </papid>medlock, 2008; medlock and briscoe, 2008; kilicoglu and bergler, 2008; <papid> W08-0607 </papid>szarvas, 2008; ganter and strube, 2009; <papid> P09-2044 </papid>morante and daelemans, 2009); 94b) related works such as named entity recognition (collins, 1999) and text chunking (zhang et al, 2001); c) some literature on dependency parsing (nivre and scholz, 2004; mcdonald et al, 2005; <papid> H05-1066 </papid>nivre, 2009; zhao et al, 2009c; zhao et al, 2009a); 3.1 notations of feature template.</citsent>
<aftsection>
<nextsent>a large amount of advanced syntactic features including syntactic connections, paths, families and their concatenations are introduced.
</nextsent>
<nextsent>many of these features come from dependency parsing, which aims at building syntactic tree expressed by dependencies between words.
</nextsent>
<nextsent>more details about dependency parsing are given in nivre and scholz (2004) and mcdonald et al (2005).<papid> H05-1066 </papid></nextsent>
<nextsent>the pars erin zhao et al (2009a) is used to construct dependency structures in our system, and some of the notations in this paper adopt those presented in zhao et al (2009c).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3398">
<title id=" W10-3013.xml">hedge detection and scope finding by sequence labeling with procedural feature selection </title>
<section> feature selection.  </section>
<citcontext>
<prevsection>
<prevsent>a) hedge cue labeling b) scope labeling the first one is the same as hedge detection task in strategy, but quite distinct in target of feature set, because hedge detection is task of sentence classification while the first step of scope finding aims at high accuracy of labeling hedge cues.therefore, three independent procedures of feature selection are conducted for bio scope corpus dataset.
</prevsent>
<prevsent>as wikipedia is not involved in the task of scope finding, it only needs one final feature set.about 200 feature templates are initially considered for each task.
</prevsent>
</prevsection>
<citsent citstr=" H05-1066 ">
we mainly borrow ideas andare enlightened by following sources while initial izing feature template sets: a) previous papers on hedge detection and scope finding (light et al, 2004; <papid> W04-3103 </papid>medlock, 2008; medlock and briscoe, 2008; kilicoglu and bergler, 2008; <papid> W08-0607 </papid>szarvas, 2008; ganter and strube, 2009; <papid> P09-2044 </papid>morante and daelemans, 2009); 94b) related works such as named entity recognition (collins, 1999) and text chunking (zhang et al, 2001); c) some literature on dependency parsing (nivre and scholz, 2004; mcdonald et al, 2005; <papid> H05-1066 </papid>nivre, 2009; zhao et al, 2009c; zhao et al, 2009a); 3.1 notations of feature template.</citsent>
<aftsection>
<nextsent>a large amount of advanced syntactic features including syntactic connections, paths, families and their concatenations are introduced.
</nextsent>
<nextsent>many of these features come from dependency parsing, which aims at building syntactic tree expressed by dependencies between words.
</nextsent>
<nextsent>more details about dependency parsing are given in nivre and scholz (2004) and mcdonald et al (2005).<papid> H05-1066 </papid></nextsent>
<nextsent>the pars erin zhao et al (2009a) is used to construct dependency structures in our system, and some of the notations in this paper adopt those presented in zhao et al (2009c).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3401">
<title id=" W10-2004.xml">hhmm parsing with limited parallelism </title>
<section> abstract </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" C08-1099 ">
hierarchical hidden markov model (hhmm) parsers have been proposed as psycho linguistic models due to their broad coverage within human-like working memory limits (schuler et al, 2008) <papid> C08-1099 </papid>and ability to model human reading time behavior according to various complexity metrics (wu et al, 2010).</citsent>
<aftsection>
<nextsent>but hhmms have been evaluated previously only with very wide beams of several thousand parallel hypotheses, weakening claims to the models efficiency and psychological relevance.
</nextsent>
<nextsent>this paper examines the effects of varying beam width on parsing accuracy and speed in this model, showing that parsing accuracy degrades gracefully as beam width decreases dramatically (to 2% of the width used to achieve previous top results), without sacrificing gains over baseline cky parser.
</nextsent>
<nextsent>probabilistic parsers have been successful at accurately estimating syntactic structure from freetext.
</nextsent>
<nextsent>typically, these systems work by considering entire sentences (or utterances) at once, using dynamic programming to obtain globally optimal solutions from locally optimal sub-parses.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3404">
<title id=" W10-2004.xml">hhmm parsing with limited parallelism </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this question creates niche in computational research for models that are able to parse accurately while adhering as closely as possible to human-like psycho linguistic constraints.
</prevsent>
<prevsent>recent work on incremental parsers includes work on hierarchical hidden markov model (hhmm) parsers that operate in linear time by maintaining bounded store of incomplete constituents (schuler et al, 2008).<papid> C08-1099 </papid></prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
despite this seeming limitation, corpus studies have shown that through the use of grammar transforms, this parser is able to cover nearly all sentences contained in the penn treebank (marcus et al, 1993) <papid> J93-2004 </papid>using small number of unconnected memory elements.</citsent>
<aftsection>
<nextsent>but this bounded-memory parsing comes at price.
</nextsent>
<nextsent>the hhmm parser obtains good coverage within human-like memory bounds only by pursuing an optionally arc-eager?
</nextsent>
<nextsent>parsing strategy, non deterministically guessing which constituent scan be kept open for attachment (occupying an active memory element), or closed for attachment(freeing memory element for subsequent con stituents).
</nextsent>
<nextsent>although empirically determining the number of parallel competing hypotheses used in human sentence processing is difficult, previous results in computational models have shown that human-like behavior can be elicited at very low levels of parallelism (boston et al, 2008<papid> P08-2002 </papid>b; brant sand crocker, 2000), <papid> C00-1017 </papid>suggesting that large numbers of active hypotheses are not needed.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3405">
<title id=" W10-2004.xml">hhmm parsing with limited parallelism </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the hhmm parser obtains good coverage within human-like memory bounds only by pursuing an optionally arc-eager?
</prevsent>
<prevsent>parsing strategy, non deterministically guessing which constituent scan be kept open for attachment (occupying an active memory element), or closed for attachment(freeing memory element for subsequent con stituents).
</prevsent>
</prevsection>
<citsent citstr=" P08-2002 ">
although empirically determining the number of parallel competing hypotheses used in human sentence processing is difficult, previous results in computational models have shown that human-like behavior can be elicited at very low levels of parallelism (boston et al, 2008<papid> P08-2002 </papid>b; brant sand crocker, 2000), <papid> C00-1017 </papid>suggesting that large numbers of active hypotheses are not needed.</citsent>
<aftsection>
<nextsent>previously, the hhmm parser has only been evaluated on large beam widths, leaving this aspect of its psycho linguistic plausibility untested.
</nextsent>
<nextsent>in this paper, the performance of an hhmm parser will be evaluated in two experiments that 27 vary the amount of parallelism allowed during parsing, measuring the degree to which this degrades the systems accuracy.
</nextsent>
<nextsent>in addition, the evaluation will compare the hhmm parser to an off-the-shelf probabilistic cky parser to evaluate the actual run time performance at various beam widths.
</nextsent>
<nextsent>this serves two purposes, evaluating one aspect of the plausibility of this parsing framework as psycho linguistic model, and evaluating its potential utility as tool for operating on unsegmented text or speech.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3407">
<title id=" W10-2004.xml">hhmm parsing with limited parallelism </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the hhmm parser obtains good coverage within human-like memory bounds only by pursuing an optionally arc-eager?
</prevsent>
<prevsent>parsing strategy, non deterministically guessing which constituent scan be kept open for attachment (occupying an active memory element), or closed for attachment(freeing memory element for subsequent con stituents).
</prevsent>
</prevsection>
<citsent citstr=" C00-1017 ">
although empirically determining the number of parallel competing hypotheses used in human sentence processing is difficult, previous results in computational models have shown that human-like behavior can be elicited at very low levels of parallelism (boston et al, 2008<papid> P08-2002 </papid>b; brant sand crocker, 2000), <papid> C00-1017 </papid>suggesting that large numbers of active hypotheses are not needed.</citsent>
<aftsection>
<nextsent>previously, the hhmm parser has only been evaluated on large beam widths, leaving this aspect of its psycho linguistic plausibility untested.
</nextsent>
<nextsent>in this paper, the performance of an hhmm parser will be evaluated in two experiments that 27 vary the amount of parallelism allowed during parsing, measuring the degree to which this degrades the systems accuracy.
</nextsent>
<nextsent>in addition, the evaluation will compare the hhmm parser to an off-the-shelf probabilistic cky parser to evaluate the actual run time performance at various beam widths.
</nextsent>
<nextsent>this serves two purposes, evaluating one aspect of the plausibility of this parsing framework as psycho linguistic model, and evaluating its potential utility as tool for operating on unsegmented text or speech.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3408">
<title id=" W10-2004.xml">hhmm parsing with limited parallelism </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in fact, garden path sentences typically cannot be understood on first pass and must be reread, indicating that the correct analysis is attainable and yet not present in the set of parallel hypotheses of the first pass.
</prevsent>
<prevsent>while parsers meeting these three criteria can claim to not violate any psycho linguistic constraints, there has been much recent work in testing psycholinguistically-motivated parsers to make forward predictions about human sentence processing, in order to provide positive evidence for certain probabilistic parsing models as valid psycho linguistic models of sentence processing.this work has largely focused on correlating measures of parsing difficulty in computational models with delays in reading time in human subjects.
</prevsent>
</prevsection>
<citsent citstr=" N01-1021 ">
hale (2001) <papid> N01-1021 </papid>introduced the surprisal metric for probabilistic parsers, which measures the log ratio of the total probability mass at word ? 1 and word t. in other words, it measures how much probability was lost in incorporating the next word into the current hypotheses.</citsent>
<aftsection>
<nextsent>boston etal.
</nextsent>
<nextsent>(2008a) show that surprisal is significant predictor of reading time (as measured in self-pacedreading experiments) using probabilistic dependency parser.
</nextsent>
<nextsent>roark et al (2009) <papid> D09-1034 </papid>dissected parsing difficulty metrics (including surprisal and entropy) to separate out the effects of syntactic and lexical difficulties, and showed that these new metrics are strong predictors of reading difficulty.</nextsent>
<nextsent>wu et al (2010) evaluate the same hierarchical hidden markov model parser used in this work in terms of its ability to reproduce human-like results for various complexity metrics, including some ofthose mentioned above, and introduce new metric called embedding difference.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3409">
<title id=" W10-2004.xml">hhmm parsing with limited parallelism </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>boston etal.
</prevsent>
<prevsent>(2008a) show that surprisal is significant predictor of reading time (as measured in self-pacedreading experiments) using probabilistic dependency parser.
</prevsent>
</prevsection>
<citsent citstr=" D09-1034 ">
roark et al (2009) <papid> D09-1034 </papid>dissected parsing difficulty metrics (including surprisal and entropy) to separate out the effects of syntactic and lexical difficulties, and showed that these new metrics are strong predictors of reading difficulty.</citsent>
<aftsection>
<nextsent>wu et al (2010) evaluate the same hierarchical hidden markov model parser used in this work in terms of its ability to reproduce human-like results for various complexity metrics, including some ofthose mentioned above, and introduce new metric called embedding difference.
</nextsent>
<nextsent>this metric is based on the idea of embedding depth, which isthe number of elements in the memory store required to hold given hypothesis.
</nextsent>
<nextsent>using more memory elements corresponds to center embedding in phrase structure trees, and presumably correlates to some degree with complexity.
</nextsent>
<nextsent>average embedding for time step is computed by computing the weighted average number of required memory elements (weighted by probability) for all hypotheses on the beam.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3412">
<title id=" W10-2004.xml">hhmm parsing with limited parallelism </title>
<section> optionally arc-eager parsing.  </section>
<citcontext>
<prevsection>
<prevsent>by placing firm limits on the number of open incomplete constituents in working memory, the hierarchical hmm parser maintains parallel hypotheses on the beam which predict whether each constituent will host subsequent attachment or not.
</prevsent>
<prevsent>empirical results described in the next section 3it is important to note that neither the right-corner nor left-corner parsing strategy by itself creates this ambiguity.the ambiguity arises from the decision to use this optionally arc-eager strategy to reduce memory store allocation in bounded memory parser.
</prevsent>
</prevsection>
<citsent citstr=" W04-0305 ">
implementations of left-corner parsers such as that of henderson (2004) <papid> W04-0305 </papid>adopt arc-standard strategy, essentially always choosing analysis (b) above, and thus do not introduce this kind of local ambiguity.</citsent>
<aftsection>
<nextsent>but in adopting this strategy, such parsers must maintain stack memory of unbounded size, and thus are not attractive as models of human parsing in short-term memory (resnik, 1992).<papid> C92-1032 </papid></nextsent>
<nextsent>31 a) d=1 d=2 d=3 word t=1 t=2 t=3 t=4 t=5 t=6 t=7 strong demand for new york city ? ?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3413">
<title id=" W10-2004.xml">hhmm parsing with limited parallelism </title>
<section> optionally arc-eager parsing.  </section>
<citcontext>
<prevsection>
<prevsent>empirical results described in the next section 3it is important to note that neither the right-corner nor left-corner parsing strategy by itself creates this ambiguity.the ambiguity arises from the decision to use this optionally arc-eager strategy to reduce memory store allocation in bounded memory parser.
</prevsent>
<prevsent>implementations of left-corner parsers such as that of henderson (2004) <papid> W04-0305 </papid>adopt arc-standard strategy, essentially always choosing analysis (b) above, and thus do not introduce this kind of local ambiguity.</prevsent>
</prevsection>
<citsent citstr=" C92-1032 ">
but in adopting this strategy, such parsers must maintain stack memory of unbounded size, and thus are not attractive as models of human parsing in short-term memory (resnik, 1992).<papid> C92-1032 </papid></citsent>
<aftsection>
<nextsent>31 a) d=1 d=2 d=3 word t=1 t=2 t=3 t=4 t=5 t=6 t=7 strong demand for new york city ? ?
</nextsent>
<nextsent>np/nn np/pp np/np np/nnp np/nnp np(dem .) b) d=1 d=2 d=3 word t=1 t=2 t=3 t=4 t=5 t=6 t=7 strong demand for new york city ? ?
</nextsent>
<nextsent>nnp/nnp nnp/nnp np(city) ? np/nn np/pp np/np np/np np/np np(dem .)/np(?)
</nextsent>
<nextsent>figure 3: alternative analyses of strong demand for new york city ...?: a) using in-element composition, compatible with strong demand for new york city is ...?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3418">
<title id=" W10-2004.xml">hhmm parsing with limited parallelism </title>
<section> experimental evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>this experiment is intended to address two questions: whether this framework is efficient 0 2 4 6 8 10 12 14 10 20 30 40 50 60 70 se co nd pe s en te nc sentence length cky hhmm figure 5: plot of parsing time vs. sentence length for hhmm and cky parsers.enough to be considered viable psycho linguistic model, and whether its parsing time and accuracy remain competitive with more standard cubic time parsing technologies at low beam widths.
</prevsent>
<prevsent>to evaluate this aspect, the hhmm parser was run at low beam widths on sentences of varyinglengths.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
the baseline was the widely-used stanford parser (klein and manning, 2003), <papid> P03-1054 </papid>run in vanilla pcfg?</citsent>
<aftsection>
<nextsent>mode.
</nextsent>
<nextsent>this parser was used rather than the custom-built cky parser from the previous experiment, to avoid the possibility that its implementation was not efficient enough to provide realistic test.
</nextsent>
<nextsent>the hhmmparser was implemented as described in the previous section.
</nextsent>
<nextsent>these experiments were run on machine with single 2.40 ghz celeron cpu, with 512 mb of ram.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3419">
<title id=" W10-3023.xml">hedge classification with syntactic dependency features based on an ensemble classifier </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>sentences containing at least one hedge/weasel cue are considered as uncertain, while sentences with no hedge/weasel cues are considered as factual.
</prevsent>
<prevsent>the results show that employing the ensemble classifier outperforms the single classifier system on the wikipedia dataset, and using the syntactic dependency information in the feature set outperform the system without syntactic dependency information on the biological dataset (in-domain).
</prevsent>
</prevsection>
<citsent citstr=" P07-1125 ">
in related work, szarvas (2008) extended the methodology of medlock and briscoe (2007), <papid> P07-1125 </papid>and presented hedge detection method in biomedical texts with weakly supervised selection of keywords.</citsent>
<aftsection>
<nextsent>ganter and strube (2009) <papid> P09-2044 </papid>proposed an approach for automatic detection of sentences containing linguistic hedges using wikipedia weasel tags and syntactic patterns.</nextsent>
<nextsent>the remainder of this paper is organized as follows.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3420">
<title id=" W10-3023.xml">hedge classification with syntactic dependency features based on an ensemble classifier </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the results show that employing the ensemble classifier outperforms the single classifier system on the wikipedia dataset, and using the syntactic dependency information in the feature set outperform the system without syntactic dependency information on the biological dataset (in-domain).
</prevsent>
<prevsent>in related work, szarvas (2008) extended the methodology of medlock and briscoe (2007), <papid> P07-1125 </papid>and presented hedge detection method in biomedical texts with weakly supervised selection of keywords.</prevsent>
</prevsection>
<citsent citstr=" P09-2044 ">
ganter and strube (2009) <papid> P09-2044 </papid>proposed an approach for automatic detection of sentences containing linguistic hedges using wikipedia weasel tags and syntactic patterns.</citsent>
<aftsection>
<nextsent>the remainder of this paper is organized as follows.
</nextsent>
<nextsent>section 2 presents the technical details of our system.
</nextsent>
<nextsent>section 3 presents experimental results and performance analysis.
</nextsent>
<nextsent>section 4 presents our discussion of the experiments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3421">
<title id=" W10-0735.xml">error driven paraphrase annotation using mechanical turk </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the source text provided to translation system is typically only one of many ways the input sentence could have been expressed, and alternative forms of expression can often produce better translation.
</prevsent>
<prevsent>this observation is familiar to most statistical mt researchers in the form of preprocessing choices ? for example, one segmentation of chinese sentence might yield better translations than another.1 over the past several years, mt frameworks have been developed that permit all the alternatives to beused as input, represented efficiently as confusion network, lattice, or forest, rather than forcing selection ofa single input representation.
</prevsent>
</prevsection>
<citsent citstr=" W07-0729 ">
this has improved performance when applied to phenomena including segmentation, morphological analysis, and more recently source langage word order (dyer, 2007; <papid> W07-0729 </papid>dyer et al, 2008; <papid> P08-1115 </papid>dyer and resnik, to appear).</citsent>
<aftsection>
<nextsent>we have begun to explore the application of the same key idea beyond low-level processing phenomena suchas segmentation, instead looking at alternative expressions of meaning.
</nextsent>
<nextsent>for example, consider translating the 1chinese is written without spaces, so most mt systems need to segment the input into words as preprocessing step.
</nextsent>
<nextsent>democratic candidates stepped up their attacks during the debate.
</nextsent>
<nextsent>the same basic meaning could have been expressed in many different ways, e.g.: ? during the debate the democratic candidates stepped up their attacks.?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3422">
<title id=" W10-0735.xml">error driven paraphrase annotation using mechanical turk </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the source text provided to translation system is typically only one of many ways the input sentence could have been expressed, and alternative forms of expression can often produce better translation.
</prevsent>
<prevsent>this observation is familiar to most statistical mt researchers in the form of preprocessing choices ? for example, one segmentation of chinese sentence might yield better translations than another.1 over the past several years, mt frameworks have been developed that permit all the alternatives to beused as input, represented efficiently as confusion network, lattice, or forest, rather than forcing selection ofa single input representation.
</prevsent>
</prevsection>
<citsent citstr=" P08-1115 ">
this has improved performance when applied to phenomena including segmentation, morphological analysis, and more recently source langage word order (dyer, 2007; <papid> W07-0729 </papid>dyer et al, 2008; <papid> P08-1115 </papid>dyer and resnik, to appear).</citsent>
<aftsection>
<nextsent>we have begun to explore the application of the same key idea beyond low-level processing phenomena suchas segmentation, instead looking at alternative expressions of meaning.
</nextsent>
<nextsent>for example, consider translating the 1chinese is written without spaces, so most mt systems need to segment the input into words as preprocessing step.
</nextsent>
<nextsent>democratic candidates stepped up their attacks during the debate.
</nextsent>
<nextsent>the same basic meaning could have been expressed in many different ways, e.g.: ? during the debate the democratic candidates stepped up their attacks.?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3423">
<title id=" W10-0735.xml">error driven paraphrase annotation using mechanical turk </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the candidates in the democratic debate attacked more vigorously.these examples illustrate lexical variation, as well as syntactic differences, e.g. whether the attacking or the increasing serves as the main verb.
</prevsent>
<prevsent>we hypothesize that variation of this kind holds potential advantage for translation systems, namely that some variations may bemore easily translated than others depending on the training data that was given to the system, and we can im prove translation quality by allowing system to take best advantage of the variations it knows about, at the sub sentential level, just as the systems described above can take advantage of alternative segmentations.paraphrase lattices provide way to make this hypothesis operational.
</prevsent>
</prevsection>
<citsent citstr=" W07-0716 ">
this idea is variation on the uses of paraphrase in translation introduced by callison-burch and explored by others, as well (callison-burch et al,2006; madnani et al, 2007; <papid> W07-0716 </papid>callison-burch, 2008; marton et al, 2009).<papid> D09-1040 </papid></citsent>
<aftsection>
<nextsent>these authors have shown that performance improvements can be gained by exploiting paraphrases using phrase pivoting.
</nextsent>
<nextsent>we have investigated using pivoting to create exhaustive paraphrase lattices, andwe have also investigated defining upper bounds by eliciting human sub-sentential paraphrases using mechanical turk.
</nextsent>
<nextsent>unfortunately, in both cases, we have found the size of the paraphrase lattice prohibitive: there are 217too many spans to paraphrase to make using turk cost effective, and automatically generated paraphrase lattices turn out to be too noisy to produce improved translations.a potential solution to this problem comes from different line of work we are pursuing, in which translation is viewed as collaborative process involving people and machines (bederson et al, 2010).
</nextsent>
<nextsent>here, the idea is thatin translating from source to target language, source and target-language speakers who are not bilingual can collaborate to improve the quality of automatic translation, via an iterative protocol involving translation, back translation, and the use of very rich user interface.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3424">
<title id=" W10-0735.xml">error driven paraphrase annotation using mechanical turk </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the candidates in the democratic debate attacked more vigorously.these examples illustrate lexical variation, as well as syntactic differences, e.g. whether the attacking or the increasing serves as the main verb.
</prevsent>
<prevsent>we hypothesize that variation of this kind holds potential advantage for translation systems, namely that some variations may bemore easily translated than others depending on the training data that was given to the system, and we can im prove translation quality by allowing system to take best advantage of the variations it knows about, at the sub sentential level, just as the systems described above can take advantage of alternative segmentations.paraphrase lattices provide way to make this hypothesis operational.
</prevsent>
</prevsection>
<citsent citstr=" D09-1040 ">
this idea is variation on the uses of paraphrase in translation introduced by callison-burch and explored by others, as well (callison-burch et al,2006; madnani et al, 2007; <papid> W07-0716 </papid>callison-burch, 2008; marton et al, 2009).<papid> D09-1040 </papid></citsent>
<aftsection>
<nextsent>these authors have shown that performance improvements can be gained by exploiting paraphrases using phrase pivoting.
</nextsent>
<nextsent>we have investigated using pivoting to create exhaustive paraphrase lattices, andwe have also investigated defining upper bounds by eliciting human sub-sentential paraphrases using mechanical turk.
</nextsent>
<nextsent>unfortunately, in both cases, we have found the size of the paraphrase lattice prohibitive: there are 217too many spans to paraphrase to make using turk cost effective, and automatically generated paraphrase lattices turn out to be too noisy to produce improved translations.a potential solution to this problem comes from different line of work we are pursuing, in which translation is viewed as collaborative process involving people and machines (bederson et al, 2010).
</nextsent>
<nextsent>here, the idea is thatin translating from source to target language, source and target-language speakers who are not bilingual can collaborate to improve the quality of automatic translation, via an iterative protocol involving translation, back translation, and the use of very rich user interface.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3425">
<title id=" W10-0735.xml">error driven paraphrase annotation using mechanical turk </title>
<section> evaluating results.  </section>
<citcontext>
<prevsection>
<prevsent>the evaluation set includes the 1000 sentence where at least one paraphrase was provided.3 our evaluation takes the form of an oracle study: ifwe knew with perfect accuracy which variant of sentence to translate, i.e. among the original and all its paraphrases, based on knowledge of the reference translation,how well could we do?
</prevsent>
<prevsent>an oracle?
</prevsent>
</prevsection>
<citsent citstr=" N04-1021 ">
telling us which variant is best is not available in the real world, of course, but in situations like this one, oracle studies are often used to establish the magnitude of the potential gain (och et al., 2004).<papid> N04-1021 </papid></citsent>
<aftsection>
<nextsent>in this case, the baseline is the average ter score for the 1000 original sentences, 84.4.
</nextsent>
<nextsent>if an oracle were permitted to choose which variant was the best to translate, the average ter score would drop to 80.6.4 drilling down bit further, we find that better-translated paraphrase sentence is available in 313 of the 1000 cases,or31.3%, and for those 313 cases, ter for the best paraphrase alternative improves on the ter for the original sentence by 12.16 ter points.
</nextsent>
<nextsent>this annotation effort has produced gold standard sub sentential paraphrases and paraphrase quality ratings for spans in large number of sentences, where the choice of spans to paraphrase is specifically focused on regions of the sentence that are difficult to translate.
</nextsent>
<nextsent>in addi3for the other 6 sentences, all problematic spans were marked unable to paraphrase?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3427">
<title id=" W10-1921.xml">integration of static relations to enhance event extraction from text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we present the first study of integrating these static relations with event data with the aim of enhancing event extraction performance.
</prevsent>
<prevsent>while obtaining promising results, we will argue that an event extraction framework will benefit most from this new data when taking intrinsic differences between various event types into account.
</prevsent>
</prevsection>
<citsent citstr=" W09-1401 ">
recently, biomedical text mining tools have evolved from extracting simple binary relations between genes or proteins to more expressive event representation (kim et al , 2009).<papid> W09-1401 </papid></citsent>
<aftsection>
<nextsent>furthermore, new datasets have been developed targeting relations between genes and gene products(ggps) and broader category of entities, covering terms that can not be annotated as named entities (nes) but that are still highly relevant for biomedical information extraction (ohta et al , 2009<papid> W09-1313 </papid>b).</nextsent>
<nextsent>in contrast to relations involving change or causality, the annotation for this data covers relations such as part-of, here termed static rela tions?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3429">
<title id=" W10-1921.xml">integration of static relations to enhance event extraction from text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>while obtaining promising results, we will argue that an event extraction framework will benefit most from this new data when taking intrinsic differences between various event types into account.
</prevsent>
<prevsent>recently, biomedical text mining tools have evolved from extracting simple binary relations between genes or proteins to more expressive event representation (kim et al , 2009).<papid> W09-1401 </papid></prevsent>
</prevsection>
<citsent citstr=" W09-1313 ">
furthermore, new datasets have been developed targeting relations between genes and gene products(ggps) and broader category of entities, covering terms that can not be annotated as named entities (nes) but that are still highly relevant for biomedical information extraction (ohta et al , 2009<papid> W09-1313 </papid>b).</citsent>
<aftsection>
<nextsent>in contrast to relations involving change or causality, the annotation for this data covers relations such as part-of, here termed static rela tions?
</nextsent>
<nextsent>(sr) (pyysalo et al , 2009).<papid> W09-1301 </papid></nextsent>
<nextsent>tissue-specific expression of interleukin-3 expression event ggp is mediated via cis-acting elements located regulation event term part-of ggp within 315 base pairs of the transcription start.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3430">
<title id=" W10-1921.xml">integration of static relations to enhance event extraction from text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>furthermore, new datasets have been developed targeting relations between genes and gene products(ggps) and broader category of entities, covering terms that can not be annotated as named entities (nes) but that are still highly relevant for biomedical information extraction (ohta et al , 2009<papid> W09-1313 </papid>b).</prevsent>
<prevsent>in contrast to relations involving change or causality, the annotation for this data covers relations such as part-of, here termed static rela tions?</prevsent>
</prevsection>
<citsent citstr=" W09-1301 ">
(sr) (pyysalo et al , 2009).<papid> W09-1301 </papid></citsent>
<aftsection>
<nextsent>tissue-specific expression of interleukin-3 expression event ggp is mediated via cis-acting elements located regulation event term part-of ggp within 315 base pairs of the transcription start.
</nextsent>
<nextsent>term part-of ggp figure 1: sentence from pmid:8662845, showing how the event dataset (single line) and the srdata set (double line) offer complementary information, enabling more precise model of the biological reality.as an example, figure 1 depicts sentence containing complementary annotations from the event dataset and the sr data.
</nextsent>
<nextsent>the event annotation indicates an expression event involving the ggp interleukin-3?.
</nextsent>
<nextsent>furthermore, regulation of this expression event is stated by the trigger word me diated?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3432">
<title id=" W10-1921.xml">integration of static relations to enhance event extraction from text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>during the last few years, event extraction has gained much interest in the field of natural language processing (nlp) of biomedical text (pyysalo et al , 2007; kim et al , 2008; kimet al , 2009).<papid> W09-1401 </papid></prevsent>
<prevsent>however, owing to the more complex nature of this task setting, performance rates are lower than for the extraction of simple binary relations.</prevsent>
</prevsection>
<citsent citstr=" D09-1013 ">
the currently best performing framework for event extraction obtains 53.29% score (miwa et al , 2010), which is considerably lower than the performance reported for extraction of protein-protein interaction relations, ranging between 65% and 87% depending on the dataset used for evaluation (miwa et al , 2009).<papid> D09-1013 </papid></citsent>
<aftsection>
<nextsent>in this paper, we will study how data on static relations can be applied to improve event extraction performance.
</nextsent>
<nextsent>first, we describe the various data sets (section 2) and the text mining framework that was applied (section 3).
</nextsent>
<nextsent>the main contributions of this paper are presented in section 4, in which we study how static relation information can be integrated into an event extraction framework to enhance extraction performance.
</nextsent>
<nextsent>finally, section 5 presents the main conclusions of this work.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3438">
<title id=" W10-1921.xml">integration of static relations to enhance event extraction from text </title>
<section> data.  </section>
<citcontext>
<prevsection>
<prevsent>the second dataset, introduced in (ohta etal., 2009<papid> W09-1313 </papid>b), contains annotation for relations holding between terms and ggps embedded in those terms.</prevsent>
<prevsent>in this study, we will use the non-embedded relations from the former dataset, referring to this data as rbn for relations between nominals?</prevsent>
</prevsection>
<citsent citstr=" W09-2415 ">
in recognition of the similarity of the task setting represented by this dataset and the task of learning semantic relations between nominals, as studied e.g. in semeval (girju et al , 2007; hendrickx et al , 2009).<papid> W09-2415 </papid></citsent>
<aftsection>
<nextsent>we use all of the latter data set,below referred to as npr for noun phrase relations?.
</nextsent>
<nextsent>the npr dataset extends on the embedded part of the data introduced by (pyysaloet al , 2009), <papid> W09-1301 </papid>increasing the coverage of terms included and the granularity of the annotated event types.</nextsent>
<nextsent>while rbn only differentiates between domain-specific variant relation and four different part-whole relations, in npr these are refined into more than 20 different types.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3445">
<title id=" W10-1921.xml">integration of static relations to enhance event extraction from text </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>subsequently, support vector machine (svm) is built with these trainingpatterns.
</prevsent>
<prevsent>the patterns include trigrams, bag-of word features, vertex walks and information about the event trigger.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
as part of the current study discusses the extension and generalization of these feature patterns (section 4.4), we will briefly discuss the various types in this section.to derive syntactic patterns, dependency parsing is applied using the stanford parser (klein and manning, 2003; <papid> P03-1054 </papid>de marneffe et al , 2006).</citsent>
<aftsection>
<nextsent>specifically, for each candidate event, the smallest subgraph is built including the relevant nodes for the trigger and the ggp names.
</nextsent>
<nextsent>each edge in this subgraph then gives rise to pattern including the information from the connecting nodes (or vertices)in combination with the syntactic relation specified by the edge.
</nextsent>
<nextsent>trigger words and ggp names are blinded by replacing their text with the strings protx and trigger (respectively), resulting in highly general features.
</nextsent>
<nextsent>figure 3 depicts an exemplary dependency graph.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3448">
<title id=" W10-1806.xml">anveshan a framework for analysis of multiple annotatorsrsquo labeling behavior </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>1 credits this work was supported by research supplement to the national science foundation cri award 0708952.
</prevsent>
<prevsent>manual annotation of language data in order to capture linguistic knowledge has become increasingly important for semantic and pragmatic annotation tasks.
</prevsent>
</prevsection>
<citsent citstr=" W09-3953 ">
a very short list of few such tasks illustrates the range of types of annotation,in varying stages of development: predicate argument structure (palmer et al, 2005b), dialogue acts (hu et al, 2009), <papid> W09-3953 </papid>discourse structure (carbone et al, 2004), <papid> W04-2323 </papid>opinion (wiebe and cardie, 2005),emotion (alm et al, 2005).<papid> H05-1073 </papid></citsent>
<aftsection>
<nextsent>the number of efforts to create corpus resources that include manual annotations has also been growing.
</nextsent>
<nextsent>a common approach in assessing the resulting manual annotations is to report single quantitative measure reflecting the quality of the annotations, either summary statistic such as percent agreement, oran agreement coefficient from the family of metrics that include krippendorffs alpha (krippen dorff, 1980) and cohens kappa (cohen, 1960).
</nextsent>
<nextsent>we present some new assessment methods to use in combination with an agreement coefficient for understanding annotator behavior when there are multiple annotators and many annotation values.
</nextsent>
<nextsent>anveshan (annotation variance estimation)1 is suite of procedures for analyzing patterns of agreement and disagreement among annotators, as well as the distributions of annotation values across annotators.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3449">
<title id=" W10-1806.xml">anveshan a framework for analysis of multiple annotatorsrsquo labeling behavior </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>1 credits this work was supported by research supplement to the national science foundation cri award 0708952.
</prevsent>
<prevsent>manual annotation of language data in order to capture linguistic knowledge has become increasingly important for semantic and pragmatic annotation tasks.
</prevsent>
</prevsection>
<citsent citstr=" W04-2323 ">
a very short list of few such tasks illustrates the range of types of annotation,in varying stages of development: predicate argument structure (palmer et al, 2005b), dialogue acts (hu et al, 2009), <papid> W09-3953 </papid>discourse structure (carbone et al, 2004), <papid> W04-2323 </papid>opinion (wiebe and cardie, 2005),emotion (alm et al, 2005).<papid> H05-1073 </papid></citsent>
<aftsection>
<nextsent>the number of efforts to create corpus resources that include manual annotations has also been growing.
</nextsent>
<nextsent>a common approach in assessing the resulting manual annotations is to report single quantitative measure reflecting the quality of the annotations, either summary statistic such as percent agreement, oran agreement coefficient from the family of metrics that include krippendorffs alpha (krippen dorff, 1980) and cohens kappa (cohen, 1960).
</nextsent>
<nextsent>we present some new assessment methods to use in combination with an agreement coefficient for understanding annotator behavior when there are multiple annotators and many annotation values.
</nextsent>
<nextsent>anveshan (annotation variance estimation)1 is suite of procedures for analyzing patterns of agreement and disagreement among annotators, as well as the distributions of annotation values across annotators.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3450">
<title id=" W10-1806.xml">anveshan a framework for analysis of multiple annotatorsrsquo labeling behavior </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>1 credits this work was supported by research supplement to the national science foundation cri award 0708952.
</prevsent>
<prevsent>manual annotation of language data in order to capture linguistic knowledge has become increasingly important for semantic and pragmatic annotation tasks.
</prevsent>
</prevsection>
<citsent citstr=" H05-1073 ">
a very short list of few such tasks illustrates the range of types of annotation,in varying stages of development: predicate argument structure (palmer et al, 2005b), dialogue acts (hu et al, 2009), <papid> W09-3953 </papid>discourse structure (carbone et al, 2004), <papid> W04-2323 </papid>opinion (wiebe and cardie, 2005),emotion (alm et al, 2005).<papid> H05-1073 </papid></citsent>
<aftsection>
<nextsent>the number of efforts to create corpus resources that include manual annotations has also been growing.
</nextsent>
<nextsent>a common approach in assessing the resulting manual annotations is to report single quantitative measure reflecting the quality of the annotations, either summary statistic such as percent agreement, oran agreement coefficient from the family of metrics that include krippendorffs alpha (krippen dorff, 1980) and cohens kappa (cohen, 1960).
</nextsent>
<nextsent>we present some new assessment methods to use in combination with an agreement coefficient for understanding annotator behavior when there are multiple annotators and many annotation values.
</nextsent>
<nextsent>anveshan (annotation variance estimation)1 is suite of procedures for analyzing patterns of agreement and disagreement among annotators, as well as the distributions of annotation values across annotators.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3451">
<title id=" W10-1806.xml">anveshan a framework for analysis of multiple annotatorsrsquo labeling behavior </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as an illustration of the utility of anveshan, we compare two groups of annotators on the same annotation word sense annotation tasks: half dozen trained annotators and fourteen mechanical turk ers.
</prevsent>
<prevsent>previous work has argued that it can be cost effective to collect multiple labels from untrained label ers at low cost per label, and to combine the multiple labels through voting method, rather than to collect single labels from highly trained la 1anveshan is sanskrit word which literally means search or exploration.
</prevsent>
</prevsection>
<citsent citstr=" D08-1027 ">
47 belers (snow et al, 2008; <papid> D08-1027 </papid>sheng et al, 2008; lam and stork, 2003).</citsent>
<aftsection>
<nextsent>the tasks included in (snow etal., 2008), <papid> D08-1027 </papid>for example, include word sense annotation; in contrast to our case, where the average number of senses per word is 9.5, the one word sense annotation task had three senses.</nextsent>
<nextsent>we find that the same half dozen trained annotator scan agree well or not on sense labels for poly semous words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3453">
<title id=" W10-1806.xml">anveshan a framework for analysis of multiple annotatorsrsquo labeling behavior </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>assessing the reliability of an annotation typically addresses the question of whether different annotators (effectively) assign the same annotation labels.
</prevsent>
<prevsent>various measures can be used to compare different annotators, including agreement coefficients such as krippendorffs alpha (krippendorff, 1980).
</prevsent>
</prevsection>
<citsent citstr=" J08-4004 ">
extensive reviews of the properties of such coefficients have been presented elsewhere, e.g.,(artstein and poesio, 2008).<papid> J08-4004 </papid></citsent>
<aftsection>
<nextsent>briefly, an agreement produce values in the interval [-1,1] indicating how much of the observed agreement is above (or below) agreement that would be predicted by chance (value of 0).
</nextsent>
<nextsent>to measure reliability in this way is to assume that for most of the instances in the data, there is single correct response.
</nextsent>
<nextsent>here we present the use of reliability metrics and other measures for word sense annotation, and we assume that in some cases there may not be single correct response.
</nextsent>
<nextsent>when annotators have less than excellent agreement, we aim to examine possible causes.we take word sense to be problematic annotation to perform, thus requiring deeper understanding of the conditions under which annotators might disagree.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3454">
<title id=" W10-1806.xml">anveshan a framework for analysis of multiple annotatorsrsquo labeling behavior </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>4 related work.
</prevsent>
<prevsent>there has been decade-long community-wide effort to evaluate word sense disambiguation (wsd)systems across languages in the four senseval efforts (1998, 2001, 2004, and 2007, cf.
</prevsent>
</prevsection>
<citsent citstr=" W02-0812 ">
(kilgarriff, 1998; pedersen, 2002<papid> W02-0812 </papid>a; pedersen, 2002<papid> W02-0812 </papid>b; palme ret al, 2005a)), with corollary effort to investigate the issues pertaining to preparation of manually annotated gold standard corpora tagged for word senses (palmer et al, 2005a).</citsent>
<aftsection>
<nextsent>differences in ia and system performance across part-of-speech have been examined, asin (ng et al, 1999; <papid> W99-0502 </papid>palmer et al, 2005a).</nextsent>
<nextsent>factors that have been proposed as affecting agreement include whether annotators are allowed to as sign multi labels (veronis, 1998; ide et al, 2002;<papid> W02-0808 </papid>passonneau et al, 2006), the number or granularity of senses (ng et al, 1999), <papid> W99-0502 </papid>merging of related senses (snow et al, 2007), <papid> D07-1107 </papid>sense similarity (chugur et al, 2002), <papid> W02-0805 </papid>entropy (diab, 2004; <papid> P04-1039 </papid>palmer et al, 2005a), and reactions times required to distinguish senses (klein and murphy, 2002; ide and wilks, 2006).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3462">
<title id=" W10-1806.xml">anveshan a framework for analysis of multiple annotatorsrsquo labeling behavior </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there has been decade-long community-wide effort to evaluate word sense disambiguation (wsd)systems across languages in the four senseval efforts (1998, 2001, 2004, and 2007, cf.
</prevsent>
<prevsent>(kilgarriff, 1998; pedersen, 2002<papid> W02-0812 </papid>a; pedersen, 2002<papid> W02-0812 </papid>b; palme ret al, 2005a)), with corollary effort to investigate the issues pertaining to preparation of manually annotated gold standard corpora tagged for word senses (palmer et al, 2005a).</prevsent>
</prevsection>
<citsent citstr=" W99-0502 ">
differences in ia and system performance across part-of-speech have been examined, asin (ng et al, 1999; <papid> W99-0502 </papid>palmer et al, 2005a).</citsent>
<aftsection>
<nextsent>factors that have been proposed as affecting agreement include whether annotators are allowed to as sign multi labels (veronis, 1998; ide et al, 2002;<papid> W02-0808 </papid>passonneau et al, 2006), the number or granularity of senses (ng et al, 1999), <papid> W99-0502 </papid>merging of related senses (snow et al, 2007), <papid> D07-1107 </papid>sense similarity (chugur et al, 2002), <papid> W02-0805 </papid>entropy (diab, 2004; <papid> P04-1039 </papid>palmer et al, 2005a), and reactions times required to distinguish senses (klein and murphy, 2002; ide and wilks, 2006).</nextsent>
<nextsent>we anticipate that one of the ways in which the data will be used will be to train machine learning approaches to wsd.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3463">
<title id=" W10-1806.xml">anveshan a framework for analysis of multiple annotatorsrsquo labeling behavior </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(kilgarriff, 1998; pedersen, 2002<papid> W02-0812 </papid>a; pedersen, 2002<papid> W02-0812 </papid>b; palme ret al, 2005a)), with corollary effort to investigate the issues pertaining to preparation of manually annotated gold standard corpora tagged for word senses (palmer et al, 2005a).</prevsent>
<prevsent>differences in ia and system performance across part-of-speech have been examined, asin (ng et al, 1999; <papid> W99-0502 </papid>palmer et al, 2005a).</prevsent>
</prevsection>
<citsent citstr=" W02-0808 ">
factors that have been proposed as affecting agreement include whether annotators are allowed to as sign multi labels (veronis, 1998; ide et al, 2002;<papid> W02-0808 </papid>passonneau et al, 2006), the number or granularity of senses (ng et al, 1999), <papid> W99-0502 </papid>merging of related senses (snow et al, 2007), <papid> D07-1107 </papid>sense similarity (chugur et al, 2002), <papid> W02-0805 </papid>entropy (diab, 2004; <papid> P04-1039 </papid>palmer et al, 2005a), and reactions times required to distinguish senses (klein and murphy, 2002; ide and wilks, 2006).</citsent>
<aftsection>
<nextsent>we anticipate that one of the ways in which the data will be used will be to train machine learning approaches to wsd.
</nextsent>
<nextsent>noise in labeling and the impact on machine learning has been discussed from various perspectives.
</nextsent>
<nextsent>in (reidsma and carletta,2008), <papid> J08-3001 </papid>it is argued that machine learning performance does not vary consistently with inter annotator agreement.</nextsent>
<nextsent>through simulation study, the authors find that machine learning performance can degrade or not with lower agreement, depending on whether the disagreement is due to noise or systematic behavior.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3465">
<title id=" W10-1806.xml">anveshan a framework for analysis of multiple annotatorsrsquo labeling behavior </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(kilgarriff, 1998; pedersen, 2002<papid> W02-0812 </papid>a; pedersen, 2002<papid> W02-0812 </papid>b; palme ret al, 2005a)), with corollary effort to investigate the issues pertaining to preparation of manually annotated gold standard corpora tagged for word senses (palmer et al, 2005a).</prevsent>
<prevsent>differences in ia and system performance across part-of-speech have been examined, asin (ng et al, 1999; <papid> W99-0502 </papid>palmer et al, 2005a).</prevsent>
</prevsection>
<citsent citstr=" D07-1107 ">
factors that have been proposed as affecting agreement include whether annotators are allowed to as sign multi labels (veronis, 1998; ide et al, 2002;<papid> W02-0808 </papid>passonneau et al, 2006), the number or granularity of senses (ng et al, 1999), <papid> W99-0502 </papid>merging of related senses (snow et al, 2007), <papid> D07-1107 </papid>sense similarity (chugur et al, 2002), <papid> W02-0805 </papid>entropy (diab, 2004; <papid> P04-1039 </papid>palmer et al, 2005a), and reactions times required to distinguish senses (klein and murphy, 2002; ide and wilks, 2006).</citsent>
<aftsection>
<nextsent>we anticipate that one of the ways in which the data will be used will be to train machine learning approaches to wsd.
</nextsent>
<nextsent>noise in labeling and the impact on machine learning has been discussed from various perspectives.
</nextsent>
<nextsent>in (reidsma and carletta,2008), <papid> J08-3001 </papid>it is argued that machine learning performance does not vary consistently with inter annotator agreement.</nextsent>
<nextsent>through simulation study, the authors find that machine learning performance can degrade or not with lower agreement, depending on whether the disagreement is due to noise or systematic behavior.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3466">
<title id=" W10-1806.xml">anveshan a framework for analysis of multiple annotatorsrsquo labeling behavior </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(kilgarriff, 1998; pedersen, 2002<papid> W02-0812 </papid>a; pedersen, 2002<papid> W02-0812 </papid>b; palme ret al, 2005a)), with corollary effort to investigate the issues pertaining to preparation of manually annotated gold standard corpora tagged for word senses (palmer et al, 2005a).</prevsent>
<prevsent>differences in ia and system performance across part-of-speech have been examined, asin (ng et al, 1999; <papid> W99-0502 </papid>palmer et al, 2005a).</prevsent>
</prevsection>
<citsent citstr=" W02-0805 ">
factors that have been proposed as affecting agreement include whether annotators are allowed to as sign multi labels (veronis, 1998; ide et al, 2002;<papid> W02-0808 </papid>passonneau et al, 2006), the number or granularity of senses (ng et al, 1999), <papid> W99-0502 </papid>merging of related senses (snow et al, 2007), <papid> D07-1107 </papid>sense similarity (chugur et al, 2002), <papid> W02-0805 </papid>entropy (diab, 2004; <papid> P04-1039 </papid>palmer et al, 2005a), and reactions times required to distinguish senses (klein and murphy, 2002; ide and wilks, 2006).</citsent>
<aftsection>
<nextsent>we anticipate that one of the ways in which the data will be used will be to train machine learning approaches to wsd.
</nextsent>
<nextsent>noise in labeling and the impact on machine learning has been discussed from various perspectives.
</nextsent>
<nextsent>in (reidsma and carletta,2008), <papid> J08-3001 </papid>it is argued that machine learning performance does not vary consistently with inter annotator agreement.</nextsent>
<nextsent>through simulation study, the authors find that machine learning performance can degrade or not with lower agreement, depending on whether the disagreement is due to noise or systematic behavior.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3467">
<title id=" W10-1806.xml">anveshan a framework for analysis of multiple annotatorsrsquo labeling behavior </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(kilgarriff, 1998; pedersen, 2002<papid> W02-0812 </papid>a; pedersen, 2002<papid> W02-0812 </papid>b; palme ret al, 2005a)), with corollary effort to investigate the issues pertaining to preparation of manually annotated gold standard corpora tagged for word senses (palmer et al, 2005a).</prevsent>
<prevsent>differences in ia and system performance across part-of-speech have been examined, asin (ng et al, 1999; <papid> W99-0502 </papid>palmer et al, 2005a).</prevsent>
</prevsection>
<citsent citstr=" P04-1039 ">
factors that have been proposed as affecting agreement include whether annotators are allowed to as sign multi labels (veronis, 1998; ide et al, 2002;<papid> W02-0808 </papid>passonneau et al, 2006), the number or granularity of senses (ng et al, 1999), <papid> W99-0502 </papid>merging of related senses (snow et al, 2007), <papid> D07-1107 </papid>sense similarity (chugur et al, 2002), <papid> W02-0805 </papid>entropy (diab, 2004; <papid> P04-1039 </papid>palmer et al, 2005a), and reactions times required to distinguish senses (klein and murphy, 2002; ide and wilks, 2006).</citsent>
<aftsection>
<nextsent>we anticipate that one of the ways in which the data will be used will be to train machine learning approaches to wsd.
</nextsent>
<nextsent>noise in labeling and the impact on machine learning has been discussed from various perspectives.
</nextsent>
<nextsent>in (reidsma and carletta,2008), <papid> J08-3001 </papid>it is argued that machine learning performance does not vary consistently with inter annotator agreement.</nextsent>
<nextsent>through simulation study, the authors find that machine learning performance can degrade or not with lower agreement, depending on whether the disagreement is due to noise or systematic behavior.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3468">
<title id=" W10-1806.xml">anveshan a framework for analysis of multiple annotatorsrsquo labeling behavior </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we anticipate that one of the ways in which the data will be used will be to train machine learning approaches to wsd.
</prevsent>
<prevsent>noise in labeling and the impact on machine learning has been discussed from various perspectives.
</prevsent>
</prevsection>
<citsent citstr=" J08-3001 ">
in (reidsma and carletta,2008), <papid> J08-3001 </papid>it is argued that machine learning performance does not vary consistently with inter annotator agreement.</citsent>
<aftsection>
<nextsent>through simulation study, the authors find that machine learning performance can degrade or not with lower agreement, depending on whether the disagreement is due to noise or systematic behavior.
</nextsent>
<nextsent>noise has relatively little impact compared with systematic disagreements.
</nextsent>
<nextsent>in (passonneau et al, 2008), <papid> L08-1167 </papid>similar lack of correlation between inter annotator agreement and machine learning performance is found in an empirical investigation.</nextsent>
<nextsent>5 word sense annotation data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3469">
<title id=" W10-1806.xml">anveshan a framework for analysis of multiple annotatorsrsquo labeling behavior </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>through simulation study, the authors find that machine learning performance can degrade or not with lower agreement, depending on whether the disagreement is due to noise or systematic behavior.
</prevsent>
<prevsent>noise has relatively little impact compared with systematic disagreements.
</prevsent>
</prevsection>
<citsent citstr=" L08-1167 ">
in (passonneau et al, 2008), <papid> L08-1167 </papid>similar lack of correlation between inter annotator agreement and machine learning performance is found in an empirical investigation.</citsent>
<aftsection>
<nextsent>5 word sense annotation data.
</nextsent>
<nextsent>5.1 trained annotator data.
</nextsent>
<nextsent>the manually annotated sub-corpus (masc) project (ide et al, 2010) is creating small, representative corpus of american english written and spoken texts drawn from the open american national corpus (oanc).2 the masc corpus includes hand-validated or manual annotations for variety of linguistic phenomena.
</nextsent>
<nextsent>the first masc release, available as of may 2010, consists of 82k words.3 one of the goals of masc is to support efforts to harmonize wordnet (miller et al, 1993) and framenet (ruppenhofer et al, 2006), in order to bring the sense distinctions each makes into better alignment.we chose ten fairly frequent, moderately polysemous words for sense tagging.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3470">
<title id=" W10-1114.xml">extracting formulaic and free text clinical research articles meta data using conditional random fields </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>(he and kayaalp, 2008) reports on the suitability ofcrfs to find biological entities, combining basic orthographic token features with features derived from semantic lexicons such as umls, abgene, sem rep and metamap.
</prevsent>
<prevsent>in related vein, crfs have been applied to gene map and relationship identification as well (bundschus et al, 2008; talreja et al, 2004).in different domain, digital library practitioners have also studied how to extract formulaic meta data to enable more comprehensive article indexing.
</prevsent>
</prevsection>
<citsent citstr=" N04-1042 ">
to extract author and title information, systems have used both the support vector machine (svm) (han et al, 2003) and crfs (peng and mccallum, 2004; <papid> N04-1042 </papid>councill et al, 2008).<papid> L08-1291 </papid></citsent>
<aftsection>
<nextsent>these works have been applied largely to the computer science community and have not yet been extensively tested on biomedical and clinical research articles.
</nextsent>
<nextsent>our work differs from the above by making use of crfs to extract fields in clinical text.
</nextsent>
<nextsent>similarlexical-based features are employed, however in addition to regular author meta data, we also attempt to extract domain-specific fields from the body text of the article.
</nextsent>
<nextsent>external to the scope of the research presented here, our wider project goal focuses on constructing knowledge base of clinical researchers, databases, instruments and expertise in the asia-pacific region.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3471">
<title id=" W10-1114.xml">extracting formulaic and free text clinical research articles meta data using conditional random fields </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>(he and kayaalp, 2008) reports on the suitability ofcrfs to find biological entities, combining basic orthographic token features with features derived from semantic lexicons such as umls, abgene, sem rep and metamap.
</prevsent>
<prevsent>in related vein, crfs have been applied to gene map and relationship identification as well (bundschus et al, 2008; talreja et al, 2004).in different domain, digital library practitioners have also studied how to extract formulaic meta data to enable more comprehensive article indexing.
</prevsent>
</prevsection>
<citsent citstr=" L08-1291 ">
to extract author and title information, systems have used both the support vector machine (svm) (han et al, 2003) and crfs (peng and mccallum, 2004; <papid> N04-1042 </papid>councill et al, 2008).<papid> L08-1291 </papid></citsent>
<aftsection>
<nextsent>these works have been applied largely to the computer science community and have not yet been extensively tested on biomedical and clinical research articles.
</nextsent>
<nextsent>our work differs from the above by making use of crfs to extract fields in clinical text.
</nextsent>
<nextsent>similarlexical-based features are employed, however in addition to regular author meta data, we also attempt to extract domain-specific fields from the body text of the article.
</nextsent>
<nextsent>external to the scope of the research presented here, our wider project goal focuses on constructing knowledge base of clinical researchers, databases, instruments and expertise in the asia-pacific region.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3476">
<title id=" W10-3015.xml">exploiting multi features to detect hedges and their scope in biomedical texts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>szarvas et al (2008) report that 17.69% of the sentences in the abstracts section of the bio scope corpus and 22.29% of the sentences in the full papers section contain hedge cues.
</prevsent>
<prevsent>light et al (2004) estimate that 11% of sentences in medline abstracts contain speculative fragments.
</prevsent>
</prevsection>
<citsent citstr=" P07-1125 ">
szarvas (2008) reports that 32.41% of gene names mentioned in the hedge classification dataset described in medlock and briscoe (2007) <papid> P07-1125 </papid>appear in speculative sentence.</citsent>
<aftsection>
<nextsent>many wikipedia articles contain specific weasel tag which mark sentences as non-factual (ganter and strube, 2009).<papid> P09-2044 </papid></nextsent>
<nextsent>there are some natural language processing (nlp) researches that demonstrate the benefit of hedge detection experimentally in several subjects, such as the icd-9-cm coding of radiology reports and gene named entity extraction (szarvas, 2008), question answering systems (riloff et al, 2003), <papid> W03-0404 </papid>information extraction from biomedical texts (medlock and briscoe, 2007).<papid> P07-1125 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3478">
<title id=" W10-3015.xml">exploiting multi features to detect hedges and their scope in biomedical texts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>light et al (2004) estimate that 11% of sentences in medline abstracts contain speculative fragments.
</prevsent>
<prevsent>szarvas (2008) reports that 32.41% of gene names mentioned in the hedge classification dataset described in medlock and briscoe (2007) <papid> P07-1125 </papid>appear in speculative sentence.</prevsent>
</prevsection>
<citsent citstr=" P09-2044 ">
many wikipedia articles contain specific weasel tag which mark sentences as non-factual (ganter and strube, 2009).<papid> P09-2044 </papid></citsent>
<aftsection>
<nextsent>there are some natural language processing (nlp) researches that demonstrate the benefit of hedge detection experimentally in several subjects, such as the icd-9-cm coding of radiology reports and gene named entity extraction (szarvas, 2008), question answering systems (riloff et al, 2003), <papid> W03-0404 </papid>information extraction from biomedical texts (medlock and briscoe, 2007).<papid> P07-1125 </papid></nextsent>
<nextsent>the conll-2010 shared task (farkas et al, 2010) learning to detect hedges and their scope in natural language text?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3479">
<title id=" W10-3015.xml">exploiting multi features to detect hedges and their scope in biomedical texts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>szarvas (2008) reports that 32.41% of gene names mentioned in the hedge classification dataset described in medlock and briscoe (2007) <papid> P07-1125 </papid>appear in speculative sentence.</prevsent>
<prevsent>many wikipedia articles contain specific weasel tag which mark sentences as non-factual (ganter and strube, 2009).<papid> P09-2044 </papid></prevsent>
</prevsection>
<citsent citstr=" W03-0404 ">
there are some natural language processing (nlp) researches that demonstrate the benefit of hedge detection experimentally in several subjects, such as the icd-9-cm coding of radiology reports and gene named entity extraction (szarvas, 2008), question answering systems (riloff et al, 2003), <papid> W03-0404 </papid>information extraction from biomedical texts (medlock and briscoe, 2007).<papid> P07-1125 </papid></citsent>
<aftsection>
<nextsent>the conll-2010 shared task (farkas et al, 2010) learning to detect hedges and their scope in natural language text?
</nextsent>
<nextsent>proposed two tasks related to speculation research.
</nextsent>
<nextsent>task 1 aimed to identify sentences containing uncertainty and task 2 aimed to resolve the in-sentence scope of hedge cues.
</nextsent>
<nextsent>we participated in both tasks.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3483">
<title id=" W10-3015.xml">exploiting multi features to detect hedges and their scope in biomedical texts </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>he argued for separation of the acquisition and classification phases in semi-supervised machine learning method and presented probabilistic acquisition model.
</prevsent>
<prevsent>in probabilistic model he assumed bigrams and single terms as features based on the intuition that many hedge cues are bigrams and single terms and achieves peak performance of around 0.82 bep.
</prevsent>
</prevsection>
<citsent citstr=" W09-1304 ">
morante and daelemans (2009) <papid> W09-1304 </papid>presented meta-learning system that finds the scope of hedge cues in biomedical texts.</citsent>
<aftsection>
<nextsent>the system worked in two phases: in the first phase hedge cues are identified, and in the second phase the full scopes of these hedge cues are found.
</nextsent>
<nextsent>the performance of the system is tested on three sub corpora of the bio scope corpus.
</nextsent>
<nextsent>in the hedge finding phase, the system achieves an f-score of 84.77% in the abstracts subcorpus.
</nextsent>
<nextsent>in the scope finding phase, the system with predicted hedge cues achieves an f-score of 78.54% in the abstracts subcorpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3485">
<title id=" W10-3015.xml">exploiting multi features to detect hedges and their scope in biomedical texts </title>
<section> hedge scope finding.  </section>
<citcontext>
<prevsection>
<prevsent>hedge scopes usually can be determined on the basis of syntactic patterns dependent on the cue.
</prevsent>
<prevsent>therefore, syntactic pattern-based system is also implemented for hedge scope finding.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
when the sentence is predicted as uncertain, the toolkit of stanford parser3 (klein and manning, 2003) <papid> P03-1054 </papid>is utilized to parse the sentence into syntactic tree, which can release lot of information about the grammatical structure of sentences that is beneficial for the finding of hedge scope.</citsent>
<aftsection>
<nextsent>for sentence (c) the stanford parser gives the syntactic tree as showed in figure 2.
</nextsent>
<nextsent>(c) this  xcope id= x*.*.*   cue ref= x*.*.*  type= speculation   may  /cue  represent viral illness /xcope .
</nextsent>
<nextsent>it is obvious to see from the syntactic tree, all the words of the parsed sentence concentrate at the places of leaves.
</nextsent>
<nextsent>we use the following rules to find the scope.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3486">
<title id=" W10-3907.xml">a look inside the distributionally similar terms </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>synonymous,hypernym-hyponym, and meronymic relations are about 62%, 17%, 8% and 1% of the classified data, respectively.
</prevsent>
<prevsent>the explosion of online text allows us to enjoy broad variety of large-scale lexical resources constructed from the texts in the web in an unsupervised fashion.
</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
this line of approach was pioneered by researchers such as hindle (1990), grefenstette (1993), lee (1997) and lin (1998).<papid> P98-2127 </papid></citsent>
<aftsection>
<nextsent>at the heart of the approach is crucial working assumption called distributional hypothesis,?
</nextsent>
<nextsent>as with harris (1954).
</nextsent>
<nextsent>we now see an impressive number of applications in natural language processing (nlp) that benefit from lexical resources directly or indirectly derived from this assumption.
</nextsent>
<nextsent>it seems that most researchers are reasonably satisfied with the results obtained thus far.does this mean, however, that the distributional hypothesis was proved to be valid?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3487">
<title id=" W10-3907.xml">a look inside the distributionally similar terms </title>
<section> method and data.  </section>
<citcontext>
<prevsection>
<prevsent>, ti,n].
</prevsent>
<prevsent>2.2 data.
</prevsent>
</prevsection>
<citsent citstr=" P08-1047 ">
for , we used kazamas nominal term clustering (kazama and torisawa, 2008; <papid> P08-1047 </papid>kazama et al,2009).</citsent>
<aftsection>
<nextsent>in this data, base set for is one million terms defined by the type counts of dependency relations, which is roughly equated with the frequencies?
</nextsent>
<nextsent>of the terms.
</nextsent>
<nextsent>each base termin is associated with up to 500 of the most distributionally similar terms.
</nextsent>
<nextsent>this defines .for m, we used the jensen-shannon divergence (js-divergence) base on the probability distributions derived by an em-based soft clustering (kazama and torisawa, 2008).<papid> P08-1047 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3489">
<title id=" W10-3907.xml">a look inside the distributionally similar terms </title>
<section> method and data.  </section>
<citcontext>
<prevsection>
<prevsent>for convenience, some relevant details of the data construction are described in appendix a, but in anutshell, we used dependency relations as distributional information.
</prevsent>
<prevsent>this makes our method comparable to that used in hindle (1990).
</prevsent>
</prevsection>
<citsent citstr=" I08-1025 ">
the statistics of the distributional data used were asfollows: roughly 920 million types of dependency relations1) were automatically acquired 1)the 920 million types come in two kinds of context triples: 590 million types of (t, p,v) and 320 million types from large-scale japanese web-corpus called the tsubaki corpus (shinzato et al, 2008) <papid> I08-1025 </papid>which consists of roughly 100 million japanese pages with six billion sentences.</citsent>
<aftsection>
<nextsent>after excluding hapax nouns, we had about 33 million types of nouns (in terms of string) and 27 million types of verbs.
</nextsent>
<nextsent>these nouns were ranked by type count of the two context triples, i.e., (t, p,v) and (n?, p?, t).
</nextsent>
<nextsent>b was determined by selecting the top one million terms with the most variations of context triples.
</nextsent>
<nextsent>2.2.1 sample of [b] for illustration, we present examples of the web-derived distributional similar terms.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3490">
<title id=" W10-3907.xml">a look inside the distributionally similar terms </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>to determine the similarity metric of pair of nominal terms (t1, t2), kazama et al (2009) used the jensen-shannon divergence (js-divergence) djs(p||q) = 12d(p||m) + 12d(q||m), where pand are probability distributions, and = p(i)log p(i)q(i) (kullback-leibler divergence, or kl-divergence) of and q, and = 12(p+ q).we obtained and in the following way.
</prevsent>
<prevsent>instead of using raw distribution, kazama etal.
</prevsent>
</prevsection>
<citsent citstr=" P99-1014 ">
(2009) applied smoothing using em algorithm (rooth et al, 1999; <papid> P99-1014 </papid>torisawa, 2001).</citsent>
<aftsection>
<nextsent>in torisawas model (2001), the probability of the occurrence of the dependency relation v,r,n? is defined as: p(v,r, t?)
</nextsent>
<nextsent>=def ? aa p(v,r?|a)p(t|a)p(a), where denotes hidden class of v,r? and term t. in this equation, the probabilities p(v,r?|a), p(t|a), and p(a) cannot be calculated directly because class is not observed in given dependency data.
</nextsent>
<nextsent>the em-based clustering method estimates these probabilities using given corpus.
</nextsent>
<nextsent>in the e-step, the probability p(a|v,r?) is calculated.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3491">
<title id=" W10-2406.xml">transliteration using a phrase based statistical machine translation system to rescore the output of a joint multi gram model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in our experiments on development data, the combined system was able to outperform both of its component systems substantially.
</prevsent>
<prevsent>in statistical machine translation the re-scoring of hypotheses produced by system with additional models that incorporate information not available to the original system has been shown to be an effective technique to improve system performance (paul et al, 2006).
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
our approach uses re-scoring technique to integrate the models of two transliteration systems that are each capable in their own right: phrase-based statistical machine translation system (koehn et al., 2003), <papid> N03-1017 </papid>and joint multi gram model (deligne and bimbot, 1995; bisani and ney, 2008).</citsent>
<aftsection>
<nextsent>in this work we treat the process of transliteration as process of direct transduction from sequences of tokens in the source language to sequences of tokens in the target language with no modeling of the phone tics of either source or target language (knight and graehl, 1997).<papid> P97-1017 </papid></nextsent>
<nextsent>taking this approach allows for very general transliteration system to be built that does not require any language specific knowledge to be incorporated into the system (for some language pairs this may not be the best strategy since linguistic information can be used to overcome issues of data sparseness on smaller datasets).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3492">
<title id=" W10-2406.xml">transliteration using a phrase based statistical machine translation system to rescore the output of a joint multi gram model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in statistical machine translation the re-scoring of hypotheses produced by system with additional models that incorporate information not available to the original system has been shown to be an effective technique to improve system performance (paul et al, 2006).
</prevsent>
<prevsent>our approach uses re-scoring technique to integrate the models of two transliteration systems that are each capable in their own right: phrase-based statistical machine translation system (koehn et al., 2003), <papid> N03-1017 </papid>and joint multi gram model (deligne and bimbot, 1995; bisani and ney, 2008).</prevsent>
</prevsection>
<citsent citstr=" P97-1017 ">
in this work we treat the process of transliteration as process of direct transduction from sequences of tokens in the source language to sequences of tokens in the target language with no modeling of the phone tics of either source or target language (knight and graehl, 1997).<papid> P97-1017 </papid></citsent>
<aftsection>
<nextsent>taking this approach allows for very general transliteration system to be built that does not require any language specific knowledge to be incorporated into the system (for some language pairs this may not be the best strategy since linguistic information can be used to overcome issues of data sparseness on smaller datasets).
</nextsent>
<nextsent>for this shared task we chose to combine two systems through process of re-scoring.
</nextsent>
<nextsent>the systems were selected because of their expected strong level of performance (smt systems have been used successfully in the field, and joint multi gram models have performed well both in grapheme to phoneme conversion and arabic english transliteration).
</nextsent>
<nextsent>secondly, the joint mul tigram model relies on key features not present in the smt system, that is the history of bilingual phrase pairs used to derive the target.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3493">
<title id=" W10-2406.xml">transliteration using a phrase based statistical machine translation system to rescore the output of a joint multi gram model </title>
<section> component systems.  </section>
<citcontext>
<prevsection>
<prevsent>in joint multi gram, the units in the model consist of multiple input and output symbols.
</prevsent>
<prevsent>(bisani and ney, 2008) refined the approach and applied to it grapheme-to-phoneme conversion, where its performance was shown to be comparable to state-of-the-art systems.
</prevsent>
</prevsection>
<citsent citstr=" W09-0438 ">
the approach was later applied to arabic-english transliteration (dese laers et al, 2009) <papid> W09-0438 </papid>again with promising results.</citsent>
<aftsection>
<nextsent>joint multi gram models have the following characteristics: ? the symbols in the source and target are co-segmented transliteration using phrase-based statistical machine translation system to re-score the output of joint multi gram model andrew finch nict 3-5 hikaridai kei hanna science city 619-0289 japan andrew.finch@nict.go.jp eiichiro sumita nict 3-5 hikaridai kei hanna science city 619-0289 japan eiichiro.sumita@nict.go.jp 48 -maximum likelihood training using an em algorithm (deligne and bimbot, 1995) the probability of sequences of joint mul tigrams is modeled using an n-gram model in these respects the model can be viewed as close relative of the joint source channel model proposed by (li et al., 2004) <papid> P04-1021 </papid>for tran slit eration.</nextsent>
<nextsent>2.2 phrase-based smt.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3494">
<title id=" W10-2406.xml">transliteration using a phrase based statistical machine translation system to rescore the output of a joint multi gram model </title>
<section> component systems.  </section>
<citcontext>
<prevsection>
<prevsent>(bisani and ney, 2008) refined the approach and applied to it grapheme-to-phoneme conversion, where its performance was shown to be comparable to state-of-the-art systems.
</prevsent>
<prevsent>the approach was later applied to arabic-english transliteration (dese laers et al, 2009) <papid> W09-0438 </papid>again with promising results.</prevsent>
</prevsection>
<citsent citstr=" P04-1021 ">
joint multi gram models have the following characteristics: ? the symbols in the source and target are co-segmented transliteration using phrase-based statistical machine translation system to re-score the output of joint multi gram model andrew finch nict 3-5 hikaridai kei hanna science city 619-0289 japan andrew.finch@nict.go.jp eiichiro sumita nict 3-5 hikaridai kei hanna science city 619-0289 japan eiichiro.sumita@nict.go.jp 48 -maximum likelihood training using an em algorithm (deligne and bimbot, 1995) the probability of sequences of joint mul tigrams is modeled using an n-gram model in these respects the model can be viewed as close relative of the joint source channel model proposed by (li et al., 2004) <papid> P04-1021 </papid>for tran slit eration.</citsent>
<aftsection>
<nextsent>2.2 phrase-based smt.
</nextsent>
<nextsent>it is possible to view the process of transliteration as process of translation at the character level, without re-ordering.
</nextsent>
<nextsent>from this perspective it is possible to directly employ phrase-based smt system in the task of transliteration (finch and sumita, 2008; <papid> I08-8003 </papid>rama and gali, 2009).<papid> W09-3528 </papid></nextsent>
<nextsent>a phrase-based smt system has the following characteristics: ? the symbols in the source and target are aligned one to many in both directions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3495">
<title id=" W10-2406.xml">transliteration using a phrase based statistical machine translation system to rescore the output of a joint multi gram model </title>
<section> component systems.  </section>
<citcontext>
<prevsection>
<prevsent>2.2 phrase-based smt.
</prevsent>
<prevsent>it is possible to view the process of transliteration as process of translation at the character level, without re-ordering.
</prevsent>
</prevsection>
<citsent citstr=" I08-8003 ">
from this perspective it is possible to directly employ phrase-based smt system in the task of transliteration (finch and sumita, 2008; <papid> I08-8003 </papid>rama and gali, 2009).<papid> W09-3528 </papid></citsent>
<aftsection>
<nextsent>a phrase-based smt system has the following characteristics: ? the symbols in the source and target are aligned one to many in both directions.
</nextsent>
<nextsent>joint sequences of source and target symbols are heuristic ally extracted given these alignments transliteration is performed using loglinear model with weights tuned on development data ? the models include: translation model (with 5 sub-models), and target language model the bilingual phrase-pairs are analogous to the joint multi grams, however the translation model of the smt system doesnt use the context of previously translated phrase-pairs, instead relying on target language model.
</nextsent>
<nextsent>3.1 smt decoder.
</nextsent>
<nextsent>in our experiments we used an in-house phrase based statistical machine translation decoder called cleopatra.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3496">
<title id=" W10-2406.xml">transliteration using a phrase based statistical machine translation system to rescore the output of a joint multi gram model </title>
<section> component systems.  </section>
<citcontext>
<prevsection>
<prevsent>2.2 phrase-based smt.
</prevsent>
<prevsent>it is possible to view the process of transliteration as process of translation at the character level, without re-ordering.
</prevsent>
</prevsection>
<citsent citstr=" W09-3528 ">
from this perspective it is possible to directly employ phrase-based smt system in the task of transliteration (finch and sumita, 2008; <papid> I08-8003 </papid>rama and gali, 2009).<papid> W09-3528 </papid></citsent>
<aftsection>
<nextsent>a phrase-based smt system has the following characteristics: ? the symbols in the source and target are aligned one to many in both directions.
</nextsent>
<nextsent>joint sequences of source and target symbols are heuristic ally extracted given these alignments transliteration is performed using loglinear model with weights tuned on development data ? the models include: translation model (with 5 sub-models), and target language model the bilingual phrase-pairs are analogous to the joint multi grams, however the translation model of the smt system doesnt use the context of previously translated phrase-pairs, instead relying on target language model.
</nextsent>
<nextsent>3.1 smt decoder.
</nextsent>
<nextsent>in our experiments we used an in-house phrase based statistical machine translation decoder called cleopatra.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3498">
<title id=" W10-2406.xml">transliteration using a phrase based statistical machine translation system to rescore the output of a joint multi gram model </title>
<section> experimental conditions.  </section>
<citcontext>
<prevsection>
<prevsent>under the assumption that these parameters would perform well in the systems trained on the combined development/training corpora, these tuned parameters were transferred directly to the systems trained on all available data.
</prevsent>
<prevsent>3.6 parameter tuning.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
the smt systems were tuned using the minimum error rate training procedure introduced in (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>for convenience, we used bleu as proxy for the various metrics used in the shared task evaluation.
</nextsent>
<nextsent>the bleu score is commonly used to evaluate the performance of figure 2: the transliteration process for multi-word sequences word 1 word 2 word segment into individual words and trans literate each word independently r n l t r t t a s i e a e r n l t r t n-best hypothesis 1 hypothesis 2 ... hypothesis n-best hypothesis 1 hypothesis 2 ... hypothesis n-best hypothesis 1 hypothesis 2 ... hypothesis search for the best path figure 3: the effect on the f-score of the integrated system by tuning with respect to the smt systems interpolation weight 0.83 0.84 0.85 0 0.2 0.4 0.6 0.8 1.0 s o e smt system interpolation weight 50 machine translation systems and is function of the geometric mean of n-gram precision.
</nextsent>
<nextsent>the use of bleu score as proxy has been shown to be reasonable strategy for the metrics used in these experiments (finch and sumita, 2009).<papid> W09-3510 </papid></nextsent>
<nextsent>nonetheless, it is reasonable to assume that one would be able to improve the performance in particular evaluation metric by doing minimum error rate training specifically for that metric.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3499">
<title id=" W10-2406.xml">transliteration using a phrase based statistical machine translation system to rescore the output of a joint multi gram model </title>
<section> experimental conditions.  </section>
<citcontext>
<prevsection>
<prevsent>for convenience, we used bleu as proxy for the various metrics used in the shared task evaluation.
</prevsent>
<prevsent>the bleu score is commonly used to evaluate the performance of figure 2: the transliteration process for multi-word sequences word 1 word 2 word segment into individual words and trans literate each word independently r n l t r t t a s i e a e r n l t r t n-best hypothesis 1 hypothesis 2 ... hypothesis n-best hypothesis 1 hypothesis 2 ... hypothesis n-best hypothesis 1 hypothesis 2 ... hypothesis search for the best path figure 3: the effect on the f-score of the integrated system by tuning with respect to the smt systems interpolation weight 0.83 0.84 0.85 0 0.2 0.4 0.6 0.8 1.0 s o e smt system interpolation weight 50 machine translation systems and is function of the geometric mean of n-gram precision.
</prevsent>
</prevsection>
<citsent citstr=" W09-3510 ">
the use of bleu score as proxy has been shown to be reasonable strategy for the metrics used in these experiments (finch and sumita, 2009).<papid> W09-3510 </papid></citsent>
<aftsection>
<nextsent>nonetheless, it is reasonable to assume that one would be able to improve the performance in particular evaluation metric by doing minimum error rate training specifically for that metric.
</nextsent>
<nextsent>the interpolation weight was tuned by grid search to find the value that gave the maximal fscore (according to the official f-score evaluation metric for the shared task) on the development data, the process for english-japanese is shown in figure 3.
</nextsent>
<nextsent>the results of our experiments are shown in table 1.
</nextsent>
<nextsent>these results are the official shared task evaluation results on the test data, and the scores for all of the evaluation metrics are shown in the table.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3500">
<title id=" W10-3209.xml">constructing thai opinion mining resource a case study on hotel reviews </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>opinion mining and sentiment analysis is such task for analyzing and summarizing what people think about certain topic.
</prevsent>
<prevsent>due to its potential and useful applications, opinion mining has gained lot of interest in text mining and nlp communities (ding et al, 2008; jin et al, 2009).
</prevsent>
</prevsection>
<citsent citstr=" P02-1053 ">
much work in this area focused on evaluating reviews as being positive or negative either at the document level (turney, 2002; <papid> P02-1053 </papid>pang et al, 2002; <papid> W02-1011 </papid>dave et al, 2003; beineke et al, 2004) <papid> P04-1034 </papid>or sentence level (kim and hovy, 2004; <papid> C04-1200 </papid>wiebe and riloff, 2005; wilson et al,2009; <papid> J09-3003 </papid>yu and hatzivassiloglou, 2003).<papid> W03-1017 </papid></citsent>
<aftsection>
<nextsent>for instance, given some reviews of product, the system classifies them into positive or negative reviews.
</nextsent>
<nextsent>no specific details or features are identified about what customers like or dislike.
</nextsent>
<nextsent>to obtain such details, feature-based opinion mining approach has been proposed (hu and liu, 2004;popescu and etzioni, 2005).<papid> H05-1043 </papid></nextsent>
<nextsent>this approach typically consists of two following steps.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3501">
<title id=" W10-3209.xml">constructing thai opinion mining resource a case study on hotel reviews </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>opinion mining and sentiment analysis is such task for analyzing and summarizing what people think about certain topic.
</prevsent>
<prevsent>due to its potential and useful applications, opinion mining has gained lot of interest in text mining and nlp communities (ding et al, 2008; jin et al, 2009).
</prevsent>
</prevsection>
<citsent citstr=" W02-1011 ">
much work in this area focused on evaluating reviews as being positive or negative either at the document level (turney, 2002; <papid> P02-1053 </papid>pang et al, 2002; <papid> W02-1011 </papid>dave et al, 2003; beineke et al, 2004) <papid> P04-1034 </papid>or sentence level (kim and hovy, 2004; <papid> C04-1200 </papid>wiebe and riloff, 2005; wilson et al,2009; <papid> J09-3003 </papid>yu and hatzivassiloglou, 2003).<papid> W03-1017 </papid></citsent>
<aftsection>
<nextsent>for instance, given some reviews of product, the system classifies them into positive or negative reviews.
</nextsent>
<nextsent>no specific details or features are identified about what customers like or dislike.
</nextsent>
<nextsent>to obtain such details, feature-based opinion mining approach has been proposed (hu and liu, 2004;popescu and etzioni, 2005).<papid> H05-1043 </papid></nextsent>
<nextsent>this approach typically consists of two following steps.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3502">
<title id=" W10-3209.xml">constructing thai opinion mining resource a case study on hotel reviews </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>opinion mining and sentiment analysis is such task for analyzing and summarizing what people think about certain topic.
</prevsent>
<prevsent>due to its potential and useful applications, opinion mining has gained lot of interest in text mining and nlp communities (ding et al, 2008; jin et al, 2009).
</prevsent>
</prevsection>
<citsent citstr=" P04-1034 ">
much work in this area focused on evaluating reviews as being positive or negative either at the document level (turney, 2002; <papid> P02-1053 </papid>pang et al, 2002; <papid> W02-1011 </papid>dave et al, 2003; beineke et al, 2004) <papid> P04-1034 </papid>or sentence level (kim and hovy, 2004; <papid> C04-1200 </papid>wiebe and riloff, 2005; wilson et al,2009; <papid> J09-3003 </papid>yu and hatzivassiloglou, 2003).<papid> W03-1017 </papid></citsent>
<aftsection>
<nextsent>for instance, given some reviews of product, the system classifies them into positive or negative reviews.
</nextsent>
<nextsent>no specific details or features are identified about what customers like or dislike.
</nextsent>
<nextsent>to obtain such details, feature-based opinion mining approach has been proposed (hu and liu, 2004;popescu and etzioni, 2005).<papid> H05-1043 </papid></nextsent>
<nextsent>this approach typically consists of two following steps.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3503">
<title id=" W10-3209.xml">constructing thai opinion mining resource a case study on hotel reviews </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>opinion mining and sentiment analysis is such task for analyzing and summarizing what people think about certain topic.
</prevsent>
<prevsent>due to its potential and useful applications, opinion mining has gained lot of interest in text mining and nlp communities (ding et al, 2008; jin et al, 2009).
</prevsent>
</prevsection>
<citsent citstr=" C04-1200 ">
much work in this area focused on evaluating reviews as being positive or negative either at the document level (turney, 2002; <papid> P02-1053 </papid>pang et al, 2002; <papid> W02-1011 </papid>dave et al, 2003; beineke et al, 2004) <papid> P04-1034 </papid>or sentence level (kim and hovy, 2004; <papid> C04-1200 </papid>wiebe and riloff, 2005; wilson et al,2009; <papid> J09-3003 </papid>yu and hatzivassiloglou, 2003).<papid> W03-1017 </papid></citsent>
<aftsection>
<nextsent>for instance, given some reviews of product, the system classifies them into positive or negative reviews.
</nextsent>
<nextsent>no specific details or features are identified about what customers like or dislike.
</nextsent>
<nextsent>to obtain such details, feature-based opinion mining approach has been proposed (hu and liu, 2004;popescu and etzioni, 2005).<papid> H05-1043 </papid></nextsent>
<nextsent>this approach typically consists of two following steps.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3504">
<title id=" W10-3209.xml">constructing thai opinion mining resource a case study on hotel reviews </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>opinion mining and sentiment analysis is such task for analyzing and summarizing what people think about certain topic.
</prevsent>
<prevsent>due to its potential and useful applications, opinion mining has gained lot of interest in text mining and nlp communities (ding et al, 2008; jin et al, 2009).
</prevsent>
</prevsection>
<citsent citstr=" J09-3003 ">
much work in this area focused on evaluating reviews as being positive or negative either at the document level (turney, 2002; <papid> P02-1053 </papid>pang et al, 2002; <papid> W02-1011 </papid>dave et al, 2003; beineke et al, 2004) <papid> P04-1034 </papid>or sentence level (kim and hovy, 2004; <papid> C04-1200 </papid>wiebe and riloff, 2005; wilson et al,2009; <papid> J09-3003 </papid>yu and hatzivassiloglou, 2003).<papid> W03-1017 </papid></citsent>
<aftsection>
<nextsent>for instance, given some reviews of product, the system classifies them into positive or negative reviews.
</nextsent>
<nextsent>no specific details or features are identified about what customers like or dislike.
</nextsent>
<nextsent>to obtain such details, feature-based opinion mining approach has been proposed (hu and liu, 2004;popescu and etzioni, 2005).<papid> H05-1043 </papid></nextsent>
<nextsent>this approach typically consists of two following steps.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3505">
<title id=" W10-3209.xml">constructing thai opinion mining resource a case study on hotel reviews </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>opinion mining and sentiment analysis is such task for analyzing and summarizing what people think about certain topic.
</prevsent>
<prevsent>due to its potential and useful applications, opinion mining has gained lot of interest in text mining and nlp communities (ding et al, 2008; jin et al, 2009).
</prevsent>
</prevsection>
<citsent citstr=" W03-1017 ">
much work in this area focused on evaluating reviews as being positive or negative either at the document level (turney, 2002; <papid> P02-1053 </papid>pang et al, 2002; <papid> W02-1011 </papid>dave et al, 2003; beineke et al, 2004) <papid> P04-1034 </papid>or sentence level (kim and hovy, 2004; <papid> C04-1200 </papid>wiebe and riloff, 2005; wilson et al,2009; <papid> J09-3003 </papid>yu and hatzivassiloglou, 2003).<papid> W03-1017 </papid></citsent>
<aftsection>
<nextsent>for instance, given some reviews of product, the system classifies them into positive or negative reviews.
</nextsent>
<nextsent>no specific details or features are identified about what customers like or dislike.
</nextsent>
<nextsent>to obtain such details, feature-based opinion mining approach has been proposed (hu and liu, 2004;popescu and etzioni, 2005).<papid> H05-1043 </papid></nextsent>
<nextsent>this approach typically consists of two following steps.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3506">
<title id=" W10-3209.xml">constructing thai opinion mining resource a case study on hotel reviews </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for instance, given some reviews of product, the system classifies them into positive or negative reviews.
</prevsent>
<prevsent>no specific details or features are identified about what customers like or dislike.
</prevsent>
</prevsection>
<citsent citstr=" H05-1043 ">
to obtain such details, feature-based opinion mining approach has been proposed (hu and liu, 2004;popescu and etzioni, 2005).<papid> H05-1043 </papid></citsent>
<aftsection>
<nextsent>this approach typically consists of two following steps.
</nextsent>
<nextsent>1.
</nextsent>
<nextsent>identifying and extracting features of an ob-.
</nextsent>
<nextsent>ject, topic or event from each sentence upon which the reviewers expressed their opinion.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3507">
<title id=" W10-3209.xml">constructing thai opinion mining resource a case study on hotel reviews </title>
<section> determining whether the opinions regard-.  </section>
<citcontext>
<prevsection>
<prevsent>for particular domain, set of features and polar words must be prepared.
</prevsent>
<prevsent>the process for language resource construction is generally labor intensive and time consuming.
</prevsent>
</prevsection>
<citsent citstr=" W03-1014 ">
some previous work shave proposed different approaches for automatically constructing the lexicons for the feature based opinion mining (qiu et al, 2009; riloff and wiebe, 2003; <papid> W03-1014 </papid>sarmento et al, 2009).</citsent>
<aftsection>
<nextsent>most approaches applied some machine learning algorithms for learning the rules from the corpus.
</nextsent>
<nextsent>the rules are used for extracting new features and polar words from untagged corpus.
</nextsent>
<nextsent>reviews of different approaches are given in the related work section.
</nextsent>
<nextsent>in this paper, we propose framework for constructing thai language resource for the feature-based opinion mining.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3508">
<title id=" W10-3209.xml">constructing thai opinion mining resource a case study on hotel reviews </title>
<section> determining whether the opinions regard-.  </section>
<citcontext>
<prevsection>
<prevsent>hence, if one of them contains sentiments words, the other successive sentences are likely to contain sentiment words as well.
</prevsent>
<prevsent>ku andchen (2007) proposed the bag-of-characters approach to determine sentiment words in chinese.this approach calculates the observation probabilities of characters from set of seed sentiment words first, then dynamically expands the set and adjusts their probabilities.
</prevsent>
</prevsection>
<citsent citstr=" D09-1131 ">
later in 2009, ku et al (2009), <papid> D09-1131 </papid>extended their bag-of-characters approach by including morphological structure sand syntactic structures between sentence segment.</citsent>
<aftsection>
<nextsent>their experiments showed better performance of word polarity detection and opinion sentence extraction.some other methods to automatically generate resources for subjectivity analysis for foreign language have leveraged the resources and tools available for english.
</nextsent>
<nextsent>for example, be nea et al (2008) applied machine translation and standard naive bayes and svm for subjectivity classification for romanian.
</nextsent>
<nextsent>their experiments showed promising results for applying automatic translation to construct resources and tools for opinion mining in foreign language.
</nextsent>
<nextsent>wan (2009) <papid> P09-1027 </papid>also leveraged an available english corpus for chinese sentiment classification by using the co-training approach to make full useof both english and chinese features in unified framework.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3509">
<title id=" W10-3209.xml">constructing thai opinion mining resource a case study on hotel reviews </title>
<section> determining whether the opinions regard-.  </section>
<citcontext>
<prevsection>
<prevsent>for example, be nea et al (2008) applied machine translation and standard naive bayes and svm for subjectivity classification for romanian.
</prevsent>
<prevsent>their experiments showed promising results for applying automatic translation to construct resources and tools for opinion mining in foreign language.
</prevsent>
</prevsection>
<citsent citstr=" P09-1027 ">
wan (2009) <papid> P09-1027 </papid>also leveraged an available english corpus for chinese sentiment classification by using the co-training approach to make full useof both english and chinese features in unified framework.</citsent>
<aftsection>
<nextsent>jijkoun and hofmann (2009) <papid> E09-1046 </papid>also described method for creating dutch subjectivity lexicon based on an english lexi con.</nextsent>
<nextsent>they applied pagerank-like algorithm that bootstraps subjectivity lexicon from the translation of the english lexicon and rank the words in the thesaurus by polarity using the network of lexical relations (e.g., synonymy, hy ponymy) in wordnet.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3510">
<title id=" W10-3209.xml">constructing thai opinion mining resource a case study on hotel reviews </title>
<section> determining whether the opinions regard-.  </section>
<citcontext>
<prevsection>
<prevsent>their experiments showed promising results for applying automatic translation to construct resources and tools for opinion mining in foreign language.
</prevsent>
<prevsent>wan (2009) <papid> P09-1027 </papid>also leveraged an available english corpus for chinese sentiment classification by using the co-training approach to make full useof both english and chinese features in unified framework.</prevsent>
</prevsection>
<citsent citstr=" E09-1046 ">
jijkoun and hofmann (2009) <papid> E09-1046 </papid>also described method for creating dutch subjectivity lexicon based on an english lexi con.</citsent>
<aftsection>
<nextsent>they applied pagerank-like algorithm that bootstraps subjectivity lexicon from the translation of the english lexicon and rank the words in the thesaurus by polarity using the network of lexical relations (e.g., synonymy, hy ponymy) in wordnet.
</nextsent>
<nextsent>the performance of the feature-based opinion mining relies on the design and completeness of related lexicons.
</nextsent>
<nextsent>our lexicon design distinguishes lexicons into two types, domain dependent and domain-independent.
</nextsent>
<nextsent>the design of domain-dependent lexicons is based on thefeature-based opinion mining framework proposed by liu et al (2005).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3511">
<title id=" W10-2205.xml">a method for compiling two level rules with multiple contexts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in particular, the right-arrow rule x:z =  lc1 _ rc1; lc2 _ rc2 would say that the pair x:z (which we call the centre of the rule) may occur in either one of these two contexts.
</prevsent>
<prevsent>for various formulations of two-level rules, see e.g.
</prevsent>
</prevsection>
<citsent citstr=" E87-1003 ">
(koskenniemi, 1983), (grimleyevans et al, 1996), (black et.al., 1987), (<papid> E87-1003 </papid>ruess ink, 1989), (ritchie, 1992), (<papid> J92-1003 </papid>kiraz, 2001) and comprehensive survey on their formal interpretations, see (vaillette, 2004).</citsent>
<aftsection>
<nextsent>compiling two-level rules into transducers is easy in all other cases except for right-arrow rules with multiple context-parts; see e.g. koskenniemi (1983).
</nextsent>
<nextsent>compiling right-arrow rules with multiple context parts is more difficult because the compilation of the whole rule is not in simple relation to the component expressions in the rule; see e.g. karttunen et al (1987).
</nextsent>
<nextsent>the method proposed here reduces multi context rules into set of separate simple rules, one for each context, by introducing some auxiliary variant characters.
</nextsent>
<nextsent>these auxiliary characters are then normalized back into the original surface characters after the intersecting composition of the lexicon and the modified rules.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3512">
<title id=" W10-2205.xml">a method for compiling two level rules with multiple contexts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in particular, the right-arrow rule x:z =  lc1 _ rc1; lc2 _ rc2 would say that the pair x:z (which we call the centre of the rule) may occur in either one of these two contexts.
</prevsent>
<prevsent>for various formulations of two-level rules, see e.g.
</prevsent>
</prevsection>
<citsent citstr=" J92-1003 ">
(koskenniemi, 1983), (grimleyevans et al, 1996), (black et.al., 1987), (<papid> E87-1003 </papid>ruess ink, 1989), (ritchie, 1992), (<papid> J92-1003 </papid>kiraz, 2001) and comprehensive survey on their formal interpretations, see (vaillette, 2004).</citsent>
<aftsection>
<nextsent>compiling two-level rules into transducers is easy in all other cases except for right-arrow rules with multiple context-parts; see e.g. koskenniemi (1983).
</nextsent>
<nextsent>compiling right-arrow rules with multiple context parts is more difficult because the compilation of the whole rule is not in simple relation to the component expressions in the rule; see e.g. karttunen et al (1987).
</nextsent>
<nextsent>the method proposed here reduces multi context rules into set of separate simple rules, one for each context, by introducing some auxiliary variant characters.
</nextsent>
<nextsent>these auxiliary characters are then normalized back into the original surface characters after the intersecting composition of the lexicon and the modified rules.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3513">
<title id=" W10-2205.xml">a method for compiling two level rules with multiple contexts </title>
<section> previous compilation methods.  </section>
<citcontext>
<prevsection>
<prevsent>they all produce single transducer out of each multi-context right-arrow rule.
</prevsent>
<prevsent>2.1 method based on kaplan and kay.
</prevsent>
</prevsection>
<citsent citstr=" J94-3001 ">
kaplan and kay (1994) <papid> J94-3001 </papid>developed method around 1980 for compiling rewriting rules into finite-state transducers 2 . the method was adapted by koskenniemi to the compilation of two-level rules by modifying the formula 2 douglas johnson (1972) presented similar tech-.</citsent>
<aftsection>
<nextsent>nique earlier but his work was not well known in early 1980s.
</nextsent>
<nextsent>39 slightly.
</nextsent>
<nextsent>in this method, auxiliary left and right bracket characters ( 1,  1,  2,  2, ...)
</nextsent>
<nextsent>were freely added in order to facilitate the checking of the context conditions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3514">
<title id=" W10-2205.xml">a method for compiling two level rules with multiple contexts </title>
<section> previous compilation methods.  </section>
<citcontext>
<prevsection>
<prevsent>the compilation of rules with centres whose length is one using the gr seems very similar to that of grimley-evans et al. the nice thing about gr is that one can easily express various rule types, including but not limited to the four types listed above.
</prevsent>
<prevsent>2.4 intersecting compose.
</prevsent>
</prevsection>
<citsent citstr=" C92-1025 ">
it was observed somewhere around 1990 at xerox that the rule sets may be composed with the lexicon transducers in an efficient way and that the resulting transducer was roughly similar in size as the lexicon transducer itself (karttunen et al, 1992).<papid> C92-1025 </papid></citsent>
<aftsection>
<nextsent>this observation gives room to the new approach presented below.
</nextsent>
<nextsent>at that time, it was not practical to intersect complete two-level grammars if they contained many elaborate rules (and this is still fairly heavy operation).
</nextsent>
<nextsent>another useful observation was that the intersection of the rules could be done in joint single operation with the composition (karttunen, 1994).<papid> C94-1066 </papid></nextsent>
<nextsent>avoiding the separate intersection made the combining of the lexicon and rules feasible and faster.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3515">
<title id=" W10-2205.xml">a method for compiling two level rules with multiple contexts </title>
<section> previous compilation methods.  </section>
<citcontext>
<prevsection>
<prevsent>this observation gives room to the new approach presented below.
</prevsent>
<prevsent>at that time, it was not practical to intersect complete two-level grammars if they contained many elaborate rules (and this is still fairly heavy operation).
</prevsent>
</prevsection>
<citsent citstr=" C94-1066 ">
another useful observation was that the intersection of the rules could be done in joint single operation with the composition (karttunen, 1994).<papid> C94-1066 </papid></citsent>
<aftsection>
<nextsent>avoiding the separate intersection made the combining of the lexicon and rules feasible and faster.
</nextsent>
<nextsent>in addition to xerox lexc program, e.g. the hfst finite-state software contains this operation and it is routinely used when lexicons and two-level grammars are combined into lexicon transducers (lindn et al, 2009).
</nextsent>
<nextsent>mns huldn has noted (2009) that the composing of the lexicon and the rules is sometimes heavy operation, but can be optimized if one first composes the output side of the lexicon transducer with the rules, and thereafter the original lexicon with this intermediate result.
</nextsent>
<nextsent>the idea is to modify the two-level grammar so that the rules become simpler.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3516">
<title id=" W10-2010.xml">uncertainty reduction as a measure of cognitive processing effort </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this effect is independent from the effect of surprisal.
</prevsent>
<prevsent>in the field of computational psycho linguistics, acurrently popular approach is to account for reading times on sentences words by estimates of the amount of information conveyed by these words.
</prevsent>
</prevsection>
<citsent citstr=" N01-1021 ">
processing word that conveys more information is assumed to involve more cognitive effort, which is reflected in the time required to read the word.in this context, the most common formalization of words information content is its sur prisal (hale, 2001; <papid> N01-1021 </papid>levy, 2008).</citsent>
<aftsection>
<nextsent>if word string wt1 (short for w1, w2, . . .
</nextsent>
<nextsent>wt) is the sentence so far and (wt+1|wt1) the occurrence probability of the next word wt+1, then that words surprisal is defined as ? log (wt+1|wt1).
</nextsent>
<nextsent>it is well established by now that word-reading times indeed correlate positively with surprisal values as estimated by any sufficiently accurate generative language model (boston et al , 2008; demberg and keller, 2008; frank, 2009; roark et al , 2009; <papid> D09-1034 </papid>smith and levy, 2008).</nextsent>
<nextsent>a lesser known alternative ope rationalization ofa words information content is based on theun certainty about the rest of the sentence, quantified by hale (2003),  quantified by hale (2006) as the entropy of the probability distribution over possible sentence struc tures.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3517">
<title id=" W10-2010.xml">uncertainty reduction as a measure of cognitive processing effort </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>if word string wt1 (short for w1, w2, . . .
</prevsent>
<prevsent>wt) is the sentence so far and (wt+1|wt1) the occurrence probability of the next word wt+1, then that words surprisal is defined as ? log (wt+1|wt1).
</prevsent>
</prevsection>
<citsent citstr=" D09-1034 ">
it is well established by now that word-reading times indeed correlate positively with surprisal values as estimated by any sufficiently accurate generative language model (boston et al , 2008; demberg and keller, 2008; frank, 2009; roark et al , 2009; <papid> D09-1034 </papid>smith and levy, 2008).</citsent>
<aftsection>
<nextsent>a lesser known alternative ope rationalization ofa words information content is based on theun certainty about the rest of the sentence, quantified by hale (2003),  quantified by hale (2006) as the entropy of the probability distribution over possible sentence structures.
</nextsent>
<nextsent>the reduction in entropy that results from processing word is taken to be the amount of information conveyed by that word, and was argued by hale to be predictive of word-reading time.
</nextsent>
<nextsent>however, this entropy-reduction hypothesis has not yet been comprehensively tested, possibly because of the difficulty of computing the requiredentropies.
</nextsent>
<nextsent>although hale (2006) shows how sentence entropy can be computed given pcfg, this computation is not feasible when the grammar is of realistic size.here, we empirically investigate the entropy reduction hypothesis more thoroughly than hasbeen done before, by using recurrent neural networks as language models.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3522">
<title id=" W10-2010.xml">uncertainty reduction as a measure of cognitive processing effort </title>
<section> method.  </section>
<citcontext>
<prevsection>
<prevsent>this section presents the datasets that were used, language-model details, and the evaluation metric.
</prevsent>
<prevsent>3.1 data.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
the models were trained on the pos tag sequences of the full wsj corpus (marcus et al , 1993).<papid> J93-2004 </papid></citsent>
<aftsection>
<nextsent>they were evaluated on the pos-tagged dundee corpus (kennedy and pynte, 2005), which has been used in several studies that investigate the relation between word surprisal and reading time (demberg and keller, 2008; frank, 2009; smith and levy, 2008).
</nextsent>
<nextsent>this 2 368-sentence (51 501 words) collection of british newspaper editorials comes with eye-tracking data of 10 participants.
</nextsent>
<nextsent>pos tags for the dundee corpus were taken from frank (2009).
</nextsent>
<nextsent>for each word and each participant, reading time was defined as the total fixation time on that word before any fixation on later word of the same sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3529">
<title id=" W10-3010.xml">a high precision approach to detecting hedges and their scopes </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, information extraction systems generally focus on extracting factual information, ignoring the wealth of information expressed through such phenomena.
</prevsent>
<prevsent>in recent years, the need for information extraction and text mining systems to identify and model such extra-factual information has increasingly become clear.
</prevsent>
</prevsection>
<citsent citstr=" W04-3103 ">
for example, online product and movie reviews have provided rich context for analyzing sentiments and opinions in text (see pang and lee (2008) for recent survey), while tentative, speculative nature of scientific writing, particularly in biomedical literature, has provided impetus for recent research in speculation detection (light et al , 2004).<papid> W04-3103 </papid></citsent>
<aftsection>
<nextsent>the term hedging is often used as an umbrella term to refer to an array of extra-factual phenomena in natural language and is the focus of the conll-2010 shared task on hedge detection.the conll-2010 shared task on hedge detection (farkas et al , 2010) follows in the steps of the recent bionlp09 shared task on event extraction (kim et al , 2009), <papid> W09-1401 </papid>in which one task(speculation and negation detection) was concerned with notions related to hedging in biomedical abstracts.</nextsent>
<nextsent>however, the conll-2010 shared task differs in several aspects.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3530">
<title id=" W10-3010.xml">a high precision approach to detecting hedges and their scopes </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in recent years, the need for information extraction and text mining systems to identify and model such extra-factual information has increasingly become clear.
</prevsent>
<prevsent>for example, online product and movie reviews have provided rich context for analyzing sentiments and opinions in text (see pang and lee (2008) for recent survey), while tentative, speculative nature of scientific writing, particularly in biomedical literature, has provided impetus for recent research in speculation detection (light et al , 2004).<papid> W04-3103 </papid></prevsent>
</prevsection>
<citsent citstr=" W09-1401 ">
the term hedging is often used as an umbrella term to refer to an array of extra-factual phenomena in natural language and is the focus of the conll-2010 shared task on hedge detection.the conll-2010 shared task on hedge detection (farkas et al , 2010) follows in the steps of the recent bionlp09 shared task on event extraction (kim et al , 2009), <papid> W09-1401 </papid>in which one task(speculation and negation detection) was concerned with notions related to hedging in biomedical abstracts.</citsent>
<aftsection>
<nextsent>however, the conll-2010 shared task differs in several aspects.
</nextsent>
<nextsent>it sheds light onthe pervasiveness of hedging across genres and do mains: in addition to biomedical abstracts, it is concerned with biomedical full text articles as well as with wikipedia articles.
</nextsent>
<nextsent>both shared tasks have been concerned with scope resolution; however,their definitions of scope are fundamentally differ ent: the bionlp09 shared task takes the scopeof speculation instance to be an abstract semantic object (an event), thus normalized logical form.
</nextsent>
<nextsent>the conll-2010 shared task, on the other hand, defines it as textual unit based on syntactic considerations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3532">
<title id=" W10-3010.xml">a high precision approach to detecting hedges and their scopes </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>wiebe et al  (2005) consider subjectivity in news articles, and focus on the notion of private states, encompassing speculations, opinions, and evaluations in their subjectivity frames.
</prevsent>
<prevsent>the importance of speculative language in biomedical articles was first acknowledged by light et al  (2004).<papid> W04-3103 </papid></prevsent>
</prevsection>
<citsent citstr=" P07-1125 ">
following work in this area focused on detecting speculative sentences (med lock and briscoe, 2007; <papid> P07-1125 </papid>szarvas, 2008; kilicoglu and bergler, 2008).<papid> W08-0607 </papid></citsent>
<aftsection>
<nextsent>similar to rubin et al (2005) work, thompson et al  (2008) proposed categorization scheme for epistemic modality in biomedical text according to the type of information expressed (e.g., certainty level, point of view, knowledge type).
</nextsent>
<nextsent>with the availability of the bio scope corpus (vincze et al , 2008), in which negation, hedging and their scopes are annotated, studies in detecting speculation scope have also been reported (morante and daelemans, 2009;<papid> W09-1304 </papid>ozgur and radev, 2009).</nextsent>
<nextsent>negation and uncertainty of bio-events are also annotated to some extent in the genia event corpus (kim et al , 2008).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3533">
<title id=" W10-3010.xml">a high precision approach to detecting hedges and their scopes </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>wiebe et al  (2005) consider subjectivity in news articles, and focus on the notion of private states, encompassing speculations, opinions, and evaluations in their subjectivity frames.
</prevsent>
<prevsent>the importance of speculative language in biomedical articles was first acknowledged by light et al  (2004).<papid> W04-3103 </papid></prevsent>
</prevsection>
<citsent citstr=" W08-0607 ">
following work in this area focused on detecting speculative sentences (med lock and briscoe, 2007; <papid> P07-1125 </papid>szarvas, 2008; kilicoglu and bergler, 2008).<papid> W08-0607 </papid></citsent>
<aftsection>
<nextsent>similar to rubin et al (2005) work, thompson et al  (2008) proposed categorization scheme for epistemic modality in biomedical text according to the type of information expressed (e.g., certainty level, point of view, knowledge type).
</nextsent>
<nextsent>with the availability of the bio scope corpus (vincze et al , 2008), in which negation, hedging and their scopes are annotated, studies in detecting speculation scope have also been reported (morante and daelemans, 2009;<papid> W09-1304 </papid>ozgur and radev, 2009).</nextsent>
<nextsent>negation and uncertainty of bio-events are also annotated to some extent in the genia event corpus (kim et al , 2008).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3534">
<title id=" W10-3010.xml">a high precision approach to detecting hedges and their scopes </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>following work in this area focused on detecting speculative sentences (med lock and briscoe, 2007; <papid> P07-1125 </papid>szarvas, 2008; kilicoglu and bergler, 2008).<papid> W08-0607 </papid></prevsent>
<prevsent>similar to rubin et al (2005) work, thompson et al  (2008) proposed categorization scheme for epistemic modality in biomedical text according to the type of information expressed (e.g., certainty level, point of view, knowledge type).</prevsent>
</prevsection>
<citsent citstr=" W09-1304 ">
with the availability of the bio scope corpus (vincze et al , 2008), in which negation, hedging and their scopes are annotated, studies in detecting speculation scope have also been reported (morante and daelemans, 2009;<papid> W09-1304 </papid>ozgur and radev, 2009).</citsent>
<aftsection>
<nextsent>negation and uncertainty of bio-events are also annotated to some extent in the genia event corpus (kim et al , 2008).
</nextsent>
<nextsent>the bionlp09 shared task on event extraction (kim et al , 2009) <papid> W09-1401 </papid>dedicated task to detecting negation and speculation in biomedical abstracts, based on the genia event corpus annotations.</nextsent>
<nextsent>ganter and strube (2009) elaborated on the link between vagueness in wikipedia articles indicated by weasel words and hedging.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3536">
<title id=" W10-3010.xml">a high precision approach to detecting hedges and their scopes </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>they exploited word frequency measures and shallow syntactic patterns to detect weasel words in wikipedia articles.
</prevsent>
<prevsent>our methodology for hedge detection is essentially rule-based and relies on combination of lexical and syntactic information.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
lexical information is encoded in simple dictionary, and relevant syntactic information is identified using the stanford lexicalized parser (klein and manning, 2003).<papid> P03-1054 </papid></citsent>
<aftsection>
<nextsent>we exploit constituent parse trees as wellas corresponding collapsed dependency representations (demarneffe et al , 2006), provided by the parser.
</nextsent>
<nextsent>3.1 detecting uncertainty in biological text.
</nextsent>
<nextsent>for detecting uncertain sentences in biological text (task 1b), we built on the linguistically-inspired system previously described in detail in kilicoglu and bergler (2008).<papid> W08-0607 </papid></nextsent>
<nextsent>in summary, this system relies on dictionary of lexical speculation cues, derived from set of core surface realizations of hedging identified by hyland (1998) and expanded through wordnet (fellbaum, 1998) synsets and umlsspecialist lexicon (mccray et al , 1994) nominalizations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3538">
<title id=" W10-3010.xml">a high precision approach to detecting hedges and their scopes </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>3.3 scope resolution for uncertainty in.
</prevsent>
<prevsent>biological text task 2 of the shared task involved hedging scope resolution in biological text.
</prevsent>
</prevsection>
<citsent citstr=" W09-1418 ">
we previously tackled this problem within the context of biological text in the bionlp09 shared task (kilicoglu and bergler, 2009).<papid> W09-1418 </papid></citsent>
<aftsection>
<nextsent>that task defined the scope of speculation instances as abstract, previously extracted bio-events.
</nextsent>
<nextsent>our approach relied on finding an appropriate syntactic dependency relation between the bio-event trigger word identified in 72earlier steps and the speculation cue.
</nextsent>
<nextsent>the category of the hedging cue constrained the dependency relations that are deemed appropriate.
</nextsent>
<nextsent>for example, consider the sentence in (2a), where involves is bio-event trigger for regulation event and suggest is speculation cue of epis temic verb type.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3539">
<title id=" W10-2410.xml">syllable based thai english machine transliteration </title>
<section> proposed transliteration system.  </section>
<citcontext>
<prevsection>
<prevsent>the rest are english names selected from the news 2009 corpus based on their frequencies found by the google search.
</prevsent>
<prevsent>such english names were transliterated into thai andre checked by linguists using the royal institute transliteration guideline.
</prevsent>
</prevsection>
<citsent citstr=" W09-3521 ">
our proposed model is similar to what proposed by jiang et al (2009), <papid> W09-3521 </papid>which introduced translation among chinese and english names based on syllable units and determined the best candidate using the statistical n-gram model.</citsent>
<aftsection>
<nextsent>the overall structure of our model is shown in figure 1.
</nextsent>
<nextsent>3.1 syllabification and letter-to-sound.
</nextsent>
<nextsent>an input word in the source language is first segmented into syllable-like units.
</nextsent>
<nextsent>it is noted that there are some cases where segmented units are not really syllable.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3540">
<title id=" W10-1720.xml">matrex the dcu mt system for wmt 2010 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we participated in the english spanish (en?
</prevsent>
<prevsent>es) and english czech (encs) translation tasks.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
for these two tasks, we employ several individual mt systems: 1) baseline: phrase based smt (koehn et al, 2007); <papid> P07-2045 </papid>2) ebmt: monolingually chunking both source and target sides of the dataset using marker-based chunker (gough and way, 2004); 3) factored translation model (koehn and hoang, 2007); <papid> D07-1091 </papid>4) source-side context-informed (ssci) systems (stroppa et al,2007); 5) the moses-chart (a moses implementation of the hierarchical phrase-based (hpb)approach of chiang (2007)) <papid> J07-2003 </papid>and 6) apertium (for cada et al, 2009) rule-based machine translation(rbmt).</citsent>
<aftsection>
<nextsent>finally, we use word-level combination framework (rosti et al, 2007) <papid> N07-1029 </papid>to combine the multiple translation hypotheses and employ new rescoring model to generate the final translation.</nextsent>
<nextsent>for the system combination task, we first use the minimum bayes-risk (mbr) (kumar and byrne, 2004) <papid> N04-1022 </papid>decoder to select the best hypothesis as the alignment reference for the confusion network (cn) (mangu et al, 2000).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3541">
<title id=" W10-1720.xml">matrex the dcu mt system for wmt 2010 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we participated in the english spanish (en?
</prevsent>
<prevsent>es) and english czech (encs) translation tasks.
</prevsent>
</prevsection>
<citsent citstr=" D07-1091 ">
for these two tasks, we employ several individual mt systems: 1) baseline: phrase based smt (koehn et al, 2007); <papid> P07-2045 </papid>2) ebmt: monolingually chunking both source and target sides of the dataset using marker-based chunker (gough and way, 2004); 3) factored translation model (koehn and hoang, 2007); <papid> D07-1091 </papid>4) source-side context-informed (ssci) systems (stroppa et al,2007); 5) the moses-chart (a moses implementation of the hierarchical phrase-based (hpb)approach of chiang (2007)) <papid> J07-2003 </papid>and 6) apertium (for cada et al, 2009) rule-based machine translation(rbmt).</citsent>
<aftsection>
<nextsent>finally, we use word-level combination framework (rosti et al, 2007) <papid> N07-1029 </papid>to combine the multiple translation hypotheses and employ new rescoring model to generate the final translation.</nextsent>
<nextsent>for the system combination task, we first use the minimum bayes-risk (mbr) (kumar and byrne, 2004) <papid> N04-1022 </papid>decoder to select the best hypothesis as the alignment reference for the confusion network (cn) (mangu et al, 2000).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3542">
<title id=" W10-1720.xml">matrex the dcu mt system for wmt 2010 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we participated in the english spanish (en?
</prevsent>
<prevsent>es) and english czech (encs) translation tasks.
</prevsent>
</prevsection>
<citsent citstr=" J07-2003 ">
for these two tasks, we employ several individual mt systems: 1) baseline: phrase based smt (koehn et al, 2007); <papid> P07-2045 </papid>2) ebmt: monolingually chunking both source and target sides of the dataset using marker-based chunker (gough and way, 2004); 3) factored translation model (koehn and hoang, 2007); <papid> D07-1091 </papid>4) source-side context-informed (ssci) systems (stroppa et al,2007); 5) the moses-chart (a moses implementation of the hierarchical phrase-based (hpb)approach of chiang (2007)) <papid> J07-2003 </papid>and 6) apertium (for cada et al, 2009) rule-based machine translation(rbmt).</citsent>
<aftsection>
<nextsent>finally, we use word-level combination framework (rosti et al, 2007) <papid> N07-1029 </papid>to combine the multiple translation hypotheses and employ new rescoring model to generate the final translation.</nextsent>
<nextsent>for the system combination task, we first use the minimum bayes-risk (mbr) (kumar and byrne, 2004) <papid> N04-1022 </papid>decoder to select the best hypothesis as the alignment reference for the confusion network (cn) (mangu et al, 2000).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3543">
<title id=" W10-1720.xml">matrex the dcu mt system for wmt 2010 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>es) and english czech (encs) translation tasks.
</prevsent>
<prevsent>for these two tasks, we employ several individual mt systems: 1) baseline: phrase based smt (koehn et al, 2007); <papid> P07-2045 </papid>2) ebmt: monolingually chunking both source and target sides of the dataset using marker-based chunker (gough and way, 2004); 3) factored translation model (koehn and hoang, 2007); <papid> D07-1091 </papid>4) source-side context-informed (ssci) systems (stroppa et al,2007); 5) the moses-chart (a moses implementation of the hierarchical phrase-based (hpb)approach of chiang (2007)) <papid> J07-2003 </papid>and 6) apertium (for cada et al, 2009) rule-based machine translation(rbmt).</prevsent>
</prevsection>
<citsent citstr=" N07-1029 ">
finally, we use word-level combination framework (rosti et al, 2007) <papid> N07-1029 </papid>to combine the multiple translation hypotheses and employ new rescoring model to generate the final translation.</citsent>
<aftsection>
<nextsent>for the system combination task, we first use the minimum bayes-risk (mbr) (kumar and byrne, 2004) <papid> N04-1022 </papid>decoder to select the best hypothesis as the alignment reference for the confusion network (cn) (mangu et al, 2000).</nextsent>
<nextsent>we then build the cn using the ter metric (snover et al, 2006), and finally search for the best translation.the remainder of this paper is organised as fol lows: section 2 details the various components ofour system, in particular the multi-engine strategies used for the shared task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3544">
<title id=" W10-1720.xml">matrex the dcu mt system for wmt 2010 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for these two tasks, we employ several individual mt systems: 1) baseline: phrase based smt (koehn et al, 2007); <papid> P07-2045 </papid>2) ebmt: monolingually chunking both source and target sides of the dataset using marker-based chunker (gough and way, 2004); 3) factored translation model (koehn and hoang, 2007); <papid> D07-1091 </papid>4) source-side context-informed (ssci) systems (stroppa et al,2007); 5) the moses-chart (a moses implementation of the hierarchical phrase-based (hpb)approach of chiang (2007)) <papid> J07-2003 </papid>and 6) apertium (for cada et al, 2009) rule-based machine translation(rbmt).</prevsent>
<prevsent>finally, we use word-level combination framework (rosti et al, 2007) <papid> N07-1029 </papid>to combine the multiple translation hypotheses and employ new rescoring model to generate the final translation.</prevsent>
</prevsection>
<citsent citstr=" N04-1022 ">
for the system combination task, we first use the minimum bayes-risk (mbr) (kumar and byrne, 2004) <papid> N04-1022 </papid>decoder to select the best hypothesis as the alignment reference for the confusion network (cn) (mangu et al, 2000).</citsent>
<aftsection>
<nextsent>we then build the cn using the ter metric (snover et al, 2006), and finally search for the best translation.the remainder of this paper is organised as fol lows: section 2 details the various components ofour system, in particular the multi-engine strategies used for the shared task.
</nextsent>
<nextsent>in section 3, we outline the complete system setup for the shared task and provide evaluation results on the test set.
</nextsent>
<nextsent>section 4 concludes the paper.
</nextsent>
<nextsent>2.1 system architecture.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3546">
<title id=" W10-1720.xml">matrex the dcu mt system for wmt 2010 </title>
<section> the matrex system.  </section>
<citcontext>
<prevsection>
<prevsent>2.4 factored translation model.
</prevsent>
<prevsent>we also used factored model for the enes translation task.
</prevsent>
</prevsection>
<citsent citstr=" P02-1038 ">
factored models (koehn and hoang, 2007) <papid> D07-1091 </papid>facilitate the translation by breaking it down into several factors which are further combined using log-linear model (och and ney, 2002).<papid> P02-1038 </papid></citsent>
<aftsection>
<nextsent>we used three factors in our factored translation model, which are used in two different decoding paths: surface form (sf) to sf translation factor,a lemma to lemma translation factor, and part-of speech (pos) to pos translation factor.
</nextsent>
<nextsent>finally, we used two decoding paths based on 1http://www.apertium.org the above three translation factors: an sf to sf decoding path and path which maps lemma to lemma, pos to pos, and an sf generated using the tl lemma and pos.
</nextsent>
<nextsent>the lemmas and pos foren andes were obtained using apertium (sec tion 2.3).
</nextsent>
<nextsent>2.5 source-side context-informed pb-smt.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3548">
<title id=" W10-1720.xml">matrex the dcu mt system for wmt 2010 </title>
<section> the matrex system.  </section>
<citcontext>
<prevsection>
<prevsent>for multiple system combination, we used an mbr-cn framework (du et al, 2009, 2010) asshown in figure 1.
</prevsent>
<prevsent>due to the varying word order in the mt hypotheses, it is essential to define the backbone which determines the general word order of the cn.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
instead of using single system output as the skeleton, we employ an mbr decoder to select the best single system output er from the merged -best list by minimizing the bleu (papineni et al, 2002) <papid> P02-1040 </papid>loss, as in (3): = argmin ns?</citsent>
<aftsection>
<nextsent>j=1 (1?
</nextsent>
<nextsent>bleu(ej , ei)) (3) where ns indicates the number of translations inthe merged -best list, and {ei}nsi=1 are the translations themselves.
</nextsent>
<nextsent>in our task, we only merge the 1-best output of each individual system.
</nextsent>
<nextsent>the cn is built by aligning other hypotheses against the backbone, based on the ter metric.null words are allowed in the alignment.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3549">
<title id=" W10-1720.xml">matrex the dcu mt system for wmt 2010 </title>
<section> the matrex system.  </section>
<citcontext>
<prevsection>
<prevsent>either votes or different confidence measures are assigned to each word in the network.
</prevsent>
<prevsent>each arc inthe cn represents an alternative word at that position in the sentence and the number of votes foreach word is counted when constructing the network.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
the features we used are as follows: ? word posterior probability (fiscus, 1997); ? 3, 4-gram target language model; ? word length penalty; ? null word length penalty; we use mert (och, 2003) <papid> P03-1021 </papid>to tune the weights of the cn.</citsent>
<aftsection>
<nextsent>2.8 rescoring.
</nextsent>
<nextsent>rescoring is very important part in postprocessing which can select better hypothesis from the -best list.
</nextsent>
<nextsent>we augmented our previous rescoring model (du et al, 2009) with more large-scale data.
</nextsent>
<nextsent>the features we used include: ? direct and inverse ibm model; ? 3, 4-gram target language model; ? 3, 4, 5-gram pos language model (schmid, 1994; ratnaparkhi, 1996); ? <papid> W96-0213 </papid>sentence length posterior probability (zens and ney, 2006);?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3550">
<title id=" W10-1720.xml">matrex the dcu mt system for wmt 2010 </title>
<section> the matrex system.  </section>
<citcontext>
<prevsection>
<prevsent>rescoring is very important part in postprocessing which can select better hypothesis from the -best list.
</prevsent>
<prevsent>we augmented our previous rescoring model (du et al, 2009) with more large-scale data.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
the features we used include: ? direct and inverse ibm model; ? 3, 4-gram target language model; ? 3, 4, 5-gram pos language model (schmid, 1994; ratnaparkhi, 1996); ? <papid> W96-0213 </papid>sentence length posterior probability (zens and ney, 2006);?</citsent>
<aftsection>
<nextsent>n -gram posterior probabilities within the best list (zens and ney, 2006); ? minimum bayes risk probability;?
</nextsent>
<nextsent>length ratio between source and target sen tence; the weights are optimized via mert.
</nextsent>
<nextsent>this section describes our experimental setup for the encs and enes translation tasks.
</nextsent>
<nextsent>3.1 data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3551">
<title id=" W10-1720.xml">matrex the dcu mt system for wmt 2010 </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>source tokens target tokens europarl enes 1.6m 43m 45m news-comm enes 97k 2.4m 2.7m un enes 5.9m 160m 190m news-comm encs 85k 1.8m 1.6m czeng encs 7.8m 80m 69m table 1: statistics of encs and enes parallel data.monolingual data: for language modeling purposes, in addition to the target parts of the bilingual data, we used the monolingual news corpus for cs; and the gigaword corpus fores.
</prevsent>
<prevsent>for both languages, we used the srilm toolkit (stolcke, 2002) to train 5-gram language model using all monolingual data provided.
</prevsent>
</prevsection>
<citsent citstr=" W07-0712 ">
however, for eneswe used the irstlm toolkit (federico and cettolo, 2007) <papid> W07-0712 </papid>to train 5-gram language model using the es gigaword corpus.</citsent>
<aftsection>
<nextsent>both language models use modified kneser-ney smoothing (chen and goodman, 1996).<papid> P96-1041 </papid></nextsent>
<nextsent>statistics for the monolingual corpora are given in table 2.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3552">
<title id=" W10-1720.xml">matrex the dcu mt system for wmt 2010 </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>for both languages, we used the srilm toolkit (stolcke, 2002) to train 5-gram language model using all monolingual data provided.
</prevsent>
<prevsent>however, for eneswe used the irstlm toolkit (federico and cettolo, 2007) <papid> W07-0712 </papid>to train 5-gram language model using the es gigaword corpus.</prevsent>
</prevsection>
<citsent citstr=" P96-1041 ">
both language models use modified kneser-ney smoothing (chen and goodman, 1996).<papid> P96-1041 </papid></citsent>
<aftsection>
<nextsent>statistics for the monolingual corpora are given in table 2.
</nextsent>
<nextsent>corpus language sentences tokens e/n/nc/un es 9,6m 290m gigaword es 40m 1,2g news cs 13m 210m table 2: statistics of monolingual data.
</nextsent>
<nextsent>e/n/nc/un refers to europarl/news/news commentary/united nations corpora.
</nextsent>
<nextsent>for all the systems except apertium, we first lowercase and tokenize all the monolingual and bilingual data using the tools provided by the wmt10 organizers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3553">
<title id=" W10-1720.xml">matrex the dcu mt system for wmt 2010 </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>we developed amulti-engine framework which combined the outputs of several individual mt systems and generated new -best list after cn decoding.
</prevsent>
<prevsent>then by146 using some global features, the rescoring model generated the final translation output.
</prevsent>
</prevsection>
<citsent citstr=" W04-3250 ">
the experimental results demonstrated that the combination module and rescoring module are effective in our framework for both language pairs, and produce statistically significant improvements as measured by bootstrap re sampling methods (koehn, 2004) <papid> W04-3250 </papid>on bleu over the single best system.</citsent>
<aftsection>
<nextsent>acknowledgements: this work is supported by science foundation ireland (grant no.07/ce/i1142) and by panacea, 7th framework research programme of the european union, contract number 7fp-itc-248064.
</nextsent>
<nextsent>m.l.forcadas sabbatical stay at dublin city university is supported by science foundation ireland through ets walton award 07/w.1/i1802 and by the universitat dalacant (spain).
</nextsent>


</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3554">
<title id=" W10-2604.xml">exploring representation learning approaches to domain adaptation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in experiments, our novel techniques reduce error by as much as 29% relative to the previous state of the art on out-of-domain text.
</prevsent>
<prevsent>supervised natural language processing (nlp)systems exhibit significant drop-off in performance when tested on domains that differ from their training domains.
</prevsent>
</prevsection>
<citsent citstr=" W01-0521 ">
past research in variety of nlp tasks, like parsing (gildea, 2001) <papid> W01-0521 </papid>and chunking (huang and yates, 2009), <papid> P09-1056 </papid>has shown that systems suffer from drop-off in performance on out-of-domain tests.</citsent>
<aftsection>
<nextsent>two separate experiments with part-of-speech (pos) taggers trained on wall street journal (wsj) text show that they can reach accuracies of 97-98% on wsj test sets, but achieve accuracies of at most 90% on biomedical text (r.codena et al , 2005; blitzer et al , 2006).<papid> W06-1615 </papid>the major cause for poor performance on out of-domain texts is the traditional representation used by supervised nlp systems.</nextsent>
<nextsent>most systems depend to varying degrees on lexical features, which tie predictions to the words observed in each example.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3555">
<title id=" W10-2604.xml">exploring representation learning approaches to domain adaptation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in experiments, our novel techniques reduce error by as much as 29% relative to the previous state of the art on out-of-domain text.
</prevsent>
<prevsent>supervised natural language processing (nlp)systems exhibit significant drop-off in performance when tested on domains that differ from their training domains.
</prevsent>
</prevsection>
<citsent citstr=" P09-1056 ">
past research in variety of nlp tasks, like parsing (gildea, 2001) <papid> W01-0521 </papid>and chunking (huang and yates, 2009), <papid> P09-1056 </papid>has shown that systems suffer from drop-off in performance on out-of-domain tests.</citsent>
<aftsection>
<nextsent>two separate experiments with part-of-speech (pos) taggers trained on wall street journal (wsj) text show that they can reach accuracies of 97-98% on wsj test sets, but achieve accuracies of at most 90% on biomedical text (r.codena et al , 2005; blitzer et al , 2006).<papid> W06-1615 </papid>the major cause for poor performance on out of-domain texts is the traditional representation used by supervised nlp systems.</nextsent>
<nextsent>most systems depend to varying degrees on lexical features, which tie predictions to the words observed in each example.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3556">
<title id=" W10-2604.xml">exploring representation learning approaches to domain adaptation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>supervised natural language processing (nlp)systems exhibit significant drop-off in performance when tested on domains that differ from their training domains.
</prevsent>
<prevsent>past research in variety of nlp tasks, like parsing (gildea, 2001) <papid> W01-0521 </papid>and chunking (huang and yates, 2009), <papid> P09-1056 </papid>has shown that systems suffer from drop-off in performance on out-of-domain tests.</prevsent>
</prevsection>
<citsent citstr=" W06-1615 ">
two separate experiments with part-of-speech (pos) taggers trained on wall street journal (wsj) text show that they can reach accuracies of 97-98% on wsj test sets, but achieve accuracies of at most 90% on biomedical text (r.codena et al , 2005; blitzer et al , 2006).<papid> W06-1615 </papid>the major cause for poor performance on out of-domain texts is the traditional representation used by supervised nlp systems.</citsent>
<aftsection>
<nextsent>most systems depend to varying degrees on lexical features, which tie predictions to the words observed in each example.
</nextsent>
<nextsent>while such features have been usedin variety of tasks for better in-domain performance, they are pitfalls for out-of-domain tests for two reasons: first, the vocabulary can differ greatly between domains, so that important words in the test data may never be seen in the training data.
</nextsent>
<nextsent>and second, the connection between words and labels may also change across domains.
</nextsent>
<nextsent>for instance, signaling?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3558">
<title id=" W10-2604.xml">exploring representation learning approaches to domain adaptation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our previous efforts have provided only single new feature in the learned representations.
</prevsent>
<prevsent>we now show how we can perform multi-dimensional clustering of words such that each dimension of the clustering forms new feature in our representation;such multi-dimensional representations dramatically reduce the out-of-domain error rate of our pos tagger from 9.5% to 6.7%.duce representations for domain adaptation?
</prevsent>
</prevsection>
<citsent citstr=" P05-1044 ">
recent work on contrastive estimation (smith and eisner, 2005) <papid> P05-1044 </papid>has shown that maximum-entropybased latent variable models can yield more accurate clusterings for pos tagging than more traditional generative models trained with expectation maximization.</citsent>
<aftsection>
<nextsent>our preliminary results show that such models can be used effectively as representations for domain adaptation as well, matching state-of-the-art results while using far less data.the next section provides background information on learning representations for nlp tasks using latent-variable language models.
</nextsent>
<nextsent>section 3 describes our experimental setup.
</nextsent>
<nextsent>in sections 4 and 5, we empirically investigate our two questions with series of representation-learning methods.
</nextsent>
<nextsent>section 6 analyzes our best learned representation to help explain its effectiveness.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3560">
<title id=" W10-2604.xml">exploring representation learning approaches to domain adaptation </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>in the rest of this paper, we investigate ways to improve the predictive power of the learned representations, without losing the essential property that the features remain stable across domains.
</prevsent>
<prevsent>westay within the framework of using graphical models to learn representations, and demonstrate significant improvements on our original technique.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
we use the same experimental setup as blitzer et al  (2006): <papid> W06-1615 </papid>the penn treebank (marcus et al , 1993) <papid> J93-2004 </papid>wall street journal portion for our labeled training data; 561 medline sentences (9576 words) from the penn bioie project (pennbioie,2005) for our labeled test set; and all of theun labeled text from the penn treebank wsj portion plus blitzer et al medline corpus of 71,306 24 unlabeled sentences to train our latent variablemodels.</citsent>
<aftsection>
<nextsent>the two texts come from two very different domains, making this data tough test for domain adaptation.
</nextsent>
<nextsent>23% of the word types in the test text are out-of-vocabulary (oov), meaning that they are never observed in the training data.we use number of unsupervised representation learning techniques to discover features from our unlabeled data, and supervised classifier totrain on the training set annotated with learned features.
</nextsent>
<nextsent>we use an open source conditional random field (crf) (lafferty et al , 2001) software pack age1 designed by sunita sajarwal and william w. cohen to implement our supervised models.
</nextsent>
<nextsent>werefer to the baseline system with feature set following our previous work (2009) as plain-crf.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3561">
<title id=" W10-2604.xml">exploring representation learning approaches to domain adaptation </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>our learned features will supplement this set.for comparison, we also report on the performance of blitzer et al structural correspondence learning (scl) (2006), our hmm-based model (2009)(hy09), and two other baselines: ? test-crf: our baseline model, trained and tested on the test data.
</prevsent>
<prevsent>this is our upper bound.
</prevsent>
</prevsection>
<citsent citstr=" P06-1043 ">
self-crf: following the self-training paradigm (e.g., (mcclosky et al , 2006<papid> P06-1043 </papid>b; mcclosky et al , 2006<papid> P06-1043 </papid>a)), we train our baseline first on the training set, then apply it to the test set, then retrain it on the training set plus the automatically labeled test set.</citsent>
<aftsection>
<nextsent>we perform only one iteration of retraining, although in general multiple iterations are possible, usually with diminishing marginal returns.
</nextsent>
<nextsent>from linguistic perspective, words are multidimensional objects.
</nextsent>
<nextsent>for instance, the word we?
</nextsent>
<nextsent>in we like doing domain adaptation research?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3570">
<title id=" W10-2604.xml">exploring representation learning approaches to domain adaptation </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>when labeled target-domain datais available, instance weighting and similar techniques can potentially be used in combination with our techniques to improve our results further.
</prevsent>
<prevsent>several researchers have previously studied methods for using unlabeled data for sequence labeling, either alone or as supplement to labeled data.
</prevsent>
</prevsection>
<citsent citstr=" P05-1001 ">
ando and zhang develop semi-supervisedchunker that outperforms purely supervised approaches on the conll 2000 dataset (ando and zhang, 2005).<papid> P05-1001 </papid></citsent>
<aftsection>
<nextsent>recent projects in semi-supervised (toutanova and johnson, 2007) <papid> D07-1031 </papid>and unsupervised (biemann et al , 2007; smith and eisner, 2005) <papid> P05-1044 </papid>tagging also show significant progress.</nextsent>
<nextsent>hmms have been used many times for pos tagging in supervised, semi-supervised, and in unsupervised settings (banko and moore, 2004; <papid> C04-1080 </papid>goldwater and griffiths, 2007; <papid> P07-1094 </papid>johnson, 2007).<papid> D07-1031 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3571">
<title id=" W10-2604.xml">exploring representation learning approaches to domain adaptation </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>several researchers have previously studied methods for using unlabeled data for sequence labeling, either alone or as supplement to labeled data.
</prevsent>
<prevsent>ando and zhang develop semi-supervisedchunker that outperforms purely supervised approaches on the conll 2000 dataset (ando and zhang, 2005).<papid> P05-1001 </papid></prevsent>
</prevsection>
<citsent citstr=" D07-1031 ">
recent projects in semi-supervised (toutanova and johnson, 2007) <papid> D07-1031 </papid>and unsupervised (biemann et al , 2007; smith and eisner, 2005) <papid> P05-1044 </papid>tagging also show significant progress.</citsent>
<aftsection>
<nextsent>hmms have been used many times for pos tagging in supervised, semi-supervised, and in unsupervised settings (banko and moore, 2004; <papid> C04-1080 </papid>goldwater and griffiths, 2007; <papid> P07-1094 </papid>johnson, 2007).<papid> D07-1031 </papid></nextsent>
<nextsent>the realm system for sparse information extraction has also used unsupervised hmms to help determine whether the arguments of candidate relation are of the appropriate type (downey et al , 2007).<papid> P07-1088 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3573">
<title id=" W10-2604.xml">exploring representation learning approaches to domain adaptation </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>ando and zhang develop semi-supervisedchunker that outperforms purely supervised approaches on the conll 2000 dataset (ando and zhang, 2005).<papid> P05-1001 </papid></prevsent>
<prevsent>recent projects in semi-supervised (toutanova and johnson, 2007) <papid> D07-1031 </papid>and unsupervised (biemann et al , 2007; smith and eisner, 2005) <papid> P05-1044 </papid>tagging also show significant progress.</prevsent>
</prevsection>
<citsent citstr=" C04-1080 ">
hmms have been used many times for pos tagging in supervised, semi-supervised, and in unsupervised settings (banko and moore, 2004; <papid> C04-1080 </papid>goldwater and griffiths, 2007; <papid> P07-1094 </papid>johnson, 2007).<papid> D07-1031 </papid></citsent>
<aftsection>
<nextsent>the realm system for sparse information extraction has also used unsupervised hmms to help determine whether the arguments of candidate relation are of the appropriate type (downey et al , 2007).<papid> P07-1088 </papid></nextsent>
<nextsent>schutze (1994) has presented an algorithm that categorizes word tokens in context instead of word types for tagging words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3574">
<title id=" W10-2604.xml">exploring representation learning approaches to domain adaptation </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>ando and zhang develop semi-supervisedchunker that outperforms purely supervised approaches on the conll 2000 dataset (ando and zhang, 2005).<papid> P05-1001 </papid></prevsent>
<prevsent>recent projects in semi-supervised (toutanova and johnson, 2007) <papid> D07-1031 </papid>and unsupervised (biemann et al , 2007; smith and eisner, 2005) <papid> P05-1044 </papid>tagging also show significant progress.</prevsent>
</prevsection>
<citsent citstr=" P07-1094 ">
hmms have been used many times for pos tagging in supervised, semi-supervised, and in unsupervised settings (banko and moore, 2004; <papid> C04-1080 </papid>goldwater and griffiths, 2007; <papid> P07-1094 </papid>johnson, 2007).<papid> D07-1031 </papid></citsent>
<aftsection>
<nextsent>the realm system for sparse information extraction has also used unsupervised hmms to help determine whether the arguments of candidate relation are of the appropriate type (downey et al , 2007).<papid> P07-1088 </papid></nextsent>
<nextsent>schutze (1994) has presented an algorithm that categorizes word tokens in context instead of word types for tagging words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3576">
<title id=" W10-2604.xml">exploring representation learning approaches to domain adaptation </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>recent projects in semi-supervised (toutanova and johnson, 2007) <papid> D07-1031 </papid>and unsupervised (biemann et al , 2007; smith and eisner, 2005) <papid> P05-1044 </papid>tagging also show significant progress.</prevsent>
<prevsent>hmms have been used many times for pos tagging in supervised, semi-supervised, and in unsupervised settings (banko and moore, 2004; <papid> C04-1080 </papid>goldwater and griffiths, 2007; <papid> P07-1094 </papid>johnson, 2007).<papid> D07-1031 </papid></prevsent>
</prevsection>
<citsent citstr=" P07-1088 ">
the realm system for sparse information extraction has also used unsupervised hmms to help determine whether the arguments of candidate relation are of the appropriate type (downey et al , 2007).<papid> P07-1088 </papid></citsent>
<aftsection>
<nextsent>schutze (1994) has presented an algorithm that categorizes word tokens in context instead of word types for tagging words.
</nextsent>
<nextsent>we take novel perspective on theuse of unsupervised latent-variable models by using them to compute features of each token that represent the distribution over that tokens contexts.
</nextsent>
<nextsent>these features prove to be highly useful for supervised sequence label ers in out-of-domain tests.
</nextsent>
<nextsent>in the deep learning (bengio, 2009) paradigm,researchers have investigated multi-layer latent variable models for language modeling, among other tasks.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3577">
<title id=" W10-3104.xml">does negation really matter </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, few reports describe how much assertion classification contributes to the final system performance.
</prevsent>
<prevsent>two exceptions are goldstein et al  (2007) and ambert and cohen (2009).
</prevsent>
</prevsection>
<citsent citstr=" W07-1013 ">
goldstein et al  develop hand-crafted rule based system to classify radiological reports from the 2007 computational medicine center (cmc) challenge (pestian et al  2007).<papid> W07-1013 </papid></citsent>
<aftsection>
<nextsent>they show that negation and speculation play key roles in classifying their reports.
</nextsent>
<nextsent>ambert and cohen apply machine learning (ml) approach to classifying discharge summaries from the 2008 i2b2 obesity challenge (uzuner 2008).
</nextsent>
<nextsent>they report that due to false negations,?
</nextsent>
<nextsent>simply adding negation detection to their base system does not consistently improve performance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3579">
<title id=" W10-2925.xml">distributed asynchronous online learning for natural language processing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we generalize existing asynchronous algorithms and experiment extensively with structured prediction problems from nlp, including discriminative, unsupervised, and non-convex learning scenarios.
</prevsent>
<prevsent>our results show asynchronous learning can provide substantial speed ups compared to distributed and single processor mini-batch algorithms with no signs of error arising from the approximate nature of the technique.
</prevsent>
</prevsection>
<citsent citstr=" N09-1069 ">
modern statistical nlp models are notoriously expensive to train, requiring the use of general purpose or specialized numerical optimization algorithms (e.g., gradient and coordinate ascent algorithms and variations on them like l-bfgs and em) that iterate over training data many times.two developments have led to major improvements in training time for nlp models: ? online learning algorithms (lecun et al, 1998; crammer and singer, 2003; liang and klein, 2009), <papid> N09-1069 </papid>which update the parameters of model more frequently, processing only one or small number of training examples, called mini batch,?</citsent>
<aftsection>
<nextsent>between updates; and ? distributed computing, which divides training data among multiple cpus for faster processing between updates (e.g., clark and curran, 2004).
</nextsent>
<nextsent>online algorithms offer fast convergence rates and scala bility to large datasets, but distributed computing is more natural fit for algorithms that require lot of computatione.g., processing alarge batch of training example sto be done between updates.
</nextsent>
<nextsent>typically, distributed online learning has been done in synchronous setting, meaning that mini-batch of data is divided among multiple cpus, and the model is updated when they have all completed processing (finkel et al, 2008).<papid> P08-1109 </papid></nextsent>
<nextsent>each mini-batch is processed only after the previous one has completed.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3581">
<title id=" W10-2925.xml">distributed asynchronous online learning for natural language processing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>between updates; and ? distributed computing, which divides training data among multiple cpus for faster processing between updates (e.g., clark and curran, 2004).
</prevsent>
<prevsent>online algorithms offer fast convergence rates and scala bility to large datasets, but distributed computing is more natural fit for algorithms that require lot of computatione.g., processing alarge batch of training example sto be done between updates.
</prevsent>
</prevsection>
<citsent citstr=" P08-1109 ">
typically, distributed online learning has been done in synchronous setting, meaning that mini-batch of data is divided among multiple cpus, and the model is updated when they have all completed processing (finkel et al, 2008).<papid> P08-1109 </papid></citsent>
<aftsection>
<nextsent>each mini-batch is processed only after the previous one has completed.
</nextsent>
<nextsent>synchronous frameworks are appealing in that they simulate the same algorithms that work on single processor, but they have the drawback that the benefits of parallelism are only obtainable within one mini-batch iteration.
</nextsent>
<nextsent>moreover, empirical evaluations suggest that online methods only converge faster than batch algorithms when using very small mini-batches (liang and klein, 2009).<papid> N09-1069 </papid></nextsent>
<nextsent>in this case, synchronous parallel ization will not offer much benefit.in this paper, we focus our attention on asynchronous algorithms that generalize those presented by nedic et al (2001) and langford et al (2009).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3585">
<title id=" W10-2925.xml">distributed asynchronous online learning for natural language processing </title>
<section> distributed batch optimization.  </section>
<citcontext>
<prevsection>
<prevsent>each iteration of calculating will take as long as the longest-running among the processors, whatever the cause of that processors slowness.
</prevsent>
<prevsent>in computing environments where the load on processors is beyond the control of the nlp researcher, this can be major bottleneck.
</prevsent>
</prevsection>
<citsent citstr=" W08-0333 ">
nonetheless, this simple approach is widely used in practice; approaches in which the gradient computation is distributed via map reduce have recently been described in machine learning and nlp (chu et al, 2006; dyer et al, 2008; <papid> W08-0333 </papid>wolfe etal., 2008).</citsent>
<aftsection>
<nextsent>mann et al (2009) compare this framework to one in which each processor maintains aseparate parameter vector which is updated independently of the others.
</nextsent>
<nextsent>at the end of learning, the parameter vectors are averaged or vote is taken during prediction.
</nextsent>
<nextsent>a similar parameter-averaging approach was taken by chiang et al (2008) <papid> D08-1024 </papid>when parallelizing mira (crammer et al, 2006).</nextsent>
<nextsent>in this paper, we restrict our attention to distributed frameworks which maintain and update single copy of the parameters ?.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3586">
<title id=" W10-2925.xml">distributed asynchronous online learning for natural language processing </title>
<section> distributed batch optimization.  </section>
<citcontext>
<prevsection>
<prevsent>mann et al (2009) compare this framework to one in which each processor maintains aseparate parameter vector which is updated independently of the others.
</prevsent>
<prevsent>at the end of learning, the parameter vectors are averaged or vote is taken during prediction.
</prevsent>
</prevsection>
<citsent citstr=" D08-1024 ">
a similar parameter-averaging approach was taken by chiang et al (2008) <papid> D08-1024 </papid>when parallelizing mira (crammer et al, 2006).</citsent>
<aftsection>
<nextsent>in this paper, we restrict our attention to distributed frameworks which maintain and update single copy of the parameters ?.
</nextsent>
<nextsent>the use of multiple parameter vectors is essentially orthogonal to the framework we discuss here and we leave the integration of the two ideas for future exploration.
</nextsent>
<nextsent>optimization distributed computing can speed up batch algorithms, but we would like to transfer the well known speed-ups offered by online and mini-batch algorithms to the distributed setting as well.
</nextsent>
<nextsent>the simplest way to implement mini-batch stochastic gradient descent (sgd) in distributed computing environment is to divide each mini-batch (rather than the entire batch) among the processors that are available and to update the parameters once the gradient from the mini-batch has been computed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3588">
<title id=" W10-2925.xml">distributed asynchronous online learning for natural language processing </title>
<section> distributed asynchronous mini-batch.  </section>
<citcontext>
<prevsection>
<prevsent>the convergence criterion is left unspecified here.
</prevsent>
<prevsent>of training examples.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
for example, for simple word alignment models like ibm model 1 (brown et al, 1993), <papid> J93-2003 </papid>only parameters corresponding to words appearing in the particular sub sample of sentence pairs are needed.</citsent>
<aftsection>
<nextsent>the error introduced when making asynchronous updates should intuitively be less severe in these cases, where different mini-batches use small and mostly nonoverlapping subsets of ?.
</nextsent>
<nextsent>5.1 implementation.
</nextsent>
<nextsent>the algorithm sketched above is general enough to be suitable for any distributed system, but when using system with shared memory (e.g., single multiprocessor machine) more efficient implementation is possible.
</nextsent>
<nextsent>in particular, we can avoid the master/slave architecture and simply start pthreads that each compute and execute updates independently, with synchronization lock on ?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3591">
<title id=" W10-2925.xml">distributed asynchronous online learning for natural language processing </title>
<section> distributed asynchronous mini-batch.  </section>
<citcontext>
<prevsection>
<prevsent>method convex?
</prevsent>
<prevsent>6.1 named entity recognition (crf; lafferty et al, 2001) conll 2003 english (tjong kim sang and de meulder, 2003) 14,987 sents.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
1.3m f1 sgd yes 6.2 word alignment (model 1, both directions; brown et al, 1993) <papid> J93-2003 </papid>naacl 2003 parallel text workshop (mihalcea and pedersen, 2003) 300k pairs 14.2m 2 (ef + fe) aer em yes s6.3 unsupervised pos (bigram hmm) penn treebank 121 (marcus et al, 1993) <papid> J93-2004 </papid>41,825 sents.</citsent>
<aftsection>
<nextsent>2,043,226 (johnson, 2007) <papid> D07-1031 </papid>em no table 1: our experiments consider three tasks.</nextsent>
<nextsent>0 2 4 6 8 10 12 84 86 88 90 wall clock time (hours) f1 asynchronous (4 processors)synchronous (4 processors)singleprocessor figure 1: ner: synchronous mini-batch sgd converges faster in f1 than the single-processor version, and the asynchronous version converges faster still.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3592">
<title id=" W10-2925.xml">distributed asynchronous online learning for natural language processing </title>
<section> distributed asynchronous mini-batch.  </section>
<citcontext>
<prevsection>
<prevsent>6.1 named entity recognition (crf; lafferty et al, 2001) conll 2003 english (tjong kim sang and de meulder, 2003) 14,987 sents.
</prevsent>
<prevsent>1.3m f1 sgd yes 6.2 word alignment (model 1, both directions; brown et al, 1993) <papid> J93-2003 </papid>naacl 2003 parallel text workshop (mihalcea and pedersen, 2003) 300k pairs 14.2m 2 (ef + fe) aer em yes s6.3 unsupervised pos (bigram hmm) penn treebank 121 (marcus et al, 1993) <papid> J93-2004 </papid>41,825 sents.</prevsent>
</prevsection>
<citsent citstr=" D07-1031 ">
2,043,226 (johnson, 2007) <papid> D07-1031 </papid>em no table 1: our experiments consider three tasks.</citsent>
<aftsection>
<nextsent>0 2 4 6 8 10 12 84 86 88 90 wall clock time (hours) f1 asynchronous (4 processors)synchronous (4 processors)singleprocessor figure 1: ner: synchronous mini-batch sgd converges faster in f1 than the single-processor version, and the asynchronous version converges faster still.
</nextsent>
<nextsent>all curves use mini-batch size of 4.
</nextsent>
<nextsent>we performed experiments to measure speed-upsobtainable through distributed online optimization.
</nextsent>
<nextsent>since we will be considering different optimization algorithms and computing environments, we will primarily be interested in the wall-clocktime required to obtain particular levels of performance on metrics appropriate to each task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3593">
<title id=" W10-2925.xml">distributed asynchronous online learning for natural language processing </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we also conducted experiments using cluster architecture running hadoop 0.20 (an implementation of mapreduce),consisting of 400 machines, each having 2 quad core 1.86ghz cpus with total of 6gb of ram.
</prevsent>
<prevsent>6.1 named entity recognition.
</prevsent>
</prevsection>
<citsent citstr=" D07-1033 ">
our ner crf used standard set of features, following kazama and torisawa (2007), <papid> D07-1033 </papid>along with token shape features like those in collins (2002)and simple gazetteer features; feature was included if and only it occurred at least once in training data (total 1.3m).we used diagonal gaussian prior with variance of 1.0 for each weight.we compared sgd on single processor to distributed synchronous sgd and distributed asynchronous sgd.</citsent>
<aftsection>
<nextsent>for all experiments, we used afixed step size of 0.01 and chose each training example for each mini-batch uniformly at random from the full data set.3 we report performance by3in preliminary experiments, we experimented with vari 0 2 4 6 8 10 86 88 90 f1 synchronous (4 processors)synchronous (2 processors)singleprocessor 0 2 4 6 8 10 86 88 90 wall clock time (hours) f1 asynchronous (4 processors) asynchronous (2 processors)singleprocessor figure 2: ner: (top) synchronous optimization improves very little when moving from 2 to 4 processors due to the need for load-balancing, leaving some processors idle for stretches of time.
</nextsent>
<nextsent>(bottom) asynchronous optimization doesnot require load balancing and therefore improves when moving from 2 to 4 processors because each processor is in near constant use.
</nextsent>
<nextsent>all curves use mini-batch size of 4 and the single-processor?
</nextsent>
<nextsent>curve is identical in the two plots.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3594">
<title id=" W10-2925.xml">distributed asynchronous online learning for natural language processing </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we trained ibm model 1 in both directions.
</prevsent>
<prevsent>to align test data, we symmetrized both directional viterbi alignments using the grow-diag-final?
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
heuristic (koehn et al, 2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>we evaluated our models using alignment error rate (aer).experiments on single machine we followed liang and klein (2009) <papid> N09-1069 </papid>in using synchronous (mini-batch) stepwise em on single processor for this task.</nextsent>
<nextsent>we used the same learning rate formula (?(t) = (t+2)q, with 0.5   ? 1).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3603">
<title id=" W10-2925.xml">distributed asynchronous online learning for natural language processing </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the accuracy curves for batch em do not appear because the highest accuracy reached is only 40.7% after six hours.
</prevsent>
<prevsent>over the 1-processor baseline.the accuracy of the asynchronous curves often decreases slightly after peaking.
</prevsent>
</prevsection>
<citsent citstr=" J94-2001 ">
we can surmise from the log-likelihood plot that the dropin accuracy is not due to the optimization being led astray, but probably rather due to the complex relationship between likelihood and task specific evaluation metrics in unsupervised learning (merialdo, 1994).<papid> J94-2001 </papid></citsent>
<aftsection>
<nextsent>in fact, when we examined the results of synchronous stepwise em between 6 and 12 hours of execution, we found similar drops inaccuracy as likelihood continued to improve.
</nextsent>
<nextsent>from figure 6, we conclude that the asynchronous algorithm has no harmful effect on learned models accuracy beyond the choice to optimize log-likelihood.while there are currently no theoretical convergence results for asynchronous optimization algorithms for non-convex functions, our results are encouraging for the prospects of establishing convergence results for this setting.
</nextsent>
<nextsent>our best results were obtained by exploiting multiple processors on single machine, while experiments using map reduce cluster were plagued by communication and framework overhead.since moores law predicts continual increase in the number of cores available on single machine but not necessarily an increase in the speed of those cores, we believe that algorithms that can effectively exploit multiple processors on single machine will be increasingly useful.
</nextsent>
<nextsent>even today, applications in nlp involving rich-featurestructured prediction, such as parsing and translation, typically use large portion of memory for storing pre-computed data structures, such as lexicons, feature name mappings, and feature caches.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3604">
<title id=" W10-2504.xml">mill stream systems x2013 a formal model for linking language modules by interfaces </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>since the mentioned types of tree transductions are well studied, and much is known about theiralgorithmic properties, future research on mill stream systems should investigate the relationship between different types of tree transductions and mill stream systems in detail.
</prevsent>
<prevsent>in particular, it should be tried to formulate requirements onthe interface conditions that can be used to obtain characterisations of various classes of tree transductions.
</prevsent>
</prevsection>
<citsent citstr=" J08-3004 ">
we note here that results of this type would not only be interesting from purely mathematical point of view, since tree transducers have turned out to be valuable tool in, for example, machine translation (knight and graehl, 2005; may and knight, 2006; graehl et al, 2008).<papid> J08-3004 </papid></citsent>
<aftsection>
<nextsent>7 preliminary results and future work.
</nextsent>
<nextsent>mill stream systems, as introduced in this article, are formal devices that allow to model situation sin which several tree-generating modules are interconnected by logical interfaces.
</nextsent>
<nextsent>in forthcoming paper (bensch et al, 2010), we investigate the theoretical properties of regular mso mill stream systems, i.e., mill stream systems in which the modules are regular tree grammars and the logic used is monadic second-order logic.
</nextsent>
<nextsent>in particular, we study the so-called completion problem.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3605">
<title id=" W10-3504.xml">expanding textual entailment corpora from wikipedia using co training </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the key idea is the combination of two intuitions: (1) the use of wikipedia to extract large set of textual entailment pairs; (2) the application of semi supervised machine learning methods to make the extracted dataset homogeneous to the existing ones.
</prevsent>
<prevsent>we report empirical evidence that our method successfully expands existing textual entailment corpora.
</prevsent>
</prevsection>
<citsent citstr=" W07-1401 ">
despite the growing success of the recognizing textual entailment (rte) challenges (dagan et al ., 2006; bar-haim et al , 2006; giampiccolo et al ., 2007), <papid> W07-1401 </papid>the accuracy of most textual entailment recognition systems are still below 60%.</citsent>
<aftsection>
<nextsent>an intuitive way to improve performance is to provide systems with larger annotated datasets.
</nextsent>
<nextsent>this is especially true for machine learning systems, where the size of the training corpus is an important factor.
</nextsent>
<nextsent>as consequence, several attempts have been made to train systems using larger datasets obtained by merging rte corpora of different challenges.
</nextsent>
<nextsent>unfortunately, experimental results show significant decrease inaccuracy (de marneffe et al ., 2006).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3606">
<title id=" W10-3504.xml">expanding textual entailment corpora from wikipedia using co training </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>existing rte corpora.
</prevsent>
<prevsent>the task of creating large datasets is unfeasible for human annotators.
</prevsent>
</prevsection>
<citsent citstr=" D08-1027 ">
collaborative annotation environments such as the amazon mechanical turk1 can help to annotate pairs of sentences in positive or negative entailment (zaenen, submitted; snow et al , 2008).<papid> D08-1027 </papid></citsent>
<aftsection>
<nextsent>yet, these environments can hardly solve the problem of finding relevant pairs of sentences.
</nextsent>
<nextsent>completely automatic processes of dataset creation have been proposed (burger and ferro, 2005; <papid> W05-1209 </papid>hickl et al ,2006).</nextsent>
<nextsent>unfortunately, these datasets are not homogeneous wrt.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3607">
<title id=" W10-3504.xml">expanding textual entailment corpora from wikipedia using co training </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>collaborative annotation environments such as the amazon mechanical turk1 can help to annotate pairs of sentences in positive or negative entailment (zaenen, submitted; snow et al , 2008).<papid> D08-1027 </papid></prevsent>
<prevsent>yet, these environments can hardly solve the problem of finding relevant pairs of sentences.</prevsent>
</prevsection>
<citsent citstr=" W05-1209 ">
completely automatic processes of dataset creation have been proposed (burger and ferro, 2005; <papid> W05-1209 </papid>hickl et al ,2006).</citsent>
<aftsection>
<nextsent>unfortunately, these datasets are not homogeneous wrt.
</nextsent>
<nextsent>to the rte datasets, as they are 1http://mturk.com 28created using different methodologies.
</nextsent>
<nextsent>in this paper we propose novel method to automatically extract entailment datasets which are guaranteed to be large and homogeneous torte ones.
</nextsent>
<nextsent>the key idea is the combination of two factors: (1) theuse of wikipedia as source of large set of textual entailment pairs; (2) the application of semi supervised machine learning methods, namely co training, to make corpora homogeneous torte.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3611">
<title id=" W10-3504.xml">expanding textual entailment corpora from wikipedia using co training </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>hickl and colleagues show that expanding therte-2 training set with the lcc corpus (the expansion factor is 125), their rte system improves 10% accuracy.
</prevsent>
<prevsent>this suggests that by expanding with large and balanced corpus, entailment recognition performance drastically improves.
</prevsent>
</prevsection>
<citsent citstr=" W07-1428 ">
this intuition is later contradicted in second experiment by hickl and bensley (2007).<papid> W07-1428 </papid>authors use the lcc corpus with the rte-3 training set to train new rte system, showing an improvement inaccuracy of less than 1% wrt.</citsent>
<aftsection>
<nextsent>the rte-3 training alone.overall, evidence suggests that automatic expansion of the rte corpora do not always lead to performance improvement.
</nextsent>
<nextsent>this highly depends on how balanced the corpus is, on the rte system adopted, and on the specific rte dataset that is expanded.
</nextsent>
<nextsent>in this section we outline some of the properties that reliable corpus for rte should have (sec tion 3.1), and show that corpus extracted from wikipedia conforms to these properties (sec tion 3.2).
</nextsent>
<nextsent>3.1 good practices in building rte corpora.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3612">
<title id=" W10-3504.xml">expanding textual entailment corpora from wikipedia using co training </title>
<section> expanding the rte corpus with wiki.  </section>
<citcontext>
<prevsection>
<prevsent>even if very small, the comment can be used to determine if s1 and s2 are in entailment or not.in the following section we show how we leverage comments to make the wiki corpus homogeneous to those of the rte challenges.
</prevsent>
<prevsent>using co-trainingunlike the lcc corpus where negative and positive examples are clearly separated, the wiki corpus mixes the two sets ? i.e. it is unlabelled.
</prevsent>
</prevsection>
<citsent citstr=" J03-3005 ">
in order to exploit the wiki corpus in the rte task, one should either manually annotate the corpus, 2it has been shown that web documents (as wikipedia) are reliable samples of language (keller and lapata, 2003).<papid> J03-3005 </papid></citsent>
<aftsection>
<nextsent>co-training algorithm(l,u ,k) returns h1,h2,l1,l2 set l1 = l2 = while stopping condition is not met ? learn h1 on f1 from l1, and learn h2 on f1 from l2, ? classify with h1 obtaining u1, and classify with h2 obtaining u2 ? select and remove k-best classified examples u1 and u2 from respectively u1 and u2 ? add u1 to l2 and u2 to l1 figure 2: general co-training algorithm or find an alternative strategy to leverage the corpus even if unlabelled.
</nextsent>
<nextsent>as manual annotation is unfeasible, we choose the second solution.
</nextsent>
<nextsent>the goal is then to expand labelled rte challenge training set with the un labelled wiki, so that the performance of an rte system can increase over an rte test set.
</nextsent>
<nextsent>in the literature, several techniques have been proposed to use un labelled data to expand at raining labelled corpus, e.g. expectation maximization (dempster et al , 1977).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3613">
<title id=" W10-3504.xml">expanding textual entailment corpora from wikipedia using co training </title>
<section> expanding the rte corpus with wiki.  </section>
<citcontext>
<prevsection>
<prevsent>the goal is then to expand labelled rte challenge training set with the un labelled wiki, so that the performance of an rte system can increase over an rte test set.
</prevsent>
<prevsent>in the literature, several techniques have been proposed to use un labelled data to expand at raining labelled corpus, e.g. expectation maximization (dempster et al , 1977).
</prevsent>
</prevsection>
<citsent citstr=" P02-1046 ">
we here apply the co-training technique, first proposed by (blum and mitchell, 1998) and then successfully leveraged and analyzed in different settings (ab ney, 2002).<papid> P02-1046 </papid></citsent>
<aftsection>
<nextsent>co-training can be applied when the un labelled dataset al ows two independent views on its instances (applicability condition).in this section, we first provide short description of the co-training algorithm (section 4.1).
</nextsent>
<nextsent>we then investigate if different rte corpora conform to the applicability condition (section 4.2).
</nextsent>
<nextsent>finally, we show that our wiki corpus conforms tothe condition, and then apply co-training by creating two independent views (section 4.3).
</nextsent>
<nextsent>4.1 co-training.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3614">
<title id=" W10-3504.xml">expanding textual entailment corpora from wikipedia using co training </title>
<section> expanding the rte corpus with wiki.  </section>
<citcontext>
<prevsection>
<prevsent>then comes the co training step: the k-best classified instances in u1 are added to l2 and feed the learning of new classifier h2 on the feature space f2.
</prevsent>
<prevsent>similarly, the k-best instances in u2 are added to l1 and train new classifier h1 on f1.the procedure repeats until stopping condition is met.
</prevsent>
</prevsection>
<citsent citstr=" W99-0613 ">
this can be either fixed number of added un labelled examples (blum and mitchell, 1998), the performance drop on control set of labelled instances, or filter on the disagreement of h1 and h2 in classifying (collins and singer, 1999).<papid> W99-0613 </papid></citsent>
<aftsection>
<nextsent>the final outcome of co-training is the newset of labelled examples l1l2 and the two classifier h1 and h2, obtained from the last iteration.
</nextsent>
<nextsent>4.2 applicability condition on rte corpora.
</nextsent>
<nextsent>in order to leverage co-training for homogeneously expanding an rte corpus, it is necessary to have large un labelled corpus which satisfies the applicability condition.
</nextsent>
<nextsent>unfortunately,existing methodologies cannot guarantee the condition.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3615">
<title id=" W10-3504.xml">expanding textual entailment corpora from wikipedia using co training </title>
<section> expanding the rte corpus with wiki.  </section>
<citcontext>
<prevsection>
<prevsent>4.3.1 content-pair view the content-pair view is the classical view used in rte.
</prevsent>
<prevsent>the original entry s1 represents the text , while the revision s2 is the hypothesis . any feature space of those reported in the textual entailment literature could be applied.
</prevsent>
</prevsection>
<citsent citstr=" P06-1051 ">
we here adopt the space that represents first-order syntactic rewrite rules (fosr), as described in (zan zotto and moschitti, 2006).<papid> P06-1051 </papid></citsent>
<aftsection>
<nextsent>in this feature space, each feature represents syntactic first-order or 32 grounded rewrite rule.
</nextsent>
<nextsent>for example, the rule: ? = ? r= np vp vbp bought np ? np vp vbp owns np is represented by the feature   l,  .
</nextsent>
<nextsent>a (t,h) pair activates feature if it unifies with the related rule.
</nextsent>
<nextsent>a detailed discussion of the fosr feature space is given in (zanzotto et al , 2009) and efficient algorithms for the computation of there lated kernel functions can be found in (moschitti and zanzotto, 2007; zanzotto and dellarciprete, 2009).<papid> D09-1010 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3616">
<title id=" W10-3504.xml">expanding textual entailment corpora from wikipedia using co training </title>
<section> expanding the rte corpus with wiki.  </section>
<citcontext>
<prevsection>
<prevsent>for example, the rule: ? = ? r= np vp vbp bought np ? np vp vbp owns np is represented by the feature   l,  .
</prevsent>
<prevsent>a (t,h) pair activates feature if it unifies with the related rule.
</prevsent>
</prevsection>
<citsent citstr=" D09-1010 ">
a detailed discussion of the fosr feature space is given in (zanzotto et al , 2009) and efficient algorithms for the computation of there lated kernel functions can be found in (moschitti and zanzotto, 2007; zanzotto and dellarciprete, 2009).<papid> D09-1010 </papid></citsent>
<aftsection>
<nextsent>4.4 comment view.
</nextsent>
<nextsent>a review comment is typically textual fragment describing the reason why an author has decided to make revision.
</nextsent>
<nextsent>in most cases the comment is not well-formed sentence, as authors tend to use informal slang expressions and abbreviations (e.g.details: trelew massacre; cat: dirty war, copy edit?, removed pov vandalism by spylab?, dab ba:clean up using project:awb?).
</nextsent>
<nextsent>in these cases, where syntactic analysis would mostly fail, it is advisable to use simpler surface approaches to build the feature space.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3618">
<title id=" W10-3504.xml">expanding textual entailment corpora from wikipedia using co training </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the inter-annotator agreement on thisset, computed using the kappa-statistics (siegel and castel lan, 1988), was 0.60 corresponding to substantial agreement, 33 the corpus has been randomly split in three equally numerous parts: development, training, and testing.
</prevsent>
<prevsent>we kept aside the development to design the features, while we used training and testing for the experiments.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
we use the charniak parser (charniak, 2000) <papid> A00-2018 </papid>for parsing sentences, and svm-light (joachims, 1999) extended with the syntactic first-order rule kernels described in (zanzotto and moschitti, 2006; <papid> P06-1051 </papid>moschitti and zanzotto, 2007) for creating the fosr feature space.</citsent>
<aftsection>
<nextsent>5.2 experimental results.
</nextsent>
<nextsent>the first experiment aims at checking the quality of the wiki corpus, by comparing the performance obtained by standard rte system over the corpus in exam with those obtained over any rte challenge corpus.
</nextsent>
<nextsent>the hypothesis is that if performance is comparable, then the corpus in exam has the same complexity (and quality) asthe rte challenge corpora.
</nextsent>
<nextsent>we then independently experiment with the wiki and the news corpora with the training-test splits reported in section 5.1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3620">
<title id=" W10-2101.xml">modeling and encoding traditional word lists for machine applications </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>such comparison is undoubtedly important insofar as it helps us understand how computational methods that are derived from these two lines of research can complement each other.
</prevsent>
<prevsent>however, one thing that the two areas of work have in common is that they tend to focus on majority languages and majority language resources.
</prevsent>
</prevsection>
<citsent citstr=" W02-1502 ">
even where this is not the case (bender et al , 2002; <papid> W02-1502 </papid>alvarez et al , 2006; <papid> N06-2002 </papid>palmer et al , 2009), <papid> W09-1905 </papid>the resulting products still cover relatively few languages from world wide perspective.</citsent>
<aftsection>
<nextsent>this is in part because such work cannot easily make use of the extensive language resources produced by descriptive linguists,the group of researchers that are most actively involved in documenting the worlds entire linguistic diversity.
</nextsent>
<nextsent>in fact, one particular descriptive linguistic product, the wordlistwhich is the focus of this pap ercan be found for at least quarter of the worlds languages.
</nextsent>
<nextsent>clearly, descriptive linguistic resources can beof potential value not just to traditional linguistics, but also to computational linguistics.
</nextsent>
<nextsent>the difficulty, however, is that the kinds of resources produced in the course of linguistic description are typically not easily exploitable in nlp applications.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3621">
<title id=" W10-2101.xml">modeling and encoding traditional word lists for machine applications </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>such comparison is undoubtedly important insofar as it helps us understand how computational methods that are derived from these two lines of research can complement each other.
</prevsent>
<prevsent>however, one thing that the two areas of work have in common is that they tend to focus on majority languages and majority language resources.
</prevsent>
</prevsection>
<citsent citstr=" N06-2002 ">
even where this is not the case (bender et al , 2002; <papid> W02-1502 </papid>alvarez et al , 2006; <papid> N06-2002 </papid>palmer et al , 2009), <papid> W09-1905 </papid>the resulting products still cover relatively few languages from world wide perspective.</citsent>
<aftsection>
<nextsent>this is in part because such work cannot easily make use of the extensive language resources produced by descriptive linguists,the group of researchers that are most actively involved in documenting the worlds entire linguistic diversity.
</nextsent>
<nextsent>in fact, one particular descriptive linguistic product, the wordlistwhich is the focus of this pap ercan be found for at least quarter of the worlds languages.
</nextsent>
<nextsent>clearly, descriptive linguistic resources can beof potential value not just to traditional linguistics, but also to computational linguistics.
</nextsent>
<nextsent>the difficulty, however, is that the kinds of resources produced in the course of linguistic description are typically not easily exploitable in nlp applications.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3622">
<title id=" W10-2101.xml">modeling and encoding traditional word lists for machine applications </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>such comparison is undoubtedly important insofar as it helps us understand how computational methods that are derived from these two lines of research can complement each other.
</prevsent>
<prevsent>however, one thing that the two areas of work have in common is that they tend to focus on majority languages and majority language resources.
</prevsent>
</prevsection>
<citsent citstr=" W09-1905 ">
even where this is not the case (bender et al , 2002; <papid> W02-1502 </papid>alvarez et al , 2006; <papid> N06-2002 </papid>palmer et al , 2009), <papid> W09-1905 </papid>the resulting products still cover relatively few languages from world wide perspective.</citsent>
<aftsection>
<nextsent>this is in part because such work cannot easily make use of the extensive language resources produced by descriptive linguists,the group of researchers that are most actively involved in documenting the worlds entire linguistic diversity.
</nextsent>
<nextsent>in fact, one particular descriptive linguistic product, the wordlistwhich is the focus of this pap ercan be found for at least quarter of the worlds languages.
</nextsent>
<nextsent>clearly, descriptive linguistic resources can beof potential value not just to traditional linguistics, but also to computational linguistics.
</nextsent>
<nextsent>the difficulty, however, is that the kinds of resources produced in the course of linguistic description are typically not easily exploitable in nlp applications.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3624">
<title id=" W10-2101.xml">modeling and encoding traditional word lists for machine applications </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>nevertheless, in the last decade or so,it has become widely recognized that the development of new digital methods for encoding language data can, in principle, not only help descriptive linguists to work more effectively but also allow them, with relatively little extra effort, to produce resources which can be straightforwardly re purposed for, among other things, nlp (simons et al ., 2004; farrar and lewis, 2007).
</prevsent>
<prevsent>despite this, it has proven difficult to create significant electronic descriptive resources due tothe complex and specific problems inevitably associated with the conversion of legacy data.
</prevsent>
</prevsection>
<citsent citstr=" W09-0307 ">
one exception to this is found in the work done in the context of the odin project (xia and lewis, 2009), <papid> W09-0307 </papid>significant database of inter linear glossed text (igt), standard descriptive linguistic data format (palmer et al , 2009), <papid> W09-1905 </papid>compiled by searching the web for legacy instances of igt.this paper describes another attempt to transform an existing legacy dataset into more readily repurposable format.</citsent>
<aftsection>
<nextsent>our data consists of traditional descriptive word lists originally collected for comparative and historical linguistic research.1 word lists have been widely employed as first step towards the creation of dictionary or as ameans to quickly gather information about language for the purposes of language comparison (especially in parts of the world where languages 1these word lists were collected by timothy usher and paul whitehouse and represent an enormous effort without which the work described here would not have been possible.
</nextsent>
<nextsent>the rdf/xml implementations discussed in this paper will be made available at http://lego.linguistlist.org within the context of the lexicon enhancement via the gold ontology project.
</nextsent>
<nextsent>1 are poorly documented).
</nextsent>
<nextsent>because of this, they exist for many more languages than do full lexicons.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3627">
<title id=" W10-2101.xml">modeling and encoding traditional word lists for machine applications </title>
<section> related work in descriptive.  </section>
<citcontext>
<prevsection>
<prevsent>(1) man homme woman femme as we will describe in more detail in section 5, they key features of word list entry are an index to concept assumed to be of general provenance(e.g., man) and form drawn from specific language (e.g. homme) determined to be the counterpart for that concept within that language.
</prevsent>
<prevsent>most typically, the elements indexing the relevant concepts are words drawn from languages of wider communication (e.g., english or spanish).
</prevsent>
</prevsection>
<citsent citstr=" W07-1528 ">
linguistics recent years have seen fair amount of attention paid to the modeling of traditional linguistic data types, including lexicons, glossed texts, and grammars (bell and bird, 2000; good, 2004; palmer and erk, 2007; <papid> W07-1528 </papid>nordhoff, 2008).</citsent>
<aftsection>
<nextsent>the data type offocus here, word lists, has not seen serious treatment.
</nextsent>
<nextsent>superficially, word lists resemble lexicons and, of course, they can be considered kind of lexical resource.
</nextsent>
<nextsent>however, as will be shown in section 5, there are important differences between lexicons and word lists which have implications for how they should be modeled.most of the work on modeling descriptive linguistic data types has proceeded without special consideration for possible nlp applications for the data being encoded.
</nextsent>
<nextsent>this is largely because the work was initially response to issues relating to the longevity of digital descriptive data which was,otherwise, quite often being encoded solely in (often proprietary) presentation formats (bird and simons, 2003).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3630">
<title id=" W10-2101.xml">modeling and encoding traditional word lists for machine applications </title>
<section> related work on lexicon.  </section>
<citcontext>
<prevsection>
<prevsent>interoperability in nlp the relevant related work in nlp is that focused on inter operation among lexical resources.
</prevsent>
<prevsent>oneway to achieve this is to make use of language independent ontologies (or comparable objects) forword meanings which can serve as pivots for mul 2 tiling ual applications (ide et al , 1998; vossen, 2004; nirenburg et al , 2004; ronzano et al , 2010).
</prevsent>
</prevsection>
<citsent citstr=" W98-0713 ">
the word senses provided by wordnet, for example, have been used for this purpose (ohara et al , 1998).<papid> W98-0713 </papid>a recognized data modeling standard for lexical inter operation is the lexical markup framework (lmf), which provides standardized framework for the description and representation of lexicons (francopoulo et al , 2009).</citsent>
<aftsection>
<nextsent>instantiations oflmf have also been extended to represent wordnets, e.g., wordnet-lmf (soria et al , 2009), in ways which facilitate interoperation.
</nextsent>
<nextsent>while we do not attempt to express the data model we develop here in lmf, doing so should be relatively straightforward.
</nextsent>
<nextsent>the key conceptual observation is to recognize that the sets of meaning labels found in word lists (see section 2) canbe treated either as shared language-neutral ontology or as kind of interlingua, both of which have already been the subject of lmf modeling(vossen, 2004).
</nextsent>
<nextsent>as such, they are also comparable to language-independent ontologies of word meaning, bringing them in line with the work on multilingual nlp mentioned above.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3632">
<title id=" W10-2101.xml">modeling and encoding traditional word lists for machine applications </title>
<section> applications.  </section>
<citcontext>
<prevsection>
<prevsent>therefore, while ourdata is sparse in many ways, it has coverage well beyond what is normally found.crucially, our data model makes visible the similarities between concept icon and an interlingua,thus opening up data type produced for descriptive linguistics for use in nlp contexts.
</prevsent>
<prevsent>in particular, we have created resource that we believe could be exploited for nlp applications where simple word-to-word mapping across languages is useful, as in the panimages5 search of the pan lex project, which facilitates cross-lingual image searching.
</prevsent>
</prevsection>
<citsent citstr=" W07-1317 ">
such database can also be readily exploited for machine identification of cognatesand recurrent sound correspondences to test algorithms for language family reconstruction (kon drak et al , 2007; <papid> W07-1317 </papid>nerbonne et al , 2007) <papid> W07-1301 </papid>or to assist in the automatic identification of phonemic systems and, thereby, enhance relevant existing work (moran and wright, 2009).</citsent>
<aftsection>
<nextsent>we, therefore, thinkit represents useful example of using data modeling and legacy data conversion to find common ground between descriptive linguistics and nlp.
</nextsent>
<nextsent>acknowledgments funding for the work described here was provided by nsf grant bcs-0753321, and the work is being done in the context of the larger lexicon enhancement via the gold ontology project, headed by researchers at the institute for language information and technology at eastern michigan university.
</nextsent>
<nextsent>partial funding for the collection and cura tion of the word lists was provided by the rosetta project (nsf due-0333727), along with the max planck institute for evolutionary anthropology.
</nextsent>

</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3633">
<title id=" W10-2101.xml">modeling and encoding traditional word lists for machine applications </title>
<section> applications.  </section>
<citcontext>
<prevsection>
<prevsent>therefore, while ourdata is sparse in many ways, it has coverage well beyond what is normally found.crucially, our data model makes visible the similarities between concept icon and an interlingua,thus opening up data type produced for descriptive linguistics for use in nlp contexts.
</prevsent>
<prevsent>in particular, we have created resource that we believe could be exploited for nlp applications where simple word-to-word mapping across languages is useful, as in the panimages5 search of the pan lex project, which facilitates cross-lingual image searching.
</prevsent>
</prevsection>
<citsent citstr=" W07-1301 ">
such database can also be readily exploited for machine identification of cognatesand recurrent sound correspondences to test algorithms for language family reconstruction (kon drak et al , 2007; <papid> W07-1317 </papid>nerbonne et al , 2007) <papid> W07-1301 </papid>or to assist in the automatic identification of phonemic systems and, thereby, enhance relevant existing work (moran and wright, 2009).</citsent>
<aftsection>
<nextsent>we, therefore, thinkit represents useful example of using data modeling and legacy data conversion to find common ground between descriptive linguistics and nlp.
</nextsent>
<nextsent>acknowledgments funding for the work described here was provided by nsf grant bcs-0753321, and the work is being done in the context of the larger lexicon enhancement via the gold ontology project, headed by researchers at the institute for language information and technology at eastern michigan university.
</nextsent>
<nextsent>partial funding for the collection and cura tion of the word lists was provided by the rosetta project (nsf due-0333727), along with the max planck institute for evolutionary anthropology.
</nextsent>

</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3634">
<title id=" W10-2913.xml">computing optimal alignments for the ibm3 translation model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we use the well-known branch-and-cutmethod, but also show how it can be customized to the specific problem discussed in this paper.
</prevsent>
<prevsent>in fact, large number of alignments can be excluded from the start without losing global optimality.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
brown et al (1993) <papid> J93-2003 </papid>proposed to approach the problem of automatic natural language translation from statistical viewpoint and introduced five probability models, known as ibm 1-5.</citsent>
<aftsection>
<nextsent>their models were single word based, where each source word could produce at most one target word.
</nextsent>
<nextsent>state-of-the-art statistical translation systems follow the phrase based approach, e.g.
</nextsent>
<nextsent>(och and ney, 2000; <papid> P00-1056 </papid>marcu and wong, 2002; <papid> W02-1018 </papid>koehn, 2004;chiang, 2007; <papid> J07-2003 </papid>hoang et al, 2007), and hence allow more general alignments.</nextsent>
<nextsent>yet, single word based models (brown et al, 1993; <papid> J93-2003 </papid>brown et al, 1995; vogel et al, 1996) <papid> C96-2141 </papid>are still highly relevant: many phrase based systems extract phrases from the alignments found by training the single word based models, and those that train phrases directly usually underperform these systems (denero et al., 2006).<papid> W06-3105 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3635">
<title id=" W10-2913.xml">computing optimal alignments for the ibm3 translation model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>their models were single word based, where each source word could produce at most one target word.
</prevsent>
<prevsent>state-of-the-art statistical translation systems follow the phrase based approach, e.g.
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
(och and ney, 2000; <papid> P00-1056 </papid>marcu and wong, 2002; <papid> W02-1018 </papid>koehn, 2004;chiang, 2007; <papid> J07-2003 </papid>hoang et al, 2007), and hence allow more general alignments.</citsent>
<aftsection>
<nextsent>yet, single word based models (brown et al, 1993; <papid> J93-2003 </papid>brown et al, 1995; vogel et al, 1996) <papid> C96-2141 </papid>are still highly relevant: many phrase based systems extract phrases from the alignments found by training the single word based models, and those that train phrases directly usually underperform these systems (denero et al., 2006).<papid> W06-3105 </papid></nextsent>
<nextsent>single word based models can be divided into two classes.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3636">
<title id=" W10-2913.xml">computing optimal alignments for the ibm3 translation model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>their models were single word based, where each source word could produce at most one target word.
</prevsent>
<prevsent>state-of-the-art statistical translation systems follow the phrase based approach, e.g.
</prevsent>
</prevsection>
<citsent citstr=" W02-1018 ">
(och and ney, 2000; <papid> P00-1056 </papid>marcu and wong, 2002; <papid> W02-1018 </papid>koehn, 2004;chiang, 2007; <papid> J07-2003 </papid>hoang et al, 2007), and hence allow more general alignments.</citsent>
<aftsection>
<nextsent>yet, single word based models (brown et al, 1993; <papid> J93-2003 </papid>brown et al, 1995; vogel et al, 1996) <papid> C96-2141 </papid>are still highly relevant: many phrase based systems extract phrases from the alignments found by training the single word based models, and those that train phrases directly usually underperform these systems (denero et al., 2006).<papid> W06-3105 </papid></nextsent>
<nextsent>single word based models can be divided into two classes.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3637">
<title id=" W10-2913.xml">computing optimal alignments for the ibm3 translation model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>their models were single word based, where each source word could produce at most one target word.
</prevsent>
<prevsent>state-of-the-art statistical translation systems follow the phrase based approach, e.g.
</prevsent>
</prevsection>
<citsent citstr=" J07-2003 ">
(och and ney, 2000; <papid> P00-1056 </papid>marcu and wong, 2002; <papid> W02-1018 </papid>koehn, 2004;chiang, 2007; <papid> J07-2003 </papid>hoang et al, 2007), and hence allow more general alignments.</citsent>
<aftsection>
<nextsent>yet, single word based models (brown et al, 1993; <papid> J93-2003 </papid>brown et al, 1995; vogel et al, 1996) <papid> C96-2141 </papid>are still highly relevant: many phrase based systems extract phrases from the alignments found by training the single word based models, and those that train phrases directly usually underperform these systems (denero et al., 2006).<papid> W06-3105 </papid></nextsent>
<nextsent>single word based models can be divided into two classes.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3639">
<title id=" W10-2913.xml">computing optimal alignments for the ibm3 translation model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>state-of-the-art statistical translation systems follow the phrase based approach, e.g.
</prevsent>
<prevsent>(och and ney, 2000; <papid> P00-1056 </papid>marcu and wong, 2002; <papid> W02-1018 </papid>koehn, 2004;chiang, 2007; <papid> J07-2003 </papid>hoang et al, 2007), and hence allow more general alignments.</prevsent>
</prevsection>
<citsent citstr=" C96-2141 ">
yet, single word based models (brown et al, 1993; <papid> J93-2003 </papid>brown et al, 1995; vogel et al, 1996) <papid> C96-2141 </papid>are still highly relevant: many phrase based systems extract phrases from the alignments found by training the single word based models, and those that train phrases directly usually underperform these systems (denero et al., 2006).<papid> W06-3105 </papid></citsent>
<aftsection>
<nextsent>single word based models can be divided into two classes.
</nextsent>
<nextsent>on the one hand, models like ibm-1, ibm-2 and the hmm are computationally easy to handle: both marginals and viterbi alignments can be computed by dynamic programming or even simpler techniques.on the other hand there are fertility based models, including ibm 3-5 and model 6.
</nextsent>
<nextsent>these models have been shown to be of higher practical relevance than the members of the first class (och and ney, 2003) <papid> J03-1002 </papid>since they usually produce better alignments.</nextsent>
<nextsent>at the same time, computing viterbi alignments for these methods has been shown tobe np-hard (udupa and maji, 2006), <papid> E06-1004 </papid>and computing marginals is no easier.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3640">
<title id=" W10-2913.xml">computing optimal alignments for the ibm3 translation model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>state-of-the-art statistical translation systems follow the phrase based approach, e.g.
</prevsent>
<prevsent>(och and ney, 2000; <papid> P00-1056 </papid>marcu and wong, 2002; <papid> W02-1018 </papid>koehn, 2004;chiang, 2007; <papid> J07-2003 </papid>hoang et al, 2007), and hence allow more general alignments.</prevsent>
</prevsection>
<citsent citstr=" W06-3105 ">
yet, single word based models (brown et al, 1993; <papid> J93-2003 </papid>brown et al, 1995; vogel et al, 1996) <papid> C96-2141 </papid>are still highly relevant: many phrase based systems extract phrases from the alignments found by training the single word based models, and those that train phrases directly usually underperform these systems (denero et al., 2006).<papid> W06-3105 </papid></citsent>
<aftsection>
<nextsent>single word based models can be divided into two classes.
</nextsent>
<nextsent>on the one hand, models like ibm-1, ibm-2 and the hmm are computationally easy to handle: both marginals and viterbi alignments can be computed by dynamic programming or even simpler techniques.on the other hand there are fertility based models, including ibm 3-5 and model 6.
</nextsent>
<nextsent>these models have been shown to be of higher practical relevance than the members of the first class (och and ney, 2003) <papid> J03-1002 </papid>since they usually produce better alignments.</nextsent>
<nextsent>at the same time, computing viterbi alignments for these methods has been shown tobe np-hard (udupa and maji, 2006), <papid> E06-1004 </papid>and computing marginals is no easier.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3641">
<title id=" W10-2913.xml">computing optimal alignments for the ibm3 translation model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>single word based models can be divided into two classes.
</prevsent>
<prevsent>on the one hand, models like ibm-1, ibm-2 and the hmm are computationally easy to handle: both marginals and viterbi alignments can be computed by dynamic programming or even simpler techniques.on the other hand there are fertility based models, including ibm 3-5 and model 6.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
these models have been shown to be of higher practical relevance than the members of the first class (och and ney, 2003) <papid> J03-1002 </papid>since they usually produce better alignments.</citsent>
<aftsection>
<nextsent>at the same time, computing viterbi alignments for these methods has been shown tobe np-hard (udupa and maji, 2006), <papid> E06-1004 </papid>and computing marginals is no easier.</nextsent>
<nextsent>the standard way to handle these models ? as implemented in giza++ (al-onaizan et al, 1999;och and ney, 2003) <papid> J03-1002 </papid>? is to use hill climbing algorithm.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3643">
<title id=" W10-2913.xml">computing optimal alignments for the ibm3 translation model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>on the one hand, models like ibm-1, ibm-2 and the hmm are computationally easy to handle: both marginals and viterbi alignments can be computed by dynamic programming or even simpler techniques.on the other hand there are fertility based models, including ibm 3-5 and model 6.
</prevsent>
<prevsent>these models have been shown to be of higher practical relevance than the members of the first class (och and ney, 2003) <papid> J03-1002 </papid>since they usually produce better alignments.</prevsent>
</prevsection>
<citsent citstr=" E06-1004 ">
at the same time, computing viterbi alignments for these methods has been shown tobe np-hard (udupa and maji, 2006), <papid> E06-1004 </papid>and computing marginals is no easier.</citsent>
<aftsection>
<nextsent>the standard way to handle these models ? as implemented in giza++ (al-onaizan et al, 1999;och and ney, 2003) <papid> J03-1002 </papid>? is to use hill climbing algorithm.</nextsent>
<nextsent>recently udupa and maji (2005) proposed an interesting approximation based on solving sequences of exponentially large subproblemsby means of dynamic programming and also addressed the decoding problem.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3646">
<title id=" W10-2913.xml">computing optimal alignments for the ibm3 translation model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>while there is no polynomial run-time guarantee, in practice the applied branch-and-cut framework is fast enough to find optimal solutions even for the large canadian hansa rds task (restricted to sentences with at most 75 words), with training time of 6 hours on 2.4 ghz core 2 duo (single threaded).
</prevsent>
<prevsent>98 integer linear programming in the context of machine translation first appeared in the work of germann et al (2004), who addressed the translation problem (often called decoding) in terms of travelings-salesman like formulation.
</prevsent>
</prevsection>
<citsent citstr=" P08-2007 ">
recently, denero and klein (2008) <papid> P08-2007 </papid>addressed the training problem for phrase-based models by means of integer linear programming, and proved that the problem is np-hard.</citsent>
<aftsection>
<nextsent>the main difference to our work is that they allow only consecutive words inthe phrases.
</nextsent>
<nextsent>in their formulation, allowing arbitrary phrases would require an exponential number of variables.
</nextsent>
<nextsent>in contrast, our approach handles the classical single word based model where any kind of phrases?
</nextsent>
<nextsent>in the source sentence are aligned to one-word phrases in the target sentence.lacoste-julien et al (2006) propose an integer linear program for symmetrized word-level alignment model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3647">
<title id=" W10-2913.xml">computing optimal alignments for the ibm3 translation model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in contrast to our work, they only have avery crude fertility model and they are considering substantially different model.
</prevsent>
<prevsent>it should be noted, however, that subclass of their problems can be solved in polynomial time - the problem is closely related to bipartite graph matching.
</prevsent>
</prevsection>
<citsent citstr=" C04-1032 ">
less general approaches based on matching have been proposed in (matusov et al, 2004) <papid> C04-1032 </papid>and (taskar et al., 2005).<papid> H05-1010 </papid></citsent>
<aftsection>
<nextsent>recently bodrumlu et al (2009) <papid> W09-1804 </papid>proposed avery innovative cost function for jointly optimizing dictionary entries and alignments, which they minimize using integer linear programming.</nextsent>
<nextsent>they also include mechanism to derive n-best lists.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3648">
<title id=" W10-2913.xml">computing optimal alignments for the ibm3 translation model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in contrast to our work, they only have avery crude fertility model and they are considering substantially different model.
</prevsent>
<prevsent>it should be noted, however, that subclass of their problems can be solved in polynomial time - the problem is closely related to bipartite graph matching.
</prevsent>
</prevsection>
<citsent citstr=" H05-1010 ">
less general approaches based on matching have been proposed in (matusov et al, 2004) <papid> C04-1032 </papid>and (taskar et al., 2005).<papid> H05-1010 </papid></citsent>
<aftsection>
<nextsent>recently bodrumlu et al (2009) <papid> W09-1804 </papid>proposed avery innovative cost function for jointly optimizing dictionary entries and alignments, which they minimize using integer linear programming.</nextsent>
<nextsent>they also include mechanism to derive n-best lists.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3649">
<title id=" W10-2913.xml">computing optimal alignments for the ibm3 translation model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it should be noted, however, that subclass of their problems can be solved in polynomial time - the problem is closely related to bipartite graph matching.
</prevsent>
<prevsent>less general approaches based on matching have been proposed in (matusov et al, 2004) <papid> C04-1032 </papid>and (taskar et al., 2005).<papid> H05-1010 </papid></prevsent>
</prevsection>
<citsent citstr=" W09-1804 ">
recently bodrumlu et al (2009) <papid> W09-1804 </papid>proposed avery innovative cost function for jointly optimizing dictionary entries and alignments, which they minimize using integer linear programming.</citsent>
<aftsection>
<nextsent>they also include mechanism to derive n-best lists.
</nextsent>
<nextsent>however, they mention rather long computation times for rather small corpora.
</nextsent>
<nextsent>it is not clear if the large hansa rds tasks could be addressed by their method.an overview of integer linear programming approaches for natural language processing can be found on http://ilpnlp.wikidot.com/.
</nextsent>
<nextsent>to facilitate further research in this area, the source code will be made publicly available.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3655">
<title id=" W10-2204.xml">maximum likelihood estimation of feature based distributions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the hypothesis that the atomic units of phonology are phonological features, and not segments, is one of the tenets of modern phonology (jakobson etal., 1952; chomsky and halle, 1968).
</prevsent>
<prevsent>according to this hypothesis, segments are essentially epi phenomenal and exist only by virtue of being shorthand description of collection of more primitive units the features.
</prevsent>
</prevsection>
<citsent citstr=" J96-4003 ">
incorporating this hypothesis into phonological learning models has been the focus of much influential work (gildeaand jurafsky, 1996; <papid> J96-4003 </papid>wilson, 2006; hayes and wilson, 2008; moreton, 2008; albright, 2009).</citsent>
<aftsection>
<nextsent>this paper makes three contributions.
</nextsent>
<nextsent>the first contribution is framework within which:1.
</nextsent>
<nextsent>researchers can choose which statistical independence assumptions to make regarding phonological features; 2.
</nextsent>
<nextsent>feature systems can be fully integrated into strictly local (mcnaughton and papert, 1971) (i.e. n-gram models (jurafsky and martin, 2008)) and strictly piece wise models (rogers et al, 2009; heinz and rogers, 2010) inorder to define families of prov ably well formed, feature-based probability distributions that are prov ably efficiently estimable.the main idea is to define family of distributions as the normalized product of simpler distributions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3656">
<title id=" W10-2204.xml">maximum likelihood estimation of feature based distributions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this is because the parameters of the distributions are defined in terms of the factors which combine in predictable ways via the product.
</prevsent>
<prevsent>fewer parameters means accurate estimation occurs with less data and, relatedly, the family contains fewer distributions.this idea is not new.
</prevsent>
</prevsection>
<citsent citstr=" D08-1113 ">
it is explicit in facto rial hidden markov models (fhmms) (ghahra mani and jordan, 1997; saul and jordan, 1999),and more recently underlies approaches to describing and inferring regular string transductions (dreyer et al, 2008; <papid> D08-1113 </papid>dreyer and eisner, 2009).although hmms and probabilistic finite-state automata describe the same class of distributions (vidal et al, 2005a; vidal et al, 2005b), this paper presents these ideas informal language-theoretic and automata-theoretic terms because (1) there are no hidden states and is thus simpler than fhmms, (2) determinstic automata have several desirable properties crucially used here, and (3) pdfas add probabilities to structure whereas hmms add structure to probabilities and the authors are more comfortable with the former perspective (for further discussion, see vidal et al (2005a,b)).</citsent>
<aftsection>
<nextsent>the second contribution illustrates the main idea with feature-based bigram model with 28 strong statistical independence assumption: notwo features interact.
</nextsent>
<nextsent>this is shown to capture exactly the intuition that sounds with like features have like distributions.
</nextsent>
<nextsent>also, the assumption of non-interacting features is shown to be too strong because like sounds do not have like distribution sin actual phonotactic patterns.
</nextsent>
<nextsent>four kinds of feat ural interactions are identified and possible solutions are discussed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3657">
<title id=" W10-2607.xml">domain adaptation with unlabeled data for dialog act tagging </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we refer to the labeled training domain as the source domain.
</prevsent>
<prevsent>we compare two adaptation approaches: simple one based on forcing the classifier to learn only on shared?
</prevsent>
</prevsection>
<citsent citstr=" P07-1056 ">
features that appear in both domains, and more complex one based on structural correspondence learning (scl) from blitzer et al  (2007).<papid> P07-1056 </papid></citsent>
<aftsection>
<nextsent>the shared feature approach has been investigated for adaptation in other tasks, e.g. aue and gamon (2005) for sentiment classification and dredze etal.
</nextsent>
<nextsent>(2007) for parsing.
</nextsent>
<nextsent>scl has been used successfully for sentiment classification and part-ofspeech tagging (blitzer et al , 2006); <papid> W06-1615 </papid>here we investigate its applicability to theda classification task, using multi-view learning implementation as suggested by blitzer et al  (2009).</nextsent>
<nextsent>in addition to analyzing these two methods on novel task, we show an interesting comparison between them: inthis setting, both methods turn out to have similar effect caused by correlating cues for particular da class (backchannel) with length.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3659">
<title id=" W10-2607.xml">domain adaptation with unlabeled data for dialog act tagging </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the shared feature approach has been investigated for adaptation in other tasks, e.g. aue and gamon (2005) for sentiment classification and dredze etal.
</prevsent>
<prevsent>(2007) for parsing.
</prevsent>
</prevsection>
<citsent citstr=" W06-1615 ">
scl has been used successfully for sentiment classification and part-ofspeech tagging (blitzer et al , 2006); <papid> W06-1615 </papid>here we investigate its applicability to theda classification task, using multi-view learning implementation as suggested by blitzer et al  (2009).</citsent>
<aftsection>
<nextsent>in addition to analyzing these two methods on novel task, we show an interesting comparison between them: inthis setting, both methods turn out to have similar effect caused by correlating cues for particular da class (backchannel) with length.
</nextsent>
<nextsent>we classify pre-segmented utterances based ontheir transcripts, and we consider only four high level classes: statement, question, backchannel,and incomplete.
</nextsent>
<nextsent>experiments are performed using all train/test pairs among three conversational speech corpora : the meeting recorder dialog act corpus (mrda) (shriberg et al , 2004), <papid> W04-2319 </papid>switchboard damsl (swbd) (jurafsky et al , 1997), and the spanish call home dialog act corpus (spch) (levin et al , 1998).</nextsent>
<nextsent>the first is multi-party,face-to-face meeting speech; the second is topic prompted telephone speech between strangers; and the third is informal telephone speech between friends and family members.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3660">
<title id=" W10-2607.xml">domain adaptation with unlabeled data for dialog act tagging </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in addition to analyzing these two methods on novel task, we show an interesting comparison between them: inthis setting, both methods turn out to have similar effect caused by correlating cues for particular da class (backchannel) with length.
</prevsent>
<prevsent>we classify pre-segmented utterances based ontheir transcripts, and we consider only four high level classes: statement, question, backchannel,and incomplete.
</prevsent>
</prevsection>
<citsent citstr=" W04-2319 ">
experiments are performed using all train/test pairs among three conversational speech corpora : the meeting recorder dialog act corpus (mrda) (shriberg et al , 2004), <papid> W04-2319 </papid>switchboard damsl (swbd) (jurafsky et al , 1997), and the spanish call home dialog act corpus (spch) (levin et al , 1998).</citsent>
<aftsection>
<nextsent>the first is multi-party,face-to-face meeting speech; the second is topic prompted telephone speech between strangers; and the third is informal telephone speech between friends and family members.
</nextsent>
<nextsent>the first two are in english, while the third is in spanish.
</nextsent>
<nextsent>when the source and target domains differ in language, we 45 apply machine translation to the target domain to convert it to the language of the source domain.
</nextsent>
<nextsent>automatic da tagging across domain has been investigated by handful of researchers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3661">
<title id=" W10-2607.xml">domain adaptation with unlabeled data for dialog act tagging </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>when the source and target domains differ in language, we 45 apply machine translation to the target domain to convert it to the language of the source domain.
</prevsent>
<prevsent>automatic da tagging across domain has been investigated by handful of researchers.
</prevsent>
</prevsection>
<citsent citstr=" C08-1123 ">
webband liu (2008) <papid> C08-1123 </papid>investigated cross-corpus training between swbd and another corpus consisting of task-oriented calls, although no adaptation was attempted.</citsent>
<aftsection>
<nextsent>similarly, rosset et al  (2008) reported on recognition of task-oriented da tags across domain and language (french to english) by using utterances that had been pre-processed to extract entities.
</nextsent>
<nextsent>tur (2005) applied supervised model adaptation to intent classification across customer dialog systems, and guz et al  (2010) applied supervised model adaptation methods forda segmentation and classification on mrda using labeled data from both mrda and swbd.
</nextsent>
<nextsent>most similar to our work is that of jeong et al (2009), <papid> D09-1130 </papid>who compared two methods for semi supervised adaptation, using swbd/mrda as the source training set and email or forums corpora as the target domains.</nextsent>
<nextsent>both methods were based on incorporating unlabeled target domain examples into training.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3662">
<title id=" W10-2607.xml">domain adaptation with unlabeled data for dialog act tagging </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>similarly, rosset et al  (2008) reported on recognition of task-oriented da tags across domain and language (french to english) by using utterances that had been pre-processed to extract entities.
</prevsent>
<prevsent>tur (2005) applied supervised model adaptation to intent classification across customer dialog systems, and guz et al  (2010) applied supervised model adaptation methods forda segmentation and classification on mrda using labeled data from both mrda and swbd.
</prevsent>
</prevsection>
<citsent citstr=" D09-1130 ">
most similar to our work is that of jeong et al (2009), <papid> D09-1130 </papid>who compared two methods for semi supervised adaptation, using swbd/mrda as the source training set and email or forums corpora as the target domains.</citsent>
<aftsection>
<nextsent>both methods were based on incorporating unlabeled target domain examples into training.
</nextsent>
<nextsent>success has also been reported forself-training approaches on same-domain semi supervised learning (venkataraman et al , 2003; tur et al , 2005).
</nextsent>
<nextsent>we are not aware of prior workon cross-lingual da tagging via machine translation, although translation approach has been employed for cross-lingual text classification and information retrieval, e.g. belet al  (2003).in recent years there has been increasing interest in domain adaptation methods based on unlabeled target domain data.
</nextsent>
<nextsent>several kinds of approaches have been proposed, including self training (roark and bacchiani, 2003), <papid> N03-1027 </papid>instance weighting (huang et al , 2007), change of feature representation (pan et al , 2008), and clustering methods (xing et al , 2007).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3663">
<title id=" W10-2607.xml">domain adaptation with unlabeled data for dialog act tagging </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>success has also been reported forself-training approaches on same-domain semi supervised learning (venkataraman et al , 2003; tur et al , 2005).
</prevsent>
<prevsent>we are not aware of prior workon cross-lingual da tagging via machine translation, although translation approach has been employed for cross-lingual text classification and information retrieval, e.g. belet al  (2003).in recent years there has been increasing interest in domain adaptation methods based on unlabeled target domain data.
</prevsent>
</prevsection>
<citsent citstr=" N03-1027 ">
several kinds of approaches have been proposed, including self training (roark and bacchiani, 2003), <papid> N03-1027 </papid>instance weighting (huang et al , 2007), change of feature representation (pan et al , 2008), and clustering methods (xing et al , 2007).</citsent>
<aftsection>
<nextsent>scl (blitzer et al , 2006) <papid> W06-1615 </papid>is one feature representation approach that has been effective on certain high-dimensional nlp problems, including part-of-speech tagging and sentiment classification.</nextsent>
<nextsent>scl uses unlabeled data to learn feature projections that tie together source and target features via their correlations with features shared between domains.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3665">
<title id=" W10-2607.xml">domain adaptation with unlabeled data for dialog act tagging </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>note that some previous work on da tagging has used contextual features from surrounding utterances, or markov models for theda sequence.
</prevsent>
<prevsent>in addition, some work has used prosodic or other acoustic features.
</prevsent>
</prevsection>
<citsent citstr=" J00-3003 ">
the work of stolcke et al  (2000) <papid> J00-3003 </papid>found benefits to using markov sequence models and prosodic features in addition to word features, but those benefits were relatively small, so for simplicity our experiments here useonly word features and classify utterances in iso lation.</citsent>
<aftsection>
<nextsent>we used google translate to derive english 46 translations of the spanish spch utterances, and to derive spanish translations of the english swbd and mrda utterances.
</nextsent>
<nextsent>of course, translations are far from perfect; da classification performance could likely be improved by using translation system trained on spoken dialog.
</nextsent>
<nextsent>for instance, google translate often failed on certain words like i? that are usually capitalized in text.
</nextsent>
<nextsent>even so, when training and testing on translated utterances, the results with the generic system are surprisingly good.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3675">
<title id=" W10-1405.xml">modeling morphosyntactic agreement in constituency based parsing of modern hebrew </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>morphologically marked agreement features such as gender,number and person are used to realize grammatical relations between syntactic constituents, andsuch patterns are abundantly found in (less- or) non configurational languages (hale, 1983) where the order of words is known to be (relatively) free.agreement features encompass information concerning the functional relations between constituent sin the syntactic structure, but whether incorporating agreement features in statistical parsing model leads to improved performance has so far remained an open question and saw contradictory results.
</prevsent>
<prevsent>the first author is currently researcher at the department of linguistics and philology at uppsala university.
</prevsent>
</prevsection>
<citsent citstr=" P06-1087 ">
taking semitic languages as an example, it was shown that an svm-based shallow parser (goldberg et al, 2006) <papid> P06-1087 </papid>does not benefit from including agreement features for np chunking in hebrew.phrase-structure based parsers for arabic systematically discard morphological features from theirlabel-set and never parametrize agreement explicitly (maamouri et al, 2008).</citsent>
<aftsection>
<nextsent>models based on deep grammars such as ccg (hockenmaier and steedman, 2003) and hpsg (miyao and tsujii, 2008) <papid> J08-1002 </papid>could in principle use inflectional morphology, but they currently relyon functional information mainly.</nextsent>
<nextsent>for formalisms that do incorporate morphology, generative models are may leak probability due to unification failures (abney, 1997).<papid> J97-4005 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3676">
<title id=" W10-1405.xml">modeling morphosyntactic agreement in constituency based parsing of modern hebrew </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the first author is currently researcher at the department of linguistics and philology at uppsala university.
</prevsent>
<prevsent>taking semitic languages as an example, it was shown that an svm-based shallow parser (goldberg et al, 2006) <papid> P06-1087 </papid>does not benefit from including agreement features for np chunking in hebrew.phrase-structure based parsers for arabic systematically discard morphological features from theirlabel-set and never parametrize agreement explicitly (maamouri et al, 2008).</prevsent>
</prevsection>
<citsent citstr=" J08-1002 ">
models based on deep grammars such as ccg (hockenmaier and steedman, 2003) and hpsg (miyao and tsujii, 2008) <papid> J08-1002 </papid>could in principle use inflectional morphology, but they currently relyon functional information mainly.</citsent>
<aftsection>
<nextsent>for formalisms that do incorporate morphology, generative models are may leak probability due to unification failures (abney, 1997).<papid> J97-4005 </papid></nextsent>
<nextsent>even results from dependency parsing remain inconclusive.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3677">
<title id=" W10-1405.xml">modeling morphosyntactic agreement in constituency based parsing of modern hebrew </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>taking semitic languages as an example, it was shown that an svm-based shallow parser (goldberg et al, 2006) <papid> P06-1087 </papid>does not benefit from including agreement features for np chunking in hebrew.phrase-structure based parsers for arabic systematically discard morphological features from theirlabel-set and never parametrize agreement explicitly (maamouri et al, 2008).</prevsent>
<prevsent>models based on deep grammars such as ccg (hockenmaier and steedman, 2003) and hpsg (miyao and tsujii, 2008) <papid> J08-1002 </papid>could in principle use inflectional morphology, but they currently relyon functional information mainly.</prevsent>
</prevsection>
<citsent citstr=" J97-4005 ">
for formalisms that do incorporate morphology, generative models are may leak probability due to unification failures (abney, 1997).<papid> J97-4005 </papid></citsent>
<aftsection>
<nextsent>even results from dependency parsing remain inconclusive.
</nextsent>
<nextsent>itwas shown for dependency parsing that case, defi nite ness and animacy features are useful to enhance parsing (e.g., (vrelid and nivre, 2007)), agreement patterns are often excluded.
</nextsent>
<nextsent>when agreement features were included as features in dependency parser for hebrew in (goldberg and elhadad, 2009) <papid> W09-3819 </papid>for hebrew they obtained tiny-to-no improvement.</nextsent>
<nextsent>a question thus emerges whether there are any benefits in explicitly incorporating morphosyntactic agreement patterns into our models.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3678">
<title id=" W10-1405.xml">modeling morphosyntactic agreement in constituency based parsing of modern hebrew </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>even results from dependency parsing remain inconclusive.
</prevsent>
<prevsent>itwas shown for dependency parsing that case, defi nite ness and animacy features are useful to enhance parsing (e.g., (vrelid and nivre, 2007)), agreement patterns are often excluded.
</prevsent>
</prevsection>
<citsent citstr=" W09-3819 ">
when agreement features were included as features in dependency parser for hebrew in (goldberg and elhadad, 2009) <papid> W09-3819 </papid>for hebrew they obtained tiny-to-no improvement.</citsent>
<aftsection>
<nextsent>a question thus emerges whether there are any benefits in explicitly incorporating morphosyntactic agreement patterns into our models.
</nextsent>
<nextsent>this question is manifestation of greater issue, namely, whether it is beneficial to represent complex patterns of morphology in the statistical parsing model, or whether configurational information subsume the relevant patterns, as it is commonly assumed in constituency based parsing.
</nextsent>
<nextsent>here we claim that agreement features are useful for statistical parsing provided that they are represented and parametrized in way that reflects their linguistic substance; to express functional information orthogonal to configuration.
</nextsent>
<nextsent>40we do so by extending the relational realizational (rr) model we presented in (tsarfaty and simaan, 2008) <papid> C08-1112 </papid>to explicitly encode agreement features in its native representation (rr-agr).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3679">
<title id=" W10-1405.xml">modeling morphosyntactic agreement in constituency based parsing of modern hebrew </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this question is manifestation of greater issue, namely, whether it is beneficial to represent complex patterns of morphology in the statistical parsing model, or whether configurational information subsume the relevant patterns, as it is commonly assumed in constituency based parsing.
</prevsent>
<prevsent>here we claim that agreement features are useful for statistical parsing provided that they are represented and parametrized in way that reflects their linguistic substance; to express functional information orthogonal to configuration.
</prevsent>
</prevsection>
<citsent citstr=" C08-1112 ">
40we do so by extending the relational realizational (rr) model we presented in (tsarfaty and simaan, 2008) <papid> C08-1112 </papid>to explicitly encode agreement features in its native representation (rr-agr).</citsent>
<aftsection>
<nextsent>in the rr model, joint distribution over grammatical relations is firstly articulated in the projection phase.
</nextsent>
<nextsent>the grammatical relations may be spelled out by positioning them with respect to one another in the configuration phase, through the use of morphology in the realization phase, or both.
</nextsent>
<nextsent>this paper shows that, for hebrew, this rr-agr strategy significantly outperforms constituency-based model that treats agreement features as internally structurednon-terminal state-splits (sp-agr).
</nextsent>
<nextsent>as we accumulate morphological features, the performance gap between the rr and sp models becomes larger.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3681">
<title id=" W10-1405.xml">modeling morphosyntactic agreement in constituency based parsing of modern hebrew </title>
<section> the data.  </section>
<citcontext>
<prevsection>
<prevsent>such languages do not relyon configurational information such as position and adjacency in marking grammatical relations such as subject and object, but instead they use word-level morphology.
</prevsent>
<prevsent>one way to encode grammatical relations in the form of words is by using morphological case, that is, explicitly marking an argument (e.g. nominative, accusative) with respect to its grammatical function.
</prevsent>
</prevsection>
<citsent citstr=" D09-1088 ">
in (tsarfaty et al., 2009) <papid> D09-1088 </papid>we showed that incorporating case indeed leads to improved performance for constituency based, relational-realizational parsing of hebrew.</citsent>
<aftsection>
<nextsent>1in (maamouri et al, 2008), f178.1 for gold standard input.
</nextsent>
<nextsent>a more involved way to morphologically encode grammatical relations is by making explicit reference to the properties of multiple linguistic elements.
</nextsent>
<nextsent>this is the general pattern of agreement, i.e.,?[a] systematic co variance between semantic or formal property of one element and formal property of another.?
</nextsent>
<nextsent>(steele, adapted from (corbett, 2001)) describing agreement patterns involves explicit reference to the following four components; the element which determines the agreement properties is the controller of the agreement, the element whose properties are determined by agreement is the target, the syntactic environment in which the agreement occurs is the domain of agreement, and the properties with respect to which they agree are agreement features (corbett, 2001).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3683">
<title id=" W10-1405.xml">modeling morphosyntactic agreement in constituency based parsing of modern hebrew </title>
<section> the models.  </section>
<citcontext>
<prevsection>
<prevsent>using such supervised, linguistically motivated, state-splits, based on the phrase level marking of morphological information is onemay build an efficient implementation of pcfg based parsing model that takes into account morphological features.
</prevsent>
<prevsent>state-split models were shown to obtain state-of-the-art performance with little computational effort.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
supervised state-splits for constituency-based un lexicalized parsing in (klein and manning, 2003) <papid> P03-1054 </papid>in an accurate english parser.for the pair of hebrew sentences (2b), the morphological state-split context-free representation of the domain is as described at the top of figure 1.6the relational-realizational (rr) model different way to implement syntactic model that conform to the relaxed lh is by separating the inflectional features of surface words from their grammatical functions in the syntactic representation and let 5while agreement patterns in feature-rich grammars give rise to re-entrancies that break context-freeness, gpsg shows that using feature-percolation we can get quite far in modeling morphosyntactic dependencies and retaining context-freeness.</citsent>
<aftsection>
<nextsent>6horizontal markov ization a` la (klein and manning, 2003) <papid> P03-1054 </papid>would be self-defeating here.</nextsent>
<nextsent>markov ization of constituents conditions inflectional features on configurational positions, which is inadequate for free word-order languages as hebrew.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3703">
<title id=" W10-1405.xml">modeling morphosyntactic agreement in constituency based parsing of modern hebrew </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>this suggests that incorporating all co-heads and functional elements that contribute morphological features spread inside the constituent, is more adequate for modeling morpho syn tax than focusing on the features of single head.
</prevsent>
<prevsent>we show that morphologically marked agreement features can significantly improve parsing performance if they are represented and parametrized ina way that reflects their linguistic substance: relating form-and-function in non-linear fashion.
</prevsent>
</prevsection>
<citsent citstr=" P06-1055 ">
wehave so far dealt with the adequacy of representation and we plan to test whether more sophisticated estimation (e.g., split-merge-smooth estimation as in(petrov et al, 2006)) <papid> P06-1055 </papid>can obtain further improvements from the explicit representation of agreement.</citsent>
<aftsection>
<nextsent>at the same time, the state-of-the-art results we present render the rr model promising for further exploration with morphologically rich languages.
</nextsent>
<nextsent>acknowledgements the work of the first author has been funded by nwo, grant 017.001.271.
</nextsent>
<nextsent>we wish to thank joakim nivre and three anonymous reviewers for helpful comments on earlier drafts.
</nextsent>
<nextsent>47
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3704">
<title id=" W10-0901.xml">machine reading as a process of partial question answering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent> machine reading  itself is loosely-defined notion, ranging from extracting selective facts to constructing complex, inference-supporting representations of text.
</prevsent>
<prevsent>one approach for selective extraction is the use of semantic templates ( scripts ,  frames ) to provide set of roles (slots) and constraints on objects playing those roles (fill ers) to be expected in text, and might be filled by methods ranging from simply skimming text, e.g., frump (dejong, 1979), to full language processing, e.g., (dahlgren et al, 1991).
</prevsent>
</prevsection>
<citsent citstr=" P06-2094 ">
other work has looked at techniques for learning phrasal patterns likely to contain slot fillers (riloff, 1996; sekine, 2006) <papid> P06-2094 </papid>or contain information semantically similar to set of seed examples (carlson et al 2009).<papid> W09-2201 </papid></citsent>
<aftsection>
<nextsent>at the other end of the spectrum, some systems attempt full understanding of text, i.e., have the ambitious goal of building complete representation of the text contents (e.g., zadrozny 1991, hobbs et al 1993).
</nextsent>
<nextsent>a common thread of these approaches is to search space of alternative disam biguations and elaborations and select the most 1  coherent , based on criteria such as maximizing coreference, minimizing redundancy, and avoiding contradictions.
</nextsent>
<nextsent>for example, mulkar et al(2007) search for set of abductive inferences on the (logical form of the) text that minimizes cost (maximizes coherence) of the result, where an abductive inference might be word sense or coreference decision with an associated cost.
</nextsent>
<nextsent>similarly, zadrozny and jensen (1991) <papid> J91-2003 </papid>search space of disambiguations when interpreting paragraphs by elaborating each alternative (using dictionary definitions) and selecting the most coherent based on similar criteria.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3705">
<title id=" W10-0901.xml">machine reading as a process of partial question answering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent> machine reading  itself is loosely-defined notion, ranging from extracting selective facts to constructing complex, inference-supporting representations of text.
</prevsent>
<prevsent>one approach for selective extraction is the use of semantic templates ( scripts ,  frames ) to provide set of roles (slots) and constraints on objects playing those roles (fill ers) to be expected in text, and might be filled by methods ranging from simply skimming text, e.g., frump (dejong, 1979), to full language processing, e.g., (dahlgren et al, 1991).
</prevsent>
</prevsection>
<citsent citstr=" W09-2201 ">
other work has looked at techniques for learning phrasal patterns likely to contain slot fillers (riloff, 1996; sekine, 2006) <papid> P06-2094 </papid>or contain information semantically similar to set of seed examples (carlson et al 2009).<papid> W09-2201 </papid></citsent>
<aftsection>
<nextsent>at the other end of the spectrum, some systems attempt full understanding of text, i.e., have the ambitious goal of building complete representation of the text contents (e.g., zadrozny 1991, hobbs et al 1993).
</nextsent>
<nextsent>a common thread of these approaches is to search space of alternative disam biguations and elaborations and select the most 1  coherent , based on criteria such as maximizing coreference, minimizing redundancy, and avoiding contradictions.
</nextsent>
<nextsent>for example, mulkar et al(2007) search for set of abductive inferences on the (logical form of the) text that minimizes cost (maximizes coherence) of the result, where an abductive inference might be word sense or coreference decision with an associated cost.
</nextsent>
<nextsent>similarly, zadrozny and jensen (1991) <papid> J91-2003 </papid>search space of disambiguations when interpreting paragraphs by elaborating each alternative (using dictionary definitions) and selecting the most coherent based on similar criteria.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3706">
<title id=" W10-0901.xml">machine reading as a process of partial question answering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a common thread of these approaches is to search space of alternative disam biguations and elaborations and select the most 1  coherent , based on criteria such as maximizing coreference, minimizing redundancy, and avoiding contradictions.
</prevsent>
<prevsent>for example, mulkar et al(2007) search for set of abductive inferences on the (logical form of the) text that minimizes cost (maximizes coherence) of the result, where an abductive inference might be word sense or coreference decision with an associated cost.
</prevsent>
</prevsection>
<citsent citstr=" J91-2003 ">
similarly, zadrozny and jensen (1991) <papid> J91-2003 </papid>search space of disambiguations when interpreting paragraphs by elaborating each alternative (using dictionary definitions) and selecting the most coherent based on similar criteria.</citsent>
<aftsection>
<nextsent>work on model building is inspiring but also challenging due to the lack of constraint on the final models (even with substantial domain knowledge) and the difficulty of quantifying  coherence .
</nextsent>
<nextsent>our work falls somewhere between these two.
</nextsent>
<nextsent>we do not use templates for new knowledge, but rather use inference at run-time to identify what is known and thus what to expect that the text might be saying.
</nextsent>
<nextsent>however, unlike full model building approaches, we assume that the majority of what is being read is already known (represented) in the kb, and thus the reading task is primarily one of recognizing that knowledge in the text, and extending it with any new facts that are encountered.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3707">
<title id=" W10-0901.xml">machine reading as a process of partial question answering </title>
<section> approach.  </section>
<citcontext>
<prevsection>
<prevsent>3.2 deferred sense commitment.
</prevsent>
<prevsent>two common challenges for nlp are word sense disambiguation (wsd) and semantic role labeling 3 (srl).
</prevsent>
</prevsection>
<citsent citstr=" J08-2002 ">
while there are number of existing tools for performing these tasks based on the linguistic context (e.g., toutanova et al, 2008, <papid> J08-2002 </papid>erk and pado, 2006), their performance is only moderate (e.g., agirre et al 2007).</citsent>
<aftsection>
<nextsent>the problem is accentuated when trying to disambiguate in way consistent with particular kb, because there is often degree of subjectivity in how the knowledge engineer chose to represent the world in that kb (e.g., whether some object is the  agent  or  instrument  or  site  of an activity is to degree matter of viewpoint).
</nextsent>
<nextsent>trying to create wsd or srl module that reliably mimics the knowledge engineers decision procedure is difficult.
</nextsent>
<nextsent>to address this, we defer wsd and srl commitment during the initial text processing.
</nextsent>
<nextsent>instead, these ambiguities are resolved during the subsequent stage of querying the kb to see if (some in terpretion of) the text is already known.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3708">
<title id=" W10-3112.xml">evaluating a meta knowledge annotation scheme for bio events </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>ie systems trained to extract bio-events from texts allow users to formulate semantic queries over the extracted events.
</prevsent>
<prevsent>such queries can specify semantic restrictions on the events in terms of event types, semantic role labels and named entity types etc.
</prevsent>
</prevsection>
<citsent citstr=" P06-1128 ">
(miyao et al, 2006), <papid> P06-1128 </papid>in addition to particular keywords.</citsent>
<aftsection>
<nextsent>for example, it would be possible to search only for those texts containing bio-events of type nega tive_regulation where the cause is an entity of type protein.
</nextsent>
<nextsent>such queries provide great deal more descriptive power than traditional keyword searches over unstructured documents.
</nextsent>
<nextsent>biomedical corpora that have been manually annotated with event level information (e.g., pyysalo et al, 2007; kim et al, 2008; thompson et al, 2009) facilitate the training of systems such as those described above.
</nextsent>
<nextsent>whilst event-based querying has advantages for efficient searching, the extracted events have little practical use if they are not accompanied by meta-knowledge information to aid in their interpretation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3709">
<title id=" W10-3112.xml">evaluating a meta knowledge annotation scheme for bio events </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>figure 1.
</prevsent>
<prevsent>a simple sentence from biomedical abstract figure 2.
</prevsent>
</prevsection>
<citsent citstr=" P07-1125 ">
typical structured representation of the bio-event mentioned in figure 1 event-trigger: activates event-type: positive_regulation theme: nitrate reductase operon: operon cause: narl gene product: protein 70 dimension) of meta-knowledge, normally either speculation/certainty level, (e.g., light et al, 2004; medlock &amp; briscoe, 2007; <papid> P07-1125 </papid>vincze et al, 2008) or general information content/rhetorical intent, e.g., background, methods, results, in sights.</citsent>
<aftsection>
<nextsent>this latter type of annotation has been attempted both on abstracts, (e.g., mcknight &amp; srinivasan, 2003; ruch et al, 2007) and full papers, (e.g. teufel et al, 1999; <papid> E99-1015 </papid>langer et al, 2004; <papid> W04-0207 </papid>mizuta &amp; collier, 2004), <papid> W04-1205 </papid>with the number of distinct annotation categories varying between 4 and 14.</nextsent>
<nextsent>despite the availability of these corpora, annotation at the sentence level can often be too granular.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3710">
<title id=" W10-3112.xml">evaluating a meta knowledge annotation scheme for bio events </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a simple sentence from biomedical abstract figure 2.
</prevsent>
<prevsent>typical structured representation of the bio-event mentioned in figure 1 event-trigger: activates event-type: positive_regulation theme: nitrate reductase operon: operon cause: narl gene product: protein 70 dimension) of meta-knowledge, normally either speculation/certainty level, (e.g., light et al, 2004; medlock &amp; briscoe, 2007; <papid> P07-1125 </papid>vincze et al, 2008) or general information content/rhetorical intent, e.g., background, methods, results, in sights.</prevsent>
</prevsection>
<citsent citstr=" E99-1015 ">
this latter type of annotation has been attempted both on abstracts, (e.g., mcknight &amp; srinivasan, 2003; ruch et al, 2007) and full papers, (e.g. teufel et al, 1999; <papid> E99-1015 </papid>langer et al, 2004; <papid> W04-0207 </papid>mizuta &amp; collier, 2004), <papid> W04-1205 </papid>with the number of distinct annotation categories varying between 4 and 14.</citsent>
<aftsection>
<nextsent>despite the availability of these corpora, annotation at the sentence level can often be too granular.
</nextsent>
<nextsent>in terms of information content, sentence may describe, for example, both an experimental method and its results.
</nextsent>
<nextsent>the situation becomes more complicated if sentence contains an expression of speculation.
</nextsent>
<nextsent>if this is only marked at the sentence level, there may be confusion about which part(s) of the sentence are affected by the speculative expression.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3711">
<title id=" W10-3112.xml">evaluating a meta knowledge annotation scheme for bio events </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a simple sentence from biomedical abstract figure 2.
</prevsent>
<prevsent>typical structured representation of the bio-event mentioned in figure 1 event-trigger: activates event-type: positive_regulation theme: nitrate reductase operon: operon cause: narl gene product: protein 70 dimension) of meta-knowledge, normally either speculation/certainty level, (e.g., light et al, 2004; medlock &amp; briscoe, 2007; <papid> P07-1125 </papid>vincze et al, 2008) or general information content/rhetorical intent, e.g., background, methods, results, in sights.</prevsent>
</prevsection>
<citsent citstr=" W04-0207 ">
this latter type of annotation has been attempted both on abstracts, (e.g., mcknight &amp; srinivasan, 2003; ruch et al, 2007) and full papers, (e.g. teufel et al, 1999; <papid> E99-1015 </papid>langer et al, 2004; <papid> W04-0207 </papid>mizuta &amp; collier, 2004), <papid> W04-1205 </papid>with the number of distinct annotation categories varying between 4 and 14.</citsent>
<aftsection>
<nextsent>despite the availability of these corpora, annotation at the sentence level can often be too granular.
</nextsent>
<nextsent>in terms of information content, sentence may describe, for example, both an experimental method and its results.
</nextsent>
<nextsent>the situation becomes more complicated if sentence contains an expression of speculation.
</nextsent>
<nextsent>if this is only marked at the sentence level, there may be confusion about which part(s) of the sentence are affected by the speculative expression.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3712">
<title id=" W10-3112.xml">evaluating a meta knowledge annotation scheme for bio events </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a simple sentence from biomedical abstract figure 2.
</prevsent>
<prevsent>typical structured representation of the bio-event mentioned in figure 1 event-trigger: activates event-type: positive_regulation theme: nitrate reductase operon: operon cause: narl gene product: protein 70 dimension) of meta-knowledge, normally either speculation/certainty level, (e.g., light et al, 2004; medlock &amp; briscoe, 2007; <papid> P07-1125 </papid>vincze et al, 2008) or general information content/rhetorical intent, e.g., background, methods, results, in sights.</prevsent>
</prevsection>
<citsent citstr=" W04-1205 ">
this latter type of annotation has been attempted both on abstracts, (e.g., mcknight &amp; srinivasan, 2003; ruch et al, 2007) and full papers, (e.g. teufel et al, 1999; <papid> E99-1015 </papid>langer et al, 2004; <papid> W04-0207 </papid>mizuta &amp; collier, 2004), <papid> W04-1205 </papid>with the number of distinct annotation categories varying between 4 and 14.</citsent>
<aftsection>
<nextsent>despite the availability of these corpora, annotation at the sentence level can often be too granular.
</nextsent>
<nextsent>in terms of information content, sentence may describe, for example, both an experimental method and its results.
</nextsent>
<nextsent>the situation becomes more complicated if sentence contains an expression of speculation.
</nextsent>
<nextsent>if this is only marked at the sentence level, there may be confusion about which part(s) of the sentence are affected by the speculative expression.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3713">
<title id=" W10-3112.xml">evaluating a meta knowledge annotation scheme for bio events </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>if this is only marked at the sentence level, there may be confusion about which part(s) of the sentence are affected by the speculative expression.
</prevsent>
<prevsent>certain corpora and associated systems have attempted to address these issues.
</prevsent>
</prevsection>
<citsent citstr=" W09-1105 ">
the bio scope corpus (vincze et al, 2008) annotates the scopes of negative and speculative keywords, whilst morante &amp; daelemans (2009) <papid> W09-1105 </papid>have trained system to undertake this task.</citsent>
<aftsection>
<nextsent>the scheme described by wilbur et al (2006) applies annotation to fragments of sentences, which are created on the basis of changes in the meta-knowledge expressed.
</nextsent>
<nextsent>the scheme consists of multiple annotation dimensions which capture aspects of both certainty and rhetorical/pragmatic intent, amongst other things.
</nextsent>
<nextsent>training system to automatically annotate these dimensions is shown to be highly feasible (shatkay et al, 2008).
</nextsent>
<nextsent>event-level annotation: explicit annotation of meta-knowledge at the event-level is currently rather minimal within biomedical corpora.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3715">
<title id=" W10-3112.xml">evaluating a meta knowledge annotation scheme for bio events </title>
<section> annotation scheme.  </section>
<citcontext>
<prevsection>
<prevsent>in the case of analysis events, cl encodes confidence in the truth of the event, whilst for general events, there is temporal aspect, to account for cases where particular process is explicitly stated to occur most (but not all) of the time, using marker such as normally, or only occasionally, using marker like sometimes.
</prevsent>
<prevsent>events corresponding to direct observations are not open to judgements of certainty, nor are investigation events, which refer to things which have not yet happened or have not been verified.
</prevsent>
</prevsection>
<citsent citstr=" N07-2036 ">
regarding the choice of values for the cl dimension, there is an ongoing discussion as to whether it is possible to partition the epistemic scale into discrete categories (rubin, 2007).<papid> N07-2036 </papid></citsent>
<aftsection>
<nextsent>however, the use of number of distinct categories is undoubtedly easier for annotation purposes and has been proposed in number of previous schemes.
</nextsent>
<nextsent>although recent work has suggested the use of four or more categories (shatkay et al, 2008; thompson et al, 2008), our initial analysis of bio-event corpora has shown that only three levels of certainty seem readily distinguishable for bio-events.
</nextsent>
<nextsent>this is in line with hoye (1997), whose analysis of general english showed that there are at least three articulated points on the epistemic scale.
</nextsent>
<nextsent>we have chosen to use numerical values for this dimension, in order to reduce potential annotator confusions or biases that may be introduced through the use of labels corresponding to particular lexical markers of each category, such as probable or possible, and also to account for the fact that slightly different interpretations apply to the different levels, according to whether the event has kt value of analysis or general.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3716">
<title id=" W10-1757.xml">nbest reranking by multi task learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this meta-algorithm is simple to implement, and its modular approach allows one to plug-in different learning algorithms from existing literature.
</prevsent>
<prevsent>as proofof concept, we show statistically significant improvements on machine translation system involving millions of features.
</prevsent>
</prevsection>
<citsent citstr=" N04-1023 ">
many natural language processing applications, such as machine translation (mt), parsing, and language modeling, benefit from the n-best reranking framework (shen et al, 2004; <papid> N04-1023 </papid>collin sand koo, 2005; <papid> J05-1003 </papid>roark et al, 2007).</citsent>
<aftsection>
<nextsent>the advantage of n-best reranking is that it abstracts away the complexities of first-pass decoding, allowing the researcher to try new features and learning algorithms with fast experimental turnover.
</nextsent>
<nextsent>in the n-best reranking scenario, the training data consists of sets of hypotheses (i.e. n-best lists) generated by first-pass system, along with their labels.
</nextsent>
<nextsent>given new n-best list, the goal is to rerank it such that the best hypothesis appears near the top of the list.
</nextsent>
<nextsent>existing research have focused on training single reranker directly on the entire data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3717">
<title id=" W10-1757.xml">nbest reranking by multi task learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this meta-algorithm is simple to implement, and its modular approach allows one to plug-in different learning algorithms from existing literature.
</prevsent>
<prevsent>as proofof concept, we show statistically significant improvements on machine translation system involving millions of features.
</prevsent>
</prevsection>
<citsent citstr=" J05-1003 ">
many natural language processing applications, such as machine translation (mt), parsing, and language modeling, benefit from the n-best reranking framework (shen et al, 2004; <papid> N04-1023 </papid>collin sand koo, 2005; <papid> J05-1003 </papid>roark et al, 2007).</citsent>
<aftsection>
<nextsent>the advantage of n-best reranking is that it abstracts away the complexities of first-pass decoding, allowing the researcher to try new features and learning algorithms with fast experimental turnover.
</nextsent>
<nextsent>in the n-best reranking scenario, the training data consists of sets of hypotheses (i.e. n-best lists) generated by first-pass system, along with their labels.
</nextsent>
<nextsent>given new n-best list, the goal is to rerank it such that the best hypothesis appears near the top of the list.
</nextsent>
<nextsent>existing research have focused on training single reranker directly on the entire data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3718">
<title id=" W10-1757.xml">nbest reranking by multi task learning </title>
<section> the problem of sparse feature sets.  </section>
<citcontext>
<prevsection>
<prevsent>a common methodology in reranking is to first design feature templates based on linguistic intuition and domain knowledge.
</prevsent>
<prevsent>then, numerous features are instantiated based on the training data seen.
</prevsent>
</prevsection>
<citsent citstr=" D07-1080 ">
for example, the work of (watanabe et al, 2007) <papid> D07-1080 </papid>defines feature templates based on bilingual word alignments, which lead to extraction of heavily lexicalized features of the form: h(e, f) = ? ?</citsent>
<aftsection>
<nextsent>1 if foreign word monsieur?
</nextsent>
<nextsent>and english word mr.?
</nextsent>
<nextsent>co-occur in e,f 0 otherwise (2) one can imagine that such features are sparse because it may only fire for input sentences that contain the word monsieur?.
</nextsent>
<nextsent>for all other input sentences, it is an useless, inactive feature.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3724">
<title id=" W10-1757.xml">nbest reranking by multi task learning </title>
<section> the problem of sparse feature sets.  </section>
<citcontext>
<prevsection>
<prevsent>vocabulary size), so that features for different inputs are rarely shared.ability (e.g. many different word reorderings).
</prevsent>
<prevsent>larger may improve reranking performance, but may also increase feature spar sity.
</prevsent>
</prevsection>
<citsent citstr=" N09-1025 ">
when the number of features is too large, even popular reranking algorithms such as svm (shen et al, 2004) <papid> N04-1023 </papid>and mira (watanabe et al, 2007; <papid> D07-1080 </papid>chiang et al, 2009) <papid> N09-1025 </papid>may fail.</citsent>
<aftsection>
<nextsent>our goal here is to address this situation.
</nextsent>
<nextsent>in the following, we first give an intuitive comparison between single vs. multiple task learning(section 3.1), before presenting the general meta algorithm (section 3.2) and particular instantia tions (section 3.3).
</nextsent>
<nextsent>3.1 single vs. multiple tasks.
</nextsent>
<nextsent>given set of input sentences {f i}, the training data for reranking consists of set of n-best lists {(hi,yi)}i=1,...,i , where hi are features and yi are labels.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3728">
<title id=" W10-1757.xml">nbest reranking by multi task learning </title>
<section> proposed reranking framework.  </section>
<citcontext>
<prevsection>
<prevsent>we are now ready to present our general rerankingmeta-algorithm (see algorithm 1), termed reranking by multi task learning (rml).
</prevsent>
<prevsent>algorithm 1 reranking by multi task learning input: n-best data {(hi,yi)}i=1,...,i output: common feature representation hc(e, f) and weight vector wc 1: [optional] randomhashing({hi}) 2: = multitasklearn({(hi ,yi)}) 3: hc = extractcommonfeature(w) 4: {hic} = remapfeature({hi}, hc) 5: wc = conventionalreranker({(hic ,yi)})the first step, random hashing, is optional.
</prevsent>
</prevsection>
<citsent citstr=" W08-0804 ">
random hashing is an effective trick for reducing the dimension of sparse feature sets without suffering losses infidelity (weinberger et al, 2009;ganchev and dredze, 2008).<papid> W08-0804 </papid></citsent>
<aftsection>
<nextsent>it works by collapsing random subsets of features.
</nextsent>
<nextsent>this step can be performed to speed-up multi task learning later.
</nextsent>
<nextsent>in some cases, the original feature dimension may beso large that hashed representations may be neces sary.the next two steps are key.
</nextsent>
<nextsent>a multi task learning algorithm is run on the n-best lists, and common feature space shared by all lists is extracted.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3729">
<title id=" W10-1757.xml">nbest reranking by multi task learning </title>
<section> proposed reranking framework.  </section>
<citcontext>
<prevsection>
<prevsent>norm (quattoni et al., 2009), which replaces the 2-norm with max.
</prevsent>
<prevsent>one could also define regularizer to ensure that each task-specific wi is close to some average parameter, e.g. ||wi ? wavg||2.
</prevsent>
</prevsection>
<citsent citstr=" N09-1068 ">
if we interpret wavg as prior, we begin to see links to hierarchical bayesian methods for multi task learning (finkel and manning, 2009; <papid> N09-1068 </papid>daume, 2009).</citsent>
<aftsection>
<nextsent>2.
</nextsent>
<nextsent>shared subspace: this approach assumes.
</nextsent>
<nextsent>that there is an underlying feature sub space thatis common to all tasks.
</nextsent>
<nextsent>early works on multi task learning implement this by neural networks, where different tasks have different output layers but share the same hidden layer (caruana, 1997).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3735">
<title id=" W10-1757.xml">nbest reranking by multi task learning </title>
<section> experiments and results.  </section>
<citcontext>
<prevsection>
<prevsent>all hyper parameters of the multi task method are tuned on the held-out set.
</prevsent>
<prevsent>in particular, the most important is the number of common features to extract, which we pick from {250, 500, 1000}.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
table 2 shows the results by bleu (papineniet al, 2002) <papid> P02-1040 </papid>and per.</citsent>
<aftsection>
<nextsent>the oracle results are obtained by choosing the best hypothesis per n-best list by sentence-level bleu, which achieved 36.9 bleu in both train and test.
</nextsent>
<nextsent>a summary of our observations is: 1.
</nextsent>
<nextsent>the baseline (all sparse features) overfits.
</nextsent>
<nextsent>it.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3739">
<title id=" W10-1757.xml">nbest reranking by multi task learning </title>
<section> related work in nlp.  </section>
<citcontext>
<prevsection>
<prevsent>best reranking can be seen as sub problem of structured prediction, so many general structured prediction algorithms (c.f.
</prevsent>
<prevsent>(bakir et al, 2007))can be applied.
</prevsent>
</prevsection>
<citsent citstr=" P05-1012 ">
in fact, some structured prediction algorithms, such as the mira algorithm used in dependency parsing (mcdonald et al, 2005) <papid> P05-1012 </papid>and mt (watanabe et al, 2007) <papid> D07-1080 </papid>uses iterative sets of n-best lists in its training process.</citsent>
<aftsection>
<nextsent>other training algorithms include perceptron-style algorithms (liang et al, 2006), <papid> P06-1096 </papid>maxent (charniak and johnson, 2005), <papid> P05-1022 </papid>and boosting variants (kudo et al, 2005).<papid> P05-1024 </papid>the division into two research focuses is convenient, but may be sub optimal if the training algorithm and features do not match well together.</nextsent>
<nextsent>our work can be seen as re-connecting the two focuses, where the training algorithm is explicitly used to help discover better features.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3743">
<title id=" W10-1757.xml">nbest reranking by multi task learning </title>
<section> related work in nlp.  </section>
<citcontext>
<prevsection>
<prevsent>(bakir et al, 2007))can be applied.
</prevsent>
<prevsent>in fact, some structured prediction algorithms, such as the mira algorithm used in dependency parsing (mcdonald et al, 2005) <papid> P05-1012 </papid>and mt (watanabe et al, 2007) <papid> D07-1080 </papid>uses iterative sets of n-best lists in its training process.</prevsent>
</prevsection>
<citsent citstr=" P06-1096 ">
other training algorithms include perceptron-style algorithms (liang et al, 2006), <papid> P06-1096 </papid>maxent (charniak and johnson, 2005), <papid> P05-1022 </papid>and boosting variants (kudo et al, 2005).<papid> P05-1024 </papid>the division into two research focuses is convenient, but may be sub optimal if the training algorithm and features do not match well together.</citsent>
<aftsection>
<nextsent>our work can be seen as re-connecting the two focuses, where the training algorithm is explicitly used to help discover better features.
</nextsent>
<nextsent>multi task learning is currently an active sub field within machine learning.
</nextsent>
<nextsent>there has already been some applications in nlp: for example, (collobert and weston, 2008) uses deep neural network architecture for multi task learning on partof-speech tagging, chunking, semantic role labeling, etc. they showed that jointly learning these related tasks lead to overall improvements.
</nextsent>
<nextsent>(de selaers et al, 2009) <papid> W09-0438 </papid>applies similar methods for machine transliteration.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3744">
<title id=" W10-1757.xml">nbest reranking by multi task learning </title>
<section> related work in nlp.  </section>
<citcontext>
<prevsection>
<prevsent>(bakir et al, 2007))can be applied.
</prevsent>
<prevsent>in fact, some structured prediction algorithms, such as the mira algorithm used in dependency parsing (mcdonald et al, 2005) <papid> P05-1012 </papid>and mt (watanabe et al, 2007) <papid> D07-1080 </papid>uses iterative sets of n-best lists in its training process.</prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
other training algorithms include perceptron-style algorithms (liang et al, 2006), <papid> P06-1096 </papid>maxent (charniak and johnson, 2005), <papid> P05-1022 </papid>and boosting variants (kudo et al, 2005).<papid> P05-1024 </papid>the division into two research focuses is convenient, but may be sub optimal if the training algorithm and features do not match well together.</citsent>
<aftsection>
<nextsent>our work can be seen as re-connecting the two focuses, where the training algorithm is explicitly used to help discover better features.
</nextsent>
<nextsent>multi task learning is currently an active sub field within machine learning.
</nextsent>
<nextsent>there has already been some applications in nlp: for example, (collobert and weston, 2008) uses deep neural network architecture for multi task learning on partof-speech tagging, chunking, semantic role labeling, etc. they showed that jointly learning these related tasks lead to overall improvements.
</nextsent>
<nextsent>(de selaers et al, 2009) <papid> W09-0438 </papid>applies similar methods for machine transliteration.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3745">
<title id=" W10-1757.xml">nbest reranking by multi task learning </title>
<section> related work in nlp.  </section>
<citcontext>
<prevsection>
<prevsent>(bakir et al, 2007))can be applied.
</prevsent>
<prevsent>in fact, some structured prediction algorithms, such as the mira algorithm used in dependency parsing (mcdonald et al, 2005) <papid> P05-1012 </papid>and mt (watanabe et al, 2007) <papid> D07-1080 </papid>uses iterative sets of n-best lists in its training process.</prevsent>
</prevsection>
<citsent citstr=" P05-1024 ">
other training algorithms include perceptron-style algorithms (liang et al, 2006), <papid> P06-1096 </papid>maxent (charniak and johnson, 2005), <papid> P05-1022 </papid>and boosting variants (kudo et al, 2005).<papid> P05-1024 </papid>the division into two research focuses is convenient, but may be sub optimal if the training algorithm and features do not match well together.</citsent>
<aftsection>
<nextsent>our work can be seen as re-connecting the two focuses, where the training algorithm is explicitly used to help discover better features.
</nextsent>
<nextsent>multi task learning is currently an active sub field within machine learning.
</nextsent>
<nextsent>there has already been some applications in nlp: for example, (collobert and weston, 2008) uses deep neural network architecture for multi task learning on partof-speech tagging, chunking, semantic role labeling, etc. they showed that jointly learning these related tasks lead to overall improvements.
</nextsent>
<nextsent>(de selaers et al, 2009) <papid> W09-0438 </papid>applies similar methods for machine transliteration.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3746">
<title id=" W10-1757.xml">nbest reranking by multi task learning </title>
<section> related work in nlp.  </section>
<citcontext>
<prevsection>
<prevsent>multi task learning is currently an active sub field within machine learning.
</prevsent>
<prevsent>there has already been some applications in nlp: for example, (collobert and weston, 2008) uses deep neural network architecture for multi task learning on partof-speech tagging, chunking, semantic role labeling, etc. they showed that jointly learning these related tasks lead to overall improvements.
</prevsent>
</prevsection>
<citsent citstr=" W09-0438 ">
(de selaers et al, 2009) <papid> W09-0438 </papid>applies similar methods for machine transliteration.</citsent>
<aftsection>
<nextsent>in information extraction, learning different relation types can be naturally cast as multi task problem (jiang, 2009; <papid> P09-1114 </papid>carlson et al, 2009).<papid> W09-2201 </papid></nextsent>
<nextsent>our work can be seen as following the same philosophy, but applied to n-best lists.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3747">
<title id=" W10-1757.xml">nbest reranking by multi task learning </title>
<section> related work in nlp.  </section>
<citcontext>
<prevsection>
<prevsent>there has already been some applications in nlp: for example, (collobert and weston, 2008) uses deep neural network architecture for multi task learning on partof-speech tagging, chunking, semantic role labeling, etc. they showed that jointly learning these related tasks lead to overall improvements.
</prevsent>
<prevsent>(de selaers et al, 2009) <papid> W09-0438 </papid>applies similar methods for machine transliteration.</prevsent>
</prevsection>
<citsent citstr=" P09-1114 ">
in information extraction, learning different relation types can be naturally cast as multi task problem (jiang, 2009; <papid> P09-1114 </papid>carlson et al, 2009).<papid> W09-2201 </papid></citsent>
<aftsection>
<nextsent>our work can be seen as following the same philosophy, but applied to n-best lists.
</nextsent>
<nextsent>in other areas, (reichart et al, 2008) <papid> P08-1098 </papid>introduced an active learning strategy for annotating multi task linguistic data.</nextsent>
<nextsent>(blitzer et al, 2006) <papid> W06-1615 </papid>applies the multi task algorithm of (ando and zhang, 2005) to domain adaptation problems in nlp.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3748">
<title id=" W10-1757.xml">nbest reranking by multi task learning </title>
<section> related work in nlp.  </section>
<citcontext>
<prevsection>
<prevsent>there has already been some applications in nlp: for example, (collobert and weston, 2008) uses deep neural network architecture for multi task learning on partof-speech tagging, chunking, semantic role labeling, etc. they showed that jointly learning these related tasks lead to overall improvements.
</prevsent>
<prevsent>(de selaers et al, 2009) <papid> W09-0438 </papid>applies similar methods for machine transliteration.</prevsent>
</prevsection>
<citsent citstr=" W09-2201 ">
in information extraction, learning different relation types can be naturally cast as multi task problem (jiang, 2009; <papid> P09-1114 </papid>carlson et al, 2009).<papid> W09-2201 </papid></citsent>
<aftsection>
<nextsent>our work can be seen as following the same philosophy, but applied to n-best lists.
</nextsent>
<nextsent>in other areas, (reichart et al, 2008) <papid> P08-1098 </papid>introduced an active learning strategy for annotating multi task linguistic data.</nextsent>
<nextsent>(blitzer et al, 2006) <papid> W06-1615 </papid>applies the multi task algorithm of (ando and zhang, 2005) to domain adaptation problems in nlp.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3749">
<title id=" W10-1757.xml">nbest reranking by multi task learning </title>
<section> related work in nlp.  </section>
<citcontext>
<prevsection>
<prevsent>in information extraction, learning different relation types can be naturally cast as multi task problem (jiang, 2009; <papid> P09-1114 </papid>carlson et al, 2009).<papid> W09-2201 </papid></prevsent>
<prevsent>our work can be seen as following the same philosophy, but applied to n-best lists.</prevsent>
</prevsection>
<citsent citstr=" P08-1098 ">
in other areas, (reichart et al, 2008) <papid> P08-1098 </papid>introduced an active learning strategy for annotating multi task linguistic data.</citsent>
<aftsection>
<nextsent>(blitzer et al, 2006) <papid> W06-1615 </papid>applies the multi task algorithm of (ando and zhang, 2005) to domain adaptation problems in nlp.</nextsent>
<nextsent>we expect that more novel applications of multi task learning will appear in nlp as the techniques become scalable and standard.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3750">
<title id=" W10-1757.xml">nbest reranking by multi task learning </title>
<section> related work in nlp.  </section>
<citcontext>
<prevsection>
<prevsent>our work can be seen as following the same philosophy, but applied to n-best lists.
</prevsent>
<prevsent>in other areas, (reichart et al, 2008) <papid> P08-1098 </papid>introduced an active learning strategy for annotating multi task linguistic data.</prevsent>
</prevsection>
<citsent citstr=" W06-1615 ">
(blitzer et al, 2006) <papid> W06-1615 </papid>applies the multi task algorithm of (ando and zhang, 2005) to domain adaptation problems in nlp.</citsent>
<aftsection>
<nextsent>we expect that more novel applications of multi task learning will appear in nlp as the techniques become scalable and standard.
</nextsent>
<nextsent>n-best reranking is beneficial framework for experimenting with large feature sets, but unfortunately feature sparsity leads to overfitting.
</nextsent>
<nextsent>we addressed this by re-casting n-best lists as multi task 381learning data.
</nextsent>
<nextsent>our mt experiments show consistent statistically significant improvements.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3751">
<title id=" W10-1757.xml">nbest reranking by multi task learning </title>
<section> discussion and conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>the multi task learning perspective opens up interesting new possibilities for future work, e.g.: ? different ways to partition data into tasks, e.g. clustering lists by document structure, or hierarchical clustering of data ? multi task learning on lattices or n-best lists with larger n. it is possible that larger hypothesis space may improve the estimation of task-specific weights.?
</prevsent>
<prevsent>comparing multi task learning to sparse on line learning of batch data, e.g.
</prevsent>
</prevsection>
<citsent citstr=" P09-1054 ">
(tsuruoka et al., 2009).?<papid> P09-1054 </papid></citsent>
<aftsection>
<nextsent>modifying the multi task objective to incorporate application-specific loss/decoding, such as minimum bayes risk (kumar and byrne, 2004) ? <papid> N04-1022 </papid>using multi task learning to aid large-scale feature engineering and visualization.</nextsent>
<nextsent>acknowledgments we have received numerous helpful comments throughout the course of this work.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3752">
<title id=" W10-1757.xml">nbest reranking by multi task learning </title>
<section> discussion and conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>comparing multi task learning to sparse on line learning of batch data, e.g.
</prevsent>
<prevsent>(tsuruoka et al., 2009).?<papid> P09-1054 </papid></prevsent>
</prevsection>
<citsent citstr=" N04-1022 ">
modifying the multi task objective to incorporate application-specific loss/decoding, such as minimum bayes risk (kumar and byrne, 2004) ? <papid> N04-1022 </papid>using multi task learning to aid large-scale feature engineering and visualization.</citsent>
<aftsection>
<nextsent>acknowledgments we have received numerous helpful comments throughout the course of this work.
</nextsent>
<nextsent>in particular, we would like to thank albert au yeung,jun suzuki, shinji watanabe, and the three anonymous reviewers for their valuable suggestions.
</nextsent>


</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3753">
<title id=" W10-1805.xml">consistency checking for treebank alignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>while being useful for translation studies and foreign language pedagogy (see, e.g., botleyet al, 2000; mcenery and wilson, 1996), parallel treebankssyntactically-annotated parallel corpora offer additional useful information for machine translation, cross-language information retrieval, and word-sense disambiguation (see, e.g., tiedemann, 2003), while high-quality alignments are desirable,even gold standard annotation can contain annotation errors.
</prevsent>
<prevsent>for other forms of linguistic annotation, the presence of errors has been shownto create various problems, from unreliable training and evaluation of nlp technology (e.g., padro and marquez, 1998) to low precision and recall of queries for already rare linguistic phenomena (e.g., meurers and muller, 2008).
</prevsent>
</prevsection>
<citsent citstr=" D07-1116 ">
even small number of errors can have significant imp acton the uses of linguistic annotation, e.g., changing the assessment of parsers (e.g., habash et al, 2007).<papid> D07-1116 </papid></citsent>
<aftsection>
<nextsent>one could remove potentially unfavorable sentence pairs when training statistical mt system, to avoid incorrect word alignments (okita, 2009), <papid> P09-3009 </papid>but this removes all relevant data from those sentences and does not help evaluation.we thus focus on detecting errors in the annotation of alignments.</nextsent>
<nextsent>annotation error detection has been explored for part-of-speech (pos) annotation (e.g., loftsson, 2009) <papid> E09-1060 </papid>and syntactic annotation (e.g., ule and simov, 2004; dickinson and meurers, 2005), <papid> P05-1040 </papid>but there have been few, if any, attempts to develop general approaches to error detection for aligned corpora.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3754">
<title id=" W10-1805.xml">consistency checking for treebank alignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for other forms of linguistic annotation, the presence of errors has been shownto create various problems, from unreliable training and evaluation of nlp technology (e.g., padro and marquez, 1998) to low precision and recall of queries for already rare linguistic phenomena (e.g., meurers and muller, 2008).
</prevsent>
<prevsent>even small number of errors can have significant imp acton the uses of linguistic annotation, e.g., changing the assessment of parsers (e.g., habash et al, 2007).<papid> D07-1116 </papid></prevsent>
</prevsection>
<citsent citstr=" P09-3009 ">
one could remove potentially unfavorable sentence pairs when training statistical mt system, to avoid incorrect word alignments (okita, 2009), <papid> P09-3009 </papid>but this removes all relevant data from those sentences and does not help evaluation.we thus focus on detecting errors in the annotation of alignments.</citsent>
<aftsection>
<nextsent>annotation error detection has been explored for part-of-speech (pos) annotation (e.g., loftsson, 2009) <papid> E09-1060 </papid>and syntactic annotation (e.g., ule and simov, 2004; dickinson and meurers, 2005), <papid> P05-1040 </papid>but there have been few, if any, attempts to develop general approaches to error detection for aligned corpora.</nextsent>
<nextsent>alignments are different in nature, as the annotation does not introduce abstract categories such as pos, but relies upon defining translation units with equivalent mean ings.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3755">
<title id=" W10-1805.xml">consistency checking for treebank alignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>even small number of errors can have significant imp acton the uses of linguistic annotation, e.g., changing the assessment of parsers (e.g., habash et al, 2007).<papid> D07-1116 </papid></prevsent>
<prevsent>one could remove potentially unfavorable sentence pairs when training statistical mt system, to avoid incorrect word alignments (okita, 2009), <papid> P09-3009 </papid>but this removes all relevant data from those sentences and does not help evaluation.we thus focus on detecting errors in the annotation of alignments.</prevsent>
</prevsection>
<citsent citstr=" E09-1060 ">
annotation error detection has been explored for part-of-speech (pos) annotation (e.g., loftsson, 2009) <papid> E09-1060 </papid>and syntactic annotation (e.g., ule and simov, 2004; dickinson and meurers, 2005), <papid> P05-1040 </papid>but there have been few, if any, attempts to develop general approaches to error detection for aligned corpora.</citsent>
<aftsection>
<nextsent>alignments are different in nature, as the annotation does not introduce abstract categories such as pos, but relies upon defining translation units with equivalent meanings.
</nextsent>
<nextsent>we use the idea that variation in annotation can indicate errors (section 2), for consistency checking of alignments, as detailed in section 3.
</nextsent>
<nextsent>in section 4, we outline language-independent heuristics to sort true ambiguities from errors, and evaluate them on parallel treebank in section 5.
</nextsent>
<nextsent>in section 6 we turn to complementary method, exploiting compositional properties of aligned treebanks, to align more nodes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3756">
<title id=" W10-1805.xml">consistency checking for treebank alignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>even small number of errors can have significant imp acton the uses of linguistic annotation, e.g., changing the assessment of parsers (e.g., habash et al, 2007).<papid> D07-1116 </papid></prevsent>
<prevsent>one could remove potentially unfavorable sentence pairs when training statistical mt system, to avoid incorrect word alignments (okita, 2009), <papid> P09-3009 </papid>but this removes all relevant data from those sentences and does not help evaluation.we thus focus on detecting errors in the annotation of alignments.</prevsent>
</prevsection>
<citsent citstr=" P05-1040 ">
annotation error detection has been explored for part-of-speech (pos) annotation (e.g., loftsson, 2009) <papid> E09-1060 </papid>and syntactic annotation (e.g., ule and simov, 2004; dickinson and meurers, 2005), <papid> P05-1040 </papid>but there have been few, if any, attempts to develop general approaches to error detection for aligned corpora.</citsent>
<aftsection>
<nextsent>alignments are different in nature, as the annotation does not introduce abstract categories such as pos, but relies upon defining translation units with equivalent meanings.
</nextsent>
<nextsent>we use the idea that variation in annotation can indicate errors (section 2), for consistency checking of alignments, as detailed in section 3.
</nextsent>
<nextsent>in section 4, we outline language-independent heuristics to sort true ambiguities from errors, and evaluate them on parallel treebank in section 5.
</nextsent>
<nextsent>in section 6 we turn to complementary method, exploiting compositional properties of aligned treebanks, to align more nodes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3757">
<title id=" W10-1805.xml">consistency checking for treebank alignment </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>the approach is based on detecting strings which occur multiple times in the corpus with varying annotation, the so-called variation nuclei.
</prevsent>
<prevsent>the nucleus with repeated surrounding context is referred to as variationn-gram.
</prevsent>
</prevsection>
<citsent citstr=" C08-1026 ">
the basic heuristic for detecting annotation errors requires one word of recurring context on each side of the nucleus, which is sufficient for detecting errors in grammatical annotation with high precision (dickinson, 2008).<papid> C08-1026 </papid></citsent>
<aftsection>
<nextsent>the approach detects bracketing and labeling errors in constituency annotation.
</nextsent>
<nextsent>for example, the variation nucleus last month occurs once in the penn treebank (taylor et al, 2003) with the label np and once as non-constituent, handled through special label nil.
</nextsent>
<nextsent>as labeling error example, next tuesday occurs three times, twiceas np and once as pp (dickinson and meurers, 2003).
</nextsent>
<nextsent>the method works for discontinuous constituency annotation (dickinson and meurers, 2005), <papid> P05-1040 </papid>allowing one to apply it to alignments, which may span over several words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3760">
<title id=" W10-1805.xml">consistency checking for treebank alignment </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>had 20 fuzzy matches and 1 (erroneous) exact match.
</prevsent>
<prevsent>such 1smultron is freely available for research purposes, see http://www.cl.uzh.ch/kitt/smultron/.methods are limited, in that they do not, e.g., handle missing alignments.
</prevsent>
</prevsection>
<citsent citstr=" W07-1514 ">
the treealigner2 tool for annotating and querying aligned parallel treebanks (volk et al,2007) <papid> W07-1514 </papid>employs its own consistency checking, recently developed by torsten marek.</citsent>
<aftsection>
<nextsent>one method uses 2 ? 2 contingency tables over words, looking, e.g., at the word-word or pos-pos combinations, pinpointing anomalous translation equivalents.
</nextsent>
<nextsent>while potentially effective, this does not address the use of alignments in context, i.e., when we might expect to see rare translation.
</nextsent>
<nextsent>a second, more treebank-specific method checks for so-called branch link locality: if two nodes are aligned, any node dominating one of them can only be aligned to node dominating the other one.
</nextsent>
<nextsent>while this constraint can flag erroneous links, it too does not address missing alignments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3762">
<title id=" W10-1805.xml">consistency checking for treebank alignment </title>
<section> consistency of alignment.  </section>
<citcontext>
<prevsection>
<prevsent>aligned corpora often specify additional information about each alignment, e.g., sure?
</prevsent>
<prevsent>or possible?
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
alignment (och and ney, 2003).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>in smul tron, for instance, an exact alignment means that the strings are considered direct translation equivalents outside the current sentence context,whereas fuzzy one is not as strict an equivalent.
</nextsent>
<nextsent>for example, something in english exact aligns with etwas in german.
</nextsent>
<nextsent>however, if some thing and irgend etwas (something or other?)
</nextsent>
<nextsent>are constituents on the phrase level,  something, ir gend etwas  is an acceptable alignment (since the corpus aligns as much as possible), but is fuzzy.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3768">
<title id=" W10-1805.xml">consistency checking for treebank alignment </title>
<section> a complementary method </section>
<citcontext>
<prevsection>
<prevsent>using the existing word alignments, we can search for missing or erroneous phrase alignments.
</prevsent>
<prevsent>if the words dominated by phrase are aligned, the phrases generally should be, too (cf.
</prevsent>
</prevsection>
<citsent citstr=" W08-0411 ">
lavie et al, 2008).<papid> W08-0411 </papid></citsent>
<aftsection>
<nextsent>we take the yield of constituent in one side of corpus, find the word alignments of this yield, and use these alignments to predict phrasal alignment for the constituent.
</nextsent>
<nextsent>if the predicted alignment is not annotated, it is flagged as possible error.
</nextsent>
<nextsent>this is similar to the branch link locality of the treealigner (see section 2.2), but here as prediction, rather than restriction, of alignment.
</nextsent>
<nextsent>for example, consider the english vp choose her own friends in (1).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3769">
<title id=" W10-1805.xml">consistency checking for treebank alignment </title>
<section> a complementary method </section>
<citcontext>
<prevsection>
<prevsent>this prediction arises because the aligns to word (am) outside of the german np, due to am being contraction of the preposition an and the article dem, (cf.on and the, respectively).
</prevsent>
<prevsent>the method for predicting phrase alignments, however, relies upon words being within the constituent.
</prevsent>
</prevsection>
<citsent citstr=" C08-1139 ">
we thus concludethat: 1) the cases in step 1bi are unlikely to be errors, and 2) there are types of alignments whichwe simply will not find, problem also for automatic alignment based on similar assumptions(e.g., zhechev and way, 2008).<papid> C08-1139 </papid></citsent>
<aftsection>
<nextsent>in (2), for instance, were there not already alignment between 44 .$.blhtenvflinfa bprightnntigithhnnrunndo irgslmutfh rgtnno rritok zritivv ..cinon$ gppdivva ulrhjf voioj kiighjv rofsirhjv aaavwvda pgnv uinon cf cfnp aj cf cf cfnp ft cfasp -w cf ve cfnp vepp -wsp w* sp w*v np ajh arsp np np pp*mosp sp sp figure 3: sentence with minimal alignment the nps, we would not predict it.
</nextsent>
<nextsent>6.2 evaluation.
</nextsent>
<nextsent>the method returns 318 cases, in addition to 135 cases with multiple source/target phrases and 104predicted non-alignments.
</nextsent>
<nextsent>to evaluate, we sampled 55 of the 318 flagged phrases and found that 25 should have been aligned as suggested.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3771">
<title id=" W10-1805.xml">consistency checking for treebank alignment </title>
<section> a complementary method </section>
<citcontext>
<prevsection>
<prevsent>21of the phrases have zero difference in length between source and target, while 34 have differences of up to 9 tokens.
</prevsent>
<prevsent>of the phrases with zero length difference, 18 should have been aligned(precision=85.7%), while only 7 with length differences should have been aligned.
</prevsent>
</prevsection>
<citsent citstr=" J93-1004 ">
this is in line with previous findings that length difference can help predict alignment (cf., e.g., gale and church, 1993).<papid> J93-1004 </papid></citsent>
<aftsection>
<nextsent>about half of all phrase pairs that should be aligned should be exact, regardless of the length difference.
</nextsent>
<nextsent>the method is good at predicting the alignment of one-word phrases, e.g., pronouns, as in (3).
</nextsent>
<nextsent>of the 11 suggested alignments where both source and target have length of 1, all were correct suggestions.
</nextsent>
<nextsent>this is not surprising, since all words under the phrases are (trivially) aligned.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3774">
<title id=" W10-1804.xml">agile corpus annotation in practice an overview of manual and automatic annotation of cvs </title>
<section> automatic annotation.  </section>
<citcontext>
<prevsection>
<prevsent>the layout of cvs and the lack of full sentences also pose challenge as the ner component is trained using contextual features surrounding nes that are often not present in cv data.
</prevsent>
<prevsent>finally, the strict evaluation counts numerous boundary errors fornes which can be considered correct, e.g. the system often recognizes organization names like sun microsystems, inc? whereas the annotator included the full stop at the end (sun microsystems, inc.?).
</prevsent>
</prevsection>
<citsent citstr=" W08-0603 ">
there component (haddow, 2008) <papid> W08-0603 </papid>performs with an overall f1 of 59.0 on the cv test set(69.7% of iaa).</citsent>
<aftsection>
<nextsent>it yields high or above average scores for 10 relation types (date-loc, dat equal, daterange-job, daterange-loc, daterange-org, daterange-qual, job-loc, loc org, loc-qual, org-qual).
</nextsent>
<nextsent>it yields mid-rangeto low scores for the other relation types (date job, date-org, daterange-skill, date-skill,job-org, job-timespan, loc-timespan, org timespan, skill-timespan).
</nextsent>
<nextsent>the most frequent type is daterange-skill, skill obtained during particular time period.
</nextsent>
<nextsent>its entities tend to be found in the same zone but not always in immediate context.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3775">
<title id=" W10-1404.xml">application of different techniques to dependency parsing of basque </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>we present set of experiments on dependency parsing of the basque dependency tree bank (bdt).
</prevsent>
<prevsent>the present work has examined several directions that try to explore the rich set of morphosyntactic features in the bdt: i) experimenting the impact of morphological features, ii) application of dependency tree transformations, iii) application of two-stage parsing scheme (stacking), and iv) combinations of the individual experiments.
</prevsent>
</prevsection>
<citsent citstr=" D07-1096 ">
all the tests were conducted using malt parser (nivre et al , 2007<papid> D07-1096 </papid>a), freely available and state of the art dependency parser generator.</citsent>
<aftsection>
<nextsent>this paper presents several experiments performed on dependency parsing of the basque dependency treebank (bdt, aduriz et al , 2003).
</nextsent>
<nextsent>basque can be briefly described as morphologically rich language with free constituent order of the main sentence elements with respect to the main verb.
</nextsent>
<nextsent>this work has been developed in the context of dependency parsing exemplified by the conll shared task on dependency parsing in years 2006 and 2007 (nivre et al , 2007<papid> D07-1096 </papid>b), where several systems competed analyzing data from typo logically varied range of 19 languages.</nextsent>
<nextsent>the treebanks for all languages were standardized using previously agreed conll-x format (see figure 1).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3799">
<title id=" W10-1404.xml">application of different techniques to dependency parsing of basque </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>although many systems performed feature engineering on the bdt at conll 2007, providing strong baseline, we will take step further to im prove parsing accuracy taking into account the effect of specific morphosyntactic features.
</prevsent>
<prevsent>application of dependency-tree transformations.
</prevsent>
</prevsection>
<citsent citstr=" P07-1122 ">
nilsson et al  (2007) <papid> P07-1122 </papid>showed that they can increase parsing accuracy across lan guages/treebanks.</citsent>
<aftsection>
<nextsent>we have performed similar experiments adapted to the specific properties of basque and the bdt.
</nextsent>
<nextsent>several works have tested the effect of using two-stage parser (nivre and mcdonald, 2008; <papid> P08-1108 </papid>martins et al , 2008), where the second parser takes advantage of features obtained by the first one.</nextsent>
<nextsent>similarly, we will experiment the 31 addition of new features to the input of the second-stage parser, in the form of morphosyntactic features propagated through the first parsers dependency tree and also as the addition of contextual features (such as category or dependency relation of parent, grandparent, and descendants).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3802">
<title id=" W10-1404.xml">application of different techniques to dependency parsing of basque </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>nilsson et al  (2007) <papid> P07-1122 </papid>showed that they can increase parsing accuracy across lan guages/treebanks.</prevsent>
<prevsent>we have performed similar experiments adapted to the specific properties of basque and the bdt.</prevsent>
</prevsection>
<citsent citstr=" P08-1108 ">
several works have tested the effect of using two-stage parser (nivre and mcdonald, 2008; <papid> P08-1108 </papid>martins et al , 2008), where the second parser takes advantage of features obtained by the first one.</citsent>
<aftsection>
<nextsent>similarly, we will experiment the 31 addition of new features to the input of the second-stage parser, in the form of morphosyntactic features propagated through the first parsers dependency tree and also as the addition of contextual features (such as category or dependency relation of parent, grandparent, and descendants).
</nextsent>
<nextsent>combinations of the individual experiments.
</nextsent>
<nextsent>the rest of the paper is organized as follows.
</nextsent>
<nextsent>after presenting related work in section 2, section 3 describes the main resources used in this work.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3805">
<title id=" W10-1404.xml">application of different techniques to dependency parsing of basque </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>finally, the last section outlines our main conclusions.
</prevsent>
<prevsent>until recently, many works on treebank parsing have been mostly dedicated to languages with poor morphology, as exemplified by the penn english treebank.
</prevsent>
</prevsection>
<citsent citstr=" D09-1088 ">
as the availability of treebanks for typo logically different languages has increased, there has been growing interest towards research on extending the by now standard algorithms and methods to the new languages and treebanks (tsar faty et al , 2009).<papid> D09-1088 </papid></citsent>
<aftsection>
<nextsent>for example, collins et al  (1999) <papid> P99-1065 </papid>adapted collins?</nextsent>
<nextsent>parser to czech, highly inflected language.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3806">
<title id=" W10-1404.xml">application of different techniques to dependency parsing of basque </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>until recently, many works on treebank parsing have been mostly dedicated to languages with poor morphology, as exemplified by the penn english treebank.
</prevsent>
<prevsent>as the availability of treebanks for typo logically different languages has increased, there has been growing interest towards research on extending the by now standard algorithms and methods to the new languages and treebanks (tsar faty et al , 2009).<papid> D09-1088 </papid></prevsent>
</prevsection>
<citsent citstr=" P99-1065 ">
for example, collins et al  (1999) <papid> P99-1065 </papid>adapted collins?</citsent>
<aftsection>
<nextsent>parser to czech, highly inflected language.
</nextsent>
<nextsent>cowan and collins (2005) apply the same parser to spanish, concluding that the inclusion of morphological information improves the analyzer.
</nextsent>
<nextsent>eryiit et al  (2008) experiment the use of several types of morphosyntactic information in turkish, showing how the richest the information improves precision.
</nextsent>
<nextsent>they also show that using morphemes as the unit of analysis (instead of words) gets better results, as result of the aggluti native nature of turkish, where each word form contains several morphemes that can be individually relevant for parsing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3807">
<title id=" W10-1404.xml">application of different techniques to dependency parsing of basque </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>eryiit et al  (2008) experiment the use of several types of morphosyntactic information in turkish, showing how the richest the information improves precision.
</prevsent>
<prevsent>they also show that using morphemes as the unit of analysis (instead of words) gets better results, as result of the aggluti native nature of turkish, where each word form contains several morphemes that can be individually relevant for parsing.
</prevsent>
</prevsection>
<citsent citstr=" P08-1043 ">
goldberg and tsarfaty (2008) <papid> P08-1043 </papid>concluded that an integrated model of morphological disambiguation and syntactic parsing in hebrew treebank parsing improves the results of pipe lined approach.</citsent>
<aftsection>
<nextsent>this is in accord with our experiment of dividing words into morphemes and transforming the tree accordingly (see section 4.2).
</nextsent>
<nextsent>since the early times of treebank-based parsing systems, lot of effort has been devoted to aspects of preprocessing trees in order to improve there sults (collins, 1999).
</nextsent>
<nextsent>when applied to dependency parsing, several works (nilsson et al , 2007; <papid> P07-1122 </papid>bengoetxea and gojenola, 2009<papid> W09-3822 </papid>a) have concentrated on modifying the structure of the dependency tree, changing its original shape.</nextsent>
<nextsent>for example, nilsson et al  (2007) <papid> P07-1122 </papid>present the application of pseudo projective, verbal group and coordination transformations to several languages/treebanks using malt parser, showing that they improve the results.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3809">
<title id=" W10-1404.xml">application of different techniques to dependency parsing of basque </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>this is in accord with our experiment of dividing words into morphemes and transforming the tree accordingly (see section 4.2).
</prevsent>
<prevsent>since the early times of treebank-based parsing systems, lot of effort has been devoted to aspects of preprocessing trees in order to improve there sults (collins, 1999).
</prevsent>
</prevsection>
<citsent citstr=" W09-3822 ">
when applied to dependency parsing, several works (nilsson et al , 2007; <papid> P07-1122 </papid>bengoetxea and gojenola, 2009<papid> W09-3822 </papid>a) have concentrated on modifying the structure of the dependency tree, changing its original shape.</citsent>
<aftsection>
<nextsent>for example, nilsson et al  (2007) <papid> P07-1122 </papid>present the application of pseudo projective, verbal group and coordination transformations to several languages/treebanks using malt parser, showing that they improve the results.</nextsent>
<nextsent>another interesting research direction has examined the application of two-stage parser, where the second parser tries to improve upon the result of first parser.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3828">
<title id=" W10-1404.xml">application of different techniques to dependency parsing of basque </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>this is language independent transformation already tested in several languages (nivre and nilsson, 2005).
</prevsent>
<prevsent>this transformation is totally language independent, and can be considered standard transformation.
</prevsent>
</prevsection>
<citsent citstr=" D07-1097 ">
its performance on the first version of bdt had been already tested (hall et al , 2007), <papid> D07-1097 </papid>giving significant improvements this is in accordance with bdt having 2.9% of non-projective arcs.</citsent>
<aftsection>
<nextsent>coordination (tc).
</nextsent>
<nextsent>the transformation on coordinated sentences can be considered general (nilsson et al , 2007) <papid> P07-1122 </papid>but it is also language dependent, as it depends on the specific configurations present in each language, mainly the set of coordination conjunctions and the types of elements that can be coordinated, together with their morphosyntactic properties (such as head initial or final).</nextsent>
<nextsent>coordination in bdt (both versions) is annotated in the so called prague style (ps, see figure 2), where the conjunction is taken as the head, and the 3 malt parser allows rich set of functions to be specified for.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3860">
<title id=" W10-1404.xml">application of different techniques to dependency parsing of basque </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>we will use labeled attachment score (las) as the evaluation measure: the percentage of correct arcs (both dependency relation and head) over all arcs, with respect to the gold standard.
</prevsent>
<prevsent>table 1 shows the best conll 2007 results on bdt i. the best system obtained score of 76.94%, combining six variants of malt parser, and competing with 19 systems.
</prevsent>
</prevsection>
<citsent citstr=" D07-1101 ">
carreras (2007) <papid> D07-1101 </papid>and titov and henderson (2007) <papid> D07-1099 </papid>obtained the second and third positions, respectively.</citsent>
<aftsection>
<nextsent>we consider the last two lines in table 1 as our baselines, which consist in applying single malt parser version (hall et al , 2007), <papid> D07-1097 </papid>that obtained the fifth position at conll 2007.</nextsent>
<nextsent>although hallet al  (2007) <papid> D07-1097 </papid>applied the pro jectivization transformation (tp), we will not use it in our baseline because we want to evaluate the effect of multiple techniques over base parser.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3861">
<title id=" W10-1404.xml">application of different techniques to dependency parsing of basque </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>we will use labeled attachment score (las) as the evaluation measure: the percentage of correct arcs (both dependency relation and head) over all arcs, with respect to the gold standard.
</prevsent>
<prevsent>table 1 shows the best conll 2007 results on bdt i. the best system obtained score of 76.94%, combining six variants of malt parser, and competing with 19 systems.
</prevsent>
</prevsection>
<citsent citstr=" D07-1099 ">
carreras (2007) <papid> D07-1101 </papid>and titov and henderson (2007) <papid> D07-1099 </papid>obtained the second and third positions, respectively.</citsent>
<aftsection>
<nextsent>we consider the last two lines in table 1 as our baselines, which consist in applying single malt parser version (hall et al , 2007), <papid> D07-1097 </papid>that obtained the fifth position at conll 2007.</nextsent>
<nextsent>although hallet al  (2007) <papid> D07-1097 </papid>applied the pro jectivization transformation (tp), we will not use it in our baseline because we want to evaluate the effect of multiple techniques over base parser.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3874">
<title id=" W10-3508.xml">helping volunteer translators fostering language resources </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>opening translations.
</prevsent>
<prevsent>63 figure 2: screen shot of qredit
</prevsent>
</prevsection>
<citsent citstr=" P09-4008 ">
there are many translation support tools, suchas google translator toolkit, wikibabel (ku maran et al, 2009), <papid> P09-4008 </papid>bey trans (bey et al, 2008), caitra (koehn, 2009) <papid> P09-4005 </papid>and idiom worldserversystem,2 an online multilingual document management system with translation memory func tions.</citsent>
<aftsection>
<nextsent>the functions that mnh provides are closer to those provided by idiom world server, butmnh provides high-quality bilingual dictionaries and functions for seamless wikipedia and web searches within the integrated translation aid editor qredit.
</nextsent>
<nextsent>it also enables translators to share their translations, which are also used as language resources.
</nextsent>
<nextsent>this section describes set of translation aid tools installed in mnh.
</nextsent>
<nextsent>3.1 qredit.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3875">
<title id=" W10-3508.xml">helping volunteer translators fostering language resources </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>opening translations.
</prevsent>
<prevsent>63 figure 2: screen shot of qredit
</prevsent>
</prevsection>
<citsent citstr=" P09-4005 ">
there are many translation support tools, suchas google translator toolkit, wikibabel (ku maran et al, 2009), <papid> P09-4008 </papid>bey trans (bey et al, 2008), caitra (koehn, 2009) <papid> P09-4005 </papid>and idiom worldserversystem,2 an online multilingual document management system with translation memory func tions.</citsent>
<aftsection>
<nextsent>the functions that mnh provides are closer to those provided by idiom world server, butmnh provides high-quality bilingual dictionaries and functions for seamless wikipedia and web searches within the integrated translation aid editor qredit.
</nextsent>
<nextsent>it also enables translators to share their translations, which are also used as language resources.
</nextsent>
<nextsent>this section describes set of translation aid tools installed in mnh.
</nextsent>
<nextsent>3.1 qredit.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3876">
<title id=" W10-3508.xml">helping volunteer translators fostering language resources </title>
<section> helping volunteer translators.  </section>
<citcontext>
<prevsection>
<prevsent>when user clicks an sl word, its translation candidates are displayed in pop-up window.
</prevsent>
<prevsent>2http://www.idiominc.com/en/ figure 3: screen shot of bilingual concordancer 3.2 bilingual concordancer.
</prevsent>
</prevsection>
<citsent citstr=" P03-1010 ">
the translations published on mnh are used to make parallel corpus by using sentence alignment method (utiyama and isahara, 2003).<papid> P03-1010 </papid></citsent>
<aftsection>
<nextsent>mnh also has parallel texts from the amnesty international japan, democracy now!
</nextsent>
<nextsent>japan, and open source software manuals (ishisaka et al., 2009).
</nextsent>
<nextsent>these parallel texts are searched by using simple bilingual concordancer as shown in figure 3.
</nextsent>
<nextsent>3.3 bilingual term extraction tool.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3877">
<title id=" W10-3508.xml">helping volunteer translators fostering language resources </title>
<section> helping volunteer translators.  </section>
<citcontext>
<prevsection>
<prevsent>these parallel texts are searched by using simple bilingual concordancer as shown in figure 3.
</prevsent>
<prevsent>3.3 bilingual term extraction tool.
</prevsent>
</prevsection>
<citsent citstr=" W06-1703 ">
mnh has bilingual term extraction tool that is composed of translation estimation tool (tonoike et al, 2006) <papid> W06-1703 </papid>and term extraction tool (nakagawa and mori, 2003).</citsent>
<aftsection>
<nextsent>first, we apply the translation estimation toolto extract japanese term candidates and their english translation candidates.
</nextsent>
<nextsent>next, we apply theterm extraction tool to extract english term candidates.
</nextsent>
<nextsent>if these english term candidates are found in the english translation candidates, then,we accept these term candidates as the translations of those japanese term candidates.
</nextsent>
<nextsent>being one stop?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3878">
<title id=" W10-1613.xml">the ter minet project an overview </title>
<section> the ter minet project.  </section>
<citcontext>
<prevsection>
<prevsent>in the second approach, computational terminologists have tried to define, identify and recognize terms looking at pure linguistic proper 11 the glosses and co-text sentences will not be specificied in.
</prevsent>
<prevsent>the ter minet projet.
</prevsent>
</prevsection>
<citsent citstr=" E06-2022 ">
ties, using linguistic filtering techniques aiming to identify specific syntactic term patterns (bernhard, 2006; <papid> E06-2022 </papid>pazienza et al, 2005; cabr?</citsent>
<aftsection>
<nextsent>et al, 2001).
</nextsent>
<nextsent>once ext rated, the candidate terms have be validated.
</nextsent>
<nextsent>two validation estrategies will be considered in the ter minet project.
</nextsent>
<nextsent>the first strategy consists on manually validating by domain experts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3879">
<title id=" W10-1613.xml">the ter minet project an overview </title>
<section> the ter minet project.  </section>
<citcontext>
<prevsection>
<prevsent>the second consists on automatically comparing the list of candidate terms with list of lexical unities extracted from general corpus in bp.
</prevsent>
<prevsent>the automatic acquisition of hyperonym/hyponymy relation from corpus is commonly based on linguistic methods.
</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
these methods look for linguistic clues that indisputably indicate the relation of interest (hearst, 1992).<papid> C92-2082 </papid></citsent>
<aftsection>
<nextsent>the linguistic clues are basically lexico-syntactic patters such as: [np such {np,}*{(or|and)} np] (e.g., works by such authors as herrick, and shakespeare?).
</nextsent>
<nextsent>the hierarchical relations ext rated from corpus are commonly validated by domain experts.
</nextsent>
<nextsent>(b) the linguistic-computational domain in this domain, the overall information selected and organized in the preceding domain is molded into computer-tractable representation; in the case of wordnet-like database, the computer tractable representation is based on the notions of: word form ? orthographic representation of an individual word or string of individual words joined with underscore characters; synset ? set of words built on the basis of the notion of synonymy in context, i.e. word interchangeability in some context; lexical matrix ? associations of sets of word forms and the concepts they lexicalize; relational pointers ? formal representations of the relations between the word forms in syn set and other synsets; synonymy of word forms is implicit by inclusion in the same synset; hyperonymy always relates one synset to another, and is an example of semantic rela tion; hyperonymy, in particular, is represented by reflexive pointers (i.e., if synset contains pointer to another synset, the other synset should contain corresponding reflexive pointer back to the original synset).
</nextsent>
<nextsent>(c) the computational domain in this domain, the computer-tractable representations are assembled by utilities (i.e., computational tool to create and edit lexical knowledge).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3880">
<title id=" W10-0902.xml">building an endtoend text reading system based on a packed representation </title>
<section> taking advantage of the pg.  </section>
<citcontext>
<prevsection>
<prevsent>we are currently constructing fully automated language interpretation system to produce pg representations from english sentences.
</prevsent>
<prevsent>the system will beable to maintain all possible interpretations generated at each step (including parsing, word sense disambiguation (wsd) and semantic relation assignment) and represent them using the pg representation.
</prevsent>
</prevsection>
<citsent citstr=" P05-3019 ">
this is straightforward for wsd and semantic relation assignment because most off-the-shelf software (e.g., (patwardhan et al, 2005) (<papid> P05-3019 </papid>punyakanok et al, 2005)) outputs list of candidate choices and confidence scores for type and relational ambigui ties.</citsent>
<aftsection>
<nextsent>(kim et al, 2010) describes prototype system implemented with these wsd and semantic assignment components.however, ambiguities in parsing are more difficult because it is hard to efficiently identify structural differences among various parses.
</nextsent>
<nextsent>we are currently developing an algorithm (similar to (schiehlen, 1996)) <papid> C96-2153 </papid>which converts parse forest (theambiguity-preserving chart built during pcfg parsing) (tomita, 1986) into the syntactic-level pg representation (as shown in fig.</nextsent>
<nextsent>4).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3881">
<title id=" W10-0902.xml">building an endtoend text reading system based on a packed representation </title>
<section> taking advantage of the pg.  </section>
<citcontext>
<prevsection>
<prevsent>this is straightforward for wsd and semantic relation assignment because most off-the-shelf software (e.g., (patwardhan et al, 2005) (<papid> P05-3019 </papid>punyakanok et al, 2005)) outputs list of candidate choices and confidence scores for type and relational ambigui ties.</prevsent>
<prevsent>(kim et al, 2010) describes prototype system implemented with these wsd and semantic assignment components.however, ambiguities in parsing are more difficult because it is hard to efficiently identify structural differences among various parses.</prevsent>
</prevsection>
<citsent citstr=" C96-2153 ">
we are currently developing an algorithm (similar to (schiehlen, 1996)) <papid> C96-2153 </papid>which converts parse forest (theambiguity-preserving chart built during pcfg parsing) (tomita, 1986) into the syntactic-level pg representation (as shown in fig.</citsent>
<aftsection>
<nextsent>4).
</nextsent>
<nextsent>we plan to implement this algorithm in the stanford parser (klein and manning, 2003) <papid> P03-1054 </papid>and to evaluate it along the following dimensions.</nextsent>
<nextsent>first, we will measure the improvement in parsing accuracy that results from delaying commitment to single best parse.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3882">
<title id=" W10-0902.xml">building an endtoend text reading system based on a packed representation </title>
<section> taking advantage of the pg.  </section>
<citcontext>
<prevsection>
<prevsent>we are currently developing an algorithm (similar to (schiehlen, 1996)) <papid> C96-2153 </papid>which converts parse forest (theambiguity-preserving chart built during pcfg parsing) (tomita, 1986) into the syntactic-level pg representation (as shown in fig.</prevsent>
<prevsent>4).</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
we plan to implement this algorithm in the stanford parser (klein and manning, 2003) <papid> P03-1054 </papid>and to evaluate it along the following dimensions.</citsent>
<aftsection>
<nextsent>first, we will measure the improvement in parsing accuracy that results from delaying commitment to single best parse.
</nextsent>
<nextsent>second, even though the pg representation achieves substantial compression, its size is stillbounded.
</nextsent>
<nextsent>the parser might generate more interpretations than will fit within the bound.
</nextsent>
<nextsent>we plan to handle this problem in the following way.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3883">
<title id=" W10-1002.xml">enhancing authentic web pages for language learners </title>
<section> identify the targeted language pattern..  </section>
<citcontext>
<prevsection>
<prevsent>examples of such clues are prepositions such as after and of, which can only be followed by gerund.
</prevsent>
<prevsent>in our nlp approach to this language pattern, we use constraint grammar rules (karlsson et al, 1995)on top of pos tagging, which allow for straightforward formulation of local disambiguation rules suchas: if an -ing form immediately follows the preposition by, select the gerund reading.?
</prevsent>
</prevsection>
<citsent citstr=" W08-0913 ">
standard pos 3given the nature of the input enhancement using colors, the highlighting in the figure is only visible in color printout.4the issue bears some resemblance to the task of identifying paraphrases (androutsopoulos and malakasiotis, 2009) or classes of learner answers which differ in form but are equivalent in terms of meaning (bailey and meurers, 2008).<papid> W08-0913 </papid></citsent>
<aftsection>
<nextsent>tagsets for english contain single tag for all -ingforms.
</nextsent>
<nextsent>in order to identify gerunds only, we introduce all possible readings for all -ing forms and wrote 101 cg rules to locally disambiguate them.
</nextsent>
<nextsent>the to-infinitives, on the other hand, are relatively easy to identify based on the surface form andre quire almost no disambiguation.for the implementation of the constraint grammar rules, we used the freely available cg3 system.5while simple local disambiguation rules are sufficient for the pattern discussed here, through iterative application of rules, constraint grammar can identify wide range of phenomena without the need to provide full grammatical analysis.the color activity resulting from input enhancement is similar to that for lexical classes described above, but the system here enhances both verb form sand clue phrases.
</nextsent>
<nextsent>figure 3 shows the system highlighting gerunds in orange, infiniti ves in purple, and clue phrases in blue.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3884">
<title id=" W10-1002.xml">enhancing authentic web pages for language learners </title>
<section> identify the targeted language pattern..  </section>
<citcontext>
<prevsection>
<prevsent>3.1 exercise generation.
</prevsent>
<prevsent>exercise generation is widely studied in call research and some of the work relates directly to the input enhancement approach presented in this paper.
</prevsent>
</prevsection>
<citsent citstr=" W04-1703 ">
for instance, antoniadis et al (2004) <papid> W04-1703 </papid>describe the plans of the mirto project to support gap-filling?</citsent>
<aftsection>
<nextsent>and lexical spotting?
</nextsent>
<nextsent>exercises in combination witha corpus database.
</nextsent>
<nextsent>however, mirto seems to fo 10while identifying all instances of pattern indeed is not crucial in this context, representativeness remains relevant tosome degree.
</nextsent>
<nextsent>where only skewed subset of pattern is highlighted, learners may not properly conceptualize the pattern.cus on general architecture supporting instructor determined activity design.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3885">
<title id=" W10-1002.xml">enhancing authentic web pages for language learners </title>
<section> conclusion and outlook.  </section>
<citcontext>
<prevsection>
<prevsent>enhancing of patterns presupposes that the pages contain instances of the pattern.
</prevsent>
<prevsent>the less frequent the pattern, the less likely we are to find enough instances of it in web pages returned by the standard web search engines typically used by learners to find pages of interest to them.
</prevsent>
</prevsection>
<citsent citstr=" W08-0911 ">
the issue is related to research on providing learners with texts at the right level of reading difficulty (petersen, 2007; miltsakaki and troutt, 2008), <papid> W08-0911 </papid>but the focus for us is on ensuring that texts which include instances ofthe specific language pattern targeted by given input enhancement are ranked high in the search re sults.</citsent>
<aftsection>
<nextsent>ott (2009) presents search engine prototype which, in addition to the content-focused document term information and traditional readability measures, supports indexing based on more general notion of text model into which the patterns relevant to input enhancement can be integrated ? an idea we are exploring further (ott and meurers, submitted).
</nextsent>
<nextsent>acknowledgments we benefited from the feedback we received at calico 06, euro call 06, and the icall course13 at esslli 09, where we discussed our work on the python-based werti prototype.
</nextsent>
<nextsent>we would like to thank chris hill and kathy corl for their enthusiasm and encouragement.
</nextsent>
<nextsent>we are grateful to magdalena leshtanska, emma li, iliana simova, maria tchalakova and tatiana vodolazova for their good ideas and werti module contributions in the context of seminar at the university of tubingen in summer 2008.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3886">
<title id=" W10-3205.xml">augmenting a bilingual lexicon with information for word translation disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>because each translation candidate has distinct meaning and property, we must be careful in selecting the appropriate translation candidate that has the same sense as the word inputted.
</prevsent>
<prevsent>this task is often called word translation disambiguation.in this paper, we describe method for adding information for word translation disambiguation into the bilingual lexicon.
</prevsent>
</prevsection>
<citsent citstr=" C02-1058 ">
comparable corpora can be used to determine which word associations suggest which translations of the word (kaji and morimoto, 2002).<papid> C02-1058 </papid></citsent>
<aftsection>
<nextsent>first, we extract word associations in each language corpus and align them by using bilingual dictionary.
</nextsent>
<nextsent>then, we construct word correlation matrix for each word in the source language.
</nextsent>
<nextsent>this correlation matrix works as information for word translation disambiguation.
</nextsent>
<nextsent>we carried out word translation experiments on two settings: english-to-japanese and chi nese-to-japanese.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3887">
<title id=" W10-3205.xml">augmenting a bilingual lexicon with information for word translation disambiguation </title>
<section> constructing word correlation ma-.  </section>
<citcontext>
<prevsection>
<prevsent>in this section, we describe the method for calculating word correlation matrix for each word in the source language.
</prevsent>
<prevsent>the correlation matrix for word consists of its association words and its translation candidates.
</prevsent>
</prevsection>
<citsent citstr=" P95-1050 ">
among the translation candidates, we choose the most acceptable one that is strongly suggested by its association words occurring around f. we use two assumptions for this framework: (i) parallel word associations: translations of words associated with each other in language are also associated with each other in another language 30 (rapp, 1995).<papid> P95-1050 </papid></citsent>
<aftsection>
<nextsent>for example, two english words tank?
</nextsent>
<nextsent>and soldier?
</nextsent>
<nextsent>are associated with each other and their japanese translations ???
</nextsent>
<nextsent>(sensha)?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3888">
<title id=" W10-3205.xml">augmenting a bilingual lexicon with information for word translation disambiguation </title>
<section> constructing word correlation ma-.  </section>
<citcontext>
<prevsection>
<prevsent>(hei shi)?
</prevsent>
<prevsent>are also associated with each other.
</prevsent>
</prevsection>
<citsent citstr=" H93-1052 ">
(ii) one sense per word association: polysemous word exhibits only one sense of word per word association (yarowsky, 1993).<papid> H93-1052 </papid></citsent>
<aftsection>
<nextsent>for example, poly semous word tank?
</nextsent>
<nextsent>exhibits the militaryvehicle?
</nextsent>
<nextsent>sense of word when it is associated with soldier,?
</nextsent>
<nextsent>while it exhibits the container for liquid or gas?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3889">
<title id=" W10-3205.xml">augmenting a bilingual lexicon with information for word translation disambiguation </title>
<section> constructing word correlation ma-.  </section>
<citcontext>
<prevsection>
<prevsent>let n1 and n2 be the occurrence frequencies of and respectively, and let be the frequency that and co-occur between content words.
</prevsent>
<prevsent>the parameter is window size that adjusts the range of co-occurrences.let and be the sum of occur rences/co-occurrences of all words/word pairs, respectively.
</prevsent>
</prevsection>
<citsent citstr=" J93-1007 ">
the frequencies are summarized in table 1.the word association scores (, ) are defined as follows:  dice coefficient (smadja, 1993) <papid> J93-1007 </papid>dice(, ) = 2 +  (1)  jaccard coefficient (smadja et al, 1996) <papid> J96-1001 </papid>jaccard(, ) =  +   (2)  pointwise mutual information (pmi) (church and hanks, 1990) <papid> J90-1003 </papid>pmi(, ) = log / (  )(   ) (3)  log-likelihood ratio (llr) (dunning, 1993) <papid> J93-1003 </papid>llr(, ) = 2logl(, , ) + logl(  ,  , ) logl(, ,  ) logl(  ,  , ); (4) logl(, , ) =  log  + ( ) log(1 ), (5)  =  ,  =    ,  =   (6)  students t-score (tscore) (church et al, 1991) tscore(, ) =     (7) we calculate association scores for all pairs of words when their occurrence frequencies are not less than threshold tf and when their occur not occur total occur n2 ? n2 not occur n1 ? m ? n1 ? n2 + n ? n2 total n1 ? n1 table 1.</citsent>
<aftsection>
<nextsent>contingency matrix of occurrence frequencies.
</nextsent>
<nextsent>figure 2.
</nextsent>
<nextsent>algorithm for calculating correlation matrices.
</nextsent>
<nextsent> ((), )  (, ()) max   ((), )   (, ())  (, ) = ! 1 ( : (, ) # $, (, ) # %) 0 (otherwise) &amp;  algorithm 1: input: f: an input word f?(1), ?, f?(i): associated words of e(1), ?, e(j): translation candidates of nr: number of iterations bilingual lexicon word association scores  for both languages output:cf = [cf (f?(i), e(j))]: correlation matrix for 1: if  *(), () - 0 then 2:  *(), () . 345 6(7),8(9)   346(7),8()  3: else 4:  *(), () . 0 5: end 6:  . 0 7: while   nr 8:  .  + 1 9:  *(), () . ((), ) 10: end (?: = ?{**|(,**)#@4,(*(7),**)#@4}) 32 threshold tc.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3890">
<title id=" W10-3205.xml">augmenting a bilingual lexicon with information for word translation disambiguation </title>
<section> constructing word correlation ma-.  </section>
<citcontext>
<prevsection>
<prevsent>let n1 and n2 be the occurrence frequencies of and respectively, and let be the frequency that and co-occur between content words.
</prevsent>
<prevsent>the parameter is window size that adjusts the range of co-occurrences.let and be the sum of occur rences/co-occurrences of all words/word pairs, respectively.
</prevsent>
</prevsection>
<citsent citstr=" J96-1001 ">
the frequencies are summarized in table 1.the word association scores (, ) are defined as follows:  dice coefficient (smadja, 1993) <papid> J93-1007 </papid>dice(, ) = 2 +  (1)  jaccard coefficient (smadja et al, 1996) <papid> J96-1001 </papid>jaccard(, ) =  +   (2)  pointwise mutual information (pmi) (church and hanks, 1990) <papid> J90-1003 </papid>pmi(, ) = log / (  )(   ) (3)  log-likelihood ratio (llr) (dunning, 1993) <papid> J93-1003 </papid>llr(, ) = 2logl(, , ) + logl(  ,  , ) logl(, ,  ) logl(  ,  , ); (4) logl(, , ) =  log  + ( ) log(1 ), (5)  =  ,  =    ,  =   (6)  students t-score (tscore) (church et al, 1991) tscore(, ) =     (7) we calculate association scores for all pairs of words when their occurrence frequencies are not less than threshold tf and when their occur not occur total occur n2 ? n2 not occur n1 ? m ? n1 ? n2 + n ? n2 total n1 ? n1 table 1.</citsent>
<aftsection>
<nextsent>contingency matrix of occurrence frequencies.
</nextsent>
<nextsent>figure 2.
</nextsent>
<nextsent>algorithm for calculating correlation matrices.
</nextsent>
<nextsent> ((), )  (, ()) max   ((), )   (, ())  (, ) = ! 1 ( : (, ) # $, (, ) # %) 0 (otherwise) &amp;  algorithm 1: input: f: an input word f?(1), ?, f?(i): associated words of e(1), ?, e(j): translation candidates of nr: number of iterations bilingual lexicon word association scores  for both languages output:cf = [cf (f?(i), e(j))]: correlation matrix for 1: if  *(), () - 0 then 2:  *(), () . 345 6(7),8(9)   346(7),8()  3: else 4:  *(), () . 0 5: end 6:  . 0 7: while   nr 8:  .  + 1 9:  *(), () . ((), ) 10: end (?: = ?{**|(,**)#@4,(*(7),**)#@4}) 32 threshold tc.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3891">
<title id=" W10-3205.xml">augmenting a bilingual lexicon with information for word translation disambiguation </title>
<section> constructing word correlation ma-.  </section>
<citcontext>
<prevsection>
<prevsent>let n1 and n2 be the occurrence frequencies of and respectively, and let be the frequency that and co-occur between content words.
</prevsent>
<prevsent>the parameter is window size that adjusts the range of co-occurrences.let and be the sum of occur rences/co-occurrences of all words/word pairs, respectively.
</prevsent>
</prevsection>
<citsent citstr=" J90-1003 ">
the frequencies are summarized in table 1.the word association scores (, ) are defined as follows:  dice coefficient (smadja, 1993) <papid> J93-1007 </papid>dice(, ) = 2 +  (1)  jaccard coefficient (smadja et al, 1996) <papid> J96-1001 </papid>jaccard(, ) =  +   (2)  pointwise mutual information (pmi) (church and hanks, 1990) <papid> J90-1003 </papid>pmi(, ) = log / (  )(   ) (3)  log-likelihood ratio (llr) (dunning, 1993) <papid> J93-1003 </papid>llr(, ) = 2logl(, , ) + logl(  ,  , ) logl(, ,  ) logl(  ,  , ); (4) logl(, , ) =  log  + ( ) log(1 ), (5)  =  ,  =    ,  =   (6)  students t-score (tscore) (church et al, 1991) tscore(, ) =     (7) we calculate association scores for all pairs of words when their occurrence frequencies are not less than threshold tf and when their occur not occur total occur n2 ? n2 not occur n1 ? m ? n1 ? n2 + n ? n2 total n1 ? n1 table 1.</citsent>
<aftsection>
<nextsent>contingency matrix of occurrence frequencies.
</nextsent>
<nextsent>figure 2.
</nextsent>
<nextsent>algorithm for calculating correlation matrices.
</nextsent>
<nextsent> ((), )  (, ()) max   ((), )   (, ())  (, ) = ! 1 ( : (, ) # $, (, ) # %) 0 (otherwise) &amp;  algorithm 1: input: f: an input word f?(1), ?, f?(i): associated words of e(1), ?, e(j): translation candidates of nr: number of iterations bilingual lexicon word association scores  for both languages output:cf = [cf (f?(i), e(j))]: correlation matrix for 1: if  *(), () - 0 then 2:  *(), () . 345 6(7),8(9)   346(7),8()  3: else 4:  *(), () . 0 5: end 6:  . 0 7: while   nr 8:  .  + 1 9:  *(), () . ((), ) 10: end (?: = ?{**|(,**)#@4,(*(7),**)#@4}) 32 threshold tc.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3892">
<title id=" W10-3205.xml">augmenting a bilingual lexicon with information for word translation disambiguation </title>
<section> constructing word correlation ma-.  </section>
<citcontext>
<prevsection>
<prevsent>let n1 and n2 be the occurrence frequencies of and respectively, and let be the frequency that and co-occur between content words.
</prevsent>
<prevsent>the parameter is window size that adjusts the range of co-occurrences.let and be the sum of occur rences/co-occurrences of all words/word pairs, respectively.
</prevsent>
</prevsection>
<citsent citstr=" J93-1003 ">
the frequencies are summarized in table 1.the word association scores (, ) are defined as follows:  dice coefficient (smadja, 1993) <papid> J93-1007 </papid>dice(, ) = 2 +  (1)  jaccard coefficient (smadja et al, 1996) <papid> J96-1001 </papid>jaccard(, ) =  +   (2)  pointwise mutual information (pmi) (church and hanks, 1990) <papid> J90-1003 </papid>pmi(, ) = log / (  )(   ) (3)  log-likelihood ratio (llr) (dunning, 1993) <papid> J93-1003 </papid>llr(, ) = 2logl(, , ) + logl(  ,  , ) logl(, ,  ) logl(  ,  , ); (4) logl(, , ) =  log  + ( ) log(1 ), (5)  =  ,  =    ,  =   (6)  students t-score (tscore) (church et al, 1991) tscore(, ) =     (7) we calculate association scores for all pairs of words when their occurrence frequencies are not less than threshold tf and when their occur not occur total occur n2 ? n2 not occur n1 ? m ? n1 ? n2 + n ? n2 total n1 ? n1 table 1.</citsent>
<aftsection>
<nextsent>contingency matrix of occurrence frequencies.
</nextsent>
<nextsent>figure 2.
</nextsent>
<nextsent>algorithm for calculating correlation matrices.
</nextsent>
<nextsent> ((), )  (, ()) max   ((), )   (, ())  (, ) = ! 1 ( : (, ) # $, (, ) # %) 0 (otherwise) &amp;  algorithm 1: input: f: an input word f?(1), ?, f?(i): associated words of e(1), ?, e(j): translation candidates of nr: number of iterations bilingual lexicon word association scores  for both languages output:cf = [cf (f?(i), e(j))]: correlation matrix for 1: if  *(), () - 0 then 2:  *(), () . 345 6(7),8(9)   346(7),8()  3: else 4:  *(), () . 0 5: end 6:  . 0 7: while   nr 8:  .  + 1 9:  *(), () . ((), ) 10: end (?: = ?{**|(,**)#@4,(*(7),**)#@4}) 32 threshold tc.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3893">
<title id=" W10-3205.xml">augmenting a bilingual lexicon with information for word translation disambiguation </title>
<section> experiment.  </section>
<citcontext>
<prevsection>
<prevsent>this merged dictionary contains about two million term pairs.
</prevsent>
<prevsent>while these chinese-japanese term pairs include wrong translations, it was not serious problem in our experiments because wrong translations were excluded in the procedure of our method.
</prevsent>
</prevsection>
<citsent citstr=" P09-1058 ">
we applied morphological analysis and part-of-speech tagging by using tree tagger (schmid, 1994) for english, juman for japanese, and mma (kruengkrai et al, 2009) <papid> P09-1058 </papid>for chinese, respectively.</citsent>
<aftsection>
<nextsent>in the test corpus, we manually annotated reference translations for each target word.
</nextsent>
<nextsent>2 experiment a: the parameters we used were as follows: tf = 100 (japanese), tf = 1000 (english), tc = 4, = 30, = 30.
</nextsent>
<nextsent>experiment b1/b2: tf = 100, tc = 4, = 10, = 25.some of the parameters were empirically adjusted.
</nextsent>
<nextsent>in the experiments, the matrices could be obtained for 9103 english words (a), 674 chinese words (b1) and 1258 chinese words (b2), respectively.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3894">
<title id=" W10-3205.xml">augmenting a bilingual lexicon with information for word translation disambiguation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the correlation between associated words and translation candidates also needs to be re-examined.
</prevsent>
<prevsent>similarly, we will handle verbs as associated words to the input nouns by using syntactic co-occurrence.
</prevsent>
</prevsection>
<citsent citstr=" J90-2002 ">
statistical machine translation (brown et al, 1990) <papid> J90-2002 </papid>automatically acquires knowledge for word translation disambiguation from parallel corpora.</citsent>
<aftsection>
<nextsent>word translation disambiguation is based on probabilities calculated from the word alignment, phrase pair extraction, and the language model.
</nextsent>
<nextsent>however, much broad con text/domain information is not considered.carpuat and wu (2007) proposed con text-dependent phrasal translation lexicons by introducing context-dependent features into statistical machine translation.
</nextsent>
<nextsent>unsupervised methods using dictionaries and corpora were proposed for monolingual wsd (ide and veronis, 1998).<papid> J98-1001 </papid></nextsent>
<nextsent>they used grammatical information including parts-of-speech, syntactically related words, and co-occurring words as the clues for the wsd.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3895">
<title id=" W10-3205.xml">augmenting a bilingual lexicon with information for word translation disambiguation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>word translation disambiguation is based on probabilities calculated from the word alignment, phrase pair extraction, and the language model.
</prevsent>
<prevsent>however, much broad con text/domain information is not considered.carpuat and wu (2007) proposed con text-dependent phrasal translation lexicons by introducing context-dependent features into statistical machine translation.
</prevsent>
</prevsection>
<citsent citstr=" J98-1001 ">
unsupervised methods using dictionaries and corpora were proposed for monolingual wsd (ide and veronis, 1998).<papid> J98-1001 </papid></citsent>
<aftsection>
<nextsent>they used grammatical information including parts-of-speech, syntactically related words, and co-occurring words as the clues for the wsd.
</nextsent>
<nextsent>our method uses part of the clues for bilingual wsd and word translation disambiguation.
</nextsent>
<nextsent>li and li (2002) <papid> P02-1044 </papid>constructed classifier for word translation disambiguation by using bilingual dictionary with bootstrapping techniques.</nextsent>
<nextsent>we also conducted recursive calculation by dealing with the bilingual dictionary as the seeds of the iteration.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3896">
<title id=" W10-3205.xml">augmenting a bilingual lexicon with information for word translation disambiguation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>they used grammatical information including parts-of-speech, syntactically related words, and co-occurring words as the clues for the wsd.
</prevsent>
<prevsent>our method uses part of the clues for bilingual wsd and word translation disambiguation.
</prevsent>
</prevsection>
<citsent citstr=" P02-1044 ">
li and li (2002) <papid> P02-1044 </papid>constructed classifier for word translation disambiguation by using bilingual dictionary with bootstrapping techniques.</citsent>
<aftsection>
<nextsent>we also conducted recursive calculation by dealing with the bilingual dictionary as the seeds of the iteration.
</nextsent>
<nextsent>vickrey et al (2005) <papid> H05-1097 </papid>introduced context as feature for statistical mt system and they generated word-level translations.</nextsent>
<nextsent>how to introduce the word-level translation disambiguation into sentence-level translation is considerable problem.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3897">
<title id=" W10-3205.xml">augmenting a bilingual lexicon with information for word translation disambiguation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>li and li (2002) <papid> P02-1044 </papid>constructed classifier for word translation disambiguation by using bilingual dictionary with bootstrapping techniques.</prevsent>
<prevsent>we also conducted recursive calculation by dealing with the bilingual dictionary as the seeds of the iteration.</prevsent>
</prevsection>
<citsent citstr=" H05-1097 ">
vickrey et al (2005) <papid> H05-1097 </papid>introduced context as feature for statistical mt system and they generated word-level translations.</citsent>
<aftsection>
<nextsent>how to introduce the word-level translation disambiguation into sentence-level translation is considerable problem.
</nextsent>
<nextsent>36
</nextsent>
<nextsent>in this paper, we described method for adding information for word translation disambiguation into the bilingual lexicon, by considering the associated words that co-occur with the input word.
</nextsent>
<nextsent>we based our method on the following two assumptions: parallel word associations?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3898">
<title id=" W10-0730.xml">measuring transit ivity using untrained annotators </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>volition.
</prevsent>
<prevsent>did the $subj make conscious choice to $verbthe answers were on scale of 0 to 4 (higher numbers meant the sentence evinced more of the property in2our goal of language independence and the unreliable correspondence between syntax and semantic roles precludes automatic labeling of the subjects and objects.
</prevsent>
</prevsection>
<citsent citstr=" N09-1057 ">
3these questions were developed using greene and resniks (2009) <papid> N09-1057 </papid>surveys as foundation.</citsent>
<aftsection>
<nextsent>question), and each point in the scale had description to anchor raters and to ensure consistent results.
</nextsent>
<nextsent>2.3 rewards.
</nextsent>
<nextsent>table 2 summarizes the rewards for the tasks used in these experiments.
</nextsent>
<nextsent>rewards were set at the minimal rate that could attract sufficient interest from users.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3899">
<title id=" W10-0730.xml">measuring transit ivity using untrained annotators </title>
<section> results and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>we extracted three sets of features from the sen tences: lexical features, syntactic features, and features derived from wordnet (miller, 1990).
</prevsent>
<prevsent>lexical features feature was created for each wordin sentence after being stemmed using the porter stem mer (porter, 1980).
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
syntactic features we parsed each sentence using the stanford parser (klein and manning, 2003) <papid> P03-1054 </papid>and used heuristics to identify cases where the main verb is transitive, where the subject is nominal ization (e.g. run ning?), or whether the sentence is passive.</citsent>
<aftsection>
<nextsent>if any of these constructions appear in the sentence, we generate corresponding feature.
</nextsent>
<nextsent>these represent features identified by greene and resnik (2009).<papid> N09-1057 </papid></nextsent>
<nextsent>wordnet features for each word in the sentence, we extracted all the possible senses for each word.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3901">
<title id=" W10-2910.xml">syntactic and semantic structure for opinion expression detection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>examples (1) and (2) show two sentences from the mpqa corpus where dses and eses have been manually annotated.
</prevsent>
<prevsent>(1) for instance, he [denounced]dse as [human rights violation]ese the banning and seizure of satellite dishes in iran.
</prevsent>
</prevsection>
<citsent citstr=" W06-1651 ">
(2) this [is viewed]dse as the [mainimpediment]ese to the establishment of political order in the country . the task of marking up these expressions has usually been approached using straightforward sequence labeling techniques using simple features in small contextual window (choi et al, 2006; <papid> W06-1651 </papid>breck et al, 2007).</citsent>
<aftsection>
<nextsent>however, due to the simplicity of the feature sets, this approach fails to take into account the fact that the semantic and pragmatic interpretation of sentences is not only determined by words but also by syntactic and shallow-semantic relations.
</nextsent>
<nextsent>crucially, taking grammatical relations into account allows us to model how expressions interact in various ways that influence their interpretation as subjective or not.
</nextsent>
<nextsent>consider, for instance, the word said in examples (3) and (4) below, where the interpretation as dse or an ose is influenced by the subjective content of the enclosed statement.
</nextsent>
<nextsent>67 (3) we will identify the [culprits]ese of these clashes and [punish]ese them,?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3904">
<title id=" W10-2910.xml">syntactic and semantic structure for opinion expression detection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(4) on monday, 80 libyan soldiers disembarked from an antonov transport plane carrying military equipment, an african diplomat [said]ose . in this paper, we demonstrate how syntactic and semantic structural information can be usedto improve opinion detection.
</prevsent>
<prevsent>while this feature model makes it impossible to use the standard sequence labeling method, we show that witha simple strategy based on reranking, incorporating structural features results insignificant improvement.
</prevsent>
</prevsection>
<citsent citstr=" W03-0402 ">
we investigate two different reranking strategies: the preference kernel approach (shenand joshi, 2003) <papid> W03-0402 </papid>and an approach based on structure learning (collins, 2002).<papid> W02-1001 </papid></citsent>
<aftsection>
<nextsent>in an evaluation on the mpqa corpus, the best system we evaluated, structure learning-based reranker using the passive aggressive learning algorithm, achieved 10-point absolute improvement in soft recall, and 5-point improvement in f-measure, over the baseline sequence labeler .
</nextsent>
<nextsent>most approaches to analysing the sentiment of natural-language text have relied fundamentally on purely lexical information (see (pang et al, 2002; <papid> W02-1011 </papid>yu and hatzivassiloglou, 2003), <papid> W03-1017 </papid>inter alia)or low-level grammatical information such as part of-speech tags and functional words (wiebe et al, 1999).<papid> P99-1032 </papid></nextsent>
<nextsent>this is in line with the general consensus in the information retrieval community that very little can be gained by complex linguistic processing for tasks such as text categorization and search (moschitti and basili, 2004).however, it has been suggested that subjectivity analysis is inherently more subtle than categorization and that structural linguistic information should therefore be given more attention in this context.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3905">
<title id=" W10-2910.xml">syntactic and semantic structure for opinion expression detection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(4) on monday, 80 libyan soldiers disembarked from an antonov transport plane carrying military equipment, an african diplomat [said]ose . in this paper, we demonstrate how syntactic and semantic structural information can be usedto improve opinion detection.
</prevsent>
<prevsent>while this feature model makes it impossible to use the standard sequence labeling method, we show that witha simple strategy based on reranking, incorporating structural features results insignificant improvement.
</prevsent>
</prevsection>
<citsent citstr=" W02-1001 ">
we investigate two different reranking strategies: the preference kernel approach (shenand joshi, 2003) <papid> W03-0402 </papid>and an approach based on structure learning (collins, 2002).<papid> W02-1001 </papid></citsent>
<aftsection>
<nextsent>in an evaluation on the mpqa corpus, the best system we evaluated, structure learning-based reranker using the passive aggressive learning algorithm, achieved 10-point absolute improvement in soft recall, and 5-point improvement in f-measure, over the baseline sequence labeler .
</nextsent>
<nextsent>most approaches to analysing the sentiment of natural-language text have relied fundamentally on purely lexical information (see (pang et al, 2002; <papid> W02-1011 </papid>yu and hatzivassiloglou, 2003), <papid> W03-1017 </papid>inter alia)or low-level grammatical information such as part of-speech tags and functional words (wiebe et al, 1999).<papid> P99-1032 </papid></nextsent>
<nextsent>this is in line with the general consensus in the information retrieval community that very little can be gained by complex linguistic processing for tasks such as text categorization and search (moschitti and basili, 2004).however, it has been suggested that subjectivity analysis is inherently more subtle than categorization and that structural linguistic information should therefore be given more attention in this context.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3906">
<title id=" W10-2910.xml">syntactic and semantic structure for opinion expression detection </title>
<section> motivation and related work.  </section>
<citcontext>
<prevsection>
<prevsent>we investigate two different reranking strategies: the preference kernel approach (shenand joshi, 2003) <papid> W03-0402 </papid>and an approach based on structure learning (collins, 2002).<papid> W02-1001 </papid></prevsent>
<prevsent>in an evaluation on the mpqa corpus, the best system we evaluated, structure learning-based reranker using the passive aggressive learning algorithm, achieved 10-point absolute improvement in soft recall, and 5-point improvement in f-measure, over the baseline sequence labeler .</prevsent>
</prevsection>
<citsent citstr=" W02-1011 ">
most approaches to analysing the sentiment of natural-language text have relied fundamentally on purely lexical information (see (pang et al, 2002; <papid> W02-1011 </papid>yu and hatzivassiloglou, 2003), <papid> W03-1017 </papid>inter alia)or low-level grammatical information such as part of-speech tags and functional words (wiebe et al, 1999).<papid> P99-1032 </papid></citsent>
<aftsection>
<nextsent>this is in line with the general consensus in the information retrieval community that very little can be gained by complex linguistic processing for tasks such as text categorization and search (moschitti and basili, 2004).however, it has been suggested that subjectivity analysis is inherently more subtle than categorization and that structural linguistic information should therefore be given more attention in this context.
</nextsent>
<nextsent>for instance, karlgren et al (2010) argued from construction grammar viewpoint (croft, 2005) that grammatical constructions notonly connect words, but can also be viewed as lexical items in their own right.
</nextsent>
<nextsent>starting from this intuition, they showed that incorporating construction items into bag-of-words feature representation resulted in improved results on number ofcoarse-grained opinion analysis tasks.
</nextsent>
<nextsent>these constructional features were domain-independent and were manually extracted from dependency parsetrees.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3907">
<title id=" W10-2910.xml">syntactic and semantic structure for opinion expression detection </title>
<section> motivation and related work.  </section>
<citcontext>
<prevsection>
<prevsent>we investigate two different reranking strategies: the preference kernel approach (shenand joshi, 2003) <papid> W03-0402 </papid>and an approach based on structure learning (collins, 2002).<papid> W02-1001 </papid></prevsent>
<prevsent>in an evaluation on the mpqa corpus, the best system we evaluated, structure learning-based reranker using the passive aggressive learning algorithm, achieved 10-point absolute improvement in soft recall, and 5-point improvement in f-measure, over the baseline sequence labeler .</prevsent>
</prevsection>
<citsent citstr=" W03-1017 ">
most approaches to analysing the sentiment of natural-language text have relied fundamentally on purely lexical information (see (pang et al, 2002; <papid> W02-1011 </papid>yu and hatzivassiloglou, 2003), <papid> W03-1017 </papid>inter alia)or low-level grammatical information such as part of-speech tags and functional words (wiebe et al, 1999).<papid> P99-1032 </papid></citsent>
<aftsection>
<nextsent>this is in line with the general consensus in the information retrieval community that very little can be gained by complex linguistic processing for tasks such as text categorization and search (moschitti and basili, 2004).however, it has been suggested that subjectivity analysis is inherently more subtle than categorization and that structural linguistic information should therefore be given more attention in this context.
</nextsent>
<nextsent>for instance, karlgren et al (2010) argued from construction grammar viewpoint (croft, 2005) that grammatical constructions notonly connect words, but can also be viewed as lexical items in their own right.
</nextsent>
<nextsent>starting from this intuition, they showed that incorporating construction items into bag-of-words feature representation resulted in improved results on number ofcoarse-grained opinion analysis tasks.
</nextsent>
<nextsent>these constructional features were domain-independent and were manually extracted from dependency parsetrees.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3908">
<title id=" W10-2910.xml">syntactic and semantic structure for opinion expression detection </title>
<section> motivation and related work.  </section>
<citcontext>
<prevsection>
<prevsent>we investigate two different reranking strategies: the preference kernel approach (shenand joshi, 2003) <papid> W03-0402 </papid>and an approach based on structure learning (collins, 2002).<papid> W02-1001 </papid></prevsent>
<prevsent>in an evaluation on the mpqa corpus, the best system we evaluated, structure learning-based reranker using the passive aggressive learning algorithm, achieved 10-point absolute improvement in soft recall, and 5-point improvement in f-measure, over the baseline sequence labeler .</prevsent>
</prevsection>
<citsent citstr=" P99-1032 ">
most approaches to analysing the sentiment of natural-language text have relied fundamentally on purely lexical information (see (pang et al, 2002; <papid> W02-1011 </papid>yu and hatzivassiloglou, 2003), <papid> W03-1017 </papid>inter alia)or low-level grammatical information such as part of-speech tags and functional words (wiebe et al, 1999).<papid> P99-1032 </papid></citsent>
<aftsection>
<nextsent>this is in line with the general consensus in the information retrieval community that very little can be gained by complex linguistic processing for tasks such as text categorization and search (moschitti and basili, 2004).however, it has been suggested that subjectivity analysis is inherently more subtle than categorization and that structural linguistic information should therefore be given more attention in this context.
</nextsent>
<nextsent>for instance, karlgren et al (2010) argued from construction grammar viewpoint (croft, 2005) that grammatical constructions notonly connect words, but can also be viewed as lexical items in their own right.
</nextsent>
<nextsent>starting from this intuition, they showed that incorporating construction items into bag-of-words feature representation resulted in improved results on number ofcoarse-grained opinion analysis tasks.
</nextsent>
<nextsent>these constructional features were domain-independent and were manually extracted from dependency parsetrees.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3909">
<title id=" W10-2910.xml">syntactic and semantic structure for opinion expression detection </title>
<section> motivation and related work.  </section>
<citcontext>
<prevsection>
<prevsent>they found that the most prominent constructional feature for subjectivity analysis was the tense shift construction.
</prevsent>
<prevsent>while the position by karlgren et al (2010) ? that constructional features signal opinion ? originates from particular theoretical framework and may be controversial, syntactic and shallow semantic relations have repeatedly proven useful for subtasks of subjectivity analysis that are inherently relational, above all for determining the holder or topic of given opinion.
</prevsent>
</prevsection>
<citsent citstr=" D07-1114 ">
works using syntactic features to extract topics and holders of opinions are numerous (bethard et al, 2005; kobayashi et al, 2007; <papid> D07-1114 </papid>joshi and penstein-rose?, 2009; wu et al, 2009).<papid> D09-1159 </papid></citsent>
<aftsection>
<nextsent>semantic role analysis has also proven useful: kim and hovy (2006) <papid> W06-0301 </papid>useda framenet-based semantic role labeler to determine holder and topic of opinions.</nextsent>
<nextsent>similarly, choi et al (2006) <papid> W06-1651 </papid>successfully used propbank-basedsemantic role labeler for opinion holder extraction, and wiegand and klakow (2010) recently applied tree kernel learning methods on combination of syntactic and semantic role trees for the same task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3910">
<title id=" W10-2910.xml">syntactic and semantic structure for opinion expression detection </title>
<section> motivation and related work.  </section>
<citcontext>
<prevsection>
<prevsent>they found that the most prominent constructional feature for subjectivity analysis was the tense shift construction.
</prevsent>
<prevsent>while the position by karlgren et al (2010) ? that constructional features signal opinion ? originates from particular theoretical framework and may be controversial, syntactic and shallow semantic relations have repeatedly proven useful for subtasks of subjectivity analysis that are inherently relational, above all for determining the holder or topic of given opinion.
</prevsent>
</prevsection>
<citsent citstr=" D09-1159 ">
works using syntactic features to extract topics and holders of opinions are numerous (bethard et al, 2005; kobayashi et al, 2007; <papid> D07-1114 </papid>joshi and penstein-rose?, 2009; wu et al, 2009).<papid> D09-1159 </papid></citsent>
<aftsection>
<nextsent>semantic role analysis has also proven useful: kim and hovy (2006) <papid> W06-0301 </papid>useda framenet-based semantic role labeler to determine holder and topic of opinions.</nextsent>
<nextsent>similarly, choi et al (2006) <papid> W06-1651 </papid>successfully used propbank-basedsemantic role labeler for opinion holder extraction, and wiegand and klakow (2010) recently applied tree kernel learning methods on combination of syntactic and semantic role trees for the same task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3911">
<title id=" W10-2910.xml">syntactic and semantic structure for opinion expression detection </title>
<section> motivation and related work.  </section>
<citcontext>
<prevsection>
<prevsent>while the position by karlgren et al (2010) ? that constructional features signal opinion ? originates from particular theoretical framework and may be controversial, syntactic and shallow semantic relations have repeatedly proven useful for subtasks of subjectivity analysis that are inherently relational, above all for determining the holder or topic of given opinion.
</prevsent>
<prevsent>works using syntactic features to extract topics and holders of opinions are numerous (bethard et al, 2005; kobayashi et al, 2007; <papid> D07-1114 </papid>joshi and penstein-rose?, 2009; wu et al, 2009).<papid> D09-1159 </papid></prevsent>
</prevsection>
<citsent citstr=" W06-0301 ">
semantic role analysis has also proven useful: kim and hovy (2006) <papid> W06-0301 </papid>useda framenet-based semantic role labeler to determine holder and topic of opinions.</citsent>
<aftsection>
<nextsent>similarly, choi et al (2006) <papid> W06-1651 </papid>successfully used propbank-basedsemantic role labeler for opinion holder extraction, and wiegand and klakow (2010) recently applied tree kernel learning methods on combination of syntactic and semantic role trees for the same task.</nextsent>
<nextsent>ruppenhofer et al (2008) <papid> L08-1087 </papid>argued that semantic role techniques are useful but not completely sufficient for holder and topic identification, and that other linguistic phenomena must be studied as well.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3913">
<title id=" W10-2910.xml">syntactic and semantic structure for opinion expression detection </title>
<section> motivation and related work.  </section>
<citcontext>
<prevsection>
<prevsent>semantic role analysis has also proven useful: kim and hovy (2006) <papid> W06-0301 </papid>useda framenet-based semantic role labeler to determine holder and topic of opinions.</prevsent>
<prevsent>similarly, choi et al (2006) <papid> W06-1651 </papid>successfully used propbank-basedsemantic role labeler for opinion holder extraction, and wiegand and klakow (2010) recently applied tree kernel learning methods on combination of syntactic and semantic role trees for the same task.</prevsent>
</prevsection>
<citsent citstr=" L08-1087 ">
ruppenhofer et al (2008) <papid> L08-1087 </papid>argued that semantic role techniques are useful but not completely sufficient for holder and topic identification, and that other linguistic phenomena must be studied as well.</citsent>
<aftsection>
<nextsent>one such linguistic pheonomenonis the discourse structure, which has recently attracted some attention in the opinion analysis community (somasundaran et al, 2009).<papid> D09-1018 </papid></nextsent>
<nextsent>syntactic and semantic structures previous systems for opinionated expression markup have typically used simple feature sets which have allowed the use of efficient off-the shelf sequence labeling methods based on viterbi search (choi et al, 2006; <papid> W06-1651 </papid>breck et al, 2007).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3914">
<title id=" W10-2910.xml">syntactic and semantic structure for opinion expression detection </title>
<section> motivation and related work.  </section>
<citcontext>
<prevsection>
<prevsent>similarly, choi et al (2006) <papid> W06-1651 </papid>successfully used propbank-basedsemantic role labeler for opinion holder extraction, and wiegand and klakow (2010) recently applied tree kernel learning methods on combination of syntactic and semantic role trees for the same task.</prevsent>
<prevsent>ruppenhofer et al (2008) <papid> L08-1087 </papid>argued that semantic role techniques are useful but not completely sufficient for holder and topic identification, and that other linguistic phenomena must be studied as well.</prevsent>
</prevsection>
<citsent citstr=" D09-1018 ">
one such linguistic pheonomenonis the discourse structure, which has recently attracted some attention in the opinion analysis community (somasundaran et al, 2009).<papid> D09-1018 </papid></citsent>
<aftsection>
<nextsent>syntactic and semantic structures previous systems for opinionated expression markup have typically used simple feature sets which have allowed the use of efficient off-the shelf sequence labeling methods based on viterbi search (choi et al, 2006; <papid> W06-1651 </papid>breck et al, 2007).</nextsent>
<nextsent>this is not possible in our case since we would like to extract structural, relational features that involve pairs of opinionated expressions and may apply over an arbitrarily long distance in the sentence.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3918">
<title id=" W10-2910.xml">syntactic and semantic structure for opinion expression detection </title>
<section> opinion expression detection using.  </section>
<citcontext>
<prevsection>
<prevsent>this is not possible in our case since we would like to extract structural, relational features that involve pairs of opinionated expressions and may apply over an arbitrarily long distance in the sentence.
</prevsent>
<prevsent>while it is possible that search algorithms for exact or approximate inference can be construc tured for the arg max problem in this model, we sidestepped this issue by using reranking decomposition of the problem: we first apply standard viterbi-based sequence labeler using no structural features and generate small candidate set of size k. then, second and more complex model picks 68 the top candidate from this set without having to search the whole candidate space.the advantages of reranking approach compared to more complex approaches requiring advanced search techniques are mainly simplicity and efficiency: this approach is conceptually simple and fairly easy to implement provided that kbest output can be generated efficiently, and features can be arbitrarily complex ? we dont haveto think about how the features affect the algorith mic complexity of the inference step.
</prevsent>
</prevsection>
<citsent citstr=" P08-1067 ">
a common objection to reranking is that the candidate set maynot be diverse enough to allow for much improvement unless it is very large; the candidates may be trivial variations that are all very similar to the top-scoring candidate (huang, 2008).<papid> P08-1067 </papid></citsent>
<aftsection>
<nextsent>3.1 syntactic and semantic structures.
</nextsent>
<nextsent>we used the syntactic semantic parser by johansson and nugues (2008<papid> W08-2123 </papid>a) to annnotate the sentences with dependency syntax (melcuk, 1988) and shallow semantic structures in the propbank (palmer et al, 2005) <papid> J05-1004 </papid>and nombank (meyers et al., 2004) frameworks.</nextsent>
<nextsent>figure 1 shows an example of the annotation: the sentence they called him liar, where called is dse and liar is an ese, has been annotated with dependency syntax (above the text) and propbank-based semantic role structure (below the text).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3919">
<title id=" W10-2910.xml">syntactic and semantic structure for opinion expression detection </title>
<section> opinion expression detection using.  </section>
<citcontext>
<prevsection>
<prevsent>a common objection to reranking is that the candidate set maynot be diverse enough to allow for much improvement unless it is very large; the candidates may be trivial variations that are all very similar to the top-scoring candidate (huang, 2008).<papid> P08-1067 </papid></prevsent>
<prevsent>3.1 syntactic and semantic structures.</prevsent>
</prevsection>
<citsent citstr=" W08-2123 ">
we used the syntactic semantic parser by johansson and nugues (2008<papid> W08-2123 </papid>a) to annnotate the sentences with dependency syntax (melcuk, 1988) and shallow semantic structures in the propbank (palmer et al, 2005) <papid> J05-1004 </papid>and nombank (meyers et al., 2004) frameworks.</citsent>
<aftsection>
<nextsent>figure 1 shows an example of the annotation: the sentence they called him liar, where called is dse and liar is an ese, has been annotated with dependency syntax (above the text) and propbank-based semantic role structure (below the text).
</nextsent>
<nextsent>the predicate called, which is an instance of the propbank frame call.01, has three semantic arguments: the agent (a0), the theme (a1), and the predicate (a2), which are realized on the surface-syntactic level as subject,a direct object, and an object predicative complement, respectively.
</nextsent>
<nextsent>] ese they called call.01 sbj oprd liarhim[ [a a1a0 a2 ] dse nmodobjfigure 1: syntactic and shallow semantic structure.
</nextsent>
<nextsent>3.2 sequence labeler.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3921">
<title id=" W10-2910.xml">syntactic and semantic structure for opinion expression detection </title>
<section> opinion expression detection using.  </section>
<citcontext>
<prevsection>
<prevsent>a common objection to reranking is that the candidate set maynot be diverse enough to allow for much improvement unless it is very large; the candidates may be trivial variations that are all very similar to the top-scoring candidate (huang, 2008).<papid> P08-1067 </papid></prevsent>
<prevsent>3.1 syntactic and semantic structures.</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
we used the syntactic semantic parser by johansson and nugues (2008<papid> W08-2123 </papid>a) to annnotate the sentences with dependency syntax (melcuk, 1988) and shallow semantic structures in the propbank (palmer et al, 2005) <papid> J05-1004 </papid>and nombank (meyers et al., 2004) frameworks.</citsent>
<aftsection>
<nextsent>figure 1 shows an example of the annotation: the sentence they called him liar, where called is dse and liar is an ese, has been annotated with dependency syntax (above the text) and propbank-based semantic role structure (below the text).
</nextsent>
<nextsent>the predicate called, which is an instance of the propbank frame call.01, has three semantic arguments: the agent (a0), the theme (a1), and the predicate (a2), which are realized on the surface-syntactic level as subject,a direct object, and an object predicative complement, respectively.
</nextsent>
<nextsent>] ese they called call.01 sbj oprd liarhim[ [a a1a0 a2 ] dse nmodobjfigure 1: syntactic and shallow semantic structure.
</nextsent>
<nextsent>3.2 sequence labeler.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3923">
<title id=" W10-2910.xml">syntactic and semantic structure for opinion expression detection </title>
<section> opinion expression detection using.  </section>
<citcontext>
<prevsection>
<prevsent>this is viewed b-dse as the main b-ese impediment i-ese figure 2: sequence labeling example.
</prevsent>
<prevsent>the sequence labeler used word, pos tag, and lemma features in window of size 3.
</prevsent>
</prevsection>
<citsent citstr=" H05-1044 ">
in addition, we used prior polarity and intensity features derived from the lexicon created by wilson et al(2005).<papid> H05-1044 </papid></citsent>
<aftsection>
<nextsent>in the example, viewed is listed as having strong prior subjectivity but no polarity, and impediment has strong prior subjectivity and negative polarity.
</nextsent>
<nextsent>note that prior subjectivity does not always imply subjectivity in particular context; this is why contextual features are essential for this task.
</nextsent>
<nextsent>this sequence labeler is used to generate the candidate set for the reranker; the viterbi algorithm is easily modified to give k-best output.
</nextsent>
<nextsent>to generate training data for the reranker, we carried out 5-fold cross-validation procedure: we split the training set into 5 pieces, trained sequence labeler on pieces 1 to 4, applied it to piece 5 and so on.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3926">
<title id=" W10-2910.xml">syntactic and semantic structure for opinion expression detection </title>
<section> opinion expression detection using.  </section>
<citcontext>
<prevsection>
<prevsent>3.4.1 linear kernel we created feature vectors extracted from the candidate sequences using the features described in section 3.3.
</prevsent>
<prevsent>we then trained linear svms using the liblinear software (fan et al, 2008), using l1 loss and l2 regularization.
</prevsent>
</prevsection>
<citsent citstr=" N06-1037 ">
3.4.2 tree kernel tree kernels have been successful for number of structure extraction tasks, such as relation extraction (zhang et al, 2006; <papid> N06-1037 </papid>nguyen et al, 2009) <papid> D09-1143 </papid>and opinion holder extraction (wiegand and klakow, 2010).</citsent>
<aftsection>
<nextsent>a tree kernel implicitly represents large space of fragments extracted from trees and could thus reduce the need for manual feature design.since the paths that we extract manually (sec tion 3.3) can be expressed as tree fragments, this method could be an interesting alternative to the manually extracted features used with the linear kernel.
</nextsent>
<nextsent>we therefore implemented reranker using the partial tree kernel (moschitti, 2006), <papid> E06-1015 </papid>and we trained it using the svmlight-tk software1, which is modification of svm light (joachims, 1available at http://dit.unitn.it/moschitt 701999)2.</nextsent>
<nextsent>it is still an open question how dependency trees should be represented for use with tree kernels (suzuki et al, 2003; <papid> P03-1005 </papid>nguyen et al,2009); <papid> D09-1143 </papid>we used the representation shown in figure 3.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3927">
<title id=" W10-2910.xml">syntactic and semantic structure for opinion expression detection </title>
<section> opinion expression detection using.  </section>
<citcontext>
<prevsection>
<prevsent>3.4.1 linear kernel we created feature vectors extracted from the candidate sequences using the features described in section 3.3.
</prevsent>
<prevsent>we then trained linear svms using the liblinear software (fan et al, 2008), using l1 loss and l2 regularization.
</prevsent>
</prevsection>
<citsent citstr=" D09-1143 ">
3.4.2 tree kernel tree kernels have been successful for number of structure extraction tasks, such as relation extraction (zhang et al, 2006; <papid> N06-1037 </papid>nguyen et al, 2009) <papid> D09-1143 </papid>and opinion holder extraction (wiegand and klakow, 2010).</citsent>
<aftsection>
<nextsent>a tree kernel implicitly represents large space of fragments extracted from trees and could thus reduce the need for manual feature design.since the paths that we extract manually (sec tion 3.3) can be expressed as tree fragments, this method could be an interesting alternative to the manually extracted features used with the linear kernel.
</nextsent>
<nextsent>we therefore implemented reranker using the partial tree kernel (moschitti, 2006), <papid> E06-1015 </papid>and we trained it using the svmlight-tk software1, which is modification of svm light (joachims, 1available at http://dit.unitn.it/moschitt 701999)2.</nextsent>
<nextsent>it is still an open question how dependency trees should be represented for use with tree kernels (suzuki et al, 2003; <papid> P03-1005 </papid>nguyen et al,2009); <papid> D09-1143 </papid>we used the representation shown in figure 3.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3928">
<title id=" W10-2910.xml">syntactic and semantic structure for opinion expression detection </title>
<section> opinion expression detection using.  </section>
<citcontext>
<prevsection>
<prevsent>3.4.2 tree kernel tree kernels have been successful for number of structure extraction tasks, such as relation extraction (zhang et al, 2006; <papid> N06-1037 </papid>nguyen et al, 2009) <papid> D09-1143 </papid>and opinion holder extraction (wiegand and klakow, 2010).</prevsent>
<prevsent>a tree kernel implicitly represents large space of fragments extracted from trees and could thus reduce the need for manual feature design.since the paths that we extract manually (sec tion 3.3) can be expressed as tree fragments, this method could be an interesting alternative to the manually extracted features used with the linear kernel.</prevsent>
</prevsection>
<citsent citstr=" E06-1015 ">
we therefore implemented reranker using the partial tree kernel (moschitti, 2006), <papid> E06-1015 </papid>and we trained it using the svmlight-tk software1, which is modification of svm light (joachims, 1available at http://dit.unitn.it/moschitt 701999)2.</citsent>
<aftsection>
<nextsent>it is still an open question how dependency trees should be represented for use with tree kernels (suzuki et al, 2003; <papid> P03-1005 </papid>nguyen et al,2009); <papid> D09-1143 </papid>we used the representation shown in figure 3.</nextsent>
<nextsent>note that we have concatenated the opinion expression labels to the pos tag nodes.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3929">
<title id=" W10-2910.xml">syntactic and semantic structure for opinion expression detection </title>
<section> opinion expression detection using.  </section>
<citcontext>
<prevsection>
<prevsent>a tree kernel implicitly represents large space of fragments extracted from trees and could thus reduce the need for manual feature design.since the paths that we extract manually (sec tion 3.3) can be expressed as tree fragments, this method could be an interesting alternative to the manually extracted features used with the linear kernel.
</prevsent>
<prevsent>we therefore implemented reranker using the partial tree kernel (moschitti, 2006), <papid> E06-1015 </papid>and we trained it using the svmlight-tk software1, which is modification of svm light (joachims, 1available at http://dit.unitn.it/moschitt 701999)2.</prevsent>
</prevsection>
<citsent citstr=" P03-1005 ">
it is still an open question how dependency trees should be represented for use with tree kernels (suzuki et al, 2003; <papid> P03-1005 </papid>nguyen et al,2009); <papid> D09-1143 </papid>we used the representation shown in figure 3.</citsent>
<aftsection>
<nextsent>note that we have concatenated the opinion expression labels to the pos tag nodes.
</nextsent>
<nextsent>we did not use any of the features from section 3.3 except for the base sequence labeler score.
</nextsent>
<nextsent>top root objsbj prp they him oprd prp nmod dt nnes vbdds called liar figure 3: representation of dependency tree with opinion expressions for tree kernels.
</nextsent>
<nextsent>3.5 structure learning approach.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3931">
<title id=" W10-2910.xml">syntactic and semantic structure for opinion expression detection </title>
<section> opinion expression detection using.  </section>
<citcontext>
<prevsection>
<prevsent>the preference kernel approach reduces the reranking problem to binary classification task on pairs, after which standard svm optimizer is used to train the reranker.
</prevsent>
<prevsent>a problem with this method is that the optimization problem solved by the svm ? maximizing the classification accuracy on set of independent pairs ? is not directly related to the performance of the reranker.
</prevsent>
</prevsection>
<citsent citstr=" P02-1034 ">
instead, the method employed by many re rankers following collins and duffy (2002) <papid> P02-1034 </papid>directly learna scoring function that is trained to maximize performance on the reranking task.</citsent>
<aftsection>
<nextsent>we will refer to this approach as the structure learning method.
</nextsent>
<nextsent>while there are batch learning algorithms that work in this setting (tsochantaridis et al, 2005), online learning methods have been more popular for efficiency reasons.
</nextsent>
<nextsent>we investigated two online learning algorithms: the popular structured perceptron collins and duffy (2002) <papid> P02-1034 </papid>and the passive?</nextsent>
<nextsent>aggressive (pa) algorithm (crammer et al, 2006).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3938">
<title id=" W10-2910.xml">syntactic and semantic structure for opinion expression detection </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>we were not able to achieve the same performance using tree kernels as with manually extracted features.
</prevsent>
<prevsent>it is possible that this could be improved with better strategy for representing dependency structure for tree kernels, or if the tree kernels could be incorporated into the structural learning framework.the flexible architecture we have presented enables interesting future research: (i) straightforward improvement is the use of lexical similarity to reduce data sparseness, e.g.
</prevsent>
</prevsection>
<citsent citstr=" W05-0601 ">
(basili et al., 2005; <papid> W05-0601 </papid>basili et al, 2006; bloehdorn et al, 2006).</citsent>
<aftsection>
<nextsent>however, the similarity between subjective words, which have multiple senses against other words may negatively impact the system accuracy.
</nextsent>
<nextsent>therefore, the use of the syntactic/semantic kernels, i.e.
</nextsent>
<nextsent>(bloehdorn and moschitti, 2007a; bloehdorn and moschitti, 2007b), to syntactically contextualize word similarities may improve the reranker accuracy.
</nextsent>
<nextsent>(ii) the latter can be further boosted by studying complex structural kernels, e.g.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3940">
<title id=" W10-2910.xml">syntactic and semantic structure for opinion expression detection </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>(bloehdorn and moschitti, 2007a; bloehdorn and moschitti, 2007b), to syntactically contextualize word similarities may improve the reranker accuracy.
</prevsent>
<prevsent>(ii) the latter can be further boosted by studying complex structural kernels, e.g.
</prevsent>
</prevsection>
<citsent citstr=" D09-1112 ">
(moschitti, 2008; nguyen et al, 2009;<papid> D09-1143 </papid>dinarelli et al, 2009).<papid> D09-1112 </papid></citsent>
<aftsection>
<nextsent>(iii) more specific predicate argument structures such those proposed in framenet, e.g.
</nextsent>
<nextsent>(baker et al, 1998; <papid> P98-1013 </papid>giuglea and moschitti, 2004; giuglea and moschitti, 2006; <papid> P06-1117 </papid>johansson and nugues, 2008<papid> W08-2123 </papid>b) may be useful to characterize the opinion holder and the sentence semantic context.</nextsent>
<nextsent>finally, while the strategy based on reranking resulted insignificant performance boost, it remains to be seen whether higher accuracy can be achieved by developing more sophisticated inference algorithm based on dynamic program ming.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3941">
<title id=" W10-2910.xml">syntactic and semantic structure for opinion expression detection </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>(moschitti, 2008; nguyen et al, 2009;<papid> D09-1143 </papid>dinarelli et al, 2009).<papid> D09-1112 </papid></prevsent>
<prevsent>(iii) more specific predicate argument structures such those proposed in framenet, e.g.</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
(baker et al, 1998; <papid> P98-1013 </papid>giuglea and moschitti, 2004; giuglea and moschitti, 2006; <papid> P06-1117 </papid>johansson and nugues, 2008<papid> W08-2123 </papid>b) may be useful to characterize the opinion holder and the sentence semantic context.</citsent>
<aftsection>
<nextsent>finally, while the strategy based on reranking resulted insignificant performance boost, it remains to be seen whether higher accuracy can be achieved by developing more sophisticated inference algorithm based on dynamic programming.
</nextsent>
<nextsent>however, while the development of such an algorithm is an interesting problem, it will not necessarily result in more usable system ? when using reranker, it is easy to trade accuracy for efficiency.
</nextsent>
<nextsent>74 acknowledgements the research leading to these results has received funding from the european communitys seventh framework programme (fp7/2007-2013) under grant agreement 231126: living knowledge facts, opinions and bias in time, and from trustworthy eternal systems via evolving software, data and knowledge (eternals, project number fp7 247758).
</nextsent>
<nextsent>in addition, we would like to thank eric breck for clarifying his results and experimental setup.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3942">
<title id=" W10-2910.xml">syntactic and semantic structure for opinion expression detection </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>(moschitti, 2008; nguyen et al, 2009;<papid> D09-1143 </papid>dinarelli et al, 2009).<papid> D09-1112 </papid></prevsent>
<prevsent>(iii) more specific predicate argument structures such those proposed in framenet, e.g.</prevsent>
</prevsection>
<citsent citstr=" P06-1117 ">
(baker et al, 1998; <papid> P98-1013 </papid>giuglea and moschitti, 2004; giuglea and moschitti, 2006; <papid> P06-1117 </papid>johansson and nugues, 2008<papid> W08-2123 </papid>b) may be useful to characterize the opinion holder and the sentence semantic context.</citsent>
<aftsection>
<nextsent>finally, while the strategy based on reranking resulted insignificant performance boost, it remains to be seen whether higher accuracy can be achieved by developing more sophisticated inference algorithm based on dynamic programming.
</nextsent>
<nextsent>however, while the development of such an algorithm is an interesting problem, it will not necessarily result in more usable system ? when using reranker, it is easy to trade accuracy for efficiency.
</nextsent>
<nextsent>74 acknowledgements the research leading to these results has received funding from the european communitys seventh framework programme (fp7/2007-2013) under grant agreement 231126: living knowledge facts, opinions and bias in time, and from trustworthy eternal systems via evolving software, data and knowledge (eternals, project number fp7 247758).
</nextsent>
<nextsent>in addition, we would like to thank eric breck for clarifying his results and experimental setup.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3946">
<title id=" W10-3607.xml">hybrid stemmer for gujarati </title>
<section> background and related work.  </section>
<citcontext>
<prevsection>
<prevsent>both of these stem mers are rule based and are best suited for less inflectional languages like english.
</prevsent>
<prevsent>a lot of work has been done in the field of unsupervised learning of morphology.
</prevsent>
</prevsection>
<citsent citstr=" J01-2001 ">
goldsmith (2001), <papid> J01-2001 </papid>goldsmith (2006) proposed an unsupervised algorithm for learning the morphology of language based on the minimum description length (mdl) framework which focuses on representing the data in as compact manner as possible.</citsent>
<aftsection>
<nextsent>creutz (2005), creutz (2007) uses probabilistic maximum posteriori (map) formulation for unsupervised morpheme segmentation.
</nextsent>
<nextsent>not much work has been reported for stemming for indian languages compared to english and other european languages.
</nextsent>
<nextsent>the earliest work reported by ramanathan and rao (2003) used handcrafted suffix list and performed longest match stripping for building hindi stemmer.
</nextsent>
<nextsent>majumder et al (2007) developed yass: yet another suffix stripper which uses clustering based approach based on string dis 51tance measures and requires no linguistic know ledge.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3951">
<title id=" W10-1307.xml">using reinforcement learning to create communication channel management strategies for diverse users </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>much research has focused on developing techniques for overcoming or avoiding system misunderstandings.
</prevsent>
<prevsent>yet, as the quality of automatic speech recognition improves and sds are deployed to diverse populations and in varied environments, systems will needto better attend to possible human misunderstandings.
</prevsent>
</prevsection>
<citsent citstr=" J08-4002 ">
future sds will need to manage the communication channel, in addition to managing the task, to aid in avoiding these misunderstandings.researchers have explored the use of reinforcement learning (rl) to create dialogue policies that balance and optimize measures of task success (e.g., see (scheffler and young, 2002; levin et al, 2000; henderson et al, 2008; <papid> J08-4002 </papid>walker, 2000)).</citsent>
<aftsection>
<nextsent>along these lines, rl is potentially well suited to creating policies for the subtask of managing the communication channel, as it can learn to adapt to the user while continuing the dialogue.
</nextsent>
<nextsent>in doing so, rl may choose actions that appear costly at the time, but lead to better overall dialogues.
</nextsent>
<nextsent>our long term goal is to learn how to manage the communication channel along with the task, moving away from just what?
</nextsent>
<nextsent>to say and also focusing on how?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3953">
<title id=" W10-1307.xml">using reinforcement learning to create communication channel management strategies for diverse users </title>
<section> reinforcement learning.  </section>
<citcontext>
<prevsection>
<prevsent>the approach employed to create these users varies between researchers; ranging from simulations that employ only real user data (henderson et al, 2008), <papid> J08-4002 </papid>to those that model users with probabilistic simulations based on known realistic user behaviors (levin et al, 2000).</prevsent>
<prevsent>ai etal.</prevsent>
</prevsection>
<citsent citstr=" N07-2001 ">
suggest that less realistic user simulations that allow rl to explore more of the dialogue state space may perform as well or better than simulations that statistically recreate realistic user behavior (ai et al, 2007).<papid> N07-2001 </papid></citsent>
<aftsection>
<nextsent>for this proof-of-concept work, we employ 55hand-crafted user simulation that allows full exploration of the state space.
</nextsent>
<nextsent>costs: although it is agreed that rl is viable approach to creating optimal dialogue policies, there remains much debate as to what cost functions result in the most useful policies.
</nextsent>
<nextsent>typically, these costs include measure of efficiency (e.g., number of turns)and measure of solution quality (e.g., the user successfully completed the transaction) (scheffler and young, 2002; levin et al, 2000).
</nextsent>
<nextsent>for managing the communication channel, it is unclear how the cost function should be structured.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3955">
<title id=" W10-1307.xml">using reinforcement learning to create communication channel management strategies for diverse users </title>
<section> rl and system encoding.  </section>
<citcontext>
<prevsection>
<prevsent>an amplitude change of 2 is used only when both the optimal amplitude is obvious and change of 2 will bring the amplitude setting to the optimal amplitude.
</prevsent>
<prevsent>to learn communication channel management policies we use rl with system and user actions specified using information state update rules (henderson et al, 2008).<papid> J08-4002 </papid></prevsent>
</prevsection>
<citsent citstr=" N07-1034 ">
following heeman (2007), <papid> N07-1034 </papid>we encode commonsense preconditions rather than trying to learn them, and only use subset of the information state for rl.</citsent>
<aftsection>
<nextsent>domain task: we use domain task that requires the user to supply 9 pieces of information, excluding user feedback relating to the communication channel.
</nextsent>
<nextsent>the system has deterministic way of selecting its actions, thus no learning is needed for the domain task.
</nextsent>
<nextsent>state variables: for rl, each state is represented by two variables; amp history and progress.
</nextsent>
<nextsent>amp history models the user by tracking all previous user feedback.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3956">
<title id=" W10-3501.xml">constructing largescale person ontology from wikipedia </title>
<section> ontology building method.  </section>
<citcontext>
<prevsection>
<prevsent>(bassist), we regard the hypernym of the article as the hypernym of the category.
</prevsent>
<prevsent>as most category labels and d-hypernyms are common nouns, they are likely to match instances in goi-taikei which lists possible semantic categories of words.
</prevsent>
</prevsection>
<citsent citstr=" L08-1309 ">
5as for d-hypernym extraction patterns, we used almost the same patterns described in previous works on japanese sources such as (kobayashi et al 2008; sumida et al, 2008), <papid> L08-1309 </papid>which are basically equivalent to the works on english sources such as (hearst, 1992).<papid> C92-2082 </papid></citsent>
<aftsection>
<nextsent>4 after the texts located at various structural relations a-f are collected, they are matched to the instances of goi-taikei in two different spans: span of the text ?.
</nextsent>
<nextsent>all character strings of the text ?.
</nextsent>
<nextsent>the last word of the text for the span ?, the text is segmented into words using japanese morphological analyzer.
</nextsent>
<nextsent>the last word is used because the last word usually represents the meaning of the entire noun phrase (semantic head word) in japanese.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3957">
<title id=" W10-3501.xml">constructing largescale person ontology from wikipedia </title>
<section> ontology building method.  </section>
<citcontext>
<prevsection>
<prevsent>(bassist), we regard the hypernym of the article as the hypernym of the category.
</prevsent>
<prevsent>as most category labels and d-hypernyms are common nouns, they are likely to match instances in goi-taikei which lists possible semantic categories of words.
</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
5as for d-hypernym extraction patterns, we used almost the same patterns described in previous works on japanese sources such as (kobayashi et al 2008; sumida et al, 2008), <papid> L08-1309 </papid>which are basically equivalent to the works on english sources such as (hearst, 1992).<papid> C92-2082 </papid></citsent>
<aftsection>
<nextsent>4 after the texts located at various structural relations a-f are collected, they are matched to the instances of goi-taikei in two different spans: span of the text ?.
</nextsent>
<nextsent>all character strings of the text ?.
</nextsent>
<nextsent>the last word of the text for the span ?, the text is segmented into words using japanese morphological analyzer.
</nextsent>
<nextsent>the last word is used because the last word usually represents the meaning of the entire noun phrase (semantic head word) in japanese.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3958">
<title id=" W10-2923.xml">tagging and linking web forum posts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this research is targeted at this task of enhanced support sharing,in the form of text mining over troubleshooting oriented web user forum data (baldwin et al, to appear).one facet of our proposed strategy for enhancing information access to troubleshooting-oriented web user forum data is to pre process threads to uncover the content structure?
</prevsent>
<prevsent>of the thread, in the form of its post-to-post discourse structure.
</prevsent>
</prevsection>
<citsent citstr=" J00-3003 ">
specifically, we identify which earlier post(s) agiven post responds to (linking) and in what manner (tagging), in an amalgam of dialogue act tagging (stolcke et al, 2000) <papid> J00-3003 </papid>and coherence-based discourse analysis (carlson et al, 2001; <papid> W01-1605 </papid>wolf and gibson, 2005).<papid> J05-2005 </papid></citsent>
<aftsection>
<nextsent>the reason we do this is gauge the relative role/import of individual posts, to index and weight component terms accordingly, ultimately in an attempt to enhance information access.
</nextsent>
<nextsent>evidence to suggest that this structure can enhance information retrieval effectiveness comes from xi et al (2004) and seo et al (2009) (see section 2).
</nextsent>
<nextsent>to illustrate the task, consider the thread from the cnet forum shown in figure 1, made up of5 posts (post 1, ..., post 5) with 4 distinct participants (a, b, c, d).
</nextsent>
<nextsent>in the first post, initiates the thread by requesting assistance in creating web form.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3959">
<title id=" W10-2923.xml">tagging and linking web forum posts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this research is targeted at this task of enhanced support sharing,in the form of text mining over troubleshooting oriented web user forum data (baldwin et al, to appear).one facet of our proposed strategy for enhancing information access to troubleshooting-oriented web user forum data is to pre process threads to uncover the content structure?
</prevsent>
<prevsent>of the thread, in the form of its post-to-post discourse structure.
</prevsent>
</prevsection>
<citsent citstr=" W01-1605 ">
specifically, we identify which earlier post(s) agiven post responds to (linking) and in what manner (tagging), in an amalgam of dialogue act tagging (stolcke et al, 2000) <papid> J00-3003 </papid>and coherence-based discourse analysis (carlson et al, 2001; <papid> W01-1605 </papid>wolf and gibson, 2005).<papid> J05-2005 </papid></citsent>
<aftsection>
<nextsent>the reason we do this is gauge the relative role/import of individual posts, to index and weight component terms accordingly, ultimately in an attempt to enhance information access.
</nextsent>
<nextsent>evidence to suggest that this structure can enhance information retrieval effectiveness comes from xi et al (2004) and seo et al (2009) (see section 2).
</nextsent>
<nextsent>to illustrate the task, consider the thread from the cnet forum shown in figure 1, made up of5 posts (post 1, ..., post 5) with 4 distinct participants (a, b, c, d).
</nextsent>
<nextsent>in the first post, initiates the thread by requesting assistance in creating web form.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3960">
<title id=" W10-2923.xml">tagging and linking web forum posts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this research is targeted at this task of enhanced support sharing,in the form of text mining over troubleshooting oriented web user forum data (baldwin et al, to appear).one facet of our proposed strategy for enhancing information access to troubleshooting-oriented web user forum data is to pre process threads to uncover the content structure?
</prevsent>
<prevsent>of the thread, in the form of its post-to-post discourse structure.
</prevsent>
</prevsection>
<citsent citstr=" J05-2005 ">
specifically, we identify which earlier post(s) agiven post responds to (linking) and in what manner (tagging), in an amalgam of dialogue act tagging (stolcke et al, 2000) <papid> J00-3003 </papid>and coherence-based discourse analysis (carlson et al, 2001; <papid> W01-1605 </papid>wolf and gibson, 2005).<papid> J05-2005 </papid></citsent>
<aftsection>
<nextsent>the reason we do this is gauge the relative role/import of individual posts, to index and weight component terms accordingly, ultimately in an attempt to enhance information access.
</nextsent>
<nextsent>evidence to suggest that this structure can enhance information retrieval effectiveness comes from xi et al (2004) and seo et al (2009) (see section 2).
</nextsent>
<nextsent>to illustrate the task, consider the thread from the cnet forum shown in figure 1, made up of5 posts (post 1, ..., post 5) with 4 distinct participants (a, b, c, d).
</nextsent>
<nextsent>in the first post, initiates the thread by requesting assistance in creating web form.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3962">
<title id=" W10-2923.xml">tagging and linking web forum posts </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>note, however, that more generally, itis possible for post to link to multiple preceding posts (e.g. refuting one proposed solution, and proposing different solution to the problem in the initial post).
</prevsent>
<prevsent>our primary contributions in this paper are: (1) novel post label set for post structure in web forum data, and associated dataset; and (2) series of results for post dependency linking and labelling, which achieve strong results for there spective tasks.
</prevsent>
</prevsection>
<citsent citstr=" N06-1047 ">
related work exists in the broad fields of dialogue processing, discourse analysis and information retrieval, and can be broken down into the followingtasks: (1) dialogue act tagging; (2) discourse disentanglement?; (3) community question answer ing; and (4) newsgroup/user forum search.dialogue act (da) tagging is means of capturing the function of given utterance relative to an encompassing discourse, and has been proposed variously as means of enhancing dialoguesummarisation (murray et al, 2006), <papid> N06-1047 </papid>and tracking commitments and promises in email (cohenet al, 2004; lampert et al, 2008), as well as being shown to improve speech recognition accuracy (stolcke et al, 2000).<papid> J00-3003 </papid></citsent>
<aftsection>
<nextsent>a wide range of da tag sets have been proposed, usually customised to particular medium such as speech dialogue(stolcke et al, 2000; <papid> J00-3003 </papid>shriberg et al, 2004), <papid> W04-2319 </papid>task focused email (cohen et al, 2004; wang et al,2007; lampert et al, 2008) or instant messaging (ivanovic, 2008).</nextsent>
<nextsent>the most immediately relevant da-based work we are aware of is that ofxi et al (2004), who proposed 5-way classification for news group data (including question and agreement/ammendment), but did not present any results based on the tagset.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3965">
<title id=" W10-2923.xml">tagging and linking web forum posts </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>our primary contributions in this paper are: (1) novel post label set for post structure in web forum data, and associated dataset; and (2) series of results for post dependency linking and labelling, which achieve strong results for there spective tasks.
</prevsent>
<prevsent>related work exists in the broad fields of dialogue processing, discourse analysis and information retrieval, and can be broken down into the followingtasks: (1) dialogue act tagging; (2) discourse disentanglement?; (3) community question answer ing; and (4) newsgroup/user forum search.dialogue act (da) tagging is means of capturing the function of given utterance relative to an encompassing discourse, and has been proposed variously as means of enhancing dialoguesummarisation (murray et al, 2006), <papid> N06-1047 </papid>and tracking commitments and promises in email (cohenet al, 2004; lampert et al, 2008), as well as being shown to improve speech recognition accuracy (stolcke et al, 2000).<papid> J00-3003 </papid></prevsent>
</prevsection>
<citsent citstr=" W04-2319 ">
a wide range of da tag sets have been proposed, usually customised to particular medium such as speech dialogue(stolcke et al, 2000; <papid> J00-3003 </papid>shriberg et al, 2004), <papid> W04-2319 </papid>task focused email (cohen et al, 2004; wang et al,2007; lampert et al, 2008) or instant messaging (ivanovic, 2008).</citsent>
<aftsection>
<nextsent>the most immediately relevant da-based work we are aware of is that ofxi et al (2004), who proposed 5-way classification for news group data (including question and agreement/ammendment), but did not present any results based on the tagset.
</nextsent>
<nextsent>a range of supervised models have been applied to da classification, including graphical models (ji and bilmes, 2005), kernel methods (wang et al, 2007), dependency networks (carvalho and cohen, 2005), transformation-based learning (samuel et al, 1998), <papid> P98-2188 </papid>maxent models (ang et al., 2005) and hmms (ivanovic, 2008).</nextsent>
<nextsent>there is some contention about the import of context in da classification, with the prevailing view being that context aids classification (carvalho and cohen, 2005; ang et al, 2005; ji and bilmes, 2005), butalso evidence to suggest that strictly local modelling is superior (ries, 1999; serafin and di eugenio, 2004).<papid> P04-1088 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3966">
<title id=" W10-2923.xml">tagging and linking web forum posts </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>a wide range of da tag sets have been proposed, usually customised to particular medium such as speech dialogue(stolcke et al, 2000; <papid> J00-3003 </papid>shriberg et al, 2004), <papid> W04-2319 </papid>task focused email (cohen et al, 2004; wang et al,2007; lampert et al, 2008) or instant messaging (ivanovic, 2008).</prevsent>
<prevsent>the most immediately relevant da-based work we are aware of is that ofxi et al (2004), who proposed 5-way classification for news group data (including question and agreement/ammendment), but did not present any results based on the tagset.</prevsent>
</prevsection>
<citsent citstr=" P98-2188 ">
a range of supervised models have been applied to da classification, including graphical models (ji and bilmes, 2005), kernel methods (wang et al, 2007), dependency networks (carvalho and cohen, 2005), transformation-based learning (samuel et al, 1998), <papid> P98-2188 </papid>maxent models (ang et al., 2005) and hmms (ivanovic, 2008).</citsent>
<aftsection>
<nextsent>there is some contention about the import of context in da classification, with the prevailing view being that context aids classification (carvalho and cohen, 2005; ang et al, 2005; ji and bilmes, 2005), butalso evidence to suggest that strictly local modelling is superior (ries, 1999; serafin and di eugenio, 2004).<papid> P04-1088 </papid></nextsent>
<nextsent>in this work, we draw on existing work (esp. xi et al (2004)) in proposing novel da tagset customised to the analysis of troubleshooting oriented web user forums (section 3), and compare range of text classification and structured classification methods for post-level da clas sifi cation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3967">
<title id=" W10-2923.xml">tagging and linking web forum posts </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the most immediately relevant da-based work we are aware of is that ofxi et al (2004), who proposed 5-way classification for news group data (including question and agreement/ammendment), but did not present any results based on the tagset.
</prevsent>
<prevsent>a range of supervised models have been applied to da classification, including graphical models (ji and bilmes, 2005), kernel methods (wang et al, 2007), dependency networks (carvalho and cohen, 2005), transformation-based learning (samuel et al, 1998), <papid> P98-2188 </papid>maxent models (ang et al., 2005) and hmms (ivanovic, 2008).</prevsent>
</prevsection>
<citsent citstr=" P04-1088 ">
there is some contention about the import of context in da classification, with the prevailing view being that context aids classification (carvalho and cohen, 2005; ang et al, 2005; ji and bilmes, 2005), butalso evidence to suggest that strictly local modelling is superior (ries, 1999; serafin and di eugenio, 2004).<papid> P04-1088 </papid></citsent>
<aftsection>
<nextsent>in this work, we draw on existing work (esp. xi et al (2004)) in proposing novel da tagset customised to the analysis of troubleshooting oriented web user forums (section 3), and compare range of text classification and structured classification methods for post-level da classification.
</nextsent>
<nextsent>discourse disentanglement is the process of automatically identifying coherent sub-discoursesin single thread (in the context of user fo rums/mailing lists), chat session (in the context ofirc chat data: elsner and charniak (2008)), <papid> P08-1095 </papid>system interaction (in the context of hci: lemon et al.</nextsent>
<nextsent>(2002)) or document (wolf and gibson, 2005).<papid> J05-2005 </papid>the exact definition of what constitutes sub discourse varies across domains, but for our purposes, entails an attempt to resolve the informa 193 tion need of the initiator by particular approach; if there are competing approaches proposed in asingle thread, multiple sub-discourses will necessarily arise.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3968">
<title id=" W10-2923.xml">tagging and linking web forum posts </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>there is some contention about the import of context in da classification, with the prevailing view being that context aids classification (carvalho and cohen, 2005; ang et al, 2005; ji and bilmes, 2005), butalso evidence to suggest that strictly local modelling is superior (ries, 1999; serafin and di eugenio, 2004).<papid> P04-1088 </papid></prevsent>
<prevsent>in this work, we draw on existing work (esp. xi et al (2004)) in proposing novel da tagset customised to the analysis of troubleshooting oriented web user forums (section 3), and compare range of text classification and structured classification methods for post-level da clas sifi cation.</prevsent>
</prevsection>
<citsent citstr=" P08-1095 ">
discourse disentanglement is the process of automatically identifying coherent sub-discoursesin single thread (in the context of user fo rums/mailing lists), chat session (in the context ofirc chat data: elsner and charniak (2008)), <papid> P08-1095 </papid>system interaction (in the context of hci: lemon et al.</citsent>
<aftsection>
<nextsent>(2002)) or document (wolf and gibson, 2005).<papid> J05-2005 </papid>the exact definition of what constitutes sub discourse varies across domains, but for our purposes, entails an attempt to resolve the informa 193 tion need of the initiator by particular approach; if there are competing approaches proposed in asingle thread, multiple sub-discourses will necessarily arise.</nextsent>
<nextsent>the data structure used to represent the disentangled discourse varies from simple connected sub-graph (elsner and charniak, 2008), <papid> P08-1095 </papid>to stack/tree (grosz and sidner, 1986; <papid> J86-3001 </papid>lemon et al, 2002; <papid> W02-0216 </papid>seo et al, 2009), to full directed acyclic graph (dag: rose?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3972">
<title id=" W10-2923.xml">tagging and linking web forum posts </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>discourse disentanglement is the process of automatically identifying coherent sub-discoursesin single thread (in the context of user fo rums/mailing lists), chat session (in the context ofirc chat data: elsner and charniak (2008)), <papid> P08-1095 </papid>system interaction (in the context of hci: lemon et al.</prevsent>
<prevsent>(2002)) or document (wolf and gibson, 2005).<papid> J05-2005 </papid>the exact definition of what constitutes sub discourse varies across domains, but for our purposes, entails an attempt to resolve the informa 193 tion need of the initiator by particular approach; if there are competing approaches proposed in asingle thread, multiple sub-discourses will necessarily arise.</prevsent>
</prevsection>
<citsent citstr=" J86-3001 ">
the data structure used to represent the disentangled discourse varies from simple connected sub-graph (elsner and charniak, 2008), <papid> P08-1095 </papid>to stack/tree (grosz and sidner, 1986; <papid> J86-3001 </papid>lemon et al, 2002; <papid> W02-0216 </papid>seo et al, 2009), to full directed acyclic graph (dag: rose?</citsent>
<aftsection>
<nextsent>et al (1995), wolf and gibson (2005), <papid> J05-2005 </papid>schuth et al (2007)).</nextsent>
<nextsent>disentanglement has been carried out via analysis of direct citation/user name references (schuth et al, 2007; seo et al, 2009), topic modelling (lin et al, 2009), and clustering over content-based features for pairs of posts, optionally incorporating various constraints on post recency (elsner and charniak, 2008; <papid> P08-1095 </papid>wang et al, 2008; seo et al, 2009).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3973">
<title id=" W10-2923.xml">tagging and linking web forum posts </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>discourse disentanglement is the process of automatically identifying coherent sub-discoursesin single thread (in the context of user fo rums/mailing lists), chat session (in the context ofirc chat data: elsner and charniak (2008)), <papid> P08-1095 </papid>system interaction (in the context of hci: lemon et al.</prevsent>
<prevsent>(2002)) or document (wolf and gibson, 2005).<papid> J05-2005 </papid>the exact definition of what constitutes sub discourse varies across domains, but for our purposes, entails an attempt to resolve the informa 193 tion need of the initiator by particular approach; if there are competing approaches proposed in asingle thread, multiple sub-discourses will necessarily arise.</prevsent>
</prevsection>
<citsent citstr=" W02-0216 ">
the data structure used to represent the disentangled discourse varies from simple connected sub-graph (elsner and charniak, 2008), <papid> P08-1095 </papid>to stack/tree (grosz and sidner, 1986; <papid> J86-3001 </papid>lemon et al, 2002; <papid> W02-0216 </papid>seo et al, 2009), to full directed acyclic graph (dag: rose?</citsent>
<aftsection>
<nextsent>et al (1995), wolf and gibson (2005), <papid> J05-2005 </papid>schuth et al (2007)).</nextsent>
<nextsent>disentanglement has been carried out via analysis of direct citation/user name references (schuth et al, 2007; seo et al, 2009), topic modelling (lin et al, 2009), and clustering over content-based features for pairs of posts, optionally incorporating various constraints on post recency (elsner and charniak, 2008; <papid> P08-1095 </papid>wang et al, 2008; seo et al, 2009).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3977">
<title id=" W10-2923.xml">tagging and linking web forum posts </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in this work, we follow rose?
</prevsent>
<prevsent>et al (1995) andwolf and gibson (2005) <papid> J05-2005 </papid>in adopting dag representation of discourse structure, and draw on thewide set of features used in discourse entanglement to model coherence.</prevsent>
</prevsection>
<citsent citstr=" C04-1128 ">
community question answering (cqa) is the task of identifying question answer pairs in agiven thread, e.g. for the purposes of thread summarisation (shrestha and mckeown, 2004) <papid> C04-1128 </papid>or automated compilation of resources akin to yahoo!answers.</citsent>
<aftsection>
<nextsent>cqa has been applied to both mailing list and user forum threads, conventionally based on question classification, followed by ranking of candidate answers relative to each question (shrestha and mckeown, 2004; <papid> C04-1128 </papid>ding et al, 2008; <papid> P08-1081 </papid>cong et al, 2008; cao et al, 2009).</nextsent>
<nextsent>the task is somewhat peripheral to our work, but relevant in that it involves the implicit tagging of certain postsas containing questions/answers, as well as linking the posts together.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3979">
<title id=" W10-2923.xml">tagging and linking web forum posts </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>et al (1995) andwolf and gibson (2005) <papid> J05-2005 </papid>in adopting dag representation of discourse structure, and draw on thewide set of features used in discourse entanglement to model coherence.</prevsent>
<prevsent>community question answering (cqa) is the task of identifying question answer pairs in agiven thread, e.g. for the purposes of thread summarisation (shrestha and mckeown, 2004) <papid> C04-1128 </papid>or automated compilation of resources akin to yahoo!answers.</prevsent>
</prevsection>
<citsent citstr=" P08-1081 ">
cqa has been applied to both mailing list and user forum threads, conventionally based on question classification, followed by ranking of candidate answers relative to each question (shrestha and mckeown, 2004; <papid> C04-1128 </papid>ding et al, 2008; <papid> P08-1081 </papid>cong et al, 2008; cao et al, 2009).</citsent>
<aftsection>
<nextsent>the task is somewhat peripheral to our work, but relevant in that it involves the implicit tagging of certain postsas containing questions/answers, as well as linking the posts together.
</nextsent>
<nextsent>once again, we draw on the features used in cqa in this research.
</nextsent>
<nextsent>there has been spike of recent interest in newsgroup/user forum search.
</nextsent>
<nextsent>xi et al (2004) proposed structured information retrieval (ir)model for news group search, based on author features, thread structure (based on the tree defined by the reply-to structure), thread topology?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3980">
<title id=" W10-2923.xml">tagging and linking web forum posts </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>of the 1332 posts, 65 posts have multiple labels (which possibly link to common post) and 22 posts link to two different links.
</prevsent>
<prevsent>the majority post label in the dataset is a-a (40.30%).
</prevsent>
</prevsection>
<citsent citstr=" N03-1028 ">
1http://forums.cnet.com/tag= tocleftcolumn.0we built machine learners using conventional maximum entropy (me) learner,2 as well as two structural learners, namely: (1) svm-hmms(joachims et al, 2009), as implemented in svm struct3, with linear kernel; and (2) conditional random fields (crfs) using crf++.4 svm hmms and crfs have been successfully applied to range of sequential tagging tasks such assyllabification (bartlett et al, 2009), chunk parsing (sha and pereira, 2003) <papid> N03-1028 </papid>and word segmentation (zhao et al, 2006).<papid> W06-0127 </papid></citsent>
<aftsection>
<nextsent>both are discriminative models which capture structural dependencies, which is highly desirable in terms of modelling sequential preferences between post labels(e.g. a-conf typically following a-a).
</nextsent>
<nextsent>svm hmm has the additional advantage of scaling tolarge numbers of features (namely the lexical fea tures).
</nextsent>
<nextsent>as such, we only experiment with lexical features for svm-hmm and me.all of our evaluation is based on stratified 10 fold cross-validation, st ratifying at the thread level to ensure that if given post is contained in the test data forgiven iteration, all other posts in that same thread are also in the test data (or more pertinently, not in the training data).
</nextsent>
<nextsent>we evaluate using micro-averaged precision, recall and score (?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3981">
<title id=" W10-2923.xml">tagging and linking web forum posts </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>of the 1332 posts, 65 posts have multiple labels (which possibly link to common post) and 22 posts link to two different links.
</prevsent>
<prevsent>the majority post label in the dataset is a-a (40.30%).
</prevsent>
</prevsection>
<citsent citstr=" W06-0127 ">
1http://forums.cnet.com/tag= tocleftcolumn.0we built machine learners using conventional maximum entropy (me) learner,2 as well as two structural learners, namely: (1) svm-hmms(joachims et al, 2009), as implemented in svm struct3, with linear kernel; and (2) conditional random fields (crfs) using crf++.4 svm hmms and crfs have been successfully applied to range of sequential tagging tasks such assyllabification (bartlett et al, 2009), chunk parsing (sha and pereira, 2003) <papid> N03-1028 </papid>and word segmentation (zhao et al, 2006).<papid> W06-0127 </papid></citsent>
<aftsection>
<nextsent>both are discriminative models which capture structural dependencies, which is highly desirable in terms of modelling sequential preferences between post labels(e.g. a-conf typically following a-a).
</nextsent>
<nextsent>svm hmm has the additional advantage of scaling tolarge numbers of features (namely the lexical fea tures).
</nextsent>
<nextsent>as such, we only experiment with lexical features for svm-hmm and me.all of our evaluation is based on stratified 10 fold cross-validation, st ratifying at the thread level to ensure that if given post is contained in the test data forgiven iteration, all other posts in that same thread are also in the test data (or more pertinently, not in the training data).
</nextsent>
<nextsent>we evaluate using micro-averaged precision, recall and score (?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3982">
<title id=" W10-2923.xml">tagging and linking web forum posts </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>we evaluate using micro-averaged precision, recall and score (?
</prevsent>
<prevsent>= 1).
</prevsent>
</prevsection>
<citsent citstr=" C00-2137 ">
we test the statistical significance of all above-baseline results using random ised estimation (p   0.05; yeh (2000)), <papid> C00-2137 </papid>and present all such results in bold in our results tables.</citsent>
<aftsection>
<nextsent>in our experiments, we first look at the post classification task in isolation (i.e. we predict which labels to associate with each post, under specifying which posts those labels relate to).
</nextsent>
<nextsent>we then move on to look at the link classification task, again in isolation (i.e. we predict which previous posts each post links to, under specifying the nature of the link).
</nextsent>
<nextsent>finally, we perform preliminary investigation of the joint task of da and link classification, by incorporating da class features into the link classification task.
</nextsent>
<nextsent>our first experiment is based on post-level dialogue act (da) classification, ignoring link structure in the first instance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3984">
<title id=" W10-2923.xml">tagging and linking web forum posts </title>
<section> discussion and future work.  </section>
<citcontext>
<prevsection>
<prevsent>having said this, there is more workto be done exploring synergies between the different feature sets, especially for da classification where all feature sets were found to produce above-baseline results.
</prevsent>
<prevsent>another possible direction for future research is to explore the impact of inter-post time on link structure, based on the observation that followup posts from the initiator tend to be temporally adjacent to posts they respond to with relatively short time intervals, while posts from non initiators which are well spaced out tend not to respond to one another.
</prevsent>
</prevsection>
<citsent citstr=" P07-2032 ">
combining this with profiling of the cross-thread behaviour of individual forum participants (weimer et al, 2007; <papid> P07-2032 </papid>lui and baldwin, 2009), and formal modelling of forum behaviour?</citsent>
<aftsection>
<nextsent>is also promising line of research, taking the lead from the work of gotz et al (2009), inter alia.
</nextsent>
<nextsent>in this work, we have proposed method for analysing post-to-post discourse structure in online user forum data, in the form of post linking and dialogue act tagging.
</nextsent>
<nextsent>we introduced three feature sets: structural features, post context features and semantic features.
</nextsent>
<nextsent>we experimented with three learners (maximum entropy, svm-hmm and crf), and established that crf is the superior approach to the task, achievingabove-baseline results for both post and link classification.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3985">
<title id=" W10-2911.xml">type level clustering evaluation new measures and a pos induction case study </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we demonstrate the benefits of our measures using detailed case study, pos induction.
</prevsent>
<prevsent>we experiment with seven leading algorithms, obtaining useful insights and showing that token and type level measures can weakly or even negatively correlate, which underscores the fact that these two approaches reveal different aspects of clustering quality.
</prevsent>
</prevsection>
<citsent citstr=" E03-1009 ">
clustering is central machine learning technique.in nlp, clustering has been used for virtually every semi- and unsupervised task, including pos tagging (clark, 2003), <papid> E03-1009 </papid>labeled parse tree induction(reichart and rappoport, 2008), <papid> C08-1091 </papid>verb-type classification (schulte im walde, 2006), lexical acquisition (davidov and rappoport, 2006; <papid> P06-1038 </papid>davidov and rappoport, 2008), <papid> P08-1079 </papid>multilingual document ? * both authors equally contributed to this paper.</citsent>
<aftsection>
<nextsent>omri abend is grateful to the azrieli foundation for the award of an azrieli fellowship.clustering (montavlo et al, 2006), coreference resolution (nicolae and nicolae, 2006) <papid> W06-1633 </papid>and named entity recognition (elsner et al, 2009).</nextsent>
<nextsent>consequently, the methodology of clustering evaluation is of great importance.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3987">
<title id=" W10-2911.xml">type level clustering evaluation new measures and a pos induction case study </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we demonstrate the benefits of our measures using detailed case study, pos induction.
</prevsent>
<prevsent>we experiment with seven leading algorithms, obtaining useful insights and showing that token and type level measures can weakly or even negatively correlate, which underscores the fact that these two approaches reveal different aspects of clustering quality.
</prevsent>
</prevsection>
<citsent citstr=" C08-1091 ">
clustering is central machine learning technique.in nlp, clustering has been used for virtually every semi- and unsupervised task, including pos tagging (clark, 2003), <papid> E03-1009 </papid>labeled parse tree induction(reichart and rappoport, 2008), <papid> C08-1091 </papid>verb-type classification (schulte im walde, 2006), lexical acquisition (davidov and rappoport, 2006; <papid> P06-1038 </papid>davidov and rappoport, 2008), <papid> P08-1079 </papid>multilingual document ? * both authors equally contributed to this paper.</citsent>
<aftsection>
<nextsent>omri abend is grateful to the azrieli foundation for the award of an azrieli fellowship.clustering (montavlo et al, 2006), coreference resolution (nicolae and nicolae, 2006) <papid> W06-1633 </papid>and named entity recognition (elsner et al, 2009).</nextsent>
<nextsent>consequently, the methodology of clustering evaluation is of great importance.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3988">
<title id=" W10-2911.xml">type level clustering evaluation new measures and a pos induction case study </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we demonstrate the benefits of our measures using detailed case study, pos induction.
</prevsent>
<prevsent>we experiment with seven leading algorithms, obtaining useful insights and showing that token and type level measures can weakly or even negatively correlate, which underscores the fact that these two approaches reveal different aspects of clustering quality.
</prevsent>
</prevsection>
<citsent citstr=" P06-1038 ">
clustering is central machine learning technique.in nlp, clustering has been used for virtually every semi- and unsupervised task, including pos tagging (clark, 2003), <papid> E03-1009 </papid>labeled parse tree induction(reichart and rappoport, 2008), <papid> C08-1091 </papid>verb-type classification (schulte im walde, 2006), lexical acquisition (davidov and rappoport, 2006; <papid> P06-1038 </papid>davidov and rappoport, 2008), <papid> P08-1079 </papid>multilingual document ? * both authors equally contributed to this paper.</citsent>
<aftsection>
<nextsent>omri abend is grateful to the azrieli foundation for the award of an azrieli fellowship.clustering (montavlo et al, 2006), coreference resolution (nicolae and nicolae, 2006) <papid> W06-1633 </papid>and named entity recognition (elsner et al, 2009).</nextsent>
<nextsent>consequently, the methodology of clustering evaluation is of great importance.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3989">
<title id=" W10-2911.xml">type level clustering evaluation new measures and a pos induction case study </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we demonstrate the benefits of our measures using detailed case study, pos induction.
</prevsent>
<prevsent>we experiment with seven leading algorithms, obtaining useful insights and showing that token and type level measures can weakly or even negatively correlate, which underscores the fact that these two approaches reveal different aspects of clustering quality.
</prevsent>
</prevsection>
<citsent citstr=" P08-1079 ">
clustering is central machine learning technique.in nlp, clustering has been used for virtually every semi- and unsupervised task, including pos tagging (clark, 2003), <papid> E03-1009 </papid>labeled parse tree induction(reichart and rappoport, 2008), <papid> C08-1091 </papid>verb-type classification (schulte im walde, 2006), lexical acquisition (davidov and rappoport, 2006; <papid> P06-1038 </papid>davidov and rappoport, 2008), <papid> P08-1079 </papid>multilingual document ? * both authors equally contributed to this paper.</citsent>
<aftsection>
<nextsent>omri abend is grateful to the azrieli foundation for the award of an azrieli fellowship.clustering (montavlo et al, 2006), coreference resolution (nicolae and nicolae, 2006) <papid> W06-1633 </papid>and named entity recognition (elsner et al, 2009).</nextsent>
<nextsent>consequently, the methodology of clustering evaluation is of great importance.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3990">
<title id=" W10-2911.xml">type level clustering evaluation new measures and a pos induction case study </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we experiment with seven leading algorithms, obtaining useful insights and showing that token and type level measures can weakly or even negatively correlate, which underscores the fact that these two approaches reveal different aspects of clustering quality.
</prevsent>
<prevsent>clustering is central machine learning technique.in nlp, clustering has been used for virtually every semi- and unsupervised task, including pos tagging (clark, 2003), <papid> E03-1009 </papid>labeled parse tree induction(reichart and rappoport, 2008), <papid> C08-1091 </papid>verb-type classification (schulte im walde, 2006), lexical acquisition (davidov and rappoport, 2006; <papid> P06-1038 </papid>davidov and rappoport, 2008), <papid> P08-1079 </papid>multilingual document ? * both authors equally contributed to this paper.</prevsent>
</prevsection>
<citsent citstr=" W06-1633 ">
omri abend is grateful to the azrieli foundation for the award of an azrieli fellowship.clustering (montavlo et al, 2006), coreference resolution (nicolae and nicolae, 2006) <papid> W06-1633 </papid>and named entity recognition (elsner et al, 2009).</citsent>
<aftsection>
<nextsent>consequently, the methodology of clustering evaluation is of great importance.
</nextsent>
<nextsent>in this paper we focus on external clustering evaluation, i.e., evaluation against manually annotated gold standards, which exist for almost all such nlp tasks.
</nextsent>
<nextsent>external evaluation is the dominant form of clustering evaluation in nlp, although other methods have been proposed (see e.g.
</nextsent>
<nextsent>(frank et al, 2009)).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3993">
<title id=" W10-2911.xml">type level clustering evaluation new measures and a pos induction case study </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(frank et al, 2009)).
</prevsent>
<prevsent>in this paper we discuss type level evaluation,which evaluates the set membership structure created by the clustering, independently of the token statistics of the gold standard corpus.
</prevsent>
</prevsection>
<citsent citstr=" P07-1094 ">
many clustering algorithms are evaluated by their success in tagging corpus tokens (clark, 2003; <papid> E03-1009 </papid>nicolae and nicolae, 2006; <papid> W06-1633 </papid>goldwater and griffiths, 2007;<papid> P07-1094 </papid>gao and johnson, 2008; <papid> D08-1036 </papid>elsner et al, 2009).</citsent>
<aftsection>
<nextsent>how ever, in many cases type level evaluation is the natural one.
</nextsent>
<nextsent>this is the case, for example, when pos induction algorithm is used to compute tag dictionary (the set of tags that each word can take), or when lexical acquisition algorithm is used for constructing lexicon containing the set of frames that verb can participate in, or when asense induction algorithm computes the set of possible senses of each word.
</nextsent>
<nextsent>in addition, even when the goal is corpus tagging, type level evaluation is highly valuable, since it may cast light on the relative or absolute merits of different algorithms (as we show in this paper).clustering evaluation has been extensively investigated (section 3).
</nextsent>
<nextsent>however, the discussion centers around the monosemous case, where each item belongs to exactly one cluster, although pol ysemy is the common case in nlp.the contribution of the present paper is as follows.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3994">
<title id=" W10-2911.xml">type level clustering evaluation new measures and a pos induction case study </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(frank et al, 2009)).
</prevsent>
<prevsent>in this paper we discuss type level evaluation,which evaluates the set membership structure created by the clustering, independently of the token statistics of the gold standard corpus.
</prevsent>
</prevsection>
<citsent citstr=" D08-1036 ">
many clustering algorithms are evaluated by their success in tagging corpus tokens (clark, 2003; <papid> E03-1009 </papid>nicolae and nicolae, 2006; <papid> W06-1633 </papid>goldwater and griffiths, 2007;<papid> P07-1094 </papid>gao and johnson, 2008; <papid> D08-1036 </papid>elsner et al, 2009).</citsent>
<aftsection>
<nextsent>how ever, in many cases type level evaluation is the natural one.
</nextsent>
<nextsent>this is the case, for example, when pos induction algorithm is used to compute tag dictionary (the set of tags that each word can take), or when lexical acquisition algorithm is used for constructing lexicon containing the set of frames that verb can participate in, or when asense induction algorithm computes the set of possible senses of each word.
</nextsent>
<nextsent>in addition, even when the goal is corpus tagging, type level evaluation is highly valuable, since it may cast light on the relative or absolute merits of different algorithms (as we show in this paper).clustering evaluation has been extensively investigated (section 3).
</nextsent>
<nextsent>however, the discussion centers around the monosemous case, where each item belongs to exactly one cluster, although pol ysemy is the common case in nlp.the contribution of the present paper is as follows.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3995">
<title id=" W10-2911.xml">type level clustering evaluation new measures and a pos induction case study </title>
<section> type level clustering evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>there are pos classes whose members are very frequent, e.g., determiners and prepositions.
</prevsent>
<prevsent>here, very small number of word types usually accounts for large portion of corpus tokens.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
for example, in the wsj penn treebank (marcus et al, 1993), <papid> J93-2004 </papid>there are 43,740 word types and over 1m word tokens.</citsent>
<aftsection>
<nextsent>of the types, 88 are tagged as prepositions.
</nextsent>
<nextsent>these types account for only 0.2% of the types, but for as many as 11.9% of the tokens.
</nextsent>
<nextsent>an algorithm which is accurate only on prepositions would do much better in token level evaluation than in type level one.this phenomenon is not restricted to prepositions or english.
</nextsent>
<nextsent>in the wsj corpus, determiners account for 0.05% of the types but for 9.8% of the tokens.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3997">
<title id=" W10-2911.xml">type level clustering evaluation new measures and a pos induction case study </title>
<section> existing clustering evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>when assuming the uniform distribution, the probability of an event (a gold class or an induced cluster k) is its relative size, so p(c) = ?|k|k=1 ick and p(k) = ?|c| c=1 ick (n is the total number of clustered items).
</prevsent>
<prevsent>under this assumption we define the entropies and the conditional entropies: h(c) = ? p|c|c=1 p|k| k=1 ick log p|k| k=1 ick h(c|k) = ? p|k|k=1 p|c| c=1 ick log ick p|c| c=1 ick h(k) and h(k|c) are defined similarly.
</prevsent>
</prevsection>
<citsent citstr=" D07-1043 ">
in section 5 we use two it measures for token level evaluation, (rosenberg and hirschberg, 2007) <papid> D07-1043 </papid>and nvi (reichart and rappoport, 2009) <papid> W09-1121 </papid>a normalized version of vi (meila, 2007)).</citsent>
<aftsection>
<nextsent>the appealing properties of these measures have been extensively discussed in these references; see also (pfitzner et al, 2008).
</nextsent>
<nextsent>v and nvi are defined as follows: = ( 1 h(c) = 0 1 ? h(c|k)h(c) h(c) 6= 0 = ( 1 h(k) = 0 1 ? h(k|c)h(k) h(k) 6= 0 = 2hc + 79 nv i(c, k) = ( h(c|k)+h(k|c) h(c) h(c) 6= 0 h(k) h(c) = 0in the monosemous case (type or token), the application of the measures described in this section to type level evaluation is straightforward.
</nextsent>
<nextsent>in thepolysemous case, however, they suffer from serious shortcomings.
</nextsent>
<nextsent>consider case in which each item is assigned exactly gold clusters and each gold cluster has the exact same number of items (i.e., each has size of lr|c| , where is the number of items).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG3998">
<title id=" W10-2911.xml">type level clustering evaluation new measures and a pos induction case study </title>
<section> existing clustering evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>when assuming the uniform distribution, the probability of an event (a gold class or an induced cluster k) is its relative size, so p(c) = ?|k|k=1 ick and p(k) = ?|c| c=1 ick (n is the total number of clustered items).
</prevsent>
<prevsent>under this assumption we define the entropies and the conditional entropies: h(c) = ? p|c|c=1 p|k| k=1 ick log p|k| k=1 ick h(c|k) = ? p|k|k=1 p|c| c=1 ick log ick p|c| c=1 ick h(k) and h(k|c) are defined similarly.
</prevsent>
</prevsection>
<citsent citstr=" W09-1121 ">
in section 5 we use two it measures for token level evaluation, (rosenberg and hirschberg, 2007) <papid> D07-1043 </papid>and nvi (reichart and rappoport, 2009) <papid> W09-1121 </papid>a normalized version of vi (meila, 2007)).</citsent>
<aftsection>
<nextsent>the appealing properties of these measures have been extensively discussed in these references; see also (pfitzner et al, 2008).
</nextsent>
<nextsent>v and nvi are defined as follows: = ( 1 h(c) = 0 1 ? h(c|k)h(c) h(c) 6= 0 = ( 1 h(k) = 0 1 ? h(k|c)h(k) h(k) 6= 0 = 2hc + 79 nv i(c, k) = ( h(c|k)+h(k|c) h(c) h(c) 6= 0 h(k) h(c) = 0in the monosemous case (type or token), the application of the measures described in this section to type level evaluation is straightforward.
</nextsent>
<nextsent>in thepolysemous case, however, they suffer from serious shortcomings.
</nextsent>
<nextsent>consider case in which each item is assigned exactly gold clusters and each gold cluster has the exact same number of items (i.e., each has size of lr|c| , where is the number of items).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4000">
<title id=" W10-2911.xml">type level clustering evaluation new measures and a pos induction case study </title>
<section> mapping based measures for.  </section>
<citcontext>
<prevsection>
<prevsent>2and to allow us to compute it accurately, see below.in the example in section 3 showing an unreasonable behavior of it-based measures, the score depends on for both macroi and microi.
</prevsent>
<prevsent>with our new measures, recall is always 1, but precision is rn . this is true both for 1-1 and m-1 mappings.hence, the new measures show reasonable behavior in this example for all values.
</prevsent>
</prevsection>
<citsent citstr=" D07-1023 ">
microi was used in (dasgupta and ng, 2007)<papid> D07-1023 </papid>with manually compiled mapping.</citsent>
<aftsection>
<nextsent>their mapping was not based on well-defined scheme but on heuristic.
</nextsent>
<nextsent>moreover, providing manual mapping might be impractical when the number of clusters is large, and can be inaccurate, especially when the clustering is not of very high quality.
</nextsent>
<nextsent>in the following we discuss how to compute the 1-1 and m-1 greedy mappings for each measure.
</nextsent>
<nextsent>1-1 mapping.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4005">
<title id=" W10-2911.xml">type level clustering evaluation new measures and a pos induction case study </title>
<section> evaluation of pos induction models.  </section>
<citcontext>
<prevsection>
<prevsent>pos induction algorithms.
</prevsent>
<prevsent>we experimented with the following models: arr10 (abend et al,2010), clark03 (clark, 2003), <papid> E03-1009 </papid>gg07 (goldwa ter and griffiths, 2007), <papid> P07-1094 </papid>gj08 (gao and johnson, 2008), <papid> D08-1036 </papid>and gvg09 (van gael et al, 2009) (threemodels).</prevsent>
</prevsection>
<citsent citstr=" P04-1062 ">
additional recent good results for various variants of the pos induction problem are described in e.g., (smith and eisner, 2004; <papid> P04-1062 </papid>graca et al., 2009).clark03 and arr10 are monosemous algorithms, allowing single cluster for each word type.</citsent>
<aftsection>
<nextsent>the other algorithms are polysemous.
</nextsent>
<nextsent>they perform sequence labeling where each token is tagged in its context, and different tokens (in stances) of the same type (word form) may receive different tags.
</nextsent>
<nextsent>dataset.
</nextsent>
<nextsent>all models were tested on sections 2-21 of the ptb-wsj, which consists of 39832 sentences, 950028 tokens and 39546 unique types.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4007">
<title id=" W10-1753.xml">the dcu dependency based metric in wmtmetricsmatr 2010 </title>
<section> abstract </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" W07-0714 ">
we describe dcus lfg dependency based metric submitted to the shared evaluation task of wmt-metricsmatr 2010.the metric is built on the lfg f-structure based approach presented in (owczarzak et al, 2007)<papid> W07-0714 </papid></citsent>
<aftsection>
<nextsent>we explore the following improvements on the original metric: 1) we replace the in-house lfg parser with an open source dependency parser that directly parses strings into lfg depen dencies; 2) we add stemming module and unigram paraphrases to strengthen the aligner; 3) we introduce chunk penalty following the practice of meteor to reward continuous matches; and 4) we introduce and tune parameters to maximize the correlation with human judgement.
</nextsent>
<nextsent>experiments show that these enhancements improve the dependency-based metrics correlation with human judgement.
</nextsent>
<nextsent>string-based automatic evaluation metrics such as bleu (papineni et al, 2002) <papid> P02-1040 </papid>have led directly to quality improvements in machine translation(mt).</nextsent>
<nextsent>these metrics provide an alternative to expensive human evaluations, and enable tuning of mt systems based on automatic evaluation results.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4011">
<title id=" W10-1753.xml">the dcu dependency based metric in wmtmetricsmatr 2010 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we explore the following improvements on the original metric: 1) we replace the in-house lfg parser with an open source dependency parser that directly parses strings into lfg depen dencies; 2) we add stemming module and unigram paraphrases to strengthen the aligner; 3) we introduce chunk penalty following the practice of meteor to reward continuous matches; and 4) we introduce and tune parameters to maximize the correlation with human judgement.
</prevsent>
<prevsent>experiments show that these enhancements improve the dependency-based metrics correlation with human judgement.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
string-based automatic evaluation metrics such as bleu (papineni et al, 2002) <papid> P02-1040 </papid>have led directly to quality improvements in machine translation(mt).</citsent>
<aftsection>
<nextsent>these metrics provide an alternative to expensive human evaluations, and enable tuning of mt systems based on automatic evaluation results.
</nextsent>
<nextsent>however, there is widespread recognition in the mt community that string-based metrics are not discriminative enough to reflect the translation quality of todays mt systems, many of which have gone beyond pure string-based approaches (cf.
</nextsent>
<nextsent>(callison-burch et al, 2006)).
</nextsent>
<nextsent>with that in mind, number of researchers have come up with metrics which incorporate more sophisticated and linguistically motivated resources.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4012">
<title id=" W10-1753.xml">the dcu dependency based metric in wmtmetricsmatr 2010 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(callison-burch et al, 2006)).
</prevsent>
<prevsent>with that in mind, number of researchers have come up with metrics which incorporate more sophisticated and linguistically motivated resources.
</prevsent>
</prevsection>
<citsent citstr=" W05-0909 ">
examples include meteor (banerjee and lavie, 2005; <papid> W05-0909 </papid>lavie and denkowski, 2009) and terp(snover et al, 2010), both of which now utilize stemming, wordnet and paraphrase information.</citsent>
<aftsection>
<nextsent>experimental and evaluation campaign results have shown that these metrics can obtain better correlation with human judgements than metrics that only use surface-level information.given that many of todays mt systems incorporate some kind of syntactic information, it was perhaps natural to use syntax in automatic mtevaluation as well.
</nextsent>
<nextsent>this direction was first explored by (liu and gildea, 2005), <papid> W05-0904 </papid>who used syntactic structure and dependency information to go beyond the surface level matching.</nextsent>
<nextsent>owczarzak et al (2007)<papid> W07-0714 </papid>extended this line of research with the use of term-based encoding of lexical functional grammar (lfg:(kaplan and bresnan, 1982)) labelled dependency graphs into unordered sets of dependency triples, and calculating precision, recall, and f-score on the triple sets corresponding to the translation and reference sen tences.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4013">
<title id=" W10-1753.xml">the dcu dependency based metric in wmtmetricsmatr 2010 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>examples include meteor (banerjee and lavie, 2005; <papid> W05-0909 </papid>lavie and denkowski, 2009) and terp(snover et al, 2010), both of which now utilize stemming, wordnet and paraphrase information.</prevsent>
<prevsent>experimental and evaluation campaign results have shown that these metrics can obtain better correlation with human judgements than metrics that only use surface-level information.given that many of todays mt systems incorporate some kind of syntactic information, it was perhaps natural to use syntax in automatic mtevaluation as well.</prevsent>
</prevsection>
<citsent citstr=" W05-0904 ">
this direction was first explored by (liu and gildea, 2005), <papid> W05-0904 </papid>who used syntactic structure and dependency information to go beyond the surface level matching.</citsent>
<aftsection>
<nextsent>owczarzak et al (2007)<papid> W07-0714 </papid>extended this line of research with the use of term-based encoding of lexical functional grammar (lfg:(kaplan and bresnan, 1982)) labelled dependency graphs into unordered sets of dependency triples, and calculating precision, recall, and f-score on the triple sets corresponding to the translation and reference sen tences.</nextsent>
<nextsent>with the addition of partial matching and n-best parses, owczarzak et al (2007)<papid> W07-0714 </papid>s method considerably outperforms liu and gildeas (2005) <papid> W05-0904 </papid>w.r.t. correlation with human judgement.the edpm metric (kahn et al, 2010) improves this line of research by using arc labels derived from probabilistic context-free grammar (pcfg) parse to replace the lfg labels,showing that pcfg parser is sufficient for preprocessing, compared to dependency parser in (liu and gildea, 2005) <papid> W05-0904 </papid>and (owczarzak et al, 2007)<papid> W07-0714 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4069">
<title id=" W10-1753.xml">the dcu dependency based metric in wmtmetricsmatr 2010 </title>
<section> producing and matching lfg.  </section>
<citcontext>
<prevsection>
<prevsent>we introduce our improvements to the metric in response to these observations in the following sections.
</prevsent>
<prevsent>dependency triples 3.1 the lfg parser.
</prevsent>
</prevsection>
<citsent citstr=" P04-1041 ">
the metric described in (owczarzak et al, 2007)<papid> W07-0714 </papid>uses the dcu lfg parser (cahill et al, 2004) <papid> P04-1041 </papid>to produce lfg dependency triples.</citsent>
<aftsection>
<nextsent>the parser uses penn treebank-trained parser to producec-structures (constituency trees) and an lfg structure annotation algorithm on the c-structure to obtain f-structures.
</nextsent>
<nextsent>in (owczarzak et al, 2007)<papid> W07-0714 </papid>triple matching on f-structures produced by this paradigm correlates well with human judgement,but this paradigm is not adequate for the wmtmetricsmatr evaluation in two respects: 1) the in house lfg annotation algorithm is not publicly available and 2) the speed of this paradigm is not satisfactory.</nextsent>
<nextsent>we instead use the malt parser1 (nivre et al,2006) with parsing model trained on lfg dependencies to produce the f-structure triples.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4091">
<title id=" W10-3904.xml">automatic classification of semantic relations between facts and opinions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the vast amounts of research conducted in nlp on automatic summarization, opinion mining, and question answering are illustrative of the great interest in making relevant information easier to find.
</prevsent>
<prevsent>providing internet users with thorough information requires recognizing semantic relations between both facts and opinions, however the assumptions made by current approaches are often incompatible with this goal.
</prevsent>
</prevsection>
<citsent citstr=" W00-1009 ">
for example, the existing semantic relations considered in recognizing textual entailment (rte) (dagan et al., 2005) are often too narrow in scope to be directly applicable to text on the internet, and theories like cross-document structure theory (cst) (radev, 2000) <papid> W00-1009 </papid>are only applicable to facts or second-hand reporting of opinions rather than relations between both.</citsent>
<aftsection>
<nextsent>as part of the statement map project we proposed the development of system to support information credibility analysis on the web(murakami et al, 2009<papid> W09-3027 </papid>b) by automatically summarizing facts and opinions on topics of interest to users and showing them the evidence and conflicts for each viewpoint.</nextsent>
<nextsent>to facilitate the detection of semantic relations in internet data, we defined sentence-like unit of information called the statement that encompasses both facts and opinions, started compiling corpus of statements annotated with semantic relations (mu rakami et al, 2009<papid> W09-3027 </papid>a), and begin constructing asystem to automatically identify semantic relations between statements.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4092">
<title id=" W10-3904.xml">automatic classification of semantic relations between facts and opinions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>providing internet users with thorough information requires recognizing semantic relations between both facts and opinions, however the assumptions made by current approaches are often incompatible with this goal.
</prevsent>
<prevsent>for example, the existing semantic relations considered in recognizing textual entailment (rte) (dagan et al., 2005) are often too narrow in scope to be directly applicable to text on the internet, and theories like cross-document structure theory (cst) (radev, 2000) <papid> W00-1009 </papid>are only applicable to facts or second-hand reporting of opinions rather than relations between both.</prevsent>
</prevsection>
<citsent citstr=" W09-3027 ">
as part of the statement map project we proposed the development of system to support information credibility analysis on the web(murakami et al, 2009<papid> W09-3027 </papid>b) by automatically summarizing facts and opinions on topics of interest to users and showing them the evidence and conflicts for each viewpoint.</citsent>
<aftsection>
<nextsent>to facilitate the detection of semantic relations in internet data, we defined sentence-like unit of information called the statement that encompasses both facts and opinions, started compiling corpus of statements annotated with semantic relations (mu rakami et al, 2009<papid> W09-3027 </papid>a), and begin constructing asystem to automatically identify semantic relations between statements.</nextsent>
<nextsent>in this paper, we describe the construction an devaluation of prototype semantic relation identification system.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4094">
<title id=" W10-3904.xml">automatic classification of semantic relations between facts and opinions </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>a major task in the rte challenge (recognizing textual entailment challenge) is classifying the semantic relation between text (t) and hypothesis (h) into [entailment], [contradiction], or [unknown].
</prevsent>
<prevsent>over the last several years, several corpora annotated with thousands of (t,h) pairs have been constructed for this task.
</prevsent>
</prevsection>
<citsent citstr=" W05-1201 ">
in these corpora, each pair was tagged indicating its related task (e.g. information extraction, question answering, information retrieval or summarization).the rte challenge has successfully employed variety of techniques in order to recognize instances of textual entailment, including methods based on: measuring the degree of lexical overlap between bag of words (glickman et al, 2005; jijkoun and de rijke, 2005), the alignment of graphs created from syntactic or semantic dependencies (marsi and krahmer, 2005; <papid> W05-1201 </papid>maccartney et al, 2006), <papid> N06-1006 </papid>statistical classifiers which leverage wide range of features (hicklet al, 2005), or reference rule generation (szpek tor et al, 2007).</citsent>
<aftsection>
<nextsent>these approaches have shown great promise in rte for entailment pairs in the corpus, but more robust models of recognizing logical relations are still desirable.
</nextsent>
<nextsent>the definition of contradiction in rte is that contradicts if it is very unlikely that both and can be true at the same time.
</nextsent>
<nextsent>however, in real documents on the web, there are many pairs of examples which are contradictory in part, or where one statement confines the applicability of another, as shown in the examples in table 1.
</nextsent>
<nextsent>2.2 cross-document structure theory.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4095">
<title id=" W10-3904.xml">automatic classification of semantic relations between facts and opinions </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>a major task in the rte challenge (recognizing textual entailment challenge) is classifying the semantic relation between text (t) and hypothesis (h) into [entailment], [contradiction], or [unknown].
</prevsent>
<prevsent>over the last several years, several corpora annotated with thousands of (t,h) pairs have been constructed for this task.
</prevsent>
</prevsection>
<citsent citstr=" N06-1006 ">
in these corpora, each pair was tagged indicating its related task (e.g. information extraction, question answering, information retrieval or summarization).the rte challenge has successfully employed variety of techniques in order to recognize instances of textual entailment, including methods based on: measuring the degree of lexical overlap between bag of words (glickman et al, 2005; jijkoun and de rijke, 2005), the alignment of graphs created from syntactic or semantic dependencies (marsi and krahmer, 2005; <papid> W05-1201 </papid>maccartney et al, 2006), <papid> N06-1006 </papid>statistical classifiers which leverage wide range of features (hicklet al, 2005), or reference rule generation (szpek tor et al, 2007).</citsent>
<aftsection>
<nextsent>these approaches have shown great promise in rte for entailment pairs in the corpus, but more robust models of recognizing logical relations are still desirable.
</nextsent>
<nextsent>the definition of contradiction in rte is that contradicts if it is very unlikely that both and can be true at the same time.
</nextsent>
<nextsent>however, in real documents on the web, there are many pairs of examples which are contradictory in part, or where one statement confines the applicability of another, as shown in the examples in table 1.
</nextsent>
<nextsent>2.2 cross-document structure theory.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4097">
<title id=" W10-3904.xml">automatic classification of semantic relations between facts and opinions </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, they used vector space model and tried multi-class classification.
</prevsent>
<prevsent>the results were not satisfactory.this observation may indicate that the recognition methods for each relation should be developed separately.
</prevsent>
</prevsection>
<citsent citstr=" I08-1019 ">
miyabe et al (2008) <papid> I08-1019 </papid>attempted to recognize relations that were defined in japanese cross-document relation corpus(etoh and okumura, 2005).</citsent>
<aftsection>
<nextsent>however, their target relations were limited to [equivalence]and [transition]; other relations were not targeted.
</nextsent>
<nextsent>recognizing [evidence] is indispensable for organizing information on the internet.we need to develop satisfactory methods of [ev idence] recognition.
</nextsent>
<nextsent>2.4 opinion mining and sentiment analysis.
</nextsent>
<nextsent>subjective statements, such as opinions, have recently been the focus of much nlp research including review analysis, opinion extraction, opinion question answering, and sentiment analysis.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4099">
<title id=" W10-3904.xml">automatic classification of semantic relations between facts and opinions </title>
<section> recognizing semantic relations.  </section>
<citcontext>
<prevsection>
<prevsent>5!:!j!3 !#)*$!!#$)23#!)..2%5)0 +&amp;!
</prevsent>
<prevsent>c!j! j!
</prevsent>
</prevsection>
<citsent citstr=" P10-2018 ">
b! b!c! figure 1: an example of structural alignmentsumoto, 2002) and the predicate-argument structure analyzer chapas (watanabe et al, 2010).<papid> P10-2018 </papid></citsent>
<aftsection>
<nextsent>cabocha splits the japanese text into phrase-like chunks and represents syntactic dependencies between the chunks as edges in graph.
</nextsent>
<nextsent>cha pas identifies predicate-argument structures in the dependency graph produced by cabocha.
</nextsent>
<nextsent>we also conduct extended modality analysis using the resources provided by matsuyoshi etal.
</nextsent>
<nextsent>(2010), focusing on tense, modality, and polarity, because such information provides important clues for the recognition of semantic relations between statements.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4100">
<title id=" W10-3904.xml">automatic classification of semantic relations between facts and opinions </title>
<section> recognizing semantic relations.  </section>
<citcontext>
<prevsection>
<prevsent>structural alignment we developed heuristic-based algorithm toalign chunk based on lexical similarity information.
</prevsent>
<prevsent>we incorporate the following information into an alignment confidence score that has range of 0.0-1.0 and align chunk whose scores cross an empirically-determined threshold.
</prevsent>
</prevsection>
<citsent citstr=" D09-1122 ">
surface level similarity: identical content words or cosine similarity of chunk contents ? semantic similarity of predicate-argument structures predicates we check for matches in predicate entailment databases (hashimoto etal., 2009; <papid> D09-1122 </papid>matsuyoshi et al, 2008) considering the default case frames reported by chapasarguments we check for synonym or hy pernym matches in the japanese wordnet(2008) or the japanese hypernym collection of sumida et al (2008) <papid> L08-1309 </papid>25  ?@abcdef)!</citsent>
<aftsection>
<nextsent> ? abcghf)!i! :!
</nextsent>
<nextsent>h :!
</nextsent>
<nextsent>(field) (in)!(agricultural chemicals) (acc)!
</nextsent>
<nextsent>(use)!
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4101">
<title id=" W10-3904.xml">automatic classification of semantic relations between facts and opinions </title>
<section> recognizing semantic relations.  </section>
<citcontext>
<prevsection>
<prevsent>structural alignment we developed heuristic-based algorithm toalign chunk based on lexical similarity information.
</prevsent>
<prevsent>we incorporate the following information into an alignment confidence score that has range of 0.0-1.0 and align chunk whose scores cross an empirically-determined threshold.
</prevsent>
</prevsection>
<citsent citstr=" L08-1309 ">
surface level similarity: identical content words or cosine similarity of chunk contents ? semantic similarity of predicate-argument structures predicates we check for matches in predicate entailment databases (hashimoto etal., 2009; <papid> D09-1122 </papid>matsuyoshi et al, 2008) considering the default case frames reported by chapasarguments we check for synonym or hy pernym matches in the japanese wordnet(2008) or the japanese hypernym collection of sumida et al (2008) <papid> L08-1309 </papid>25  ?@abcdef)!</citsent>
<aftsection>
<nextsent> ? abcghf)!i! :!
</nextsent>
<nextsent>h :!
</nextsent>
<nextsent>(field) (in)!(agricultural chemicals) (acc)!
</nextsent>
<nextsent>(use)!
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4102">
<title id=" W10-2912.xml">recession segmentation simpler online word segmentation using limited resources </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>we seek to determine how these limitations in the learners input and memory affect the learners performance and to demonstrate that the presented learner is robust even under non-ideal conditions.
</prevsent>
<prevsent>portions of this work were adapted from an earlier manuscript, word segmentation: quick but not dirty.
</prevsent>
</prevsection>
<citsent citstr=" N09-1036 ">
most recent work in word segmentation of child directed speech has operated within statistical optimization frameworks, particularly bayesian approaches (goldwater et al, 2009; johnson and goldwater, 2009).<papid> N09-1036 </papid></citsent>
<aftsection>
<nextsent>these models have established the state-of-the-art for the task of selecting appropriate word boundaries from stream of unstructured phonemes.
</nextsent>
<nextsent>but while these models deliver excellent performance, it is not clear how they in form the process of acquisition.
</nextsent>
<nextsent>trying to find cognitive insight from these typesof models is difficult because of the inherent mismatch in the quality and types of hypotheses they maintain during learning.
</nextsent>
<nextsent>children are incremental learners (brown, 1973), and learners relying on statistical optimization are generally not.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4106">
<title id=" W10-2912.xml">recession segmentation simpler online word segmentation using limited resources </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>this condition cannot be met if the input is sequence of monosyllabic words for which boundary must be postulated for every syllable; it is impossible to treat every boundary as local minimum.while the pseudo-words used in infant studies measuring the ability to use transitional probability information are uniformly three-syllables long, much of child-directed english consists of sequences of monosyllabic words.
</prevsent>
<prevsent>corpus statistics reveal that on average monosyllabic word is followed by another monosyllabic word 85% of time (yang, 2004), and thus learners that use only local transitional probabilities without any global optimization are unlikely to succeed.
</prevsent>
</prevsection>
<citsent citstr=" J01-3002 ">
this problem does not affect online approaches that use global information, such as computing the maximum likelihood of the corpus incrementally (venkataraman, 2001).<papid> J01-3002 </papid></citsent>
<aftsection>
<nextsent>since these approaches do not require each boundary be local minimum, they are able to correctly handle sequence of mono syllable words.
</nextsent>
<nextsent>we believe that the computational modeling of psychological processes, with special attention to concrete mechanisms and quantitative evaluations,can play an important role in identifying the constraints and structures relevant to childrens acquisition of language.
</nextsent>
<nextsent>rather than using prior which guides the learner to desired distribution, we examine learning with respect to model in which the hypothesis space is constrained by structural requirements.
</nextsent>
<nextsent>in this paper we take different approach than statistical optimization approaches by exploring how well learner can perform while proces singa corpus in an online fashion with only local information and lexicon of previously segmented 89 words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4107">
<title id=" W10-3713.xml">an efficient generic approach to extracting multiword expressions from dependency trees </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>see figure 1 for an example dependency tree produced automatically by the stanford parser from the english language data in the europarl corpus.
</prevsent>
<prevsent>(marneffe, 2008; koehn, 2005) identifying mwes with subtrees in dependency trees is not new idea.
</prevsent>
</prevsection>
<citsent citstr=" W04-0408 ">
it is close to the formal definition offered in melcuk (1998), and is applied computationally in debusmann (2004) <papid> W04-0408 </papid>however,using dependency treebanks to automatically extract mwes is fairly new and few mwe extrac figure 1.</citsent>
<aftsection>
<nextsent>a dependency tree of the sentence the minutes of yesterdays sitting have been dis tributed.?
</nextsent>
<nextsent>tion projects to date take advantage of dependency information directly.
</nextsent>
<nextsent>there are number of reasons why this is the case:?
</nextsent>
<nextsent>string-based algorithms are not readily applicable to trees.?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4108">
<title id=" W10-2310.xml">contextually mediated semantic similarity graphs for topic segmentation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we test this method both on concatenated news articles, and on more realistic segmentation task, closed-captions from commercial television programs, in which topic transitions are more subjective and less distinct.
</prevsent>
<prevsent>our methods are unsupervised and require no training; thus they do not require any labeled instances of segment boundaries.
</prevsent>
</prevsection>
<citsent citstr=" A00-2004 ">
our method attains results significantly superior to that of choi (2000), <papid> A00-2004 </papid>and approaches human performance on segmentation of television closed-captions, where inter-annotator disagreement is high.</citsent>
<aftsection>
<nextsent>2.1 summary of the approach.
</nextsent>
<nextsent>successful topic segmentation requires some representation of semantic and discourse cohesion, and the ability to detect where such cohesion is weakest.
</nextsent>
<nextsent>the underlying assumption of segmentation algorithms based on lexical chains or other term similarity measures between portions of document is that continuity in vocabulary reflects topic continuity.
</nextsent>
<nextsent>two short examples illustrating topic shifts in television news programs, with accompanying shift in vocabulary, appear in figure 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4109">
<title id=" W10-2310.xml">contextually mediated semantic similarity graphs for topic segmentation </title>
<section> graphs of lexical influence.  </section>
<citcontext>
<prevsection>
<prevsent>when processing document for segmentation, we first calculate ris for all the terms in that document.
</prevsent>
<prevsent>an ri for term is built sentence-by-sentence, beginning with sentence where occurs.
</prevsent>
</prevsection>
<citsent citstr=" C96-1021 ">
a sentence immediately succeeding or preceding the sentences already in the ri is added to that ri if it contains terms with sufficiently high pmi values with t. an adjacent sentence is also added to an ri if there is pronominal believed to refer to t; the algorithm for determining pronominal reference is closely based on kennedy and boguraev (1996).<papid> C96-1021 </papid></citsent>
<aftsection>
<nextsent>expansion of an ri is terminated if there are no motivations for expanding it further.
</nextsent>
<nextsent>additional termination conditions can be included as well.
</nextsent>
<nextsent>for example, if large local voca 1 pmi values are constructed for all words other than those.
</nextsent>
<nextsent>in list of stopwords.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4111">
<title id=" W10-2310.xml">contextually mediated semantic similarity graphs for topic segmentation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>evaluation is then relatively simple, employing pseudo-documents constructed by concatenating set of documents.
</prevsent>
<prevsent>this is suitable technique for detecting coarse grained topic shifts.
</prevsent>
</prevsection>
<citsent citstr=" P07-1061 ">
as ferret (2007) <papid> P07-1061 </papid>points out, approaches to the problem vary both in the kinds of knowledge they depend on, and on the kinds of features they employ.</citsent>
<aftsection>
<nextsent>research on topic segmentation has exploited information internal to the corpus of documents to be segmented and information derived from external resources.
</nextsent>
<nextsent>if corpus of documents pertinent to domain is available, statistical topic models such as those developed by beeferman et al.
</nextsent>
<nextsent>(1999) or blei and moreno (2001) can be tailored to documents of that type.
</nextsent>
<nextsent>lexical cohesion techniques include similarity measures between adjacent blocks of text, as in text tiling (hearst, 1994, <papid> P94-1002 </papid>1997) and lexical chains based on recurrences of term or related terms, as in morris and hirst (1991), <papid> J91-1002 </papid>kozima (1993), <papid> P93-1041 </papid>and galley, et al.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4112">
<title id=" W10-2310.xml">contextually mediated semantic similarity graphs for topic segmentation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>if corpus of documents pertinent to domain is available, statistical topic models such as those developed by beeferman et al.
</prevsent>
<prevsent>(1999) or blei and moreno (2001) can be tailored to documents of that type.
</prevsent>
</prevsection>
<citsent citstr=" P94-1002 ">
lexical cohesion techniques include similarity measures between adjacent blocks of text, as in text tiling (hearst, 1994, <papid> P94-1002 </papid>1997) and lexical chains based on recurrences of term or related terms, as in morris and hirst (1991), <papid> J91-1002 </papid>kozima (1993), <papid> P93-1041 </papid>and galley, et al.</citsent>
<aftsection>
<nextsent>(2003).
</nextsent>
<nextsent>in kan, et al (1998) <papid> W98-1123 </papid>recurrences of the same term within certain number of sentences are used for chains (the number varies with the type of term), and chains are based on entity reference as well as lexical identity.</nextsent>
<nextsent>our method is related to lexical chain techniques, in that the graphs we construct contain chains of nodes that extend the influence of term beyond the site where it occurs.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4113">
<title id=" W10-2310.xml">contextually mediated semantic similarity graphs for topic segmentation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>if corpus of documents pertinent to domain is available, statistical topic models such as those developed by beeferman et al.
</prevsent>
<prevsent>(1999) or blei and moreno (2001) can be tailored to documents of that type.
</prevsent>
</prevsection>
<citsent citstr=" J91-1002 ">
lexical cohesion techniques include similarity measures between adjacent blocks of text, as in text tiling (hearst, 1994, <papid> P94-1002 </papid>1997) and lexical chains based on recurrences of term or related terms, as in morris and hirst (1991), <papid> J91-1002 </papid>kozima (1993), <papid> P93-1041 </papid>and galley, et al.</citsent>
<aftsection>
<nextsent>(2003).
</nextsent>
<nextsent>in kan, et al (1998) <papid> W98-1123 </papid>recurrences of the same term within certain number of sentences are used for chains (the number varies with the type of term), and chains are based on entity reference as well as lexical identity.</nextsent>
<nextsent>our method is related to lexical chain techniques, in that the graphs we construct contain chains of nodes that extend the influence of term beyond the site where it occurs.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4114">
<title id=" W10-2310.xml">contextually mediated semantic similarity graphs for topic segmentation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>if corpus of documents pertinent to domain is available, statistical topic models such as those developed by beeferman et al.
</prevsent>
<prevsent>(1999) or blei and moreno (2001) can be tailored to documents of that type.
</prevsent>
</prevsection>
<citsent citstr=" P93-1041 ">
lexical cohesion techniques include similarity measures between adjacent blocks of text, as in text tiling (hearst, 1994, <papid> P94-1002 </papid>1997) and lexical chains based on recurrences of term or related terms, as in morris and hirst (1991), <papid> J91-1002 </papid>kozima (1993), <papid> P93-1041 </papid>and galley, et al.</citsent>
<aftsection>
<nextsent>(2003).
</nextsent>
<nextsent>in kan, et al (1998) <papid> W98-1123 </papid>recurrences of the same term within certain number of sentences are used for chains (the number varies with the type of term), and chains are based on entity reference as well as lexical identity.</nextsent>
<nextsent>our method is related to lexical chain techniques, in that the graphs we construct contain chains of nodes that extend the influence of term beyond the site where it occurs.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4115">
<title id=" W10-2310.xml">contextually mediated semantic similarity graphs for topic segmentation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>lexical cohesion techniques include similarity measures between adjacent blocks of text, as in text tiling (hearst, 1994, <papid> P94-1002 </papid>1997) and lexical chains based on recurrences of term or related terms, as in morris and hirst (1991), <papid> J91-1002 </papid>kozima (1993), <papid> P93-1041 </papid>and galley, et al.</prevsent>
<prevsent>(2003).</prevsent>
</prevsection>
<citsent citstr=" W98-1123 ">
in kan, et al (1998) <papid> W98-1123 </papid>recurrences of the same term within certain number of sentences are used for chains (the number varies with the type of term), and chains are based on entity reference as well as lexical identity.</citsent>
<aftsection>
<nextsent>our method is related to lexical chain techniques, in that the graphs we construct contain chains of nodes that extend the influence of term beyond the site where it occurs.
</nextsent>
<nextsent>but we differ in that we do not require term (or semantically related term) to recur, in order to build such chains.
</nextsent>
<nextsent>63 figure 4.
</nextsent>
<nextsent>a portion of the graph generated from the second excerpt in figure 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4116">
<title id=" W10-2310.xml">contextually mediated semantic similarity graphs for topic segmentation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>63 figure 4.
</prevsent>
<prevsent>a portion of the graph generated from the second excerpt in figure 1.
</prevsent>
</prevsection>
<citsent citstr=" D07-1037 ">
each node is labeled s_i__term_pos, where indicates the sentence index in this respect, our approach also resembles that of matveeva and levow (2007), <papid> D07-1037 </papid>who build semantic similarity among terms into their lexical cohesion model through latent semantic anal ysis.</citsent>
<aftsection>
<nextsent>our techniques differ in that we incorporate semantic relatedness between terms directly into graph, rather than computing similarities between blocks of text.
</nextsent>
<nextsent>in our experiments, we compare our method to c99 (choi, 2000), <papid> A00-2004 </papid>an algorithm widely treated as baseline.</nextsent>
<nextsent>chois algorithm is based on measure of local coherence; vocabulary similarity between each pair of sentences in document is computed and the similarity scores of nearby sentences are ranked, with boundaries hypothesized where similarity across sentences is low.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4126">
<title id=" W10-2310.xml">contextually mediated semantic similarity graphs for topic segmentation </title>
<section> experiments, results, and evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>we compute precision, recall, and f-measure based on exact boundary matches between the system and the reference segmentation.
</prevsent>
<prevsent>as numerous researchers have pointed out, this alone is not perspicacious way to evaluate segmentation algorithm, as system that misses gold standard boundary by one sentence would be treated just like one that misses it by ten.
</prevsent>
</prevsection>
<citsent citstr=" W97-0304 ">
we therefore computed two additional, widely used measures, pk (beeferman, et al, 1997) <papid> W97-0304 </papid>and win dowdiff (pevzner and hearst, 2002).<papid> J02-1002 </papid></citsent>
<aftsection>
<nextsent>pk assesses penalty against system for each position of sliding window across document in which the system and the gold standard differ on the presence or absence of (at least one) segment boundary.
</nextsent>
<nextsent>window diff is similar, but where the system differs from the gold standard, the penalty is equal to the difference in the number of boundaries between the two.
</nextsent>
<nextsent>this penalizes missed boundaries and near-misses?
</nextsent>
<nextsent>less than pk (but see lamprier, et al, (2007) for further analysis and some criticism of windowdiff).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4127">
<title id=" W10-2310.xml">contextually mediated semantic similarity graphs for topic segmentation </title>
<section> experiments, results, and evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>we compute precision, recall, and f-measure based on exact boundary matches between the system and the reference segmentation.
</prevsent>
<prevsent>as numerous researchers have pointed out, this alone is not perspicacious way to evaluate segmentation algorithm, as system that misses gold standard boundary by one sentence would be treated just like one that misses it by ten.
</prevsent>
</prevsection>
<citsent citstr=" J02-1002 ">
we therefore computed two additional, widely used measures, pk (beeferman, et al, 1997) <papid> W97-0304 </papid>and win dowdiff (pevzner and hearst, 2002).<papid> J02-1002 </papid></citsent>
<aftsection>
<nextsent>pk assesses penalty against system for each position of sliding window across document in which the system and the gold standard differ on the presence or absence of (at least one) segment boundary.
</nextsent>
<nextsent>window diff is similar, but where the system differs from the gold standard, the penalty is equal to the difference in the number of boundaries between the two.
</nextsent>
<nextsent>this penalizes missed boundaries and near-misses?
</nextsent>
<nextsent>less than pk (but see lamprier, et al, (2007) for further analysis and some criticism of windowdiff).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4129">
<title id=" W10-2310.xml">contextually mediated semantic similarity graphs for topic segmentation </title>
<section> experiments, results, and evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>we used three-sentence sliding window, and if three or more of the five annotators place boundary in that window, we assign boundary where the majority of them place it (in case of tie, we choose one location arbitrarily).
</prevsent>
<prevsent>although the annotators are rather inconsistent in their use of this rating system, given annotator tends to be consistent in the granularity of segmentation employed across all documents.
</prevsent>
</prevsection>
<citsent citstr=" P06-1004 ">
this observation is consistent with the remarks of malioutov and barzilay (2006) <papid> P06-1004 </papid>regarding varying topic granularity across human annotators on spoken material.</citsent>
<aftsection>
<nextsent>we thus computed two versions of the combined boundaries, one in which all boundaries are used, and another in which we ignore minor boundaries those the annotator assigned score of 1 or 2.
</nextsent>
<nextsent>we ran our experiments with both versions of the combined boundaries as the reference segmentation.
</nextsent>
<nextsent>we use pk to assess inter-annotator agreement among our five annotators.
</nextsent>
<nextsent>table 4 presents two 66 pk values for each pair of annotators; one set of values is for all boundaries, while the other is for major?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4131">
<title id=" W10-1609.xml">a machine learning approach for recognizing textual entailment in spanish </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>thus, ave task is very similar torte (recognition of textual entailments).
</prevsent>
<prevsent>in this paper, we address the rte task problem of determining the entailment value between text and hypothesis pairs in spanish, applying machine learning techniques.
</prevsent>
</prevsection>
<citsent citstr=" W07-1412 ">
in the past, rtes challenges machine learning algorithms were widely used for the task of recognizing textual entailment (marneffe et al, 2006; zanzotto et al, 2007; <papid> W07-1412 </papid>castillo, 2009) and they have reported goods results for english language.</citsent>
<aftsection>
<nextsent>also, our system applies machine learning algorithms to the spanish.
</nextsent>
<nextsent>we built set of datasets based on public available datasets for english, together to sparte (peas et al 2006), an available corpus in spanish.
</nextsent>
<nextsent>this corpus contains 2962 hypothesis with document label and true/false value indicating whether the document entails the hypothesis or not.
</nextsent>
<nextsent>up to our knowledge, sparte corpus in the only corpus aimed at evaluating rte systems in spanish.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4132">
<title id=" W10-1011.xml">a human computer collaboration approach to improve accuracy of an automated english scoring system </title>
<section> verb_subcat_err|6-7|.  </section>
<citcontext>
<prevsection>
<prevsent>150,419 pairs of the errors were assorted into 657 types.
</prevsent>
<prevsent>the frequency of each type of the candidates was then calculated.
</prevsent>
</prevsection>
<citsent citstr=" P94-1033 ">
these candidate errors were filtered by applying pmi (pointwise mutual informa tion) and rfc (relative frequency count) (su et al., 1994).<papid> P94-1033 </papid></citsent>
<aftsection>
<nextsent>)()( ),( log),( 21 21 21 epep eep eepmi = (1) freq eefreq eerfc ),( ),( 21 21 = (2) pmi is represented by number indicating how frequently two errors e1 and e2 occur simultaneously.
</nextsent>
<nextsent>rfc refers to relative frequency against average frequency of the total candidates.
</nextsent>
<nextsent>the filtering equation is as follows: keerfceepmi ??
</nextsent>
<nextsent>),(),( 2121 (3) using this equation, the system filtered the candidates whose value was above the threshold k. for this experiment, 0.4 was assigned to and 111 error types were selected.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4133">
<title id=" W10-1302.xml">automatic generation of conversational utterances and narrative for augmentative and alternative communication a prototype system </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>possibly the first technology to be included in many commercial systems to date was word prediction and completion.
</prevsent>
<prevsent>there have also been many research prototypes exploring the applicability of more emerging technologies such as named entity recognition from synthesized speech (wisenburn and higginbotham 2008), the generation of well-formed utterances from telegraphic input (mccoy, pennington et al 1998) and the automatic identification of contextual vocabulary from the web (higginbotham, bisantz et al 2008).
</prevsent>
</prevsection>
<citsent citstr=" N06-2027 ">
netzer and elhadad (2006) <papid> N06-2027 </papid>used nlg to allow these mantic authoring of utterances.</citsent>
<aftsection>
<nextsent>however, nlg, in the sense of data-to-text (reiter and dale 2000), has had limited application within aac thus far, although reiter et al (2009) <papid> W09-0601 </papid>showed it is possible to generate stories from sensor data which allow child using aac to tell others about their day at school.</nextsent>
<nextsent>2.3 system rationale.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4134">
<title id=" W10-1302.xml">automatic generation of conversational utterances and narrative for augmentative and alternative communication a prototype system </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>there have also been many research prototypes exploring the applicability of more emerging technologies such as named entity recognition from synthesized speech (wisenburn and higginbotham 2008), the generation of well-formed utterances from telegraphic input (mccoy, pennington et al 1998) and the automatic identification of contextual vocabulary from the web (higginbotham, bisantz et al 2008).
</prevsent>
<prevsent>netzer and elhadad (2006) <papid> N06-2027 </papid>used nlg to allow these mantic authoring of utterances.</prevsent>
</prevsection>
<citsent citstr=" W09-0601 ">
however, nlg, in the sense of data-to-text (reiter and dale 2000), has had limited application within aac thus far, although reiter et al (2009) <papid> W09-0601 </papid>showed it is possible to generate stories from sensor data which allow child using aac to tell others about their day at school.</citsent>
<aftsection>
<nextsent>2.3 system rationale.
</nextsent>
<nextsent>this project is exploring the use of nlg to produce conversational utterances in aac systems designed for social interaction.
</nextsent>
<nextsent>at the outset it was hoped that using nlg might address some of the difficulties observed in pre-storage systems.
</nextsent>
<nextsent>for instance, the generation component could theoretically produce range of utterances and speech act types automatically from the same underlying data and adapt these somewhat to the interac tional context.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4135">
<title id=" W10-0732.xml">non expert correction of automatically generated relation annotations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>slot filling, general form of relation extraction, includes relations between non entities, such as person and an occupation, age, or cause of death (mcnamee and dang, 2009).re annotated data, such as ace (2008), is expensive to produce so systems take different approaches to minimizing data needs.
</prevsent>
<prevsent>for example, tree kernels can reduce feature sparsity and generalize across many examples (guodong et al, 2007; zhou etal., 2009).
</prevsent>
</prevsection>
<citsent citstr=" P07-1073 ">
distant supervision automatically generates noisy training examples from knowledge base (kb) without needing annotations (bunescu and mooney, 2007; <papid> P07-1073 </papid>mintz et al, 2009).<papid> P09-1113 </papid></citsent>
<aftsection>
<nextsent>while this method can quickly generate training data, it also generates many false examples.
</nextsent>
<nextsent>we reduce the noise in such examples by using amazon mechanical turk (mturk), which has been shown to produce high quality annotations for variety of natural language processing tasks (snow et al, 2008).<papid> D08-1027 </papid></nextsent>
<nextsent>we use mturk for annotation of textual relation sto establish an inexpensive and rapid method of creating data for slot filling.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4136">
<title id=" W10-0732.xml">non expert correction of automatically generated relation annotations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>slot filling, general form of relation extraction, includes relations between non entities, such as person and an occupation, age, or cause of death (mcnamee and dang, 2009).re annotated data, such as ace (2008), is expensive to produce so systems take different approaches to minimizing data needs.
</prevsent>
<prevsent>for example, tree kernels can reduce feature sparsity and generalize across many examples (guodong et al, 2007; zhou etal., 2009).
</prevsent>
</prevsection>
<citsent citstr=" P09-1113 ">
distant supervision automatically generates noisy training examples from knowledge base (kb) without needing annotations (bunescu and mooney, 2007; <papid> P07-1073 </papid>mintz et al, 2009).<papid> P09-1113 </papid></citsent>
<aftsection>
<nextsent>while this method can quickly generate training data, it also generates many false examples.
</nextsent>
<nextsent>we reduce the noise in such examples by using amazon mechanical turk (mturk), which has been shown to produce high quality annotations for variety of natural language processing tasks (snow et al, 2008).<papid> D08-1027 </papid></nextsent>
<nextsent>we use mturk for annotation of textual relation sto establish an inexpensive and rapid method of creating data for slot filling.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4137">
<title id=" W10-0732.xml">non expert correction of automatically generated relation annotations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>distant supervision automatically generates noisy training examples from knowledge base (kb) without needing annotations (bunescu and mooney, 2007; <papid> P07-1073 </papid>mintz et al, 2009).<papid> P09-1113 </papid></prevsent>
<prevsent>while this method can quickly generate training data, it also generates many false examples.</prevsent>
</prevsection>
<citsent citstr=" D08-1027 ">
we reduce the noise in such examples by using amazon mechanical turk (mturk), which has been shown to produce high quality annotations for variety of natural language processing tasks (snow et al, 2008).<papid> D08-1027 </papid></citsent>
<aftsection>
<nextsent>we use mturk for annotation of textual relation sto establish an inexpensive and rapid method of creating data for slot filling.
</nextsent>
<nextsent>we present two step annotation process: (1) automatic creation of noisy examples, and (2) human validation of examples.
</nextsent>
<nextsent>2.1 automatic generation of noisy examples.
</nextsent>
<nextsent>to create noisy examples we use similar approach to mintz et al (2009).<papid> P09-1113 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4139">
<title id=" W10-3404.xml">textual entail maint recognition using word overlap mutual information and subpath set </title>
<section> related works.  </section>
<citcontext>
<prevsection>
<prevsent>the results 19 of the experiment yielded an accuracy of approximately 57%.
</prevsent>
<prevsent>we improved this method, and used it then as subpath set.
</prevsent>
</prevsection>
<citsent citstr=" W07-1407 ">
prodromos malakasiotis and ion androutsopoulos (prodromos malakasiotis and ion androutsopoulos, 2007) <papid> W07-1407 </papid>used support vector machines.</citsent>
<aftsection>
<nextsent>they assumed that the entailment judgment was true?
</nextsent>
<nextsent>when the similarity of words, pos tags and chunk tags were high.
</nextsent>
<nextsent>the results of the experiment yielded an accuracy of approximately 62%.
</nextsent>
<nextsent>however, they forgot to combine past rte methods as feature of svm.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4140">
<title id=" W10-3404.xml">textual entail maint recognition using word overlap mutual information and subpath set </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>moreover, we will propose new method for the feature of machine learning.
</prevsent>
<prevsent>we will also consider to expand wordnet.
</prevsent>
</prevsection>
<citsent citstr=" P09-1051 ">
shnarch et al  (shnarch et al , 2009) <papid> P09-1051 </papid>researched the extraction from wikipedia of lexical reference rules, identifying references to term meaning triggered by other terms.</citsent>
<aftsection>
<nextsent>they evaluated their lexical reference relation for rte.
</nextsent>
<nextsent>they improved previous rte methods.
</nextsent>
<nextsent>we will use their method for ours in order to expand japanese wordnet.
</nextsent>
<nextsent>we believe that this can help us improve our method/results.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4141">
<title id=" W10-0903.xml">semantic enrichment of text with background knowledge </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>surprisingly, we find that some quite simple processing can be effective if we are able to con textualize the text under interpretation.
</prevsent>
<prevsent>for our exploratory experiments, we are working with collection of 30,000 documents in the domain of us football.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
we parsed the collection using standard dependency parser (marneffe and manning, 2008; klein and maning, 2003) <papid> P03-1054 </papid>and, after collapsing some syntactic dependencies, obtained the simple textual representations shown in section 2.</citsent>
<aftsection>
<nextsent>from them, we built background knowledge base by automatically harvesting propositions expressed in the collection (section 3).
</nextsent>
<nextsent>their frequency in the collection lead the enrichment process: given new text in the same domain, we build exactly the same kind of representation, and attach the background knowledge propositions as related to the text (section 4).
</nextsent>
<nextsent>since this is an exploratory sketch, we cannot provide quantitative evaluation yet, but the qualitative study over some examples suggest that this simple framework is promising enough to start long term research (section 5).
</nextsent>
<nextsent>finally, we conclude with the next steps we want to follow and the kind of evaluation we plan to do.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4143">
<title id=" W10-1815.xml">characteristics of high agreement affect annotation in text </title>
<section> corpus data overview.  </section>
<citcontext>
<prevsection>
<prevsent>affect, which is highly subjective, is arguably better captured by flexible acceptability.5fig.
</prevsent>
<prevsent>1 shows that sentences only labeled neutral were frequent, as were disagreements, which were more common for sentences marked both with neutral and one or more affectclasses.
</prevsent>
</prevsection>
<citsent citstr=" H05-1044 ">
this parallels findings for polarity expressions in subjective texts (wilson et al 2005), <papid> H05-1044 </papid>and shows that the border between affective and neutral is fuzzy.</citsent>
<aftsection>
<nextsent>(affect perception lacks clear definitions and is subjective, and neutrality suffers fromthe same dilemma.)
</nextsent>
<nextsent>a sentence with high agreement affect was defined as all four primary emotion and mood labels having the same affective label (given the merged label set).
</nextsent>
<nextsent>these were more common than mixed affective labels.
</nextsent>
<nextsent>this section examines the subset of high agreement sentences in the h. c. andersen data froma qualitative-interpretive perspective.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4144">
<title id=" W10-1815.xml">characteristics of high agreement affect annotation in text </title>
<section> high agreement in h. c. andersen.  </section>
<citcontext>
<prevsection>
<prevsent>angry-disgusted: they buzzed round the prince and stung his face and hands; angrily he drew his sword and brandished it, but he only touched the air and did not hit the gnats.
</prevsent>
<prevsent>(villain1,2) that narration can directly announce affective states is an indication of the important narrative role affect can play in stories.
</prevsent>
</prevsection>
<citsent citstr=" W03-2102 ">
also, wilson and wiebe (2003) <papid> W03-2102 </papid>interestingly noted that annotators agreed more strongly with strong subjective expressions, which affect words are examples of.</citsent>
<aftsection>
<nextsent>some illustrative affect words from the examined data are (for surprised): alarmed, astonished,astonishment, shocked, shocking, startled, surprised.
</nextsent>
<nextsent>special cases include negation (e.g. not happy for sad); figurative/idiomatic phrases (e.g.one of his heartstrings had broken for sad); or appearance with more than one affect (e.g. anguish for sad or fearful).
</nextsent>
<nextsent>4.1.2 words for related/contrastive affect states expressions in the sentential context naming related or contrastive affective states not in the label set (e.g. dull, pride, relief, or shame) may also help evoke particular affect, as in: happy: they looked at little claus ploughing with his five horses, and he was so proud that he smacked his whip, and said, gee-up, my five horses.?
</nextsent>
<nextsent>(hero1,2) 4.1.3 affect related words or expressions lexical items or phrases which describe actions, properties, behaviors, cognitive states, or objects associated with particular affects occur frequently in the examined high agreement subset, e.g. as in: happy: they laughed and they wept; and peter embraced the old fire-drum.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4145">
<title id=" W10-2102.xml">evidentiality for text trustworthiness detection </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>finally, in section 5 we discuss the experiment results and conclude the current research.
</prevsent>
<prevsent>the research of text trustworthiness is very helpful for many other natural language processing applications.
</prevsent>
</prevsection>
<citsent citstr=" N09-2040 ">
for example, in their research on question answering, banerjee and han (2009) <papid> N09-2040 </papid>modulate answer grade by using weighted combination of the original score and answer credibility evaluation.</citsent>
<aftsection>
<nextsent>also, weerkamp and rijke (2008) <papid> P08-1105 </papid>incorporate textual credibility indicators in the retrieval process to improve topical blog posts retrieval.</nextsent>
<nextsent>gyongyi et al(2004) propose trust rank algorithm for semi automatically separating reputable, good web pages from spams.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4146">
<title id=" W10-2102.xml">evidentiality for text trustworthiness detection </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the research of text trustworthiness is very helpful for many other natural language processing applications.
</prevsent>
<prevsent>for example, in their research on question answering, banerjee and han (2009) <papid> N09-2040 </papid>modulate answer grade by using weighted combination of the original score and answer credibility evaluation.</prevsent>
</prevsection>
<citsent citstr=" P08-1105 ">
also, weerkamp and rijke (2008) <papid> P08-1105 </papid>incorporate textual credibility indicators in the retrieval process to improve topical blog posts retrieval.</citsent>
<aftsection>
<nextsent>gyongyi et al(2004) propose trust rank algorithm for semi automatically separating reputable, good web pages from spams.
</nextsent>
<nextsent>2.1 general approaches for text trust-.
</nextsent>
<nextsent>worthiness detection in past research, the judgment for the trustworthiness or credibility of given text content is usually tackled from two aspects: entity oriented and content oriented (rubin and liddy, 2005).
</nextsent>
<nextsent>the former approach takes into consideration the information providers?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4151">
<title id=" W10-3406.xml">how to expand dictionaries by web mining techniques </title>
<section> expanding conceptual classes.  </section>
<citcontext>
<prevsection>
<prevsent>this kind of method uses information regarding the popularity?
</prevsent>
<prevsent>of the web and is in-dependent of particular corpus.
</prevsent>
</prevsection>
<citsent citstr=" P08-1052 ">
our method of acquisition is quite similar to that of (nakov and hearst, 2008).<papid> P08-1052 </papid></citsent>
<aftsection>
<nextsent>these authors propose to query the web using the google search engine to characterize the semantic rela-tion between pair of nouns.
</nextsent>
<nextsent>the google star operator among others, is used to that end.
</nextsent>
<nextsent>(na-kov and hearst, 2008) <papid> P08-1052 </papid>refer to the study of (lin and pantel, 2001) who used web mining ap-proach to discover inference rules missed by humans.</nextsent>
<nextsent>to apply our method, we first consider the common objects of semantically close verbs, which are instances of reference concepts (e.g. vehicle).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4153">
<title id=" W10-3004.xml">a hedge hop over a max margin framework using hedge cues </title>
<section> introduction and related work.  </section>
<citcontext>
<prevsection>
<prevsent>they adopted bag-of-words representation of text sentences occurring in medline abstracts and reported on preliminary results obtained.
</prevsent>
<prevsent>as baseline they used an algorithm based on finding speculative sentences by simply checking whether any cue (from given list of 14 cues) occurs in the sentence to be classified.
</prevsent>
</prevsection>
<citsent citstr=" P07-1125 ">
medlock and briscoe (2007) <papid> P07-1125 </papid>also used single words as input features in order to classify sentences from scientific articles in biomedical domain as speculative or non-speculative.</citsent>
<aftsection>
<nextsent>in first step they employed weakly supervised bayesian learning model in order to derive the probability of each word to represent hedge cue.
</nextsent>
<nextsent>in the next step, they perform feature selection based on these probabilities.
</nextsent>
<nextsent>in the last step classifier trained on given number of selected features was applied.
</nextsent>
<nextsent>medlock and briscoe (2007) <papid> P07-1125 </papid>use similar baseline as the one adopted by light et al (2004), i.e. nave algorithm based on substring matching, but with different list of terms to match against.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4168">
<title id=" W10-3004.xml">a hedge hop over a max margin framework using hedge cues </title>
<section> introduction and related work.  </section>
<citcontext>
<prevsection>
<prevsent>their baseline has recall/precision break-even point of 0.60, while their system improves the accuracy to recall/precision break-even point of 0.76.
</prevsent>
<prevsent>however medlock and briscoe (2007) <papid> P07-1125 </papid>note that their model is unsuccessful in identifying assertive statements of knowledge paucity which are generally marked rather syntactically than lexically.</prevsent>
</prevsection>
<citsent citstr=" W08-0607 ">
kilicoglu and bergler (2008) <papid> W08-0607 </papid>proposed semiautomatic approach incorporating syntactic and some semantic information in order to enrich or refine list of lexical hedging cues that are used as input features for automatic detection of uncertain sentences in the biomedical domain.</citsent>
<aftsection>
<nextsent>they also used lexical cues and syntactic patterns that strongly suggest non-speculative contexts (unhedges?).
</nextsent>
<nextsent>then they manually expanded and refined the set of lexical hedging and unhedging?
</nextsent>
<nextsent>cues using conceptual semantic and lexical relations extracted from wordnet (fellbaum, 1998) and the umls specialist lexicon (mccray et al 1994).
</nextsent>
<nextsent>kilicoglu and bergler (2008) <papid> W08-0607 </papid>did experiments on the same dataset as medlock and briscoe (2007) <papid> P07-1125 </papid>and their experimental results proved that the classification accuracy can be improved by approximately 9% (from an f-score of 76% to an f-score of 85%) if syntactic and semantic information are incorporated.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4182">
<title id=" W10-3004.xml">a hedge hop over a max margin framework using hedge cues </title>
<section> introduction and related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, medlock (2008) illustrates that whether particular term acts as hedge cue is quite often rather subtle function of its sense usage, in which case the distinctions may well not be captured by part-of-speech tagging?.
</prevsent>
<prevsent>mra et al (2009) also used machine learning framework based on lexical input features and part-of-speech tags.
</prevsent>
</prevsection>
<citsent citstr=" P09-2044 ">
other recent work on hedge detection (ganter and strube, 2009; <papid> P09-2044 </papid>marco and mercer, 2004; mercer et al, 2004; morante and daelemans, 2009<papid> W09-1304 </papid>a; szarvas, 2008) relied primarily on word frequencies as primary features including various shallow syntactic or semantic information.</citsent>
<aftsection>
<nextsent>the corpora made available in the conll shared task (farkas et al, 2010; vincze et al, 2008) contains multi-word expressions that have been annotated by linguists as cue words tending to express hedging.
</nextsent>
<nextsent>in this paper, we test whether it might suffice to relyon this list of cues alone for automatic hedge detection.
</nextsent>
<nextsent>the classification results reported on are obtained using support vector machines trained with features essentially incorporating lexical information, i.e. features extracted from the list of hedge cues provided with the training corpus.
</nextsent>
<nextsent>in the following, we will first describe some preliminary considerations regarding the results that can be achieved using nave baseline algorithm (section 2).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4183">
<title id=" W10-3004.xml">a hedge hop over a max margin framework using hedge cues </title>
<section> introduction and related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, medlock (2008) illustrates that whether particular term acts as hedge cue is quite often rather subtle function of its sense usage, in which case the distinctions may well not be captured by part-of-speech tagging?.
</prevsent>
<prevsent>mra et al (2009) also used machine learning framework based on lexical input features and part-of-speech tags.
</prevsent>
</prevsection>
<citsent citstr=" W09-1304 ">
other recent work on hedge detection (ganter and strube, 2009; <papid> P09-2044 </papid>marco and mercer, 2004; mercer et al, 2004; morante and daelemans, 2009<papid> W09-1304 </papid>a; szarvas, 2008) relied primarily on word frequencies as primary features including various shallow syntactic or semantic information.</citsent>
<aftsection>
<nextsent>the corpora made available in the conll shared task (farkas et al, 2010; vincze et al, 2008) contains multi-word expressions that have been annotated by linguists as cue words tending to express hedging.
</nextsent>
<nextsent>in this paper, we test whether it might suffice to relyon this list of cues alone for automatic hedge detection.
</nextsent>
<nextsent>the classification results reported on are obtained using support vector machines trained with features essentially incorporating lexical information, i.e. features extracted from the list of hedge cues provided with the training corpus.
</nextsent>
<nextsent>in the following, we will first describe some preliminary considerations regarding the results that can be achieved using nave baseline algorithm (section 2).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4184">
<title id=" W10-1817.xml">the unified annotation of syntax and discourse in the copenhagen dependency treebanks </title>
<section> the discourse annotation of the cdt.  </section>
<citcontext>
<prevsection>
<prevsent>basically, the cdt discourse annotation consists in linking up each such sentence top node with its nucleus (under stood as the unique word within another sentence that is deemed to govern the relation) and labelling the relations between the two nodes.
</prevsent>
<prevsent>the inventory of discourse relations in cdt is described in the cdt manual.
</prevsent>
</prevsection>
<citsent citstr=" W01-1605 ">
it borrows heavily from other discourse frameworks, in particular rhetorical structure theory, rst (mann and thompson, 1987; tabaoda and mann, 2006; carlson et al, 2001) <papid> W01-1605 </papid>and the penn discourse treebank, pdtb (webber 2004; dinesh et al., 2005, <papid> W05-0305 </papid>prasad et al., 2007, 2008), as well as (korzen, 2006, 2007), although the inventory had to be extended to accommodate the great in relative clauses, the relative verb functions as the head, i.e., the arrow goes from (book)?</citsent>
<aftsection>
<nextsent>to was (written)?.
</nextsent>
<nextsent>5in terms of their formal semantics, complements function as arguments to their governor, whereas adjuncts function as modifiers; i.e., semantically, the governor (type x) acts as an argument with the modifier (type x/x) as its functor.
</nextsent>
<nextsent>128 variety of text types in the cdt corpus other than news stories.
</nextsent>
<nextsent>the inventory allows relation names to be formed as dis junctions or conjunctions of simple relation names, to specify multiple relations or ambiguous alternatives.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4185">
<title id=" W10-1817.xml">the unified annotation of syntax and discourse in the copenhagen dependency treebanks </title>
<section> the discourse annotation of the cdt.  </section>
<citcontext>
<prevsection>
<prevsent>basically, the cdt discourse annotation consists in linking up each such sentence top node with its nucleus (under stood as the unique word within another sentence that is deemed to govern the relation) and labelling the relations between the two nodes.
</prevsent>
<prevsent>the inventory of discourse relations in cdt is described in the cdt manual.
</prevsent>
</prevsection>
<citsent citstr=" W05-0305 ">
it borrows heavily from other discourse frameworks, in particular rhetorical structure theory, rst (mann and thompson, 1987; tabaoda and mann, 2006; carlson et al, 2001) <papid> W01-1605 </papid>and the penn discourse treebank, pdtb (webber 2004; dinesh et al., 2005, <papid> W05-0305 </papid>prasad et al., 2007, 2008), as well as (korzen, 2006, 2007), although the inventory had to be extended to accommodate the great in relative clauses, the relative verb functions as the head, i.e., the arrow goes from (book)?</citsent>
<aftsection>
<nextsent>to was (written)?.
</nextsent>
<nextsent>5in terms of their formal semantics, complements function as arguments to their governor, whereas adjuncts function as modifiers; i.e., semantically, the governor (type x) acts as an argument with the modifier (type x/x) as its functor.
</nextsent>
<nextsent>128 variety of text types in the cdt corpus other than news stories.
</nextsent>
<nextsent>the inventory allows relation names to be formed as dis junctions or conjunctions of simple relation names, to specify multiple relations or ambiguous alternatives.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4186">
<title id=" W10-1817.xml">the unified annotation of syntax and discourse in the copenhagen dependency treebanks </title>
<section> the discourse annotation of the cdt.  </section>
<citcontext>
<prevsection>
<prevsent>the inventory allows relation names to be formed as dis junctions or conjunctions of simple relation names, to specify multiple relations or ambiguous alternatives.
</prevsent>
<prevsent>one of the most important differences between the cdt framework and other discourse frameworks lies in the way texts are segmented.
</prevsent>
</prevsection>
<citsent citstr=" J05-2005 ">
in particular, cdt uses words as the basic building blocks in the discourse structure, while most other discourse frameworks use clauses as their atomic discourse units, including rst, pdtb, graph bank (wolf and gibson, 2005), <papid> J05-2005 </papid>and the potts dam commentary corpus, pcc (stede 2009).6 this allows the nucleus and satellite in discourse relation to be identified precisely by means of their headwords, as in the example (1) below from the cdt corpus, where the second paragraph is analyzed as an elaboration of the de verbal noun phrase their judgment?</citsent>
<aftsection>
<nextsent>(words that are included in our condensed cdt analysis in figure 4 are indicated with boldface and sub scripted with numbers that identify them):6as noted by carlson and marcu (2001), the boundary between syntax and discourse is rather unclear: the same meaning can be expressed in continuum of ways that range from clear discourse constructions (he laughed.
</nextsent>
<nextsent>that annoyed me.?)
</nextsent>
<nextsent>to clear syntactic constructions (his laugh annoyed me.?).
</nextsent>
<nextsent>moreover, long discourse units may function as objects of attribution verbs in direct or indirect speech, or as parenthetical remarks embedded within an otherwise normal sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4188">
<title id=" W10-1735.xml">chunk based verb reordering in vso sentences for arabic english statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>from this analysis, specific verb reordering lattices arethen built on the test sentences before decoding them.
</prevsent>
<prevsent>the application of our reordering methods on the training and test sets results inconsistent bleu score improvements on the nist-mt 2009 arabic english benchmark.
</prevsent>
</prevsection>
<citsent citstr=" W09-0434 ">
shortcomings of phrase-based statistical machine translation (psmt) with respect to word reordering have been recently shown on the arabic english pair by birch et al (2009).<papid> W09-0434 </papid></citsent>
<aftsection>
<nextsent>an empirical investigation of the output of strong baseline we developed with the moses toolkit (koehn et al., 2007) <papid> P07-2045 </papid>for the nist 2009 evaluation, revealed that an evident cause of syntactic dis fluency is the anticipation of the verb in arabic verb-subject object (vso) sentences ? class that is highly represented in the news genre1.</nextsent>
<nextsent>fig.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4189">
<title id=" W10-1735.xml">chunk based verb reordering in vso sentences for arabic english statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the application of our reordering methods on the training and test sets results inconsistent bleu score improvements on the nist-mt 2009 arabic english benchmark.
</prevsent>
<prevsent>shortcomings of phrase-based statistical machine translation (psmt) with respect to word reordering have been recently shown on the arabic english pair by birch et al (2009).<papid> W09-0434 </papid></prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
an empirical investigation of the output of strong baseline we developed with the moses toolkit (koehn et al., 2007) <papid> P07-2045 </papid>for the nist 2009 evaluation, revealed that an evident cause of syntactic dis fluency is the anticipation of the verb in arabic verb-subject object (vso) sentences ? class that is highly represented in the news genre1.</citsent>
<aftsection>
<nextsent>fig.
</nextsent>
<nextsent>1 shows two examples where the arabic main verb phrase comes before the subject.
</nextsent>
<nextsent>in such sentences, the subject can be followed by adjectives, adverbs, coordinations, or appositions that further increase the distance between the verb 1in fact, arabic syntax admits both svo and vso orders.
</nextsent>
<nextsent>and its object.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4190">
<title id=" W10-1735.xml">chunk based verb reordering in vso sentences for arabic english statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in such sentences, the subject can be followed by adjectives, adverbs, coordinations, or appositions that further increase the distance between the verb 1in fact, arabic syntax admits both svo and vso orders.
</prevsent>
<prevsent>and its object.
</prevsent>
</prevsection>
<citsent citstr=" P01-1030 ">
when translating into english ? primarily svo language ? the resulting long verb reorderings are often missed by the psmt decoder either because of pure modeling errors or because of search errors (germann et al, 2001): <papid> P01-1030 </papid>i.e. their span is longer than the maximum allowed distortion distance, or the correct reordering hypothesis does not emerge from the explored search space because of low score.</citsent>
<aftsection>
<nextsent>in the two examples, the missed verb reorderings result in different translation errors by the decoder, respectively, the introduction of subject pronoun before the verb and, even worse, ver bless sentence.
</nextsent>
<nextsent>in arabic-english machine translation, other kinds of reordering are of course very frequent: for instance, adjectival modifiers following their noun and head-initial genitive constructions (idafa).these, however, appear to be mostly local, therefore more likely to be modeled through phrase internal alignments, or to be captured by the reordering capabilities of the decoder.
</nextsent>
<nextsent>in general there is aquite uneven distribution of word-reordering phenomena in arabic-english, and long-range movements concentrate on few patterns.
</nextsent>
<nextsent>reordering in psmt is typically performed by (i) constraining the maximum allowed word movement and exponentially penalizing long reorderings (distortion limit and penalty), and (ii) through so-called lexicalized orientation models (och et al, 2004; koehn et al, 2007; <papid> P07-2045 </papid>galley and manning, 2008).<papid> D08-1089 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4192">
<title id=" W10-1735.xml">chunk based verb reordering in vso sentences for arabic english statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in arabic-english machine translation, other kinds of reordering are of course very frequent: for instance, adjectival modifiers following their noun and head-initial genitive constructions (idafa).these, however, appear to be mostly local, therefore more likely to be modeled through phrase internal alignments, or to be captured by the reordering capabilities of the decoder.
</prevsent>
<prevsent>in general there is aquite uneven distribution of word-reordering phenomena in arabic-english, and long-range movements concentrate on few patterns.
</prevsent>
</prevsection>
<citsent citstr=" D08-1089 ">
reordering in psmt is typically performed by (i) constraining the maximum allowed word movement and exponentially penalizing long reorderings (distortion limit and penalty), and (ii) through so-called lexicalized orientation models (och et al, 2004; koehn et al, 2007; <papid> P07-2045 </papid>galley and manning, 2008).<papid> D08-1089 </papid></citsent>
<aftsection>
<nextsent>while the former is mainly aimed at reducing the computational complexity of the decoding algorithm, the latter assigns at each decoding step score to the next source phrase to cover, according to its orientation with respect to the last translated phrase.
</nextsent>
<nextsent>in fact, neither method discriminates among different reordering distances for specific word or syntactic class.
</nextsent>
<nextsent>toour view, this could be reason for their inadequacy to properly deal with the reordering peculiarities of the arabic-english language pair.
</nextsent>
<nextsent>in 235 src: astdet kl mn alsewdyp lybya swryasubj sfra?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4193">
<title id=" W10-1735.xml">chunk based verb reordering in vso sentences for arabic english statistical machine translation </title>
<section> analysis of verb reordering.  </section>
<citcontext>
<prevsection>
<prevsent>236figure 2: percentage of verb reorderings by maximum shift (0 stands for no movement).
</prevsent>
<prevsent>agree with amira-style segmentation.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
for the second corpus (eval08-nw), we filtered out sentences longer than 80 tokens in order to make word alignment feasible with giza++ (och and ney, 2003).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>we then used the intersection of the direct and inverse alignments, as computed bymoses.
</nextsent>
<nextsent>the choice of such high-precision, low recall alignment set is supported by the findings of habash (2007) on syntactic rule extraction from parallel corpora.
</nextsent>
<nextsent>3.1 the verbs dance.
</nextsent>
<nextsent>there are 1,955 verb phrases in gale-nw and 11,833 in eval08-nw.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4194">
<title id=" W10-1735.xml">chunk based verb reordering in vso sentences for arabic english statistical machine translation </title>
<section> preliminary experiments.  </section>
<citcontext>
<prevsection>
<prevsent>given our experimental setting, one could argue that our bleu score is biased because one of the references was also used to generate theverb reordering.
</prevsent>
<prevsent>however, in series of experiments not reported here, we evaluated the same systems using only the remaining three reference sand observed similar trends as when all four references are used.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
feature weights were optimized through mert(och, 2003) <papid> P03-1021 </papid>on the newswire section of the nistmt06 evaluation set (dev06-nw), in the original version for the baseline system, in the verb reordered version for the reordered system.</citsent>
<aftsection>
<nextsent>4ldc2007t08, 2003t07, 2004e72, 2004t17, 2004t18, 2005e46, 2006e25, 2006e44 and ldc2006e39 ? the two last with first reference only.
</nextsent>
<nextsent>figure 4: bleu scores of baseline and reordered system on plain and oracle reordered eval08-nw.
</nextsent>
<nextsent>fig.
</nextsent>
<nextsent>4 shows the results in terms of bleu score for (i) the baseline system, (ii) the reordered system on plain version of eval08-nw and (iii) the reordered system on the reordered test.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4195">
<title id=" W10-1735.xml">chunk based verb reordering in vso sentences for arabic english statistical machine translation </title>
<section> verb reordering lattices.  </section>
<citcontext>
<prevsection>
<prevsent>as in real working conditions word alignments of the input text are not available, we explore reordering lattice approach.
</prevsent>
<prevsent>5.1 lattice construction.
</prevsent>
</prevsection>
<citsent citstr=" P08-1115 ">
firstly conceived to optimally encode multiple transcription hypothesis produced by speech recognizer, word lattices have later been used to represent various forms of input ambiguity, mainly atthe level of token boundaries (e.g. word segmentation, morphological decomposition, word decom pounding (dyer et al, 2008)).<papid> P08-1115 </papid>a main problem when dealing with permutations is that the lattice size can grow very quickly when medium to long reorderings are represented.we are particularly concerned with this issue because our decoding will perform additional reordering on the lattice input.</citsent>
<aftsection>
<nextsent>thanks to there strictions we set on our verb movement reordering rules described insect.
</nextsent>
<nextsent>2 ? i.e. only reordering between chunks and no overlap between consecutive verb chunks movement ? we are able to produce quite compact word lattices.
</nextsent>
<nextsent>fig.
</nextsent>
<nextsent>5 illustrates how chunk-based reordering lattice is generated.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4197">
<title id=" W10-1735.xml">chunk based verb reordering in vso sentences for arabic english statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the rules involve reordering of syntactic constituents and are applied in deterministic way (always the most probable) as preprocessing of training and test data.
</prevsent>
<prevsent>the technique achieves consistent improvements only in very restrictive conditions:maximum phrase size of 1 and monotonic decoding, thus failing to enhance the existing reordering capabilities of psmt.
</prevsent>
</prevsection>
<citsent citstr=" W08-0307 ">
in (crego and habash,2008; <papid> W08-0307 </papid>elming and habash, 2009) <papid> W09-0809 </papid>possible in put permutations are represented through word graph, which is then processed by monotonic phrase or n-gram-based decoder.</citsent>
<aftsection>
<nextsent>thus, these approaches are conceived as alternatives, rather than integrations, to psmt reordering.
</nextsent>
<nextsent>on the contrary,we focused on single type of significant long reorderings, in order to integrate class-specific reordering methods into standard psmt system.
</nextsent>
<nextsent>to our knowledge, the work by niehues andkolss (2009) <papid> W09-0435 </papid>on german-english is the only example of lattice-based reordering approach being coupled with reordering at decoding time.</nextsent>
<nextsent>intheir paper, discontinuous non-deterministic pos based rules learned from word-aligned corpus are applied to german sentences in the form of weighted edges in word lattice.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4198">
<title id=" W10-1735.xml">chunk based verb reordering in vso sentences for arabic english statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the rules involve reordering of syntactic constituents and are applied in deterministic way (always the most probable) as preprocessing of training and test data.
</prevsent>
<prevsent>the technique achieves consistent improvements only in very restrictive conditions:maximum phrase size of 1 and monotonic decoding, thus failing to enhance the existing reordering capabilities of psmt.
</prevsent>
</prevsection>
<citsent citstr=" W09-0809 ">
in (crego and habash,2008; <papid> W08-0307 </papid>elming and habash, 2009) <papid> W09-0809 </papid>possible in put permutations are represented through word graph, which is then processed by monotonic phrase or n-gram-based decoder.</citsent>
<aftsection>
<nextsent>thus, these approaches are conceived as alternatives, rather than integrations, to psmt reordering.
</nextsent>
<nextsent>on the contrary,we focused on single type of significant long reorderings, in order to integrate class-specific reordering methods into standard psmt system.
</nextsent>
<nextsent>to our knowledge, the work by niehues andkolss (2009) <papid> W09-0435 </papid>on german-english is the only example of lattice-based reordering approach being coupled with reordering at decoding time.</nextsent>
<nextsent>intheir paper, discontinuous non-deterministic pos based rules learned from word-aligned corpus are applied to german sentences in the form of weighted edges in word lattice.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4199">
<title id=" W10-1735.xml">chunk based verb reordering in vso sentences for arabic english statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>thus, these approaches are conceived as alternatives, rather than integrations, to psmt reordering.
</prevsent>
<prevsent>on the contrary,we focused on single type of significant long reorderings, in order to integrate class-specific reordering methods into standard psmt system.
</prevsent>
</prevsection>
<citsent citstr=" W09-0435 ">
to our knowledge, the work by niehues andkolss (2009) <papid> W09-0435 </papid>on german-english is the only example of lattice-based reordering approach being coupled with reordering at decoding time.</citsent>
<aftsection>
<nextsent>intheir paper, discontinuous non-deterministic pos based rules learned from word-aligned corpus are applied to german sentences in the form of weighted edges in word lattice.
</nextsent>
<nextsent>their phrase based decoder admits local reordering within fixed window of 2 words, while, in our work, we performed experiments up to distortion limit of 10.
</nextsent>
<nextsent>another major difference is that we used shal-.
</nextsent>
<nextsent>low syntax annotation to effectively reduce the number of possible permutations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4200">
<title id=" W10-1907.xml">improving summarization of biomedical documents using word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>researchers can use summaries to quickly determine whether document is of interest without having to read it all.
</prevsent>
<prevsent>summarization systems usually work with are presentation of the document consisting of information that can be directly extracted from the document itself (erkan and radev, 2004; mihalcea and tarau, 2004).
</prevsent>
</prevsection>
<citsent citstr=" W08-2008 ">
however, recent studies have demonstrated the benefit of summarization based on richer representations that make use of external knowledge sources (plaza et al, 2008; <papid> W08-2008 </papid>fiszman etal., 2004).<papid> W04-2611 </papid></citsent>
<aftsection>
<nextsent>these approaches can represent semantic associations between the words and terms in the document (i.e. synonymy, hypernymy, homonymyor co-occurrence) and use this information to improve the quality of the summaries.
</nextsent>
<nextsent>in the biomedical domain the unified medical language system (umls) (nelson et al, 2002) has proved to be useful knowledge source for summarization (fiszman et al, 2004; <papid> W04-2611 </papid>reeve et al, 2007; plaza etal., 2008).<papid> W08-2008 </papid></nextsent>
<nextsent>in order to access the information contained in the umls, the vocabulary of the document being summarized has to be mapped ontoit.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4201">
<title id=" W10-1907.xml">improving summarization of biomedical documents using word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>researchers can use summaries to quickly determine whether document is of interest without having to read it all.
</prevsent>
<prevsent>summarization systems usually work with are presentation of the document consisting of information that can be directly extracted from the document itself (erkan and radev, 2004; mihalcea and tarau, 2004).
</prevsent>
</prevsection>
<citsent citstr=" W04-2611 ">
however, recent studies have demonstrated the benefit of summarization based on richer representations that make use of external knowledge sources (plaza et al, 2008; <papid> W08-2008 </papid>fiszman etal., 2004).<papid> W04-2611 </papid></citsent>
<aftsection>
<nextsent>these approaches can represent semantic associations between the words and terms in the document (i.e. synonymy, hypernymy, homonymyor co-occurrence) and use this information to improve the quality of the summaries.
</nextsent>
<nextsent>in the biomedical domain the unified medical language system (umls) (nelson et al, 2002) has proved to be useful knowledge source for summarization (fiszman et al, 2004; <papid> W04-2611 </papid>reeve et al, 2007; plaza etal., 2008).<papid> W08-2008 </papid></nextsent>
<nextsent>in order to access the information contained in the umls, the vocabulary of the document being summarized has to be mapped ontoit.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4205">
<title id=" W10-1907.xml">improving summarization of biomedical documents using word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>and cold temperature?.the purpose of this paper is to study the effect of lexical ambiguity in the knowledge source on semantic approaches to biomedical summarization.
</prevsent>
<prevsent>to this end, the paper describes concept based summarization system for biomedical documents that uses the umls as an external knowledge source.
</prevsent>
</prevsection>
<citsent citstr=" E09-1005 ">
to address the word ambiguity problem, we have adapted an existing wsd system (agirre and soroa, 2009) <papid> E09-1005 </papid>to assign concepts fromthe umls.</citsent>
<aftsection>
<nextsent>the system is applied to the summarization of 150 biomedical scientific articles from the biomed central corpus and it is found that 55 wsd improves the quality of the summaries.
</nextsent>
<nextsent>this paper is, to our knowledge, the first to apply wsd to the summarization of biomedical document sand also demonstrates that this leads to an improvement in performance.the next section describes related work on summarization and wsd.
</nextsent>
<nextsent>section 3 introduces theumls resources used in the wsd and summarization systems.
</nextsent>
<nextsent>section 4 describes our concept-based summarization algorithm.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4207">
<title id=" W10-1907.xml">improving summarization of biomedical documents using word sense disambiguation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>this problem can be partially solved by dealing with concepts and semantic relations from domain-specific resources, rather than terms and lexical or syntactic relations.
</prevsent>
<prevsent>consequently, some recent approaches have adapted existing methods to represent the document at conceptual level.
</prevsent>
</prevsection>
<citsent citstr=" W97-0703 ">
in particular, in the biomedical domain reeve et al(2007) adapt the lexical chaining approach (barzilay and elhadad, 1997) <papid> W97-0703 </papid>to work with umls concepts, using the metamap transfer tool to annotate these concepts.</citsent>
<aftsection>
<nextsent>yoo et al (2007) represent corpus of documents as graph, where the nodes are the mesh descriptors found in the corpus, and the edges represent hypernymy and co-occurrence relations between them.
</nextsent>
<nextsent>they cluster the mesh concepts in the corpus to identify sets of documents dealing with the same topic and then generate summary from each document cluster.
</nextsent>
<nextsent>word sense disambiguation attempts to solve lexical ambiguities by identifying the correct meaning of word based on its context.
</nextsent>
<nextsent>supervised approaches have been shown to perform better than unsupervised ones (agirre and edmonds, 2006) but need large amounts of manually-tagged data, which are often unavailable or impractical to create.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4221">
<title id=" W10-2608.xml">frustratingly easy semi supervised domain adaptation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>subsequently, this framework (evgeniou and pontil, 2004) was extended (dredze et al, 2010) to online multi domain setting.
</prevsent>
<prevsent>prior work on semi-supervisedapproaches to domain adaptation also exists in literature.
</prevsent>
</prevsection>
<citsent citstr=" W06-1615 ">
extraction of specific features from the available dataset was proposed (arnold and cohen, 2008; blitzer et al, 2006) <papid> W06-1615 </papid>to facilitate the task of domain adaptation.</citsent>
<aftsection>
<nextsent>co-adaptation (tur, 2009), combination of co-training and domain adaptation, can also be considered as semi supervised approach to domain adaptation.
</nextsent>
<nextsent>asemi-supervised em algorithm for domain adaptation was proposed in (dai et al, 2007).
</nextsent>
<nextsent>similar to graph based semi-supervised approaches, label propagation method was proposed (xing et al, 2007) to facilitate domain adaptation.
</nextsent>
<nextsent>the recently proposed domain adaptation machine (dam) (duan et al, 2009) is semi-supervised extension of svms for domain adaptation and presents extensive empirical results.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4223">
<title id=" W10-1736.xml">head finalization a simple reordering rule for sov languages </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>conventional statistical machine translation (smt) systems work well within each of these language families.
</prevsent>
<prevsent>however, smt-based translation from an svo language to an sov language does not work well because their word orders are completely different.
</prevsent>
</prevsection>
<citsent citstr=" N09-1028 ">
recently, few groups have proposed rule based preprocessing methods to mitigate this problem (xu et al , 2009; <papid> N09-1028 </papid>hong et al ,2009).<papid> P09-2059 </papid></citsent>
<aftsection>
<nextsent>these methods rewrite svo sentences to derive more sov-like sentences by using set of handcrafted rules.
</nextsent>
<nextsent>in this paper, we propose an alternative single reordering rule: head finalization.
</nextsent>
<nextsent>this is syntax-based preprocessing approach that offers the advantage of simplicity.
</nextsent>
<nextsent>wedo not have to be concerned about part of-speech tags or rule weights because the powerful enju parser allows us to implement the rule at general level.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4224">
<title id=" W10-1736.xml">head finalization a simple reordering rule for sov languages </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>conventional statistical machine translation (smt) systems work well within each of these language families.
</prevsent>
<prevsent>however, smt-based translation from an svo language to an sov language does not work well because their word orders are completely different.
</prevsent>
</prevsection>
<citsent citstr=" P09-2059 ">
recently, few groups have proposed rule based preprocessing methods to mitigate this problem (xu et al , 2009; <papid> N09-1028 </papid>hong et al ,2009).<papid> P09-2059 </papid></citsent>
<aftsection>
<nextsent>these methods rewrite svo sentences to derive more sov-like sentences by using set of handcrafted rules.
</nextsent>
<nextsent>in this paper, we propose an alternative single reordering rule: head finalization.
</nextsent>
<nextsent>this is syntax-based preprocessing approach that offers the advantage of simplicity.
</nextsent>
<nextsent>wedo not have to be concerned about part of-speech tags or rule weights because the powerful enju parser allows us to implement the rule at general level.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4225">
<title id=" W10-1736.xml">head finalization a simple reordering rule for sov languages </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>statistical machine translation (smt) is useful for building machine translator between pair of languages that follow similar word orders.
</prevsent>
<prevsent>how ever, smt does not work well for distant language pairs such as english and japanese, since english is an svo language and japanese is an sov lan guage.some existing methods try to solve this word order problem in language-independent ways.they usually parse input sentences and learn reordering decision at each node of the parse trees.
</prevsent>
</prevsection>
<citsent citstr=" P01-1067 ">
for example, yamada and knight (2001), <papid> P01-1067 </papid>quirk et al .</citsent>
<aftsection>
<nextsent>(2005), xia and mccord (2004), <papid> C04-1073 </papid>and li et al  (2007) <papid> P07-1091 </papid>proposed such methods.other methods tackle this problem in language dependent ways (katz-brown and collins, 2008; collins et al , 2005; <papid> P05-1066 </papid>nguyen and shimazu, 2006).</nextsent>
<nextsent>recently, xu et al  (2009) <papid> N09-1028 </papid>and hong et al  (2009)<papid> P09-2059 </papid>proposed rule-based preprocessing methods forsov languages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4226">
<title id=" W10-1736.xml">head finalization a simple reordering rule for sov languages </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>how ever, smt does not work well for distant language pairs such as english and japanese, since english is an svo language and japanese is an sov lan guage.some existing methods try to solve this word order problem in language-independent ways.they usually parse input sentences and learn reordering decision at each node of the parse trees.
</prevsent>
<prevsent>for example, yamada and knight (2001), <papid> P01-1067 </papid>quirk et al .</prevsent>
</prevsection>
<citsent citstr=" C04-1073 ">
(2005), xia and mccord (2004), <papid> C04-1073 </papid>and li et al  (2007) <papid> P07-1091 </papid>proposed such methods.other methods tackle this problem in language dependent ways (katz-brown and collins, 2008; collins et al , 2005; <papid> P05-1066 </papid>nguyen and shimazu, 2006).</citsent>
<aftsection>
<nextsent>recently, xu et al  (2009) <papid> N09-1028 </papid>and hong et al  (2009)<papid> P09-2059 </papid>proposed rule-based preprocessing methods forsov languages.</nextsent>
<nextsent>these methods parse input sentences and reorder the words using set of handcrafted rules to get sov-like sentences.if we could completely reorder the words in in put sentences by preprocessing to match the word order of the target language, we would be able to greatly reduce the computational cost of smt sys tems.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4227">
<title id=" W10-1736.xml">head finalization a simple reordering rule for sov languages </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>how ever, smt does not work well for distant language pairs such as english and japanese, since english is an svo language and japanese is an sov lan guage.some existing methods try to solve this word order problem in language-independent ways.they usually parse input sentences and learn reordering decision at each node of the parse trees.
</prevsent>
<prevsent>for example, yamada and knight (2001), <papid> P01-1067 </papid>quirk et al .</prevsent>
</prevsection>
<citsent citstr=" P07-1091 ">
(2005), xia and mccord (2004), <papid> C04-1073 </papid>and li et al  (2007) <papid> P07-1091 </papid>proposed such methods.other methods tackle this problem in language dependent ways (katz-brown and collins, 2008; collins et al , 2005; <papid> P05-1066 </papid>nguyen and shimazu, 2006).</citsent>
<aftsection>
<nextsent>recently, xu et al  (2009) <papid> N09-1028 </papid>and hong et al  (2009)<papid> P09-2059 </papid>proposed rule-based preprocessing methods forsov languages.</nextsent>
<nextsent>these methods parse input sentences and reorder the words using set of handcrafted rules to get sov-like sentences.if we could completely reorder the words in in put sentences by preprocessing to match the word order of the target language, we would be able to greatly reduce the computational cost of smt sys tems.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4228">
<title id=" W10-1736.xml">head finalization a simple reordering rule for sov languages </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>how ever, smt does not work well for distant language pairs such as english and japanese, since english is an svo language and japanese is an sov lan guage.some existing methods try to solve this word order problem in language-independent ways.they usually parse input sentences and learn reordering decision at each node of the parse trees.
</prevsent>
<prevsent>for example, yamada and knight (2001), <papid> P01-1067 </papid>quirk et al .</prevsent>
</prevsection>
<citsent citstr=" P05-1066 ">
(2005), xia and mccord (2004), <papid> C04-1073 </papid>and li et al  (2007) <papid> P07-1091 </papid>proposed such methods.other methods tackle this problem in language dependent ways (katz-brown and collins, 2008; collins et al , 2005; <papid> P05-1066 </papid>nguyen and shimazu, 2006).</citsent>
<aftsection>
<nextsent>recently, xu et al  (2009) <papid> N09-1028 </papid>and hong et al  (2009)<papid> P09-2059 </papid>proposed rule-based preprocessing methods forsov languages.</nextsent>
<nextsent>these methods parse input sentences and reorder the words using set of handcrafted rules to get sov-like sentences.if we could completely reorder the words in in put sentences by preprocessing to match the word order of the target language, we would be able to greatly reduce the computational cost of smt sys tems.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4241">
<title id=" W10-1736.xml">head finalization a simple reordering rule for sov languages </title>
<section> head finalization.  </section>
<citcontext>
<prevsection>
<prevsent>then we get john ball hit, which has the same word order as its japanese translation jon wa bohru wo utta except for the functional words a, wa, and wo.
</prevsent>
<prevsent>we have to add japanese particles wa (topic marker) or ga (nominative case marker) for john and wo (objective case marker) for ball to get an acceptable japanese sentence.it is well known that smt is not good at generating appropriate particles from english, whitch does not have particles.
</prevsent>
</prevsection>
<citsent citstr=" N07-1007 ">
particle generation was tackled by few research groups (toutanova and suzuki, 2007; <papid> N07-1007 </papid>hong et al , 2009).<papid> P09-2059 </papid></citsent>
<aftsection>
<nextsent>here, we use enjus output to generate seeds sentence id=s0?
</nextsent>
<nextsent>parse status=success??
</nextsent>
<nextsent>cons id=c0?
</nextsent>
<nextsent>cat=s? xcat=??
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4244">
<title id=" W10-1736.xml">head finalization a simple reordering rule for sov languages </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>246
</prevsent>
<prevsent>in order to show how closely our head finalization makes english follow japanese word order,we measured ken dalls ? , rank correlation coefficient.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
we also measured bleu (papineni et al ., 2002) <papid> P02-1040 </papid>and other automatic evaluation scores to show that head finalization can actually improve the translation quality.we used ntcir7 pat-mts patent corpus (fujii et al , 2008).</citsent>
<aftsection>
<nextsent>its training corpus has 1.8 million sentence pairs.
</nextsent>
<nextsent>we used mecab (http:// mecab.sourceforge.net/) to segment japanese sentences.
</nextsent>
<nextsent>3.1 rough evaluation of reordering.
</nextsent>
<nextsent>first, we examined rank correlation between head final english sentences produced by the head finalization rule and japanese reference sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4245">
<title id=" W10-1736.xml">head finalization a simple reordering rule for sov languages </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>3.1 rough evaluation of reordering.
</prevsent>
<prevsent>first, we examined rank correlation between head final english sentences produced by the head finalization rule and japanese reference sentences.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
since we do not have handcrafted word alignment data for an english-to-japanese bilingual corpus,we used giza++ (och and ney, 2003) <papid> J03-1002 </papid>to get automatic word alignment.</citsent>
<aftsection>
<nextsent>based on this automatic word alignment, we measured ken dalls ? for the word order between hfe sentences and japanese sentences.
</nextsent>
<nextsent>ken dalls ? is kind of rank correlation measure defined as follows.
</nextsent>
<nextsent>suppose list of inte gers such as = [2, 1, 3, 4].
</nextsent>
<nextsent>the number of all integer pairs in this listis 4c2 = 4 ? 3/(2 ? 1) = 6.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4249">
<title id=" W10-1736.xml">head finalization a simple reordering rule for sov languages </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>therefore, hit is moved after threw just like (2), and the two clauses become mixed up.
</prevsent>
<prevsent>consequently, we need heuristic rule like xus. 5.2 penn treebank-style parsers.
</prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
we also tried charniak-johnsons parser (char niak and johnson, 2005).<papid> P05-1022 </papid></citsent>
<aftsection>
<nextsent>pyinputtree (http://www.cs.brown.edu/dmcc/software/ pyinputtree/) gives heads.
</nextsent>
<nextsent>enju outputs at most two children for mother node, but penntreebank-style parsers do not have such limitation on the number of children.
</nextsent>
<nextsent>this fact causes problem.
</nextsent>
<nextsent>when we use enju, this toy is popular in japan?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4251">
<title id=" W10-1912.xml">extraction of disease treatment semantic relations from biomedical sentences </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the aim of this paper is to show which nlp and ml techniques are suitable for the task of identifying semantic relations between diseases and treatments in short biomedical texts.
</prevsent>
<prevsent>the value of our work stands in the results we obtain and the new feature representation techniques.
</prevsent>
</prevsection>
<citsent citstr=" P04-1055 ">
the most relevant work for our study is the work of rosario and hearst (2004).<papid> P04-1055 </papid></citsent>
<aftsection>
<nextsent>the authors of this paper are the ones that created and distributed the dataset used in our research.
</nextsent>
<nextsent>the dataset is annotated with disease and treatments entities and with 8 semantic relations between diseases and treatments.
</nextsent>
<nextsent>the main focus of their work is on entity recognition ? the task of identifying entities, diseases and treatments in biomedical text sentences.
</nextsent>
<nextsent>the authors use hidden markov models and maximum entropy models to perform both the task of entity recognition and of relation discrimination.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4262">
<title id=" W10-1752.xml">normalized compression distance based measures for metricsmatr 2010 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>more advanced methods achieve better correlation with human judgments, but typically use additional language specific linguistic resources.
</prevsent>
<prevsent>dobrinkat et al (2010) experimented with relaxed word matching, adding language specific resources to ncd.
</prevsent>
</prevsection>
<citsent citstr=" W08-0312 ">
the metric called mncd, which works similarly to mbleu(agarwal and lavie, 2008), <papid> W08-0312 </papid>showed improved correlation to human judgments in english, the only language where meteor synonym module was used.</citsent>
<aftsection>
<nextsent>the motivation for this challenge submission is to evaluate the mt-ncd and mt-mncd metric performance in an open competition with state-of 343 the-art mt evaluation metrics.
</nextsent>
<nextsent>our experiment sand submission build on ncd and mncd.
</nextsent>
<nextsent>we expand ncd to handle multiple references andre port experimental results for replicating segments as preprocessing step that improves the ncd as an mt evaluation metric.
</nextsent>
<nextsent>ncd-based mt evaluation metrics build on the idea that string is similar to another string y,when both share common substrings.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4264">
<title id=" W10-3110.xml">whatrsquos great and whatrsquos not learning to classify the scope of negation for improved sentiment analysis </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>lessons learned and future directions are discussed in 6.
</prevsent>
<prevsent>negation and its scope in the context of sentiment analysis has been studied in the past (moila nen and pulman, 2007).
</prevsent>
</prevsection>
<citsent citstr=" D08-1083 ">
in this work we focuson explicit negation mentions, also called functional negation by choi and cardie (2008).<papid> D08-1083 </papid></citsent>
<aftsection>
<nextsent>however, others have studied various forms of negation within the domain of sentiment analysis, including work on content negators, which typically are verbs such as hampered?, lacked?, de nied?, etc.
</nextsent>
<nextsent>(moilanen and pulman, 2007; choiand cardie, 2008).<papid> D08-1083 </papid></nextsent>
<nextsent>a recent study by danescuniculescu-mizil et al (2009) looked at the problem of finding downward-entailing operators that include wider range of lexical items, including soft negators such as the adverbs rarely?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4266">
<title id=" W10-3110.xml">whatrsquos great and whatrsquos not learning to classify the scope of negation for improved sentiment analysis </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>and hardly?.
</prevsent>
<prevsent>with the absence of general purpose corpus annotating the precise scope of negation in sentiment corpora, many studies incorporate negation terms through heuristics or soft-constraints in statistical models.
</prevsent>
</prevsection>
<citsent citstr=" H05-1044 ">
in the work of wilson et al (2005), <papid> H05-1044 </papid>supervised polarity classifier is trained with set of negation features derived from list of cue words and small window around them in the text.</citsent>
<aftsection>
<nextsent>choi and cardie (2008) <papid> D08-1083 </papid>combine different kinds of negators with lexical polarity items through various compositional semantic models, both heuristic and machine learned, to im prove phrasal sentiment analysis.</nextsent>
<nextsent>in that work the scope of negation was either left undefined or determined through surface level syntactic patterns similar to the syntactic patterns from moilanen and pulman (2007).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4268">
<title id=" W10-3110.xml">whatrsquos great and whatrsquos not learning to classify the scope of negation for improved sentiment analysis </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>thus, this work is complimentary to those mentioned above in that weare measuring not only whether negation detection is useful for sentiment, but to what extent we can determine its exact scope in the text.
</prevsent>
<prevsent>towards this end in we describe both an annotated negation span corpus as well as negation span detector that is trained on the corpus.
</prevsent>
</prevsection>
<citsent citstr=" N07-1009 ">
the span detector is based on conditional random fields (crfs) (lafferty, mccallum, and pereira, 2001), which isa structured prediction learning framework common in sub-sentential natural language processing tasks, including sentiment analysis (choi and cardie, 2007; <papid> N07-1009 </papid>mcdonald et al, 2007) <papid> P07-1055 </papid>the approach presented here resembles work by morante and daelemans (2009), <papid> W09-1105 </papid>who used igtree to predict negation cues and crf metalearnerthat combined input from k-nearest neighbor classification, support vector machine, and another underlying crf to predict the scope of nega tions within the bio scope corpus.</citsent>
<aftsection>
<nextsent>however, ourwork represents simplified approach that replaces machine-learned cue prediction with lexicon of explicit negation cues, and uses only single crf to predict negation scopes, with more comprehensive model that includes features from dependency parser.
</nextsent>
<nextsent>one of the only freely available resources for evaluating negation detection performance is the bio scope corpus (vincze et al, 2008), which consists of annotated clinical radiology reports, biological full papers, and biological abstracts.
</nextsent>
<nextsent>annotation sin bio scope consist of labeled negation and speculation cues along with the boundary of their associated text scopes.
</nextsent>
<nextsent>each cue is associated with exactly one scope, and the cue itself is considered to be part of its own scope.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4269">
<title id=" W10-3110.xml">whatrsquos great and whatrsquos not learning to classify the scope of negation for improved sentiment analysis </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>thus, this work is complimentary to those mentioned above in that weare measuring not only whether negation detection is useful for sentiment, but to what extent we can determine its exact scope in the text.
</prevsent>
<prevsent>towards this end in we describe both an annotated negation span corpus as well as negation span detector that is trained on the corpus.
</prevsent>
</prevsection>
<citsent citstr=" P07-1055 ">
the span detector is based on conditional random fields (crfs) (lafferty, mccallum, and pereira, 2001), which isa structured prediction learning framework common in sub-sentential natural language processing tasks, including sentiment analysis (choi and cardie, 2007; <papid> N07-1009 </papid>mcdonald et al, 2007) <papid> P07-1055 </papid>the approach presented here resembles work by morante and daelemans (2009), <papid> W09-1105 </papid>who used igtree to predict negation cues and crf metalearnerthat combined input from k-nearest neighbor classification, support vector machine, and another underlying crf to predict the scope of nega tions within the bio scope corpus.</citsent>
<aftsection>
<nextsent>however, ourwork represents simplified approach that replaces machine-learned cue prediction with lexicon of explicit negation cues, and uses only single crf to predict negation scopes, with more comprehensive model that includes features from dependency parser.
</nextsent>
<nextsent>one of the only freely available resources for evaluating negation detection performance is the bio scope corpus (vincze et al, 2008), which consists of annotated clinical radiology reports, biological full papers, and biological abstracts.
</nextsent>
<nextsent>annotation sin bio scope consist of labeled negation and speculation cues along with the boundary of their associated text scopes.
</nextsent>
<nextsent>each cue is associated with exactly one scope, and the cue itself is considered to be part of its own scope.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4270">
<title id=" W10-3110.xml">whatrsquos great and whatrsquos not learning to classify the scope of negation for improved sentiment analysis </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>thus, this work is complimentary to those mentioned above in that weare measuring not only whether negation detection is useful for sentiment, but to what extent we can determine its exact scope in the text.
</prevsent>
<prevsent>towards this end in we describe both an annotated negation span corpus as well as negation span detector that is trained on the corpus.
</prevsent>
</prevsection>
<citsent citstr=" W09-1105 ">
the span detector is based on conditional random fields (crfs) (lafferty, mccallum, and pereira, 2001), which isa structured prediction learning framework common in sub-sentential natural language processing tasks, including sentiment analysis (choi and cardie, 2007; <papid> N07-1009 </papid>mcdonald et al, 2007) <papid> P07-1055 </papid>the approach presented here resembles work by morante and daelemans (2009), <papid> W09-1105 </papid>who used igtree to predict negation cues and crf metalearnerthat combined input from k-nearest neighbor classification, support vector machine, and another underlying crf to predict the scope of nega tions within the bio scope corpus.</citsent>
<aftsection>
<nextsent>however, ourwork represents simplified approach that replaces machine-learned cue prediction with lexicon of explicit negation cues, and uses only single crf to predict negation scopes, with more comprehensive model that includes features from dependency parser.
</nextsent>
<nextsent>one of the only freely available resources for evaluating negation detection performance is the bio scope corpus (vincze et al, 2008), which consists of annotated clinical radiology reports, biological full papers, and biological abstracts.
</nextsent>
<nextsent>annotation sin bio scope consist of labeled negation and speculation cues along with the boundary of their associated text scopes.
</nextsent>
<nextsent>each cue is associated with exactly one scope, and the cue itself is considered to be part of its own scope.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4274">
<title id=" W10-3110.xml">whatrsquos great and whatrsquos not learning to classify the scope of negation for improved sentiment analysis </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>the negation scope detection system is built as an individual annotator within larger annotationpipeline.
</prevsent>
<prevsent>the negation annotator relies on two dis 54 tinct upstream annotators for 1) sentence boundary annotations, derived from rule-based sentence boundary extractor and 2) token annotations from dependency parser.
</prevsent>
</prevsection>
<citsent citstr=" C04-1010 ">
the dependency parser is an implementation of the parsing systems described in nivre and scholz (2004) <papid> C04-1010 </papid>and nivre et al (2007).</citsent>
<aftsection>
<nextsent>each annotator marks the character offsets for the begin and end positions of individual annotation ranges within documents, and makes the annotations available to downstream processes.
</nextsent>
<nextsent>the dependency annotator controls multiple lower-level nlp routines, including tokenization and part of speech (pos) tagging in addition to parsing sentence level dependency structure.
</nextsent>
<nextsent>the output that is kept for downstream use includes only pos and dependency relations for each token.
</nextsent>
<nextsent>the tokenization performed at this stage is recycled when learning to identify negation scopes.the feature space of the learning problem adheres to the dimensions presented in table 2,and negation scopes are modeled using first order linear-chain conditional random field (crf)2, with label set of size two indicating whether token is within or outside of negation span.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4281">
<title id=" W10-1754.xml">tesla translation evaluation of sentences with linearprogrammingbased analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in recent years, many machine translation (mt) evaluation metrics have been proposed, exploiting varying amounts of linguistic resources.
</prevsent>
<prevsent>heavyweight linguistic approaches including rte (pado et al, 2009) and ulc (gimnez and mrquez, 2008) performed the best in the wmt2009 shared evaluation task.
</prevsent>
</prevsection>
<citsent citstr=" W05-0909 ">
they exploit an extensive array of linguistic features such as parsing,semantic role labeling, textual entailment, and discourse representation, which may also limit their practical applications.lightweight linguistic approaches such as meteor (banerjee and lavie, 2005), <papid> W05-0909 </papid>maxsim (chan and ng, 2008), wpf and wpbleu (popovicand ney, 2009) exploit limited range of linguistic information that is relatively cheap to acquire and to compute, including lemmatization, part-of speech (pos) tagging, and synonym dictionaries.non-linguistic approaches include bleu (pap ineni et al, 2002) <papid> P02-1040 </papid>and its variants, ter (snover et al., 2006), among others.</citsent>
<aftsection>
<nextsent>they operate purely at the surface word level and no linguistic resources are required.
</nextsent>
<nextsent>although still very popular with mt researchers, they have generally shown inferior performances than the linguistic approaches.we believe that the lightweight linguistic approaches are good compromise given the current state of computational linguistics research andre sources.
</nextsent>
<nextsent>in this paper, we devise tesla-m and tesla, two lightweight approaches to mt evaluation.
</nextsent>
<nextsent>specifically: (1) the core features are measures derived by matching bags of n-grams; (2) both recall and precision are considered, with more emphasis on recall; and (3) wordnet synonyms feature prominently.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4282">
<title id=" W10-1754.xml">tesla translation evaluation of sentences with linearprogrammingbased analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in recent years, many machine translation (mt) evaluation metrics have been proposed, exploiting varying amounts of linguistic resources.
</prevsent>
<prevsent>heavyweight linguistic approaches including rte (pado et al, 2009) and ulc (gimnez and mrquez, 2008) performed the best in the wmt2009 shared evaluation task.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
they exploit an extensive array of linguistic features such as parsing,semantic role labeling, textual entailment, and discourse representation, which may also limit their practical applications.lightweight linguistic approaches such as meteor (banerjee and lavie, 2005), <papid> W05-0909 </papid>maxsim (chan and ng, 2008), wpf and wpbleu (popovicand ney, 2009) exploit limited range of linguistic information that is relatively cheap to acquire and to compute, including lemmatization, part-of speech (pos) tagging, and synonym dictionaries.non-linguistic approaches include bleu (pap ineni et al, 2002) <papid> P02-1040 </papid>and its variants, ter (snover et al., 2006), among others.</citsent>
<aftsection>
<nextsent>they operate purely at the surface word level and no linguistic resources are required.
</nextsent>
<nextsent>although still very popular with mt researchers, they have generally shown inferior performances than the linguistic approaches.we believe that the lightweight linguistic approaches are good compromise given the current state of computational linguistics research andre sources.
</nextsent>
<nextsent>in this paper, we devise tesla-m and tesla, two lightweight approaches to mt evaluation.
</nextsent>
<nextsent>specifically: (1) the core features are measures derived by matching bags of n-grams; (2) both recall and precision are considered, with more emphasis on recall; and (3) wordnet synonyms feature prominently.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4283">
<title id=" W10-1754.xml">tesla translation evaluation of sentences with linearprogrammingbased analysis </title>
<section> tesla.  </section>
<citcontext>
<prevsection>
<prevsent>their matching is done in the same way as described for btngs in the previous section.
</prevsent>
<prevsent>4.1 phrase level semantic representation.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
given sentence-aligned bitext between the target language and pivot language, we can align the text at the word level using well known tools such as giza++ (och and ney, 2003) <papid> J03-1002 </papid>or the berkeley aligner (liang et al, 2006; <papid> N06-1014 </papid>haghighi et al, 2009).<papid> P09-1104 </papid></citsent>
<aftsection>
<nextsent>we observe that the distribution of aligned phrases in pivot language can serve as semantic representation of target language phrase.
</nextsent>
<nextsent>that is, if two target language phrases are often aligned to the same pivot language phrase, then they can be inferred to be similar in meaning.
</nextsent>
<nextsent>similar observations have been made by previous researchers (bannard and callison-burch, 2005; callison-burch et al, 2006; snover et al, 2009).<papid> W09-0441 </papid></nextsent>
<nextsent>we note here two differences from wordnet synonyms: (1) the relationship is not restricted to the word level only, and (2) the relationship is not binary.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4284">
<title id=" W10-1754.xml">tesla translation evaluation of sentences with linearprogrammingbased analysis </title>
<section> tesla.  </section>
<citcontext>
<prevsection>
<prevsent>their matching is done in the same way as described for btngs in the previous section.
</prevsent>
<prevsent>4.1 phrase level semantic representation.
</prevsent>
</prevsection>
<citsent citstr=" N06-1014 ">
given sentence-aligned bitext between the target language and pivot language, we can align the text at the word level using well known tools such as giza++ (och and ney, 2003) <papid> J03-1002 </papid>or the berkeley aligner (liang et al, 2006; <papid> N06-1014 </papid>haghighi et al, 2009).<papid> P09-1104 </papid></citsent>
<aftsection>
<nextsent>we observe that the distribution of aligned phrases in pivot language can serve as semantic representation of target language phrase.
</nextsent>
<nextsent>that is, if two target language phrases are often aligned to the same pivot language phrase, then they can be inferred to be similar in meaning.
</nextsent>
<nextsent>similar observations have been made by previous researchers (bannard and callison-burch, 2005; callison-burch et al, 2006; snover et al, 2009).<papid> W09-0441 </papid></nextsent>
<nextsent>we note here two differences from wordnet synonyms: (1) the relationship is not restricted to the word level only, and (2) the relationship is not binary.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4285">
<title id=" W10-1754.xml">tesla translation evaluation of sentences with linearprogrammingbased analysis </title>
<section> tesla.  </section>
<citcontext>
<prevsection>
<prevsent>their matching is done in the same way as described for btngs in the previous section.
</prevsent>
<prevsent>4.1 phrase level semantic representation.
</prevsent>
</prevsection>
<citsent citstr=" P09-1104 ">
given sentence-aligned bitext between the target language and pivot language, we can align the text at the word level using well known tools such as giza++ (och and ney, 2003) <papid> J03-1002 </papid>or the berkeley aligner (liang et al, 2006; <papid> N06-1014 </papid>haghighi et al, 2009).<papid> P09-1104 </papid></citsent>
<aftsection>
<nextsent>we observe that the distribution of aligned phrases in pivot language can serve as semantic representation of target language phrase.
</nextsent>
<nextsent>that is, if two target language phrases are often aligned to the same pivot language phrase, then they can be inferred to be similar in meaning.
</nextsent>
<nextsent>similar observations have been made by previous researchers (bannard and callison-burch, 2005; callison-burch et al, 2006; snover et al, 2009).<papid> W09-0441 </papid></nextsent>
<nextsent>we note here two differences from wordnet synonyms: (1) the relationship is not restricted to the word level only, and (2) the relationship is not binary.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4286">
<title id=" W10-1754.xml">tesla translation evaluation of sentences with linearprogrammingbased analysis </title>
<section> tesla.  </section>
<citcontext>
<prevsection>
<prevsent>we observe that the distribution of aligned phrases in pivot language can serve as semantic representation of target language phrase.
</prevsent>
<prevsent>that is, if two target language phrases are often aligned to the same pivot language phrase, then they can be inferred to be similar in meaning.
</prevsent>
</prevsection>
<citsent citstr=" W09-0441 ">
similar observations have been made by previous researchers (bannard and callison-burch, 2005; callison-burch et al, 2006; snover et al, 2009).<papid> W09-0441 </papid></citsent>
<aftsection>
<nextsent>we note here two differences from wordnet synonyms: (1) the relationship is not restricted to the word level only, and (2) the relationship is not binary.
</nextsent>
<nextsent>the degree of similarity can be measured by the percentage of overlap between the semantic representations.
</nextsent>
<nextsent>for example, at the word level, 356 the phrases good morning and hello are unrelated even with synonym dictionary, but they both very often align to the same french phrase bonjour, and we conclude they are semantically related to high degree.
</nextsent>
<nextsent>4.2 segmenting sentence into phrases.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4287">
<title id=" W10-1754.xml">tesla translation evaluation of sentences with linearprogrammingbased analysis </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we pos tag and lemmatize the texts using the following tools: for english, opennlp pos-tagger3 and wordnet lemmatizer; for french and german, treetagger4; for spanish, the free ling toolkit (atserias et al, 2006); and for czech, the morce morphological tagger5.
</prevsent>
<prevsent>for german, we additionally perform noun compound splitting.
</prevsent>
</prevsection>
<citsent citstr=" E03-1076 ">
for each noun, we choose the split that maximizes the geometric mean of the frequency counts of its parts, following the method in (koehn and knight, 2003): <papid> E03-1076 </papid>max n,p1,p2,...,pn [ n?</citsent>
<aftsection>
<nextsent>i=1 n(pi) ] 1 the resulting compound split sentence is then pos tagged and lemmatized.
</nextsent>
<nextsent>finally, we remove all non-alphanumeric tokens from the text in all languages.
</nextsent>
<nextsent>to generate the language model features, we train srilm (stolcke, 2002) trigram models with modified kneser-ney discounting on the supplied monolingual europarl and news commentary texts.
</nextsent>
<nextsent>we build phrase tables from the supplied news commentary bitexts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4288">
<title id=" W10-1754.xml">tesla translation evaluation of sentences with linearprogrammingbased analysis </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we build phrase tables from the supplied news commentary bitexts.
</prevsent>
<prevsent>word alignments are produced by the berkeley aligner.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
the widely used phrase extraction heuristic in (koehn et al, 2003) <papid> N03-1017 </papid>is used to extract phrase pairs and phrases of up to 4 words are collected.</citsent>
<aftsection>
<nextsent>5.3 into-english task.
</nextsent>
<nextsent>for each of the bng features, we generate three scores, for unigrams, bigrams, and trigrams respectively.
</nextsent>
<nextsent>for bpngs, we generate one such triple for each of the four pivot languages supplied, namely czech, french, german, and spanish.
</nextsent>
<nextsent>3opennlp.sourceforge.net 4www.ims.uni-stuttgart.de/projekte/corplex/treetagger 5ufal.mff.cuni.cz/morce/index.php system correlation sentence consistency tesla 0.8993 0.6324 tesla-m 0.8718 0.6097 ulc 0.83 0.63 maxsim 0.80 0.62 meteor-0.6 0.72 0.50 table 1: into-english task on wmt 2009 data table 1 compares the scores of tesla and tesla-m against three participants in wmt2009 under identical settings6: ulc (a heavyweight linguistic approach with the best performance in wmt 2009), maxsim, and meteor.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4289">
<title id=" W10-1830.xml">combining parallel treebanks and geo tagging </title>
<section> parallel treebanks.  </section>
<citcontext>
<prevsection>
<prevsent>192 usage instructions for dvd player (gohring, 2009).
</prevsent>
<prevsent>we have annotated the english sentences according to the well-established penn tree bank guidelines.
</prevsent>
</prevsection>
<citsent citstr=" W04-1910 ">
for german we followed the tiger annotation guidelines, and we adapted these guidelines also for swedish (see (volkand samuelsson, 2004)).<papid> W04-1910 </papid></citsent>
<aftsection>
<nextsent>for french treebank ing we are looking for inspiration from the le monde treebank (abeille?
</nextsent>
<nextsent>et al, 2003) and fromlarboratoire (bick, 2010).
</nextsent>
<nextsent>the le monde tree bank is constituent structure treebank partially annotated with functional labels.
</nextsent>
<nextsent>larboratoire is based on constraint grammar analysis but can also output constituent trees.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4290">
<title id=" W10-1830.xml">combining parallel treebanks and geo tagging </title>
<section> parallel treebanks.  </section>
<citcontext>
<prevsection>
<prevsent>both trees are constituent structure trees, but the edge labels contain function labels (like subject,object, attribute) which can be used to easily convert the trees to dependency structures (cf.
</prevsent>
<prevsent>(marek et al, 2009)).
</prevsent>
</prevsection>
<citsent citstr=" W07-1514 ">
recently we have extended the treealigners functionality from being solely an alignment tool to also being powerful search tool over parallel treebanks (volk et al, 2007; <papid> W07-1514 </papid>marek et al, 2008).this enables our annotators to improve the alignment quality by cross-checking previous align ments.</citsent>
<aftsection>
<nextsent>this functionality makes the treealigner also attractive to wider user base (e.g. linguists,translation scientists) who are interested in searching rather than building parallel treebanks.
</nextsent>
<nextsent>3.2 similar tree banking projects.
</nextsent>
<nextsent>parallel treebanks have evolved into an active research field in the last decade.
</nextsent>
<nextsent>cmejrek et al 2the treealigner has been implemented in python by joakim lundborg and torsten marek and is freely available at http://kitt.cl.uzh.ch/kitt/treealigner.(2003) have built parallel treebank for the specific purpose of machine translation, the czech english penn treebank with tecto-grammatical dependency trees.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4291">
<title id=" W10-1201.xml">lda based similarity modeling for question answering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>some approaches to qa usekeyword-based techniques to locate candidate pas sages/sentences in the retrieved documents and then filter based on the presence of the desired answer type in candidate text.
</prevsent>
<prevsent>ranking is then done using syntactic features to characterize similarity to query.
</prevsent>
</prevsection>
<citsent citstr=" P06-1114 ">
in cases where simple question formulation is not satisfactory, many advanced qa systems implement more sophisticated syntactic, semantic and contextual processing such as named-entity recognition (molla et al , 2006), coreference resolution (vicedo and ferrandez, 2000), logical inferences (abductionor entailment) (harabagiu and hickl, 2006) <papid> P06-1114 </papid>translation (ma and mckeowon, 2009), <papid> P09-2084 </papid>etc., to improve answer ranking.</citsent>
<aftsection>
<nextsent>for instance, how questions, or spatially constrained questions, etc., require such typesof deeper understanding of the question and there trieved documents/passages.many studies on qa have focused on discriminative models to predict function of matching features between each question and candidate passage (set of sentences), namely q/a pairs, e.g., (ng et al , 2001; <papid> W01-0509 </papid>echihabi and marcu, 2003; <papid> P03-1003 </papid>harabagiu and hickl, 2006; <papid> P06-1114 </papid>shen and klakow, 2006; <papid> P06-1112 </papid>celikyilmaz et al , 2009).</nextsent>
<nextsent>despite their success, they have some room for improvement which are not usually raised,e.g., they require hand engineered features; or cascade features learnt separately from other module sin qa pipeline, thus propagating errors.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4292">
<title id=" W10-1201.xml">lda based similarity modeling for question answering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>some approaches to qa usekeyword-based techniques to locate candidate pas sages/sentences in the retrieved documents and then filter based on the presence of the desired answer type in candidate text.
</prevsent>
<prevsent>ranking is then done using syntactic features to characterize similarity to query.
</prevsent>
</prevsection>
<citsent citstr=" P09-2084 ">
in cases where simple question formulation is not satisfactory, many advanced qa systems implement more sophisticated syntactic, semantic and contextual processing such as named-entity recognition (molla et al , 2006), coreference resolution (vicedo and ferrandez, 2000), logical inferences (abductionor entailment) (harabagiu and hickl, 2006) <papid> P06-1114 </papid>translation (ma and mckeowon, 2009), <papid> P09-2084 </papid>etc., to improve answer ranking.</citsent>
<aftsection>
<nextsent>for instance, how questions, or spatially constrained questions, etc., require such typesof deeper understanding of the question and there trieved documents/passages.many studies on qa have focused on discriminative models to predict function of matching features between each question and candidate passage (set of sentences), namely q/a pairs, e.g., (ng et al , 2001; <papid> W01-0509 </papid>echihabi and marcu, 2003; <papid> P03-1003 </papid>harabagiu and hickl, 2006; <papid> P06-1114 </papid>shen and klakow, 2006; <papid> P06-1112 </papid>celikyilmaz et al , 2009).</nextsent>
<nextsent>despite their success, they have some room for improvement which are not usually raised,e.g., they require hand engineered features; or cascade features learnt separately from other module sin qa pipeline, thus propagating errors.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4293">
<title id=" W10-1201.xml">lda based similarity modeling for question answering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>ranking is then done using syntactic features to characterize similarity to query.
</prevsent>
<prevsent>in cases where simple question formulation is not satisfactory, many advanced qa systems implement more sophisticated syntactic, semantic and contextual processing such as named-entity recognition (molla et al , 2006), coreference resolution (vicedo and ferrandez, 2000), logical inferences (abductionor entailment) (harabagiu and hickl, 2006) <papid> P06-1114 </papid>translation (ma and mckeowon, 2009), <papid> P09-2084 </papid>etc., to improve answer ranking.</prevsent>
</prevsection>
<citsent citstr=" W01-0509 ">
for instance, how questions, or spatially constrained questions, etc., require such typesof deeper understanding of the question and there trieved documents/passages.many studies on qa have focused on discriminative models to predict function of matching features between each question and candidate passage (set of sentences), namely q/a pairs, e.g., (ng et al , 2001; <papid> W01-0509 </papid>echihabi and marcu, 2003; <papid> P03-1003 </papid>harabagiu and hickl, 2006; <papid> P06-1114 </papid>shen and klakow, 2006; <papid> P06-1112 </papid>celikyilmaz et al , 2009).</citsent>
<aftsection>
<nextsent>despite their success, they have some room for improvement which are not usually raised,e.g., they require hand engineered features; or cascade features learnt separately from other module sin qa pipeline, thus propagating errors.
</nextsent>
<nextsent>the structures to be learned can become more complex thanthe amount of training data, e.g., alignment, entailment, translation, etc. in such cases, other source of information, e.g., unlabeled examples, or human prior knowledge, should be used to improve performance.
</nextsent>
<nextsent>generative modeling is way of encoding this additional information, providing natural way to use unlabeled data.
</nextsent>
<nextsent>in this work, we present new similarity measures to discover deeper relationship between q/a pairs based on probabilistic model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4294">
<title id=" W10-1201.xml">lda based similarity modeling for question answering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>ranking is then done using syntactic features to characterize similarity to query.
</prevsent>
<prevsent>in cases where simple question formulation is not satisfactory, many advanced qa systems implement more sophisticated syntactic, semantic and contextual processing such as named-entity recognition (molla et al , 2006), coreference resolution (vicedo and ferrandez, 2000), logical inferences (abductionor entailment) (harabagiu and hickl, 2006) <papid> P06-1114 </papid>translation (ma and mckeowon, 2009), <papid> P09-2084 </papid>etc., to improve answer ranking.</prevsent>
</prevsection>
<citsent citstr=" P03-1003 ">
for instance, how questions, or spatially constrained questions, etc., require such typesof deeper understanding of the question and there trieved documents/passages.many studies on qa have focused on discriminative models to predict function of matching features between each question and candidate passage (set of sentences), namely q/a pairs, e.g., (ng et al , 2001; <papid> W01-0509 </papid>echihabi and marcu, 2003; <papid> P03-1003 </papid>harabagiu and hickl, 2006; <papid> P06-1114 </papid>shen and klakow, 2006; <papid> P06-1112 </papid>celikyilmaz et al , 2009).</citsent>
<aftsection>
<nextsent>despite their success, they have some room for improvement which are not usually raised,e.g., they require hand engineered features; or cascade features learnt separately from other module sin qa pipeline, thus propagating errors.
</nextsent>
<nextsent>the structures to be learned can become more complex thanthe amount of training data, e.g., alignment, entailment, translation, etc. in such cases, other source of information, e.g., unlabeled examples, or human prior knowledge, should be used to improve performance.
</nextsent>
<nextsent>generative modeling is way of encoding this additional information, providing natural way to use unlabeled data.
</nextsent>
<nextsent>in this work, we present new similarity measures to discover deeper relationship between q/a pairs based on probabilistic model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4296">
<title id=" W10-1201.xml">lda based similarity modeling for question answering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>ranking is then done using syntactic features to characterize similarity to query.
</prevsent>
<prevsent>in cases where simple question formulation is not satisfactory, many advanced qa systems implement more sophisticated syntactic, semantic and contextual processing such as named-entity recognition (molla et al , 2006), coreference resolution (vicedo and ferrandez, 2000), logical inferences (abductionor entailment) (harabagiu and hickl, 2006) <papid> P06-1114 </papid>translation (ma and mckeowon, 2009), <papid> P09-2084 </papid>etc., to improve answer ranking.</prevsent>
</prevsection>
<citsent citstr=" P06-1112 ">
for instance, how questions, or spatially constrained questions, etc., require such typesof deeper understanding of the question and there trieved documents/passages.many studies on qa have focused on discriminative models to predict function of matching features between each question and candidate passage (set of sentences), namely q/a pairs, e.g., (ng et al , 2001; <papid> W01-0509 </papid>echihabi and marcu, 2003; <papid> P03-1003 </papid>harabagiu and hickl, 2006; <papid> P06-1114 </papid>shen and klakow, 2006; <papid> P06-1112 </papid>celikyilmaz et al , 2009).</citsent>
<aftsection>
<nextsent>despite their success, they have some room for improvement which are not usually raised,e.g., they require hand engineered features; or cascade features learnt separately from other module sin qa pipeline, thus propagating errors.
</nextsent>
<nextsent>the structures to be learned can become more complex thanthe amount of training data, e.g., alignment, entailment, translation, etc. in such cases, other source of information, e.g., unlabeled examples, or human prior knowledge, should be used to improve performance.
</nextsent>
<nextsent>generative modeling is way of encoding this additional information, providing natural way to use unlabeled data.
</nextsent>
<nextsent>in this work, we present new similarity measures to discover deeper relationship between q/a pairs based on probabilistic model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4298">
<title id=" W10-2008.xml">towards a data driven model of eye movement control in reading </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>current models such as e-z reader (reichle, 2006a; pollatsek et al, 2006; reichle et al, 2009) and swift (engbert et al, 2002; engbert et al, 2005) account for numerous of the known facts about saccade behavior in reading.
</prevsent>
<prevsent>this include sword frequency and predictability effects on fixation times, word skipping rates, and preview and spillover effects.a recent approach to eye-movement modeling, less tied to psycho physiological assumptions about the mechanisms that drive eye movements, is to build models directly from eye-tracking data using machine learning techniques inspired by recent work in natural language processing.
</prevsent>
</prevsection>
<citsent citstr=" W09-1113 ">
thus, nilsson and nivre (2009) <papid> W09-1113 </papid>show how classifier can be trained on authentic eye-tracking data andthen used to predict the saccade behavior of individual readers on new texts.</citsent>
<aftsection>
<nextsent>methodologically this differs from the standard approach in computational modeling of eye movement control, where model parameters are often fitted to data but model predictions are not evaluated on unseen data in order to assess the generalization error of these predictions.
</nextsent>
<nextsent>without questioning the validity of the standard approach, we believe that the strict separation of training data and test data assumed in machine learning may provide additional insights about the properties of these models.
</nextsent>
<nextsent>the model of nilsson and nivre (2009) <papid> W09-1113 </papid>is basedon simple transition system for saccadic movements, classifier that predicts where to fixate nextand classifier-guided search algorithm to simulate fixation sequences over sentences.</nextsent>
<nextsent>63 one obvious limitation of the model proposed by nilsson and nivre (2009) <papid> W09-1113 </papid>is that it does not at all capture the temporal aspects of eye movement behavior.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4324">
<title id=" W10-1724.xml">linear inversion transduction grammar alignments as a second translation path </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the main problem with itgs is the time complexity, o(gn6) doesnt scale well.
</prevsent>
<prevsent>by limiting the grammar to bracketing itg (bitg), the grammar constant (g) can be eliminated, but o(n6) is still prohibitive for large data sets.there has been some work on approximate inference of itgs.
</prevsent>
</prevsection>
<citsent citstr=" P08-1012 ">
zhang et al (2008) <papid> P08-1012 </papid>present method for evaluating spans in the sentence pair to determine whether they should be excluded ornot.</citsent>
<aftsection>
<nextsent>the algorithm has best case time complexity of o(n3).
</nextsent>
<nextsent>saers, nivre &amp; wu (2009) introduce beam pruning scheme, which reduces time complexity to o(bn3).
</nextsent>
<nextsent>they also show that severe pruning is possible without significant deterioration in alignment quality (as measured by downstream translation quality).
</nextsent>
<nextsent>haghighi et al.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4325">
<title id=" W10-1724.xml">linear inversion transduction grammar alignments as a second translation path </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>haghighi et al.
</prevsent>
<prevsent>(2009) use simpler aligner as guidance for pruning, which reduces the time complexity bytwo orders of magnitude.
</prevsent>
</prevsection>
<citsent citstr=" J97-3002 ">
their work also partially implements the phrasal itgs for translation driven segmentation introduced in wu (1997), <papid> J97-3002 </papid>although they only allow for one-to-many alignments, rather than many-to-many alignments.</citsent>
<aftsection>
<nextsent>a more extreme approach is taken in saers, nivre &amp; wu (2010).
</nextsent>
<nextsent>not only is the search severely pruned, but the grammar itself is limited to linear ized form, getting rid of branching within single parse.
</nextsent>
<nextsent>although small deterioration in down stream translation quality is noted (compared to harshly pruned sbitgs), the grammar can be induced in linear time.
</nextsent>
<nextsent>in this paper we apply sblitgs to full size german english wmt10 translation task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4327">
<title id=" W10-1724.xml">linear inversion transduction grammar alignments as a second translation path </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>e a?
</prevsent>
<prevsent>f inducing an itg from parallel corpus is still slow, as the time complexity is o(gn6).
</prevsent>
</prevsection>
<citsent citstr=" P09-1104 ">
several ways to get around this has been proposed (zhang et al, 2008; <papid> P08-1012 </papid>haghighi et al, 2009; <papid> P09-1104 </papid>saers et al, 2009; <papid> W09-3804 </papid>saers et al, 2010).</citsent>
<aftsection>
<nextsent>taking closer look at the linear itgs (saers etal., 2010), there are five rules in normal form.
</nextsent>
<nextsent>decomposing these five rule types into monolingual rule types reveals that the monolingual grammars are linear grammars (lgs): litgl1,l2 lgl1 lgl2 a?
</nextsent>
<nextsent>[ e/f ] a?
</nextsent>
<nextsent>e a?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4328">
<title id=" W10-1724.xml">linear inversion transduction grammar alignments as a second translation path </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>e a?
</prevsent>
<prevsent>f inducing an itg from parallel corpus is still slow, as the time complexity is o(gn6).
</prevsent>
</prevsection>
<citsent citstr=" W09-3804 ">
several ways to get around this has been proposed (zhang et al, 2008; <papid> P08-1012 </papid>haghighi et al, 2009; <papid> P09-1104 </papid>saers et al, 2009; <papid> W09-3804 </papid>saers et al, 2010).</citsent>
<aftsection>
<nextsent>taking closer look at the linear itgs (saers etal., 2010), there are five rules in normal form.
</nextsent>
<nextsent>decomposing these five rule types into monolingual rule types reveals that the monolingual grammars are linear grammars (lgs): litgl1,l2 lgl1 lgl2 a?
</nextsent>
<nextsent>[ e/f ] a?
</nextsent>
<nextsent>e a?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4330">
<title id=" W10-1724.xml">linear inversion transduction grammar alignments as a second translation path </title>
<section> setup.  </section>
<citcontext>
<prevsection>
<prevsent>the alignments given by sbitgs and sblitgs has been shown to give better translation quality than bidirectional ibm-models, when applied to short sentence corpora (saers and wu, 2009; saers et al,2009; <papid> W09-3804 </papid>saers et al, 2010).</prevsent>
<prevsent>in this paper we explore whether this hold for sblitgs on standard sentence corpora.</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
the baseline system for the shared task was aphrase based translation model based on bidirectional ibm- (brown et al, 1993) <papid> J93-2003 </papid>and hmm models (vogel et al, 1996) <papid> C96-2141 </papid>combined with the grow-diag-final-and heuristic.</citsent>
<aftsection>
<nextsent>this is computed with the giza++ tool (och and ney, 2003) <papid> J03-1002 </papid>and the moses toolkit (koehn et al, 2007).<papid> P07-2045 </papid>the language model was 5-gram srilm (stolcke, 2002).</nextsent>
<nextsent>parameters in the final translation system were determined with minimum error-rate training (och, 2003), <papid> P03-1021 </papid>and translation quality was assessed with the automatic measures bleu (pap ineni et al, 2002) <papid> P02-1040 </papid>and nist (doddington, 2002).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4331">
<title id=" W10-1724.xml">linear inversion transduction grammar alignments as a second translation path </title>
<section> setup.  </section>
<citcontext>
<prevsection>
<prevsent>the alignments given by sbitgs and sblitgs has been shown to give better translation quality than bidirectional ibm-models, when applied to short sentence corpora (saers and wu, 2009; saers et al,2009; <papid> W09-3804 </papid>saers et al, 2010).</prevsent>
<prevsent>in this paper we explore whether this hold for sblitgs on standard sentence corpora.</prevsent>
</prevsection>
<citsent citstr=" C96-2141 ">
the baseline system for the shared task was aphrase based translation model based on bidirectional ibm- (brown et al, 1993) <papid> J93-2003 </papid>and hmm models (vogel et al, 1996) <papid> C96-2141 </papid>combined with the grow-diag-final-and heuristic.</citsent>
<aftsection>
<nextsent>this is computed with the giza++ tool (och and ney, 2003) <papid> J03-1002 </papid>and the moses toolkit (koehn et al, 2007).<papid> P07-2045 </papid>the language model was 5-gram srilm (stolcke, 2002).</nextsent>
<nextsent>parameters in the final translation system were determined with minimum error-rate training (och, 2003), <papid> P03-1021 </papid>and translation quality was assessed with the automatic measures bleu (pap ineni et al, 2002) <papid> P02-1040 </papid>and nist (doddington, 2002).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4332">
<title id=" W10-1724.xml">linear inversion transduction grammar alignments as a second translation path </title>
<section> setup.  </section>
<citcontext>
<prevsection>
<prevsent>in this paper we explore whether this hold for sblitgs on standard sentence corpora.
</prevsent>
<prevsent>the baseline system for the shared task was aphrase based translation model based on bidirectional ibm- (brown et al, 1993) <papid> J93-2003 </papid>and hmm models (vogel et al, 1996) <papid> C96-2141 </papid>combined with the grow-diag-final-and heuristic.</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
this is computed with the giza++ tool (och and ney, 2003) <papid> J03-1002 </papid>and the moses toolkit (koehn et al, 2007).<papid> P07-2045 </papid>the language model was 5-gram srilm (stolcke, 2002).</citsent>
<aftsection>
<nextsent>parameters in the final translation system were determined with minimum error-rate training (och, 2003), <papid> P03-1021 </papid>and translation quality was assessed with the automatic measures bleu (pap ineni et al, 2002) <papid> P02-1040 </papid>and nist (doddington, 2002).</nextsent>
<nextsent>168 corpus type size german english europarl out of domain 1,219,343 sentence pairs german english news commentary in-domain 86,941 sentence pairs english news commentary in-domain 48,653,884 sentences german english news commentary in-domain tuning data 2,051 sentence pairs german english news commentary in-domain test data 2,489 sentence pairs table 1: corpora available for the german english translation task after baseline cleaning.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4333">
<title id=" W10-1724.xml">linear inversion transduction grammar alignments as a second translation path </title>
<section> setup.  </section>
<citcontext>
<prevsection>
<prevsent>in this paper we explore whether this hold for sblitgs on standard sentence corpora.
</prevsent>
<prevsent>the baseline system for the shared task was aphrase based translation model based on bidirectional ibm- (brown et al, 1993) <papid> J93-2003 </papid>and hmm models (vogel et al, 1996) <papid> C96-2141 </papid>combined with the grow-diag-final-and heuristic.</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
this is computed with the giza++ tool (och and ney, 2003) <papid> J03-1002 </papid>and the moses toolkit (koehn et al, 2007).<papid> P07-2045 </papid>the language model was 5-gram srilm (stolcke, 2002).</citsent>
<aftsection>
<nextsent>parameters in the final translation system were determined with minimum error-rate training (och, 2003), <papid> P03-1021 </papid>and translation quality was assessed with the automatic measures bleu (pap ineni et al, 2002) <papid> P02-1040 </papid>and nist (doddington, 2002).</nextsent>
<nextsent>168 corpus type size german english europarl out of domain 1,219,343 sentence pairs german english news commentary in-domain 86,941 sentence pairs english news commentary in-domain 48,653,884 sentences german english news commentary in-domain tuning data 2,051 sentence pairs german english news commentary in-domain test data 2,489 sentence pairs table 1: corpora available for the german english translation task after baseline cleaning.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4334">
<title id=" W10-1724.xml">linear inversion transduction grammar alignments as a second translation path </title>
<section> setup.  </section>
<citcontext>
<prevsection>
<prevsent>the baseline system for the shared task was aphrase based translation model based on bidirectional ibm- (brown et al, 1993) <papid> J93-2003 </papid>and hmm models (vogel et al, 1996) <papid> C96-2141 </papid>combined with the grow-diag-final-and heuristic.</prevsent>
<prevsent>this is computed with the giza++ tool (och and ney, 2003) <papid> J03-1002 </papid>and the moses toolkit (koehn et al, 2007).<papid> P07-2045 </papid>the language model was 5-gram srilm (stolcke, 2002).</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
parameters in the final translation system were determined with minimum error-rate training (och, 2003), <papid> P03-1021 </papid>and translation quality was assessed with the automatic measures bleu (pap ineni et al, 2002) <papid> P02-1040 </papid>and nist (doddington, 2002).</citsent>
<aftsection>
<nextsent>168 corpus type size german english europarl out of domain 1,219,343 sentence pairs german english news commentary in-domain 86,941 sentence pairs english news commentary in-domain 48,653,884 sentences german english news commentary in-domain tuning data 2,051 sentence pairs german english news commentary in-domain test data 2,489 sentence pairs table 1: corpora available for the german english translation task after baseline cleaning.
</nextsent>
<nextsent>system bleu nist giza++ 17.88 5.9748 sblitg 17.61 5.8846 sblitg (only europarl) 17.46 5.8491 sblitg (only news) 15.49 5.4987 giza++ and sblitg 17.66 5.9650 giza++ and sblitg (only europarl) 17.58 5.9819 giza++ and sblitg (only news) 17.48 5.9693 table 2: results for the german english translation task.
</nextsent>
<nextsent>we chose to focus on the german english translation task.
</nextsent>
<nextsent>the corpora resources available for that task is summarized in table 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4335">
<title id=" W10-1724.xml">linear inversion transduction grammar alignments as a second translation path </title>
<section> setup.  </section>
<citcontext>
<prevsection>
<prevsent>the baseline system for the shared task was aphrase based translation model based on bidirectional ibm- (brown et al, 1993) <papid> J93-2003 </papid>and hmm models (vogel et al, 1996) <papid> C96-2141 </papid>combined with the grow-diag-final-and heuristic.</prevsent>
<prevsent>this is computed with the giza++ tool (och and ney, 2003) <papid> J03-1002 </papid>and the moses toolkit (koehn et al, 2007).<papid> P07-2045 </papid>the language model was 5-gram srilm (stolcke, 2002).</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
parameters in the final translation system were determined with minimum error-rate training (och, 2003), <papid> P03-1021 </papid>and translation quality was assessed with the automatic measures bleu (pap ineni et al, 2002) <papid> P02-1040 </papid>and nist (doddington, 2002).</citsent>
<aftsection>
<nextsent>168 corpus type size german english europarl out of domain 1,219,343 sentence pairs german english news commentary in-domain 86,941 sentence pairs english news commentary in-domain 48,653,884 sentences german english news commentary in-domain tuning data 2,051 sentence pairs german english news commentary in-domain test data 2,489 sentence pairs table 1: corpora available for the german english translation task after baseline cleaning.
</nextsent>
<nextsent>system bleu nist giza++ 17.88 5.9748 sblitg 17.61 5.8846 sblitg (only europarl) 17.46 5.8491 sblitg (only news) 15.49 5.4987 giza++ and sblitg 17.66 5.9650 giza++ and sblitg (only europarl) 17.58 5.9819 giza++ and sblitg (only news) 17.48 5.9693 table 2: results for the german english translation task.
</nextsent>
<nextsent>we chose to focus on the german english translation task.
</nextsent>
<nextsent>the corpora resources available for that task is summarized in table 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4336">
<title id=" W10-1724.xml">linear inversion transduction grammar alignments as a second translation path </title>
<section> setup.  </section>
<citcontext>
<prevsection>
<prevsent>we also combined all three sblitg systems with the baseline system to see whether the additional translation paths would help.
</prevsent>
<prevsent>the system we submitted corresponds to the giza++ and sblitg (only news)?
</prevsent>
</prevsection>
<citsent citstr=" P07-1065 ">
system, butwith randlm (talbot and osborne, 2007) <papid> P07-1065 </papid>aslan guage model rather than srilm.</citsent>
<aftsection>
<nextsent>this was because we lacked the necessary ram resources to calculate the full srilm model before the system submission deadline.
</nextsent>
<nextsent>the results for the development test set are summarized in table 2.
</nextsent>
<nextsent>the submitted system achieved bleu score of 0.1759 and nist score of 5.9579 for cased output on this years test set (these numbers are not comparable to thosein table 2).
</nextsent>
<nextsent>to our surprise, adding the additional phrases as second translation path does not seem to help.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4337">
<title id=" W10-2808.xml">sketch techniques for scaling distributional similarity to the web </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our method returns semantic similarity between word pairs in o(k) time and can compute similarity between any word pairs that are stored in the sketch.
</prevsent>
<prevsent>in our experiments, we show that our framework is as effective as using the exact counts.
</prevsent>
</prevsection>
<citsent citstr=" D07-1090 ">
in many nlp problems, researchers (brants et al, 2007; <papid> D07-1090 </papid>turney, 2008) <papid> C08-1114 </papid>have shown that having large amounts of data is beneficial.</citsent>
<aftsection>
<nextsent>it has also been shown that (agirre et al, 2009; <papid> N09-1003 </papid>pantel et al, 2009; <papid> D09-1098 </papid>ravichandran et al, 2005) <papid> P05-1077 </papid>having large amounts of data helps capturing the semantic similarity between pairs of words.</nextsent>
<nextsent>however, computing distributional similarity (sec.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4338">
<title id=" W10-2808.xml">sketch techniques for scaling distributional similarity to the web </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our method returns semantic similarity between word pairs in o(k) time and can compute similarity between any word pairs that are stored in the sketch.
</prevsent>
<prevsent>in our experiments, we show that our framework is as effective as using the exact counts.
</prevsent>
</prevsection>
<citsent citstr=" C08-1114 ">
in many nlp problems, researchers (brants et al, 2007; <papid> D07-1090 </papid>turney, 2008) <papid> C08-1114 </papid>have shown that having large amounts of data is beneficial.</citsent>
<aftsection>
<nextsent>it has also been shown that (agirre et al, 2009; <papid> N09-1003 </papid>pantel et al, 2009; <papid> D09-1098 </papid>ravichandran et al, 2005) <papid> P05-1077 </papid>having large amounts of data helps capturing the semantic similarity between pairs of words.</nextsent>
<nextsent>however, computing distributional similarity (sec.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4339">
<title id=" W10-2808.xml">sketch techniques for scaling distributional similarity to the web </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in our experiments, we show that our framework is as effective as using the exact counts.
</prevsent>
<prevsent>in many nlp problems, researchers (brants et al, 2007; <papid> D07-1090 </papid>turney, 2008) <papid> C08-1114 </papid>have shown that having large amounts of data is beneficial.</prevsent>
</prevsection>
<citsent citstr=" N09-1003 ">
it has also been shown that (agirre et al, 2009; <papid> N09-1003 </papid>pantel et al, 2009; <papid> D09-1098 </papid>ravichandran et al, 2005) <papid> P05-1077 </papid>having large amounts of data helps capturing the semantic similarity between pairs of words.</citsent>
<aftsection>
<nextsent>however, computing distributional similarity (sec.
</nextsent>
<nextsent>2.1) between word pairs from large text collections is computationally expensive task.
</nextsent>
<nextsent>in this work, we consider scaling distributional similarity methods for computing semantic similarity between words to web-scale.the major difficulty in computing pairwise similarities stems from the rapid increase in the number of unique word-context pairs with the size of text corpus (number of tokens).
</nextsent>
<nextsent>fig.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4340">
<title id=" W10-2808.xml">sketch techniques for scaling distributional similarity to the web </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in our experiments, we show that our framework is as effective as using the exact counts.
</prevsent>
<prevsent>in many nlp problems, researchers (brants et al, 2007; <papid> D07-1090 </papid>turney, 2008) <papid> C08-1114 </papid>have shown that having large amounts of data is beneficial.</prevsent>
</prevsection>
<citsent citstr=" D09-1098 ">
it has also been shown that (agirre et al, 2009; <papid> N09-1003 </papid>pantel et al, 2009; <papid> D09-1098 </papid>ravichandran et al, 2005) <papid> P05-1077 </papid>having large amounts of data helps capturing the semantic similarity between pairs of words.</citsent>
<aftsection>
<nextsent>however, computing distributional similarity (sec.
</nextsent>
<nextsent>2.1) between word pairs from large text collections is computationally expensive task.
</nextsent>
<nextsent>in this work, we consider scaling distributional similarity methods for computing semantic similarity between words to web-scale.the major difficulty in computing pairwise similarities stems from the rapid increase in the number of unique word-context pairs with the size of text corpus (number of tokens).
</nextsent>
<nextsent>fig.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4341">
<title id=" W10-2808.xml">sketch techniques for scaling distributional similarity to the web </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in our experiments, we show that our framework is as effective as using the exact counts.
</prevsent>
<prevsent>in many nlp problems, researchers (brants et al, 2007; <papid> D07-1090 </papid>turney, 2008) <papid> C08-1114 </papid>have shown that having large amounts of data is beneficial.</prevsent>
</prevsection>
<citsent citstr=" P05-1077 ">
it has also been shown that (agirre et al, 2009; <papid> N09-1003 </papid>pantel et al, 2009; <papid> D09-1098 </papid>ravichandran et al, 2005) <papid> P05-1077 </papid>having large amounts of data helps capturing the semantic similarity between pairs of words.</citsent>
<aftsection>
<nextsent>however, computing distributional similarity (sec.
</nextsent>
<nextsent>2.1) between word pairs from large text collections is computationally expensive task.
</nextsent>
<nextsent>in this work, we consider scaling distributional similarity methods for computing semantic similarity between words to web-scale.the major difficulty in computing pairwise similarities stems from the rapid increase in the number of unique word-context pairs with the size of text corpus (number of tokens).
</nextsent>
<nextsent>fig.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4346">
<title id=" W10-2808.xml">sketch techniques for scaling distributional similarity to the web </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>in our work, we store all unique word-context pairs in cu sketch with pre-defined size4.
</prevsent>
<prevsent>recently, the streaming algorithm paradigm has been used to provide memory and time-efficient platform to deal with tera bytes of data.
</prevsent>
</prevsection>
<citsent citstr=" N09-1058 ">
for example, we (goyal et al, 2009); <papid> N09-1058 </papid>levenberg and osborne (2009) <papid> D09-1079 </papid>build approximate language models and show their effectiveness in smt.</citsent>
<aftsection>
<nextsent>in (van durme and lall, 2009b), tomb counter (van durme and lall, 2009a) was used to find the top-k verbs y? with the highest pmi forgiven verb x?.
</nextsent>
<nextsent>the idea of tomb is similar to cu sketch.
</nextsent>
<nextsent>however, we use cu sketch because of its simplicity and attractive properties (see sec.
</nextsent>
<nextsent>3).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4347">
<title id=" W10-2808.xml">sketch techniques for scaling distributional similarity to the web </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>in our work, we store all unique word-context pairs in cu sketch with pre-defined size4.
</prevsent>
<prevsent>recently, the streaming algorithm paradigm has been used to provide memory and time-efficient platform to deal with tera bytes of data.
</prevsent>
</prevsection>
<citsent citstr=" D09-1079 ">
for example, we (goyal et al, 2009); <papid> N09-1058 </papid>levenberg and osborne (2009) <papid> D09-1079 </papid>build approximate language models and show their effectiveness in smt.</citsent>
<aftsection>
<nextsent>in (van durme and lall, 2009b), tomb counter (van durme and lall, 2009a) was used to find the top-k verbs y? with the highest pmi forgiven verb x?.
</nextsent>
<nextsent>the idea of tomb is similar to cu sketch.
</nextsent>
<nextsent>however, we use cu sketch because of its simplicity and attractive properties (see sec.
</nextsent>
<nextsent>3).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4351">
<title id=" W10-2909.xml">improved unsupervised pos induction using intrinsic clustering quality and a zipfian constraint </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>in this paper we address this issue usingan unsupervised test for intrinsic clustering quality.
</prevsent>
<prevsent>we run base tagger with different random initializations, and select the best tagging using the quality test.
</prevsent>
</prevsection>
<citsent citstr=" E03-1009 ">
asa base tagger, we modify leading unsupervised pos tagger (clark, 2003) <papid> E03-1009 </papid>to constrain the distributions of word types across clusters to be zipfian, allowing us to utilize perplexity-based quality test.</citsent>
<aftsection>
<nextsent>we show that the correlation between our quality test and gold standard-based tagging quality measures is high.
</nextsent>
<nextsent>our results are better in most evaluation measures than all results reported in the literature for this task, and are always better than the clark average results.
</nextsent>
<nextsent>unsupervised part-of-speech (pos) induction is of major theoretical and practical importance.
</nextsent>
<nextsent>it counters the arbitrary nature of manually designed tag sets, and avoids manual corpus annotationcosts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4356">
<title id=" W10-2909.xml">improved unsupervised pos induction using intrinsic clustering quality and a zipfian constraint </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the absolute variability of the induced tagging quality is 10-15%, which is around 20% of the mean.
</prevsent>
<prevsent>strong variability has also been reported by other authors (section 3).the common practice in the literature is to report mean results over several random initializa tions of the algorithm (e.g.
</prevsent>
</prevsection>
<citsent citstr=" P05-1044 ">
(clark, 2003; <papid> E03-1009 </papid>smith and eisner, 2005;<papid> P05-1044 </papid>goldwater and griffiths, 2007;<papid> P07-1094 </papid>johnson, 2007)).<papid> D07-1031 </papid></citsent>
<aftsection>
<nextsent>this means that applications using the induced tagging are not guaranteed to use tagging of the reported quality.
</nextsent>
<nextsent>in this paper we address this issue using an unsupervised test for intrinsic clustering quality.
</nextsent>
<nextsent>we present quality-based algorithmic family q. each of its concrete member algorithms q(b) runsa base tagger with different random initializa tions, and selects the best tagging according thequality test.
</nextsent>
<nextsent>if the test is highly positively correlated with external tagging quality measures (e.g., those based on gold standard tagging), q(b) will produce better results than with high probability.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4358">
<title id=" W10-2909.xml">improved unsupervised pos induction using intrinsic clustering quality and a zipfian constraint </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the absolute variability of the induced tagging quality is 10-15%, which is around 20% of the mean.
</prevsent>
<prevsent>strong variability has also been reported by other authors (section 3).the common practice in the literature is to report mean results over several random initializa tions of the algorithm (e.g.
</prevsent>
</prevsection>
<citsent citstr=" P07-1094 ">
(clark, 2003; <papid> E03-1009 </papid>smith and eisner, 2005;<papid> P05-1044 </papid>goldwater and griffiths, 2007;<papid> P07-1094 </papid>johnson, 2007)).<papid> D07-1031 </papid></citsent>
<aftsection>
<nextsent>this means that applications using the induced tagging are not guaranteed to use tagging of the reported quality.
</nextsent>
<nextsent>in this paper we address this issue using an unsupervised test for intrinsic clustering quality.
</nextsent>
<nextsent>we present quality-based algorithmic family q. each of its concrete member algorithms q(b) runsa base tagger with different random initializa tions, and selects the best tagging according thequality test.
</nextsent>
<nextsent>if the test is highly positively correlated with external tagging quality measures (e.g., those based on gold standard tagging), q(b) will produce better results than with high probability.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4359">
<title id=" W10-2909.xml">improved unsupervised pos induction using intrinsic clustering quality and a zipfian constraint </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the absolute variability of the induced tagging quality is 10-15%, which is around 20% of the mean.
</prevsent>
<prevsent>strong variability has also been reported by other authors (section 3).the common practice in the literature is to report mean results over several random initializa tions of the algorithm (e.g.
</prevsent>
</prevsection>
<citsent citstr=" D07-1031 ">
(clark, 2003; <papid> E03-1009 </papid>smith and eisner, 2005;<papid> P05-1044 </papid>goldwater and griffiths, 2007;<papid> P07-1094 </papid>johnson, 2007)).<papid> D07-1031 </papid></citsent>
<aftsection>
<nextsent>this means that applications using the induced tagging are not guaranteed to use tagging of the reported quality.
</nextsent>
<nextsent>in this paper we address this issue using an unsupervised test for intrinsic clustering quality.
</nextsent>
<nextsent>we present quality-based algorithmic family q. each of its concrete member algorithms q(b) runsa base tagger with different random initializa tions, and selects the best tagging according thequality test.
</nextsent>
<nextsent>if the test is highly positively correlated with external tagging quality measures (e.g., those based on gold standard tagging), q(b) will produce better results than with high probability.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4362">
<title id=" W10-2909.xml">improved unsupervised pos induction using intrinsic clustering quality and a zipfian constraint </title>
<section> the q(zcc) algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>finally, we provide an unsupervised technique for selecting the parameter of the zipfian constraint.
</prevsent>
<prevsent>2.1 the original clark tagger (ct).
</prevsent>
</prevsection>
<citsent citstr=" J92-4003 ">
the taggers statistical model combines distributional and morphological information with the likelihood function of the brown algorithm (brown et al, 1992; <papid> J92-4003 </papid>ney et al, 1994; martin etal., 1998).</citsent>
<aftsection>
<nextsent>in the brown algorithm class assignment function is selected such that the class bigram likelihood of the corpus, p(m |g), is maximized.
</nextsent>
<nextsent>morphological and distributional information is introduced to the clark model through prior p(g).
</nextsent>
<nextsent>the prior prefers morphologically uniform clusters and skewed cluster sizes.
</nextsent>
<nextsent>the probability function the algorithm tries to maximize is: (1) p(m, g) = p(m |g) ? p(g) (2) p(m |g) = i=ni=2 p(g(wi)|g(wi1)) (3) p(g) = nj=1 ? g(w)=j qj(w) where qj(wi) is the probability of assigningwi ? by cluster cj according to the morphological model and is the coefficient of clusterj, which equals to the number of word types assigned to that cluster divided by the total number of word types in the vocabulary . the objective of the algorithm is formally specified by: g?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4365">
<title id=" W10-2909.xml">improved unsupervised pos induction using intrinsic clustering quality and a zipfian constraint </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>in the rest of this paper we show results where the exponent value is 1.1.
</prevsent>
<prevsent>unsupervised pos induction/tagging is fruitful area of research.
</prevsent>
</prevsection>
<citsent citstr=" J94-2001 ">
a major direction is hidden markov models (hmm) (merialdo, 1994; <papid> J94-2001 </papid>banko and moore, 2004; wang and schuurmans, 2005).</citsent>
<aftsection>
<nextsent>several recent works have tried to improve this model using bayesian estimation (goldwater and griffiths, 2007;<papid> P07-1094 </papid> johnson, 2007; <papid> D07-1031 </papid>gao and johnson, 2008), <papid> D08-1036 </papid>sophisticated initialization (goldberg et al, 2008), <papid> P08-1085 </papid>induction of an initial clustering used to train an hmm (freitag, 2004; <papid> C04-1052 </papid>biemann, 2006),<papid> P06-3002 </papid>infinite hmm models (van gael et al, 2009), integration of integer linear programming into the parameter estimation process (ravi and knight,2009), <papid> P09-1057 </papid>and biasing the model such that the number of possible tags that each word can get is small (graca et al, 2009).</nextsent>
<nextsent>the bayesian works integrated into the model information about the distribution of words to pos tags.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4370">
<title id=" W10-2909.xml">improved unsupervised pos induction using intrinsic clustering quality and a zipfian constraint </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>unsupervised pos induction/tagging is fruitful area of research.
</prevsent>
<prevsent>a major direction is hidden markov models (hmm) (merialdo, 1994; <papid> J94-2001 </papid>banko and moore, 2004; wang and schuurmans, 2005).</prevsent>
</prevsection>
<citsent citstr=" D08-1036 ">
several recent works have tried to improve this model using bayesian estimation (goldwater and griffiths, 2007;<papid> P07-1094 </papid> johnson, 2007; <papid> D07-1031 </papid>gao and johnson, 2008), <papid> D08-1036 </papid>sophisticated initialization (goldberg et al, 2008), <papid> P08-1085 </papid>induction of an initial clustering used to train an hmm (freitag, 2004; <papid> C04-1052 </papid>biemann, 2006),<papid> P06-3002 </papid>infinite hmm models (van gael et al, 2009), integration of integer linear programming into the parameter estimation process (ravi and knight,2009), <papid> P09-1057 </papid>and biasing the model such that the number of possible tags that each word can get is small (graca et al, 2009).</citsent>
<aftsection>
<nextsent>the bayesian works integrated into the model information about the distribution of words to pos tags.
</nextsent>
<nextsent>for example, johnson (2007) <papid> D07-1031 </papid>integrated tothe em-hmm model prior that prefers cluster ings where the distributions of hidden states to words is skewed.</nextsent>
<nextsent>other approaches include transformation based learning (brill, 1995), <papid> W95-0101 </papid>contrastive estimation for conditional random fields (smith and eisner, 2005), <papid> P05-1044 </papid>markov random fields (haghighi and klein, 2006), <papid> N06-1041 </papid>multilingual approach (snyder et al., 2008; <papid> D08-1109 </papid>snyder et al, 2008) <papid> D08-1109 </papid>and expanding 3the figure is for greedy many-to-one mapping and spear mans rank correlation coefficient, explained in further sections.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4372">
<title id=" W10-2909.xml">improved unsupervised pos induction using intrinsic clustering quality and a zipfian constraint </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>unsupervised pos induction/tagging is fruitful area of research.
</prevsent>
<prevsent>a major direction is hidden markov models (hmm) (merialdo, 1994; <papid> J94-2001 </papid>banko and moore, 2004; wang and schuurmans, 2005).</prevsent>
</prevsection>
<citsent citstr=" P08-1085 ">
several recent works have tried to improve this model using bayesian estimation (goldwater and griffiths, 2007;<papid> P07-1094 </papid> johnson, 2007; <papid> D07-1031 </papid>gao and johnson, 2008), <papid> D08-1036 </papid>sophisticated initialization (goldberg et al, 2008), <papid> P08-1085 </papid>induction of an initial clustering used to train an hmm (freitag, 2004; <papid> C04-1052 </papid>biemann, 2006),<papid> P06-3002 </papid>infinite hmm models (van gael et al, 2009), integration of integer linear programming into the parameter estimation process (ravi and knight,2009), <papid> P09-1057 </papid>and biasing the model such that the number of possible tags that each word can get is small (graca et al, 2009).</citsent>
<aftsection>
<nextsent>the bayesian works integrated into the model information about the distribution of words to pos tags.
</nextsent>
<nextsent>for example, johnson (2007) <papid> D07-1031 </papid>integrated tothe em-hmm model prior that prefers cluster ings where the distributions of hidden states to words is skewed.</nextsent>
<nextsent>other approaches include transformation based learning (brill, 1995), <papid> W95-0101 </papid>contrastive estimation for conditional random fields (smith and eisner, 2005), <papid> P05-1044 </papid>markov random fields (haghighi and klein, 2006), <papid> N06-1041 </papid>multilingual approach (snyder et al., 2008; <papid> D08-1109 </papid>snyder et al, 2008) <papid> D08-1109 </papid>and expanding 3the figure is for greedy many-to-one mapping and spear mans rank correlation coefficient, explained in further sections.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4373">
<title id=" W10-2909.xml">improved unsupervised pos induction using intrinsic clustering quality and a zipfian constraint </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>unsupervised pos induction/tagging is fruitful area of research.
</prevsent>
<prevsent>a major direction is hidden markov models (hmm) (merialdo, 1994; <papid> J94-2001 </papid>banko and moore, 2004; wang and schuurmans, 2005).</prevsent>
</prevsection>
<citsent citstr=" C04-1052 ">
several recent works have tried to improve this model using bayesian estimation (goldwater and griffiths, 2007;<papid> P07-1094 </papid> johnson, 2007; <papid> D07-1031 </papid>gao and johnson, 2008), <papid> D08-1036 </papid>sophisticated initialization (goldberg et al, 2008), <papid> P08-1085 </papid>induction of an initial clustering used to train an hmm (freitag, 2004; <papid> C04-1052 </papid>biemann, 2006),<papid> P06-3002 </papid>infinite hmm models (van gael et al, 2009), integration of integer linear programming into the parameter estimation process (ravi and knight,2009), <papid> P09-1057 </papid>and biasing the model such that the number of possible tags that each word can get is small (graca et al, 2009).</citsent>
<aftsection>
<nextsent>the bayesian works integrated into the model information about the distribution of words to pos tags.
</nextsent>
<nextsent>for example, johnson (2007) <papid> D07-1031 </papid>integrated tothe em-hmm model prior that prefers cluster ings where the distributions of hidden states to words is skewed.</nextsent>
<nextsent>other approaches include transformation based learning (brill, 1995), <papid> W95-0101 </papid>contrastive estimation for conditional random fields (smith and eisner, 2005), <papid> P05-1044 </papid>markov random fields (haghighi and klein, 2006), <papid> N06-1041 </papid>multilingual approach (snyder et al., 2008; <papid> D08-1109 </papid>snyder et al, 2008) <papid> D08-1109 </papid>and expanding 3the figure is for greedy many-to-one mapping and spear mans rank correlation coefficient, explained in further sections.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4374">
<title id=" W10-2909.xml">improved unsupervised pos induction using intrinsic clustering quality and a zipfian constraint </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>unsupervised pos induction/tagging is fruitful area of research.
</prevsent>
<prevsent>a major direction is hidden markov models (hmm) (merialdo, 1994; <papid> J94-2001 </papid>banko and moore, 2004; wang and schuurmans, 2005).</prevsent>
</prevsection>
<citsent citstr=" P06-3002 ">
several recent works have tried to improve this model using bayesian estimation (goldwater and griffiths, 2007;<papid> P07-1094 </papid> johnson, 2007; <papid> D07-1031 </papid>gao and johnson, 2008), <papid> D08-1036 </papid>sophisticated initialization (goldberg et al, 2008), <papid> P08-1085 </papid>induction of an initial clustering used to train an hmm (freitag, 2004; <papid> C04-1052 </papid>biemann, 2006),<papid> P06-3002 </papid>infinite hmm models (van gael et al, 2009), integration of integer linear programming into the parameter estimation process (ravi and knight,2009), <papid> P09-1057 </papid>and biasing the model such that the number of possible tags that each word can get is small (graca et al, 2009).</citsent>
<aftsection>
<nextsent>the bayesian works integrated into the model information about the distribution of words to pos tags.
</nextsent>
<nextsent>for example, johnson (2007) <papid> D07-1031 </papid>integrated tothe em-hmm model prior that prefers cluster ings where the distributions of hidden states to words is skewed.</nextsent>
<nextsent>other approaches include transformation based learning (brill, 1995), <papid> W95-0101 </papid>contrastive estimation for conditional random fields (smith and eisner, 2005), <papid> P05-1044 </papid>markov random fields (haghighi and klein, 2006), <papid> N06-1041 </papid>multilingual approach (snyder et al., 2008; <papid> D08-1109 </papid>snyder et al, 2008) <papid> D08-1109 </papid>and expanding 3the figure is for greedy many-to-one mapping and spear mans rank correlation coefficient, explained in further sections.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4375">
<title id=" W10-2909.xml">improved unsupervised pos induction using intrinsic clustering quality and a zipfian constraint </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>unsupervised pos induction/tagging is fruitful area of research.
</prevsent>
<prevsent>a major direction is hidden markov models (hmm) (merialdo, 1994; <papid> J94-2001 </papid>banko and moore, 2004; wang and schuurmans, 2005).</prevsent>
</prevsection>
<citsent citstr=" P09-1057 ">
several recent works have tried to improve this model using bayesian estimation (goldwater and griffiths, 2007;<papid> P07-1094 </papid> johnson, 2007; <papid> D07-1031 </papid>gao and johnson, 2008), <papid> D08-1036 </papid>sophisticated initialization (goldberg et al, 2008), <papid> P08-1085 </papid>induction of an initial clustering used to train an hmm (freitag, 2004; <papid> C04-1052 </papid>biemann, 2006),<papid> P06-3002 </papid>infinite hmm models (van gael et al, 2009), integration of integer linear programming into the parameter estimation process (ravi and knight,2009), <papid> P09-1057 </papid>and biasing the model such that the number of possible tags that each word can get is small (graca et al, 2009).</citsent>
<aftsection>
<nextsent>the bayesian works integrated into the model information about the distribution of words to pos tags.
</nextsent>
<nextsent>for example, johnson (2007) <papid> D07-1031 </papid>integrated tothe em-hmm model prior that prefers cluster ings where the distributions of hidden states to words is skewed.</nextsent>
<nextsent>other approaches include transformation based learning (brill, 1995), <papid> W95-0101 </papid>contrastive estimation for conditional random fields (smith and eisner, 2005), <papid> P05-1044 </papid>markov random fields (haghighi and klein, 2006), <papid> N06-1041 </papid>multilingual approach (snyder et al., 2008; <papid> D08-1109 </papid>snyder et al, 2008) <papid> D08-1109 </papid>and expanding 3the figure is for greedy many-to-one mapping and spear mans rank correlation coefficient, explained in further sections.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4377">
<title id=" W10-2909.xml">improved unsupervised pos induction using intrinsic clustering quality and a zipfian constraint </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>the bayesian works integrated into the model information about the distribution of words to pos tags.
</prevsent>
<prevsent>for example, johnson (2007) <papid> D07-1031 </papid>integrated tothe em-hmm model prior that prefers cluster ings where the distributions of hidden states to words is skewed.</prevsent>
</prevsection>
<citsent citstr=" W95-0101 ">
other approaches include transformation based learning (brill, 1995), <papid> W95-0101 </papid>contrastive estimation for conditional random fields (smith and eisner, 2005), <papid> P05-1044 </papid>markov random fields (haghighi and klein, 2006), <papid> N06-1041 </papid>multilingual approach (snyder et al., 2008; <papid> D08-1109 </papid>snyder et al, 2008) <papid> D08-1109 </papid>and expanding 3the figure is for greedy many-to-one mapping and spear mans rank correlation coefficient, explained in further sections.</citsent>
<aftsection>
<nextsent>other external measures and rank correlation scores demonstrate the same pattern.partial dictionary and use it to learn disambiguation rules (zhao and marcus, 2009).<papid> D09-1072 </papid></nextsent>
<nextsent>these works, except (haghighi and klein, 2006; <papid> N06-1041 </papid>johnson, 2007; <papid> D07-1031 </papid>gao and johnson, 2008) <papid> D08-1036 </papid>and one experiment in (goldwater and griffiths, 2007), <papid> P07-1094 </papid>used dictionary listing the allowable tagsfor each word in the text.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4379">
<title id=" W10-2909.xml">improved unsupervised pos induction using intrinsic clustering quality and a zipfian constraint </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>the bayesian works integrated into the model information about the distribution of words to pos tags.
</prevsent>
<prevsent>for example, johnson (2007) <papid> D07-1031 </papid>integrated tothe em-hmm model prior that prefers cluster ings where the distributions of hidden states to words is skewed.</prevsent>
</prevsection>
<citsent citstr=" N06-1041 ">
other approaches include transformation based learning (brill, 1995), <papid> W95-0101 </papid>contrastive estimation for conditional random fields (smith and eisner, 2005), <papid> P05-1044 </papid>markov random fields (haghighi and klein, 2006), <papid> N06-1041 </papid>multilingual approach (snyder et al., 2008; <papid> D08-1109 </papid>snyder et al, 2008) <papid> D08-1109 </papid>and expanding 3the figure is for greedy many-to-one mapping and spear mans rank correlation coefficient, explained in further sections.</citsent>
<aftsection>
<nextsent>other external measures and rank correlation scores demonstrate the same pattern.partial dictionary and use it to learn disambiguation rules (zhao and marcus, 2009).<papid> D09-1072 </papid></nextsent>
<nextsent>these works, except (haghighi and klein, 2006; <papid> N06-1041 </papid>johnson, 2007; <papid> D07-1031 </papid>gao and johnson, 2008) <papid> D08-1036 </papid>and one experiment in (goldwater and griffiths, 2007), <papid> P07-1094 </papid>used dictionary listing the allowable tagsfor each word in the text.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4381">
<title id=" W10-2909.xml">improved unsupervised pos induction using intrinsic clustering quality and a zipfian constraint </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>the bayesian works integrated into the model information about the distribution of words to pos tags.
</prevsent>
<prevsent>for example, johnson (2007) <papid> D07-1031 </papid>integrated tothe em-hmm model prior that prefers cluster ings where the distributions of hidden states to words is skewed.</prevsent>
</prevsection>
<citsent citstr=" D08-1109 ">
other approaches include transformation based learning (brill, 1995), <papid> W95-0101 </papid>contrastive estimation for conditional random fields (smith and eisner, 2005), <papid> P05-1044 </papid>markov random fields (haghighi and klein, 2006), <papid> N06-1041 </papid>multilingual approach (snyder et al., 2008; <papid> D08-1109 </papid>snyder et al, 2008) <papid> D08-1109 </papid>and expanding 3the figure is for greedy many-to-one mapping and spear mans rank correlation coefficient, explained in further sections.</citsent>
<aftsection>
<nextsent>other external measures and rank correlation scores demonstrate the same pattern.partial dictionary and use it to learn disambiguation rules (zhao and marcus, 2009).<papid> D09-1072 </papid></nextsent>
<nextsent>these works, except (haghighi and klein, 2006; <papid> N06-1041 </papid>johnson, 2007; <papid> D07-1031 </papid>gao and johnson, 2008) <papid> D08-1036 </papid>and one experiment in (goldwater and griffiths, 2007), <papid> P07-1094 </papid>used dictionary listing the allowable tagsfor each word in the text.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4383">
<title id=" W10-2909.xml">improved unsupervised pos induction using intrinsic clustering quality and a zipfian constraint </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>for example, johnson (2007) <papid> D07-1031 </papid>integrated tothe em-hmm model prior that prefers cluster ings where the distributions of hidden states to words is skewed.</prevsent>
<prevsent>other approaches include transformation based learning (brill, 1995), <papid> W95-0101 </papid>contrastive estimation for conditional random fields (smith and eisner, 2005), <papid> P05-1044 </papid>markov random fields (haghighi and klein, 2006), <papid> N06-1041 </papid>multilingual approach (snyder et al., 2008; <papid> D08-1109 </papid>snyder et al, 2008) <papid> D08-1109 </papid>and expanding 3the figure is for greedy many-to-one mapping and spear mans rank correlation coefficient, explained in further sections.</prevsent>
</prevsection>
<citsent citstr=" D09-1072 ">
other external measures and rank correlation scores demonstrate the same pattern.partial dictionary and use it to learn disambiguation rules (zhao and marcus, 2009).<papid> D09-1072 </papid></citsent>
<aftsection>
<nextsent>these works, except (haghighi and klein, 2006; <papid> N06-1041 </papid>johnson, 2007; <papid> D07-1031 </papid>gao and johnson, 2008) <papid> D08-1036 </papid>and one experiment in (goldwater and griffiths, 2007), <papid> P07-1094 </papid>used dictionary listing the allowable tagsfor each word in the text.</nextsent>
<nextsent>this dictionary is usually extracted from the manual tagging of the text, contradicting the unsupervised nature of the task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4395">
<title id=" W10-2909.xml">improved unsupervised pos induction using intrinsic clustering quality and a zipfian constraint </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>clearly, the availability of such dictionary is not always reasonable assumption (see e.g.
</prevsent>
<prevsent>(gold water and griffiths, 2007)).<papid> P07-1094 </papid></prevsent>
</prevsection>
<citsent citstr=" D07-1023 ">
in different algorithmic direction, (schuetze, 1995) applied latent semantic analysis with svd based dimensionality reduction, and (schuetze, 1995; clark, 2003; <papid> E03-1009 </papid>dasgupta and ng, 2007) <papid> D07-1023 </papid>used distributional and morphological statistics to find meaningful word types clusters.</citsent>
<aftsection>
<nextsent>clark (2003) <papid> E03-1009 </papid>is the only such work to have evaluated its algorithm as pos tagger for large corpora, like we do in this paper.</nextsent>
<nextsent>a zipfian constraint was utilized in (goldwaterand et al, 2006) for language modeling and morphological disambiguation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4412">
<title id=" W10-2909.xml">improved unsupervised pos induction using intrinsic clustering quality and a zipfian constraint </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>moreover, we show that our algorithm outperforms existing pos taggers for most evaluation measures (table 3).
</prevsent>
<prevsent>identifying good solutions among many runs of randomly-initialized algorithm is well known problem.
</prevsent>
</prevsection>
<citsent citstr=" P04-1062 ">
we discuss here the work of (smith and eisner, 2004) <papid> P04-1062 </papid>that addressed the problem in the unsupervised pos tagging context.</citsent>
<aftsection>
<nextsent>in this work, deterministic annealing (rose et al, 1990) was ap 61 plied to an hmm model for unsupervised pos tagging with dictionary.
</nextsent>
<nextsent>this method is not sensitive to its initialization, and while it is not theoretically guaranteed to converge to better solution than the traditional em-hmm, it was experimentally shown to achieve better results.
</nextsent>
<nextsent>the problem has, of course, been addressed in other contexts as well (see, e.g., (wang et al, 2002)).
</nextsent>
<nextsent>setup.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4415">
<title id=" W10-2909.xml">improved unsupervised pos induction using intrinsic clustering quality and a zipfian constraint </title>
<section> experimental setup and evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>many evaluation measures for unsupervised clustering against gold standardexist.
</prevsent>
<prevsent>here we use measures from two well accepted families: mapping based and information theoretic (it) based.
</prevsent>
</prevsection>
<citsent citstr=" W09-1121 ">
for recent discussion on this subject see (reichart and rappoport, 2009).<papid> W09-1121 </papid></citsent>
<aftsection>
<nextsent>the mapping based measures are accuracy with greedy many-to-1 (m-1) and with greedy 1-to-1 (1-1) mappings of the induced to the gold labels.
</nextsent>
<nextsent>in the former mapping, two induced clusters can be mapped to the same gold standard cluster, whilein the latter mapping each and every induced cluster is assigned unique gold cluster.
</nextsent>
<nextsent>after each induced label is mapped to gold label, tagging accuracy is computed.
</nextsent>
<nextsent>accuracy is defined to be the number of correctly tagged words in the corpus divided by the total number of words in the corpus.the it based measures we use are (rosen berg and hirschberg, 2007) <papid> D07-1043 </papid>and nvi (reichart and rappoport, 2009).<papid> W09-1121 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4418">
<title id=" W10-2909.xml">improved unsupervised pos induction using intrinsic clustering quality and a zipfian constraint </title>
<section> experimental setup and evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>in the former mapping, two induced clusters can be mapped to the same gold standard cluster, whilein the latter mapping each and every induced cluster is assigned unique gold cluster.
</prevsent>
<prevsent>after each induced label is mapped to gold label, tagging accuracy is computed.
</prevsent>
</prevsection>
<citsent citstr=" D07-1043 ">
accuracy is defined to be the number of correctly tagged words in the corpus divided by the total number of words in the corpus.the it based measures we use are (rosen berg and hirschberg, 2007) <papid> D07-1043 </papid>and nvi (reichart and rappoport, 2009).<papid> W09-1121 </papid></citsent>
<aftsection>
<nextsent>the latter is normalization of the vi measure (meila, 2007).
</nextsent>
<nextsent>vi and nvi induce the same order over clusterings but nvi values for good clusterings lie in [0, 1].
</nextsent>
<nextsent>for v, the higher the score, the better the clustering.
</nextsent>
<nextsent>for nvi lower scores imply improved clustering quality.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4422">
<title id=" W10-2909.xml">improved unsupervised pos induction using intrinsic clustering quality and a zipfian constraint </title>
<section> experimental setup and evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>the measures are given by the equations: (6) kendall ? tau = 2(ncnd)r(r1) (7) spears man = 1 ? 6 i=1 2 r(r21) 62 0 10 20 30 400 0.2 0.4 0.6 0.8 1 number of pos tags ra ct io o it m figure 3: the fraction of word types (solid curve) and word instances (dashed curve) labeled with the (x axis) most frequent pos tags (in types and tokens respectively) in sections 2-21 of the wsj corpus.
</prevsent>
<prevsent>where is the number of runs (100 in our case),nc and nd are the numbers of concordant and discordant pairs respectively6 and di is the absolute value of the difference between the ranks of item i. the two measures have the properties that perfect agreement between rankings results in score of 1, perfect disagreement results in score of 1, completely independent rankings have the value of 0 on the average, the range of values is between 1 and 1, and increasing values imply increasing agreement between the rankings.
</prevsent>
</prevsection>
<citsent citstr=" J06-4002 ">
for discussion see (lapata, 2006).<papid> J06-4002 </papid></citsent>
<aftsection>
<nextsent>table 1 presents the results of the q(zcc) and q(ct) algorithms, which are both better than those of the original clark tagger ct. the algorithms provide tagging that is better than that produced by ct in 82-100% (q(zcc)) and 75 100% (q(ct)) of the cases.the q(zcc) algorithm is superior when evaluated with the mapping based measures.
</nextsent>
<nextsent>the q(ct) algorithm is superior when evaluated with the it measures.
</nextsent>
<nextsent>table 3 presents reported results for all recent algorithms we are aware of that tackled the task of unsupervised pos induction from plain text 7.
</nextsent>
<nextsent>the settings of the various experiments vary in terms of the exact gold annotation scheme used for evaluation (the full wsj set was used by all authors except goldwater and griffiths (2007) <papid> P07-1094 </papid>and 6a pair r, in two lists and is concordant if sign(xt ? xr) = sign(yt ? yr), where xr is the index of in the list . 7vg and gg used 2 as the base of the logarithm in it measures, which affects vi.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4443">
<title id=" W10-1748.xml">bbn system description for wmt10 system combination task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>on the multi-source condition, the system combination gained 6.6 bleu points.
</prevsent>
<prevsent>the bbn submissions to the wmt10 system combination task were based on confusion network decoding.
</prevsent>
</prevsection>
<citsent citstr=" W09-0409 ">
the confusion networks were built using the incremental hypothesis alignment algorithm with flexible matching introduced in thebbn submission for the wmt09 system combination task (rosti et al, 2009).<papid> W09-0409 </papid></citsent>
<aftsection>
<nextsent>this year, the system combination weights were tuned to maximize the bleu score (papineni et al, 2002) <papid> P02-1040 </papid>of the 1-best decoding output (lattice based bleu tuning) using downhill simplex method (press etal., 2007).</nextsent>
<nextsent>a 44 system multi-source combination was also submitted.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4444">
<title id=" W10-1748.xml">bbn system description for wmt10 system combination task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the bbn submissions to the wmt10 system combination task were based on confusion network decoding.
</prevsent>
<prevsent>the confusion networks were built using the incremental hypothesis alignment algorithm with flexible matching introduced in thebbn submission for the wmt09 system combination task (rosti et al, 2009).<papid> W09-0409 </papid></prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
this year, the system combination weights were tuned to maximize the bleu score (papineni et al, 2002) <papid> P02-1040 </papid>of the 1-best decoding output (lattice based bleu tuning) using downhill simplex method (press etal., 2007).</citsent>
<aftsection>
<nextsent>a 44 system multi-source combination was also submitted.
</nextsent>
<nextsent>since the gradient-free optimization algorithms do not seem to be able to handle more than 20-30 weights, gradient ascent to maximize an approximate expected bleu objective was used to optimize the larger number of weights.the lattice based bleu tuning may be implemented using any optimization algorithm that does not require the gradient of the objective function.due to the size of the lattices, the objective function evaluation may have to be distributed to multiple servers.
</nextsent>
<nextsent>the optimizer client accumulates the bleu statistics of the 1-best hypotheses from the servers forgiven search weights, computes the final bleu score, and passes it to the optimization algorithm which returns new set of searchweights.
</nextsent>
<nextsent>the lattice based tuning explores the entire search space and does not require multiple decoding iterations with -best list merging to approximate the search space as in the standard minimum error rate training (och, 2003).<papid> P03-1021 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4445">
<title id=" W10-1748.xml">bbn system description for wmt10 system combination task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>since the gradient-free optimization algorithms do not seem to be able to handle more than 20-30 weights, gradient ascent to maximize an approximate expected bleu objective was used to optimize the larger number of weights.the lattice based bleu tuning may be implemented using any optimization algorithm that does not require the gradient of the objective function.due to the size of the lattices, the objective function evaluation may have to be distributed to multiple servers.
</prevsent>
<prevsent>the optimizer client accumulates the bleu statistics of the 1-best hypotheses from the servers forgiven search weights, computes the final bleu score, and passes it to the optimization algorithm which returns new set of searchweights.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
the lattice based tuning explores the entire search space and does not require multiple decoding iterations with -best list merging to approximate the search space as in the standard minimum error rate training (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>this allows much faster turnaround in weight tuning.
</nextsent>
<nextsent>differentiable approximations of bleu have been proposed for consensus decoding.
</nextsent>
<nextsent>tromble et al (2008) <papid> D08-1065 </papid>used linear approximation and pauls et al (2009) <papid> D09-1147 </papid>used closer approximation calledcobleu.</nextsent>
<nextsent>cobleu is based on the bleu formula but the n-gram counts are replaced by expected counts over translation forest.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4446">
<title id=" W10-1748.xml">bbn system description for wmt10 system combination task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this allows much faster turnaround in weight tuning.
</prevsent>
<prevsent>differentiable approximations of bleu have been proposed for consensus decoding.
</prevsent>
</prevsection>
<citsent citstr=" D08-1065 ">
tromble et al (2008) <papid> D08-1065 </papid>used linear approximation and pauls et al (2009) <papid> D09-1147 </papid>used closer approximation calledcobleu.</citsent>
<aftsection>
<nextsent>cobleu is based on the bleu formula but the n-gram counts are replaced by expected counts over translation forest.
</nextsent>
<nextsent>due to the min-functions required in converting the n-gram counts to matches and non-differentiable brevity penalty, sub-gradient ascent must be used.
</nextsent>
<nextsent>inthis work, an approximate expected bleu (exp bleu) defined over -best lists was used as differentiable objective function.
</nextsent>
<nextsent>expbleu uses expected bleu statistics where the min-functionis not needed as the statistics are computed offline and the brevity penalty is replaced by differentiable approximation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4447">
<title id=" W10-1748.xml">bbn system description for wmt10 system combination task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this allows much faster turnaround in weight tuning.
</prevsent>
<prevsent>differentiable approximations of bleu have been proposed for consensus decoding.
</prevsent>
</prevsection>
<citsent citstr=" D09-1147 ">
tromble et al (2008) <papid> D08-1065 </papid>used linear approximation and pauls et al (2009) <papid> D09-1147 </papid>used closer approximation calledcobleu.</citsent>
<aftsection>
<nextsent>cobleu is based on the bleu formula but the n-gram counts are replaced by expected counts over translation forest.
</nextsent>
<nextsent>due to the min-functions required in converting the n-gram counts to matches and non-differentiable brevity penalty, sub-gradient ascent must be used.
</nextsent>
<nextsent>inthis work, an approximate expected bleu (exp bleu) defined over -best lists was used as differentiable objective function.
</nextsent>
<nextsent>expbleu uses expected bleu statistics where the min-functionis not needed as the statistics are computed offline and the brevity penalty is replaced by differentiable approximation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4449">
<title id=" W10-1748.xml">bbn system description for wmt10 system combination task </title>
<section> hypothesis alignment.  </section>
<citcontext>
<prevsection>
<prevsent>the alignment algorithm explores shifts of blocks of words that minimize the edit distance between the current confusion network and an unaligned hypothe1hypotheses are tokenized and lower-cased prior to alignment.
</prevsent>
<prevsent>tokens generally refer to words and punctuation.
</prevsent>
</prevsection>
<citsent citstr=" W09-0441 ">
2http://www.cs.umd.edu/snover/tercom/ current version 0.7.25.3this algorithm is not equivalent to an incremental ter plus (snover et al, 2009) <papid> W09-0441 </papid>due to different shift constraints and the lack of paraphrase matching 30 1cat(1) 2sat(1) mat(1) (a) skeleton hypothesis.</citsent>
<aftsection>
<nextsent>40 1cat(1), 40 1cat(1) 2sat(1),  2sat(1) 3on(0),  3on(1)null(1), null(0) mat(1),  mat(1) (b) two hypotheses (insertion).
</nextsent>
<nextsent>40 1cat(1,1,0)null(0,0,1) 2sat(1,1,1) 3on(0,1,0)null(1,0,1) mat(1,1,1) (c) three hypotheses (deletion).
</nextsent>
<nextsent>40 1cat(1,1,0,1)null(0,0,1,0) 2sat(1,1,1,1) 3on(0,1,0,0)null(1,0,1,1) mat(1,1,1,0)hat(0,0,0,1) (d) four hypotheses (substitution).
</nextsent>
<nextsent>figure 1: example of incrementally aligning cat sat mat?, cat sat on mat?, sat mat?, and cat sat hat?.sis.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4450">
<title id=" W10-1748.xml">bbn system description for wmt10 system combination task </title>
<section> hypothesis alignment.  </section>
<citcontext>
<prevsection>
<prevsent>which becomes substitution for mat?
</prevsent>
<prevsent>in figure 1(d).
</prevsent>
</prevsection>
<citsent citstr=" P07-1040 ">
the binary vectors in the parentheses following each token show which system generated the token aligned to that arc. ifthe systems generated -best hypotheses, fractional increment could be added to these vector sas in (rosti et al, 2007).<papid> P07-1040 </papid></citsent>
<aftsection>
<nextsent>given these system specific scores are normalized to sum to one over all arcs connecting two consecutive nodes, they may be viewed as system specific word arc posterior estimates.
</nextsent>
<nextsent>note, for 1-best hypotheses the scores sum to one without normalization.
</nextsent>
<nextsent>given system outputs = {e1, . . .
</nextsent>
<nextsent>, ens}, an algorithm to build set of ns confusion networks = {c1, . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4453">
<title id=" W10-3602.xml">thai sentence breaking for largescale smt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>thai is one such language, since it uses space neither to distinguish syllables from words or affixes, nor to unambiguously signal sentence boundaries.
</prevsent>
<prevsent>written thai has no sentence-end punctuation, but space character is always present between sentences.
</prevsent>
</prevsection>
<citsent citstr=" J97-2002 ">
there is generally no space between words, but space character may appear within sentence according to linguistic or prescriptive orthographic motivation (wathabunditkul 2003), and these characteristics disqualify sentence breaking (sb) methods used for other languages, such as palmer and hearst (1997).<papid> J97-2002 </papid></citsent>
<aftsection>
<nextsent>thai sb has therefore been regarded as the task of classifying each space that appears in thai source text as either sentence-breaking (sb) or non-sentence breaking (nsb).
</nextsent>
<nextsent>several researchers have investigated thai sb.
</nextsent>
<nextsent>along with discussion of thai word breaking (wb), aroonmanakun (2007) examines the issue.
</nextsent>
<nextsent>with human study, he establishes that sentence breaks elicited from thai informants exhibit varying degrees of consensus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4454">
<title id=" W10-3602.xml">thai sentence breaking for largescale smt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>charoenpornsawat and sornlertlamvanich (2001) apply winnow, multiplicative trigger threshold classifier, to the problem.
</prevsent>
<prevsent>their model has ten features: the number of words to the left and right, and the left-two and right-two pos tags and words.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
we present monolingual thai sb based on maximum entropy (me) classifier (ratnaparkhi 1996; <papid> W96-0213 </papid>reynar and ratnaparkhi, 1997) <papid> A97-1004 </papid>which is suitable for sentence-breaking smt training data and runtime inputs.</citsent>
<aftsection>
<nextsent>our model uses four token window of thai lemmas, plus categorical features, to describe the proximal environment of the space token under consideration, allowing runtime classification of space tokens with possibly unseen contexts.
</nextsent>
<nextsent>as our sb model relies on thai wb, we review our approach to this problem, plus related preprocessing, in the next section.
</nextsent>
<nextsent>section 2 also discusses the complementary operation to wb, namely, the re-spacing of thai text generated by smt output.
</nextsent>
<nextsent>section 3 details our sb model and evaluates its performance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4455">
<title id=" W10-3602.xml">thai sentence breaking for largescale smt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>charoenpornsawat and sornlertlamvanich (2001) apply winnow, multiplicative trigger threshold classifier, to the problem.
</prevsent>
<prevsent>their model has ten features: the number of words to the left and right, and the left-two and right-two pos tags and words.
</prevsent>
</prevsection>
<citsent citstr=" A97-1004 ">
we present monolingual thai sb based on maximum entropy (me) classifier (ratnaparkhi 1996; <papid> W96-0213 </papid>reynar and ratnaparkhi, 1997) <papid> A97-1004 </papid>which is suitable for sentence-breaking smt training data and runtime inputs.</citsent>
<aftsection>
<nextsent>our model uses four token window of thai lemmas, plus categorical features, to describe the proximal environment of the space token under consideration, allowing runtime classification of space tokens with possibly unseen contexts.
</nextsent>
<nextsent>as our sb model relies on thai wb, we review our approach to this problem, plus related preprocessing, in the next section.
</nextsent>
<nextsent>section 2 also discusses the complementary operation to wb, namely, the re-spacing of thai text generated by smt output.
</nextsent>
<nextsent>section 3 details our sb model and evaluates its performance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4456">
<title id=" W10-3602.xml">thai sentence breaking for largescale smt </title>
<section> smt system and integration.  </section>
<citcontext>
<prevsection>
<prevsent>and ?(?)
</prevsent>
<prevsent>are trained, the combination weights ??
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
are tuned on held-out dataset to optimize an objective function, which we set to be the bleu score (papineni et al 2002): {???}<papid> P02-1040 </papid></citsent>
<aftsection>
<nextsent>= max{??}
</nextsent>
<nextsent>bleu({??}, {?}) ??
</nextsent>
<nextsent>= argmaxe {log ? ??(?|?)
</nextsent>
<nextsent>+log ? ??(?)} where {r} is the set of gold translations for the given input source sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4457">
<title id=" W10-3602.xml">thai sentence breaking for largescale smt </title>
<section> smt system and integration.  </section>
<citcontext>
<prevsection>
<prevsent>+log ? ??(?)} where {r} is the set of gold translations for the given input source sentences.
</prevsent>
<prevsent>to learn ??
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
we use the algorithm described by och (2003), <papid> P03-1021 </papid>where the decoder output at any point is approximated using n-best lists, allowing an optimal line search to be employed.</citsent>
<aftsection>
<nextsent>4.2 phrasal and treelet translation.
</nextsent>
<nextsent>since we have high-quality real-time rule based english parser available, we base our eng 13 lish-to-thai translation (eng-tha) on the treelet?
</nextsent>
<nextsent>concept suggested in menezes and quirk (2008).<papid> D08-1077 </papid></nextsent>
<nextsent>this approach parses the source language into dependency tree which includes part-of-speech labels.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4458">
<title id=" W10-3602.xml">thai sentence breaking for largescale smt </title>
<section> smt system and integration.  </section>
<citcontext>
<prevsection>
<prevsent>4.2 phrasal and treelet translation.
</prevsent>
<prevsent>since we have high-quality real-time rule based english parser available, we base our eng 13 lish-to-thai translation (eng-tha) on the treelet?
</prevsent>
</prevsection>
<citsent citstr=" D08-1077 ">
concept suggested in menezes and quirk (2008).<papid> D08-1077 </papid></citsent>
<aftsection>
<nextsent>this approach parses the source language into dependency tree which includes part-of-speech labels.
</nextsent>
<nextsent>lacking thai parser, we use purely statistical phrasal translator after pharaoh (koehn 2004) for tha-eng translation, where we adopt the name and date translation described in sections 2.3 and 2.4.
</nextsent>
<nextsent>we also experimented with phrasal eng tha translation.
</nextsent>
<nextsent>though we actually achieved slightly better bleu score than treelet for this translation direction, qualitative human evaluation by native speaker informants was mixed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4459">
<title id=" W10-3206.xml">construction of bilingual multimodal corpora of referring expressions in collaborative problem solving </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in fact, research on reference resolution has developed significantly as result of large scale corpora, e.g. those provided by the message understanding conference (muc)1 and the automatic content extraction (ace)2 project.
</prevsent>
<prevsent>these corpora were constructed primarily for information extraction research, thus were annotated with co-reference relations within texts.
</prevsent>
</prevsection>
<citsent citstr=" L08-1033 ">
also in the language generation community, several corpora 1http://www.nlpir.nist.gov/related projects/muc/ 2http://www.itl.nist.gov/iad/tests/ace/ 38have been developed (di eugenio et al, 2000; byron, 2005; van deemter et al, 2006; foster and oberlander, 2007; foster et al, 2008; stoia et al, 2008; <papid> L08-1033 </papid>spanger et al, 2009<papid> W09-0618 </papid>a; belz et al, 2010).</citsent>
<aftsection>
<nextsent>unlike the corpora of muc and ace, many are collected from situated dialogues, and therefore include multimodal information (e.g. gestures and eye-gaze) other than just transcribed text (martinet al, 2007).
</nextsent>
<nextsent>foster and oberlander (2007) emphasised that any corpus for language generation should include all possible contextual information at the appropriate granularity.
</nextsent>
<nextsent>since constructing dialogue corpus generally requires experiments for data collection, this kind of corpus tends to be small-scale compared with corpora for reference resolution.against this background, we have been developing multimodal corpora of referring expressions in collaborative problem-solving settings.this paper presents on-going work of constructing bilingual (english and japanese) comparable corpora in this domain.
</nextsent>
<nextsent>we achieve our goal by replicating, for the english corpus, the same process of data collection and annotation as we used for our existing japanese corpus (spanger et al, 2009<papid> W09-0618 </papid>a).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4460">
<title id=" W10-3206.xml">construction of bilingual multimodal corpora of referring expressions in collaborative problem solving </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in fact, research on reference resolution has developed significantly as result of large scale corpora, e.g. those provided by the message understanding conference (muc)1 and the automatic content extraction (ace)2 project.
</prevsent>
<prevsent>these corpora were constructed primarily for information extraction research, thus were annotated with co-reference relations within texts.
</prevsent>
</prevsection>
<citsent citstr=" W09-0618 ">
also in the language generation community, several corpora 1http://www.nlpir.nist.gov/related projects/muc/ 2http://www.itl.nist.gov/iad/tests/ace/ 38have been developed (di eugenio et al, 2000; byron, 2005; van deemter et al, 2006; foster and oberlander, 2007; foster et al, 2008; stoia et al, 2008; <papid> L08-1033 </papid>spanger et al, 2009<papid> W09-0618 </papid>a; belz et al, 2010).</citsent>
<aftsection>
<nextsent>unlike the corpora of muc and ace, many are collected from situated dialogues, and therefore include multimodal information (e.g. gestures and eye-gaze) other than just transcribed text (martinet al, 2007).
</nextsent>
<nextsent>foster and oberlander (2007) emphasised that any corpus for language generation should include all possible contextual information at the appropriate granularity.
</nextsent>
<nextsent>since constructing dialogue corpus generally requires experiments for data collection, this kind of corpus tends to be small-scale compared with corpora for reference resolution.against this background, we have been developing multimodal corpora of referring expressions in collaborative problem-solving settings.this paper presents on-going work of constructing bilingual (english and japanese) comparable corpora in this domain.
</nextsent>
<nextsent>we achieve our goal by replicating, for the english corpus, the same process of data collection and annotation as we used for our existing japanese corpus (spanger et al, 2009<papid> W09-0618 </papid>a).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4476">
<title id=" W10-3206.xml">construction of bilingual multimodal corpora of referring expressions in collaborative problem solving </title>
<section> annotation.  </section>
<citcontext>
<prevsection>
<prevsent>as result, we have 11 time-aligned elan tiers as shown in table 1.two annotators (two of the authors) first annotated four japanese dialogues separately and based on discussion of discrepancies, decide don the following criteria to identify referring ex pression.?
</prevsent>
<prevsent>the minimum span of noun phrase including necessary information to identify areferent is annotated.
</prevsent>
</prevsection>
<citsent citstr=" H93-1066 ">
the span might include repairs with their reparandum and dis fluency (nakatani and hirschberg, 1993) <papid> H93-1066 </papid>if needed.?</citsent>
<aftsection>
<nextsent>demonstrative adjectives are included in expressions.
</nextsent>
<nextsent>erroneous expressions are annotated with special attribute.
</nextsent>
<nextsent>an expression without definite referent (i.e.a group of possible referents or none) is assigned referent number sequence consisting of prefix, followed by the sequence of possible referents as its referent, if any are present.
</nextsent>
<nextsent>all expressions appearing in muttering to oneself are excluded.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4477">
<title id=" W10-3206.xml">construction of bilingual multimodal corpora of referring expressions in collaborative problem solving </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the table gives us an impression of significantly frequent use of demonstrative pronouns (dpr) by the 43 table 6: comparison of attribute distribution english japanese (4 dialogues) (24 dialogues) attribute frq frq/dlg frq frq/dlg dpr 226 56.5 678 28.3 dad 29 7.3 178 7.4 siz 68 17.0 288 12.0 typ 103 25.8 655 27.3 dir 0 0 7 0.3 prj 10 2.5 141 5.9 tpl 4 1 9 0.4 ovl 0 0 2 0.1 act 5 1.3 103 4.3 cmp 17 4.3 33 1.4 sim 0 0 7 0.3 num 22 5.5 35 1.5 rpr 0 0 1 0 err 0 0 1 0 nest 1 0.3 31 1.3 meta 1 0.3 6 0.3 english subjects.
</prevsent>
<prevsent>the japanese subjects use more attributes of projective spatial relations (prj) and actions on the referent (act).6 the english subjects use more complement attributes (cmp) as well as more number attributes (num).
</prevsent>
</prevsection>
<citsent citstr=" J95-3003 ">
over the last decade, with growing recognition that referring expressions frequently appear in collaborative task dialogues (clark and wilkes gibbs, 1986; heeman and hirst, 1995), <papid> J95-3003 </papid>number of corpora have been constructed to study the nature of their use.</citsent>
<aftsection>
<nextsent>this tendency also reflects the recognition that this area yields both challenging research topics as well as promising applications such as human-robot interaction (foster et al., 2008; kruijff et al, 2010).
</nextsent>
<nextsent>the coconut corpus (di eugenio et al,2000) was collected from keyboard-dialogs between two participants, who worked together on simple 2-d design task, buying and arranging furniture for two rooms.
</nextsent>
<nextsent>the coconut corpus is limited in annotations which describe symbolic object information such as object intrinsic attributes and location in discrete co-ordinates.
</nextsent>
<nextsent>asan initial work of constructing corpus for collaborative tasks, the coconut corpus can be characterised as having rather simple domain as well6we called such expressions as action-mentioning expressions (ame) in our previous work.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4480">
<title id=" W10-3206.xml">construction of bilingual multimodal corpora of referring expressions in collaborative problem solving </title>
<section> conclusion and future work.  </section>
<citcontext>
<prevsection>
<prevsent>#valid status t2008-08 tangram 6 24 24 completed t2009-03 tangram 10 40 16 completed t2009-11 tangram 10 36 27 validating n2009-11 tangram 5 20 8 validating p2009-11 polyomino 7 28 24 annotating d2009-11 2-tangram 7 42 24 annotating
</prevsent>
<prevsent>this paper presented an overview of our english japanese bilingual multimodal corpora of referring expressions in collaborative problem solving setting.
</prevsent>
</prevsection>
<citsent citstr=" P10-1128 ">
the japanese corpus was completed and has already been used for research (spanger et al., 2009<papid> W09-0618 </papid>b; spanger et al, 2010; iida et al, 2010),<papid> P10-1128 </papid>but the english counterpart is still undergoing an notation.</citsent>
<aftsection>
<nextsent>we have also presented preliminary comparative analysis of these corpora in terms ofthe task performance and usage of referring expressions.
</nextsent>
<nextsent>we found significant difference of the task performance, which could be attributed to the difference in diversity of subjects.
</nextsent>
<nextsent>we have tentative results on the usage of referring expressions, since only four english dialogues are available at the moment.the data collection experiments were conducted in august 2008 for japanese and in march 2010 for english.
</nextsent>
<nextsent>between these periods, we conducted various data collections to build different types of japanese corpora (march, 2009 and november 2009).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4481">
<title id=" W10-0906.xml">open domain commonsense reasoning using discourse relations from a corpus of weblog stories </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>such reasoning supports fundamental tasks such as textual entailment (giampiccolo et al, 2008), automated question answering (clark et al, 2008), and narrative comprehension (graesser et al, 1994).
</prevsent>
<prevsent>these tasks, when conducted in open domains, require vast amounts of commonsense knowledge pertaining to states, events, and their causal and temporal relationships.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
manually created resources such as framenet (baker et al, 1998), <papid> P98-1013 </papid>wordnet (fellbaum, 1998), andcyc (lenat, 1995) encode many aspects of commonsense knowledge; however, coverage of causa land temporal relationships remains low for many do mains.</citsent>
<aftsection>
<nextsent>gordon and swanson (2008) argued that the commonsense tasks of prediction, explanation, and imagination (collectively called envisionment) canbe supported by knowledge mined from large corpus of personal stories written by internet weblog authors.1 gordon and swanson (2008) identified three primary obstacles to such an approach.
</nextsent>
<nextsent>first, stories must be distinguished from other weblog content (e.g., lists, recipes, and reviews).
</nextsent>
<nextsent>second,stories must be analyzed in order to extract the implicit commonsense knowledge that they contain.
</nextsent>
<nextsent>third, inference mechanisms must be developed thatuse the extracted knowledge to perform the core en vision ment tasks listed above.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4482">
<title id=" W10-0906.xml">open domain commonsense reasoning using discourse relations from a corpus of weblog stories </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>(2009), which was used for the data challenge portion of the international conference on weblogs and social media (icwsm).
</prevsent>
<prevsent>the icwsm weblogcorpus (referred to here as spinn3r) is freely available and comprises tens of millions of weblog entries posted between august 1st, 2008 and october 1st, 2008.
</prevsent>
</prevsection>
<citsent citstr=" W03-0902 ">
gordon et al (2009) describe an approach to knowledge extraction over the spinn3r corpus using techniques described by schubert and tong (2003).<papid> W03-0902 </papid>in this approach, logical propositions (known as factoids) are constructed via approximate interpretation of syntactic analyses.</citsent>
<aftsection>
<nextsent>as an example, the system identified factoid glossed as doors to room may be opened?.
</nextsent>
<nextsent>gordon et al (2009) found thatthe extracted facto ids cover roughly half of the facto ids present in the corresponding wikipedia2 articles.
</nextsent>
<nextsent>we used subset of the spinn3r corpus inour work, but focused on discourse analyses of entire texts instead of syntactic analyses of single sentences.
</nextsent>
<nextsent>our goal was to extract general causal and temporal propositions instead of the fine-grained 2http://en.wikipedia.org properties expressed by many facto ids extracted by gordon et al (2009).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4486">
<title id=" W10-0906.xml">open domain commonsense reasoning using discourse relations from a corpus of weblog stories </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the authors showed how the extracted knowledge tuples can be used to improve syntactic parsing and textual entailmentrecognition.
</prevsent>
<prevsent>bar-haim et al (2009) present an efficient method of performing inference with such knowledge.
</prevsent>
</prevsection>
<citsent citstr=" P09-1095 ">
our work is also related to the work of persing and ng (2009), <papid> P09-1095 </papid>in which the authors developed semi-supervised method of identifying the causes of events described in aviation safety reports.</citsent>
<aftsection>
<nextsent>similarly, our system extracts causal (as well as tem poral) knowledge; however, it does this in an open domain and does not place limitations on the types of causes to be identified.
</nextsent>
<nextsent>this greatly increases the complexity of the inference task, and our results exhibit corresponding degradation; however, our evaluations provide important insights into the task.gordon and swanson (2009) developed supervised classification-based approach for identifying personal stories within the spinn3r corpus.
</nextsent>
<nextsent>their method achieved 75% precision on the binary task of predicting story versus non-story on held-out subset of the spinn3r corpus.
</nextsent>
<nextsent>the extracted story corpus?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4487">
<title id=" W10-0906.xml">open domain commonsense reasoning using discourse relations from a corpus of weblog stories </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>we addressed the second step - knowledge extraction by parsing the corpus using rhetorical structure theory (carlson and marcu, 2001) parser based on the one described by sagae (2009).
</prevsent>
<prevsent>the parser performs joint syntactic and discourse dependency 3the system (called sayanything) is available at http://sayanything.ict.usc.edu 44 parsing using stack-based, shift-reduce algorithm with runtime that is linear in the input length.
</prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
this lightweight approach is very efficient; however, itmay not be quite as accurate as more complex, chart based approaches (e.g., the approach of charniak and johnson (2005) <papid> P05-1022 </papid>for syntactic parsing).</citsent>
<aftsection>
<nextsent>we trained the discourse parser over the causal and temporal relations contained in the rst corpus.
</nextsent>
<nextsent>examples of these relations are shown below: (1) [cause packages often get buried in the load] [result and are delivered late.]
</nextsent>
<nextsent>(2) [before three months after she arrived in l.a.] [after she spent $120 she didnt have.]the rst corpus defines many fine-grained relations that capture causal and temporal properties.for example, the corpus differentiates between result and reason for causation and temporal-after andtemporal-before for temporal order.
</nextsent>
<nextsent>in order to increase the amount of available training data, we collapsed all causal and temporal relations into two general relations causes and precedes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4488">
<title id=" W10-0906.xml">open domain commonsense reasoning using discourse relations from a corpus of weblog stories </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>as in other nlp tasks, we observed significant performance degradation when moving from the training genre (newswire) to the testing genre (internet 48 weblog stories).
</prevsent>
<prevsent>because our discourse parser relies heavily on lexical and syntactic features for classification, and because the distribution of the feature values varies widely between the two genres, the performance degradation is to be expected.
</prevsent>
</prevsection>
<citsent citstr=" P06-1043 ">
recent techniques in parser adaptation for the brown corpus (mcclosky et al, 2006) <papid> P06-1043 </papid>might be usefully applied to the weblog genre as well.</citsent>
<aftsection>
<nextsent>our supervised classification-based approach to discourse parsing could also be improved with additional training data.
</nextsent>
<nextsent>causal and temporal relations are instantiated combined 2,840 times in the rst corpus, with large majority of these being causal.
</nextsent>
<nextsent>in contrast, the penn discourse treebank (prasad et al., 2008) <papid> L08-1093 </papid>contains 7,448 training instances of causal relations and 2,763 training instances of temporal relations.</nextsent>
<nextsent>this represents significant increase in the amount of training data over the rst corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4489">
<title id=" W10-0906.xml">open domain commonsense reasoning using discourse relations from a corpus of weblog stories </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>our supervised classification-based approach to discourse parsing could also be improved with additional training data.
</prevsent>
<prevsent>causal and temporal relations are instantiated combined 2,840 times in the rst corpus, with large majority of these being causal.
</prevsent>
</prevsection>
<citsent citstr=" L08-1093 ">
in contrast, the penn discourse treebank (prasad et al., 2008) <papid> L08-1093 </papid>contains 7,448 training instances of causal relations and 2,763 training instances of temporal relations.</citsent>
<aftsection>
<nextsent>this represents significant increase in the amount of training data over the rst corpus.
</nextsent>
<nextsent>it would be informative to compare our current results with those obtained using discourse parser trained on the penn discourse treebank.one might also extract causal and temporal relations using traditional semantic role analysis based on framenet (baker et al, 1998) <papid> P98-1013 </papid>or propbank (kingsbury and palmer, 2003).</nextsent>
<nextsent>the former defines number of frames related to causation and temporal order, and roles within the latter could be mapped to standard thematic roles (e.g., cause) via semlink.5 5.2 envisioning with the analysis results.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4491">
<title id=" W10-3207.xml">labeling emotion in bengali blog corpus x2013 a fine grained tagging at sentence level </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the knowledge of rhetorical structure helps in removing the subjective discrepancies from the 1 www.amarblog.com 47 writers point of view.
</prevsent>
<prevsent>the annotation scheme is used to annotate 123 blog posts containing 4,740 emotional sentences having single emotion tag and 322 emotional sentences for mixed emotion tagss along with 7087 neutral sentences in bengali.
</prevsent>
</prevsection>
<citsent citstr=" J96-2004 ">
three types of standard agreement measures such as cohens kappa () (cohen, 1960; carletta, 1996), <papid> J96-2004 </papid>measure of agreement on set-valued items (masi) (pas sonneau, 2004) and agr (wiebe et al, 2005) metrics are employed for annotating the emotion related components.</citsent>
<aftsection>
<nextsent>the relaxed agreement schemes like masi and agr are specially considered for fixing the boundaries of emotional expressions and topic spans in the emotional sentences.
</nextsent>
<nextsent>the inter annotator agreement of some emotional components such as sentential emotions, holders, topics show satisfactory performance but the sentences of mixed emotion and intensities of general and low show the disagreement.
</nextsent>
<nextsent>a preliminary experiment for word level emotion classification on small set of the whole corpus yielded satisfactory results.the rest of the paper is organized as follows.
</nextsent>
<nextsent>section 2 describes the related work.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4492">
<title id=" W10-3207.xml">labeling emotion in bengali blog corpus x2013 a fine grained tagging at sentence level </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>one of the most well known tasks of annotating the private states in texts is carried out by (wiebe et al, 2005).
</prevsent>
<prevsent>they manually annotated the private states including emotions, opinions, and sentiment in 10,000-sentence corpus (the mpqa corpus) of news articles.
</prevsent>
</prevsection>
<citsent citstr=" L08-1088 ">
the opinion holder information is also annotated in the mpqa corpus but the topic annotation task has been initiated later by (stoyanov and cardie, 2008<papid> L08-1088 </papid>a).</citsent>
<aftsection>
<nextsent>in contrast, the present annotation strategy includes the fine-grained emotion classes and specially handles the emoticons present in the blog posts.
</nextsent>
<nextsent>(alm et al, 2005) <papid> H05-1073 </papid>have considered eight emotion categories (angry, disgusted, fearful, happy, sad, positively surprised, negatively surprised) to accomplish the emotion annotation task at sentence level.</nextsent>
<nextsent>they have manually annotated 1580 sentences extracted from 22 grimms?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4493">
<title id=" W10-3207.xml">labeling emotion in bengali blog corpus x2013 a fine grained tagging at sentence level </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the opinion holder information is also annotated in the mpqa corpus but the topic annotation task has been initiated later by (stoyanov and cardie, 2008<papid> L08-1088 </papid>a).</prevsent>
<prevsent>in contrast, the present annotation strategy includes the fine-grained emotion classes and specially handles the emoticons present in the blog posts.</prevsent>
</prevsection>
<citsent citstr=" H05-1073 ">
(alm et al, 2005) <papid> H05-1073 </papid>have considered eight emotion categories (angry, disgusted, fearful, happy, sad, positively surprised, negatively surprised) to accomplish the emotion annotation task at sentence level.</citsent>
<aftsection>
<nextsent>they have manually annotated 1580 sentences extracted from 22 grimms?
</nextsent>
<nextsent>tales.
</nextsent>
<nextsent>the present approach discusses the issues of annotating unstructured blog text considering rhetoric knowledge along with the attributes, e.g. negation, conjunct, reduplication etc. mishne (2005) experimented with mood classification in blog corpus of 815,494 posts from live journal (http://www.livejournal.com), free weblog service with large community.
</nextsent>
<nextsent>(mihalcea and liu, 2006) have used the same data source for classifying the blog posts into two particular emotions ? happiness and sadness.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4494">
<title id=" W10-3207.xml">labeling emotion in bengali blog corpus x2013 a fine grained tagging at sentence level </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the present task considers all the above emotion information during annotation.
</prevsent>
<prevsent>but, the present annotation task additionally includes the components like emotion holder, single or multiple topic spans.
</prevsent>
</prevsection>
<citsent citstr=" C08-1111 ">
the emotion corpora for japanese were built for recognizing emotions (tokuhisa et al, 2008).<papid> C08-1111 </papid></citsent>
<aftsection>
<nextsent>an available emotion corpus in chinese is yahoo!s chinese news (http://tw.news.yahoo.com), which is used for chinese emotion classification of news readers (lin, et al, 2007).
</nextsent>
<nextsent>the manual annotation of eight emotional categories (expect, joy, love, surprise, anxiety, sorrow, angry and hate) along with intensity, holder, word/phrase, degree word, negative word, conjunction, rhetoric, punctuation and other linguistic expressions are carried out at sentence, paragraph as well as document level on 1,487 chinese blog documents (quan and ren, 2009).<papid> D09-1150 </papid></nextsent>
<nextsent>in addition 48to the above emotion entities, the present approach also includes the annotation of single or multiple emotion topics in target span.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4495">
<title id=" W10-3207.xml">labeling emotion in bengali blog corpus x2013 a fine grained tagging at sentence level </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the emotion corpora for japanese were built for recognizing emotions (tokuhisa et al, 2008).<papid> C08-1111 </papid></prevsent>
<prevsent>an available emotion corpus in chinese is yahoo!s chinese news (http://tw.news.yahoo.com), which is used for chinese emotion classification of news readers (lin, et al, 2007).</prevsent>
</prevsection>
<citsent citstr=" D09-1150 ">
the manual annotation of eight emotional categories (expect, joy, love, surprise, anxiety, sorrow, angry and hate) along with intensity, holder, word/phrase, degree word, negative word, conjunction, rhetoric, punctuation and other linguistic expressions are carried out at sentence, paragraph as well as document level on 1,487 chinese blog documents (quan and ren, 2009).<papid> D09-1150 </papid></citsent>
<aftsection>
<nextsent>in addition 48to the above emotion entities, the present approach also includes the annotation of single or multiple emotion topics in target span.
</nextsent>
<nextsent>recent study shows that non-native english speakers support the growing use of the internet 2.
</nextsent>
<nextsent>this raises the demand of linguistic resources for languages other than english.
</nextsent>
<nextsent>bengali is the fifth popular language in the world, second in india and the national language in bangladesh but it is less computerized compared to english.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4496">
<title id=" W10-3207.xml">labeling emotion in bengali blog corpus x2013 a fine grained tagging at sentence level </title>
<section> identifying emotion holder.  </section>
<citcontext>
<prevsection>
<prevsent>2.
</prevsent>
<prevsent>general structure of blog docu ment?
</prevsent>
</prevsection>
<citsent citstr=" H05-1045 ">
prior work in identification of opinion holders has sometimes identified only single opinion per sentence (bethard et al, 2004), 51 and sometimes several (choi et al, 2005).<papid> H05-1045 </papid></citsent>
<aftsection>
<nextsent>as the blog corpus has sentence level emotion annotations, the former category is adopted.
</nextsent>
<nextsent>but, it is observed that the long sentences contain more than one emotional expression and hence associated with multiple emotion holders (eh).
</nextsent>
<nextsent>all probable emotion holders of sentence are stored in an anchoring vector successively according to their order of occurrence.
</nextsent>
<nextsent>the annotation of emotion holder at sentence level requires the knowledge of two basic constraints (implicit and explicit) separately.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4498">
<title id=" W10-3207.xml">labeling emotion in bengali blog corpus x2013 a fine grained tagging at sentence level </title>
<section> experiments on emotion classifica-.  </section>
<citcontext>
<prevsection>
<prevsent>the selection of emotion topic from other relevant topics causes the disagreement.
</prevsent>
<prevsent>emotion classes [# sentences, # topics] agreement between pair of annotators (masi) [agr] a1-a2 a2-a3 a1-a3 avg happy [804, 848] (0.83) [0.85] (0.81) [0.83] (0.79) [0.82] (0.81) [0.83] sad [826, 862] (0.84) [0.86] (0.77) [0.79] (0.81) [0.83] (0.80) [0.82] anger [765,723] (0.80) [0.78] (0.81) [0.78] (0.86) [0.84] (0.82) [0.80] disgust [766, 750] (0.77) [0.76] (0.78) [0.74] (0.72) [0.70] (0.75) [0.73] fear [757, 784] (0.78) [0.79] (0.77) [0.80] (0.79) [0.81] (0.78) [0.80 surprise [822, 810] (0.90) [0.86] (0.85) [0.82] (0.82) [0.80] (0.85) [0.82] table 3: inter-annotator agreement for topic annotation
</prevsent>
</prevsection>
<citsent citstr=" P09-2038 ">
tion preliminary experiment (das and bandyopadhyay, 2009<papid> P09-2038 </papid>b) was carried out on small set of 1200 sentences of the annotated blog corpus using conditional random field (crf) (mccallum et al, 2001).</citsent>
<aftsection>
<nextsent>we have employed the same corpus and similar features (e.g. pos, punctuation symbols, sentiment words etc.) for classifying the emotion words using support vector machine (svm) (joachims, 1999).
</nextsent>
<nextsent>the results on 200 test sentences are shown in table 4.
</nextsent>
<nextsent>the results of the automatic emotion classification at word level show that svm outperforms crf significantly.
</nextsent>
<nextsent>it is observed 53 that both classifiers fail to identify the emotion words that are enriched by morphological inflections.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4503">
<title id=" W10-2920.xml">cross caption coreference resolution for automatic image understanding </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>like natural language processing, computervision requires suitable training data, and there are currently no publicly available datasets that would enable the development of such systems.
</prevsent>
<prevsent>photo sharing sites such as flickr allow usersto annotate images with keywords and other descriptions, and vision researchers have access tolarge collections of images annotated with keywords (e.g. the corel collection).
</prevsent>
</prevsection>
<citsent citstr=" P08-1032 ">
a lot of recent work in computervision has been aimed at predicting these keywords (blei et al , 2003; barnard et al , 2003; feng and lapata, 2008; <papid> P08-1032 </papid>deschacht and moens, 2007; <papid> P07-1126 </papid>jeon et al , 2003).</citsent>
<aftsection>
<nextsent>but keywords alone are not expressive enough to capture relations between entities.
</nextsent>
<nextsent>some research has usedthe text that surrounds an image in news article as proxy (feng and lapata, 2008; <papid> P08-1032 </papid>deschacht and moens, 2007).<papid> P07-1126 </papid></nextsent>
<nextsent>however, in many cases, the surrounding text or user-provided caption does not simply describe what is depicted in the image (since this is usually obvious to the human reader for which this text is intended), but provides additional information.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4505">
<title id=" W10-2920.xml">cross caption coreference resolution for automatic image understanding </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>like natural language processing, computervision requires suitable training data, and there are currently no publicly available datasets that would enable the development of such systems.
</prevsent>
<prevsent>photo sharing sites such as flickr allow usersto annotate images with keywords and other descriptions, and vision researchers have access tolarge collections of images annotated with keywords (e.g. the corel collection).
</prevsent>
</prevsection>
<citsent citstr=" P07-1126 ">
a lot of recent work in computervision has been aimed at predicting these keywords (blei et al , 2003; barnard et al , 2003; feng and lapata, 2008; <papid> P08-1032 </papid>deschacht and moens, 2007; <papid> P07-1126 </papid>jeon et al , 2003).</citsent>
<aftsection>
<nextsent>but keywords alone are not expressive enough to capture relations between entities.
</nextsent>
<nextsent>some research has usedthe text that surrounds an image in news article as proxy (feng and lapata, 2008; <papid> P08-1032 </papid>deschacht and moens, 2007).<papid> P07-1126 </papid></nextsent>
<nextsent>however, in many cases, the surrounding text or user-provided caption does not simply describe what is depicted in the image (since this is usually obvious to the human reader for which this text is intended), but provides additional information.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4509">
<title id=" W10-2920.xml">cross caption coreference resolution for automatic image understanding </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we have collected corpus of 8108 images associated with several simple descriptive captions.
</prevsent>
<prevsent>in contrast to the text near animage on the web, the captions in our corpus provide direct, if partial and slightly noisy, descriptions of the image content.
</prevsent>
</prevsection>
<citsent citstr=" P01-1008 ">
our dataset differs from paraphrase corpora (barzilay and mckeown,2001; <papid> P01-1008 </papid>dolan et al , 2004) <papid> C04-1051 </papid>in that the different captions of an image are produced independently by different writers.</citsent>
<aftsection>
<nextsent>there are many ways of describing the same image, because it is often possible to focus on different aspects of the depicted situation, and because certain aspects of the situation may be unclear to the human viewer.
</nextsent>
<nextsent>one of our goals is to use these captions to obtain semantic representation of each image that is consistent with all of its captions.
</nextsent>
<nextsent>in order to obtain such representation, it is necessary to identify the entities that appear in the image, and to perform cross-caption coreference resolution, i.e. to identify all mentions of the same entity in the five captions associated with an image.
</nextsent>
<nextsent>in this paper, we compare different meth 162 golden retriever (animal) is playing with smaller black and brown dog(animal) in pink collar (clothing).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4510">
<title id=" W10-2920.xml">cross caption coreference resolution for automatic image understanding </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we have collected corpus of 8108 images associated with several simple descriptive captions.
</prevsent>
<prevsent>in contrast to the text near animage on the web, the captions in our corpus provide direct, if partial and slightly noisy, descriptions of the image content.
</prevsent>
</prevsection>
<citsent citstr=" C04-1051 ">
our dataset differs from paraphrase corpora (barzilay and mckeown,2001; <papid> P01-1008 </papid>dolan et al , 2004) <papid> C04-1051 </papid>in that the different captions of an image are produced independently by different writers.</citsent>
<aftsection>
<nextsent>there are many ways of describing the same image, because it is often possible to focus on different aspects of the depicted situation, and because certain aspects of the situation may be unclear to the human viewer.
</nextsent>
<nextsent>one of our goals is to use these captions to obtain semantic representation of each image that is consistent with all of its captions.
</nextsent>
<nextsent>in order to obtain such representation, it is necessary to identify the entities that appear in the image, and to perform cross-caption coreference resolution, i.e. to identify all mentions of the same entity in the five captions associated with an image.
</nextsent>
<nextsent>in this paper, we compare different meth 162 golden retriever (animal) is playing with smaller black and brown dog(animal) in pink collar (clothing).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4511">
<title id=" W10-2920.xml">cross caption coreference resolution for automatic image understanding </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>share synset into single coreference chain.
</prevsent>
<prevsent>6 bayesian coreference models.
</prevsent>
</prevsection>
<citsent citstr=" P07-1107 ">
since we cannot afford to manually annotate our entire dataset with coreference information, we follow haghighi and klein (2007)<papid> P07-1107 </papid>s work on unsupervised coreference resolution, and develop series of generative bayesian models for our task.</citsent>
<aftsection>
<nextsent>6.1 model 0: simple mixture model.
</nextsent>
<nextsent>in our first model, based on haghighi and kleins baseline dirichlet process model, each image corresponds to the set of observed mentions wi from across its captions.
</nextsent>
<nextsent>image has hidden global topic ti, drawn from distribution with gem prior with hyperparameter ? as explained by teh et al  (2006).
</nextsent>
<nextsent>in dirichlet process, the gem distribution is an infinite analog of the dirich let distribution, allowing for potentially infinite number of mixture components.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4512">
<title id=" W10-2920.xml">cross caption coreference resolution for automatic image understanding </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the set of all images belonging to the same topic is analogous to an individual document in haghighi and kleins baseline model.11 all headwords of the same entity type are assumed to be co referent, similar to haghighi and kleins model.
</prevsent>
<prevsent>as described in section 4, we use wordnet to identify the subset of types that can actually produce the given words.
</prevsent>
</prevsection>
<citsent citstr=" W09-2206 ">
therefore, similar to the way andrzejewski and zhu (2009) <papid> W09-2206 </papid>handled priori knowledge of topics, we will define an indicator variable ij that is 1 iff the wordnet information allows word to be produced from entity set and 0 otherwise.</citsent>
<aftsection>
<nextsent>6.1.1 sampling model 0we find argmaxz,tp (z,t|x) with gibbs sampling.
</nextsent>
<nextsent>here, and are the collection of type and topic assignments, with zj = z?
</nextsent>
<nextsent>{zj} and ti = ? {ti}.
</nextsent>
<nextsent>this style of notation will be extended analogously to other variables.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4514">
<title id=" W10-2920.xml">cross caption coreference resolution for automatic image understanding </title>
<section> sampling ti:.  </section>
<citcontext>
<prevsection>
<prevsent>wordnet synsets and hypernyms: the most likely synset is either the first one that appears in wordnet or one of the ones predicted by our coreference system.
</prevsent>
<prevsent>for each of these possibilities, we include all of that synsets hypernyms.
</prevsent>
</prevsection>
<citsent citstr=" J07-4004 ">
syntactic role: we parsed our captions with the c&c; parser (clark and curran, 2007), <papid> J07-4004 </papid>and record whether the word appears as direct object of verb, as the object of preposition, as the subject of the sentence, or as modifier.</citsent>
<aftsection>
<nextsent>if it is modifier, we also add the head word of the phrase being modified.14for example, we deem bowls and silverware to be movable objects; furniture, fixed; and carpets, background.
</nextsent>
<nextsent>more over, in all three cases, we must correctly distinguish that these objects are man-made and not found in nature.
</nextsent>
<nextsent>168 model opennlp chunks gold chunks rec.
</nextsent>
<nextsent>prec.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4515">
<title id=" W10-2920.xml">cross caption coreference resolution for automatic image understanding </title>
<section> sampling ti:.  </section>
<citcontext>
<prevsection>
<prevsent>we plan to make this dataset available for further research in computer vision and natural language processing.
</prevsent>
<prevsent>inorder to enable the creation of semantic representation of the image content that is consistent with the captions in our dataset, we use wordnet and series of bayesian models to perform cross-caption coreference resolution.
</prevsent>
</prevsection>
<citsent citstr=" D09-1120 ">
similar to haghighi and klein (2009), <papid> D09-1120 </papid>who find that linguistic heuristics can provide very strong baselines for standard coreference result ion, relatively simple heuristics based on wordnet al ne perform surprisingly well on our task, although they are outperformed by our bayesian models for overall entity prediction.</citsent>
<aftsection>
<nextsent>since our generative models are based on dirichlet process priors, they are designed to favor small number of unique entities per image.
</nextsent>
<nextsent>in the heuristic algorithm, this bias is built in explicitly, resulting in slightly higher performance on the coreference resolution task.
</nextsent>
<nextsent>however, while the generative models can use global information to learn what entity type each word is likely to represent, the heuristic is unable to capture any non-local information about the entities, and thus provides less useful input for the prediction of onto logical classes.future work will aim to improve on these results by overcoming the upper bound on performance imposed by wordnet, and through more sophisticated model of modifiers.
</nextsent>
<nextsent>we will also investigate how image features can be incorporated into our model to improve performance on entitydetection.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4516">
<title id=" W10-1901.xml">two strong baselines for the bionlp 2009 event extraction task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the term biomedical event extraction is used to refer to tasks whose aim is the extraction of information beyond the entity level.
</prevsent>
<prevsent>it commonly involves recognizing actions and relations between one or more entities.
</prevsent>
</prevsection>
<citsent citstr=" W09-1401 ">
the recent bionlp 2009 shared task on event extraction (kim et al, 2009) <papid> W09-1401 </papid>focused on number of relations of varying complexity in which an event consisted of trigger and one or more arguments.</citsent>
<aftsection>
<nextsent>it attracted 24 submissions and provided basis for system development.
</nextsent>
<nextsent>the performances ranged from 16% to 52% in f-score.
</nextsent>
<nextsent>in this paper we describe two strong baseline approaches for the main task (described in sec.
</nextsent>
<nextsent>2)with focus on annotation costs and reproducibility.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4517">
<title id=" W10-1901.xml">two strong baselines for the bionlp 2009 event extraction task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>both approaches relyon dictionary of lem mas associated with event types (sec.
</prevsent>
<prevsent>3).
</prevsent>
</prevsection>
<citsent citstr=" W09-1405 ">
first we re-implement the rule-based approach of vlachos et al (2009) <papid> W09-1405 </papid>using resources provided in the sharedtask.</citsent>
<aftsection>
<nextsent>while it is unlikely to reach the performance of approaches combining supervised machine learning, exploring its potential can highlight what annotated data is useful and its potential contribution to performance.
</nextsent>
<nextsent>also, given its reliance on syntax, it allows us to assess the importance of syntactic parsing.
</nextsent>
<nextsent>nevertheless, the performance achieved (35.39% f-score) is competitive with systems that used more annotated data and/or other resources (sec.
</nextsent>
<nextsent>5).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4520">
<title id=" W10-1901.xml">two strong baselines for the bionlp 2009 event extraction task </title>
<section> definition, datasets and resources.  </section>
<citcontext>
<prevsection>
<prevsent>parsing model.
</prevsent>
<prevsent>this parser was trained on newswire data exclusively.
</prevsent>
</prevsection>
<citsent citstr=" P08-2026 ">
the re-ranking parser of charniak &amp; johnson adapted to the biomedical domain (mccloskyand charniak, 2008).<papid> P08-2026 </papid></citsent>
<aftsection>
<nextsent>the in-domain, part-of speech (pos) tagger was trained on the genia corpus (kim et al, 2003) and the self-trainingof the re-ranking module used part of the genia treebank as development data.
</nextsent>
<nextsent>the c&c; combinatory categorial grammar(ccg) parser adapted to the biomedical domain (rimell and clark, 2009).
</nextsent>
<nextsent>the pos tagger was trained on the genia corpus, while 1,000 sentences were annotated with lexical categories and added to the training data of the ccg super tagger and 600 sentences of the bio infer corpus (pyysalo et al, 2007) were used for parameter tuning.
</nextsent>
<nextsent>the gdep dependency parser trained for the biomedical domain in the experiments of miyao et al (2008).<papid> P08-1006 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4521">
<title id=" W10-1901.xml">two strong baselines for the bionlp 2009 event extraction task </title>
<section> definition, datasets and resources.  </section>
<citcontext>
<prevsection>
<prevsent>the c&c; combinatory categorial grammar(ccg) parser adapted to the biomedical domain (rimell and clark, 2009).
</prevsent>
<prevsent>the pos tagger was trained on the genia corpus, while 1,000 sentences were annotated with lexical categories and added to the training data of the ccg super tagger and 600 sentences of the bio infer corpus (pyysalo et al, 2007) were used for parameter tuning.
</prevsent>
</prevsection>
<citsent citstr=" P08-1006 ">
the gdep dependency parser trained for the biomedical domain in the experiments of miyao et al (2008).<papid> P08-1006 </papid></citsent>
<aftsection>
<nextsent>this parser was trained for the biomedical domain using the genia treebank.
</nextsent>
<nextsent>the native penn treebank output of bikels and mccloskys parser was converted to the stanford dependency (sd) collapsed dependency format (de marneffe and manning, 2008).
</nextsent>
<nextsent>the output ofthe ccg parser was also converted to the same dependency format, while the output of gdep was provided in different dependency format used for the dependency parsing conll 2007 shared task.
</nextsent>
<nextsent>from the description above, it is clear thatthe various parsers have different levels of adaptation to the biomedical domain.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4522">
<title id=" W10-1901.xml">two strong baselines for the bionlp 2009 event extraction task </title>
<section> trigger extraction.  </section>
<citcontext>
<prevsection>
<prevsent>in order to keep only the terms denoting the event type.
</prevsent>
<prevsent>then, using the single-token triggers only, we associate each lemma with its most common event type.
</prevsent>
</prevsection>
<citsent citstr=" W09-1418 ">
in cases 1kilicoglu and bergler (2009) <papid> W09-1418 </papid>made similar observations on the lemma activity?</citsent>
<aftsection>
<nextsent>without formalizing them.
</nextsent>
<nextsent>where lemma consistently generates more that one event trigger of different types (typically oneof the simple event class and one of the regulation class, we associate the lemma with allthe relevant event types.
</nextsent>
<nextsent>for example, overex press?
</nextsent>
<nextsent>consistently denotes gene expression and positive regulation events.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4527">
<title id=" W10-1901.xml">two strong baselines for the bionlp 2009 event extraction task </title>
<section> rule-based system results.  </section>
<citcontext>
<prevsection>
<prevsent>the best rule-based system (kil icoglu and bergler, 2009) <papid> W09-1418 </papid>had overall performance of 44.62% in f-score, ranking third overall.</prevsent>
<prevsent>the main difference is that it used much larger setof lexicalized rules (27) which were extracted using the training data.</prevsent>
</prevsection>
<citsent citstr=" W06-3312 ">
also, heuristics were employed in order to correct syntactic parsing errors (schuman and bergler, 2006).<papid> W06-3312 </papid></citsent>
<aftsection>
<nextsent>while the benefits from these additional processing steps are indisputable, they involved lot of manual work, both for rule construction as well as for the annotation of the data used to extract the rules.
</nextsent>
<nextsent>we argue that these performance benefits could be obtained using machine learning methods aimed at ameliorating the argument identification stage.
</nextsent>
<nextsent>compared to the rule-based approach of vlachos etal.
</nextsent>
<nextsent>(2009), the performance is improved substantially.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4528">
<title id=" W10-1901.xml">two strong baselines for the bionlp 2009 event extraction task </title>
<section> rule-based system results.  </section>
<citcontext>
<prevsection>
<prevsent>compared to the rule-based approach of vlachos etal.
</prevsent>
<prevsent>(2009), the performance is improved substantially.
</prevsent>
</prevsection>
<citsent citstr=" P06-4020 ">
the main difference between that system and the one presented here is that the former uses the domain-independent rasp parser (briscoe et al., 2006).<papid> P06-4020 </papid></citsent>
<aftsection>
<nextsent>while its performance was reasonable (it was ranked 10th overall, 30.80% f-score), these results lag behind those reported here.
</nextsent>
<nextsent>note that direct comparison using the output of rasp is not possible since the latter uses its own syntactic dependency scheme and there is no loss less conversion to the sd scheme.
</nextsent>
<nextsent>overall, the results of this section demonstrate that the use of domain-adapted parsing is beneficial to event extraction.
</nextsent>
<nextsent>this is not surprising since the system presented depends heavily on the parsing output.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4529">
<title id=" W10-1901.xml">two strong baselines for the bionlp 2009 event extraction task </title>
<section> svm-based system results.  </section>
<citcontext>
<prevsection>
<prevsent>furthermore, we argue thatthe data provided by the organizers are not suit able to train trigger extractor, since only triggers participating in events are annotated, and semantically valid triggers without appropriate arguments present are ignored.
</prevsent>
<prevsent>we hypothesize that this is the reason the authors had to adjust the decisions of their svm classifiers.
</prevsent>
</prevsection>
<citsent citstr=" W09-1403 ">
the second best system (buyko et al, 2009) <papid> W09-1403 </papid>achieved 45.82%/47.52%/46.66% (r/p/f) using many external knowledge sources such as thegene ontology annotation database, the universal protein resource and the medical subject headings thesaurus.</citsent>
<aftsection>
<nextsent>while the use of these resources and their successful usage is commendable, we believe it is important that the system presented achieves comparable performance using fewer resources.
</nextsent>
<nextsent>furthermore, joint inference models such as 7 markov logic networks were applied to the bionlp 2009 event extraction shared task by riedel et al (2009) <papid> W09-1406 </papid>and were ranked fourth.</nextsent>
<nextsent>this result was improved upon recently by poonand vanderwende (2010) who achieved 50% fscore, 2.11 percentage points better than there sult achieved in this work.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4530">
<title id=" W10-1901.xml">two strong baselines for the bionlp 2009 event extraction task </title>
<section> svm-based system results.  </section>
<citcontext>
<prevsection>
<prevsent>the second best system (buyko et al, 2009) <papid> W09-1403 </papid>achieved 45.82%/47.52%/46.66% (r/p/f) using many external knowledge sources such as thegene ontology annotation database, the universal protein resource and the medical subject headings thesaurus.</prevsent>
<prevsent>while the use of these resources and their successful usage is commendable, we believe it is important that the system presented achieves comparable performance using fewer resources.</prevsent>
</prevsection>
<citsent citstr=" W09-1406 ">
furthermore, joint inference models such as 7 markov logic networks were applied to the bionlp 2009 event extraction shared task by riedel et al (2009) <papid> W09-1406 </papid>and were ranked fourth.</citsent>
<aftsection>
<nextsent>this result was improved upon recently by poonand vanderwende (2010) who achieved 50% fscore, 2.11 percentage points better than there sult achieved in this work.
</nextsent>
<nextsent>such models have great potential for event extraction and we believe that they can benefit from the insights presented here.finally, despite the fact that we used the same experimental setup as the shared task participants,we do not consider our results are directly comparable to theirs since we did not work under the same time constraints and we profited from their experiences.
</nextsent>
<nextsent>our error analysis on the output of the best system on the development data discouraged us from pursuing further improvements.
</nextsent>
<nextsent>echoing the observations of buyko et al (2009), <papid> W09-1403 </papid>we found that annotation inconsistency was affecting our results significantly.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4532">
<title id=" W10-1901.xml">two strong baselines for the bionlp 2009 event extraction task </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>the best performance achieved was 29% in f-score, while many of the teams scored below 10%.
</prevsent>
<prevsent>however, we believe that future work should look at improving the annotation in order to beable to assess the progress in the systems developed.
</prevsent>
</prevsection>
<citsent citstr=" W08-2121 ">
in particular, we argue that we should move towards dependency-based representation, similar to the one introduced by surdeanu et al (2008)<papid> W08-2121 </papid>for joint syntactic parsing and semantic role label ing.</citsent>
<aftsection>
<nextsent>such representation can express the nested nature of the events and evaluate the dependencies between them directly.
</nextsent>
<nextsent>furthermore, given the importance of syntactic parsing via syntactic dependencies to event extraction, it would be interesting to see how performing these tasks jointly would help improve the performance.
</nextsent>
<nextsent>a dependency based representation would also allow for noncontiguous event components, as well as more complex phenomena such as the light triggers discussed earlier.
</nextsent>
<nextsent>in this paper we focused on the bionlp 2009 shared task on event extraction.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4533">
<title id=" W10-3113.xml">using svms with the command relation features to identify negated events in biomedical literature </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>detection of neg ations is of particular importance for ie methods, as it often can hugely affect the quality of the extracted information.
</prevsent>
<prevsent>for example, when mining molecular events, key piece of information is whether the text states that the two proteins are or are not interacting, or that given gene is or is not expressed.
</prevsent>
</prevsection>
<citsent citstr=" W09-1401 ">
in recent years, several challenges and shared tasks have included the extraction of neg ations, typically as part of other tasks (e.g. the bionlp09 shared task 3 (kim et al 2009)).<papid> W09-1401 </papid></citsent>
<aftsection>
<nextsent>several systems and methods have aimed to handle negation detection in order to improve the quality of extracted information (hakenberg et al. 2009; <papid> W09-1411 </papid>morante and daelemans 2009).<papid> W09-1105 </papid></nextsent>
<nextsent>prior research on this topic has primarily focused on finding negated concepts by negation cues and scopes.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4534">
<title id=" W10-3113.xml">using svms with the command relation features to identify negated events in biomedical literature </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, when mining molecular events, key piece of information is whether the text states that the two proteins are or are not interacting, or that given gene is or is not expressed.
</prevsent>
<prevsent>in recent years, several challenges and shared tasks have included the extraction of neg ations, typically as part of other tasks (e.g. the bionlp09 shared task 3 (kim et al 2009)).<papid> W09-1401 </papid></prevsent>
</prevsection>
<citsent citstr=" W09-1411 ">
several systems and methods have aimed to handle negation detection in order to improve the quality of extracted information (hakenberg et al. 2009; <papid> W09-1411 </papid>morante and daelemans 2009).<papid> W09-1105 </papid></citsent>
<aftsection>
<nextsent>prior research on this topic has primarily focused on finding negated concepts by negation cues and scopes.
</nextsent>
<nextsent>these concepts are usually represented by set of predefined terms, and negation detection typically aims to determine whether term falls within the scope of negation cue.
</nextsent>
<nextsent>in this paper we address the task of identification of negated events.
</nextsent>
<nextsent>we present machine learning (ml) method that combines set of features mainly engineered from sentence parse tree with lexical cues.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4535">
<title id=" W10-3113.xml">using svms with the command relation features to identify negated events in biomedical literature </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, when mining molecular events, key piece of information is whether the text states that the two proteins are or are not interacting, or that given gene is or is not expressed.
</prevsent>
<prevsent>in recent years, several challenges and shared tasks have included the extraction of neg ations, typically as part of other tasks (e.g. the bionlp09 shared task 3 (kim et al 2009)).<papid> W09-1401 </papid></prevsent>
</prevsection>
<citsent citstr=" W09-1105 ">
several systems and methods have aimed to handle negation detection in order to improve the quality of extracted information (hakenberg et al. 2009; <papid> W09-1411 </papid>morante and daelemans 2009).<papid> W09-1105 </papid></citsent>
<aftsection>
<nextsent>prior research on this topic has primarily focused on finding negated concepts by negation cues and scopes.
</nextsent>
<nextsent>these concepts are usually represented by set of predefined terms, and negation detection typically aims to determine whether term falls within the scope of negation cue.
</nextsent>
<nextsent>in this paper we address the task of identification of negated events.
</nextsent>
<nextsent>we present machine learning (ml) method that combines set of features mainly engineered from sentence parse tree with lexical cues.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4539">
<title id=" W10-3113.xml">using svms with the command relation features to identify negated events in biomedical literature </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>events are typically represented via participants (biomedical entities that take part in an event) and event triggers (to kens that indicate presence of the event).
</prevsent>
<prevsent>van landeghem et al (2008) used rule-based approach based on token distances in sentence and lexical information in event triggers to detect negated molecular events.
</prevsent>
</prevsection>
<citsent citstr=" W09-1418 ">
kilicoglu and bergler (2009), <papid> W09-1418 </papid>hakenberg et al (2009), <papid> W09-1411 </papid>and sanchez (2007) used number of heuristic rules concerning the type of the negation cue and the type of the dependency relation to detect negated molecular events described in text.</citsent>
<aftsection>
<nextsent>for example, rule can state that if the negation cue is lack?
</nextsent>
<nextsent>or absence?, then the trigger has to be in the prepositional phrase of the cue; or that if the cue is unable?
</nextsent>
<nextsent>or fail?, then the trigger has to be in the clausal complement of the cue (kilicoglu and bergler 2009).<papid> W09-1418 </papid></nextsent>
<nextsent>as expected, such approaches suffer from lower recall.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4542">
<title id=" W10-3113.xml">using svms with the command relation features to identify negated events in biomedical literature </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>or fail?, then the trigger has to be in the clausal complement of the cue (kilicoglu and bergler 2009).<papid> W09-1418 </papid></prevsent>
<prevsent>as expected, such approaches suffer from lower recall.</prevsent>
</prevsection>
<citsent citstr=" W09-1410 ">
mackinlay et al (2009), <papid> W09-1410 </papid>on the other hand, use ml, assigning vector of complex deep parse features (including syntactic predicates to capture negation scopes, conjunctions and semantically negated verbs) to every event trigger.</citsent>
<aftsection>
<nextsent>the system achieved an f-score of 36% on the same dataset as used in this paper.
</nextsent>
<nextsent>we note that the methods mentioned above mainly focus on finding negated triggers in order to detect negated events.
</nextsent>
<nextsent>in this paper we explore not only negation of triggers but also phrases in which participants are negated (consider, forex ample, slp-76?
</nextsent>
<nextsent>in the sentence in contrast, grb2 can be coimmunoprecipitated with sos1 and sos2 but not with slp-76.?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4544">
<title id=" W10-3113.xml">using svms with the command relation features to identify negated events in biomedical literature </title>
<section> molecular events.  </section>
<citcontext>
<prevsection>
<prevsent>table 1 shows examples of five events, where participants are biomedical entities (events 1-3) or other events (events 4 and 5).
</prevsent>
<prevsent>note that sentence can express more than one molecular event.
</prevsent>
</prevsection>
<citsent citstr=" W09-1417 ">
identification of molecular events in the literature is challenging ie task (kim et al 2009; <papid> W09-1401 </papid>sarafraz et al 2009).<papid> W09-1417 </papid></citsent>
<aftsection>
<nextsent>for the task of identifying negated events, we assume that events have already been identified in text.
</nextsent>
<nextsent>each event is represented by its type, textual trigger, and one or more participants or causes (see table 1).
</nextsent>
<nextsent>since the participants of different event types can vary in both their number and type, we consider three classes of events to support our analysis (see section 5): ? class comprises events with exactly one entity theme (e.g. transcription, protein ca tabolism, localization, gene expression, phosphorylation).
</nextsent>
<nextsent>class ii events include binding events only, which have one or more entity participants.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4547">
<title id=" W10-3113.xml">using svms with the command relation features to identify negated events in biomedical literature </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>however, the effects on the score were typically not significant.
</prevsent>
<prevsent>the results are only shown using the larger cue set.
</prevsent>
</prevsection>
<citsent citstr=" H05-1059 ">
the texts were processed using the genia tagger (tsuruoka and tsujii 2005).<papid> H05-1059 </papid>we used constituency parse trees automatically produced by two different constituency parsers reported in (mcclosky et al 2006) <papid> N06-1020 </papid>and (bikel 2004).<papid> W04-3224 </papid></citsent>
<aftsection>
<nextsent>no major differences were observed in the results using the two parsers.
</nextsent>
<nextsent>the data shown in there sults are produced by the former.
</nextsent>
<nextsent>5.1 baseline results.
</nextsent>
<nextsent>our baseline method relies on an implementation of the negex algorithm as explained in section 2.1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4548">
<title id=" W10-3113.xml">using svms with the command relation features to identify negated events in biomedical literature </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>however, the effects on the score were typically not significant.
</prevsent>
<prevsent>the results are only shown using the larger cue set.
</prevsent>
</prevsection>
<citsent citstr=" N06-1020 ">
the texts were processed using the genia tagger (tsuruoka and tsujii 2005).<papid> H05-1059 </papid>we used constituency parse trees automatically produced by two different constituency parsers reported in (mcclosky et al 2006) <papid> N06-1020 </papid>and (bikel 2004).<papid> W04-3224 </papid></citsent>
<aftsection>
<nextsent>no major differences were observed in the results using the two parsers.
</nextsent>
<nextsent>the data shown in there sults are produced by the former.
</nextsent>
<nextsent>5.1 baseline results.
</nextsent>
<nextsent>our baseline method relies on an implementation of the negex algorithm as explained in section 2.1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4549">
<title id=" W10-3113.xml">using svms with the command relation features to identify negated events in biomedical literature </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>however, the effects on the score were typically not significant.
</prevsent>
<prevsent>the results are only shown using the larger cue set.
</prevsent>
</prevsection>
<citsent citstr=" W04-3224 ">
the texts were processed using the genia tagger (tsuruoka and tsujii 2005).<papid> H05-1059 </papid>we used constituency parse trees automatically produced by two different constituency parsers reported in (mcclosky et al 2006) <papid> N06-1020 </papid>and (bikel 2004).<papid> W04-3224 </papid></citsent>
<aftsection>
<nextsent>no major differences were observed in the results using the two parsers.
</nextsent>
<nextsent>the data shown in there sults are produced by the former.
</nextsent>
<nextsent>5.1 baseline results.
</nextsent>
<nextsent>our baseline method relies on an implementation of the negex algorithm as explained in section 2.1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4553">
<title id=" W10-1903.xml">event extraction for post translational modifications </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for instance, tissue specific or context dependent expression of many proteins is now known to be controlled by specific ptm of his tone proteins, such as methyl ation and acetyl ation (jaenisch and bird, 2003).
</prevsent>
<prevsent>this methyl ation andacetylation of specific amino acid residues in his tone proteins are strongly implicated in unwinding the nucleosomes and exposing genes to transcription, replication and dna repairing machinery.
</prevsent>
</prevsection>
<citsent citstr=" W09-1401 ">
the recent bionlp09 shared task on event extraction (kim et al , 2009<papid> W09-1401 </papid>a) (below, bionlp shared task) represented the first community-wide step toward the extraction of fine-grained event representations of information from biomolecular domain publications (ananiadou et al , 2010).</citsent>
<aftsection>
<nextsent>the nine event types targeted in the task included oneptm type, phosphorylation, whose extraction involved identifying the modified protein and, when stated, the specific phosphorylated site.
</nextsent>
<nextsent>there sults of the shared task showed this ptm event to be single most reliably extracted event type in the data, with the best-performing system for the event type achieving 91% precision and 76% recall (83% f-score) in the extraction of phosphorylation events (buyko et al , 2009).<papid> W09-1403 </papid></nextsent>
<nextsent>the results suggest both that the event representation is well applicable to ptm and that current extraction methods are capable of reliable ptm extraction.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4556">
<title id=" W10-1903.xml">event extraction for post translational modifications </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the recent bionlp09 shared task on event extraction (kim et al , 2009<papid> W09-1401 </papid>a) (below, bionlp shared task) represented the first community-wide step toward the extraction of fine-grained event representations of information from biomolecular domain publications (ananiadou et al , 2010).</prevsent>
<prevsent>the nine event types targeted in the task included oneptm type, phosphorylation, whose extraction involved identifying the modified protein and, when stated, the specific phosphorylated site.</prevsent>
</prevsection>
<citsent citstr=" W09-1403 ">
there sults of the shared task showed this ptm event to be single most reliably extracted event type in the data, with the best-performing system for the event type achieving 91% precision and 76% recall (83% f-score) in the extraction of phosphorylation events (buyko et al , 2009).<papid> W09-1403 </papid></citsent>
<aftsection>
<nextsent>the results suggest both that the event representation is well applicable to ptm and that current extraction methods are capable of reliable ptm extraction.
</nextsent>
<nextsent>most of the proposed state-of-the-art methods for event extraction are further largely machine-learning based.
</nextsent>
<nextsent>this suggest that the coverage of many existing methods could be straightforwardly extended to new event types and domains by extending the scope of available ptm annotations and retraining the methods on newly annotated data.
</nextsent>
<nextsent>in this study, we take such an annotation-based approach to extend the extraction capabilities of state of the art event extraction methods for ptm.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4558">
<title id=" W10-1903.xml">event extraction for post translational modifications </title>
<section> corpus annotation.  </section>
<citcontext>
<prevsection>
<prevsent>together with the elimination of duplicates and entries judged to fall outside of the event annotation criteria (see section 2.4), this reduced the number of source texts below our target, necessitating further selection strategy.for further annotation, we aimed to select abstracts that contain specific ptm statements identifying both the name of modified protein and the modified site.
</prevsent>
<prevsent>as for the initial selection, we further wished to avoid limiting the search by searching for any specific ptm expressions.
</prevsent>
</prevsection>
<citsent citstr=" P06-4005 ">
to implement this selection, we used the medie system5 (ohta et al , 2006; <papid> P06-4005 </papid>miyao et al , 2006) <papid> P06-1128 </papid>to search pubmed for sentences where specific protein and known modified site were found together in sentence occurring in an abstract annotated with specific mesh term.</citsent>
<aftsection>
<nextsent>the (protein name, modified site, mesh term) triples were extracted from pir records, substituting the appropriate mesh termfor each ptm type.
</nextsent>
<nextsent>some examples with the number of matching documents are shown in table 3.
</nextsent>
<nextsent>as most queries returned either no documents or small number of hits, we gave priority to response sto queries that returned small number of documents to avoid biasing the corpus toward proteins whose modifications are frequently discussed.
</nextsent>
<nextsent>we note that while the pir annotations typically identified focused text spans considerably shorter than single sentence and sentence-level search was used in the medie-based search to increase the likelihood of identifying relevant statements, after selection all annotation was performed to full abstracts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4559">
<title id=" W10-1903.xml">event extraction for post translational modifications </title>
<section> corpus annotation.  </section>
<citcontext>
<prevsection>
<prevsent>together with the elimination of duplicates and entries judged to fall outside of the event annotation criteria (see section 2.4), this reduced the number of source texts below our target, necessitating further selection strategy.for further annotation, we aimed to select abstracts that contain specific ptm statements identifying both the name of modified protein and the modified site.
</prevsent>
<prevsent>as for the initial selection, we further wished to avoid limiting the search by searching for any specific ptm expressions.
</prevsent>
</prevsection>
<citsent citstr=" P06-1128 ">
to implement this selection, we used the medie system5 (ohta et al , 2006; <papid> P06-4005 </papid>miyao et al , 2006) <papid> P06-1128 </papid>to search pubmed for sentences where specific protein and known modified site were found together in sentence occurring in an abstract annotated with specific mesh term.</citsent>
<aftsection>
<nextsent>the (protein name, modified site, mesh term) triples were extracted from pir records, substituting the appropriate mesh termfor each ptm type.
</nextsent>
<nextsent>some examples with the number of matching documents are shown in table 3.
</nextsent>
<nextsent>as most queries returned either no documents or small number of hits, we gave priority to response sto queries that returned small number of documents to avoid biasing the corpus toward proteins whose modifications are frequently discussed.
</nextsent>
<nextsent>we note that while the pir annotations typically identified focused text spans considerably shorter than single sentence and sentence-level search was used in the medie-based search to increase the likelihood of identifying relevant statements, after selection all annotation was performed to full abstracts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4560">
<title id=" W10-1903.xml">event extraction for post translational modifications </title>
<section> corpus annotation.  </section>
<citcontext>
<prevsection>
<prevsent>2.5 annotation results.
</prevsent>
<prevsent>the new ptm annotation covers 157 pubmed abstracts.
</prevsent>
</prevsection>
<citsent citstr=" W09-1313 ">
following the model of the bionlp shared task, all mentions of specific gene or gene product names in the abstracts were annotated, applying the annotation criteria of (ohta et al , 2009).<papid> W09-1313 </papid></citsent>
<aftsection>
<nextsent>this new named entity annotation covers 1031 gene/gene product mentions, thus averaging more than six mentions per annotated abstract.
</nextsent>
<nextsent>in total, 422 events of which 405 are of the novel ptm 23 event type count glycosylation 122 hydroxyl ation 103 methyl ation 90 acetyl ation 90 positive reg.
</nextsent>
<nextsent>12 phosphorylation 3 protein modification 2 total 422table 6: statistics of the introduced event annotation.
</nextsent>
<nextsent>arguments count theme, site 363 theme 36 site 6table 7: statistics for the arguments of the annotated ptm events.types were annotated, matching the initial annotation target in number and giving well-balanced distribution of the specific ptm types (table 6).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4570">
<title id=" W10-1612.xml">irasubcat a highly parametrizable language independent tool for the acquisition of verbal subcategorization information from corpus </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>it also implements procedure to identify verbal constituents that could be playing the role of an adjunct in pattern.thresholds controlling frequency and identification of adjuncts can be customized by the user, or else they are given default value.
</prevsent>
<prevsent>characterizing the behavior of verbs as nuclear organizers of clauses (the so-called subcategorization information) is crucial to obtain deep analyses of natural language.
</prevsent>
</prevsection>
<citsent citstr=" P03-1002 ">
for example, it can significantly reduce structural ambiguities in parsing (carroll et al., 1999; carroll and fang, 2004), help in word sense disambiguation or improve information extraction (surdeanu et al, 2003).<papid> P03-1002 </papid></citsent>
<aftsection>
<nextsent>however, the usual construction of linguistic resources for verbal subcategorization involves many expert hours, and it is usually prone to low coverage and inconsistencies across human experts.corpora can be very useful to alleviate the problems of low coverage and inconsistencies.
</nextsent>
<nextsent>verb scan be characterized by their behavior in big corpus of the language.
</nextsent>
<nextsent>thus, lexicographers only needto validate, correct or complete this digested information about the behavior of verbs.
</nextsent>
<nextsent>moreover, the starting information can have higher coverage and be more unbiased than if it is manually constructed.thats why automatic acquisition of subcategorization frames has been an active research area since the mid-90s (manning, 1993; <papid> P93-1032 </papid>brent, 1993; <papid> J93-2002 </papid>briscoe and carroll, 1997).<papid> A97-1052 </papid>however, most of the approaches have been ad hoc for particular languages or particular settings,like determined corpus with given kind of annotation, be it manual or automatic.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4571">
<title id=" W10-1612.xml">irasubcat a highly parametrizable language independent tool for the acquisition of verbal subcategorization information from corpus </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>verb scan be characterized by their behavior in big corpus of the language.
</prevsent>
<prevsent>thus, lexicographers only needto validate, correct or complete this digested information about the behavior of verbs.
</prevsent>
</prevsection>
<citsent citstr=" P93-1032 ">
moreover, the starting information can have higher coverage and be more unbiased than if it is manually constructed.thats why automatic acquisition of subcategorization frames has been an active research area since the mid-90s (manning, 1993; <papid> P93-1032 </papid>brent, 1993; <papid> J93-2002 </papid>briscoe and carroll, 1997).<papid> A97-1052 </papid>however, most of the approaches have been ad hoc for particular languages or particular settings,like determined corpus with given kind of annotation, be it manual or automatic.</citsent>
<aftsection>
<nextsent>to our knowledge, there is no system to acquire subcategorization information from corpora that is flexible enough towork with different languages and levels of annotation of corpora.we present irasubcat, tool that acquires information about the behaviour of verbs from corpora.
</nextsent>
<nextsent>it is aimed to address variety of situations and needs, ranging from rich annotated corpora to virtually raw text (because the tags to study can be selected in the configuration file).
</nextsent>
<nextsent>the characterization of linguistic patterns associated to verbs willbe correspondingly rich.
</nextsent>
<nextsent>the tool allows to customize most of the aspects of its functioning, toadapt to different requirements of the users.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4572">
<title id=" W10-1612.xml">irasubcat a highly parametrizable language independent tool for the acquisition of verbal subcategorization information from corpus </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>verb scan be characterized by their behavior in big corpus of the language.
</prevsent>
<prevsent>thus, lexicographers only needto validate, correct or complete this digested information about the behavior of verbs.
</prevsent>
</prevsection>
<citsent citstr=" J93-2002 ">
moreover, the starting information can have higher coverage and be more unbiased than if it is manually constructed.thats why automatic acquisition of subcategorization frames has been an active research area since the mid-90s (manning, 1993; <papid> P93-1032 </papid>brent, 1993; <papid> J93-2002 </papid>briscoe and carroll, 1997).<papid> A97-1052 </papid>however, most of the approaches have been ad hoc for particular languages or particular settings,like determined corpus with given kind of annotation, be it manual or automatic.</citsent>
<aftsection>
<nextsent>to our knowledge, there is no system to acquire subcategorization information from corpora that is flexible enough towork with different languages and levels of annotation of corpora.we present irasubcat, tool that acquires information about the behaviour of verbs from corpora.
</nextsent>
<nextsent>it is aimed to address variety of situations and needs, ranging from rich annotated corpora to virtually raw text (because the tags to study can be selected in the configuration file).
</nextsent>
<nextsent>the characterization of linguistic patterns associated to verbs willbe correspondingly rich.
</nextsent>
<nextsent>the tool allows to customize most of the aspects of its functioning, toadapt to different requirements of the users.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4573">
<title id=" W10-1612.xml">irasubcat a highly parametrizable language independent tool for the acquisition of verbal subcategorization information from corpus </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>verb scan be characterized by their behavior in big corpus of the language.
</prevsent>
<prevsent>thus, lexicographers only needto validate, correct or complete this digested information about the behavior of verbs.
</prevsent>
</prevsection>
<citsent citstr=" A97-1052 ">
moreover, the starting information can have higher coverage and be more unbiased than if it is manually constructed.thats why automatic acquisition of subcategorization frames has been an active research area since the mid-90s (manning, 1993; <papid> P93-1032 </papid>brent, 1993; <papid> J93-2002 </papid>briscoe and carroll, 1997).<papid> A97-1052 </papid>however, most of the approaches have been ad hoc for particular languages or particular settings,like determined corpus with given kind of annotation, be it manual or automatic.</citsent>
<aftsection>
<nextsent>to our knowledge, there is no system to acquire subcategorization information from corpora that is flexible enough towork with different languages and levels of annotation of corpora.we present irasubcat, tool that acquires information about the behaviour of verbs from corpora.
</nextsent>
<nextsent>it is aimed to address variety of situations and needs, ranging from rich annotated corpora to virtually raw text (because the tags to study can be selected in the configuration file).
</nextsent>
<nextsent>the characterization of linguistic patterns associated to verbs willbe correspondingly rich.
</nextsent>
<nextsent>the tool allows to customize most of the aspects of its functioning, toadapt to different requirements of the users.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4575">
<title id=" W10-1612.xml">irasubcat a highly parametrizable language independent tool for the acquisition of verbal subcategorization information from corpus </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>he detected six frame types and filtered associations between verbs and frames with the binomial hypothesis test.
</prevsent>
<prevsent>this approach obtained 73.85% f-score in an evaluation with human judges.
</prevsent>
</prevsection>
<citsent citstr=" W93-0109 ">
also in 1993, (ushioda et al, 1993) <papid> W93-0109 </papid>exploited also the wsj corpus but only the part that was annotated with part-of-speech tags, with 600.000 words.</citsent>
<aftsection>
<nextsent>he studied also six frame types and did not distinguishing arguments and adjuncts.
</nextsent>
<nextsent>the same year, (manning, 1993) <papid> P93-1032 </papid>used 4 million words of the new york times (sandhaus, ), selected only clauses with auxiliary verbs and automatically analyzed them with finite-state parser.</nextsent>
<nextsent>he defined 19 frame types, and reported an f-score of 58.20%.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4578">
<title id=" W10-1612.xml">irasubcat a highly parametrizable language independent tool for the acquisition of verbal subcategorization information from corpus </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>he defined 19 frame types, and reported an f-score of 58.20%.
</prevsent>
<prevsent>various authors developed approaches assuming full syntactic analysis, which was usually annotated manually in corpora (briscoe and carroll, 1997;<papid> A97-1052 </papid>kinyon and prolo, 2002).</prevsent>
</prevsection>
<citsent citstr=" J05-3003 ">
others associated syntactic analyses to corpora with automatic parsers (odonovan et al, 2005).<papid> J05-3003 </papid></citsent>
<aftsection>
<nextsent>various approaches were also found for languages other than english.
</nextsent>
<nextsent>for german, (eckle-kohler,1999) studied the behaviour of 6305 verbs on automatically pos-tagged corpus data.
</nextsent>
<nextsent>he defined linguistic heuristics by regular expression queries over the usage of 244 frame types.
</nextsent>
<nextsent>(wauschkuhn, 1999) studied 1044 german verbs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4579">
<title id=" W10-1612.xml">irasubcat a highly parametrizable language independent tool for the acquisition of verbal subcategorization information from corpus </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>he found valency patterns, which were grouped inorder to extract the most frequent pattern combinations, resulting in verb-frame lexicon with 42 frame types.(schulte im walde, 2000) worked with 18.7 million words of german corpus, found 38 frame types.
</prevsent>
<prevsent>she used the duden das stilworterbuch(ag, 2001) to evaluate results and reported f-score 57,24% with pp and 62,30% without.
</prevsent>
</prevsection>
<citsent citstr=" C00-2100 ">
many other approaches have been pursued for various languages: (de lima, 2002) for portuguese, (georgala, 2003) for greek, (sarkar and zeman, 2000) <papid> C00-2100 </papid>for czech, (spranger and heid, 2003) for dutch, (chesley and salmon-alt, 2006) for french or (chrupala, 2003) for spanish, to name few.</citsent>
<aftsection>
<nextsent>irasubcat takes as input corpus in xml format.this corpus is expected to have some kind of annotation associated to its elements, which will enrich the description of the patterns associated to verbs.
</nextsent>
<nextsent>the minimal required annotation is that verbs are marked.
</nextsent>
<nextsent>if no other information is available, the form of words will be used to build the patterns.
</nextsent>
<nextsent>if the corpus has rich annotation for its elements, the system can build the patterns with the value of attributes or with combination of them, and also with combinations with lexical items.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4580">
<title id=" W10-1612.xml">irasubcat a highly parametrizable language independent tool for the acquisition of verbal subcategorization information from corpus </title>
<section> associating patterns to verbs.  </section>
<citcontext>
<prevsection>
<prevsent>one of the critical aspects of subcategorization acquisition is the association of verbs and patterns.
</prevsent>
<prevsent>how often must pattern occur with verb to make part of the subcategorization frame of the verb?
</prevsent>
</prevsection>
<citsent citstr=" W00-1325 ">
to deal with this problem, different approaches have been taken, going from simple co-occurrence count to various kinds of hypothesis testing (korhonen et al., 2000).<papid> W00-1325 </papid>to determine whether verb and pattern are associated, irasubcat provides co-occurrence frequency threshold, that can be tuned by the user, anda hypothesis test, the likelihood ratio test (dun ning, 1993).</citsent>
<aftsection>
<nextsent>we chose to implement this test, andnot others like the binomial that have been extensively used in subcategorization acquisition, because the likelihood ratio is specially good at modeling un frequent events.
</nextsent>
<nextsent>to perform this test, the null hypothesis is that the distribution of an observed pattern mj?
</nextsent>
<nextsent>is independent of of the distribution of verb vi?.
</nextsent>
<nextsent>87 figure 1: example of application of the procedure to identify adjuncts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4581">
<title id=" W10-1759.xml">translation model adaptation by re sampling </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>adaptation of smt systems is topic of increasing interest since few years.
</prevsent>
<prevsent>in previous work, adaptation is done by using mixture models, by exploiting comparable corpora and by self enhancement of translation models.mixture models were used to optimize the coefficients to the adaptation domain.
</prevsent>
</prevsection>
<citsent citstr=" W07-0722 ">
(civera and juan, 2007) <papid> W07-0722 </papid>proposed model that can be usedto generate topic-dependent alignments by extension of the hmm alignment model and derivation of viterbi alignments.</citsent>
<aftsection>
<nextsent>(zhao et al, 2004) <papid> C04-1059 </papid>constructed specific language models by using machine translation output as queries to extract similar sentences from large monolingual corpora.</nextsent>
<nextsent>(foster and kuhn, 2007) <papid> W07-0717 </papid>applied mixture model approach to adapt the system to new domain byusing weights that depend on text distances to mixture components.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4582">
<title id=" W10-1759.xml">translation model adaptation by re sampling </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in previous work, adaptation is done by using mixture models, by exploiting comparable corpora and by self enhancement of translation models.mixture models were used to optimize the coefficients to the adaptation domain.
</prevsent>
<prevsent>(civera and juan, 2007) <papid> W07-0722 </papid>proposed model that can be usedto generate topic-dependent alignments by extension of the hmm alignment model and derivation of viterbi alignments.</prevsent>
</prevsection>
<citsent citstr=" C04-1059 ">
(zhao et al, 2004) <papid> C04-1059 </papid>constructed specific language models by using machine translation output as queries to extract similar sentences from large monolingual corpora.</citsent>
<aftsection>
<nextsent>(foster and kuhn, 2007) <papid> W07-0717 </papid>applied mixture model approach to adapt the system to new domain byusing weights that depend on text distances to mixture components.</nextsent>
<nextsent>the training corpus was divided into different components, model was trained on each part and then weighted appropriately for the given context.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4583">
<title id=" W10-1759.xml">translation model adaptation by re sampling </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>(civera and juan, 2007) <papid> W07-0722 </papid>proposed model that can be usedto generate topic-dependent alignments by extension of the hmm alignment model and derivation of viterbi alignments.</prevsent>
<prevsent>(zhao et al, 2004) <papid> C04-1059 </papid>constructed specific language models by using machine translation output as queries to extract similar sentences from large monolingual corpora.</prevsent>
</prevsection>
<citsent citstr=" W07-0717 ">
(foster and kuhn, 2007) <papid> W07-0717 </papid>applied mixture model approach to adapt the system to new domain byusing weights that depend on text distances to mixture components.</citsent>
<aftsection>
<nextsent>the training corpus was divided into different components, model was trained on each part and then weighted appropriately for the given context.
</nextsent>
<nextsent>(koehn and schroeder, 2007) <papid> W07-0733 </papid>used two language models and two translation models: one in-domain and other out-of-domain to adapt the system.</nextsent>
<nextsent>two decoding paths were used to translate the text.comparable corpora are exploited to find additional parallel texts.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4584">
<title id=" W10-1759.xml">translation model adaptation by re sampling </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>(foster and kuhn, 2007) <papid> W07-0717 </papid>applied mixture model approach to adapt the system to new domain byusing weights that depend on text distances to mixture components.</prevsent>
<prevsent>the training corpus was divided into different components, model was trained on each part and then weighted appropriately for the given context.</prevsent>
</prevsection>
<citsent citstr=" W07-0733 ">
(koehn and schroeder, 2007) <papid> W07-0733 </papid>used two language models and two translation models: one in-domain and other out-of-domain to adapt the system.</citsent>
<aftsection>
<nextsent>two decoding paths were used to translate the text.comparable corpora are exploited to find additional parallel texts.
</nextsent>
<nextsent>information retrieval techniques are used to identify candidate sentences (hildebrand et al, 2005).
</nextsent>
<nextsent>(snover et al, 2008) <papid> D08-1090 </papid>used cross-lingual information retrieval to find texts in the target language that are related to the domain of the source texts.</nextsent>
<nextsent>a self-enhancing approach was applied by (ueffing, 2006) to filter the translations of the test set with the help of confidence score and to use reliable alignments to train an additional phrase table.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4585">
<title id=" W10-1759.xml">translation model adaptation by re sampling </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>two decoding paths were used to translate the text.comparable corpora are exploited to find additional parallel texts.
</prevsent>
<prevsent>information retrieval techniques are used to identify candidate sentences (hildebrand et al, 2005).
</prevsent>
</prevsection>
<citsent citstr=" D08-1090 ">
(snover et al, 2008) <papid> D08-1090 </papid>used cross-lingual information retrieval to find texts in the target language that are related to the domain of the source texts.</citsent>
<aftsection>
<nextsent>a self-enhancing approach was applied by (ueffing, 2006) to filter the translations of the test set with the help of confidence score and to use reliable alignments to train an additional phrase table.
</nextsent>
<nextsent>this additional table was used with the existing generic phrase table.
</nextsent>
<nextsent>(ueffing, 2007)further refined this approach by using trans duc tive semi-supervised methods for effective use of monolingual data from the source text.
</nextsent>
<nextsent>(chen etal., 2008) <papid> P08-2040 </papid>performed domain adaptation simultaneously for the translation, language and reordering model by learning posterior knowledge fromn-best hypothesis.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4586">
<title id=" W10-1759.xml">translation model adaptation by re sampling </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>this additional table was used with the existing generic phrase table.
</prevsent>
<prevsent>(ueffing, 2007)further refined this approach by using trans duc tive semi-supervised methods for effective use of monolingual data from the source text.
</prevsent>
</prevsection>
<citsent citstr=" P08-2040 ">
(chen etal., 2008) <papid> P08-2040 </papid>performed domain adaptation simultaneously for the translation, language and reordering model by learning posterior knowledge fromn-best hypothesis.</citsent>
<aftsection>
<nextsent>a related approach was investigated in (schwenk, 2008) and (schwenk and senellart, 2009) in which lightly supervised training was used.
</nextsent>
<nextsent>an smt system was used to translate large collections of monolingual texts, which were then filtered and added to the training data.
</nextsent>
<nextsent>(matsoukas et al, 2009) <papid> D09-1074 </papid>propose to weight each sentence in the training bitext by optimizing discriminative function on given tuning set.</nextsent>
<nextsent>sentence level features were extracted to estimate the weights that are relevant to the given task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4587">
<title id=" W10-1759.xml">translation model adaptation by re sampling </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>a related approach was investigated in (schwenk, 2008) and (schwenk and senellart, 2009) in which lightly supervised training was used.
</prevsent>
<prevsent>an smt system was used to translate large collections of monolingual texts, which were then filtered and added to the training data.
</prevsent>
</prevsection>
<citsent citstr=" D09-1074 ">
(matsoukas et al, 2009) <papid> D09-1074 </papid>propose to weight each sentence in the training bitext by optimizing discriminative function on given tuning set.</citsent>
<aftsection>
<nextsent>sentence level features were extracted to estimate the weights that are relevant to the given task.
</nextsent>
<nextsent>then certain parts of the training bitexts were down weighted to optimize an objective function on the development data.
</nextsent>
<nextsent>this can lead to parameterover-fitting if the function that maps sentence features to weights is complex.the technique proposed in this paper is some how related to the above approach of weighting the texts.
</nextsent>
<nextsent>our method does not require an explicit specification of the in-domain and out-of domain training data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4588">
<title id=" W10-2411.xml">english to indian languages machine transliteration system at news 2010 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>transliteration between two languages that use the same set of alphabets is trivial: the word is left as it is. however, for languages those use different alphabet sets the names must be transliterated or rendered in the target language alphabets.
</prevsent>
<prevsent>transliteration of words is necessary in many applications, such as machine translation, corpus alignment, cross-language information retrieval, information extraction and automatic lexicon acquisition.
</prevsent>
</prevsection>
<citsent citstr=" P04-1021 ">
in the literature, number of transliteration algorithms are available involving english (li et al, 2004; <papid> P04-1021 </papid>vigra and khudanpur, 2003; go to et al, 2003), european languages (marino et al., 2005) and some of the asian languages, namely chinese (li et al, 2004; <papid> P04-1021 </papid>vigra and khudanpur, 2003), japanese (goto et al, 2003; knight and graehl, 1998), <papid> J98-4003 </papid>korean (jung et al, 2000) <papid> C00-1056 </papid>and arabic (al-onaizan and knight, 2002a; al-onaizan and knight, 2002c).</citsent>
<aftsection>
<nextsent>recently, some works have been initiated involving indian languages (ekbal et al, 2006; <papid> P06-2025 </papid>ekbal et al, 2007; surana and singh, 2008).<papid> I08-1009 </papid></nextsent>
<nextsent>the detailed report of our participation in news 2009 could be found in (das et al, 2009).<papid> W09-3517 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4592">
<title id=" W10-2411.xml">english to indian languages machine transliteration system at news 2010 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>transliteration between two languages that use the same set of alphabets is trivial: the word is left as it is. however, for languages those use different alphabet sets the names must be transliterated or rendered in the target language alphabets.
</prevsent>
<prevsent>transliteration of words is necessary in many applications, such as machine translation, corpus alignment, cross-language information retrieval, information extraction and automatic lexicon acquisition.
</prevsent>
</prevsection>
<citsent citstr=" J98-4003 ">
in the literature, number of transliteration algorithms are available involving english (li et al, 2004; <papid> P04-1021 </papid>vigra and khudanpur, 2003; go to et al, 2003), european languages (marino et al., 2005) and some of the asian languages, namely chinese (li et al, 2004; <papid> P04-1021 </papid>vigra and khudanpur, 2003), japanese (goto et al, 2003; knight and graehl, 1998), <papid> J98-4003 </papid>korean (jung et al, 2000) <papid> C00-1056 </papid>and arabic (al-onaizan and knight, 2002a; al-onaizan and knight, 2002c).</citsent>
<aftsection>
<nextsent>recently, some works have been initiated involving indian languages (ekbal et al, 2006; <papid> P06-2025 </papid>ekbal et al, 2007; surana and singh, 2008).<papid> I08-1009 </papid></nextsent>
<nextsent>the detailed report of our participation in news 2009 could be found in (das et al, 2009).<papid> W09-3517 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4593">
<title id=" W10-2411.xml">english to indian languages machine transliteration system at news 2010 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>transliteration between two languages that use the same set of alphabets is trivial: the word is left as it is. however, for languages those use different alphabet sets the names must be transliterated or rendered in the target language alphabets.
</prevsent>
<prevsent>transliteration of words is necessary in many applications, such as machine translation, corpus alignment, cross-language information retrieval, information extraction and automatic lexicon acquisition.
</prevsent>
</prevsection>
<citsent citstr=" C00-1056 ">
in the literature, number of transliteration algorithms are available involving english (li et al, 2004; <papid> P04-1021 </papid>vigra and khudanpur, 2003; go to et al, 2003), european languages (marino et al., 2005) and some of the asian languages, namely chinese (li et al, 2004; <papid> P04-1021 </papid>vigra and khudanpur, 2003), japanese (goto et al, 2003; knight and graehl, 1998), <papid> J98-4003 </papid>korean (jung et al, 2000) <papid> C00-1056 </papid>and arabic (al-onaizan and knight, 2002a; al-onaizan and knight, 2002c).</citsent>
<aftsection>
<nextsent>recently, some works have been initiated involving indian languages (ekbal et al, 2006; <papid> P06-2025 </papid>ekbal et al, 2007; surana and singh, 2008).<papid> I08-1009 </papid></nextsent>
<nextsent>the detailed report of our participation in news 2009 could be found in (das et al, 2009).<papid> W09-3517 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4594">
<title id=" W10-2411.xml">english to indian languages machine transliteration system at news 2010 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>transliteration of words is necessary in many applications, such as machine translation, corpus alignment, cross-language information retrieval, information extraction and automatic lexicon acquisition.
</prevsent>
<prevsent>in the literature, number of transliteration algorithms are available involving english (li et al, 2004; <papid> P04-1021 </papid>vigra and khudanpur, 2003; go to et al, 2003), european languages (marino et al., 2005) and some of the asian languages, namely chinese (li et al, 2004; <papid> P04-1021 </papid>vigra and khudanpur, 2003), japanese (goto et al, 2003; knight and graehl, 1998), <papid> J98-4003 </papid>korean (jung et al, 2000) <papid> C00-1056 </papid>and arabic (al-onaizan and knight, 2002a; al-onaizan and knight, 2002c).</prevsent>
</prevsection>
<citsent citstr=" P06-2025 ">
recently, some works have been initiated involving indian languages (ekbal et al, 2006; <papid> P06-2025 </papid>ekbal et al, 2007; surana and singh, 2008).<papid> I08-1009 </papid></citsent>
<aftsection>
<nextsent>the detailed report of our participation in news 2009 could be found in (das et al, 2009).<papid> W09-3517 </papid></nextsent>
<nextsent>one standard run for bengali (bengali standard run: bsr), hindi (hindi standard run: hsr), kannada (kannada standard run: ksr) and tamil (tamil standard run: tsr) were submitted.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4595">
<title id=" W10-2411.xml">english to indian languages machine transliteration system at news 2010 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>transliteration of words is necessary in many applications, such as machine translation, corpus alignment, cross-language information retrieval, information extraction and automatic lexicon acquisition.
</prevsent>
<prevsent>in the literature, number of transliteration algorithms are available involving english (li et al, 2004; <papid> P04-1021 </papid>vigra and khudanpur, 2003; go to et al, 2003), european languages (marino et al., 2005) and some of the asian languages, namely chinese (li et al, 2004; <papid> P04-1021 </papid>vigra and khudanpur, 2003), japanese (goto et al, 2003; knight and graehl, 1998), <papid> J98-4003 </papid>korean (jung et al, 2000) <papid> C00-1056 </papid>and arabic (al-onaizan and knight, 2002a; al-onaizan and knight, 2002c).</prevsent>
</prevsection>
<citsent citstr=" I08-1009 ">
recently, some works have been initiated involving indian languages (ekbal et al, 2006; <papid> P06-2025 </papid>ekbal et al, 2007; surana and singh, 2008).<papid> I08-1009 </papid></citsent>
<aftsection>
<nextsent>the detailed report of our participation in news 2009 could be found in (das et al, 2009).<papid> W09-3517 </papid></nextsent>
<nextsent>one standard run for bengali (bengali standard run: bsr), hindi (hindi standard run: hsr), kannada (kannada standard run: ksr) and tamil (tamil standard run: tsr) were submitted.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4596">
<title id=" W10-2411.xml">english to indian languages machine transliteration system at news 2010 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the literature, number of transliteration algorithms are available involving english (li et al, 2004; <papid> P04-1021 </papid>vigra and khudanpur, 2003; go to et al, 2003), european languages (marino et al., 2005) and some of the asian languages, namely chinese (li et al, 2004; <papid> P04-1021 </papid>vigra and khudanpur, 2003), japanese (goto et al, 2003; knight and graehl, 1998), <papid> J98-4003 </papid>korean (jung et al, 2000) <papid> C00-1056 </papid>and arabic (al-onaizan and knight, 2002a; al-onaizan and knight, 2002c).</prevsent>
<prevsent>recently, some works have been initiated involving indian languages (ekbal et al, 2006; <papid> P06-2025 </papid>ekbal et al, 2007; surana and singh, 2008).<papid> I08-1009 </papid></prevsent>
</prevsection>
<citsent citstr=" W09-3517 ">
the detailed report of our participation in news 2009 could be found in (das et al, 2009).<papid> W09-3517 </papid></citsent>
<aftsection>
<nextsent>one standard run for bengali (bengali standard run: bsr), hindi (hindi standard run: hsr), kannada (kannada standard run: ksr) and tamil (tamil standard run: tsr) were submitted.
</nextsent>
<nextsent>two non-standard runs for english to hindi (hindi non-standard run 1 &amp; 2: hnsr1 &amp; hnsr2) and bengali (bengali nonstandard run 1 &amp; 2: bnsr1 &amp; bnsr1) transliteration were submitted.
</nextsent>
<nextsent>only one non-standard run were submitted for kannada (kannada nonstandard run-1: knsr1) and tamil (tamil non-standard run-1: tnsr1).
</nextsent>
<nextsent>71
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4598">
<title id=" W10-1836.xml">the revised arabic propbank </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>1 these resources can now be exploited by the computational linguistics community with the aim of improving the automatic processing of arabic.
</prevsent>
<prevsent>this paper discusses semantic labeling.
</prevsent>
</prevsection>
<citsent citstr=" P02-1031 ">
shallow approaches to semantic processing are making large advances in the direction of efficiently and effectively deriving application relevant explicit semantic information from text (pradhan et al, 2003; gildea and palmer, 2002; <papid> P02-1031 </papid>pradhan et al, 2004; <papid> N04-1030 </papid>gildea and jurafsky, 2002; <papid> J02-3001 </papid>xue and palmer, 2004; <papid> W04-3212 </papid>chen and rambow, 2003; <papid> W03-1006 </papid>carreras and marquez, 2005; moschitti, 2004; <papid> P04-1043 </papid>moschitti et al, 2005; <papid> W05-0630 </papid>diab et al, 2008).<papid> P08-1091 </papid></citsent>
<aftsection>
<nextsent>indeed, the existence of semantically annotated resources in english such as framenet (baker et al., 1998) and propbank (kingsbury and palmer, 2003; palmer et al, 2005) <papid> J05-1004 </papid>corpora have marked surge inefficient approaches to automatic se 1 in this paper, we use arabic to refer to modern standard.</nextsent>
<nextsent>arabic (msa).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4599">
<title id=" W10-1836.xml">the revised arabic propbank </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>1 these resources can now be exploited by the computational linguistics community with the aim of improving the automatic processing of arabic.
</prevsent>
<prevsent>this paper discusses semantic labeling.
</prevsent>
</prevsection>
<citsent citstr=" N04-1030 ">
shallow approaches to semantic processing are making large advances in the direction of efficiently and effectively deriving application relevant explicit semantic information from text (pradhan et al, 2003; gildea and palmer, 2002; <papid> P02-1031 </papid>pradhan et al, 2004; <papid> N04-1030 </papid>gildea and jurafsky, 2002; <papid> J02-3001 </papid>xue and palmer, 2004; <papid> W04-3212 </papid>chen and rambow, 2003; <papid> W03-1006 </papid>carreras and marquez, 2005; moschitti, 2004; <papid> P04-1043 </papid>moschitti et al, 2005; <papid> W05-0630 </papid>diab et al, 2008).<papid> P08-1091 </papid></citsent>
<aftsection>
<nextsent>indeed, the existence of semantically annotated resources in english such as framenet (baker et al., 1998) and propbank (kingsbury and palmer, 2003; palmer et al, 2005) <papid> J05-1004 </papid>corpora have marked surge inefficient approaches to automatic se 1 in this paper, we use arabic to refer to modern standard.</nextsent>
<nextsent>arabic (msa).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4600">
<title id=" W10-1836.xml">the revised arabic propbank </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>1 these resources can now be exploited by the computational linguistics community with the aim of improving the automatic processing of arabic.
</prevsent>
<prevsent>this paper discusses semantic labeling.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
shallow approaches to semantic processing are making large advances in the direction of efficiently and effectively deriving application relevant explicit semantic information from text (pradhan et al, 2003; gildea and palmer, 2002; <papid> P02-1031 </papid>pradhan et al, 2004; <papid> N04-1030 </papid>gildea and jurafsky, 2002; <papid> J02-3001 </papid>xue and palmer, 2004; <papid> W04-3212 </papid>chen and rambow, 2003; <papid> W03-1006 </papid>carreras and marquez, 2005; moschitti, 2004; <papid> P04-1043 </papid>moschitti et al, 2005; <papid> W05-0630 </papid>diab et al, 2008).<papid> P08-1091 </papid></citsent>
<aftsection>
<nextsent>indeed, the existence of semantically annotated resources in english such as framenet (baker et al., 1998) and propbank (kingsbury and palmer, 2003; palmer et al, 2005) <papid> J05-1004 </papid>corpora have marked surge inefficient approaches to automatic se 1 in this paper, we use arabic to refer to modern standard.</nextsent>
<nextsent>arabic (msa).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4601">
<title id=" W10-1836.xml">the revised arabic propbank </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>1 these resources can now be exploited by the computational linguistics community with the aim of improving the automatic processing of arabic.
</prevsent>
<prevsent>this paper discusses semantic labeling.
</prevsent>
</prevsection>
<citsent citstr=" W04-3212 ">
shallow approaches to semantic processing are making large advances in the direction of efficiently and effectively deriving application relevant explicit semantic information from text (pradhan et al, 2003; gildea and palmer, 2002; <papid> P02-1031 </papid>pradhan et al, 2004; <papid> N04-1030 </papid>gildea and jurafsky, 2002; <papid> J02-3001 </papid>xue and palmer, 2004; <papid> W04-3212 </papid>chen and rambow, 2003; <papid> W03-1006 </papid>carreras and marquez, 2005; moschitti, 2004; <papid> P04-1043 </papid>moschitti et al, 2005; <papid> W05-0630 </papid>diab et al, 2008).<papid> P08-1091 </papid></citsent>
<aftsection>
<nextsent>indeed, the existence of semantically annotated resources in english such as framenet (baker et al., 1998) and propbank (kingsbury and palmer, 2003; palmer et al, 2005) <papid> J05-1004 </papid>corpora have marked surge inefficient approaches to automatic se 1 in this paper, we use arabic to refer to modern standard.</nextsent>
<nextsent>arabic (msa).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4602">
<title id=" W10-1836.xml">the revised arabic propbank </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>1 these resources can now be exploited by the computational linguistics community with the aim of improving the automatic processing of arabic.
</prevsent>
<prevsent>this paper discusses semantic labeling.
</prevsent>
</prevsection>
<citsent citstr=" W03-1006 ">
shallow approaches to semantic processing are making large advances in the direction of efficiently and effectively deriving application relevant explicit semantic information from text (pradhan et al, 2003; gildea and palmer, 2002; <papid> P02-1031 </papid>pradhan et al, 2004; <papid> N04-1030 </papid>gildea and jurafsky, 2002; <papid> J02-3001 </papid>xue and palmer, 2004; <papid> W04-3212 </papid>chen and rambow, 2003; <papid> W03-1006 </papid>carreras and marquez, 2005; moschitti, 2004; <papid> P04-1043 </papid>moschitti et al, 2005; <papid> W05-0630 </papid>diab et al, 2008).<papid> P08-1091 </papid></citsent>
<aftsection>
<nextsent>indeed, the existence of semantically annotated resources in english such as framenet (baker et al., 1998) and propbank (kingsbury and palmer, 2003; palmer et al, 2005) <papid> J05-1004 </papid>corpora have marked surge inefficient approaches to automatic se 1 in this paper, we use arabic to refer to modern standard.</nextsent>
<nextsent>arabic (msa).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4603">
<title id=" W10-1836.xml">the revised arabic propbank </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>1 these resources can now be exploited by the computational linguistics community with the aim of improving the automatic processing of arabic.
</prevsent>
<prevsent>this paper discusses semantic labeling.
</prevsent>
</prevsection>
<citsent citstr=" P04-1043 ">
shallow approaches to semantic processing are making large advances in the direction of efficiently and effectively deriving application relevant explicit semantic information from text (pradhan et al, 2003; gildea and palmer, 2002; <papid> P02-1031 </papid>pradhan et al, 2004; <papid> N04-1030 </papid>gildea and jurafsky, 2002; <papid> J02-3001 </papid>xue and palmer, 2004; <papid> W04-3212 </papid>chen and rambow, 2003; <papid> W03-1006 </papid>carreras and marquez, 2005; moschitti, 2004; <papid> P04-1043 </papid>moschitti et al, 2005; <papid> W05-0630 </papid>diab et al, 2008).<papid> P08-1091 </papid></citsent>
<aftsection>
<nextsent>indeed, the existence of semantically annotated resources in english such as framenet (baker et al., 1998) and propbank (kingsbury and palmer, 2003; palmer et al, 2005) <papid> J05-1004 </papid>corpora have marked surge inefficient approaches to automatic se 1 in this paper, we use arabic to refer to modern standard.</nextsent>
<nextsent>arabic (msa).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4604">
<title id=" W10-1836.xml">the revised arabic propbank </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>1 these resources can now be exploited by the computational linguistics community with the aim of improving the automatic processing of arabic.
</prevsent>
<prevsent>this paper discusses semantic labeling.
</prevsent>
</prevsection>
<citsent citstr=" W05-0630 ">
shallow approaches to semantic processing are making large advances in the direction of efficiently and effectively deriving application relevant explicit semantic information from text (pradhan et al, 2003; gildea and palmer, 2002; <papid> P02-1031 </papid>pradhan et al, 2004; <papid> N04-1030 </papid>gildea and jurafsky, 2002; <papid> J02-3001 </papid>xue and palmer, 2004; <papid> W04-3212 </papid>chen and rambow, 2003; <papid> W03-1006 </papid>carreras and marquez, 2005; moschitti, 2004; <papid> P04-1043 </papid>moschitti et al, 2005; <papid> W05-0630 </papid>diab et al, 2008).<papid> P08-1091 </papid></citsent>
<aftsection>
<nextsent>indeed, the existence of semantically annotated resources in english such as framenet (baker et al., 1998) and propbank (kingsbury and palmer, 2003; palmer et al, 2005) <papid> J05-1004 </papid>corpora have marked surge inefficient approaches to automatic se 1 in this paper, we use arabic to refer to modern standard.</nextsent>
<nextsent>arabic (msa).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4605">
<title id=" W10-1836.xml">the revised arabic propbank </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>1 these resources can now be exploited by the computational linguistics community with the aim of improving the automatic processing of arabic.
</prevsent>
<prevsent>this paper discusses semantic labeling.
</prevsent>
</prevsection>
<citsent citstr=" P08-1091 ">
shallow approaches to semantic processing are making large advances in the direction of efficiently and effectively deriving application relevant explicit semantic information from text (pradhan et al, 2003; gildea and palmer, 2002; <papid> P02-1031 </papid>pradhan et al, 2004; <papid> N04-1030 </papid>gildea and jurafsky, 2002; <papid> J02-3001 </papid>xue and palmer, 2004; <papid> W04-3212 </papid>chen and rambow, 2003; <papid> W03-1006 </papid>carreras and marquez, 2005; moschitti, 2004; <papid> P04-1043 </papid>moschitti et al, 2005; <papid> W05-0630 </papid>diab et al, 2008).<papid> P08-1091 </papid></citsent>
<aftsection>
<nextsent>indeed, the existence of semantically annotated resources in english such as framenet (baker et al., 1998) and propbank (kingsbury and palmer, 2003; palmer et al, 2005) <papid> J05-1004 </papid>corpora have marked surge inefficient approaches to automatic se 1 in this paper, we use arabic to refer to modern standard.</nextsent>
<nextsent>arabic (msa).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4606">
<title id=" W10-1836.xml">the revised arabic propbank </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper discusses semantic labeling.
</prevsent>
<prevsent>shallow approaches to semantic processing are making large advances in the direction of efficiently and effectively deriving application relevant explicit semantic information from text (pradhan et al, 2003; gildea and palmer, 2002; <papid> P02-1031 </papid>pradhan et al, 2004; <papid> N04-1030 </papid>gildea and jurafsky, 2002; <papid> J02-3001 </papid>xue and palmer, 2004; <papid> W04-3212 </papid>chen and rambow, 2003; <papid> W03-1006 </papid>carreras and marquez, 2005; moschitti, 2004; <papid> P04-1043 </papid>moschitti et al, 2005; <papid> W05-0630 </papid>diab et al, 2008).<papid> P08-1091 </papid></prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
indeed, the existence of semantically annotated resources in english such as framenet (baker et al., 1998) and propbank (kingsbury and palmer, 2003; palmer et al, 2005) <papid> J05-1004 </papid>corpora have marked surge inefficient approaches to automatic se 1 in this paper, we use arabic to refer to modern standard.</citsent>
<aftsection>
<nextsent>arabic (msa).
</nextsent>
<nextsent>mantic labeling of the english language.
</nextsent>
<nextsent>forex ample, in the english sentence, john enjoys movies?, the predicate is enjoys?
</nextsent>
<nextsent>and the first argument, the subject, is john?, and the second argument, the object, is movies?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4607">
<title id=" W10-1836.xml">the revised arabic propbank </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>is the theme (arg1).
</prevsent>
<prevsent>in addition to english, there are propbank efforts in chinese (xue et al, 2009), korean (palmer et al 2006) and hindi (palmer et al, 2009), as well as framenet annotations in chinese, german, japanese, spanish and other languages (hans 2009).
</prevsent>
</prevsection>
<citsent citstr=" L08-1461 ">
being able to automatically apply this level of analysis to arabic is clearly desirable goal, and indeed, we began pilot arabic propbank effort several years ago (palmer et al, 2008).<papid> L08-1461 </papid></citsent>
<aftsection>
<nextsent>in this paper, we present recent work on adapting the original pilot arabic proposition bank (apb) annotation to the recent changes that have been made to the arabic treebank (maamouri et al, 2008).
</nextsent>
<nextsent>these changes have presented both linguistic and engineering challenges as described in the following sections.
</nextsent>
<nextsent>in section 2 we discuss major linguistics changes in the arabic treebank annotation, and any impact they might have for the apb effort.
</nextsent>
<nextsent>in section 3 we discuss the engineering ramifications of adding and deleting nodes from parse trees, which necessitates mov 222ing all of the apb label pointers to new tree locations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4609">
<title id=" W10-3114.xml">contradiction focused qualitative evaluation of textual entailment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>rte datasets have been mainly built with the purpose of showing the applicability of the te framework to different semantic applications in computational linguistics.
</prevsent>
<prevsent>starting from 2005, [t,h] pairs were created including samples from summarization, question answering, information extraction, and other applications.
</prevsent>
</prevsection>
<citsent citstr=" E06-1052 ">
this evaluation provides useful cues for researchers and developers aiming at the integration of te components in larger applications (see, for instance, the use of ate engine for question answering in the qall me project system 1 , the use in relation extraction(romano et al, 2006), <papid> E06-1052 </papid>and in reading comprehension systems (nielsen et al, 2009)).although the rte evaluations showed progresses in te technologies, we think that there is still large room for improving qualitative analysis of both the rte datasets and the system results.</citsent>
<aftsection>
<nextsent>in particular, we intend to focus this paper on contradiction judgments and on deep inspection of the linguistic phenomena that determine such judgments.
</nextsent>
<nextsent>more specifically, we address two distinguishing aspects of te: (i) the variety of linguistic phenomena that are relevant for contradiction and how their distribution is represented in rte datasets; (ii) the fact that in te it is not enough to detect the polarity of sentence, as in traditional semantic analysis, but rather it is necessary to analyze the dependencies between two sentences (i.e.the [t,h] pair) in order to establish whether contradiction holds between the pair.
</nextsent>
<nextsent>under this respect we are interested to investigate both how polarity among text and hypothesis affects theentailment/contradiction judgments and how different linguistic phenomena interact with polarity (e.g. whether specific combinations of phenomena are more frequent than others).
</nextsent>
<nextsent>as an example, let us consider the pair: t: mexicos new president, felipe calderon, seems to be doing all the right things in cracking down on mexicos drug traffickers.[...]
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4610">
<title id=" W10-3114.xml">contradiction focused qualitative evaluation of textual entailment </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>behaviours: for example, on the mono thematic dataset edits produces pretty high number of false positives, meaning thatfor this system if there are no evidences of contradiction, pair should be marked as entailment(in order to improve such system, strategies to detect contradiction pairs should be thought).
</prevsent>
<prevsent>on the contrary, venses produces pretty high number of false negatives, meaning that if the system is not able to find evidences of entailment, it assigns the contradiction value to the pairs (for this system, being able to correctly detect all the phenomena contributing to entailment in pair is fundamental, otherwise it will be marked as contradiction).
</prevsent>
</prevsection>
<citsent citstr=" W03-0906 ">
condoravdi et al (2003) <papid> W03-0906 </papid>first proposed contradiction detection as an important nlp task, then(harabagiu et al, 2006) provided the first empirical results for it, focusing on contradiction caused by negation, antonymy, and paraphrases.voorhees (2008) carries out an analysis of rte 3 extended task, examining systems?</citsent>
<aftsection>
<nextsent>abilities to detect contradiction and providing explanations of their reasoning when making entailment decisions.
</nextsent>
<nextsent>beside defining the categories of construction from which contradiction may arise, marneffe et al.
</nextsent>
<nextsent>(2008) provide the annotation of the rte datasets (rte-1 and rte-2) for contradiction.
</nextsent>
<nextsent>furthermore, they also collect contradiction inthe wild?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4611">
<title id=" W10-3114.xml">contradiction focused qualitative evaluation of textual entailment </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>furthermore, they also collect contradiction inthe wild?
</prevsent>
<prevsent>(e.g. from newswire, wikipedia) to sample naturally occurring ones.
</prevsent>
</prevsection>
<citsent citstr=" D08-1002 ">
6 ritter et al (2008) <papid> D08-1002 </papid>extend (marneffe et al, 2008)s analysis to class of contradiction that can only be detected using backgroud knowledge, and describe case study of contradiction detection based on functional relations.</citsent>
<aftsection>
<nextsent>they also automatically generate corpus of seeming contradiction from the web text.
</nextsent>
<nextsent>7 furthermore, some of the systems presented inthe previous editions of the rte challenges attempted specic strategies to focus on the phenomenon of negation.
</nextsent>
<nextsent>for instance, (snow et al,2006) <papid> N06-1005 </papid>presents framework for recognizing textual entailment that focuses on the use of syntactic heuristics to recognize false entailment.</nextsent>
<nextsent>among the others, heuristics concerning negation mismatch and antonym match are defined.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4612">
<title id=" W10-3114.xml">contradiction focused qualitative evaluation of textual entailment </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>they also automatically generate corpus of seeming contradiction from the web text.
</prevsent>
<prevsent>7 furthermore, some of the systems presented inthe previous editions of the rte challenges attempted specic strategies to focus on the phenomenon of negation.
</prevsent>
</prevsection>
<citsent citstr=" N06-1005 ">
for instance, (snow et al,2006) <papid> N06-1005 </papid>presents framework for recognizing textual entailment that focuses on the use of syntactic heuristics to recognize false entailment.</citsent>
<aftsection>
<nextsent>among the others, heuristics concerning negation mismatch and antonym match are defined.
</nextsent>
<nextsent>in (tatu et al, 2007) the logic representation of sentences with negated concepts was altered to mark as negated the entire scope of the negation.
</nextsent>
<nextsent>(ferrandez et al, 2009) propose system facing the entailment recognition by computing shallow lexical deductions and richer inferences based on semantics, and features relating to negation are extracted.
</nextsent>
<nextsent>in (iftene et al, 2009) several rules are extracted and applied to detect contradiction cases.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4613">
<title id=" W10-1308.xml">a multimodal vocabulary for augmentative and alternative communication from sound image label datasets </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this approach is viable because the words in the sound/image labels were shown to evoke one another based on the auditory/visual content, and their meanings can be identified by considering all the tags generated forgiven sound or image as context.
</prevsent>
<prevsent>with the availability of large sound/image label datasets, the vocabulary created from wsd can be easily expanded.
</prevsent>
</prevsection>
<citsent citstr=" P97-1009 ">
a variety of wsd methods (e.g. knowledge based methods (lesk, 1986), unsupervised methods (lin, 1997), <papid> P97-1009 </papid>semi-supervised methods (hearst, 1991) (yarowsky, 1995), <papid> P95-1026 </papid>and supervised methods (novischi et al , 2007)) <papid> W07-2047 </papid>were developed and evaluated with corpus data and other text documents like webpages.</citsent>
<aftsection>
<nextsent>compared to the text data that wsd methods work with, labels for sounds and images have unique characteristics.
</nextsent>
<nextsent>the labels are bag of words related to the visual/auditory content; there is no syntactic or part of speech information, nor are the words necessarily contextual neighbors.
</nextsent>
<nextsent>for example, contexts suggest landscape senses for the word pair bank?
</nextsent>
<nextsent>and water?, whereas in an image, person may drink water inside bank building.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4614">
<title id=" W10-1308.xml">a multimodal vocabulary for augmentative and alternative communication from sound image label datasets </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this approach is viable because the words in the sound/image labels were shown to evoke one another based on the auditory/visual content, and their meanings can be identified by considering all the tags generated forgiven sound or image as context.
</prevsent>
<prevsent>with the availability of large sound/image label datasets, the vocabulary created from wsd can be easily expanded.
</prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
a variety of wsd methods (e.g. knowledge based methods (lesk, 1986), unsupervised methods (lin, 1997), <papid> P97-1009 </papid>semi-supervised methods (hearst, 1991) (yarowsky, 1995), <papid> P95-1026 </papid>and supervised methods (novischi et al , 2007)) <papid> W07-2047 </papid>were developed and evaluated with corpus data and other text documents like webpages.</citsent>
<aftsection>
<nextsent>compared to the text data that wsd methods work with, labels for sounds and images have unique characteristics.
</nextsent>
<nextsent>the labels are bag of words related to the visual/auditory content; there is no syntactic or part of speech information, nor are the words necessarily contextual neighbors.
</nextsent>
<nextsent>for example, contexts suggest landscape senses for the word pair bank?
</nextsent>
<nextsent>and water?, whereas in an image, person may drink water inside bank building.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4615">
<title id=" W10-1308.xml">a multimodal vocabulary for augmentative and alternative communication from sound image label datasets </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this approach is viable because the words in the sound/image labels were shown to evoke one another based on the auditory/visual content, and their meanings can be identified by considering all the tags generated forgiven sound or image as context.
</prevsent>
<prevsent>with the availability of large sound/image label datasets, the vocabulary created from wsd can be easily expanded.
</prevsent>
</prevsection>
<citsent citstr=" W07-2047 ">
a variety of wsd methods (e.g. knowledge based methods (lesk, 1986), unsupervised methods (lin, 1997), <papid> P97-1009 </papid>semi-supervised methods (hearst, 1991) (yarowsky, 1995), <papid> P95-1026 </papid>and supervised methods (novischi et al , 2007)) <papid> W07-2047 </papid>were developed and evaluated with corpus data and other text documents like webpages.</citsent>
<aftsection>
<nextsent>compared to the text data that wsd methods work with, labels for sounds and images have unique characteristics.
</nextsent>
<nextsent>the labels are bag of words related to the visual/auditory content; there is no syntactic or part of speech information, nor are the words necessarily contextual neighbors.
</nextsent>
<nextsent>for example, contexts suggest landscape senses for the word pair bank?
</nextsent>
<nextsent>and water?, whereas in an image, person may drink water inside bank building.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4616">
<title id=" W10-1308.xml">a multimodal vocabulary for augmentative and alternative communication from sound image label datasets </title>
<section> evocation and other semantic related-.  </section>
<citcontext>
<prevsection>
<prevsent>shortest path length between syn sets, inversely proportional to the number of nodes on the path.
</prevsent>
<prevsent>wup?
</prevsent>
</prevsection>
<citsent citstr=" P94-1019 ">
(wu and palmer, 1994) ? <papid> P94-1019 </papid>ratio of the depth of the least common subsumer (lcs) to the depths of two synsets in the wordnet taxonomy.</citsent>
<aftsection>
<nextsent>lch?
</nextsent>
<nextsent>(leacock and chodorow, 1998) ? considering the length of the shortest path between two synsets to the depth of the wordnet taxonomy.
</nextsent>
<nextsent>2) information and content based measures.
</nextsent>
<nextsent>res?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4618">
<title id=" W10-1308.xml">a multimodal vocabulary for augmentative and alternative communication from sound image label datasets </title>
<section> evocation and other semantic related-.  </section>
<citcontext>
<prevsection>
<prevsent>(banerjee and pedersen, 2002) ? overlaps in the definitions of two synsets.
</prevsent>
<prevsent>vector?
</prevsent>
</prevsection>
<citsent citstr=" W06-2501 ">
(patwardhan and pedersen, 2006) ? <papid> W06-2501 </papid>cosine of the angle between the cooccurrence vector computed from the definitions around the two synsets.</citsent>
<aftsection>
<nextsent>vector_pairs?
</nextsent>
<nextsent>co-occurrence vectors are computed from definition pairs separately.
</nextsent>
<nextsent>the computation of the relatedness scores using measures listed above were carried out by codes from the wordnet::similarity (pedersen et al , 2004) and wordnet::senserelate projects (pedersen and kolhatkar, 2009).<papid> N09-5005 </papid></nextsent>
<nextsent>in contrast to word net::senserelated, which employs only one similarity measure in the wsd process, this paper proposes strategy of having several semantic relatedness measures vote for the best synset for each word.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4619">
<title id=" W10-1308.xml">a multimodal vocabulary for augmentative and alternative communication from sound image label datasets </title>
<section> evocation and other semantic related-.  </section>
<citcontext>
<prevsection>
<prevsent>vector_pairs?
</prevsent>
<prevsent>co-occurrence vectors are computed from definition pairs separately.
</prevsent>
</prevsection>
<citsent citstr=" N09-5005 ">
the computation of the relatedness scores using measures listed above were carried out by codes from the wordnet::similarity (pedersen et al , 2004) and wordnet::senserelate projects (pedersen and kolhatkar, 2009).<papid> N09-5005 </papid></citsent>
<aftsection>
<nextsent>in contrast to word net::senserelated, which employs only one similarity measure in the wsd process, this paper proposes strategy of having several semantic relatedness measures vote for the best synset for each word.
</nextsent>
<nextsent>the voting algorithm intends to improve wsd performance by combining conclusions from various measures to eliminate false result.
</nextsent>
<nextsent>since there is no syntax among the words generated for sound/image, they should all be considered for wsd.
</nextsent>
<nextsent>thus, the width of the context window is the total number of words in the context.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4620">
<title id=" W10-1615.xml">recognition and extraction of definitional contexts in spanish for sketching a lexical network </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>table 3: sequence frequencies of predication patterns and analytical definitions analytical definitions cli cie primary predication candidates 1686 494 dcs 111 127 recall precision 100% 6.6% 100% 25.7% secondary predication candidates 701 61 dcs 66 11 recall precision 100% 9.4% 100% 18.0% we derived frequency distribution of the verbs with type of predication for cli and cie corpora.
</prevsent>
<prevsent>the table 4 shows the relative frequency of use of each verb explored.
</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
most of these verbs do not have been considered in automatic extraction tasks of hyponymy-hyperonymy relations, e. g.: hearst (1992) <papid> C92-2082 </papid>or wilks, slator &amp; guthrie (1995).</citsent>
<aftsection>
<nextsent>table 4: frequency distribution of verbal predicate, and its use in analytical definitions predication corpora cli cie primary referir(a)/to refer 0 0.02 representar/to represent 0 0.04 significar/to signify 0 0.03 ser/to be 1 0.91 secondary caracterizar/to characterize 0.12 0.18 concebir/to concibe 0.09 0 conocer/to know 0.17 0 considerar/to consider 0.21 0.27 definir/to define 0.27 0.27 describir/to describe 0.03 0.09 entender/to understand 0.06 0.18 identificar/to identify 0.03 0 visualizar/to visualize 0.02 0once established this distribution, we have analyzed the degree of assurance to find good candidate for analytical definitions.
</nextsent>
<nextsent>we have applied method of conditional probabilities for primary and secondary predications.
</nextsent>
<nextsent>our conditional probabilities are formulated by the hypothesis that the probability (p) of co-occurrence of predications (pred) linked to analytical definition (ad) is high.
</nextsent>
<nextsent>thus, we apply the following formula of conditional probability: p(ad ? pred) p(ad|pred) = p(pred) 112 taking into account the formula mentioned above, we obtained the following results: table 5: conditional probabilities of co-occurrence between predications and analytical definitions predication cli cie primary analytical definitions 93% 100% not-analytical definitions 7% 0% secondary analytical definitions 95% 100% not-analytical definitions 5% 0% therefore, we considered that the possibility to identify good candidate of analytical definition is high, insofar as we took into account their relationship with primary and secondary predications.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4622">
<title id=" W10-1204.xml">a graph based semi supervised learning for question semantic labeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we investigate question understanding based on machine learning approach to discover semantic components (table 1).
</prevsent>
<prevsent>an important issue in information extraction from text is that one often deals with insufficient labeled data and large number of unlabeled data, which have led to improvements in semi-supervised learning (ssl) methods, e.g., (belkin and niyogi., 2002b), (zhou et al, 2004).
</prevsent>
</prevsection>
<citsent citstr=" N07-1026 ">
recently, graph based ssl methods have gained interest (alexandrescu and kirchhoff, 2007), (<papid> N07-1026 </papid>goldberg and zhu, 2009).<papid> W09-2203 </papid>these methods create graphs whose vertices correspond to labeled and unlabeled data, while the edge weights encode the similarity between each pair of data points.</citsent>
<aftsection>
<nextsent>classification is performed using these graphs by scoring unlabeled points in such way what?
</nextsent>
<nextsent>other film ? ??
</nextsent>
<nextsent>focus introduced?
</nextsent>
<nextsent>event jar jar binks?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4623">
<title id=" W10-1204.xml">a graph based semi supervised learning for question semantic labeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we investigate question understanding based on machine learning approach to discover semantic components (table 1).
</prevsent>
<prevsent>an important issue in information extraction from text is that one often deals with insufficient labeled data and large number of unlabeled data, which have led to improvements in semi-supervised learning (ssl) methods, e.g., (belkin and niyogi., 2002b), (zhou et al, 2004).
</prevsent>
</prevsection>
<citsent citstr=" W09-2203 ">
recently, graph based ssl methods have gained interest (alexandrescu and kirchhoff, 2007), (<papid> N07-1026 </papid>goldberg and zhu, 2009).<papid> W09-2203 </papid>these methods create graphs whose vertices correspond to labeled and unlabeled data, while the edge weights encode the similarity between each pair of data points.</citsent>
<aftsection>
<nextsent>classification is performed using these graphs by scoring unlabeled points in such way what?
</nextsent>
<nextsent>other film ? ??
</nextsent>
<nextsent>focus introduced?
</nextsent>
<nextsent>event jar jar binks?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4624">
<title id=" W10-1204.xml">a graph based semi supervised learning for question semantic labeling </title>
<section> related work on question analysis.  </section>
<citcontext>
<prevsection>
<prevsent>to extract topic-focus from questions, (ha jicova et al, 1993) used rule-based approaches via dependency parser structures.
</prevsent>
<prevsent>(burger, 2006) implemented parsers and mixture of rule-based and learning methods to extract different salient features such as question type, event, entities, etc.
</prevsent>
</prevsection>
<citsent citstr=" W04-2504 ">
(chai and jin, 2004) <papid> W04-2504 </papid>explored semantic units based on their discourse relations via rule-based systems.in (duan et al, 2008) <papid> P08-1019 </papid>language model is presented to extract semantic components from ques tions.</citsent>
<aftsection>
<nextsent>similarly, (fan et al, 2008)<papid> W08-1601 </papid>s semantic chunk annotation uses conditional random fields (crf) (lafferty et al, 2001) to annotate semantic chunks of questions in chinese.</nextsent>
<nextsent>our work aparts from these studies in that we use graph-based ssl method to extract semantic components from unlabeled questions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4625">
<title id=" W10-1204.xml">a graph based semi supervised learning for question semantic labeling </title>
<section> related work on question analysis.  </section>
<citcontext>
<prevsection>
<prevsent>to extract topic-focus from questions, (ha jicova et al, 1993) used rule-based approaches via dependency parser structures.
</prevsent>
<prevsent>(burger, 2006) implemented parsers and mixture of rule-based and learning methods to extract different salient features such as question type, event, entities, etc.
</prevsent>
</prevsection>
<citsent citstr=" P08-1019 ">
(chai and jin, 2004) <papid> W04-2504 </papid>explored semantic units based on their discourse relations via rule-based systems.in (duan et al, 2008) <papid> P08-1019 </papid>language model is presented to extract semantic components from ques tions.</citsent>
<aftsection>
<nextsent>similarly, (fan et al, 2008)<papid> W08-1601 </papid>s semantic chunk annotation uses conditional random fields (crf) (lafferty et al, 2001) to annotate semantic chunks of questions in chinese.</nextsent>
<nextsent>our work aparts from these studies in that we use graph-based ssl method to extract semantic components from unlabeled questions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4626">
<title id=" W10-1204.xml">a graph based semi supervised learning for question semantic labeling </title>
<section> related work on question analysis.  </section>
<citcontext>
<prevsection>
<prevsent>(burger, 2006) implemented parsers and mixture of rule-based and learning methods to extract different salient features such as question type, event, entities, etc.
</prevsent>
<prevsent>(chai and jin, 2004) <papid> W04-2504 </papid>explored semantic units based on their discourse relations via rule-based systems.in (duan et al, 2008) <papid> P08-1019 </papid>language model is presented to extract semantic components from ques tions.</prevsent>
</prevsection>
<citsent citstr=" W08-1601 ">
similarly, (fan et al, 2008)<papid> W08-1601 </papid>s semantic chunk annotation uses conditional random fields (crf) (lafferty et al, 2001) to annotate semantic chunks of questions in chinese.</citsent>
<aftsection>
<nextsent>our work aparts from these studies in that we use graph-based ssl method to extract semantic components from unlabeled questions.
</nextsent>
<nextsent>graph-based methods are suitable for labeling tasks because when two lexical unitsin different questions are close in the intrinsic geometry of question forms, their semantic components (labels) will be similar to each other.
</nextsent>
<nextsent>labels vary smoothly along the geodesics, i.e., manifold assumption, which plays an essential role in ssl (belkin et al, 2006).
</nextsent>
<nextsent>this paper presents new graph construction to improve performance of an important module of qawhen labeled data is sparse.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4627">
<title id=" W10-1204.xml">a graph based semi supervised learning for question semantic labeling </title>
<section> semantic component labeling.  </section>
<citcontext>
<prevsection>
<prevsent>the following pre-processing modules are built for feature extraction prior to graph construction.
</prevsent>
<prevsent>3.1.1 pre-processing for feature extraction phrase analysis(pa): using basic syntactic analysis (shallow parsing), the pa module re-buildsphrases from linguistic structures such as noun phrases (nn), basic prepositional phrases (pp) or verb groups (vg).
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
using stanford dependency parser (klein and manning, 2003), (<papid> P03-1054 </papid>marneffe et al,2006), which produces 48 different grammatical relations, pa module re-constructs the phrases.</citsent>
<aftsection>
<nextsent>for example for the question in table 1, dependency parser generates two relations: ? nn(binks-3, jar-1) and nn(binks-3, jar-2),pa reveals jar jar binks?
</nextsent>
<nextsent>as noun phrase reconstructing the nn:noun compound modifier.
</nextsent>
<nextsent>wealso extract part of speech tags of questions via dependency parser to be used for feature extraction.
</nextsent>
<nextsent>question dependency relations (qdr): using shallow semantics, we decode underlying stanford dependency trees (marneffe et al, 2006) that embody linguistic relationships such as head-subject(h-s), head-modifier (complement) (h-m), head object (h-o), etc. for example: how did troops enter the area last friday??
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4628">
<title id=" W10-3811.xml">manipurienglish bidirectional statistical machine translation systems using morphology and dependency relations </title>
<section> related works.  </section>
<citcontext>
<prevsection>
<prevsent>83 the parallel corpora used is in news domain which have been collected, cleaned and aligned (singh et al , 2010b) from the sangai express newspaper website www.thesangaiexpress.com available in both mani puri and english.
</prevsent>
<prevsent>a daily basis collection was done covering the period from may 2008 to november 2008 since there is no repository.
</prevsent>
</prevsection>
<citsent citstr=" D07-1091 ">
koehn and hoang (2007) <papid> D07-1091 </papid>developed framework for statistical translation models that tightly integrates additional morphological, syntactic, or semantic information.</citsent>
<aftsection>
<nextsent>statistical machine translation with scarce resources using morphosyntactic information is discussed in (nieen and ney, 2004).
</nextsent>
<nextsent>it introduces sentence level restructuring transformations that aim at the assimilation of word order in related sentences and exploitation of the bilingual training data by explicitly taking into account the interdependencies of related inflected forms thereby improving the translation quality.
</nextsent>
<nextsent>popovic and ney (2006) discussed smt with small amount of bilingual training data.
</nextsent>
<nextsent>case markers and morphology are used to address the crux of fluency in the eng lish-hindi smt system (ramanathan et al, 2009).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4629">
<title id=" W10-3811.xml">manipurienglish bidirectional statistical machine translation systems using morphology and dependency relations </title>
<section> related works.  </section>
<citcontext>
<prevsection>
<prevsent>popovic and ney (2006) discussed smt with small amount of bilingual training data.
</prevsent>
<prevsent>case markers and morphology are used to address the crux of fluency in the eng lish-hindi smt system (ramanathan et al, 2009).
</prevsent>
</prevsection>
<citsent citstr=" P08-1087 ">
work on translating from rich to poor morphology using factored model is reported in (avramidis and koehn, 2008).<papid> P08-1087 </papid></citsent>
<aftsection>
<nextsent>in this method of enriching input, the case agreement for nouns, adjectives and articles are mainly defined by the syntactic role of each phrase.
</nextsent>
<nextsent>resolution of verb conjugation is done by identifying the person of verb and using the linguistic information tag.
</nextsent>
<nextsent>mani puri to english example based machine translation system is reported in (singh and bandyopadhyay, 2010a) on news domain.
</nextsent>
<nextsent>for this, pos tagging, morphological analysis, ner and chunking are applied on the parallel corpus for phrase level alignment.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4630">
<title id=" W10-3811.xml">manipurienglish bidirectional statistical machine translation systems using morphology and dependency relations </title>
<section> syntactic reordering.  </section>
<citcontext>
<prevsection>
<prevsent>the program for syntactic reordering uses the parse trees generated by stanford parser1 and applies handful of reordering rules written using perl module parse::recdescent.
</prevsent>
<prevsent>by doing this, the svo order of english is changed to sov order for mani puri, and post modifiers are converted to pre-modifiers.
</prevsent>
</prevsection>
<citsent citstr=" D07-1077 ">
the basic difference of mani puri phrase order compared to english is handled by reordering the input sentence following the rule (rao et al, 2000): ssmv vmoomcm ms ms mo mv  where, s: subject o: object : verb cm: clause modifier : corresponding constituent in mani puri, where is s, o, or xm: modifier of there are two reasons why the syntactic reordering approach improves over the baseline phrase-based smt system (wang et al, 2007).<papid> D07-1077 </papid></citsent>
<aftsection>
<nextsent>one obvious benefit is that the word order of the transformed source sentence is much closer to the target sentence, which reduces the reliance on the distortion model to perform reordering during decoding.
</nextsent>
<nextsent>another potential benefit is that the alignment between the two sides will be of higher quality because of fewer distortions?
</nextsent>
<nextsent>between the source and the target, so that the resulting phrase table of the reordered system would be better.
</nextsent>
<nextsent>however, counterargument is that the reordering is very error prone, so that the added noise in the reordered data actually hurts the alignments and hence the phrase tables.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4631">
<title id=" W10-3811.xml">manipurienglish bidirectional statistical machine translation systems using morphology and dependency relations </title>
<section> morphology.  </section>
<citcontext>
<prevsection>
<prevsent>the affixes are the determining factor of the word class in manipuri.
</prevsent>
<prevsent>in this agglutinative language the number of verbal suffixes is more than that of nominal suffixes.
</prevsent>
</prevsection>
<citsent citstr=" I08-3015 ">
works on mani puri morphology are found in (singh and bandyopadhyay, 2006) and (singh and bandyopadhyay, 2008).<papid> I08-3015 </papid></citsent>
<aftsection>
<nextsent>in this language, verb must minimally consist of verb root and an inflectional suffix.
</nextsent>
<nextsent>a noun may be optionally affixed by derivational morphemes indicating gender, number and quantity.
</nextsent>
<nextsent>further, noun may be prefixed by pronominal prefix which indicates its possessor.
</nextsent>
<nextsent>words in mani puri consist of stems or bound roots with suffixes (from one to ten suffixes), prefixes (only one per word) and/or enclitics.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4633">
<title id=" W10-1744.xml">cmu multiengine machine translation for wmt 2010 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>on tuning data, improvement in bleu over the best system depends on the language pair and ranges from 0.89% to 5.57% with mean 2.37%.
</prevsent>
<prevsent>system combination merges the output of several machine translation systems into single improved output.
</prevsent>
</prevsection>
<citsent citstr=" W09-0408 ">
our system combination scheme, submitted to the workshop on statistical machine translation (wmt) 2010 as cmu-heafield-combo, is an improvement over our previous system (heafield et al, 2009), <papid> W09-0408 </papid>called cmu-combo in wmt 2009.</citsent>
<aftsection>
<nextsent>the scheme consists of aligning 1-best outputs from each system using the meteor (denkowski and lavie, 2010) aligner, identifying candidate combinations by forming left-to-right paths through the aligned system outputs, and scoring these candidates using battery of features.
</nextsent>
<nextsent>improvements this year include unigram paraphrase alignment, support forall target languages, new features, language modeling without pruning, and more parameter optimization.
</nextsent>
<nextsent>this paper describes our scheme with emphasis on improved areas.
</nextsent>
<nextsent>confusion networks (rosti et al, 2008) <papid> W08-0329 </papid>are the most popular form of system combination.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4634">
<title id=" W10-1744.xml">cmu multiengine machine translation for wmt 2010 </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>improvements this year include unigram paraphrase alignment, support forall target languages, new features, language modeling without pruning, and more parameter optimization.
</prevsent>
<prevsent>this paper describes our scheme with emphasis on improved areas.
</prevsent>
</prevsection>
<citsent citstr=" W08-0329 ">
confusion networks (rosti et al, 2008) <papid> W08-0329 </papid>are the most popular form of system combination.</citsent>
<aftsection>
<nextsent>in this approach, single system output acts as back bone to which the other outputs are aligned.
</nextsent>
<nextsent>this backbone determines word order while other outputs vote for substitution, deletion, and insertion operations.
</nextsent>
<nextsent>essentially, the backbone is edited to produce combined output which largely preserves word order.
</nextsent>
<nextsent>our approach differs in thatwe allow paths to switch between sentences, effectively permitting the backbone to switch at every word.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4636">
<title id=" W10-1744.xml">cmu multiengine machine translation for wmt 2010 </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>essentially, the backbone is edited to produce combined output which largely preserves word order.
</prevsent>
<prevsent>our approach differs in thatwe allow paths to switch between sentences, effectively permitting the backbone to switch at every word.
</prevsent>
</prevsection>
<citsent citstr=" P08-2021 ">
other system combination techniques typically use ter (snover et al, 2006) or itgs (karakos et al, 2008) <papid> P08-2021 </papid>to align system outputs, meaning they depend solely on positional information to find approximate matches; we explicitly use stem, synonym, and paraphrase data to find alignments.</citsent>
<aftsection>
<nextsent>our use of paraphrases is similar to leusch et al (2009), though they learn monolingual phrase table while we apply cross-lingual pivoting (ban nard and callison-burch, 2005).
</nextsent>
<nextsent>system outputs are aligned at the token level using variant of the meteor (denkowski and lavie, 2010) aligner.
</nextsent>
<nextsent>this identifies, in decreasing order of priority: exact, stem, synonym, and unigram paraphrase matches.
</nextsent>
<nextsent>stems (porter, 2001) are available for all languages except czech, though this is planned for future work and expected to produce significant improvement.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4641">
<title id=" W10-1744.xml">cmu multiengine machine translation for wmt 2010 </title>
<section> scoring features.  </section>
<citcontext>
<prevsection>
<prevsent>we find that both versions have their advantages, and therefore include two sets of match features: one that counts only exact alignments and another that counts all alignments.
</prevsent>
<prevsent>we also tried copies of the match features at the stem and synonym level but found these impose additional tuning cost with no measurable improvement in quality.
</prevsent>
</prevsection>
<citsent citstr=" W09-0406 ">
since systems have different strengths and weaknesses, we avoid assigning single system confidence (rosti et al, 2008) <papid> W08-0329 </papid>or counting n-grammatches with uniform system confidence (hilde brand and vogel, 2009).<papid> W09-0406 </papid></citsent>
<aftsection>
<nextsent>the weight on match feature ms,n corresponds to our confidence in ngrams from system s. these weights are fully tunable.
</nextsent>
<nextsent>however, there is another hyperparameter: the maximum length of n-gram considered; we typically use 2 or 3 with little gain seen above this.
</nextsent>
<nextsent>5.2 language model.
</nextsent>
<nextsent>we built language models for each of the five target languages with the aim of using all constrained data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4642">
<title id=" W10-1744.xml">cmu multiengine machine translation for wmt 2010 </title>
<section> parameter optimization.  </section>
<citcontext>
<prevsection>
<prevsent>this amounts to making the oov probability tunable parameter.
</prevsent>
<prevsent>6.1 feature weights.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
feature weights are tuned using minimum error rate training (mert) (och, 2003) <papid> P03-1021 </papid>on the 455provided references.</citsent>
<aftsection>
<nextsent>our largest submission, xx en primary, combines 17 systems with five match features each plus three other features for total of 88 features.
</nextsent>
<nextsent>this immediately raises two concerns.
</nextsent>
<nextsent>first, there is over fitting and we expect to see loss in the test results, although our experience in the nist open mt evaluation is that the amount of over fitting does not significantly increase at this number of parameters.
</nextsent>
<nextsent>second, mert is poor at fitting this many feature weights.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4643">
<title id=" W10-1744.xml">cmu multiengine machine translation for wmt 2010 </title>
<section> parameter optimization.  </section>
<citcontext>
<prevsection>
<prevsent>we emphasize that the point is to introduce randomness in sentences decoded during mert, and therefore considered during parameter tuning, and not on the specific formula presented in this system description.
</prevsent>
<prevsent>in practice, this technique increases the number of iterations and decreases the difference in tuning scores following mert.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
in our experiments,weights are tuned towards uncased bleu (papineni et al, 2002) <papid> P02-1040 </papid>or the combined metric ter bleu (snover et al, 2006).</citsent>
<aftsection>
<nextsent>6.2 hyperparameters.
</nextsent>
<nextsent>in total, we tried 1167 hyperparameter configurations, limited by cpu time during the evaluationperiod.
</nextsent>
<nextsent>for each of these configurations, the feature weights were fully trained with mert and scored on the same tuning set, which we used to select the submitted combinations.
</nextsent>
<nextsent>because these configurations represent small fraction of the hyperparameter space, we focused on values that work well based on prior experience and tuning scores as they became available:set of systems top systems by bleu.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4646">
<title id=" W10-2419.xml">rule based named entity recognition in urdu </title>
<section> characteristics of urdu.  </section>
<citcontext>
<prevsection>
<prevsent>(that is my laptop).
</prevsent>
<prevsent>in the above example, microsoft word did not support english embedding within the urdu sentence and displayed it improperly.
</prevsent>
</prevsection>
<citsent citstr=" W02-1201 ">
but while electronically processing, the tokenization will be done correctly (becker and riaz, 2002).<papid> W02-1201 </papid></citsent>
<aftsection>
<nextsent>in order to process urdu and other right to left languages unicode encoding and proper font usage is necessary.
</nextsent>
<nextsent>becker and riaz (2002) <papid> W02-1201 </papid>discuss urdu unicode encoding in detail.</nextsent>
<nextsent>named entity recognition was first introduced as part of message understanding conference (muc-6) in 1995 and related conference met 1 in 1996 introduced named entity recognition in non-english text.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4648">
<title id=" W10-1916.xml">semantic role labeling of gene regulation events preliminary results </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>the corpus is divided into two species specific subcorpora: e. coli (167 abstracts, 2394 events) and human (73 abstracts, 673 events).
</prevsent>
<prevsent>we perform two preprocessing steps.
</prevsent>
</prevsection>
<citsent citstr=" D07-1111 ">
first, we extract the text and parse it with the gdepparser (sagae and tsujii, 2007) <papid> D07-1111 </papid>and then we convert the corpus from xml into conll format.</citsent>
<aftsection>
<nextsent>table 1 shows preprocessed sentence.
</nextsent>
<nextsent>the system performs argument identification and semantic role assignment in single step, assuming gold standard event identification.
</nextsent>
<nextsent>it consists of one classifier that classifies an instance into one of the semantic role classes or the none class.
</nextsent>
<nextsent>an instance represents combination of an event and potential argument (pa).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4649">
<title id=" W10-1916.xml">semantic role labeling of gene regulation events preliminary results </title>
<section> preliminary results.  </section>
<citcontext>
<prevsection>
<prevsent>the cv results are obtained by training and testing on different partitions of the same corpus.
</prevsent>
<prevsent>the cd results are obtained by training on one corpus and testing on the other.
</prevsent>
</prevsection>
<citsent citstr=" C08-1096 ">
although we cannot directly compare this results with results of other systems on exactly the same corpus, sasaki et al (2008) <papid> C08-1096 </papid>report cv results on corpus of 677 medline abstracts on e. coli gene regulation events.</citsent>
<aftsection>
<nextsent>the precision achieved by their system is 49.00 and the recall 18.60.
</nextsent>
<nextsent>we consider that the results ofour system are encouraging to proceed with further research.
</nextsent>
<nextsent>corpus precision recall f1 coli cv 59.72 32.29 41.92 coli cd 49.87 18.07 26.53 human cv 47.98 22.43 30.57 human cd 56.57 25.90 35.53 table 2: f1, precision and recall for argument identification and labeling.
</nextsent>
<nextsent>future work will deal with incorporating domain specific knowledge and with improving thema chine learning techniques.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4650">
<title id=" W10-1709.xml">improved features and grammar selection for syntax based mt </title>
<section> system overview.  </section>
<citcontext>
<prevsection>
<prevsent>we built our system on partial selection ofthe provided french english training data, using the europarl, news commentary, and un sets, but ignoring the giga-fren data.
</prevsent>
<prevsent>after tokenization and some pruning of our training data, this left us with corpus of approximately 8.6 million sentence pairs.
</prevsent>
</prevsection>
<citsent citstr=" W08-0509 ">
we word-aligned the corpus with mgiza++ (gao and vogel, 2008), <papid> W08-0509 </papid>multi-threaded implementation of the standard word alignment tool giza++ (och and ney, 2003).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>word alignments were symmetrized withthe grow-diag-final-and?
</nextsent>
<nextsent>heuristic.
</nextsent>
<nextsent>we automatically parsed the french side of the corpus with the berkeley parser (petrov and klein, 2007), <papid> N07-1051 </papid>whilewe used the fast vanilla pcfg model of the stanford parser (klein and manning, 2003) for the english side.</nextsent>
<nextsent>these steps resulted in parallel parsed corpus from which to extract phrase pairs and grammar rules.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4651">
<title id=" W10-1709.xml">improved features and grammar selection for syntax based mt </title>
<section> system overview.  </section>
<citcontext>
<prevsection>
<prevsent>we built our system on partial selection ofthe provided french english training data, using the europarl, news commentary, and un sets, but ignoring the giga-fren data.
</prevsent>
<prevsent>after tokenization and some pruning of our training data, this left us with corpus of approximately 8.6 million sentence pairs.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
we word-aligned the corpus with mgiza++ (gao and vogel, 2008), <papid> W08-0509 </papid>multi-threaded implementation of the standard word alignment tool giza++ (och and ney, 2003).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>word alignments were symmetrized withthe grow-diag-final-and?
</nextsent>
<nextsent>heuristic.
</nextsent>
<nextsent>we automatically parsed the french side of the corpus with the berkeley parser (petrov and klein, 2007), <papid> N07-1051 </papid>whilewe used the fast vanilla pcfg model of the stanford parser (klein and manning, 2003) for the english side.</nextsent>
<nextsent>these steps resulted in parallel parsed corpus from which to extract phrase pairs and grammar rules.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4652">
<title id=" W10-1709.xml">improved features and grammar selection for syntax based mt </title>
<section> system overview.  </section>
<citcontext>
<prevsection>
<prevsent>word alignments were symmetrized withthe grow-diag-final-and?
</prevsent>
<prevsent>heuristic.
</prevsent>
</prevsection>
<citsent citstr=" N07-1051 ">
we automatically parsed the french side of the corpus with the berkeley parser (petrov and klein, 2007), <papid> N07-1051 </papid>whilewe used the fast vanilla pcfg model of the stanford parser (klein and manning, 2003) for the english side.</citsent>
<aftsection>
<nextsent>these steps resulted in parallel parsed corpus from which to extract phrase pairs and grammar rules.
</nextsent>
<nextsent>phrase extraction involves three distinct steps.
</nextsent>
<nextsent>in the first, we perform standard (non-syntactic) phrase extraction according to the heuristics of phrase-based smt (koehn et al, 2003).<papid> N03-1017 </papid></nextsent>
<nextsent>in the second, we obtain syntactic phrase pairs using the tree-to-tree matching method of lavie et al(2008).<papid> W08-0411 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4653">
<title id=" W10-1709.xml">improved features and grammar selection for syntax based mt </title>
<section> system overview.  </section>
<citcontext>
<prevsection>
<prevsent>these steps resulted in parallel parsed corpus from which to extract phrase pairs and grammar rules.
</prevsent>
<prevsent>phrase extraction involves three distinct steps.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
in the first, we perform standard (non-syntactic) phrase extraction according to the heuristics of phrase-based smt (koehn et al, 2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>in the second, we obtain syntactic phrase pairs using the tree-to-tree matching method of lavie et al(2008).<papid> W08-0411 </papid></nextsent>
<nextsent>briefly, this method aligns nodes in parallel parse trees by projecting up from the word alignments.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4654">
<title id=" W10-1709.xml">improved features and grammar selection for syntax based mt </title>
<section> system overview.  </section>
<citcontext>
<prevsection>
<prevsent>phrase extraction involves three distinct steps.
</prevsent>
<prevsent>in the first, we perform standard (non-syntactic) phrase extraction according to the heuristics of phrase-based smt (koehn et al, 2003).<papid> N03-1017 </papid></prevsent>
</prevsection>
<citsent citstr=" W08-0411 ">
in the second, we obtain syntactic phrase pairs using the tree-to-tree matching method of lavie et al(2008).<papid> W08-0411 </papid></citsent>
<aftsection>
<nextsent>briefly, this method aligns nodes in parallel parse trees by projecting up from the word alignments.
</nextsent>
<nextsent>a source-tree node will be aligned to target-tree node if the word alignments in the yield of all land within the yield of t, and vice versa.
</nextsent>
<nextsent>this node alignment is similar in spirit to the subtree alignment method of zhechev and way(2008), <papid> C08-1139 </papid>except our method is based on the specific viterbi word alignment links found for each 82sentence rather than on the general word translation probabilities computed for the corpus as whole.</nextsent>
<nextsent>this enables us to use efficient dynamic programming to infer node alignments, rather than resorting to greedy search or the enumeration of all possible alignments.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4655">
<title id=" W10-1709.xml">improved features and grammar selection for syntax based mt </title>
<section> system overview.  </section>
<citcontext>
<prevsection>
<prevsent>briefly, this method aligns nodes in parallel parse trees by projecting up from the word alignments.
</prevsent>
<prevsent>a source-tree node will be aligned to target-tree node if the word alignments in the yield of all land within the yield of t, and vice versa.
</prevsent>
</prevsection>
<citsent citstr=" C08-1139 ">
this node alignment is similar in spirit to the subtree alignment method of zhechev and way(2008), <papid> C08-1139 </papid>except our method is based on the specific viterbi word alignment links found for each 82sentence rather than on the general word translation probabilities computed for the corpus as whole.</citsent>
<aftsection>
<nextsent>this enables us to use efficient dynamic programming to infer node alignments, rather than resorting to greedy search or the enumeration of all possible alignments.
</nextsent>
<nextsent>finally, in the third step, we use the node alignments from syntactic phrase pair extraction to extract grammar rules.
</nextsent>
<nextsent>each aligned node in tree pair specifies decomposition point for breaking the parallel trees into series of scfg rules.
</nextsent>
<nextsent>like galley et al (2006), <papid> P06-1121 </papid>we allow composed?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4656">
<title id=" W10-1709.xml">improved features and grammar selection for syntax based mt </title>
<section> system overview.  </section>
<citcontext>
<prevsection>
<prevsent>finally, in the third step, we use the node alignments from syntactic phrase pair extraction to extract grammar rules.
</prevsent>
<prevsent>each aligned node in tree pair specifies decomposition point for breaking the parallel trees into series of scfg rules.
</prevsent>
</prevsection>
<citsent citstr=" P06-1121 ">
like galley et al (2006), <papid> P06-1121 </papid>we allow composed?</citsent>
<aftsection>
<nextsent>(non-minimal) rules when they build entirely on lexical items.
</nextsent>
<nextsent>however, to control the size of the grammar, we do not produce composed rules that build on other non-terminals, nor do we produce multiple possible rules whenwe encounter unaligned words.
</nextsent>
<nextsent>another difference is that we discard internal structure of composed lexical rules so that we produce scfg rules rather than synchronous tree substitution grammar rules.
</nextsent>
<nextsent>the extracted phrase pairs and grammar rules are collected together and scored according to avariety of features (section 3).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4657">
<title id=" W10-1709.xml">improved features and grammar selection for syntax based mt </title>
<section> system overview.  </section>
<citcontext>
<prevsection>
<prevsent>the extracted phrase pairs and grammar rules are collected together and scored according to avariety of features (section 3).
</prevsent>
<prevsent>instead of decoding with the very large complete set of extracted grammar rules, we select only small number of rules meeting certain criteria (section 4).
</prevsent>
</prevsection>
<citsent citstr=" W09-0424 ">
in contrast to previous years, when we used the stat-xfer decoder, this year we switched to thethe joshua decoder (li et al, 2009) <papid> W09-0424 </papid>to take advantage of its more efficient architecture and implementation of modern decoding techniques, such ascube pruning and multi-threading.</citsent>
<aftsection>
<nextsent>we also managed system-building work flows with loony bin (clark and lavie, 2010), toolkit for managing multi-step experiments across different servers or computing clusters.
</nextsent>
<nextsent>section 5 details our experimental results.
</nextsent>
<nextsent>one major improvement in our system this year is the feature scores we applied to our grammar and phrase pairs.
</nextsent>
<nextsent>inspired largely by the syntax augmented mt system (zollmann and venugopal, 2006), <papid> W06-3119 </papid>our translation model contains 22features in addition to the language model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4658">
<title id=" W10-1709.xml">improved features and grammar selection for syntax based mt </title>
<section> translation model construction.  </section>
<citcontext>
<prevsection>
<prevsent>section 5 details our experimental results.
</prevsent>
<prevsent>one major improvement in our system this year is the feature scores we applied to our grammar and phrase pairs.
</prevsent>
</prevsection>
<citsent citstr=" W06-3119 ">
inspired largely by the syntax augmented mt system (zollmann and venugopal, 2006), <papid> W06-3119 </papid>our translation model contains 22features in addition to the language model.</citsent>
<aftsection>
<nextsent>in contrast to earlier formulations of our features (han neman and lavie, 2009), <papid> W09-2301 </papid>our maximum-likelihoodfeatures are now based on strict separation between counts drawn from non-syntactic phrase extraction heuristics and our syntactic rule extractor; no feature is estimated from counts in both spaces.we define an aggregate rule instance as 5 tuple = (l,s, t,cphr, csyn) that contains left-hand-side label l, sequence of terminals and non-terminals for the source (s) and target (t ) right-hand sides, and aggregated counts from phrase-based smt extraction heuristics cphr and the syntactic rule extractor csyn.</nextsent>
<nextsent>in preparation for feature scoring, we: 1.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4659">
<title id=" W10-1709.xml">improved features and grammar selection for syntax based mt </title>
<section> translation model construction.  </section>
<citcontext>
<prevsection>
<prevsent>one major improvement in our system this year is the feature scores we applied to our grammar and phrase pairs.
</prevsent>
<prevsent>inspired largely by the syntax augmented mt system (zollmann and venugopal, 2006), <papid> W06-3119 </papid>our translation model contains 22features in addition to the language model.</prevsent>
</prevsection>
<citsent citstr=" W09-2301 ">
in contrast to earlier formulations of our features (han neman and lavie, 2009), <papid> W09-2301 </papid>our maximum-likelihoodfeatures are now based on strict separation between counts drawn from non-syntactic phrase extraction heuristics and our syntactic rule extractor; no feature is estimated from counts in both spaces.we define an aggregate rule instance as 5 tuple = (l,s, t,cphr, csyn) that contains left-hand-side label l, sequence of terminals and non-terminals for the source (s) and target (t ) right-hand sides, and aggregated counts from phrase-based smt extraction heuristics cphr and the syntactic rule extractor csyn.</citsent>
<aftsection>
<nextsent>in preparation for feature scoring, we: 1.
</nextsent>
<nextsent>run phrase instance extraction using stan-.
</nextsent>
<nextsent>dard phrase-based smt heuristics to obtain tuples (phr, s, t,cphr, ?) where and never contain non-terminals 2.
</nextsent>
<nextsent>run syntactic rule instance extraction as de-.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4660">
<title id=" W10-1709.xml">improved features and grammar selection for syntax based mt </title>
<section> grammar selection.  </section>
<citcontext>
<prevsection>
<prevsent>in the joshua decoder, these monotonic rules stitch syntactic parse fragments together at no model cost.
</prevsent>
<prevsent>with extracted grammars typically reaching tens of millions of unique rules ? not to mention phrase pairs ? our systems clearly face an engineering challenge when attempting to include the full grammar at decoding time.
</prevsent>
</prevsection>
<citsent citstr=" E09-1044 ">
iglesias et al(2009) <papid> E09-1044 </papid>classified scfg rules according to the pattern of terminals and non-terminals on the rules?</citsent>
<aftsection>
<nextsent>right-hand sides, and found that certain patterns could be entirely left out of the grammar without loss of mt quality.
</nextsent>
<nextsent>in particular, large classes of monotonic rules could be removed without loss in automatic metric scores, while small classes of reordering rules contributed much more to the success of the system.
</nextsent>
<nextsent>inspired by that approach, we passed our full set of extracted grammar rule instances through filter after scoring.
</nextsent>
<nextsent>using the rule notation from section 3, the filter retained only those rules that matched one of the following patterns: = x1 w, = x1 = x1, = x1 s = x1 x2, = x2 x1 = x1 x2, = x1 x2where represents any non-terminal and represents any span of one or more terminals.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4661">
<title id=" W10-1709.xml">improved features and grammar selection for syntax based mt </title>
<section> results and analysis.  </section>
<citcontext>
<prevsection>
<prevsent>in all cases of grammar selection, we disallowed rules that inserted unaligned target-side terminals unless the inserted terminals were among the top 100 most frequent unigrams in the target-side vocabulary.
</prevsent>
<prevsent>5.1 comparison with wmt 2009 results.
</prevsent>
</prevsection>
<citsent citstr=" W09-0425 ">
we performed our initial development work onan updated version of our previous wmt submission (hanneman et al, 2009) <papid> W09-0425 </papid>so that the effects of our changes could be directly compared.our 2009 system was trained from the full eu roparl and news commentary data available that year, plus the pre-release version of the giga-fren data, for total of 9.4 million sentence pairs.</citsent>
<aftsection>
<nextsent>weused the news-dev2009a set for minimum error rate training and tested system performance on news-dev2009b.
</nextsent>
<nextsent>to maintain continuity with our previously reported scores, we report new score shere using the same training, tuning, and testing sets, using the uncased versions of ibm-style 84 system configuration meteor bleu 1.
</nextsent>
<nextsent>wmt 09 submission 0.5263 0.2073.
</nextsent>
<nextsent>2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4662">
<title id=" W10-1709.xml">improved features and grammar selection for syntax based mt </title>
<section> results and analysis.  </section>
<citcontext>
<prevsection>
<prevsent>n = 10,000 0.5332 0.2198 6.
</prevsent>
<prevsent>n = 10,000, filtered 0.5350 0.2250 table 2: dev test results (on news-dev2009b) fromour wmt 2009 system with and without pattern based grammar selection.
</prevsent>
</prevsection>
<citsent citstr=" W07-0734 ">
bleu 1.04 (papineni et al, 2002) and meteor 0.6 (lavie and agarwal, 2007).<papid> W07-0734 </papid></citsent>
<aftsection>
<nextsent>table 1 shows the effect of our new scoring and decoding environment.
</nextsent>
<nextsent>line 2 uses the same extracted phrase pairs and grammar rules as line 1, but the system is tuned and tested with the joshua decoder instead of stat-xfer.
</nextsent>
<nextsent>for line 3, we rescored the extracted phrase pairs from lines 1 and2 using the updated features discussed in section 3.1 the difference in automatic metric scores shows significant benefit from both the new decoder and the updated feature formulations: 0.8 bleu points from the change in decoder, and 0.9bleu points from the expanded set of 22 translation model features.
</nextsent>
<nextsent>our next test was to examine the usefulness of the pattern-based grammar selection described in section 4.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4663">
<title id=" W10-3103.xml">towards a better understanding of uncertainties and speculations in swedish clinical text x2013 analysis of an initial annotation trial </title>
<section> related research.  </section>
<citcontext>
<prevsection>
<prevsent>three annotators annotated the corpus, and the guidelines were modified several times during the annotation process, in order to resolve problematic issues and refine definitions.
</prevsent>
<prevsent>the iaa results, measured with 1 -score, in the clinical sub-corpus for negation keywords ranged between0.91 and 0.96, and for speculative keywords between 0.84 and 0.92.
</prevsent>
</prevsection>
<citsent citstr=" W09-1304 ">
the bio scope corpus hasbeen used to train and evaluate automatic classifiers (e.g. ? ozgur and radev (2009) and morante and daelemans (2009)) <papid> W09-1304 </papid>with promising results.</citsent>
<aftsection>
<nextsent>five qualitative dimensions for characterizing scientific sentences are defined in wilbur et al(2006), including levels of certainty.
</nextsent>
<nextsent>here, guidelines are also developed over long period of time(more than year), testing and revising the guidelines consecutively.
</nextsent>
<nextsent>their final iaa results, measured with 1 -score, range between 0.70 and 0.80.
</nextsent>
<nextsent>different levels of dimensionality for categorizing certainty (in newspaper articles) is also presented in rubin et al (2006).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4665">
<title id=" W10-2919.xml">a hybrid approach to emotional sentence polarity and intensity classification </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>companies and organizations are interested in finding out costumer sentiments and opinions, while individuals are interested in others?
</prevsent>
<prevsent>opinions when purchasing product or deciding whether or not watching movie.
</prevsent>
</prevsection>
<citsent citstr=" W02-1011 ">
many approaches have dealt with sentiment analysis as the problem of classifying product or service reviews (pang et al, 2002; <papid> W02-1011 </papid>turney, 2002), <papid> P02-1053 </papid>while others have attempted to classify news items (devitt and ahmad, 2007).<papid> P07-1124 </papid></citsent>
<aftsection>
<nextsent>the task is usually addressed as 2-classes classification problem (positive vs. negative).
</nextsent>
<nextsent>recent works have included the neutral class, trying to detect not only the polarity but also the absence of emotional meaning (wilson et al, 2005; <papid> H05-1044 </papid>esuli and sebastiani, 2006).<papid> E06-1025 </papid></nextsent>
<nextsent>however, few approaches try to face more fine-grained prediction of the intensity (e.g. classifying the polarity into strongly negative, weakly negative, neutral, weakly positive and strongly positive).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4666">
<title id=" W10-2919.xml">a hybrid approach to emotional sentence polarity and intensity classification </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>companies and organizations are interested in finding out costumer sentiments and opinions, while individuals are interested in others?
</prevsent>
<prevsent>opinions when purchasing product or deciding whether or not watching movie.
</prevsent>
</prevsection>
<citsent citstr=" P02-1053 ">
many approaches have dealt with sentiment analysis as the problem of classifying product or service reviews (pang et al, 2002; <papid> W02-1011 </papid>turney, 2002), <papid> P02-1053 </papid>while others have attempted to classify news items (devitt and ahmad, 2007).<papid> P07-1124 </papid></citsent>
<aftsection>
<nextsent>the task is usually addressed as 2-classes classification problem (positive vs. negative).
</nextsent>
<nextsent>recent works have included the neutral class, trying to detect not only the polarity but also the absence of emotional meaning (wilson et al, 2005; <papid> H05-1044 </papid>esuli and sebastiani, 2006).<papid> E06-1025 </papid></nextsent>
<nextsent>however, few approaches try to face more fine-grained prediction of the intensity (e.g. classifying the polarity into strongly negative, weakly negative, neutral, weakly positive and strongly positive).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4667">
<title id=" W10-2919.xml">a hybrid approach to emotional sentence polarity and intensity classification </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>companies and organizations are interested in finding out costumer sentiments and opinions, while individuals are interested in others?
</prevsent>
<prevsent>opinions when purchasing product or deciding whether or not watching movie.
</prevsent>
</prevsection>
<citsent citstr=" P07-1124 ">
many approaches have dealt with sentiment analysis as the problem of classifying product or service reviews (pang et al, 2002; <papid> W02-1011 </papid>turney, 2002), <papid> P02-1053 </papid>while others have attempted to classify news items (devitt and ahmad, 2007).<papid> P07-1124 </papid></citsent>
<aftsection>
<nextsent>the task is usually addressed as 2-classes classification problem (positive vs. negative).
</nextsent>
<nextsent>recent works have included the neutral class, trying to detect not only the polarity but also the absence of emotional meaning (wilson et al, 2005; <papid> H05-1044 </papid>esuli and sebastiani, 2006).<papid> E06-1025 </papid></nextsent>
<nextsent>however, few approaches try to face more fine-grained prediction of the intensity (e.g. classifying the polarity into strongly negative, weakly negative, neutral, weakly positive and strongly positive).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4668">
<title id=" W10-2919.xml">a hybrid approach to emotional sentence polarity and intensity classification </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>many approaches have dealt with sentiment analysis as the problem of classifying product or service reviews (pang et al, 2002; <papid> W02-1011 </papid>turney, 2002), <papid> P02-1053 </papid>while others have attempted to classify news items (devitt and ahmad, 2007).<papid> P07-1124 </papid></prevsent>
<prevsent>the task is usually addressed as 2-classes classification problem (positive vs. negative).</prevsent>
</prevsection>
<citsent citstr=" H05-1044 ">
recent works have included the neutral class, trying to detect not only the polarity but also the absence of emotional meaning (wilson et al, 2005; <papid> H05-1044 </papid>esuli and sebastiani, 2006).<papid> E06-1025 </papid></citsent>
<aftsection>
<nextsent>however, few approaches try to face more fine-grained prediction of the intensity (e.g. classifying the polarity into strongly negative, weakly negative, neutral, weakly positive and strongly positive).
</nextsent>
<nextsent>another important problem of most of these approximations is that they usually work with terms, and so disregard the contextual meaning of those terms in the sentence (martineau and finin, 2009; moilanen and pulman, 2007).
</nextsent>
<nextsent>the use of word disambiguation is not usual in this task, due to the fact that most approaches use lexical resources created to work with terms.
</nextsent>
<nextsent>however, it is essential to correctly capture the meaning of these terms within the text.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4669">
<title id=" W10-2919.xml">a hybrid approach to emotional sentence polarity and intensity classification </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>many approaches have dealt with sentiment analysis as the problem of classifying product or service reviews (pang et al, 2002; <papid> W02-1011 </papid>turney, 2002), <papid> P02-1053 </papid>while others have attempted to classify news items (devitt and ahmad, 2007).<papid> P07-1124 </papid></prevsent>
<prevsent>the task is usually addressed as 2-classes classification problem (positive vs. negative).</prevsent>
</prevsection>
<citsent citstr=" E06-1025 ">
recent works have included the neutral class, trying to detect not only the polarity but also the absence of emotional meaning (wilson et al, 2005; <papid> H05-1044 </papid>esuli and sebastiani, 2006).<papid> E06-1025 </papid></citsent>
<aftsection>
<nextsent>however, few approaches try to face more fine-grained prediction of the intensity (e.g. classifying the polarity into strongly negative, weakly negative, neutral, weakly positive and strongly positive).
</nextsent>
<nextsent>another important problem of most of these approximations is that they usually work with terms, and so disregard the contextual meaning of those terms in the sentence (martineau and finin, 2009; moilanen and pulman, 2007).
</nextsent>
<nextsent>the use of word disambiguation is not usual in this task, due to the fact that most approaches use lexical resources created to work with terms.
</nextsent>
<nextsent>however, it is essential to correctly capture the meaning of these terms within the text.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4672">
<title id=" W10-2919.xml">a hybrid approach to emotional sentence polarity and intensity classification </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>which are combined with bags of word features to automatically classify movie reviews.
</prevsent>
<prevsent>to this aim, they use semi-automated method to generate lexicon of appraising adjectives and modifiers.
</prevsent>
</prevsection>
<citsent citstr=" P99-1032 ">
during the past few years, the problem of polarity recognition has been usually faced as step beyond the identification of the subjectivity or objectivity of texts (wiebe et al, 1999).<papid> P99-1032 </papid></citsent>
<aftsection>
<nextsent>different approximations have been proposed to deal with this problem.
</nextsent>
<nextsent>pang and lee (2004) <papid> P04-1035 </papid>propose graph-based method which finds minimum cuts in document graph to classify the sentences into subjective or objective.</nextsent>
<nextsent>after that, they use bag of words approximation to classify the subjective sentences into positive or negative.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4673">
<title id=" W10-2919.xml">a hybrid approach to emotional sentence polarity and intensity classification </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>during the past few years, the problem of polarity recognition has been usually faced as step beyond the identification of the subjectivity or objectivity of texts (wiebe et al, 1999).<papid> P99-1032 </papid></prevsent>
<prevsent>different approximations have been proposed to deal with this problem.</prevsent>
</prevsection>
<citsent citstr=" P04-1035 ">
pang and lee (2004) <papid> P04-1035 </papid>propose graph-based method which finds minimum cuts in document graph to classify the sentences into subjective or objective.</citsent>
<aftsection>
<nextsent>after that, they use bag of words approximation to classify the subjective sentences into positive or negative.
</nextsent>
<nextsent>kim and hovy (2004) <papid> C04-1200 </papid>also introduce previous step to identify the subjectivity of sentences regarding certain topic, and later classify these sentences into positives or negatives.</nextsent>
<nextsent>most recent approaches do not only deal with the 2-classes classification problem, but also introduce new class representing neutrality.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4674">
<title id=" W10-2919.xml">a hybrid approach to emotional sentence polarity and intensity classification </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>pang and lee (2004) <papid> P04-1035 </papid>propose graph-based method which finds minimum cuts in document graph to classify the sentences into subjective or objective.</prevsent>
<prevsent>after that, they use bag of words approximation to classify the subjective sentences into positive or negative.</prevsent>
</prevsection>
<citsent citstr=" C04-1200 ">
kim and hovy (2004) <papid> C04-1200 </papid>also introduce previous step to identify the subjectivity of sentences regarding certain topic, and later classify these sentences into positives or negatives.</citsent>
<aftsection>
<nextsent>most recent approaches do not only deal with the 2-classes classification problem, but also introduce new class representing neutrality.
</nextsent>
<nextsent>thus, the aim of these works is to classify the text into positive, negative or neutral.
</nextsent>
<nextsent>wilson et al (2005) <papid> H05-1044 </papid>present double subjectivity classifier based on features such as syntactic classes and sentence position, and more semantic features such as adjective graduation.</nextsent>
<nextsent>the first classifier determines the subjectivity or neutrality of the phrases in the text, while the second determines its polarity (in cluding neutrality).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4677">
<title id=" W10-2919.xml">a hybrid approach to emotional sentence polarity and intensity classification </title>
<section> the method.  </section>
<citcontext>
<prevsection>
<prevsent>to this aim, the system analyzes the text, splits it into sentences and tags the tokens with their part of speech.
</prevsent>
<prevsent>the gate architecture3 and the stanford parser4 once the sentences have been split and tagged, the method maps each word of each sentence into its sense in wordnet according to its context.
</prevsent>
</prevsection>
<citsent citstr=" P05-3019 ">
to this end, the lesk wsd algorithm implemented in the wordnet sense-relate perl package is used (patwardhan et al, 2005).<papid> P05-3019 </papid></citsent>
<aftsection>
<nextsent>the disambiguation is carried out only over the words belonging to the grammatical categories noun, verb, adjective and adverb, as only these categories can present an emotional meaning.
</nextsent>
<nextsent>as result, we get the stem and sense in wordnet of each word, and this information is used to retrieve its synset.
</nextsent>
<nextsent>were selected to carry out this process.
</nextsent>
<nextsent>in particular the annie english tokeniser, hash gaz etter, regex sentence splitter and the stanford parser modules in gate are used to analyze the input.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4678">
<title id=" W10-2919.xml">a hybrid approach to emotional sentence polarity and intensity classification </title>
<section> the method.  </section>
<citcontext>
<prevsection>
<prevsent>4.3 post-processing: negation and quantifi-.
</prevsent>
<prevsent>ers detection once the concepts of the sentence have been labeled with their emotional categories, the next step aims to detect and solve the effect of the neg ations and the quantifiers on the emotional categories identified in the previous step.
</prevsent>
</prevsection>
<citsent citstr=" W09-1105 ">
the effect of negation has been broadly studied in nlp (morante and daelemans, 2009) <papid> W09-1105 </papid>and sentiment analysis (jia et al, 2009).</citsent>
<aftsection>
<nextsent>two main considerations must be taken into account when dealing with negation.
</nextsent>
<nextsent>first, the negation scope may affect only word (no reason), proposition (beckham does not want to play again for real) or even subject (no one would like to do 156this).
</nextsent>
<nextsent>different approximations have been proposed to delimit the scope of negation.
</nextsent>
<nextsent>some assume the scope to be those words between the negation token and the first punctuation mark (pang et al, 2002), <papid> W02-1011 </papid>others consider fixed number of words after the negation token (hu and liu, 2004).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4682">
<title id=" W10-2919.xml">a hybrid approach to emotional sentence polarity and intensity classification </title>
<section> evaluation framework and results.  </section>
<citcontext>
<prevsection>
<prevsent>regarding the 5-classes distribution evaluation, to the authors?
</prevsent>
<prevsent>knowledge no other work has been evaluated under these conditions.
</prevsent>
</prevsection>
<citsent citstr=" W07-2094 ">
how ever, our system reports promising results: using 5 classes it achieves better results than other participant in the semeval task using just 3 classes (chaumartin, 2007; <papid> W07-2094 </papid>katz et al, 2007).<papid> W07-2067 </papid></citsent>
<aftsection>
<nextsent>5.3 evaluating the effect of word ambiguity.
</nextsent>
<nextsent>on sentiment analysis further test has been conducted to examine the effect of word ambiguity on the classification results.
</nextsent>
<nextsent>to this aim, we repeated the experiments above without using wsd.
</nextsent>
<nextsent>first, we simply assigned to each word its first sense in wordnet.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4683">
<title id=" W10-2919.xml">a hybrid approach to emotional sentence polarity and intensity classification </title>
<section> evaluation framework and results.  </section>
<citcontext>
<prevsection>
<prevsent>regarding the 5-classes distribution evaluation, to the authors?
</prevsent>
<prevsent>knowledge no other work has been evaluated under these conditions.
</prevsent>
</prevsection>
<citsent citstr=" W07-2067 ">
how ever, our system reports promising results: using 5 classes it achieves better results than other participant in the semeval task using just 3 classes (chaumartin, 2007; <papid> W07-2094 </papid>katz et al, 2007).<papid> W07-2067 </papid></citsent>
<aftsection>
<nextsent>5.3 evaluating the effect of word ambiguity.
</nextsent>
<nextsent>on sentiment analysis further test has been conducted to examine the effect of word ambiguity on the classification results.
</nextsent>
<nextsent>to this aim, we repeated the experiments above without using wsd.
</nextsent>
<nextsent>first, we simply assigned to each word its first sense in wordnet.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4684">
<title id=" W10-3217.xml">a supervised learning based chunking in thai using categorial grammar </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>lafferty (2001) proposed conditional random fields for sequence labeling.
</prevsent>
<prevsent>crf can be recognized as generative model that is able to reach global optimum while other sequential classifiers focus on making the best local decision.
</prevsent>
</prevsection>
<citsent citstr=" N03-1028 ">
sha and pereira (2003) <papid> N03-1028 </papid>compared crf to other supervised learning in conll task.</citsent>
<aftsection>
<nextsent>they achieved results better than other approaches.
</nextsent>
<nextsent>molina et al (2002) improved the accuracy of hmm-based shallow parser by introducing the specialized hmms.
</nextsent>
<nextsent>in thai language processing, many researches focus on fundamental level of nlp, such as word segmentation, pos tagging.
</nextsent>
<nextsent>for example, kruengkrai et al (2006) introduced crf for word segmentation and pos tagging trained over orchid corpus (sornlertlamvanich et al, 1998.).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4686">
<title id=" W10-3302.xml">using goitaikei as an upper ontology to build a largescale japanese ontology from wikipedia </title>
<section> ontology building method.  </section>
<citcontext>
<prevsection>
<prevsent>the hypernym of the category name is extracted from the definition sentence if it exists.
</prevsent>
<prevsent>if there is an article whose title is the same as its category, the hypernym of the article is used as that of the category.
</prevsent>
</prevsection>
<citsent citstr=" L08-1309 ">
as for lexico-syntactic patterns, we used almost the same patterns described in previous work related to japanese such as (kobayashi et al, 2008; sumida et al, 2008), <papid> L08-1309 </papid>which is basically equivalent to work related to english such as (hearst, 1992).<papid> C92-2082 </papid></citsent>
<aftsection>
<nextsent>here are some examples.
</nextsent>
<nextsent>[hypernym]  (  |  |  |.
</nextsent>
<nextsent>) (one|kind|name|.
</nextsent>
<nextsent>) of [hypernym] [hypernym](  |  [ |.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4687">
<title id=" W10-3302.xml">using goitaikei as an upper ontology to build a largescale japanese ontology from wikipedia </title>
<section> ontology building method.  </section>
<citcontext>
<prevsection>
<prevsent>the hypernym of the category name is extracted from the definition sentence if it exists.
</prevsent>
<prevsent>if there is an article whose title is the same as its category, the hypernym of the article is used as that of the category.
</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
as for lexico-syntactic patterns, we used almost the same patterns described in previous work related to japanese such as (kobayashi et al, 2008; sumida et al, 2008), <papid> L08-1309 </papid>which is basically equivalent to work related to english such as (hearst, 1992).<papid> C92-2082 </papid></citsent>
<aftsection>
<nextsent>here are some examples.
</nextsent>
<nextsent>[hypernym]  (  |  |  |.
</nextsent>
<nextsent>) (one|kind|name|.
</nextsent>
<nextsent>) of [hypernym] [hypernym](  |  [ |.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4688">
<title id=" W10-3302.xml">using goitaikei as an upper ontology to build a largescale japanese ontology from wikipedia </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>unlike previous methods, it can create single connected taxonomy with well-defined upper level taxonomy inherited from goi-taikei, as well as fined grained and up-to-date lower level taxonomy with broad-coverage extracted from wikipedia.
</prevsent>
<prevsent>future work will include automatic category alignment between goi-taikei and wikipedia to fully automate the ontology building.
</prevsent>
</prevsection>
<citsent citstr=" L08-1077 ">
it would be interesting to use another japanese thesaurus, such as the recently released japanese wordnet (bond et al, 2008), <papid> L08-1077 </papid>as an upper ontology for the proposed method.</citsent>
<aftsection>
<nextsent>one of the problems with the proposed method is that it only uses about half of the knowledge(categories and articles) in wikipedia.
</nextsent>
<nextsent>this is because we restricted the alignment points in goi taikei category hierarchy to its leaves.
</nextsent>
<nextsent>in ponzetto and navigli (2009), they present method for aligning wordnet and wikipedia fully at many levels with both of them retaining hierarchalstructure.
</nextsent>
<nextsent>however, their method does not integrate the two hierarchies into single taxonomy.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4689">
<title id=" W10-2202.xml">verifying vowel harmony typologies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these rich representations pose unique opportunity to integrate theoretical and computational methodologies.
</prevsent>
<prevsent>specifically, we capture these rich representations through the contenders algorithm (riggle, 2004b).
</prevsent>
</prevsection>
<citsent citstr=" J94-1003 ">
further, vowel harmony is an important area of research in computational phonology (bird &ellison;, 1994; <papid> J94-1003 </papid>ellison, 1992; goldsmith &amp; xanthos, 2009) because the representation of agreement between vowels across consonants poses unique challenges to the learner.</citsent>
<aftsection>
<nextsent>this paper differs from previous computational models of vowel harmony because the present work is aninstantiation of generative ot model.
</nextsent>
<nextsent>the present work focuses on framing work done in theoretical linguistics in computational framework.
</nextsent>
<nextsent>the paper begins with brief overview of the contenders algorithm (section 2).
</nextsent>
<nextsent>this is followed by description of turbid spreading and its formalization in finite-state representations (section 3).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4691">
<title id=" W10-2202.xml">verifying vowel harmony typologies </title>
<section> turbid spreading.  </section>
<citcontext>
<prevsection>
<prevsent>6 in addition to *cc, other constraints such as *#c or *c#may trigger epenthesis.
</prevsent>
<prevsent>for simplicity, these additional constraints are not included in the present analysis.
</prevsent>
</prevsection>
<citsent citstr=" C00-1038 ">
14 figure 8: *cc violations for both spreading constraints are assigned directionally such that violation on the first vowel is more severe than violations later inthe word (eisner, 2000), <papid> C00-1038 </papid>formalized in simplified version where violations at different parts of the word are greater than other parts of the word.</citsent>
<aftsection>
<nextsent>in order to prevent gang?
</nextsent>
<nextsent>effects, violations are assigned exponentially such that for three vowel input, violation on the second vowel incurs 100 violations, while violation on the third vowel incurs only 10 violations.
</nextsent>
<nextsent>this simplified version of directional evaluation only allows for finite number of vowels in the input.
</nextsent>
<nextsent>however, because the theory is tested with inputs of 3 and 4 vowels in length, these simplified transducers capture the data analyzed here.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4692">
<title id=" W10-3002.xml">a cascade method for detecting hedges and their scope in natural language text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as vincze et al (2008) suggest that information that falls in the scopeof hedges can not be presented as factual information.
</prevsent>
<prevsent>detecting hedges and their scope in natural language text is very important for information inference.
</prevsent>
</prevsection>
<citsent citstr=" W09-1304 ">
recently, relative research has received considerable interest in the biomedical nlp community, including detecting hedges and their in-sentence scope in biomedical texts(morante and daelemans, 2009).<papid> W09-1304 </papid></citsent>
<aftsection>
<nextsent>the conll 2010 has launched shared task for exploiting the hedge scope annotated in the bio scope (vincze etal., 2008) and publicly available wikipedia (gan ter and strube, 2009) <papid> P09-2044 </papid>weasel annotations.</nextsent>
<nextsent>the shared task contains two subtasks (farkas et al, 2010): 1.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4693">
<title id=" W10-3002.xml">a cascade method for detecting hedges and their scope in natural language text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>detecting hedges and their scope in natural language text is very important for information inference.
</prevsent>
<prevsent>recently, relative research has received considerable interest in the biomedical nlp community, including detecting hedges and their in-sentence scope in biomedical texts(morante and daelemans, 2009).<papid> W09-1304 </papid></prevsent>
</prevsection>
<citsent citstr=" P09-2044 ">
the conll 2010 has launched shared task for exploiting the hedge scope annotated in the bio scope (vincze etal., 2008) and publicly available wikipedia (gan ter and strube, 2009) <papid> P09-2044 </papid>weasel annotations.</citsent>
<aftsection>
<nextsent>the shared task contains two subtasks (farkas et al, 2010): 1.
</nextsent>
<nextsent>learning to detect hedges in sentences on bio scope and wikipedia; 2.
</nextsent>
<nextsent>learning to detect the in-sentence scope of these hedges on bioscope.
</nextsent>
<nextsent>in this paper, we present system based on cascade method for the conll-2010 shared task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4694">
<title id=" W10-3002.xml">a cascade method for detecting hedges and their scope in natural language text </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>thena two-layer cascaded classifier is built for prediction.
</prevsent>
<prevsent>there are crf classifier and large margin-based classifier in the first layer and crf classifier in the second layer.
</prevsent>
</prevsection>
<citsent citstr=" I05-2046 ">
in the first layer, the following features are used in our system: ? word andword shape of the lemma: we used the similar scheme as shown in (tsai et al, 2005).<papid> I05-2046 </papid></citsent>
<aftsection>
<nextsent>1http://www-tsujii.is.s.u-tokyo.ac.jp/genia/tagger/ ? prefix and suffix with length 3-5.
</nextsent>
<nextsent>context of the lemma, pos and the chunk in the window [-2,2].
</nextsent>
<nextsent>combined features including l0c0, lip0 and lic0, where 1 ? ? 1 denotes the lemma of word, denotes pos and denotes chunk tag.?
</nextsent>
<nextsent>the type of chunk; the lemma and posse quences of it.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4696">
<title id=" W10-2922.xml">online entropy based model of lexical category acquisition </title>
<section> the acquisition of lexical categories.  </section>
<citcontext>
<prevsection>
<prevsent>human language acquisition is bounded by memory and processing limitations, and it is implausible that humans process large volumes of text at once and induce an optimum set of categories.
</prevsent>
<prevsent>efficient online computational models are needed to investigate whether distributional information is equally useful in an online process of word categorization.
</prevsent>
</prevsection>
<citsent citstr=" W08-2112 ">
however, the few incremental models of category acquisition which have been proposed so far are generally inefficient and over-sensitive to the properties of the input data (cartwright &amp; brent, 1997; parisien et al, 2008).<papid> W08-2112 </papid></citsent>
<aftsection>
<nextsent>moreover, the unsupervised nature of these models makes their assessment challenge, and the evaluation techniques proposed in the literature are limited.
</nextsent>
<nextsent>the main contributions of our research aretwofold.
</nextsent>
<nextsent>first, we propose an incremental entropy model for efficiently clustering words into categories given their local context.
</nextsent>
<nextsent>we train our model on corpus of child-directed speech from childes (macwhinney, 2000) and show that the model learns fine-grained set of intuitive wordcategories.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4699">
<title id=" W10-2922.xml">online entropy based model of lexical category acquisition </title>
<section> the acquisition of lexical categories.  </section>
<citcontext>
<prevsection>
<prevsent>the results show thatthe categories induced by our model can be successfully used in variety of tasks and typically perform better than other category sets.
</prevsent>
<prevsent>1.1 unsupervised models of category.
</prevsent>
</prevsection>
<citsent citstr=" J92-4003 ">
induction several computational models have used distributional information for categorizing words (e.g. brown et al, 1992; <papid> J92-4003 </papid>redington et al, 1998; clark,2000; <papid> W00-0717 </papid>mintz, 2002).</citsent>
<aftsection>
<nextsent>the majority of these mod 182 els partition the vocabulary into set of optimum clusters (e.g., brown et al, 1992; <papid> J92-4003 </papid>clark, 2000).<papid> W00-0717 </papid></nextsent>
<nextsent>the generated clusters are intuitive, and can be used in different tasks such as word prediction and parsing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4701">
<title id=" W10-2922.xml">online entropy based model of lexical category acquisition </title>
<section> the acquisition of lexical categories.  </section>
<citcontext>
<prevsection>
<prevsent>the results show thatthe categories induced by our model can be successfully used in variety of tasks and typically perform better than other category sets.
</prevsent>
<prevsent>1.1 unsupervised models of category.
</prevsent>
</prevsection>
<citsent citstr=" W00-0717 ">
induction several computational models have used distributional information for categorizing words (e.g. brown et al, 1992; <papid> J92-4003 </papid>redington et al, 1998; clark,2000; <papid> W00-0717 </papid>mintz, 2002).</citsent>
<aftsection>
<nextsent>the majority of these mod 182 els partition the vocabulary into set of optimum clusters (e.g., brown et al, 1992; <papid> J92-4003 </papid>clark, 2000).<papid> W00-0717 </papid></nextsent>
<nextsent>the generated clusters are intuitive, and can be used in different tasks such as word prediction and parsing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4705">
<title id=" W10-2922.xml">online entropy based model of lexical category acquisition </title>
<section> the acquisition of lexical categories.  </section>
<citcontext>
<prevsection>
<prevsent>moreover, these models confirm the learn ability of abstract word categories, and show that distributional cues are useful source of information for this purpose.
</prevsent>
<prevsent>however, (i) they categorize word types rather than word tokens, and as such provide no account of words belonging tomore than one category, and (ii) the batch algorithms used by these systems make them implausible for modeling human category induction.
</prevsent>
</prevsection>
<citsent citstr=" P07-1094 ">
unsupervised models of pos tagging such as goldwater &amp; griffiths (2007) <papid> P07-1094 </papid>do assign labels to word tokens, but they still typically use batch processing, and what is even more problematic, they hard wire important aspects of the model, such as the final number of categories.</citsent>
<aftsection>
<nextsent>only few previously proposed models process data incrementally, categorize word-tokens and do not pre-specify fixed category set.
</nextsent>
<nextsent>the model of cartwright &amp; brent (1997) uses an algorithm which incrementally merges word clusters so that minimum description length criterion for template grammar is optimized.
</nextsent>
<nextsent>the model treats whole sentences as contextual units, which sacrifices degree of incrementality, as well as making it less robust to noise in the input.parisien et al (2008) <papid> W08-2112 </papid>propose bayesian clustering model which copes with ambiguity and exhibits the developmental trends observed in children (e.g. the order of acquisition of different categories).</nextsent>
<nextsent>however, their model is overly sensitive to context variability, which results in the creation of sparse categories.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4709">
<title id=" W10-2922.xml">online entropy based model of lexical category acquisition </title>
<section> the acquisition of lexical categories.  </section>
<citcontext>
<prevsection>
<prevsent>these mechanisms improve the overall performance of the model when trained on large amounts of training data, but they complicate the model with ad-hoc extensions and add to the (al ready considerable) computational load.what is lacking is an incremental model of lexical category which can efficiently process naturalistic input data and gradually build robust categories with little training data.
</prevsent>
<prevsent>1.2 evaluation of the induced categories.
</prevsent>
</prevsection>
<citsent citstr=" E03-1009 ">
there is no standard and straightforward method for evaluating the unsupervised models of category learning (see clark, 2003, <papid> E03-1009 </papid>for discussion).many unsupervised models of lexical category acquisition treat the traditional part of speech (pos)tags as the gold standard, and measure the accuracy and completeness of their induced categories based on how closely they resemble the pos categories (e.g. redington et al, 1998; mintz, 2003; parisien et al, 2008).<papid> W08-2112 </papid></citsent>
<aftsection>
<nextsent>however, it is not at all clear whether humans form the same types of categories.
</nextsent>
<nextsent>in fact, many language tasks might benefit from finer-grained categories than the traditional pos tags used for corpus annotation.frank et al (2009) propose different, automatically generated set of gold standard categories for evaluating an unsupervised categorization model.the gold-standard categories are formed according to substitutability?: if one word can be replaced by another and the resulting sentence is still grammatical, then there is good chance that thetwo words belong to the same category.
</nextsent>
<nextsent>they extract 3-word frames from the training data, and form the gold standard categories based on the words that appear in the same frame.
</nextsent>
<nextsent>they emphasize that in order to provide some degree of generalization, different datasets must be used for forming the gold-standard categories and performing the evaluation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4720">
<title id=" W10-2922.xml">online entropy based model of lexical category acquisition </title>
<section> grammaticality judgment.  </section>
<citcontext>
<prevsection>
<prevsent>grammaticality judgment has been viewed as one of the main criteria for measuring how well language is learned by human learner.
</prevsent>
<prevsent>experimental studies have shown that children asyoung as five years old can judge the gram mati cality of the sentences that they hear, and that both childrens and adults?
</prevsent>
</prevsection>
<citsent citstr=" D07-1012 ">
grammaticality judgments are influenced by the distributional properties of words and their context (e.g., theakston, 2004).several methods have been proposed for automatically distinguishing between grammatical and ungrammatical usages (e.g., wagner et al, 2007).<papid> D07-1012 </papid>the shallow?</citsent>
<aftsection>
<nextsent>methods are mainly based on ngram frequencies of words or categories in corpus, whereas the deep?
</nextsent>
<nextsent>methods treat parsing failure as an indication of grammatical error.
</nextsent>
<nextsent>since our focus is on evaluating our category set,we use trigram probabilities as measure of gram maticality, using equation 9 with = 3.as before, we label each test sentence using different category sets, and calculate the probability for each trigram in that sentence.
</nextsent>
<nextsent>we define the overall grammaticality score of sentence as the minimum of the probabilities of all the trigrams in that sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4725">
<title id=" W10-1729.xml">applying morphological decompositions to statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, we didnot see improvements for the czech-to english translations.
</prevsent>
<prevsent>the effect of morphological variation in languages can be alleviated by using word analysis schemes,which may include morpheme discovery, part-of speech tagging, or other linguistic information.words are very convenient and even efficient representation in statistical natural language processing, especially with english, but morphologically rich languages can benefit from more fine-grainedinformation.
</prevsent>
</prevsection>
<citsent citstr=" N06-1062 ">
for instance, statistical morphs discovered with unsupervised methods result in better performance in automatic speech recognition for highly-inflecting and agglutinative languages (hirsimaki et al , 2006; kurimo et al , 2006).<papid> N06-1062 </papid></citsent>
<aftsection>
<nextsent>virpioja et al  (2007) applied morph-based models in statistical machine translation (smt) between several language pairs without gaining improvement in bleu score, but obtaining reductions in out-of-vocabulary rates.
</nextsent>
<nextsent>they utilized morphs both in the source and in the target language.
</nextsent>
<nextsent>later, de gispert et al  (2009)<papid> N09-2019 </papid>showed that minimum bayes risk (mbr) combination of word-based and morph-based translation models improves translation with arabic to-english and finnish-to-english language pairs,where only the source language utilized morph based models.</nextsent>
<nextsent>similar results have been shown forfinnish-to-english and finnish-to-german in performance evaluation of various unsupervised morpheme analysis algorithms in morpho challenge 2009 competition (kurimo et al , 2009).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4726">
<title id=" W10-1729.xml">applying morphological decompositions to statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>virpioja et al  (2007) applied morph-based models in statistical machine translation (smt) between several language pairs without gaining improvement in bleu score, but obtaining reductions in out-of-vocabulary rates.
</prevsent>
<prevsent>they utilized morphs both in the source and in the target language.
</prevsent>
</prevsection>
<citsent citstr=" N09-2019 ">
later, de gispert et al  (2009)<papid> N09-2019 </papid>showed that minimum bayes risk (mbr) combination of word-based and morph-based translation models improves translation with arabic to-english and finnish-to-english language pairs,where only the source language utilized morph based models.</citsent>
<aftsection>
<nextsent>similar results have been shown forfinnish-to-english and finnish-to-german in performance evaluation of various unsupervised morpheme analysis algorithms in morpho challenge 2009 competition (kurimo et al , 2009).
</nextsent>
<nextsent>we continue the research described above and examine how the level of decomposition affects both the individual morph-based systems and mbr combinations with the baseline word-based model.
</nextsent>
<nextsent>experiments are conducted with the wmt10 shared task data for german-to-english and czech-to-english language pairs.
</nextsent>
<nextsent>in this work, morphological analyses are conducted on the source language data, and each different analysis is applied to create unique segmentation of words into morphemes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4727">
<title id=" W10-1729.xml">applying morphological decompositions to statistical machine translation </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>experiments are conducted with the wmt10 shared task data for german-to-english and czech-to-english language pairs.
</prevsent>
<prevsent>in this work, morphological analyses are conducted on the source language data, and each different analysis is applied to create unique segmentation of words into morphemes.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
translation systems are trained with the moses toolkit (koehnet al , 2007) <papid> P07-2045 </papid>from each differently segmented version of the same source language to the target lan guage.</citsent>
<aftsection>
<nextsent>evaluation with bleu is performed onboth the individual systems and system combinations, using different levels of decomposition.
</nextsent>
<nextsent>2.1 morphological models for words.
</nextsent>
<nextsent>morfessor (creutz and lagus, 2002; <papid> W02-0603 </papid>creutz and lagus, 2007, etc.) is family of methods for unsupervised morphological segmentation.</nextsent>
<nextsent>mor fessor does not limit the number of morphemes for each word, making it suitable for agglutina tive and compounding languages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4728">
<title id=" W10-1729.xml">applying morphological decompositions to statistical machine translation </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>evaluation with bleu is performed onboth the individual systems and system combinations, using different levels of decomposition.
</prevsent>
<prevsent>2.1 morphological models for words.
</prevsent>
</prevsection>
<citsent citstr=" W02-0603 ">
morfessor (creutz and lagus, 2002; <papid> W02-0603 </papid>creutz and lagus, 2007, etc.) is family of methods for unsupervised morphological segmentation.</citsent>
<aftsection>
<nextsent>mor fessor does not limit the number of morphemes for each word, making it suitable for agglutina tive and compounding languages.
</nextsent>
<nextsent>an analysis of single word is list of non-overlapping segments, 195 morphs, stored in the model lexicon.
</nextsent>
<nextsent>we use both the morfessor baseline (creutz and lagus, 2005b) and the morfessor categories-map (creutz and lagus, 2005a) algorithms.1 both are formulated in maximum posteriori (map) framework, i.e.,the learning algorithm tries to optimize the product of the model prior and the data likelihood.
</nextsent>
<nextsent>the generative model applied by morfessor baseline assumes that the morphs are independent.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4731">
<title id=" W10-1729.xml">applying morphological decompositions to statistical machine translation </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>for combining individual models, we apply minimum bayes risk (mbr) system combination (sim et al , 2007).
</prevsent>
<prevsent>n-best lists from multiple smt systems trained with different morphological analysis methods are merged; the posterior distributions over the individual lists are interpolated to form new distribution over the merged list.
</prevsent>
</prevsection>
<citsent citstr=" N04-1022 ">
mbr hypotheses selection is then performed using sentence-level bleu score (kumar and byrne, 2004).<papid> N04-1022 </papid>in this work, the focus of the system combination is not to combine different translation systems (e.g., moses and systran), but to combine systems trained with the same translation algorithm using the same source language data with with different morphological decompositions.</citsent>
<aftsection>
<nextsent>the german-to-english and czech-to-english parts of the acl wmt10 shared task data were investigated.
</nextsent>
<nextsent>vanilla smt models were trained with moses using word tokens for mbr combination and comparison purposes.
</nextsent>
<nextsent>several different morphological segmentation models for germ anand czech were trained with morfessor.
</nextsent>
<nextsent>each segmentation model corresponds to morph-based smt model trained with moses.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4733">
<title id=" W10-1729.xml">applying morphological decompositions to statistical machine translation </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>with the de-en language pair, the improvement was statistically significant with all tested segmentation models.
</prevsent>
<prevsent>however, the improvements were not as large as those obtained before and the results for the cz-en language pair were not significantly different in most cases.
</prevsent>
</prevsection>
<citsent citstr=" D07-1091 ">
whether this is due to the different languages, training datasets, the domain of the evaluation datasets, or some problems in the model training, is currently uncertain.one very different approach for applying different levels of linguistic analysis is factor models for smt (koehn and hoang, 2007), <papid> D07-1091 </papid>where pre-determined factors (e.g., surface form, lemma and part-of-speech) are stored as vectors for eachword.</citsent>
<aftsection>
<nextsent>this provides better integration of morphosyntactic information and more control of the process, but the translation models are more complex and the number and factor types in each word must be fixed.
</nextsent>
<nextsent>our submissions to the acl wmt10 shared task utilize unsupervised morphological decomposition models in straightforward manner.
</nextsent>
<nextsent>the individual morph-based models trained with the source language words segmented into morphs did not improve the vanilla word-based models trained with the unsegmented source language.we have replicated the result for the germanto-english language pair that an mbr combination of word-based and segmented morph based model gives significant improvements to thebleu score.
</nextsent>
<nextsent>however, we did not see improvements for the czech-to-english translations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4734">
<title id=" W10-2409.xml">reranking with multiple features for better transliteration </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in order to make proper choice, the direct orthographic mapping requires aprecise alignment and better transliteration option selection.
</prevsent>
<prevsent>thus, powerful algorithms for effective use of the parallel data is indispensable, especially when the available data is limited in volume.
</prevsent>
</prevsection>
<citsent citstr=" W09-3511 ">
interestingly, although an smt based approach could not achieve precise top-1 transliteration result, it is found in (song et al, 2009) <papid> W09-3511 </papid>that, in contrast to the ordinary top-1 accuracy (acc) score, its recall rate, which is defined in terms of whether the correct answer is generated in the n-best output list, is rather high.</citsent>
<aftsection>
<nextsent>this observation suggests that if we could rearrange those outputs into better order, especially, push the correct one to the top,the overall performance could be enhanced significantly, without any further refinement of the original generation process.
</nextsent>
<nextsent>this reranking strategy is proved to be efficient in transliteration generation with multi-engine approach (oh et al, 2009).<papid> W09-3506 </papid></nextsent>
<nextsent>in this paper, we present our recent work on reranking the transliteration candidates via an on line discriminative learning framework, namely,the averaged perceptron.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4736">
<title id=" W10-2409.xml">reranking with multiple features for better transliteration </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>interestingly, although an smt based approach could not achieve precise top-1 transliteration result, it is found in (song et al, 2009) <papid> W09-3511 </papid>that, in contrast to the ordinary top-1 accuracy (acc) score, its recall rate, which is defined in terms of whether the correct answer is generated in the n-best output list, is rather high.</prevsent>
<prevsent>this observation suggests that if we could rearrange those outputs into better order, especially, push the correct one to the top,the overall performance could be enhanced significantly, without any further refinement of the original generation process.</prevsent>
</prevsection>
<citsent citstr=" W09-3506 ">
this reranking strategy is proved to be efficient in transliteration generation with multi-engine approach (oh et al, 2009).<papid> W09-3506 </papid></citsent>
<aftsection>
<nextsent>in this paper, we present our recent work on reranking the transliteration candidates via an on line discriminative learning framework, namely,the averaged perceptron.
</nextsent>
<nextsent>multiple features are incorporated into it for performance enhancement.the following sections will give the technical details of our method and present its results fornews2010 shared task for named entity transliteration.
</nextsent>
<nextsent>for the generation of transliteration candidates, we follow the work (song et al, 2009), <papid> W09-3511 </papid>using phrase-based smt procedure with the log-linear model (t|s) = exp[ i=1 ihi(s, t)]?</nextsent>
<nextsent>t exp[ i=1 ihi(s, t)] (1) for decoding.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4740">
<title id=" W10-2409.xml">reranking with multiple features for better transliteration </title>
<section> generation.  </section>
<citcontext>
<prevsection>
<prevsent>62 try in it.
</prevsent>
<prevsent>after that, we use phoneme resource2 to refine the phrase table by filtering out the wrongly extracted phrases and cleaning up the noise in it.in the decoding process, dynamic pruning is performed when generating the hypothesis in each step, in which the threshold is variable according to the current searching space, for we need to obtain good candidate list as precise as possible for the next stage.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
the parameter for each feature function in log-linear model is optimized by mert training (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>finally, maximum number of 50 candidates are generated for each source name.
</nextsent>
<nextsent>3.1 learning framework.
</nextsent>
<nextsent>for reranking training and prediction, we adopt the averaged perceptron (collins, 2002) <papid> W02-1001 </papid>as our learning framework, which has more stable performance than the non-averaged version.</nextsent>
<nextsent>it is presented in algorithm 1.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4741">
<title id=" W10-2409.xml">reranking with multiple features for better transliteration </title>
<section> reranking.  </section>
<citcontext>
<prevsection>
<prevsent>finally, maximum number of 50 candidates are generated for each source name.
</prevsent>
<prevsent>3.1 learning framework.
</prevsent>
</prevsection>
<citsent citstr=" W02-1001 ">
for reranking training and prediction, we adopt the averaged perceptron (collins, 2002) <papid> W02-1001 </papid>as our learning framework, which has more stable performance than the non-averaged version.</citsent>
<aftsection>
<nextsent>it is presented in algorithm 1.
</nextsent>
<nextsent>where ~?
</nextsent>
<nextsent>is the vector of parameters we want to optimize, x, are the corresponding source (with different syllabification) and target graphemes in the candidate list, and ? represents the feature vector in the pair of andy.
</nextsent>
<nextsent>in this algorithm, reference yi is the most appropriate output in the candidate list according to the true target named entity in the training data.we use the mean-f score to identify which candidate can be the reference, by locating the one with the maximum mean-f score value.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4742">
<title id=" W10-2409.xml">reranking with multiple features for better transliteration </title>
<section> reranking.  </section>
<citcontext>
<prevsection>
<prevsent>it performs in similar way as the language model for smt decoding.
</prevsent>
<prevsent>we use tri-gram syllables in this learning framework.
</prevsent>
</prevsection>
<citsent citstr=" P04-1021 ">
paired source-to-target transition feature, f(  s,  ii1); this type of feature is firstly proposed in (li et al, 2004), <papid> P04-1021 </papid>aiming at generating source and target graphemes simultaneously under suitable constraint.</citsent>
<aftsection>
<nextsent>we use this feature to restrict the synchronous transition of both source and target graphemes, measuring how well are those transitions, such as for st?, 63 whether s? transliterated by ???
</nextsent>
<nextsent>is followed by t? transliterated by ???.
</nextsent>
<nextsent>in order to deal with the data sparseness, only bi-gram transition relations are considered in this feature.
</nextsent>
<nextsent>hidden markov model (hmm) style features; there are group of features with hmm style constraint for evaluating the candidates generated in previous smt process, including, previous syllable hmm features,f(siin+1, ti), posterior syllable hmm features, f(si+n1i , ti), and posterior character hmm features, f(si, l, ti), where denotes the character following the previous syllable in the source language.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4747">
<title id=" W10-1762.xml">divide and translate improving long distance reordering in statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>reordering in smt can be roughly classified intotwo approaches, namely search in smt decoding and preprocessing.
</prevsent>
<prevsent>the former approach is straightforward waythat models reordering in noisy channel translation, and has been studied from the early period of smt research.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
distance-based reordering is atypical approach used in many previous studies related to word-based smt (brown et al, 1993) <papid> J93-2003 </papid>and phrase-based smt (koehn et al, 2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>along with the advances in phrase-based smt, lexicalized reordering with block orientation model was proposed (tillmann, 2004; <papid> N04-4026 </papid>koehn et al, 2005).</nextsent>
<nextsent>this kind of reordering is suitable and commonly used in phrase-based smt.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4748">
<title id=" W10-1762.xml">divide and translate improving long distance reordering in statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>reordering in smt can be roughly classified intotwo approaches, namely search in smt decoding and preprocessing.
</prevsent>
<prevsent>the former approach is straightforward waythat models reordering in noisy channel translation, and has been studied from the early period of smt research.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
distance-based reordering is atypical approach used in many previous studies related to word-based smt (brown et al, 1993) <papid> J93-2003 </papid>and phrase-based smt (koehn et al, 2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>along with the advances in phrase-based smt, lexicalized reordering with block orientation model was proposed (tillmann, 2004; <papid> N04-4026 </papid>koehn et al, 2005).</nextsent>
<nextsent>this kind of reordering is suitable and commonly used in phrase-based smt.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4749">
<title id=" W10-1762.xml">divide and translate improving long distance reordering in statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the former approach is straightforward waythat models reordering in noisy channel translation, and has been studied from the early period of smt research.
</prevsent>
<prevsent>distance-based reordering is atypical approach used in many previous studies related to word-based smt (brown et al, 1993) <papid> J93-2003 </papid>and phrase-based smt (koehn et al, 2003).<papid> N03-1017 </papid></prevsent>
</prevsection>
<citsent citstr=" N04-4026 ">
along with the advances in phrase-based smt, lexicalized reordering with block orientation model was proposed (tillmann, 2004; <papid> N04-4026 </papid>koehn et al, 2005).</citsent>
<aftsection>
<nextsent>this kind of reordering is suitable and commonly used in phrase-based smt.
</nextsent>
<nextsent>on the other hand,a syntax-based smt naturally includes reordering in its translation model.
</nextsent>
<nextsent>a lot of research work undertaken in this decade has used syntactic parsing for linguistically-motivated translation.
</nextsent>
<nextsent>(yamada and knight, 2001; <papid> P01-1067 </papid>graehl and knight, 2004; <papid> N04-1014 </papid>galley et al, 2004; liu et al, 2006).<papid> P06-1077 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4750">
<title id=" W10-1762.xml">divide and translate improving long distance reordering in statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>on the other hand,a syntax-based smt naturally includes reordering in its translation model.
</prevsent>
<prevsent>a lot of research work undertaken in this decade has used syntactic parsing for linguistically-motivated translation.
</prevsent>
</prevsection>
<citsent citstr=" P01-1067 ">
(yamada and knight, 2001; <papid> P01-1067 </papid>graehl and knight, 2004; <papid> N04-1014 </papid>galley et al, 2004; liu et al, 2006).<papid> P06-1077 </papid></citsent>
<aftsection>
<nextsent>wu(1997) <papid> J97-3002 </papid>and chiang (2007) <papid> J07-2003 </papid>focus on formal structures that can be extracted from parallel corpora,instead of syntactic parser trained using treebanks.</nextsent>
<nextsent>these syntactic approaches can theoretically model reordering over an arbitrary length, however, long distance reordering still faces the difficulty of searching over an extremely large search space.the preprocessing approach employs deterministic reordering so that the following translation process requires only short distance reordering (or even monotone).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4751">
<title id=" W10-1762.xml">divide and translate improving long distance reordering in statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>on the other hand,a syntax-based smt naturally includes reordering in its translation model.
</prevsent>
<prevsent>a lot of research work undertaken in this decade has used syntactic parsing for linguistically-motivated translation.
</prevsent>
</prevsection>
<citsent citstr=" N04-1014 ">
(yamada and knight, 2001; <papid> P01-1067 </papid>graehl and knight, 2004; <papid> N04-1014 </papid>galley et al, 2004; liu et al, 2006).<papid> P06-1077 </papid></citsent>
<aftsection>
<nextsent>wu(1997) <papid> J97-3002 </papid>and chiang (2007) <papid> J07-2003 </papid>focus on formal structures that can be extracted from parallel corpora,instead of syntactic parser trained using treebanks.</nextsent>
<nextsent>these syntactic approaches can theoretically model reordering over an arbitrary length, however, long distance reordering still faces the difficulty of searching over an extremely large search space.the preprocessing approach employs deterministic reordering so that the following translation process requires only short distance reordering (or even monotone).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4752">
<title id=" W10-1762.xml">divide and translate improving long distance reordering in statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>on the other hand,a syntax-based smt naturally includes reordering in its translation model.
</prevsent>
<prevsent>a lot of research work undertaken in this decade has used syntactic parsing for linguistically-motivated translation.
</prevsent>
</prevsection>
<citsent citstr=" P06-1077 ">
(yamada and knight, 2001; <papid> P01-1067 </papid>graehl and knight, 2004; <papid> N04-1014 </papid>galley et al, 2004; liu et al, 2006).<papid> P06-1077 </papid></citsent>
<aftsection>
<nextsent>wu(1997) <papid> J97-3002 </papid>and chiang (2007) <papid> J07-2003 </papid>focus on formal structures that can be extracted from parallel corpora,instead of syntactic parser trained using treebanks.</nextsent>
<nextsent>these syntactic approaches can theoretically model reordering over an arbitrary length, however, long distance reordering still faces the difficulty of searching over an extremely large search space.the preprocessing approach employs deterministic reordering so that the following translation process requires only short distance reordering (or even monotone).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4753">
<title id=" W10-1762.xml">divide and translate improving long distance reordering in statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>a lot of research work undertaken in this decade has used syntactic parsing for linguistically-motivated translation.
</prevsent>
<prevsent>(yamada and knight, 2001; <papid> P01-1067 </papid>graehl and knight, 2004; <papid> N04-1014 </papid>galley et al, 2004; liu et al, 2006).<papid> P06-1077 </papid></prevsent>
</prevsection>
<citsent citstr=" J97-3002 ">
wu(1997) <papid> J97-3002 </papid>and chiang (2007) <papid> J07-2003 </papid>focus on formal structures that can be extracted from parallel corpora,instead of syntactic parser trained using treebanks.</citsent>
<aftsection>
<nextsent>these syntactic approaches can theoretically model reordering over an arbitrary length, however, long distance reordering still faces the difficulty of searching over an extremely large search space.the preprocessing approach employs deterministic reordering so that the following translation process requires only short distance reordering (or even monotone).
</nextsent>
<nextsent>several previous studies have proposed syntax-driven reordering based on source-side parse trees.
</nextsent>
<nextsent>xia and mccord (2004) <papid> C04-1073 </papid>extracted reordering rules automatically from bilingual corpora for english-to french translation; collins et al (2005) <papid> P05-1066 </papid>used linguistically-motivated clause restructuring rules for german-to-english translation; li et al (2007)<papid> P07-1091 </papid>modeled reordering on parse tree nodes by using maximum entropy model with surface and syntactic features for chinese-to-english trans lation; katz-brown and collins (2008) applieda very simple reverse ordering to japanese-to english translation, which reversed the word order in japanese segments separated by few simple cues; xu et al (2009) <papid> N09-1028 </papid>utilized dependency parser with several hand-labeled precedence rules for reordering english to subject-object-verb order like korean and japanese.</nextsent>
<nextsent>tromble and eisner (2009) <papid> D09-1105 </papid>proposed another reordering approach based on alinear ordering problem over source words without linguistically syntactic structure.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4754">
<title id=" W10-1762.xml">divide and translate improving long distance reordering in statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>a lot of research work undertaken in this decade has used syntactic parsing for linguistically-motivated translation.
</prevsent>
<prevsent>(yamada and knight, 2001; <papid> P01-1067 </papid>graehl and knight, 2004; <papid> N04-1014 </papid>galley et al, 2004; liu et al, 2006).<papid> P06-1077 </papid></prevsent>
</prevsection>
<citsent citstr=" J07-2003 ">
wu(1997) <papid> J97-3002 </papid>and chiang (2007) <papid> J07-2003 </papid>focus on formal structures that can be extracted from parallel corpora,instead of syntactic parser trained using treebanks.</citsent>
<aftsection>
<nextsent>these syntactic approaches can theoretically model reordering over an arbitrary length, however, long distance reordering still faces the difficulty of searching over an extremely large search space.the preprocessing approach employs deterministic reordering so that the following translation process requires only short distance reordering (or even monotone).
</nextsent>
<nextsent>several previous studies have proposed syntax-driven reordering based on source-side parse trees.
</nextsent>
<nextsent>xia and mccord (2004) <papid> C04-1073 </papid>extracted reordering rules automatically from bilingual corpora for english-to french translation; collins et al (2005) <papid> P05-1066 </papid>used linguistically-motivated clause restructuring rules for german-to-english translation; li et al (2007)<papid> P07-1091 </papid>modeled reordering on parse tree nodes by using maximum entropy model with surface and syntactic features for chinese-to-english trans lation; katz-brown and collins (2008) applieda very simple reverse ordering to japanese-to english translation, which reversed the word order in japanese segments separated by few simple cues; xu et al (2009) <papid> N09-1028 </papid>utilized dependency parser with several hand-labeled precedence rules for reordering english to subject-object-verb order like korean and japanese.</nextsent>
<nextsent>tromble and eisner (2009) <papid> D09-1105 </papid>proposed another reordering approach based on alinear ordering problem over source words without linguistically syntactic structure.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4755">
<title id=" W10-1762.xml">divide and translate improving long distance reordering in statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>these syntactic approaches can theoretically model reordering over an arbitrary length, however, long distance reordering still faces the difficulty of searching over an extremely large search space.the preprocessing approach employs deterministic reordering so that the following translation process requires only short distance reordering (or even monotone).
</prevsent>
<prevsent>several previous studies have proposed syntax-driven reordering based on source-side parse trees.
</prevsent>
</prevsection>
<citsent citstr=" C04-1073 ">
xia and mccord (2004) <papid> C04-1073 </papid>extracted reordering rules automatically from bilingual corpora for english-to french translation; collins et al (2005) <papid> P05-1066 </papid>used linguistically-motivated clause restructuring rules for german-to-english translation; li et al (2007)<papid> P07-1091 </papid>modeled reordering on parse tree nodes by using maximum entropy model with surface and syntactic features for chinese-to-english trans lation; katz-brown and collins (2008) applieda very simple reverse ordering to japanese-to english translation, which reversed the word order in japanese segments separated by few simple cues; xu et al (2009) <papid> N09-1028 </papid>utilized dependency parser with several hand-labeled precedence rules for reordering english to subject-object-verb order like korean and japanese.</citsent>
<aftsection>
<nextsent>tromble and eisner (2009) <papid> D09-1105 </papid>proposed another reordering approach based on alinear ordering problem over source words without linguistically syntactic structure.</nextsent>
<nextsent>these preprocessing methods reorder source words closeto the target-side order by employing language dependent rules or statistical reordering models based on automatic word alignment.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4756">
<title id=" W10-1762.xml">divide and translate improving long distance reordering in statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>these syntactic approaches can theoretically model reordering over an arbitrary length, however, long distance reordering still faces the difficulty of searching over an extremely large search space.the preprocessing approach employs deterministic reordering so that the following translation process requires only short distance reordering (or even monotone).
</prevsent>
<prevsent>several previous studies have proposed syntax-driven reordering based on source-side parse trees.
</prevsent>
</prevsection>
<citsent citstr=" P05-1066 ">
xia and mccord (2004) <papid> C04-1073 </papid>extracted reordering rules automatically from bilingual corpora for english-to french translation; collins et al (2005) <papid> P05-1066 </papid>used linguistically-motivated clause restructuring rules for german-to-english translation; li et al (2007)<papid> P07-1091 </papid>modeled reordering on parse tree nodes by using maximum entropy model with surface and syntactic features for chinese-to-english trans lation; katz-brown and collins (2008) applieda very simple reverse ordering to japanese-to english translation, which reversed the word order in japanese segments separated by few simple cues; xu et al (2009) <papid> N09-1028 </papid>utilized dependency parser with several hand-labeled precedence rules for reordering english to subject-object-verb order like korean and japanese.</citsent>
<aftsection>
<nextsent>tromble and eisner (2009) <papid> D09-1105 </papid>proposed another reordering approach based on alinear ordering problem over source words without linguistically syntactic structure.</nextsent>
<nextsent>these preprocessing methods reorder source words closeto the target-side order by employing language dependent rules or statistical reordering models based on automatic word alignment.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4757">
<title id=" W10-1762.xml">divide and translate improving long distance reordering in statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>these syntactic approaches can theoretically model reordering over an arbitrary length, however, long distance reordering still faces the difficulty of searching over an extremely large search space.the preprocessing approach employs deterministic reordering so that the following translation process requires only short distance reordering (or even monotone).
</prevsent>
<prevsent>several previous studies have proposed syntax-driven reordering based on source-side parse trees.
</prevsent>
</prevsection>
<citsent citstr=" P07-1091 ">
xia and mccord (2004) <papid> C04-1073 </papid>extracted reordering rules automatically from bilingual corpora for english-to french translation; collins et al (2005) <papid> P05-1066 </papid>used linguistically-motivated clause restructuring rules for german-to-english translation; li et al (2007)<papid> P07-1091 </papid>modeled reordering on parse tree nodes by using maximum entropy model with surface and syntactic features for chinese-to-english trans lation; katz-brown and collins (2008) applieda very simple reverse ordering to japanese-to english translation, which reversed the word order in japanese segments separated by few simple cues; xu et al (2009) <papid> N09-1028 </papid>utilized dependency parser with several hand-labeled precedence rules for reordering english to subject-object-verb order like korean and japanese.</citsent>
<aftsection>
<nextsent>tromble and eisner (2009) <papid> D09-1105 </papid>proposed another reordering approach based on alinear ordering problem over source words without linguistically syntactic structure.</nextsent>
<nextsent>these preprocessing methods reorder source words closeto the target-side order by employing language dependent rules or statistical reordering models based on automatic word alignment.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4758">
<title id=" W10-1762.xml">divide and translate improving long distance reordering in statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>these syntactic approaches can theoretically model reordering over an arbitrary length, however, long distance reordering still faces the difficulty of searching over an extremely large search space.the preprocessing approach employs deterministic reordering so that the following translation process requires only short distance reordering (or even monotone).
</prevsent>
<prevsent>several previous studies have proposed syntax-driven reordering based on source-side parse trees.
</prevsent>
</prevsection>
<citsent citstr=" N09-1028 ">
xia and mccord (2004) <papid> C04-1073 </papid>extracted reordering rules automatically from bilingual corpora for english-to french translation; collins et al (2005) <papid> P05-1066 </papid>used linguistically-motivated clause restructuring rules for german-to-english translation; li et al (2007)<papid> P07-1091 </papid>modeled reordering on parse tree nodes by using maximum entropy model with surface and syntactic features for chinese-to-english trans lation; katz-brown and collins (2008) applieda very simple reverse ordering to japanese-to english translation, which reversed the word order in japanese segments separated by few simple cues; xu et al (2009) <papid> N09-1028 </papid>utilized dependency parser with several hand-labeled precedence rules for reordering english to subject-object-verb order like korean and japanese.</citsent>
<aftsection>
<nextsent>tromble and eisner (2009) <papid> D09-1105 </papid>proposed another reordering approach based on alinear ordering problem over source words without linguistically syntactic structure.</nextsent>
<nextsent>these preprocessing methods reorder source words closeto the target-side order by employing language dependent rules or statistical reordering models based on automatic word alignment.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4759">
<title id=" W10-1762.xml">divide and translate improving long distance reordering in statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>several previous studies have proposed syntax-driven reordering based on source-side parse trees.
</prevsent>
<prevsent>xia and mccord (2004) <papid> C04-1073 </papid>extracted reordering rules automatically from bilingual corpora for english-to french translation; collins et al (2005) <papid> P05-1066 </papid>used linguistically-motivated clause restructuring rules for german-to-english translation; li et al (2007)<papid> P07-1091 </papid>modeled reordering on parse tree nodes by using maximum entropy model with surface and syntactic features for chinese-to-english trans lation; katz-brown and collins (2008) applieda very simple reverse ordering to japanese-to english translation, which reversed the word order in japanese segments separated by few simple cues; xu et al (2009) <papid> N09-1028 </papid>utilized dependency parser with several hand-labeled precedence rules for reordering english to subject-object-verb order like korean and japanese.</prevsent>
</prevsection>
<citsent citstr=" D09-1105 ">
tromble and eisner (2009) <papid> D09-1105 </papid>proposed another reordering approach based on alinear ordering problem over source words without linguistically syntactic structure.</citsent>
<aftsection>
<nextsent>these preprocessing methods reorder source words closeto the target-side order by employing language dependent rules or statistical reordering models based on automatic word alignment.
</nextsent>
<nextsent>although the use of language-dependent rules is natural and promising way of bridging gaps between languages with large syntactic differences, the rules are usually unsuitable for other language groups.on the other hand, statistical methods can be applied to any language pairs.
</nextsent>
<nextsent>however, it is very difficult to reorder all source words so that they are monotonic with the target words.
</nextsent>
<nextsent>this is because automatic word alignment is not usually reliable owing to data sparseness and the weak modeling of many-to-many word alignments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4761">
<title id=" W10-1762.xml">divide and translate improving long distance reordering in statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>our method can be seen as variant of tree-to-stringtranslation that focuses only on the clause structure in parse trees and independently translates the clauses.
</prevsent>
<prevsent>although previous syntax-based methods can theoretically model this kind of derivation, it is practically difficult to decode long multi-clause sentences as described above.our approach is also related to sentence simplification and is intended to obtain simple and short source sentences for better translation.
</prevsent>
</prevsection>
<citsent citstr=" P98-1070 ">
kim and ehara (1994) proposed rule-based method for splitting long japanese sentences for japanese to-english translation; furuse et al (1998) <papid> P98-1070 </papid>used syntactic structure to split ill-formed inputs in speech translation.</citsent>
<aftsection>
<nextsent>their splitting approach splits sentence sequentially to obtain short segments, and does not undertake their reordering.
</nextsent>
<nextsent>another related field is clause identification (tjong et al, 2001).
</nextsent>
<nextsent>the proposed method is not limited to specific clause identification method and any method can be employed, if their clause definition matches the proposed method where clauses are independently translated.
</nextsent>
<nextsent>the proposed method consists of the following steps illustrated in figure 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4762">
<title id=" W10-1762.xml">divide and translate improving long distance reordering in statistical machine translation </title>
<section> proposed method.  </section>
<citcontext>
<prevsection>
<prevsent>= argmaxk t(lm = k|fm).
</prevsent>
<prevsent>in practice, this may sometimes lead to japanese clauses that have too many gaps, so we employ two-stage procedure to extract clauses that are more contiguous.
</prevsent>
</prevsection>
<citsent citstr=" P06-1004 ">
first, we segment the japanese sentence into kclauses based on dynamic programming algorithm proposed by malioutov and barzilay (2006).<papid> P06-1004 </papid></citsent>
<aftsection>
<nextsent>we define an ? similarity matrix = [sij ] with sij = exp(?||lilj ||) where li is (k + i)-th row vector in the label matrix l. sij represents the similarity between the i-th and j-th japanese words with respect to their clause alignment scoredistributions; if the score distributions are similar then sij is large.
</nextsent>
<nextsent>the details of this algorithm can be found in (malioutov and barzilay,2006).<papid> P06-1004 </papid></nextsent>
<nextsent>the clause segmentation gives us contiguous japanese clauses f1, f2, ..., fk , thus minimizing inter-segment similarity and maximizing intra-segment similarity.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4764">
<title id=" W10-1762.xml">divide and translate improving long distance reordering in statistical machine translation </title>
<section> experiment.  </section>
<citcontext>
<prevsection>
<prevsent>the parallel corpus consisted of research paper abstracts in english taken frompubmed4 and the corresponding japanese transla tions.the training portion consisted of 25,500 sentences (no-clause-seg.; original sentences without clause segmentation).
</prevsent>
<prevsent>4,132 english sentences in the corpus were composed of multiple clauses and were separated at the clause level 4http://www.ncbi.nlm.nih.gov/pubmed/by the procedure in section 3.1.
</prevsent>
</prevsection>
<citsent citstr=" J08-1002 ">
as the syntactic parser, we used the enju5 (miyao and tsujii, 2008) <papid> J08-1002 </papid>english hpsg parser.</citsent>
<aftsection>
<nextsent>for these training sentences, we automatically aligned japanese words with each english clause as described in section 3.2 and developed clause-level aligned corpus, called auto-aligned corpus.
</nextsent>
<nextsent>we prepared manually-aligned (oracle) clauses for reference,called oracle-aligned clauses.
</nextsent>
<nextsent>the clause alignment error rate of the auto-aligned corpus was14% (number of wrong clause assignments divided by total number of words).
</nextsent>
<nextsent>the development and test portions each consisted of 1,032 multi-clause sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4765">
<title id=" W10-1762.xml">divide and translate improving long distance reordering in statistical machine translation </title>
<section> experiment.  </section>
<citcontext>
<prevsection>
<prevsent>our resource statistics are summarized in table 1.
</prevsent>
<prevsent>4.2 model and decoder.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
we used two decoders in the experiments,moses9 (koehn et al, 2007) <papid> P07-2045 </papid>and our in house hierarchical phrase-based smt (almost equivalent to hiero (chiang, 2007)).<papid> J07-2003 </papid></citsent>
<aftsection>
<nextsent>moses used phrase table with maximum phrase length of 7, lexicalized reordering model with msd-bidirectional-fe, and distortion limit of 1210.
</nextsent>
<nextsent>our hierarchical phrase-based smt used phrase table with maximum rule length of 7 and window size (hieros ?) of 12 11.
</nextsent>
<nextsent>both 5http://www-tsujii.is.s.u-tokyo.ac.jp/enju/index.html 6http://lsd.pharm.kyoto-u.ac.jp/en/index.html 7http://mecab.sourceforge.net/ 8http://sourceforge.jp/projects/comedic/ (in japanese) 9http://www.statmt.org/moses/ 10unlimited distortion was also tested but the results were worse.11a larger window size could not be used due to its memory requirements.
</nextsent>
<nextsent>423 table 1: data statistics on training, development, and test sets.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4767">
<title id=" W10-1762.xml">divide and translate improving long distance reordering in statistical machine translation </title>
<section> experiment.  </section>
<citcontext>
<prevsection>
<prevsent>j 942,913 25,550 parallel 135,698 (auto-aligned) 183,043 4,132 (oracle-aligned) 183,147 (10,766 clauses) 263,175 155.692dictionary 291,455 (entries) development corpus type #words #sentences parallel 34,417 1,032 (oracle-aligned) 46,480 (2,683 clauses) test corpus type #words #sentences parallel 34,433 1,032 (clause-seg.)
</prevsent>
<prevsent>j 45,975 (2,737 clauses) decoders employed two language models: word5-gram language model from the japanese sentences in the parallel corpus and word 4-gram language model from the japanese entries in the dictionary.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
the feature weights were optimized for bleu (papineni et al, 2002) <papid> P02-1040 </papid>by mert, using the development sentences.</citsent>
<aftsection>
<nextsent>4.3 compared methods.
</nextsent>
<nextsent>we compared four different training and test conditions with respect to the use of clauses in training and testing.
</nextsent>
<nextsent>the development (i.e., mert) conditions followed the test conditions.
</nextsent>
<nextsent>two additional conditions with oracle clause alignment were also tested for reference.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4768">
<title id=" W10-1762.xml">divide and translate improving long distance reordering in statistical machine translation </title>
<section> experiment.  </section>
<citcontext>
<prevsection>
<prevsent>clauses.
</prevsent>
<prevsent>4.4 results.
</prevsent>
</prevsection>
<citsent citstr=" W01-1408 ">
table 3 shows the results in bleu, translation edit rate (ter) (snover et al, 2006), and position-independent word-error rate (per) (och et al, 2001), <papid> W01-1408 </papid>obtained with moses and our hierarchical phrase-based smt, respectively.</citsent>
<aftsection>
<nextsent>boldface results indicate the best scores obtained with the compared methods (excluding oracles).the proposed method consistently outperformed the baseline.
</nextsent>
<nextsent>the bleu improvements with the proposed method over the base line and comparison methods were statistically significant according to the bootstrap sampling test (p   0.05, 1,000 samples) (zhang et al,2004).
</nextsent>
<nextsent>with moses, the improvement when using the proposed method was 1.4% (33.19% to 34.60%) in bleu and 1.3% (57.83% to 56.50%) inter, with slight improvement in per (35.84% to 35.61%).
</nextsent>
<nextsent>we observed: oracle ? proposed ? comp.(1) ? baseline ? comp.(2) by the bonferroni method, where the symbol ? means as improvement over is statistically significant.?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4769">
<title id=" W10-2007.xml">predicting cognitively salient modifiers of the constitutive parts of concepts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these feature norms (as collections of subject-elicited properties are called in the relevant literature) areused in simulations of cognitive tasks and experimental design.
</prevsent>
<prevsent>moreover, vector spaces that have subject-generated properties as dimensions have been shown to be good complement or alternative to traditional semantic models based on corpus collocates (andrews et al , 2009; baroni et al , 2010).
</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
since the concept property pairs in feature norms resemble the tuples that relation extraction algorithms extract from corpora (hearst, 1992; <papid> C92-2082 </papid>pan tel and pennacchiotti, 2006), <papid> P06-1015 </papid>recent research has attempted to extract feature-norm-like concept descriptions from corpora (almuhareb, 2006; baroni et al , 2010; shaoul and westbury, 2008).</citsent>
<aftsection>
<nextsent>froma practical point of view, the success of this enterprise would mean being able to produce much larger norms without the need to resort to expensive and time-consuming elicitation experiments, leading to wider cognitive simulations and possibly better vector space models of semantics.
</nextsent>
<nextsent>from theoretical point of view, corpus-based system that produces human-like concept descriptions might provide cues of how humans themselves come up with such descriptions.
</nextsent>
<nextsent>however, the corpus-based models proposed forthis task up to this point overlook the fact that subjects very often produce composite properties: subjects state that rabbits have long ears, not just ears; cars have four wheels; calf is baby cow, etc.composite properties are not multi-word expressions in the usual sense.
</nextsent>
<nextsent>there is nothing special or idiomatic about long ears.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4770">
<title id=" W10-2007.xml">predicting cognitively salient modifiers of the constitutive parts of concepts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these feature norms (as collections of subject-elicited properties are called in the relevant literature) areused in simulations of cognitive tasks and experimental design.
</prevsent>
<prevsent>moreover, vector spaces that have subject-generated properties as dimensions have been shown to be good complement or alternative to traditional semantic models based on corpus collocates (andrews et al , 2009; baroni et al , 2010).
</prevsent>
</prevsection>
<citsent citstr=" P06-1015 ">
since the concept property pairs in feature norms resemble the tuples that relation extraction algorithms extract from corpora (hearst, 1992; <papid> C92-2082 </papid>pan tel and pennacchiotti, 2006), <papid> P06-1015 </papid>recent research has attempted to extract feature-norm-like concept descriptions from corpora (almuhareb, 2006; baroni et al , 2010; shaoul and westbury, 2008).</citsent>
<aftsection>
<nextsent>froma practical point of view, the success of this enterprise would mean being able to produce much larger norms without the need to resort to expensive and time-consuming elicitation experiments, leading to wider cognitive simulations and possibly better vector space models of semantics.
</nextsent>
<nextsent>from theoretical point of view, corpus-based system that produces human-like concept descriptions might provide cues of how humans themselves come up with such descriptions.
</nextsent>
<nextsent>however, the corpus-based models proposed forthis task up to this point overlook the fact that subjects very often produce composite properties: subjects state that rabbits have long ears, not just ears; cars have four wheels; calf is baby cow, etc.composite properties are not multi-word expressions in the usual sense.
</nextsent>
<nextsent>there is nothing special or idiomatic about long ears.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4771">
<title id=" W10-2007.xml">predicting cognitively salient modifiers of the constitutive parts of concepts </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>features that, once the modifier has been stripped of, are not that salient anymore (what distinguishes mono cycle from tricycle is that one has 1 wheel,the other 3, not simply having wheels).
</prevsent>
<prevsent>it is conceivable that method to assign sensible modifier sto features might actually improve the overall quality of feature extraction algorithms.
</prevsent>
</prevsection>
<citsent citstr=" J90-1003 ">
following very long tradition in computational linguistics (church and hanks, 1990), <papid> J90-1003 </papid>we use cooccurrence statistics for words in certain contexts to hypothesise meaningful connection between the words.</citsent>
<aftsection>
<nextsent>in this respect, what we propose is not different from common methods to extract and rank 55collocations, multi-word expressions or semantically related terms (evert, 2008).
</nextsent>
<nextsent>from technical point of view, the innovative aspect of our task is that we do not just look for co-occurrences between two items, but for co-occurrences in the context of third element, i. e., we are interested in modifier?
</nextsent>
<nextsent>part pairs that are related when predicated of acer tain concept.
</nextsent>
<nextsent>the method we apply to the extraction of modifier part pairs when they co-occur with the target concept in large window is similar to the idea of looking for partially untethered contextual patterns proposed by garera and yarowsky (2009), <papid> E09-1035 </papid>that extract namepatternproperty tupleswhere the pattern and the property must be adjacent, but the target name is only required to occur in the same sentence.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4772">
<title id=" W10-2007.xml">predicting cognitively salient modifiers of the constitutive parts of concepts </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>from technical point of view, the innovative aspect of our task is that we do not just look for co-occurrences between two items, but for co-occurrences in the context of third element, i. e., we are interested in modifier?
</prevsent>
<prevsent>part pairs that are related when predicated of acer tain concept.
</prevsent>
</prevsection>
<citsent citstr=" E09-1035 ">
the method we apply to the extraction of modifier part pairs when they co-occur with the target concept in large window is similar to the idea of looking for partially untethered contextual patterns proposed by garera and yarowsky (2009), <papid> E09-1035 </papid>that extract namepatternproperty tupleswhere the pattern and the property must be adjacent, but the target name is only required to occur in the same sentence.</citsent>
<aftsection>
<nextsent>our empirical starting point are the feature norms collected in parallel from 73 german and 69 italian subjects by kremer et al  (2008), <papid> W08-1913 </papid>following methodology similar to that of mcrae et al  (2005).</nextsent>
<nextsent>the norms pertain to 50 concrete concepts from 10 classes such as mammals (e. g., dog), manipulable tools (e. g., comb), etc. the concept part pairs in these norms served on the one hand as input to our algorithm ? on the other hand, its output (the set of selected modifiers from the corpus) could be evaluated against those modifiers that were produced by the subjects.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4773">
<title id=" W10-2007.xml">predicting cognitively salient modifiers of the constitutive parts of concepts </title>
<section> composite parts in feature norms.  </section>
<citcontext>
<prevsection>
<prevsent>part pairs that are related when predicated of acer tain concept.
</prevsent>
<prevsent>the method we apply to the extraction of modifier part pairs when they co-occur with the target concept in large window is similar to the idea of looking for partially untethered contextual patterns proposed by garera and yarowsky (2009), <papid> E09-1035 </papid>that extract namepatternproperty tupleswhere the pattern and the property must be adjacent, but the target name is only required to occur in the same sentence.</prevsent>
</prevsection>
<citsent citstr=" W08-1913 ">
our empirical starting point are the feature norms collected in parallel from 73 german and 69 italian subjects by kremer et al  (2008), <papid> W08-1913 </papid>following methodology similar to that of mcrae et al  (2005).</citsent>
<aftsection>
<nextsent>the norms pertain to 50 concrete concepts from 10 classes such as mammals (e. g., dog), manipulable tools (e. g., comb), etc. the concept part pairs in these norms served on the one hand as input to our algorithm ? on the other hand, its output (the set of selected modifiers from the corpus) could be evaluated against those modifiers that were produced by the subjects.
</nextsent>
<nextsent>furthermore, the bilingual nature of the norms allows us to tune our algorithm on one language (german), and evaluate its performance on the other (italian), to assess its cross-lingual generalisation capability.to confirm that speakers actually frequently produce properties composed of part and modifier, observe that in the german data (10,010 descriptive phrases in total), of the 1,667 parts produced, 625 (more than one third) were composite parts, and 404 were composed of an adjective and noun, the target of this research work.
</nextsent>
<nextsent>looking at the distinct parts that were elicited, 92 were always produced with modifier, 280 only without modifier, and 122 both with and without modifier.
</nextsent>
<nextsent>that is, for about43% of the parts at least some speakers used composite expression of adjective and noun.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4774">
<title id=" W10-1402.xml">improving arabic dependency parsing with lexical and inflectional morphological features </title>
<section> corpus.  </section>
<citcontext>
<prevsection>
<prevsent>for msa, the space of possible morphological features is fairly large.
</prevsent>
<prevsent>we determine which morphological features help and why, and we determine the upper bound for their contribution to parsing quality.we first present the corpus we use (2), then relevant arabic linguistic facts (3); we survey related work (4), describe our experiments (5), and conclude with analysis of parsing error types (6).
</prevsent>
</prevsection>
<citsent citstr=" P09-2056 ">
we use the columbia arabic treebank (catib) (habash and roth, 2009).<papid> P09-2056 </papid></citsent>
<aftsection>
<nextsent>specifically, we use the portion converted from part 3 of the penn arabic treebank (patb) (maamouri et al, 2004) to thecatib format, which enriches the catib dependency trees with full patb morphological information.
</nextsent>
<nextsent>catibs dependency representation is basedon traditional arabic grammar and emphasizes syntactic case relations.
</nextsent>
<nextsent>it has reduced pos tagset (with six tags only), but standard set of eight dependency relations: sbj and obj for subject and (direct or indirect) object, respectively, (whether they appear pre- or post-verbally); idf for the idafa(possessive) relation; mod for most other modi fica tions; and other less common relations that we will not discuss here.
</nextsent>
<nextsent>for more information, see (habash and roth, 2009).<papid> P09-2056 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4782">
<title id=" W10-1402.xml">improving arabic dependency parsing with lexical and inflectional morphological features </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>following this exploration, we also extend core12, producing (f) core12ex (see section 5 for details).
</prevsent>
<prevsent>much work has been done on the use of morphological features for parsing of morphologically richlanguages.
</prevsent>
</prevsection>
<citsent citstr=" P99-1065 ">
collins et al (1999) <papid> P99-1065 </papid>report that an optimal tagset for parsing czech consists of basic pos tag plus case feature (when applicable).</citsent>
<aftsection>
<nextsent>this tagset (size 58) outperforms the basic czech pos tagset (size 13) and the complete tagset (size 3000+).
</nextsent>
<nextsent>they also report that the use of gender,number and person features did not yield any improvements.
</nextsent>
<nextsent>we get similar results for case in thegold experimental setting but not when using predicted pos tags (pos tagger output).
</nextsent>
<nextsent>this may be result of case tagging having lower error rate in czech (5.0%) (hajic?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4783">
<title id=" W10-1402.xml">improving arabic dependency parsing with lexical and inflectional morphological features </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>we also find thatthe number feature helps for arabic.
</prevsent>
<prevsent>looking at hebrew, semitic language related to arabic, tsarfaty and simaan (2007) report that extending pos and phrase structure tags with definite ness information helps un lexicalized pcfg parsing.
</prevsent>
</prevsection>
<citsent citstr=" W06-2920 ">
as for work on arabic, results have been reported on patb (kulick et al, 2006; diab, 2007), the prague dependency treebank (padt) (buchholz and marsi, 2006; <papid> W06-2920 </papid>nivre, 2008) and the columbia arabic treebank (catib) (habash and roth, 2009).<papid> P09-2056 </papid></citsent>
<aftsection>
<nextsent>besides the work we describe in 3, nivre (2008) reports experiments on arabic parsing using his malt parser (nivre et al, 2007), trained on the padt.his results are not directly comparable to ours be cause of the different treebanks representations and tokenization used, even though all our experiments reported here were performed using the maltparser.
</nextsent>
<nextsent>our results agree with previous published work on arabic and hebrew in that marking the definite article is helpful for parsing.
</nextsent>
<nextsent>however, we go beyond previous work in that we also extend this morphologically enhanced feature set to include additional 15lexical and inflectional morphological features.
</nextsent>
<nextsent>previous work with malt parser in russian, turkish and hindi showed gains with case but not with agreement features (nivre et al, 2008; <papid> C08-1081 </papid>eryigit et al, 2008; nivre, 2009).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4787">
<title id=" W10-1402.xml">improving arabic dependency parsing with lexical and inflectional morphological features </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>our results agree with previous published work on arabic and hebrew in that marking the definite article is helpful for parsing.
</prevsent>
<prevsent>however, we go beyond previous work in that we also extend this morphologically enhanced feature set to include additional 15lexical and inflectional morphological features.
</prevsent>
</prevsection>
<citsent citstr=" C08-1081 ">
previous work with malt parser in russian, turkish and hindi showed gains with case but not with agreement features (nivre et al, 2008; <papid> C08-1081 </papid>eryigit et al, 2008; nivre, 2009).</citsent>
<aftsection>
<nextsent>our work is the first to show gains using agreement in malt parser and in arabic dependency parsing.
</nextsent>
<nextsent>5.1 experimental space.
</nextsent>
<nextsent>we examined large space of settings including the following: (a) the contribution of pos tagsets to the parsing quality, as function of the amount of information encoded in the tagset; (b) parsing performance on gold vs. predicted pos and morphological feature values for all models; (c) prediction accuracy of each pos tagset and morphological feature;(d) the contribution of numerous morphological features in controlled fashion; and (e) the contribution of certain feature and pos tagset combinations.
</nextsent>
<nextsent>all results are reported mainly in terms of labeled attachment accuracy (parent word and the dependency relation to it).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4788">
<title id=" W10-1402.xml">improving arabic dependency parsing with lexical and inflectional morphological features </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>for all experiments reported here we used the syntactic dependency parser malt parser v1.3 (nivre, 2003; nivre, 2008; kbler et al, 2009) ? transition-based parser with an input buffer and stack, using svm classifiers to predict the next state in the parse derivation.
</prevsent>
<prevsent>all experiments were done using the nivre  eager  algorithm.7 we trained the parser on the training portion of patb part 3 (maamouri et al, 2004).
</prevsent>
</prevsection>
<citsent citstr=" P06-1073 ">
we used the same split as in zitouni et al (2006) <papid> P06-1073 </papid>for dev/test, and kept the test unseen during training.</citsent>
<aftsection>
<nextsent>there are five default attributes, in the malt parser terminology, for each token in the text: word id (ordinal position in the sentence), word form, pos7nivre (2008) reports that non-projective and pseudo projective algorithms outperform the  eager  projective algorithm in maltparser; however, our training data did not contain any non-projective dependencies, so there was no point in using these algorithms.
</nextsent>
<nextsent>the nivre  standard  algorithm is also reported to do better on arabic, but in preliminary experimentation, it did slightly worse than the  eager?
</nextsent>
<nextsent>one.
</nextsent>
<nextsent>this couldbe due to high percentage of right branching (left headed struc tures) in our arabic training set, an observation already noted in nivre (2008).tag, head (parent word id), and deprel (the dependency relation between the current word and its par ent).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4789">
<title id=" W10-1402.xml">improving arabic dependency parsing with lexical and inflectional morphological features </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>butin practice, pos tags are annotated by automatic taggers, so parsers get predicted pos tags as input, as opposed to gold (human-annotated) tags.
</prevsent>
<prevsent>the more informative the tagset, the less accurate the tag prediction might be, so the effect on overall parsing quality is unclear.
</prevsent>
</prevsection>
<citsent citstr=" P05-1071 ">
therefore, we repeated the experiments above with pos tags predicted by the morphological analysis and disambiguation for arabic (mada) toolkit (habash and rambow, 2005).<papid> P05-1071 </papid></citsent>
<aftsection>
<nextsent>see table 1, columns 5-7.
</nextsent>
<nextsent>it turned out that bw, thebest gold performer, with lowest pos prediction accuracy (81.8%), suffered the biggest drop (11.38%) and was the worst performer with predicted tags.the simplest tagset, catib6, and its extension, catibex, benefited from the highest pos prediction accuracy (97.7%), and their performance suffered theleast.
</nextsent>
<nextsent>catibex was the best performer with predicted pos tags.
</nextsent>
<nextsent>performance drop and pos prediction accuracy are given in columns 8 and 9, respectively.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4790">
<title id=" W10-1402.xml">improving arabic dependency parsing with lexical and inflectional morphological features </title>
<section> conclusions and future work.  </section>
<citcontext>
<prevsection>
<prevsent>while more informative features (e.g., richer pos tags) yield better parsing quality in gold conditions, they are hard to predict, and as such they might not contribute to ? and even hurt ? the parsing quality under predicted conditions.
</prevsent>
<prevsent>we find that definite ness (det), phi-features (person, number, gender), and undiacritzed lemma (lmm) are most helpful for arabic parsing on predicted input, while case and state are most helpful on gold.
</prevsent>
</prevsection>
<citsent citstr=" E06-1011 ">
in the future we plan to improve case prediction accuracy; produce high accuracy super tag features, modeling active and passive valency; and use other parsers (e.g., mcdonald and pereira, 2006).<papid> E06-1011 </papid></citsent>
<aftsection>
<nextsent>acknowledgments this work was supported by the darpa gale program, contract hr0011-08-c-0110.
</nextsent>
<nextsent>we thank joakim nivre for his useful remarks, and ryan roth for his help with catib conversion and mada.
</nextsent>
<nextsent>20
</nextsent>

</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4791">
<title id=" W10-1013.xml">off topic essay detection using short prompt texts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>and are likely to appear in discussion of any one aspect.
</prevsent>
<prevsent>these expansions could comprise antonyms and other related words too.
</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
this idea of word similarity was implemented in work by lin (1998).<papid> P98-2127 </papid></citsent>
<aftsection>
<nextsent>similarity between two words is estimated by examining the degree of overlap of their contexts in large corpus.
</nextsent>
<nextsent>we access lins similarity estimates usinga tool from leacock and chodorow (2003) that returns words with similarity values above cutoff.
</nextsent>
<nextsent>word association norms: word associations have been of great interest in psycho linguistic research.
</nextsent>
<nextsent>participants are given target word and asked to mention words that readily come to mind.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4792">
<title id=" W10-2503.xml">parsing and translation algorithms based on weighted extended tree transducers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the field of statistical machine translation, considerable interest has recently been shown for translation models based on weighted tree transducers.
</prevsent>
<prevsent>in this paper we consider the so-called weighted extended (top-down) tree transducers (wxtts for short).
</prevsent>
</prevsection>
<citsent citstr=" N04-1014 ">
wxtts have been proposed by graehl and knight (2004) <papid> N04-1014 </papid>and knight (2007)and are rooted in similar devices introduced earlier in the formal language literature (arnold and dauchet, 1982).</citsent>
<aftsection>
<nextsent>wxtts have enough expressivity to represent hierarchical syntactic analyses for natural language sentences and can directly model most of the elementary operations that rule the process of translation between natural languages (knight,2007).
</nextsent>
<nextsent>furthermore, the use of weights and internal states allows the encoding of statistical parameters that have recently been shown to be extremely useful in discriminating likely translations from less plausible ones.for an wxtt , the parsing problem is traditionally defined for pair of trees and andre quires as output some representation of the set of all computations ofm that map into u. similarly,the translation problem form is defined for an input tree and requires as output some representation of the set of all computations of mapping financially supported by the ministerio de educacion ciencia (mec) grant jdci-2007-760.
</nextsent>
<nextsent>into any other tree.
</nextsent>
<nextsent>when we deal with natural language processing applications, however, parsing and translation are most often represented on the basis of input strings rather than trees.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4796">
<title id=" W10-2503.xml">parsing and translation algorithms based on weighted extended tree transducers </title>
<section> weighted extended tree transducers.  </section>
<citcontext>
<prevsection>
<prevsent>to keep the presentation simple, we also construct nonstandard wxtts in the sequel.
</prevsent>
<prevsent>however, we implicitly assume that those are converted into standard wxtts.the semantics of standard wxtt is inspired by the initial-algebra semantics for classical weighted top-down and bottom-up tree transducers (fulop and vogler, 2009) [also called topdown and bottom-up tree series transducers by engelfriet et al (2002)].
</prevsent>
</prevsection>
<citsent citstr=" J08-3004 ">
note that our semantic sis equivalent to the classical term rewriting semantics, which is presented by graehl and knight (2004) <papid> N04-1014 </papid>and graehl et al (2008), <papid> J08-3004 </papid>for example.</citsent>
<aftsection>
<nextsent>in fact, we will present an equivalent semantics based on runs later.
</nextsent>
<nextsent>let = (q,?,?, i, r) be awxtt.
</nextsent>
<nextsent>we present definition that is more general than immediately necessary, but the generalization will be useful later on.
</nextsent>
<nextsent>for every ? n, p1, . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4797">
<title id=" W10-2503.xml">parsing and translation algorithms based on weighted extended tree transducers </title>
<section> input and output restrictions of wxtt.  </section>
<citcontext>
<prevsection>
<prevsent>then the input product transducer mw = prod(nw,m) provides compact representation of the set of all computations of that translate the string w. from corollary 5 we have that the weights of these computations are also preserved.
</prevsent>
<prevsent>thus, mw(t? ? t?) = ?
</prevsent>
</prevsection>
<citsent citstr=" D09-1005 ">
(t,u)tt? mw(t, u) is the weight of the set of string translations of w.as usual in natural language processing applications, we can exploit appropriate semi rings and compute several useful statistical parameters through mw(t? ? t?), as for instance the highest weight of computation, the inside probability and the rule expectations; see (li and eisner, 2009) <papid> D09-1005 </papid>for further discussion.</citsent>
<aftsection>
<nextsent>one could also construct in linear time the range tree automaton for mw, which can be interpret edas parsing forest with all the weighted trees assigned to translations of under . if we further assume thatm is unambiguous, thenmw will also have this property, and we can apply standard techniques to extract from mw the highest score computation.
</nextsent>
<nextsent>in machine translation applications, the un ambiguity assumption is usually met, and avoids the so-called spurious?
</nextsent>
<nextsent>ambiguity, that is, having several computations for an individual pair of trees.
</nextsent>
<nextsent>the parsing problem for input strings and can be treated in similar way, by restricting both to the left and to the right.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4798">
<title id=" W10-2503.xml">parsing and translation algorithms based on weighted extended tree transducers </title>
<section> rule factor ization.  </section>
<citcontext>
<prevsection>
<prevsent>as already discussed, the time complexity of the product construction is an exponential function of the rank of the transducer.
</prevsent>
<prevsent>unfortunately, it is not possible in the general case to cast 23 wxtt into normal form such that the rank is bounded by some constant.
</prevsent>
</prevsection>
<citsent citstr=" H05-1101 ">
this is also expected from the fact that the translation problem for subclasses of wxtts such as synchronous context free grammars is np-hard (satta and peserico, 2005).<papid> H05-1101 </papid></citsent>
<aftsection>
<nextsent>nonetheless, there are cases in which rank reduction is possible, which might result in an improvement of the asymptotical run-time of our construction.
</nextsent>
<nextsent>following the above line, we present here linear time algorithm for reducing the rank of awxtt under certain conditions.
</nextsent>
<nextsent>similar algorithms for tree-based transformation devices have been discussed in the literature.
</nextsent>
<nextsent>nesson et al(2008) consider synchronous tree adjoining grammars; their algorithm is conceptually very similar to ours, but computationally more demanding due to the treatment of adjunction.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4799">
<title id=" W10-2503.xml">parsing and translation algorithms based on weighted extended tree transducers </title>
<section> rule factor ization.  </section>
<citcontext>
<prevsection>
<prevsent>the recursive structure of the input wxtt, as formalized below.
</prevsent>
<prevsent>galley et al (2004) algorithm also behaves in linear time, but deals with the different problem of tree to stringtranslation.
</prevsent>
</prevsection>
<citsent citstr=" N06-1033 ">
rank reduction algorithms for string based translation devices have also been discussed by zhang et al (2006) <papid> N06-1033 </papid>and gildea et al (2006).<papid> P06-2036 </papid></citsent>
<aftsection>
<nextsent>recall that = (q,?,?, i, r) is standard wxtt.
</nextsent>
<nextsent>let ? = (q?,?,?, ?, r?)
</nextsent>
<nextsent>be wxtt with ? q?.3 then ? is structure-preserving factor ization of if ? ?(q) = i(q) for every ? and ?(q) = 0 otherwise, and ? hp1pnr?
</nextsent>
<nextsent>(t, u)q = p1pn (t, u)q for every q, p1, . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4800">
<title id=" W10-2503.xml">parsing and translation algorithms based on weighted extended tree transducers </title>
<section> rule factor ization.  </section>
<citcontext>
<prevsection>
<prevsent>the recursive structure of the input wxtt, as formalized below.
</prevsent>
<prevsent>galley et al (2004) algorithm also behaves in linear time, but deals with the different problem of tree to stringtranslation.
</prevsent>
</prevsection>
<citsent citstr=" P06-2036 ">
rank reduction algorithms for string based translation devices have also been discussed by zhang et al (2006) <papid> N06-1033 </papid>and gildea et al (2006).<papid> P06-2036 </papid></citsent>
<aftsection>
<nextsent>recall that = (q,?,?, i, r) is standard wxtt.
</nextsent>
<nextsent>let ? = (q?,?,?, ?, r?)
</nextsent>
<nextsent>be wxtt with ? q?.3 then ? is structure-preserving factor ization of if ? ?(q) = i(q) for every ? and ?(q) = 0 otherwise, and ? hp1pnr?
</nextsent>
<nextsent>(t, u)q = p1pn (t, u)q for every q, p1, . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4801">
<title id=" W10-3208.xml">sentiwordnet for indian languages </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a number of automatic, semi-automatic and manual valid ations and evaluation methodologies have been adopted to measure the coverage and credibility of the developed sentiwordnet(s).
</prevsent>
<prevsent>sentiment analysis and classification from electronic text is hard semantic disambiguation problem.
</prevsent>
</prevsection>
<citsent citstr=" W02-1011 ">
the regulating aspects of semantic orientation of text are natural language context information (pang et al , 2002) <papid> W02-1011 </papid>language properties (wiebe and mihalcea, 2006), <papid> P06-1134 </papid>domain pragmatic knowledge (aue and ga mon, 2005) and lastly most challenging is the time dimension (read, 2005).<papid> P05-2008 </papid></citsent>
<aftsection>
<nextsent>the following example shows that the polarity tag associated with sentiment word depends on the time dimension.
</nextsent>
<nextsent>during 90s mobile phone users generally reported in various online reviews about their color phones but in recent times color phone is not just enough.
</nextsent>
<nextsent>people are fascinated and influenced by touch screen and various software(s) installation facilities on these new generation gadgets.
</nextsent>
<nextsent>in typical computational approaches (higa shinaka et al , 2007; hatzivassiloglou et al , 2000) to sentiment analysis researchers consider the problem of learning dictionary that maps semantic representations to verbaliza tions, where the data comes from opinionated electronic text.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4802">
<title id=" W10-3208.xml">sentiwordnet for indian languages </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a number of automatic, semi-automatic and manual valid ations and evaluation methodologies have been adopted to measure the coverage and credibility of the developed sentiwordnet(s).
</prevsent>
<prevsent>sentiment analysis and classification from electronic text is hard semantic disambiguation problem.
</prevsent>
</prevsection>
<citsent citstr=" P06-1134 ">
the regulating aspects of semantic orientation of text are natural language context information (pang et al , 2002) <papid> W02-1011 </papid>language properties (wiebe and mihalcea, 2006), <papid> P06-1134 </papid>domain pragmatic knowledge (aue and ga mon, 2005) and lastly most challenging is the time dimension (read, 2005).<papid> P05-2008 </papid></citsent>
<aftsection>
<nextsent>the following example shows that the polarity tag associated with sentiment word depends on the time dimension.
</nextsent>
<nextsent>during 90s mobile phone users generally reported in various online reviews about their color phones but in recent times color phone is not just enough.
</nextsent>
<nextsent>people are fascinated and influenced by touch screen and various software(s) installation facilities on these new generation gadgets.
</nextsent>
<nextsent>in typical computational approaches (higa shinaka et al , 2007; hatzivassiloglou et al , 2000) to sentiment analysis researchers consider the problem of learning dictionary that maps semantic representations to verbaliza tions, where the data comes from opinionated electronic text.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4803">
<title id=" W10-3208.xml">sentiwordnet for indian languages </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a number of automatic, semi-automatic and manual valid ations and evaluation methodologies have been adopted to measure the coverage and credibility of the developed sentiwordnet(s).
</prevsent>
<prevsent>sentiment analysis and classification from electronic text is hard semantic disambiguation problem.
</prevsent>
</prevsection>
<citsent citstr=" P05-2008 ">
the regulating aspects of semantic orientation of text are natural language context information (pang et al , 2002) <papid> W02-1011 </papid>language properties (wiebe and mihalcea, 2006), <papid> P06-1134 </papid>domain pragmatic knowledge (aue and ga mon, 2005) and lastly most challenging is the time dimension (read, 2005).<papid> P05-2008 </papid></citsent>
<aftsection>
<nextsent>the following example shows that the polarity tag associated with sentiment word depends on the time dimension.
</nextsent>
<nextsent>during 90s mobile phone users generally reported in various online reviews about their color phones but in recent times color phone is not just enough.
</nextsent>
<nextsent>people are fascinated and influenced by touch screen and various software(s) installation facilities on these new generation gadgets.
</nextsent>
<nextsent>in typical computational approaches (higa shinaka et al , 2007; hatzivassiloglou et al , 2000) to sentiment analysis researchers consider the problem of learning dictionary that maps semantic representations to verbaliza tions, where the data comes from opinionated electronic text.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4804">
<title id=" W10-3208.xml">sentiwordnet for indian languages </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper we propose several computational techniques to generate sentiment lexicons in indian languages automatically and semiautomatically.
</prevsent>
<prevsent>in the present task, sentiword 56 net(s) are being developed for the bengali, hindi and telugu languages.
</prevsent>
</prevsection>
<citsent citstr=" H05-1044 ">
several prior polarity sentiment lexicons are available for english such as sentiwordnet (esuli et. al., 2006), subjectivity word list (wilson et. al., 2005), <papid> H05-1044 </papid>wordnet affect list (strapparava et al , 2004), taboadas adjective list (taboada et al , 2006).</citsent>
<aftsection>
<nextsent>among these publicly available sentiment lexicon resources we find that sentiwordnet is most widely used (number of citation is higher than other resources1) in several applications such as sentiment analysis, opinion mining and emotion analysis.
</nextsent>
<nextsent>subjectivity word list is most tru stable as the opinion mining system opinionfinder2 that uses the subjectivity word list has reported highest score for opi nion/sentiment subjectivity (wiebe and riloff, 2006).
</nextsent>
<nextsent>sentiwordnet is an automatically constructed lexical resource for english that assigns positivity score and negativity score to each wordnet synset.
</nextsent>
<nextsent>the subjectivity word list is compiled from manually developed resources augmented with entries learned from corpora.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4805">
<title id=" W10-3208.xml">sentiwordnet for indian languages </title>
<section> related works.  </section>
<citcontext>
<prevsection>
<prevsent>the first type contains the semantically contrasting word pairs but the second type includes orthographic suffix/affix as clue.
</prevsent>
<prevsent>the second type is highly productive using very less number of affix ation rules.
</prevsent>
</prevsection>
<citsent citstr=" D08-1103 ">
degree of antonymy (mohammad et al , 2008) <papid> D08-1103 </papid>is defined to encompass the complete semantic range as combined measure of the contrast in meaning conveyed by two antonymy words and is identified by distributional hypothesis.</citsent>
<aftsection>
<nextsent>it helps to measure relative sentiment score of word and its antonym.
</nextsent>
<nextsent>kumaran et al , (2008) introduced beautiful method for automatic data creation by on line intuitive games.
</nextsent>
<nextsent>a methodology has been 57 proposed for community creation of linguistic data by community collaborative framework known as wikibabel3.
</nextsent>
<nextsent>it may be described as revolutionary approach to automatically create large credible linguistic data by involving internet population for content creation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4806">
<title id=" W10-2108.xml">cross lingual variation of light verb constructions using parallel corpora and automatic alignment for linguistic research </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there is also interest in using parallel corpora to automatically develop new annotated linguistic resources by projecting the annotation that already exists in one language (usually english) (pado?, 2007; basili etal., 2009).
</prevsent>
<prevsent>such resources can be used for training systems for automatic parsing for different languages.
</prevsent>
</prevsection>
<citsent citstr=" N09-1010 ">
recently, parallel multilingual corpora have also been used to improve performance in mono-lingual tasks (snyder et al, 2009).<papid> N09-1010 </papid>for most of these applications, the aligned sentences in the parallel corpora need to be analysed into smaller units (phrases and words), which, inturn, need to be aligned.</citsent>
<aftsection>
<nextsent>although crucial for successful use of parallel corpora, word (and phrase) alignment is still challenging task (och and ney, 2003; <papid> J03-1002 </papid>collins et al, 2005; <papid> P05-1066 </papid>pado?, 2007).our research concentrates on one type of construction that needs special treatment in the taskof aligning corpora and projecting linguistic annotation from one language to another, namely light verb constructions.</nextsent>
<nextsent>these constructions, usually identified as paraphrases of verbs (e.g. have laugh means laugh, give talk means talk), are frequent, cross-lingually productive forms, where simple-minded parallelism often breaksdown.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4807">
<title id=" W10-2108.xml">cross lingual variation of light verb constructions using parallel corpora and automatic alignment for linguistic research </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>such resources can be used for training systems for automatic parsing for different languages.
</prevsent>
<prevsent>recently, parallel multilingual corpora have also been used to improve performance in mono-lingual tasks (snyder et al, 2009).<papid> N09-1010 </papid>for most of these applications, the aligned sentences in the parallel corpora need to be analysed into smaller units (phrases and words), which, inturn, need to be aligned.</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
although crucial for successful use of parallel corpora, word (and phrase) alignment is still challenging task (och and ney, 2003; <papid> J03-1002 </papid>collins et al, 2005; <papid> P05-1066 </papid>pado?, 2007).our research concentrates on one type of construction that needs special treatment in the taskof aligning corpora and projecting linguistic annotation from one language to another, namely light verb constructions.</citsent>
<aftsection>
<nextsent>these constructions, usually identified as paraphrases of verbs (e.g. have laugh means laugh, give talk means talk), are frequent, cross-lingually productive forms, where simple-minded parallelism often breaksdown.
</nextsent>
<nextsent>their meaning is partially uncomposi tional, formed in conventional way, which means that they cannot be analysed as regular constructions and that they cannot be translated to another language directly word by word.
</nextsent>
<nextsent>unlike collocations and idioms, however, these constructions are formed according to the same semi-productivepattern in different languages.
</nextsent>
<nextsent>due to their cross lingual analysability, they can be expected to be aligned at the word level in parallel corpus, even if their components are not direct word-to-word translations of each other.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4808">
<title id=" W10-2108.xml">cross lingual variation of light verb constructions using parallel corpora and automatic alignment for linguistic research </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>such resources can be used for training systems for automatic parsing for different languages.
</prevsent>
<prevsent>recently, parallel multilingual corpora have also been used to improve performance in mono-lingual tasks (snyder et al, 2009).<papid> N09-1010 </papid>for most of these applications, the aligned sentences in the parallel corpora need to be analysed into smaller units (phrases and words), which, inturn, need to be aligned.</prevsent>
</prevsection>
<citsent citstr=" P05-1066 ">
although crucial for successful use of parallel corpora, word (and phrase) alignment is still challenging task (och and ney, 2003; <papid> J03-1002 </papid>collins et al, 2005; <papid> P05-1066 </papid>pado?, 2007).our research concentrates on one type of construction that needs special treatment in the taskof aligning corpora and projecting linguistic annotation from one language to another, namely light verb constructions.</citsent>
<aftsection>
<nextsent>these constructions, usually identified as paraphrases of verbs (e.g. have laugh means laugh, give talk means talk), are frequent, cross-lingually productive forms, where simple-minded parallelism often breaksdown.
</nextsent>
<nextsent>their meaning is partially uncomposi tional, formed in conventional way, which means that they cannot be analysed as regular constructions and that they cannot be translated to another language directly word by word.
</nextsent>
<nextsent>unlike collocations and idioms, however, these constructions are formed according to the same semi-productivepattern in different languages.
</nextsent>
<nextsent>due to their cross lingual analysability, they can be expected to be aligned at the word level in parallel corpus, even if their components are not direct word-to-word translations of each other.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4809">
<title id=" W10-2108.xml">cross lingual variation of light verb constructions using parallel corpora and automatic alignment for linguistic research </title>
<section> two types of light verb constructions.  </section>
<citcontext>
<prevsection>
<prevsent>they are better seen as two ends of continuum of verb usages with different degrees of verbs?
</prevsent>
<prevsent>lightness and different degrees of compositionality of the meaning of constructions.
</prevsent>
</prevsection>
<citsent citstr=" W04-0401 ">
(stevenson et al, 2004; <papid> W04-0401 </papid>butt and geuder, 2001; grimshaw and mester, 1988).</citsent>
<aftsection>
<nextsent>even though several english verbs have been identified as having light usages (e.g. take,make, have, give, pay), there has been little research on the influence that the properties of the heading light verb can have on the degree of semantic compositionality of the construction.the purpose of the present research is to examine the german translation equivalents of the rangeof different english light verb constructions occur ring in parallel corpus and study the differential performance of standard aligner on this language pair for these constructions.
</nextsent>
<nextsent>our study is based on the assumption that the quality and bijectivity of the alignment are proportional to the corpus frequency and linguistic com positionality of the construction.
</nextsent>
<nextsent>therefore, we identify two aspects of the alignment of these constructions as the relevant objects of study.first, we quantify the amount and nature of correct word alignments for light verb constructions compared to regular verbs, as determined by human inspection.
</nextsent>
<nextsent>given the described divergences between english and german, it can be expected that light verb constructions will be aligned with single word more often than constructions headed by regular verb.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4819">
<title id=" W10-1822.xml">proposal for mwe annotation in running text </title>
<section> mwe lexicon.  </section>
<citcontext>
<prevsection>
<prevsent>for each of those several examples are collected from the corpus.
</prevsent>
<prevsent>each mwe entry is also assigned 1more infomation at: http://multiword.sourceforge.net/ 2mwe lexicon: http://www.clul.ul.pt/sectores/linguistica de corpus/manual combinatorias online.php 152to one or multiple word lemmas, of total number of 1180 single word lemmas.
</prevsent>
</prevsection>
<citsent citstr=" J90-1003 ">
the mwe were selected from sorted list of n-grams based on the mutual information measure (church and hanks, 1990) <papid> J90-1003 </papid>and validated manually (mendes etal., 2006; antunes et al, 2006; bacelar do nascimento et al, 2006).</citsent>
<aftsection>
<nextsent>in this section we discuss our approach to the annotation of mwes in the corpus.
</nextsent>
<nextsent>4.1 typology.
</nextsent>
<nextsent>we want to classify each idiomatic mwe occurring in the cintil corpus according to typology that expresses the typical properties of the mwe.
</nextsent>
<nextsent>although the lexicon of mwes covers wide range of units, from idiomatic expression sto collocations, we decided to restrict our annotation of the corpus to cases of idiomatic mwes because those are the problematic ones for any task of semantic annotation and disambiguation.the mwe lexicon does not provide labels for idiomatic vs. compositional expressions, so this information will have to be added during the annotation task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4820">
<title id=" W10-0911.xml">machine reading at the university of washington </title>
<section> summary of progress to date.  </section>
<citcontext>
<prevsection>
<prevsent>dashed lines signify influence and solid lines signify dataflow.
</prevsent>
<prevsent>at the top are the years of publications.
</prevsent>
</prevsection>
<citsent citstr=" H05-1043 ">
shopbot learns comparison shopping agents via self-supervision using heuristic knowledge (doorenbos et al, 1997); wien induces wrappers for information extraction via self-supervision using joint inference to combine simple atomic extractors (kushmerick et al, 1997); mulder answers factoid questions by leveraging redundancy to rank candidate answers extracted from multiple search query results (kwok et al, 2001); knowitall conducts open-domain information extraction via self supervision bootstrapping from hearst patterns (etzioni et al, 2005); opine builds on knowitall and mines product reviews via self-supervision using joint inference over neighborhood features (popescu and etzioni, 2005); <papid> H05-1043 </papid>kylin pop ulates wikipedia info boxes via self-supervision bootstrapping from existing info boxes (wu and weld, 2007); lex conducts web-scale name entity recognition by leveraging collocation statistics (downey et al, 2007<papid> P07-1088 </papid>a); realm improves sparse open-domain information extraction via relational clustering and language modeling (downey et al,2007<papid> P07-1088 </papid>b); re solver performs entity and relation resolution via relational clustering (yates and etzioni, 2007); <papid> N07-1016 </papid>tex trunner conducts open-domain information extraction via self-supervision bootstrapping from heuristic rules (bankoet al, 2007); aucontraire automatically identifies contradictory statements in large web corpus using functional relations (ritter et al, 2008); <papid> D08-1002 </papid>holmes infers new facts from text runner output using markov logic (schoenmackers et al, 2008); kog learns rich ontology by combining wikipedia info boxes with wordnet via joint inference using markov logic networks (wu and weld, 2008), shrinkage over this ontology vastly improves the recall of kylins extractors; ucr performs state-of-the-art unsupervised coreference resolution by incorporating small amount of domain knowledge and conducting joint inference among entity mentions with markov logic (poon and domingos, 2008<papid> D08-1068 </papid>b); sne constructs semantic network over text runner output via relational clustering with markov logic (kok and domingos, 2008); web tables conducts web-scale information extraction by leveraging html table structures (cafarella et al, 2008); iia learns from info boxes to filter open-domain information extraction toward assertions that are interesting to people (lin et al, 2009); usp jointly learns semantic parser and extracts knowledge via recursive relational clustering with markov logic (poon and domingos, 2009); <papid> D09-1001 </papid>lda-sp automatically infers compact representation describing the plausible arguments for relation using an lda-style model and bayesian inference (ritter et al, 2010); loft builds on usp and jointly performs ontology induction, population, and knowledge extraction via joint recursive relational clustering and shrinkage with markov logic (poon and domingos, 2010); olpi improves the efficiency of lifted probabilistic inference and learning via coarse-to-fine inference based on type hierarchies (kiddon and domingos, 2010).</citsent>
<aftsection>
<nextsent>sherlock induces new inference rules via relational learning (schoenmackers et al, 2010); srl-ie conducts open-domain information extraction by bootstrapping from semantic role labels, prec hybrid is hybrid version between srl-ie and text runner, which given budget of computation time does better than either system (christensen et al, 2010); woe builds on kylin and conducts open-domain information extraction (wu and weld, 2010); wpe learns 5000 relational extractors by bootstrapping from wikipedia and using web lists to generate dynamic, relation-specific lexicon features (hoffmann et al, 2010).
</nextsent>
<nextsent>91 text runner, kylin, kog, woe, wpe).
</nextsent>
<nextsent>another uses unsupervised learning and often takes particular form of relational clustering (e.g., objects associated with similar relations tend to be the same and vice versa, as in realm, re solver, sne, ucr, usp, lda-sp, loft, etc.).some distinctive types of self-supervision include shrinkage based on an ontology (kog,loft, olpi), probabilistic inference via handcrafted or learned inference patterns (holmes, sher lock), and co training using relation-specific and relation-independent (open) extraction to reinforce semantic coherence (wu et al, 2008).
</nextsent>
<nextsent>a key direction for future work is to develop unifying framework for self-supervised learning by combining the strengths of existing methods and overcoming their limitations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4821">
<title id=" W10-0911.xml">machine reading at the university of washington </title>
<section> summary of progress to date.  </section>
<citcontext>
<prevsection>
<prevsent>dashed lines signify influence and solid lines signify dataflow.
</prevsent>
<prevsent>at the top are the years of publications.
</prevsent>
</prevsection>
<citsent citstr=" P07-1088 ">
shopbot learns comparison shopping agents via self-supervision using heuristic knowledge (doorenbos et al, 1997); wien induces wrappers for information extraction via self-supervision using joint inference to combine simple atomic extractors (kushmerick et al, 1997); mulder answers factoid questions by leveraging redundancy to rank candidate answers extracted from multiple search query results (kwok et al, 2001); knowitall conducts open-domain information extraction via self supervision bootstrapping from hearst patterns (etzioni et al, 2005); opine builds on knowitall and mines product reviews via self-supervision using joint inference over neighborhood features (popescu and etzioni, 2005); <papid> H05-1043 </papid>kylin pop ulates wikipedia info boxes via self-supervision bootstrapping from existing info boxes (wu and weld, 2007); lex conducts web-scale name entity recognition by leveraging collocation statistics (downey et al, 2007<papid> P07-1088 </papid>a); realm improves sparse open-domain information extraction via relational clustering and language modeling (downey et al,2007<papid> P07-1088 </papid>b); re solver performs entity and relation resolution via relational clustering (yates and etzioni, 2007); <papid> N07-1016 </papid>tex trunner conducts open-domain information extraction via self-supervision bootstrapping from heuristic rules (bankoet al, 2007); aucontraire automatically identifies contradictory statements in large web corpus using functional relations (ritter et al, 2008); <papid> D08-1002 </papid>holmes infers new facts from text runner output using markov logic (schoenmackers et al, 2008); kog learns rich ontology by combining wikipedia info boxes with wordnet via joint inference using markov logic networks (wu and weld, 2008), shrinkage over this ontology vastly improves the recall of kylins extractors; ucr performs state-of-the-art unsupervised coreference resolution by incorporating small amount of domain knowledge and conducting joint inference among entity mentions with markov logic (poon and domingos, 2008<papid> D08-1068 </papid>b); sne constructs semantic network over text runner output via relational clustering with markov logic (kok and domingos, 2008); web tables conducts web-scale information extraction by leveraging html table structures (cafarella et al, 2008); iia learns from info boxes to filter open-domain information extraction toward assertions that are interesting to people (lin et al, 2009); usp jointly learns semantic parser and extracts knowledge via recursive relational clustering with markov logic (poon and domingos, 2009); <papid> D09-1001 </papid>lda-sp automatically infers compact representation describing the plausible arguments for relation using an lda-style model and bayesian inference (ritter et al, 2010); loft builds on usp and jointly performs ontology induction, population, and knowledge extraction via joint recursive relational clustering and shrinkage with markov logic (poon and domingos, 2010); olpi improves the efficiency of lifted probabilistic inference and learning via coarse-to-fine inference based on type hierarchies (kiddon and domingos, 2010).</citsent>
<aftsection>
<nextsent>sherlock induces new inference rules via relational learning (schoenmackers et al, 2010); srl-ie conducts open-domain information extraction by bootstrapping from semantic role labels, prec hybrid is hybrid version between srl-ie and text runner, which given budget of computation time does better than either system (christensen et al, 2010); woe builds on kylin and conducts open-domain information extraction (wu and weld, 2010); wpe learns 5000 relational extractors by bootstrapping from wikipedia and using web lists to generate dynamic, relation-specific lexicon features (hoffmann et al, 2010).
</nextsent>
<nextsent>91 text runner, kylin, kog, woe, wpe).
</nextsent>
<nextsent>another uses unsupervised learning and often takes particular form of relational clustering (e.g., objects associated with similar relations tend to be the same and vice versa, as in realm, re solver, sne, ucr, usp, lda-sp, loft, etc.).some distinctive types of self-supervision include shrinkage based on an ontology (kog,loft, olpi), probabilistic inference via handcrafted or learned inference patterns (holmes, sher lock), and co training using relation-specific and relation-independent (open) extraction to reinforce semantic coherence (wu et al, 2008).
</nextsent>
<nextsent>a key direction for future work is to develop unifying framework for self-supervised learning by combining the strengths of existing methods and overcoming their limitations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4823">
<title id=" W10-0911.xml">machine reading at the university of washington </title>
<section> summary of progress to date.  </section>
<citcontext>
<prevsection>
<prevsent>dashed lines signify influence and solid lines signify dataflow.
</prevsent>
<prevsent>at the top are the years of publications.
</prevsent>
</prevsection>
<citsent citstr=" N07-1016 ">
shopbot learns comparison shopping agents via self-supervision using heuristic knowledge (doorenbos et al, 1997); wien induces wrappers for information extraction via self-supervision using joint inference to combine simple atomic extractors (kushmerick et al, 1997); mulder answers factoid questions by leveraging redundancy to rank candidate answers extracted from multiple search query results (kwok et al, 2001); knowitall conducts open-domain information extraction via self supervision bootstrapping from hearst patterns (etzioni et al, 2005); opine builds on knowitall and mines product reviews via self-supervision using joint inference over neighborhood features (popescu and etzioni, 2005); <papid> H05-1043 </papid>kylin pop ulates wikipedia info boxes via self-supervision bootstrapping from existing info boxes (wu and weld, 2007); lex conducts web-scale name entity recognition by leveraging collocation statistics (downey et al, 2007<papid> P07-1088 </papid>a); realm improves sparse open-domain information extraction via relational clustering and language modeling (downey et al,2007<papid> P07-1088 </papid>b); re solver performs entity and relation resolution via relational clustering (yates and etzioni, 2007); <papid> N07-1016 </papid>tex trunner conducts open-domain information extraction via self-supervision bootstrapping from heuristic rules (bankoet al, 2007); aucontraire automatically identifies contradictory statements in large web corpus using functional relations (ritter et al, 2008); <papid> D08-1002 </papid>holmes infers new facts from text runner output using markov logic (schoenmackers et al, 2008); kog learns rich ontology by combining wikipedia info boxes with wordnet via joint inference using markov logic networks (wu and weld, 2008), shrinkage over this ontology vastly improves the recall of kylins extractors; ucr performs state-of-the-art unsupervised coreference resolution by incorporating small amount of domain knowledge and conducting joint inference among entity mentions with markov logic (poon and domingos, 2008<papid> D08-1068 </papid>b); sne constructs semantic network over text runner output via relational clustering with markov logic (kok and domingos, 2008); web tables conducts web-scale information extraction by leveraging html table structures (cafarella et al, 2008); iia learns from info boxes to filter open-domain information extraction toward assertions that are interesting to people (lin et al, 2009); usp jointly learns semantic parser and extracts knowledge via recursive relational clustering with markov logic (poon and domingos, 2009); <papid> D09-1001 </papid>lda-sp automatically infers compact representation describing the plausible arguments for relation using an lda-style model and bayesian inference (ritter et al, 2010); loft builds on usp and jointly performs ontology induction, population, and knowledge extraction via joint recursive relational clustering and shrinkage with markov logic (poon and domingos, 2010); olpi improves the efficiency of lifted probabilistic inference and learning via coarse-to-fine inference based on type hierarchies (kiddon and domingos, 2010).</citsent>
<aftsection>
<nextsent>sherlock induces new inference rules via relational learning (schoenmackers et al, 2010); srl-ie conducts open-domain information extraction by bootstrapping from semantic role labels, prec hybrid is hybrid version between srl-ie and text runner, which given budget of computation time does better than either system (christensen et al, 2010); woe builds on kylin and conducts open-domain information extraction (wu and weld, 2010); wpe learns 5000 relational extractors by bootstrapping from wikipedia and using web lists to generate dynamic, relation-specific lexicon features (hoffmann et al, 2010).
</nextsent>
<nextsent>91 text runner, kylin, kog, woe, wpe).
</nextsent>
<nextsent>another uses unsupervised learning and often takes particular form of relational clustering (e.g., objects associated with similar relations tend to be the same and vice versa, as in realm, re solver, sne, ucr, usp, lda-sp, loft, etc.).some distinctive types of self-supervision include shrinkage based on an ontology (kog,loft, olpi), probabilistic inference via handcrafted or learned inference patterns (holmes, sher lock), and co training using relation-specific and relation-independent (open) extraction to reinforce semantic coherence (wu et al, 2008).
</nextsent>
<nextsent>a key direction for future work is to develop unifying framework for self-supervised learning by combining the strengths of existing methods and overcoming their limitations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4824">
<title id=" W10-0911.xml">machine reading at the university of washington </title>
<section> summary of progress to date.  </section>
<citcontext>
<prevsection>
<prevsent>dashed lines signify influence and solid lines signify dataflow.
</prevsent>
<prevsent>at the top are the years of publications.
</prevsent>
</prevsection>
<citsent citstr=" D08-1002 ">
shopbot learns comparison shopping agents via self-supervision using heuristic knowledge (doorenbos et al, 1997); wien induces wrappers for information extraction via self-supervision using joint inference to combine simple atomic extractors (kushmerick et al, 1997); mulder answers factoid questions by leveraging redundancy to rank candidate answers extracted from multiple search query results (kwok et al, 2001); knowitall conducts open-domain information extraction via self supervision bootstrapping from hearst patterns (etzioni et al, 2005); opine builds on knowitall and mines product reviews via self-supervision using joint inference over neighborhood features (popescu and etzioni, 2005); <papid> H05-1043 </papid>kylin pop ulates wikipedia info boxes via self-supervision bootstrapping from existing info boxes (wu and weld, 2007); lex conducts web-scale name entity recognition by leveraging collocation statistics (downey et al, 2007<papid> P07-1088 </papid>a); realm improves sparse open-domain information extraction via relational clustering and language modeling (downey et al,2007<papid> P07-1088 </papid>b); re solver performs entity and relation resolution via relational clustering (yates and etzioni, 2007); <papid> N07-1016 </papid>tex trunner conducts open-domain information extraction via self-supervision bootstrapping from heuristic rules (bankoet al, 2007); aucontraire automatically identifies contradictory statements in large web corpus using functional relations (ritter et al, 2008); <papid> D08-1002 </papid>holmes infers new facts from text runner output using markov logic (schoenmackers et al, 2008); kog learns rich ontology by combining wikipedia info boxes with wordnet via joint inference using markov logic networks (wu and weld, 2008), shrinkage over this ontology vastly improves the recall of kylins extractors; ucr performs state-of-the-art unsupervised coreference resolution by incorporating small amount of domain knowledge and conducting joint inference among entity mentions with markov logic (poon and domingos, 2008<papid> D08-1068 </papid>b); sne constructs semantic network over text runner output via relational clustering with markov logic (kok and domingos, 2008); web tables conducts web-scale information extraction by leveraging html table structures (cafarella et al, 2008); iia learns from info boxes to filter open-domain information extraction toward assertions that are interesting to people (lin et al, 2009); usp jointly learns semantic parser and extracts knowledge via recursive relational clustering with markov logic (poon and domingos, 2009); <papid> D09-1001 </papid>lda-sp automatically infers compact representation describing the plausible arguments for relation using an lda-style model and bayesian inference (ritter et al, 2010); loft builds on usp and jointly performs ontology induction, population, and knowledge extraction via joint recursive relational clustering and shrinkage with markov logic (poon and domingos, 2010); olpi improves the efficiency of lifted probabilistic inference and learning via coarse-to-fine inference based on type hierarchies (kiddon and domingos, 2010).</citsent>
<aftsection>
<nextsent>sherlock induces new inference rules via relational learning (schoenmackers et al, 2010); srl-ie conducts open-domain information extraction by bootstrapping from semantic role labels, prec hybrid is hybrid version between srl-ie and text runner, which given budget of computation time does better than either system (christensen et al, 2010); woe builds on kylin and conducts open-domain information extraction (wu and weld, 2010); wpe learns 5000 relational extractors by bootstrapping from wikipedia and using web lists to generate dynamic, relation-specific lexicon features (hoffmann et al, 2010).
</nextsent>
<nextsent>91 text runner, kylin, kog, woe, wpe).
</nextsent>
<nextsent>another uses unsupervised learning and often takes particular form of relational clustering (e.g., objects associated with similar relations tend to be the same and vice versa, as in realm, re solver, sne, ucr, usp, lda-sp, loft, etc.).some distinctive types of self-supervision include shrinkage based on an ontology (kog,loft, olpi), probabilistic inference via handcrafted or learned inference patterns (holmes, sher lock), and co training using relation-specific and relation-independent (open) extraction to reinforce semantic coherence (wu et al, 2008).
</nextsent>
<nextsent>a key direction for future work is to develop unifying framework for self-supervised learning by combining the strengths of existing methods and overcoming their limitations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4825">
<title id=" W10-0911.xml">machine reading at the university of washington </title>
<section> summary of progress to date.  </section>
<citcontext>
<prevsection>
<prevsent>dashed lines signify influence and solid lines signify dataflow.
</prevsent>
<prevsent>at the top are the years of publications.
</prevsent>
</prevsection>
<citsent citstr=" D08-1068 ">
shopbot learns comparison shopping agents via self-supervision using heuristic knowledge (doorenbos et al, 1997); wien induces wrappers for information extraction via self-supervision using joint inference to combine simple atomic extractors (kushmerick et al, 1997); mulder answers factoid questions by leveraging redundancy to rank candidate answers extracted from multiple search query results (kwok et al, 2001); knowitall conducts open-domain information extraction via self supervision bootstrapping from hearst patterns (etzioni et al, 2005); opine builds on knowitall and mines product reviews via self-supervision using joint inference over neighborhood features (popescu and etzioni, 2005); <papid> H05-1043 </papid>kylin pop ulates wikipedia info boxes via self-supervision bootstrapping from existing info boxes (wu and weld, 2007); lex conducts web-scale name entity recognition by leveraging collocation statistics (downey et al, 2007<papid> P07-1088 </papid>a); realm improves sparse open-domain information extraction via relational clustering and language modeling (downey et al,2007<papid> P07-1088 </papid>b); re solver performs entity and relation resolution via relational clustering (yates and etzioni, 2007); <papid> N07-1016 </papid>tex trunner conducts open-domain information extraction via self-supervision bootstrapping from heuristic rules (bankoet al, 2007); aucontraire automatically identifies contradictory statements in large web corpus using functional relations (ritter et al, 2008); <papid> D08-1002 </papid>holmes infers new facts from text runner output using markov logic (schoenmackers et al, 2008); kog learns rich ontology by combining wikipedia info boxes with wordnet via joint inference using markov logic networks (wu and weld, 2008), shrinkage over this ontology vastly improves the recall of kylins extractors; ucr performs state-of-the-art unsupervised coreference resolution by incorporating small amount of domain knowledge and conducting joint inference among entity mentions with markov logic (poon and domingos, 2008<papid> D08-1068 </papid>b); sne constructs semantic network over text runner output via relational clustering with markov logic (kok and domingos, 2008); web tables conducts web-scale information extraction by leveraging html table structures (cafarella et al, 2008); iia learns from info boxes to filter open-domain information extraction toward assertions that are interesting to people (lin et al, 2009); usp jointly learns semantic parser and extracts knowledge via recursive relational clustering with markov logic (poon and domingos, 2009); <papid> D09-1001 </papid>lda-sp automatically infers compact representation describing the plausible arguments for relation using an lda-style model and bayesian inference (ritter et al, 2010); loft builds on usp and jointly performs ontology induction, population, and knowledge extraction via joint recursive relational clustering and shrinkage with markov logic (poon and domingos, 2010); olpi improves the efficiency of lifted probabilistic inference and learning via coarse-to-fine inference based on type hierarchies (kiddon and domingos, 2010).</citsent>
<aftsection>
<nextsent>sherlock induces new inference rules via relational learning (schoenmackers et al, 2010); srl-ie conducts open-domain information extraction by bootstrapping from semantic role labels, prec hybrid is hybrid version between srl-ie and text runner, which given budget of computation time does better than either system (christensen et al, 2010); woe builds on kylin and conducts open-domain information extraction (wu and weld, 2010); wpe learns 5000 relational extractors by bootstrapping from wikipedia and using web lists to generate dynamic, relation-specific lexicon features (hoffmann et al, 2010).
</nextsent>
<nextsent>91 text runner, kylin, kog, woe, wpe).
</nextsent>
<nextsent>another uses unsupervised learning and often takes particular form of relational clustering (e.g., objects associated with similar relations tend to be the same and vice versa, as in realm, re solver, sne, ucr, usp, lda-sp, loft, etc.).some distinctive types of self-supervision include shrinkage based on an ontology (kog,loft, olpi), probabilistic inference via handcrafted or learned inference patterns (holmes, sher lock), and co training using relation-specific and relation-independent (open) extraction to reinforce semantic coherence (wu et al, 2008).
</nextsent>
<nextsent>a key direction for future work is to develop unifying framework for self-supervised learning by combining the strengths of existing methods and overcoming their limitations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4826">
<title id=" W10-0911.xml">machine reading at the university of washington </title>
<section> summary of progress to date.  </section>
<citcontext>
<prevsection>
<prevsent>dashed lines signify influence and solid lines signify dataflow.
</prevsent>
<prevsent>at the top are the years of publications.
</prevsent>
</prevsection>
<citsent citstr=" D09-1001 ">
shopbot learns comparison shopping agents via self-supervision using heuristic knowledge (doorenbos et al, 1997); wien induces wrappers for information extraction via self-supervision using joint inference to combine simple atomic extractors (kushmerick et al, 1997); mulder answers factoid questions by leveraging redundancy to rank candidate answers extracted from multiple search query results (kwok et al, 2001); knowitall conducts open-domain information extraction via self supervision bootstrapping from hearst patterns (etzioni et al, 2005); opine builds on knowitall and mines product reviews via self-supervision using joint inference over neighborhood features (popescu and etzioni, 2005); <papid> H05-1043 </papid>kylin pop ulates wikipedia info boxes via self-supervision bootstrapping from existing info boxes (wu and weld, 2007); lex conducts web-scale name entity recognition by leveraging collocation statistics (downey et al, 2007<papid> P07-1088 </papid>a); realm improves sparse open-domain information extraction via relational clustering and language modeling (downey et al,2007<papid> P07-1088 </papid>b); re solver performs entity and relation resolution via relational clustering (yates and etzioni, 2007); <papid> N07-1016 </papid>tex trunner conducts open-domain information extraction via self-supervision bootstrapping from heuristic rules (bankoet al, 2007); aucontraire automatically identifies contradictory statements in large web corpus using functional relations (ritter et al, 2008); <papid> D08-1002 </papid>holmes infers new facts from text runner output using markov logic (schoenmackers et al, 2008); kog learns rich ontology by combining wikipedia info boxes with wordnet via joint inference using markov logic networks (wu and weld, 2008), shrinkage over this ontology vastly improves the recall of kylins extractors; ucr performs state-of-the-art unsupervised coreference resolution by incorporating small amount of domain knowledge and conducting joint inference among entity mentions with markov logic (poon and domingos, 2008<papid> D08-1068 </papid>b); sne constructs semantic network over text runner output via relational clustering with markov logic (kok and domingos, 2008); web tables conducts web-scale information extraction by leveraging html table structures (cafarella et al, 2008); iia learns from info boxes to filter open-domain information extraction toward assertions that are interesting to people (lin et al, 2009); usp jointly learns semantic parser and extracts knowledge via recursive relational clustering with markov logic (poon and domingos, 2009); <papid> D09-1001 </papid>lda-sp automatically infers compact representation describing the plausible arguments for relation using an lda-style model and bayesian inference (ritter et al, 2010); loft builds on usp and jointly performs ontology induction, population, and knowledge extraction via joint recursive relational clustering and shrinkage with markov logic (poon and domingos, 2010); olpi improves the efficiency of lifted probabilistic inference and learning via coarse-to-fine inference based on type hierarchies (kiddon and domingos, 2010).</citsent>
<aftsection>
<nextsent>sherlock induces new inference rules via relational learning (schoenmackers et al, 2010); srl-ie conducts open-domain information extraction by bootstrapping from semantic role labels, prec hybrid is hybrid version between srl-ie and text runner, which given budget of computation time does better than either system (christensen et al, 2010); woe builds on kylin and conducts open-domain information extraction (wu and weld, 2010); wpe learns 5000 relational extractors by bootstrapping from wikipedia and using web lists to generate dynamic, relation-specific lexicon features (hoffmann et al, 2010).
</nextsent>
<nextsent>91 text runner, kylin, kog, woe, wpe).
</nextsent>
<nextsent>another uses unsupervised learning and often takes particular form of relational clustering (e.g., objects associated with similar relations tend to be the same and vice versa, as in realm, re solver, sne, ucr, usp, lda-sp, loft, etc.).some distinctive types of self-supervision include shrinkage based on an ontology (kog,loft, olpi), probabilistic inference via handcrafted or learned inference patterns (holmes, sher lock), and co training using relation-specific and relation-independent (open) extraction to reinforce semantic coherence (wu et al, 2008).
</nextsent>
<nextsent>a key direction for future work is to develop unifying framework for self-supervised learning by combining the strengths of existing methods and overcoming their limitations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4828">
<title id=" W10-0731.xml">amazon mechanical turk for subjectivity word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the annotation process to obtain this data is very laborious and expensive.
</prevsent>
<prevsent>this makes supervised nlp systems subject to so-called knowledge acquisition bottle neck.
</prevsent>
</prevsection>
<citsent citstr=" W97-0201 ">
for example, (ng, 1997) <papid> W97-0201 </papid>estimates an effort of16 person years to construct training data for high accuracy domain independent word sense disambiguation (wsd) system.</citsent>
<aftsection>
<nextsent>recently researchers have been investigating amazon mechanical turk (mturk) as source of non-expert natural language annotation, which is cheap and quick alternative to expert annotations (kaisser and lowe, 2008; <papid> L08-1307 </papid>mrozinski et al, 2008).<papid> P08-1051 </papid></nextsent>
<nextsent>in this paper, we utilize mturk to obtain training data for subjectivity word sense disambiguation (swsd) as described in (akkaya et al, 2009).<papid> D09-1020 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4829">
<title id=" W10-0731.xml">amazon mechanical turk for subjectivity word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this makes supervised nlp systems subject to so-called knowledge acquisition bottle neck.
</prevsent>
<prevsent>for example, (ng, 1997) <papid> W97-0201 </papid>estimates an effort of16 person years to construct training data for high accuracy domain independent word sense disambiguation (wsd) system.</prevsent>
</prevsection>
<citsent citstr=" L08-1307 ">
recently researchers have been investigating amazon mechanical turk (mturk) as source of non-expert natural language annotation, which is cheap and quick alternative to expert annotations (kaisser and lowe, 2008; <papid> L08-1307 </papid>mrozinski et al, 2008).<papid> P08-1051 </papid></citsent>
<aftsection>
<nextsent>in this paper, we utilize mturk to obtain training data for subjectivity word sense disambiguation (swsd) as described in (akkaya et al, 2009).<papid> D09-1020 </papid></nextsent>
<nextsent>the goal of swsd is to automatically determine which word instances in corpus are being used with subjective senses, and which are being used with objective senses.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4830">
<title id=" W10-0731.xml">amazon mechanical turk for subjectivity word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this makes supervised nlp systems subject to so-called knowledge acquisition bottle neck.
</prevsent>
<prevsent>for example, (ng, 1997) <papid> W97-0201 </papid>estimates an effort of16 person years to construct training data for high accuracy domain independent word sense disambiguation (wsd) system.</prevsent>
</prevsection>
<citsent citstr=" P08-1051 ">
recently researchers have been investigating amazon mechanical turk (mturk) as source of non-expert natural language annotation, which is cheap and quick alternative to expert annotations (kaisser and lowe, 2008; <papid> L08-1307 </papid>mrozinski et al, 2008).<papid> P08-1051 </papid></citsent>
<aftsection>
<nextsent>in this paper, we utilize mturk to obtain training data for subjectivity word sense disambiguation (swsd) as described in (akkaya et al, 2009).<papid> D09-1020 </papid></nextsent>
<nextsent>the goal of swsd is to automatically determine which word instances in corpus are being used with subjective senses, and which are being used with objective senses.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4831">
<title id=" W10-0731.xml">amazon mechanical turk for subjectivity word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, (ng, 1997) <papid> W97-0201 </papid>estimates an effort of16 person years to construct training data for high accuracy domain independent word sense disambiguation (wsd) system.</prevsent>
<prevsent>recently researchers have been investigating amazon mechanical turk (mturk) as source of non-expert natural language annotation, which is cheap and quick alternative to expert annotations (kaisser and lowe, 2008; <papid> L08-1307 </papid>mrozinski et al, 2008).<papid> P08-1051 </papid></prevsent>
</prevsection>
<citsent citstr=" D09-1020 ">
in this paper, we utilize mturk to obtain training data for subjectivity word sense disambiguation (swsd) as described in (akkaya et al, 2009).<papid> D09-1020 </papid></citsent>
<aftsection>
<nextsent>the goal of swsd is to automatically determine which word instances in corpus are being used with subjective senses, and which are being used with objective senses.
</nextsent>
<nextsent>swsd is new task which suffers from the absence of substantial amount of annotated data and thus can only be applied on small scale.
</nextsent>
<nextsent>swsd has strong connections to wsd.
</nextsent>
<nextsent>like supervised wsd, it requires training data where target word instances ? words which need to be dis ambiguated by the system ? are labeled as having an objective sense or subjective sense.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4839">
<title id=" W10-0731.xml">amazon mechanical turk for subjectivity word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we hypothesize that annotations for swsd can be provided by non-experts reliably if the annotation task is presented in simple way.
</prevsent>
<prevsent>the annotations obtained from mturk workers are noisy by nature, because mturk workers are not trained for the underlying annotation task.
</prevsent>
</prevsection>
<citsent citstr=" D08-1027 ">
that is why previous work explored methods to assess annotation quality and to aggregate multiple noisy annotations for high reliability (snow et al, 2008; <papid> D08-1027 </papid>callison-burch, 2009).</citsent>
<aftsection>
<nextsent>it is understandable that not every worker will provide high-quality annotations, 195depending on their background and interest.
</nextsent>
<nextsent>unfortunately, some mturk workers do not follow the annotation guidelines and carelessly submit annotations in order to gain economic benefits with only minimal effort.
</nextsent>
<nextsent>we define this group of worker sas spammers.
</nextsent>
<nextsent>we believe it is essential to distinguish between workers as well-meaning annotators and workers as spam mers who should be filtered out as first step when utilizing mturk.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4844">
<title id=" W10-0731.xml">amazon mechanical turk for subjectivity word sense disambiguation </title>
<section> word sense subjectivity.  </section>
<citcontext>
<prevsection>
<prevsent>(an estimated quantity) figure 1: subjective and objective word sense examples.techniques such as majority voting among the submissions can be used to aggregate the results for some types of hits, resulting in higher-quality final answer.
</prevsent>
<prevsent>previous work (snow et al, 2008) <papid> D08-1027 </papid>demonstrates that aggregating worker submissions often leads to an increase in quality.</prevsent>
</prevsection>
<citsent citstr=" P06-1134 ">
(wiebe and mihalcea, 2006) <papid> P06-1134 </papid>define subjective expressions as words and phrases being used to express mental and emotional states, such as speculations, evaluations, sentiments, and beliefs.</citsent>
<aftsection>
<nextsent>many approaches to sentiment and subjectivity analysis relyon lexicons of such words (subjectivity clues).
</nextsent>
<nextsent>however, such clues often have both subjective and objective senses, as illustrated by (wiebe and mihalcea, 2006).<papid> P06-1134 </papid></nextsent>
<nextsent>figure 1 provides subjective and objective examples of senses.(akkaya et al, 2009) <papid> D09-1020 </papid>points out that most subjectivity lexicons are compiled as lists of keywords,rather than word meanings (senses).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4878">
<title id=" W10-0731.xml">amazon mechanical turk for subjectivity word sense disambiguation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>(snow et al, 2008) <papid> D08-1027 </papid>report mturk annotation quality on various nlp tasks (e.g. wsd, textual entailment, word similarity) and definea bias correction method for non-expert annota tors.</prevsent>
<prevsent>(callison-burch, 2009) uses mturk workers for manual evaluation of automatic translation quality and experiments with weighed voting to combine multiple annotations.</prevsent>
</prevsection>
<citsent citstr=" W09-1904 ">
(hsueh et al, 2009) <papid> W09-1904 </papid>define various annotation quality measures and show that they are useful for selecting annotations leading to more accurate classifiers.</citsent>
<aftsection>
<nextsent>our work investigates the effect of built-in qualifications on the quality of mturk annotations.(hsueh et al, 2009) <papid> W09-1904 </papid>applies mturk to get sentiment annotations on political blog snippets.</nextsent>
<nextsent>(snowet al, 2008) <papid> D08-1027 </papid>utilizes mturk for affective text annotation task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4887">
<title id=" W10-2201.xml">instance based acquisition of vowel harmony </title>
<section> explaining phonological patterns.  </section>
<citcontext>
<prevsection>
<prevsent>indicates that speakers?
</prevsent>
<prevsent>knowledge and use of language, both in production and comprehension, is at least partly episodic, or instance-based (goldinger, 1996; johnson, 1997).
</prevsent>
</prevsection>
<citsent citstr=" J94-3007 ">
additionally, 1 daelemans et al (1994) <papid> J94-3007 </papid>is notable exception.motivation for instance-based models of categorisation has lengthy history in cognitive psychology (medin and schaffer, 1978), and these methods are well-known in the statistical and machine learning literature, having been studied for over half century (fix and hodges, 1951; cover and hart, 1967; hastie et al, 2009).</citsent>
<aftsection>
<nextsent>consequently, itseems worthy endeavour applying an instance based method to problem that is of interest to traditional phonologists, the acquisition and use of vowel harmony, while simultaneously effecting rapprochement with adjacent disicplines in the cognitive sciences.
</nextsent>
<nextsent>in sections 2 and 3 give some brief background on vowel harmony and instance based models, respectively.
</nextsent>
<nextsent>section 4 introduces my model, libphon, and section 5 the languages it learns.
</nextsent>
<nextsent>i discuss some simulations and results in section 6, and conclude in section 7.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4888">
<title id=" W10-1808.xml">to annotate more accurately or to annotate more </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>acorpus where each instance is annotated by single tagger unavoidably contains errors.
</prevsent>
<prevsent>to im prove the quality of the data, an annotation project may choose to annotate each instance twice and adjudicate the disagreements, thus producing the (largely) error-free gold standard.
</prevsent>
</prevsection>
<citsent citstr=" N06-2015 ">
for example,ontonotes (hovy et al, 2006), <papid> N06-2015 </papid>large-scale annotation project, chose this option.</citsent>
<aftsection>
<nextsent>however, given virtually unlimited supply of unlabeled data and limited funding ? typical set of constraints in nlp ? an annotation project must always face the realization that for the cost of double annotation, more than twice as much data can be single annotated.
</nextsent>
<nextsent>the philosophy behind this alternative says that modern machine learning algorithms can still generalize well in the presence of noise, especially when given larger amounts of training data.
</nextsent>
<nextsent>currently, the commonly accepted wisdom sides with the view that says that blind double annotation followed by adjudication of disagreements is necessary to create annotated corpora that leads to the best possible performance.
</nextsent>
<nextsent>we provide empirical evidence that this is unlikely to bethe case.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4889">
<title id=" W10-1808.xml">to annotate more accurately or to annotate more </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>rather, the greatest value for your annotation dollar lies in single annotating more data.
</prevsent>
<prevsent>there may, however, be other considerations that still argue in favor of double annotation.
</prevsent>
</prevsection>
<citsent citstr=" P09-1032 ">
in this paper, we also consider the arguments of beigman and klebanov (2009), <papid> P09-1032 </papid>who suggest that data should be multiply annotated and then filtered to discard all of the examples where the annotators do not have perfect agreement.</citsent>
<aftsection>
<nextsent>we provide evidence that single annotating more data for thesame cost is likely to result in better system per formance.this paper proceeds as follows: first, we out line our evaluation framework in section 2.
</nextsent>
<nextsent>next,we compare the single annotation and adjudication scenarios in section 3.
</nextsent>
<nextsent>then, we compare the annotation scenario of beigman and klebanov(2009) <papid> P09-1032 </papid>with the single annotation scenario in section 4.</nextsent>
<nextsent>after that, we discuss the results and future work in section 5.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4891">
<title id=" W10-1808.xml">to annotate more accurately or to annotate more </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>2.3 automatic word sense disambiguation.
</prevsent>
<prevsent>for the experiments we conduct in this study, we needed word sense disambiguation (wsd) system.
</prevsent>
</prevsection>
<citsent citstr=" P08-2008 ">
our wsd system is modeled after the state of-the-art verb wsd system described in (dligach and palmer, 2008).<papid> P08-2008 </papid></citsent>
<aftsection>
<nextsent>we will briefly outline it here.we view wsd as supervised learning problem.
</nextsent>
<nextsent>each instance of the target verb is represent edas vector of binary features that indicate the presence (or absence) of the corresponding features in the neighborhood of the target verb.
</nextsent>
<nextsent>we utilize all of the linguistic features that were shown to be useful for disambiguating verb senses in (chen et al., 2007).
</nextsent>
<nextsent>to extract the lexical features we pos-tag the sentence containing the target verb and thetwo surrounding sentences using mxpost software (ratnaparkhi, 1998).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4895">
<title id=" W10-1808.xml">to annotate more accurately or to annotate more </title>
<section> discussion and future work.  </section>
<citcontext>
<prevsection>
<prevsent>on the other hand, when the unlabeled data is not freely obtainable, double annotation may be more suitable as route to improving system performance.
</prevsent>
<prevsent>there may also be factors other than cost-effectiveness which make double annotation desirable.
</prevsent>
</prevsection>
<citsent citstr=" J08-4004 ">
many projects point to their ita rates and corresponding kappa values as measure of annotation quality, and of the reliability of the annotators (artstein and poesio, 2008).<papid> J08-4004 </papid></citsent>
<aftsection>
<nextsent>the ontonotes project used ita rates as way of evaluating the clarity of the sense inventory that was being developed in parallel with the annotation.
</nextsent>
<nextsent>lexical entries that resulted in low ita rates were revised, usually improving the ita rate.
</nextsent>
<nextsent>calculating these rates requires double-blind annotation.
</nextsent>
<nextsent>annotators who consistently produced ita rates lower than average were also removed from theproject.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4896">
<title id=" W10-2916.xml">a semi supervised batch mode active learning strategy for improved statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they also propose technique,based on tf-idf, to de-emphasize sentences similar to those that have already been selected.
</prevsent>
<prevsent>however, this strategy is boot strapped by random initial choices that do not necessarily favor sentences that are difficult to translate.
</prevsent>
</prevsection>
<citsent citstr=" N09-1047 ">
finally, they work exclusively with the source language and do not use any smt-derived features to guide selection.haffari et al (2009) <papid> N09-1047 </papid>propose number of features, such as similarity to the seed corpus, translation probability, relative frequencies of n-grams and phrases?</citsent>
<aftsection>
<nextsent>in the seed vs. pool data, etc., for active learning.
</nextsent>
<nextsent>while many of their experiments use the above features independently to compare their relative efficacy, one of their experiments attempts to predict rank, as linear combination of these features, for each candidate sentence.
</nextsent>
<nextsent>the top-ranked sentences are chosen for manualtranslation.
</nextsent>
<nextsent>the latter strategy is particularly relevant to this paper, because the goal of our active 126 learning strategy is not to compare features, but to learn the trade-off between various characteristics of the candidate sentences that potentially maximizes translation improvement.the parameters of the linear ranking model proposed by haffari et al (2009) <papid> N09-1047 </papid>are trained using two held-out development sets d1 and d2 - the model attempts to learn the ordering of d1 that incrementally maximizes translation performance on d2.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4900">
<title id=" W10-2916.xml">a semi supervised batch mode active learning strategy for improved statistical machine translation </title>
<section> active learning architecture.  </section>
<citcontext>
<prevsection>
<prevsent>we begin by randomly sampling small fraction of the large monolingual pool to create pool training set pt, which is used to train the learner.
</prevsent>
<prevsent>the remainder, which we call the pool evaluation set pe, is set aside for active selection.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
we also train an initial phrase-based smt system(koehn et al, 2003) <papid> N03-1017 </papid>with the available seed cor pus.</citsent>
<aftsection>
<nextsent>the pool training set pt, in conjunction withthe seed corpus s, initial smt system, and held out development set d, is used to derive number of input features as well as target labels for training two parallel classifiers.
</nextsent>
<nextsent>3.1 preferred ordering.
</nextsent>
<nextsent>the learner must be able to map input features to an ordering of the pool sentences that attempts to maximize coverage on an unseen test set.
</nextsent>
<nextsent>we teach it to do this by providing it with an ordering of pt that incrementally maximizes source coverage on d. this preferred ordering algorithm incrementally maps sentences in pt to ordered set ot by picking, at each iteration, the sentence with the highest coverage criterion with respect to d, and inserting it at the current position within ot.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4901">
<title id=" W10-2916.xml">a semi supervised batch mode active learning strategy for improved statistical machine translation </title>
<section> active learning architecture.  </section>
<citcontext>
<prevsection>
<prevsent>sentences in conversational domains are typically short, while those in web and newswire domains run longer.
</prevsent>
<prevsent>3.2.2 translation difficulty all else being equal, the selection strategy should favor sentences that the existing smt system finds difficult to translate.
</prevsent>
</prevsection>
<citsent citstr=" C04-1046 ">
to this end, we estimate confidence score for each smt hypothesis, usinga discriminative classification framework reminiscent of blatz et al (2004).<papid> C04-1046 </papid></citsent>
<aftsection>
<nextsent>confidence estimation is treated as binary classification problem,where each hypothesized word is labeled cor rect?
</nextsent>
<nextsent>or incorrect?.
</nextsent>
<nextsent>word-level reference labels for training the classifier are obtained from translation edit rate (ter) analysis, which produces the lowest-cost alignment between the hypotheses and the gold-standard references (snover et al., 2006).
</nextsent>
<nextsent>a hypothesized word is correct?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4902">
<title id=" W10-2916.xml">a semi supervised batch mode active learning strategy for improved statistical machine translation </title>
<section> experimental setup and results.  </section>
<citcontext>
<prevsection>
<prevsent>at the end of 30 iterations, the bleu score gained 2.46 points, relative improvement of 45.9%.
</prevsent>
<prevsent>by contrast, the nearest competitor was the random selection baseline, whose performance gained only 1.33 points in bleu, 24.8% improvement.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
note that we tune the phrase-based smt feature weights using mert (och, 2003) <papid> P03-1021 </papid>once in the beginning, and use the same weights across all iterations.</citsent>
<aftsection>
<nextsent>this allowed us to compare selection methods without variations introduced by fluctuation of the weights.
</nextsent>
<nextsent>131 (a) trajectory of bleu (b) trajectory of untranslated word ratio (c) directionality match (d) diversity/uniqueness figure 2: simulation results for data selection.
</nextsent>
<nextsent>batch size at each iteration is 200 sentences.
</nextsent>
<nextsent>132 the second method measures test set coverage in terms of the proportion of untranslated words in the smt hypotheses, which arise due to the absence of appropriate in-context phrase pairs inthe training data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4903">
<title id=" W10-2005.xml">the role of memory in superiority violation gradience </title>
<section> methodology.  </section>
<citcontext>
<prevsection>
<prevsent>table 6 provides list of the nominal intervenors considered.
</prevsent>
<prevsent>gibsons hierarchy is extended to include nominal wh-words to more accurately model the experimental conditions.
</prevsent>
</prevsection>
<citsent citstr=" W04-0308 ">
intervenor pos example nn book nns books prp they nnp pat nnps americans wp-what what wp-who who wdt-which which book wdt-what what book table 6: pos for nominal intervenors.the sequence of stack next features are sensitive to the parsers memory, in the form of the pos of elements at varying depths of the stack.these features are found to have high overall accuracy in the nivre parser (nivre, 2004) <papid> W04-0308 </papid>and in human sentence processing modeling (boston et al, 2008).<papid> P08-2002 </papid>activation, interference, andre trieval predictions are based on the sequence of lewis &amp; vasisth (2005) calculations provided in equations 1-4.</citsent>
<aftsection>
<nextsent>these equations require some notion of duration, which is calculated as function of parser actions and word retrieval times.
</nextsent>
<nextsent>table 7 describes this calculation, motivated by the production rule time in lewis &amp; vasisths act-r model.
</nextsent>
<nextsent>transition time left 50 ms + 50 ms + retrieval time right 50 ms + 50 ms + retrieval time shift 50ms reduce 0ms table 7: how time is determined in the parser.
</nextsent>
<nextsent>because only words at the top of the stack can be retrieved, the following will be described for 1 . retrieval time for 1 is based on its activation a, calculated as in equation 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4904">
<title id=" W10-2005.xml">the role of memory in superiority violation gradience </title>
<section> methodology.  </section>
<citcontext>
<prevsection>
<prevsent>table 6 provides list of the nominal intervenors considered.
</prevsent>
<prevsent>gibsons hierarchy is extended to include nominal wh-words to more accurately model the experimental conditions.
</prevsent>
</prevsection>
<citsent citstr=" P08-2002 ">
intervenor pos example nn book nns books prp they nnp pat nnps americans wp-what what wp-who who wdt-which which book wdt-what what book table 6: pos for nominal intervenors.the sequence of stack next features are sensitive to the parsers memory, in the form of the pos of elements at varying depths of the stack.these features are found to have high overall accuracy in the nivre parser (nivre, 2004) <papid> W04-0308 </papid>and in human sentence processing modeling (boston et al, 2008).<papid> P08-2002 </papid>activation, interference, andre trieval predictions are based on the sequence of lewis &amp; vasisth (2005) calculations provided in equations 1-4.</citsent>
<aftsection>
<nextsent>these equations require some notion of duration, which is calculated as function of parser actions and word retrieval times.
</nextsent>
<nextsent>table 7 describes this calculation, motivated by the production rule time in lewis &amp; vasisths act-r model.
</nextsent>
<nextsent>transition time left 50 ms + 50 ms + retrieval time right 50 ms + 50 ms + retrieval time shift 50ms reduce 0ms table 7: how time is determined in the parser.
</nextsent>
<nextsent>because only words at the top of the stack can be retrieved, the following will be described for 1 . retrieval time for 1 is based on its activation a, calculated as in equation 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4905">
<title id=" W10-2005.xml">the role of memory in superiority violation gradience </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>despite their similarity, none of these features are able to model the attachment behavior in the experimental data.
</prevsent>
<prevsent>the stack3next feature differs from the other features in that it allows the leftarc attachment to occur in any of the conditions.
</prevsent>
</prevsection>
<citsent citstr=" N01-1021 ">
although this does not match the interpretation of the experimental results followed in this paper, it leaves open the possibility that the feature could model the data according to different measure of parsing difficulty, such as surprisal (hale, 2001).<papid> N01-1021 </papid></citsent>
<aftsection>
<nextsent>the relmin constraint is not able to model the experimental results for gradience.
</nextsent>
<nextsent>the results demonstrate that modeling the experimental data for suv gradience requires parser that can vary memory resources as well as be sensitive to the types of the nominal intervenors currently in memory.
</nextsent>
<nextsent>the gradience is modeled by increasing memory resources, in the form of increases in the beam-width.
</nextsent>
<nextsent>this demonstrates the usefulness of varying both the types and amounts of memory resources available in computational model of human sentence processing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4906">
<title id=" W10-1750.xml">document level automatic mt evaluation based on discourse representations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for that purpose we take advantage of two coincidental facts.
</prevsent>
<prevsent>first, test beds employed in recent mt evaluation campaigns include document structure grouping sentences related to the same event, story or topic (przybocki et al, 2008; przybocki et al, 2009; callison-burch et al, 2009).
</prevsent>
</prevsection>
<citsent citstr=" P07-2009 ">
second, we count on automatic linguistic processors which provide very detailed discourse level representations of text (curran et al, 2007).<papid> P07-2009 </papid></citsent>
<aftsection>
<nextsent>discourse representations allow us to focus on relevant pieces of information, such as the agent 1a segment typically consists of one or two sentences.
</nextsent>
<nextsent>(who), location (where), time (when), and theme (what), which may be spread all over the text.
</nextsent>
<nextsent>counting on means of discerning the events, the individuals taking part in each of them, and their role, is crucial to determine the semantic equivalence between reference document and candidate translation.
</nextsent>
<nextsent>moreover, the discourse analysis of document is not mere concatenation of the analyses of its individual sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4908">
<title id=" W10-1750.xml">document level automatic mt evaluation based on discourse representations </title>
<section> metric description.  </section>
<citcontext>
<prevsection>
<prevsent>2.2 definition of similarity measures.
</prevsent>
<prevsent>in this work, as first proposal, instead of elaborating on novel similarity measures, we have borrowed and extended the discourse representation (dr) metrics defined by gimenez and ma`rquez(2009).
</prevsent>
</prevsection>
<citsent citstr=" W08-2222 ">
these metrics analyze similarities between automatic and reference translations by comparing their respective discourse representations over individual sentences.for the discursive analysis of texts, dr metrics relyon the c&c; tools (curran et al, 2007), <papid> P07-2009 </papid>specifically on the boxer component (bos, 2008).<papid> W08-2222 </papid>this software is based on the discourse representation theory (drt) by kamp and reyle (1993).drt is theoretical framework offering representation language for the examination of contextually dependent meaning in discourse.</citsent>
<aftsection>
<nextsent>a discourse is represented in discourse representation structure (drs), which is essentially variation of first-order predicate calculus its forms are pairs 334 of first-order formulae and the free variables that occur in them.
</nextsent>
<nextsent>drss are viewed as semantic trees, built through the application of two types of drs con ditions:basic conditions: one-place properties (pred icates), two-place properties (relations), named entities, time-expressions, cardinal expressions and equalities.
</nextsent>
<nextsent>complex conditions: disjunction, implication, negation, question, and propositional attitude operations.
</nextsent>
<nextsent>for instance, the drs representation for the sentence every man loves mary.?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4909">
<title id=" W10-1750.xml">document level automatic mt evaluation based on discourse representations </title>
<section> metric description.  </section>
<citcontext>
<prevsection>
<prevsent>is as follows: named(y,mary, per) ?
</prevsent>
<prevsent>(x man(x) ? love(z) ? event(z) ? agent(z, x) ? patient(z, y)).
</prevsent>
</prevsection>
<citsent citstr=" W05-0904 ">
dr integrates three different kinds of metrics:dr-stm these metrics are similar to the syntactic tree matching metric defined by liu and gildea (2005), <papid> W05-0904 </papid>in this case applied to drssinstead of constituent trees.</citsent>
<aftsection>
<nextsent>all semantic sub paths in the candidate and reference trees are retrieved.
</nextsent>
<nextsent>the fraction of matching sub paths of given length (l=4 in our experiments) is computed.dr-or(?)
</nextsent>
<nextsent>average lexical overlap between discourse representation structures of the same type.
</nextsent>
<nextsent>overlap is measured according to the formulae and definitions by gimenez and ma`rquez (2007).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4910">
<title id=" W10-1750.xml">document level automatic mt evaluation based on discourse representations </title>
<section> experimental work.  </section>
<citcontext>
<prevsection>
<prevsent>we have computed pearson, spearman and kendall correlation coefficients between metric scores and adequacy assessments.
</prevsent>
<prevsent>document level and system-level assessments have been obtained by averaging over segment-level assessments.
</prevsent>
</prevsection>
<citsent citstr=" W04-3250 ">
we have computed correlation coefficient sand confidence intervals applying bootstrap re sampling at 99% statistical significance (efron and tibshirani, 1986; koehn, 2004).<papid> W04-3250 </papid></citsent>
<aftsection>
<nextsent>since the cost of exhaustive re sampling was prohibitive, wehave limited to 1,000 resamplings.
</nextsent>
<nextsent>confidence intervals, not shown in the tables, are in all cases lower than 103.
</nextsent>
<nextsent>3.2 metric performance.
</nextsent>
<nextsent>table 1 shows correlation coefficients at the document level for several dr metric representatives, and their document-level counterparts (drdoc).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4911">
<title id=" W10-3204.xml">sequential tagging of semantic roles on chinese framenet </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>semantic parsing is important in natural language processing, and it has attracted an increasing number of studies in recent years.
</prevsent>
<prevsent>currently, its most important aspect is the formalization of the proposition meaning of one sentence through the semantic role labeling.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
therefore, many large human-annotated corpora have been constructed to support related research, such as framenet (baker et al, 1998), <papid> P98-1013 </papid>propbank (kings bury and palmer, 2002), nombank (meyers et al,2004), and so on.</citsent>
<aftsection>
<nextsent>on this basis, several international semantic evaluations have been organized, which include senseval 3 (litkowski, 2004), semeval 2007 (baker,et al, 2007), <papid> W07-2018 </papid>conll 2008 (surdeanu et al, 2008), <papid> W08-2121 </papid>conll 2009 (hajic et al, 2009), and so on.the first srl model on framenet was proposed by gildea and jurafsky(2002).<papid> J02-3001 </papid></nextsent>
<nextsent>the model consists of two subtasks of boundary identifica tion(bi) and semantic role classification(src).both subtasks were implemented on the pretreatment results of the full parsing tree.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4912">
<title id=" W10-3204.xml">sequential tagging of semantic roles on chinese framenet </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>currently, its most important aspect is the formalization of the proposition meaning of one sentence through the semantic role labeling.
</prevsent>
<prevsent>therefore, many large human-annotated corpora have been constructed to support related research, such as framenet (baker et al, 1998), <papid> P98-1013 </papid>propbank (kings bury and palmer, 2002), nombank (meyers et al,2004), and so on.</prevsent>
</prevsection>
<citsent citstr=" W07-2018 ">
on this basis, several international semantic evaluations have been organized, which include senseval 3 (litkowski, 2004), semeval 2007 (baker,et al, 2007), <papid> W07-2018 </papid>conll 2008 (surdeanu et al, 2008), <papid> W08-2121 </papid>conll 2009 (hajic et al, 2009), and so on.the first srl model on framenet was proposed by gildea and jurafsky(2002).<papid> J02-3001 </papid></citsent>
<aftsection>
<nextsent>the model consists of two subtasks of boundary identifica tion(bi) and semantic role classification(src).both subtasks were implemented on the pretreatment results of the full parsing tree.
</nextsent>
<nextsent>many lexical and syntactic features were extracted to im prove the accuracy of the model.
</nextsent>
<nextsent>on the test data of framenet, the system achieved 65% precision and 61% recall.most works on srl followed gildeas framework of processing the srl task on english framenet and propbank.
</nextsent>
<nextsent>they built their model on the full parse tree and selected features using various machine learning methods to improve the accuracy of srl models.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4913">
<title id=" W10-3204.xml">sequential tagging of semantic roles on chinese framenet </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>currently, its most important aspect is the formalization of the proposition meaning of one sentence through the semantic role labeling.
</prevsent>
<prevsent>therefore, many large human-annotated corpora have been constructed to support related research, such as framenet (baker et al, 1998), <papid> P98-1013 </papid>propbank (kings bury and palmer, 2002), nombank (meyers et al,2004), and so on.</prevsent>
</prevsection>
<citsent citstr=" W08-2121 ">
on this basis, several international semantic evaluations have been organized, which include senseval 3 (litkowski, 2004), semeval 2007 (baker,et al, 2007), <papid> W07-2018 </papid>conll 2008 (surdeanu et al, 2008), <papid> W08-2121 </papid>conll 2009 (hajic et al, 2009), and so on.the first srl model on framenet was proposed by gildea and jurafsky(2002).<papid> J02-3001 </papid></citsent>
<aftsection>
<nextsent>the model consists of two subtasks of boundary identifica tion(bi) and semantic role classification(src).both subtasks were implemented on the pretreatment results of the full parsing tree.
</nextsent>
<nextsent>many lexical and syntactic features were extracted to im prove the accuracy of the model.
</nextsent>
<nextsent>on the test data of framenet, the system achieved 65% precision and 61% recall.most works on srl followed gildeas framework of processing the srl task on english framenet and propbank.
</nextsent>
<nextsent>they built their model on the full parse tree and selected features using various machine learning methods to improve the accuracy of srl models.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4914">
<title id=" W10-3204.xml">sequential tagging of semantic roles on chinese framenet </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>currently, its most important aspect is the formalization of the proposition meaning of one sentence through the semantic role labeling.
</prevsent>
<prevsent>therefore, many large human-annotated corpora have been constructed to support related research, such as framenet (baker et al, 1998), <papid> P98-1013 </papid>propbank (kings bury and palmer, 2002), nombank (meyers et al,2004), and so on.</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
on this basis, several international semantic evaluations have been organized, which include senseval 3 (litkowski, 2004), semeval 2007 (baker,et al, 2007), <papid> W07-2018 </papid>conll 2008 (surdeanu et al, 2008), <papid> W08-2121 </papid>conll 2009 (hajic et al, 2009), and so on.the first srl model on framenet was proposed by gildea and jurafsky(2002).<papid> J02-3001 </papid></citsent>
<aftsection>
<nextsent>the model consists of two subtasks of boundary identifica tion(bi) and semantic role classification(src).both subtasks were implemented on the pretreatment results of the full parsing tree.
</nextsent>
<nextsent>many lexical and syntactic features were extracted to im prove the accuracy of the model.
</nextsent>
<nextsent>on the test data of framenet, the system achieved 65% precision and 61% recall.most works on srl followed gildeas framework of processing the srl task on english framenet and propbank.
</nextsent>
<nextsent>they built their model on the full parse tree and selected features using various machine learning methods to improve the accuracy of srl models.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4915">
<title id=" W10-2927.xml">inspecting the structural biases of dependency parsing algorithms </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we show that all four parsers are biased with respect to the kind of annotation they are trained to parse.
</prevsent>
<prevsent>we present detailed analysis of the biases that highlights specific differences and commonalities between the parsing systems, and improves our understanding of their strengths and weaknesses.
</prevsent>
</prevsection>
<citsent citstr=" D07-1096 ">
dependency parsing, the task of inferring dependency structure over an input sentence, has gained lot of research attention in the last couple of years, due in part to to the two conll shared tasks (nivre et al, 2007; <papid> D07-1096 </papid>buchholz and marsi,2006) <papid> W06-2920 </papid>in which various dependency parsing algorithms were compared on various data sets.</citsent>
<aftsection>
<nextsent>as result of this research effort, we have choice of several robust, efficient and accurate parsing algorithms.
</nextsent>
<nextsent>we would like to thank reut tsarfaty for comments and discussions that helped us improve this paper.
</nextsent>
<nextsent>this work is supported in part by the lynn and william frankel center for computer science.these different parsing systems achieve comparable scores, yet produce qualitatively different parses.
</nextsent>
<nextsent>sagae and lavie (2006) <papid> N06-2033 </papid>demonstrated thata simple combination scheme of the outputs of different parsers can obtain substantially improved accuracies.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4916">
<title id=" W10-2927.xml">inspecting the structural biases of dependency parsing algorithms </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we show that all four parsers are biased with respect to the kind of annotation they are trained to parse.
</prevsent>
<prevsent>we present detailed analysis of the biases that highlights specific differences and commonalities between the parsing systems, and improves our understanding of their strengths and weaknesses.
</prevsent>
</prevsection>
<citsent citstr=" W06-2920 ">
dependency parsing, the task of inferring dependency structure over an input sentence, has gained lot of research attention in the last couple of years, due in part to to the two conll shared tasks (nivre et al, 2007; <papid> D07-1096 </papid>buchholz and marsi,2006) <papid> W06-2920 </papid>in which various dependency parsing algorithms were compared on various data sets.</citsent>
<aftsection>
<nextsent>as result of this research effort, we have choice of several robust, efficient and accurate parsing algorithms.
</nextsent>
<nextsent>we would like to thank reut tsarfaty for comments and discussions that helped us improve this paper.
</nextsent>
<nextsent>this work is supported in part by the lynn and william frankel center for computer science.these different parsing systems achieve comparable scores, yet produce qualitatively different parses.
</nextsent>
<nextsent>sagae and lavie (2006) <papid> N06-2033 </papid>demonstrated thata simple combination scheme of the outputs of different parsers can obtain substantially improved accuracies.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4917">
<title id=" W10-2927.xml">inspecting the structural biases of dependency parsing algorithms </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we would like to thank reut tsarfaty for comments and discussions that helped us improve this paper.
</prevsent>
<prevsent>this work is supported in part by the lynn and william frankel center for computer science.these different parsing systems achieve comparable scores, yet produce qualitatively different parses.
</prevsent>
</prevsection>
<citsent citstr=" N06-2033 ">
sagae and lavie (2006) <papid> N06-2033 </papid>demonstrated thata simple combination scheme of the outputs of different parsers can obtain substantially improved accuracies.</citsent>
<aftsection>
<nextsent>nivre and mcdonald (2008) <papid> P08-1108 </papid>explore parser stacking approach in which the output of one parser is fed as an input to different kind of parser.</nextsent>
<nextsent>the stacking approach also produces more accurate parses.however, while we know how to produce accurate parsers and how to blend and stack their outputs, little effort was directed toward understanding the behavior of different parsing systems in terms of structures they produce and errors theymake.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4918">
<title id=" W10-2927.xml">inspecting the structural biases of dependency parsing algorithms </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this work is supported in part by the lynn and william frankel center for computer science.these different parsing systems achieve comparable scores, yet produce qualitatively different parses.
</prevsent>
<prevsent>sagae and lavie (2006) <papid> N06-2033 </papid>demonstrated thata simple combination scheme of the outputs of different parsers can obtain substantially improved accuracies.</prevsent>
</prevsection>
<citsent citstr=" P08-1108 ">
nivre and mcdonald (2008) <papid> P08-1108 </papid>explore parser stacking approach in which the output of one parser is fed as an input to different kind of parser.</citsent>
<aftsection>
<nextsent>the stacking approach also produces more accurate parses.however, while we know how to produce accurate parsers and how to blend and stack their outputs, little effort was directed toward understanding the behavior of different parsing systems in terms of structures they produce and errors theymake.
</nextsent>
<nextsent>question such as which linguistic phenomena are hard for parser y?
</nextsent>
<nextsent>and what kinds of errors are common for parser z?, as well as the more ambitious which parsing approach is most suitable to parse language x?, remain largely unanswered.the current work aims to fill this gap by proposing methodology to identify systematic biases in various parsing models and proposing and initial analysis of such biases.mcdonald and nivre (2007) <papid> D07-1013 </papid>analyze the difference between graph-based and transition-based parsers (specifically the malt and mst parsers) by comparing the different kinds of errors made by both parsers.</nextsent>
<nextsent>they focus on single edge errors, and learn that mst is better for longer dependency arcs while malt is better on short dependency arcs, that malt is better than mst in predicting edges further from the root and vice-versa, that malt has slight advantage when predicting the parents of nouns and pronouns, and that mst is better at all other word categories.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4919">
<title id=" W10-2927.xml">inspecting the structural biases of dependency parsing algorithms </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the stacking approach also produces more accurate parses.however, while we know how to produce accurate parsers and how to blend and stack their outputs, little effort was directed toward understanding the behavior of different parsing systems in terms of structures they produce and errors theymake.
</prevsent>
<prevsent>question such as which linguistic phenomena are hard for parser y?
</prevsent>
</prevsection>
<citsent citstr=" D07-1013 ">
and what kinds of errors are common for parser z?, as well as the more ambitious which parsing approach is most suitable to parse language x?, remain largely unanswered.the current work aims to fill this gap by proposing methodology to identify systematic biases in various parsing models and proposing and initial analysis of such biases.mcdonald and nivre (2007) <papid> D07-1013 </papid>analyze the difference between graph-based and transition-based parsers (specifically the malt and mst parsers) by comparing the different kinds of errors made by both parsers.</citsent>
<aftsection>
<nextsent>they focus on single edge errors, and learn that mst is better for longer dependency arcs while malt is better on short dependency arcs, that malt is better than mst in predicting edges further from the root and vice-versa, that malt has slight advantage when predicting the parents of nouns and pronouns, and that mst is better at all other word categories.
</nextsent>
<nextsent>they also conclude that the greedy malt parser suffer from error propagation more than the globally optimized 234 mst parser.
</nextsent>
<nextsent>in what follows, we complement their work by suggesting different methodology of analysis of parsers behaviour.
</nextsent>
<nextsent>our methodology is based onthe notion of structural bias of parsers, further explained in section 2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4920">
<title id=" W10-2927.xml">inspecting the structural biases of dependency parsing algorithms </title>
<section> structural bias.  </section>
<citcontext>
<prevsection>
<prevsent>features the number of possible predictors is exponential in the size of each tree, and an exhaustive search is impractical.
</prevsent>
<prevsent>instead, we solve the search problem using boosting algorithm for tree classification using subtree features.
</prevsent>
</prevsection>
<citsent citstr=" W04-3239 ">
the details of the algorithm and its efficient implementation are given in (kudo and matsumoto, 2004).<papid> W04-3239 </papid></citsent>
<aftsection>
<nextsent>we briefly describe the main idea behind the algorithm.
</nextsent>
<nextsent>the boosting algorithm with subtree features gets as input two parse sets with labeled, orderedtrees.
</nextsent>
<nextsent>the output of the algorithm is set of subtrees ti and their weights wi.
</nextsent>
<nextsent>these weighted subtrees define linear classifier over trees f(t ) = ? tit wi, where f(t )   0 for trees in set and f(t )   0 for trees in set b. the algorithm works in rounds.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4922">
<title id=" W10-2927.xml">inspecting the structural biases of dependency parsing algorithms </title>
<section> biases in dependency parsers.  </section>
<citcontext>
<prevsection>
<prevsent>a high classification accuracy means more structural bias between the two sets, while an accuracy of 50% or lower means that, at least under our class of predictors, the sets are structurally indistinguishable.
</prevsent>
<prevsent>3.1 experimental setup.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
in what follows, we analyze and compare the structural biases of 4 parsers, with respect to dependency representation of english.syntactic representation the dependency tree bank we use is conversion of the english wsj treebank (marcus et al, 1993) <papid> J93-2004 </papid>to dependency structure using the procedure described in (jo hansson and nugues, 2007).</citsent>
<aftsection>
<nextsent>we use the melcuk encoding of coordination structure, in which the first conjunct is the head of the coordination structure, the coordinating conjunction depends on thehead, and the second conjunct depend on the coordinating conjunction (johansson, 2008).
</nextsent>
<nextsent>data sections 15-18 were used for training the parsers3.
</nextsent>
<nextsent>the first 4,000 sentences from sections 10-11 were used to train the boosting algorithm and find structural predictors candidates.
</nextsent>
<nextsent>sections 4-7 were used as validation set for ranking the structural predictors.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4923">
<title id=" W10-2927.xml">inspecting the structural biases of dependency parsing algorithms </title>
<section> biases in dependency parsers.  </section>
<citcontext>
<prevsection>
<prevsent>in all experiments, we used the gold-standard pos tags.
</prevsent>
<prevsent>we binned the distance-to-parent values to 1,2,3,4-5,6-8 and 9+.
</prevsent>
</prevsection>
<citsent citstr=" P05-1012 ">
parsers for graph-based parsers, we usedthe projective first-order (mst1) and second order (mst2) variants of the freely available mst parser4 (mcdonald et al, 2005; <papid> P05-1012 </papid>mcdonald and pereira, 2006).<papid> E06-1011 </papid></citsent>
<aftsection>
<nextsent>for the transition-based parsers, we used the arc-eager (arce) variant of the freely available malt parser5 (nivre et al,2006), and our own implementation of an arc standard parser (arcs) as described in (huang et al., 2009).<papid> D09-1127 </papid></nextsent>
<nextsent>the unlabeled attachment accuracies of the four parsers are presented in table 1.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4924">
<title id=" W10-2927.xml">inspecting the structural biases of dependency parsing algorithms </title>
<section> biases in dependency parsers.  </section>
<citcontext>
<prevsection>
<prevsent>in all experiments, we used the gold-standard pos tags.
</prevsent>
<prevsent>we binned the distance-to-parent values to 1,2,3,4-5,6-8 and 9+.
</prevsent>
</prevsection>
<citsent citstr=" E06-1011 ">
parsers for graph-based parsers, we usedthe projective first-order (mst1) and second order (mst2) variants of the freely available mst parser4 (mcdonald et al, 2005; <papid> P05-1012 </papid>mcdonald and pereira, 2006).<papid> E06-1011 </papid></citsent>
<aftsection>
<nextsent>for the transition-based parsers, we used the arc-eager (arce) variant of the freely available malt parser5 (nivre et al,2006), and our own implementation of an arc standard parser (arcs) as described in (huang et al., 2009).<papid> D09-1127 </papid></nextsent>
<nextsent>the unlabeled attachment accuracies of the four parsers are presented in table 1.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4925">
<title id=" W10-2927.xml">inspecting the structural biases of dependency parsing algorithms </title>
<section> biases in dependency parsers.  </section>
<citcontext>
<prevsection>
<prevsent>we binned the distance-to-parent values to 1,2,3,4-5,6-8 and 9+.
</prevsent>
<prevsent>parsers for graph-based parsers, we usedthe projective first-order (mst1) and second order (mst2) variants of the freely available mst parser4 (mcdonald et al, 2005; <papid> P05-1012 </papid>mcdonald and pereira, 2006).<papid> E06-1011 </papid></prevsent>
</prevsection>
<citsent citstr=" D09-1127 ">
for the transition-based parsers, we used the arc-eager (arce) variant of the freely available malt parser5 (nivre et al,2006), and our own implementation of an arc standard parser (arcs) as described in (huang et al., 2009).<papid> D09-1127 </papid></citsent>
<aftsection>
<nextsent>the unlabeled attachment accuracies of the four parsers are presented in table 1.
</nextsent>
<nextsent>procedure for each parser, we train boosting classifier to distinguish between the gold-standard trees and the parses produced for them by the3most work on parsing english uses much larger training set.
</nextsent>
<nextsent>we chose to use smaller set for convenience.
</nextsent>
<nextsent>training the parsers is much faster, and we can get ample test data without resorting to jackknifing techniques.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4926">
<title id=" W10-2927.xml">inspecting the structural biases of dependency parsing algorithms </title>
<section> transition-based parsers.  </section>
<citcontext>
<prevsection>
<prevsent>we now turn to analyze the specific structural biases of the parsing systems.
</prevsent>
<prevsent>for each system we present some prominent structures which are under-produced by the system (these structures appear in the language more often than they are produce by the parser) and some structures which are over-produced by the system (these structures 6http://chasen.org/taku/software/bact/ 7http://www.cs.bgu.ac.il/yoavg/software/ are produced by the parser more often than they appear in the language).8 specifically, we manually inspected the predictors where the ratio between language and parser was high, ranked by absolute number of occurrences.
</prevsent>
</prevsection>
<citsent citstr=" J08-4003 ">
we analyze two transition-based parsers (nivre,2008).<papid> J08-4003 </papid></citsent>
<aftsection>
<nextsent>the parsers differ in the transition systems they adopt.
</nextsent>
<nextsent>the arce system makes use of transition system with four transitions: left,right,shift,reduce.
</nextsent>
<nextsent>the semantics of this transition system is described in (nivre,2004).<papid> W04-0308 </papid></nextsent>
<nextsent>the arcs system adopts an alternative transition system, with three transitions: at tachl,attachr,shift.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4927">
<title id=" W10-2927.xml">inspecting the structural biases of dependency parsing algorithms </title>
<section> transition-based parsers.  </section>
<citcontext>
<prevsection>
<prevsent>the parsers differ in the transition systems they adopt.
</prevsent>
<prevsent>the arce system makes use of transition system with four transitions: left,right,shift,reduce.
</prevsent>
</prevsection>
<citsent citstr=" W04-0308 ">
the semantics of this transition system is described in (nivre,2004).<papid> W04-0308 </papid></citsent>
<aftsection>
<nextsent>the arcs system adopts an alternative transition system, with three transitions: at tachl,attachr,shift.
</nextsent>
<nextsent>the semantics of the system is described in (huang et al, 2009).<papid> D09-1127 </papid></nextsent>
<nextsent>the main difference between the systems is that thearce system makes attachments as early as possible, while the arcs system should not attach aparent to its dependent until the dependent has acquired all its own dependents.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4929">
<title id=" W10-3106.xml">automatic annotation of speculation in biomedical texts new perspectives and largescale evaluation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>has not exactly the same meaning in these two statements (depending if it comes from computational linguists or from biologists).
</prevsent>
<prevsent>indeed, because biologists are almost interested in knowing only factual statements, the information extraction tools have to remove all uncertain statements, identified as hedging or speculation, or at least to present them separately from definite results.
</prevsent>
</prevsection>
<citsent citstr=" W09-1304 ">
consequently, the vast majority of natural language processing tools dealing with the identification of speculation have followed this very large meaning of the word speculation?, in order to avoid extracting uncertain information as factual information (kilicoglu and bergler, 2008; medlock, 2008; szarvas, 2008; morante and daelemans, 2009; <papid> W09-1304 </papid>zgur and radev, 2009).</citsent>
<aftsection>
<nextsent>to help improve the information extraction tools, corpus, called bio scope, has been annotated for speculation, negation and its linguistic scopes in biomedical texts (szarvas et al, 2008).
</nextsent>
<nextsent>however, when biologist says he is interested in knowing all speculations about biological entity (gene or protein for example) or biological process, this claim concerns another meaning of the word speculation?.
</nextsent>
<nextsent>the latter is in this case more restrictive than previously, and close to the notion of hypothesis and uncertain proposal.
</nextsent>
<nextsent>this interest of biologists can be explained by different reasons.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4936">
<title id=" W10-1732.xml">hierarchical phrase based mt at the charles university for the wmt 2010 shared task </title>
<section> the translation system.  </section>
<citcontext>
<prevsection>
<prevsent>our submission to the shared task should reveal where pure hierarchical system stands in this jungle and what of the abovementioned ideas match the phenomena the system suffers from.
</prevsent>
<prevsent>although our primary focus lies on english-to-czech translation, we also report the accuracy of the same system on moderately-sized corpora for the other three languages and seven translation directions.
</prevsent>
</prevsection>
<citsent citstr=" J07-2003 ">
our translation system belongs to the hierarchical phrase-based class (chiang, 2007), <papid> J07-2003 </papid>i.e. phrase pairs with nonterminals (rules of synchronouscontext-free grammar) are extracted from sym metrized word alignments and subsequently usedby the decoder.</citsent>
<aftsection>
<nextsent>we use joshua, java-based open source implementation of the hierarchical decoder (li et al, 2009), <papid> W09-0424 </papid>release 1.1.1 word alignment was computed using the first three steps of the train-factored-phrase model.perl script packed with moses2 (koehn et al., 2007).<papid> P07-2045 </papid></nextsent>
<nextsent>this includes the usual combination ofword clustering using mkcls3 (och, 1999), two way word alignment using giza++4 (och and ney, 2003), <papid> J03-1002 </papid>and alignment symmetrization using the grow-diag-final-and heuristic (koehn et al, 2003).<papid> N03-1017 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4937">
<title id=" W10-1732.xml">hierarchical phrase based mt at the charles university for the wmt 2010 shared task </title>
<section> the translation system.  </section>
<citcontext>
<prevsection>
<prevsent>although our primary focus lies on english-to-czech translation, we also report the accuracy of the same system on moderately-sized corpora for the other three languages and seven translation directions.
</prevsent>
<prevsent>our translation system belongs to the hierarchical phrase-based class (chiang, 2007), <papid> J07-2003 </papid>i.e. phrase pairs with nonterminals (rules of synchronouscontext-free grammar) are extracted from sym metrized word alignments and subsequently usedby the decoder.</prevsent>
</prevsection>
<citsent citstr=" W09-0424 ">
we use joshua, java-based open source implementation of the hierarchical decoder (li et al, 2009), <papid> W09-0424 </papid>release 1.1.1 word alignment was computed using the first three steps of the train-factored-phrase model.perl script packed with moses2 (koehn et al., 2007).<papid> P07-2045 </papid></citsent>
<aftsection>
<nextsent>this includes the usual combination ofword clustering using mkcls3 (och, 1999), two way word alignment using giza++4 (och and ney, 2003), <papid> J03-1002 </papid>and alignment symmetrization using the grow-diag-final-and heuristic (koehn et al, 2003).<papid> N03-1017 </papid></nextsent>
<nextsent>for language modeling we use the srilmtoolkit5 (stolcke, 2002) with modified kneser ney smoothing (kneser and ney, 1995; chen and goodman, 1998).we use the z-mert implementation of minimum error rate training (zaidan, 2009).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4938">
<title id=" W10-1732.xml">hierarchical phrase based mt at the charles university for the wmt 2010 shared task </title>
<section> the translation system.  </section>
<citcontext>
<prevsection>
<prevsent>although our primary focus lies on english-to-czech translation, we also report the accuracy of the same system on moderately-sized corpora for the other three languages and seven translation directions.
</prevsent>
<prevsent>our translation system belongs to the hierarchical phrase-based class (chiang, 2007), <papid> J07-2003 </papid>i.e. phrase pairs with nonterminals (rules of synchronouscontext-free grammar) are extracted from sym metrized word alignments and subsequently usedby the decoder.</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
we use joshua, java-based open source implementation of the hierarchical decoder (li et al, 2009), <papid> W09-0424 </papid>release 1.1.1 word alignment was computed using the first three steps of the train-factored-phrase model.perl script packed with moses2 (koehn et al., 2007).<papid> P07-2045 </papid></citsent>
<aftsection>
<nextsent>this includes the usual combination ofword clustering using mkcls3 (och, 1999), two way word alignment using giza++4 (och and ney, 2003), <papid> J03-1002 </papid>and alignment symmetrization using the grow-diag-final-and heuristic (koehn et al, 2003).<papid> N03-1017 </papid></nextsent>
<nextsent>for language modeling we use the srilmtoolkit5 (stolcke, 2002) with modified kneser ney smoothing (kneser and ney, 1995; chen and goodman, 1998).we use the z-mert implementation of minimum error rate training (zaidan, 2009).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4939">
<title id=" W10-1732.xml">hierarchical phrase based mt at the charles university for the wmt 2010 shared task </title>
<section> the translation system.  </section>
<citcontext>
<prevsection>
<prevsent>our translation system belongs to the hierarchical phrase-based class (chiang, 2007), <papid> J07-2003 </papid>i.e. phrase pairs with nonterminals (rules of synchronouscontext-free grammar) are extracted from sym metrized word alignments and subsequently usedby the decoder.</prevsent>
<prevsent>we use joshua, java-based open source implementation of the hierarchical decoder (li et al, 2009), <papid> W09-0424 </papid>release 1.1.1 word alignment was computed using the first three steps of the train-factored-phrase model.perl script packed with moses2 (koehn et al., 2007).<papid> P07-2045 </papid></prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
this includes the usual combination ofword clustering using mkcls3 (och, 1999), two way word alignment using giza++4 (och and ney, 2003), <papid> J03-1002 </papid>and alignment symmetrization using the grow-diag-final-and heuristic (koehn et al, 2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>for language modeling we use the srilmtoolkit5 (stolcke, 2002) with modified kneser ney smoothing (kneser and ney, 1995; chen and goodman, 1998).we use the z-mert implementation of minimum error rate training (zaidan, 2009).
</nextsent>
<nextsent>the following settings have been used for joshua and mert: 1http://sourceforge.net/projects/joshua/ 2http://www.statmt.org/moses/ 3http://fjoch.com/mkcls.html 4http://fjoch.com/giza++.html 5http://www-speech.sri.com/projects/srilm/ 212 ? grammar extraction: --maxphraselength=5 ? decoding: span_limit=10 fuzz1=0.1fuzz2=0.1 max_n_items=30 rela tive_threshold=10.0 max_n_rules=50 rule_relative_threshold=10.0 ? n-best decoding: use_unique_nbest=true use_tree_nbest=false add_combined_cost=true top_n=300 ? z-mert: -m bleu 4 closest -maxit 5 -ipi 20
</nextsent>
<nextsent>3.1 baseline experiments.
</nextsent>
<nextsent>we applied our system to all eight language pairs.however, for all but one we ran only baseline experiment.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4940">
<title id=" W10-1732.xml">hierarchical phrase based mt at the charles university for the wmt 2010 shared task </title>
<section> the translation system.  </section>
<citcontext>
<prevsection>
<prevsent>our translation system belongs to the hierarchical phrase-based class (chiang, 2007), <papid> J07-2003 </papid>i.e. phrase pairs with nonterminals (rules of synchronouscontext-free grammar) are extracted from sym metrized word alignments and subsequently usedby the decoder.</prevsent>
<prevsent>we use joshua, java-based open source implementation of the hierarchical decoder (li et al, 2009), <papid> W09-0424 </papid>release 1.1.1 word alignment was computed using the first three steps of the train-factored-phrase model.perl script packed with moses2 (koehn et al., 2007).<papid> P07-2045 </papid></prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
this includes the usual combination ofword clustering using mkcls3 (och, 1999), two way word alignment using giza++4 (och and ney, 2003), <papid> J03-1002 </papid>and alignment symmetrization using the grow-diag-final-and heuristic (koehn et al, 2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>for language modeling we use the srilmtoolkit5 (stolcke, 2002) with modified kneser ney smoothing (kneser and ney, 1995; chen and goodman, 1998).we use the z-mert implementation of minimum error rate training (zaidan, 2009).
</nextsent>
<nextsent>the following settings have been used for joshua and mert: 1http://sourceforge.net/projects/joshua/ 2http://www.statmt.org/moses/ 3http://fjoch.com/mkcls.html 4http://fjoch.com/giza++.html 5http://www-speech.sri.com/projects/srilm/ 212 ? grammar extraction: --maxphraselength=5 ? decoding: span_limit=10 fuzz1=0.1fuzz2=0.1 max_n_items=30 rela tive_threshold=10.0 max_n_rules=50 rule_relative_threshold=10.0 ? n-best decoding: use_unique_nbest=true use_tree_nbest=false add_combined_cost=true top_n=300 ? z-mert: -m bleu 4 closest -maxit 5 -ipi 20
</nextsent>
<nextsent>3.1 baseline experiments.
</nextsent>
<nextsent>we applied our system to all eight language pairs.however, for all but one we ran only baseline experiment.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4941">
<title id=" W10-1906.xml">arguments of nominals in semantic interpretation of biomedical text </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>the theoretical linguistics literature has addressed the syntax of nominalizations (e.g. chomsky, 1970; grimshaw, 1990; grimshaw and williams, 1993), however, largely as support for theoretical argumentation, rather than detailed description of the facts.
</prevsent>
<prevsent>quirk et al (1985) concentrate on the morphological derivation of 46 nominalizations from verbs.
</prevsent>
</prevsection>
<citsent citstr=" W04-2705 ">
within the context of nombank, project dedicated to annotation of argument structure, meyers et al (2004<papid> W04-2705 </papid>a) describe the linguistics of nominalizations, emphasizing semantic roles.</citsent>
<aftsection>
<nextsent>however, major syntactic patterns of argument realization are also noted.
</nextsent>
<nextsent>cohen et al (2008) provide comprehensive overview of nominalizations in biomedical text.
</nextsent>
<nextsent>they include review of the relevant literature, and discuss range of linguistic considerations, including morphological derivation, passiviza tion, transit ivity, and semantic topics (e.g. agent/instrument (activator) vs. ac tion/process/state (activation)).
</nextsent>
<nextsent>based on an analysis of the pennbioie corpus (kulick et al, 2004), <papid> W04-3111 </papid>detailed distributional results are provided on alternation patterns for several nominalizations with high frequency of occurrence in biomedical text, such as activation and treatment.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4942">
<title id=" W10-1906.xml">arguments of nominals in semantic interpretation of biomedical text </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>cohen et al (2008) provide comprehensive overview of nominalizations in biomedical text.
</prevsent>
<prevsent>they include review of the relevant literature, and discuss range of linguistic considerations, including morphological derivation, passiviza tion, transit ivity, and semantic topics (e.g. agent/instrument (activator) vs. ac tion/process/state (activation)).
</prevsent>
</prevsection>
<citsent citstr=" W04-3111 ">
based on an analysis of the pennbioie corpus (kulick et al, 2004), <papid> W04-3111 </papid>detailed distributional results are provided on alternation patterns for several nominalizations with high frequency of occurrence in biomedical text, such as activation and treatment.</citsent>
<aftsection>
<nextsent>in computational linguistics, pundit (dahl et al, 1987) exploited similarities between nomi nalizations and related verbs.
</nextsent>
<nextsent>hull and gomez (1996) describe semantic interpretation for limited set of nominalizations, relying on wordnet (fellbaum, 1998) senses for restricting fillers of semantic roles.
</nextsent>
<nextsent>meyers et al (1998) <papid> W98-0604 </papid>present procedure which maps syntactic and semantic information for verbs into set of patterns for nominalizations.</nextsent>
<nextsent>they use nomlex (macleod et al, 1998), nominal ization lexicon, as the basis for this transformation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4943">
<title id=" W10-1906.xml">arguments of nominals in semantic interpretation of biomedical text </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>in computational linguistics, pundit (dahl et al, 1987) exploited similarities between nomi nalizations and related verbs.
</prevsent>
<prevsent>hull and gomez (1996) describe semantic interpretation for limited set of nominalizations, relying on wordnet (fellbaum, 1998) senses for restricting fillers of semantic roles.
</prevsent>
</prevsection>
<citsent citstr=" W98-0604 ">
meyers et al (1998) <papid> W98-0604 </papid>present procedure which maps syntactic and semantic information for verbs into set of patterns for nominalizations.</citsent>
<aftsection>
<nextsent>they use nomlex (macleod et al, 1998), nominal ization lexicon, as the basis for this transformation.
</nextsent>
<nextsent>more recently, the availability of the nombank corpus (meyers et al., 2004<papid> W04-2705 </papid>b) has supported supervised machine learning for nominal semantic role labeling (e.g. pradhan et al, 2004; <papid> N04-4036 </papid>jiang and ng, 2006; liu and ng, 2007).<papid> P07-1027 </papid></nextsent>
<nextsent>in contrast, pad?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4945">
<title id=" W10-1906.xml">arguments of nominals in semantic interpretation of biomedical text </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>meyers et al (1998) <papid> W98-0604 </papid>present procedure which maps syntactic and semantic information for verbs into set of patterns for nominalizations.</prevsent>
<prevsent>they use nomlex (macleod et al, 1998), nominal ization lexicon, as the basis for this transformation.</prevsent>
</prevsection>
<citsent citstr=" N04-4036 ">
more recently, the availability of the nombank corpus (meyers et al., 2004<papid> W04-2705 </papid>b) has supported supervised machine learning for nominal semantic role labeling (e.g. pradhan et al, 2004; <papid> N04-4036 </papid>jiang and ng, 2006; liu and ng, 2007).<papid> P07-1027 </papid></citsent>
<aftsection>
<nextsent>in contrast, pad?
</nextsent>
<nextsent>et al (2008) use unsupervised machine learning for semantic role labeling of even tive nominalizations by exploiting similarities between the argument structure of event nominalizations and corresponding verbs.
</nextsent>
<nextsent>gurevich and waterman (2009) use large parsed corpus of wikipedia to derive lexical models for determining the underlying argument structure of nominalizations.
</nextsent>
<nextsent>nominalizations have only recently garnered attention in biomedical language processing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4946">
<title id=" W10-1906.xml">arguments of nominals in semantic interpretation of biomedical text </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>meyers et al (1998) <papid> W98-0604 </papid>present procedure which maps syntactic and semantic information for verbs into set of patterns for nominalizations.</prevsent>
<prevsent>they use nomlex (macleod et al, 1998), nominal ization lexicon, as the basis for this transformation.</prevsent>
</prevsection>
<citsent citstr=" P07-1027 ">
more recently, the availability of the nombank corpus (meyers et al., 2004<papid> W04-2705 </papid>b) has supported supervised machine learning for nominal semantic role labeling (e.g. pradhan et al, 2004; <papid> N04-4036 </papid>jiang and ng, 2006; liu and ng, 2007).<papid> P07-1027 </papid></citsent>
<aftsection>
<nextsent>in contrast, pad?
</nextsent>
<nextsent>et al (2008) use unsupervised machine learning for semantic role labeling of even tive nominalizations by exploiting similarities between the argument structure of event nominalizations and corresponding verbs.
</nextsent>
<nextsent>gurevich and waterman (2009) use large parsed corpus of wikipedia to derive lexical models for determining the underlying argument structure of nominalizations.
</nextsent>
<nextsent>nominalizations have only recently garnered attention in biomedical language processing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4947">
<title id=" W10-1906.xml">arguments of nominals in semantic interpretation of biomedical text </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>nominalizations have only recently garnered attention in biomedical language processing.
</prevsent>
<prevsent>ge nescene (leroy and chen, 2005) considers only arguments of nominalizations marked by prepositional cues.
</prevsent>
</prevsection>
<citsent citstr=" W06-3312 ">
similarly, schuman and bergler (2006) <papid> W06-3312 </papid>focus on the problem of prepositional phrase attachment.</citsent>
<aftsection>
<nextsent>in the bionlp09 shared task on event extraction (kim et al, 2009), <papid> W09-1401 </papid>the most frequent predicates were nominals.</nextsent>
<nextsent>several participating systems discuss techniques that accommodate nominalizations (e.g. k. b. cohen et al., 2009; kilicoglu and bergler, 2009).<papid> W09-1418 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4948">
<title id=" W10-1906.xml">arguments of nominals in semantic interpretation of biomedical text </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>ge nescene (leroy and chen, 2005) considers only arguments of nominalizations marked by prepositional cues.
</prevsent>
<prevsent>similarly, schuman and bergler (2006) <papid> W06-3312 </papid>focus on the problem of prepositional phrase attachment.</prevsent>
</prevsection>
<citsent citstr=" W09-1401 ">
in the bionlp09 shared task on event extraction (kim et al, 2009), <papid> W09-1401 </papid>the most frequent predicates were nominals.</citsent>
<aftsection>
<nextsent>several participating systems discuss techniques that accommodate nominalizations (e.g. k. b. cohen et al., 2009; kilicoglu and bergler, 2009).<papid> W09-1418 </papid></nextsent>
<nextsent>nomina liz ations have not previously been addressed in clinically oriented text.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4949">
<title id=" W10-1906.xml">arguments of nominals in semantic interpretation of biomedical text </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>similarly, schuman and bergler (2006) <papid> W06-3312 </papid>focus on the problem of prepositional phrase attachment.</prevsent>
<prevsent>in the bionlp09 shared task on event extraction (kim et al, 2009), <papid> W09-1401 </papid>the most frequent predicates were nominals.</prevsent>
</prevsection>
<citsent citstr=" W09-1418 ">
several participating systems discuss techniques that accommodate nominalizations (e.g. k. b. cohen et al., 2009; kilicoglu and bergler, 2009).<papid> W09-1418 </papid></citsent>
<aftsection>
<nextsent>nomina liz ations have not previously been addressed in clinically oriented text.
</nextsent>
<nextsent>2.1 semrep.
</nextsent>
<nextsent>semrep (rindflesch and fiszman, 2003) automatically extracts semantic predications (logical subject-predicate-logical object triples) from unstructured text (titles and abstracts) of med line citations.
</nextsent>
<nextsent>it uses domain knowledge from the unified medical language system?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4950">
<title id=" W10-1906.xml">arguments of nominals in semantic interpretation of biomedical text </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>an array of semantic predications generated by mapping to an ontology (umls) normalizes the interpretation of verbs and nominalizations.
</prevsent>
<prevsent>processing is linguistically based, and several syntactic phenomena are addressed, including passivization, argument coordination, and relativization.
</prevsent>
</prevsection>
<citsent citstr=" W04-2611 ">
the benefits of such processing include effective applications for extracting information on genetic diseases from text (masseroli et al, 2006), as well as research in medical knowledge summarization (fiszman et al, 2004; <papid> W04-2611 </papid>fiszman et al, 2009), literature-based discovery (ahlers et al, 2007; hristovski et al, 2010), and enhanced information retrieval (kilicoglu et al, 2008; t. cohen et al, 2009).</citsent>
<aftsection>
<nextsent>acknowledgments this study was supported in part by the intramural research program of the national institutes of health, national library of medicine.
</nextsent>



</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4951">
<title id=" W10-3410.xml">in search of the rsquorightrsquo word </title>
<section> the recollection problem?.  </section>
<citcontext>
<prevsection>
<prevsent>here, we will call this situation the recollection problem?.
</prevsent>
<prevsent>alpha-betically organised dictionaries are of little help 66 in such situations.
</prevsent>
</prevsection>
<citsent citstr=" W08-1902 ">
of course, the recollection problem is well known one (for discussion, see zock and bilac, 2004; zock and schwab, 2008).<papid> W08-1902 </papid></citsent>
<aftsection>
<nextsent>works with an international reputation have tried to face it and, of course, rogets the-saurus, printed dictionary, and wordnet and euro wordnet, both digital ones, spring easily to mind.
</nextsent>
<nextsent>an interesting difference between the two dictionaries is exactly about the interaction with the user: while in rogets lexical relations are left implicit and material is explicit, in wordnet one has to go via lexical relations such as hy-ponymy?
</nextsent>
<nextsent>and sister term?
</nextsent>
<nextsent>to find the material.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4952">
<title id=" W10-3410.xml">in search of the rsquorightrsquo word </title>
<section> the recollection problem?.  </section>
<citcontext>
<prevsection>
<prevsent>on the other hand, humans do instinctively look for words on the 2 we use the term concept to define set of words that are conceptually related.
</prevsent>
<prevsent>such sets are defined in rogets thesaurus and the onomasticon?.
</prevsent>
</prevsection>
<citsent citstr=" W08-1913 ">
basis of domain relations several of which can be argued to mirror (aspects of) human cognition (gaume et al, 2003; kremer et al, 2008).<papid> W08-1913 </papid></citsent>
<aftsection>
<nextsent>fur-thermore, the data we will present here indicate that searching for word is also matter of habit and training, having lot to do with ones pro-fession and familiarity with certain types of dic-tionary.
</nextsent>
<nextsent>as already said, we report on user require-ment survey that was conducted in the frame-work of the project ekfrasis.
</nextsent>
<nextsent>our aim was primarily to see how the lexicographic material should be presented to the user; however, we were also interested in fine-tuning our ideas about the nature of the material required.
</nextsent>
<nextsent>we start with brief presentation of the main ideas behind the dictionary ekfrasis.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4953">
<title id=" W10-2105.xml">grammar driven versus data driven which parsing system is more affected by domain shifts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the performance variation of grammar-driven versus two data-driven systems across domains is evaluated, and asimple measure to quantify domain sensitivity proposed.
</prevsent>
<prevsent>this will give an estimate of which parsing system is more affected by domain shifts, and thus more in need for adaptation techniques.
</prevsent>
</prevsection>
<citsent citstr=" W01-0521 ">
most modern natural language processing (nlp) systems are subject to the well known problem oflack of portability to new domains: there is substantial drop in their performance when the system gets input from another text domain (gildea,2001).<papid> W01-0521 </papid></citsent>
<aftsection>
<nextsent>this is the problem of domain adaptation.
</nextsent>
<nextsent>although the problem exists ever since the emergence of supervised machine learning, it has started to get attention only in recent years.
</nextsent>
<nextsent>studies on supervised domain adaptation (where there are limited amounts of annotated resources in the new domain) have shown that straightforward baselines (e.g. models based on source only, target only, or the union of the data) achieve relatively high performance level and are surprisingly difficult to beat?
</nextsent>
<nextsent>(daume?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4954">
<title id=" W10-2105.xml">grammar driven versus data driven which parsing system is more affected by domain shifts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>iii, 2007).
</prevsent>
<prevsent>in contrast, semi-supervised adaptation (i.e. no annotated resources in the new domain) is much more realistic situation but is clearly also considerably more difficult.
</prevsent>
</prevsection>
<citsent citstr=" D07-1112 ">
current studies on semi supervised approaches show very mixed results.dredze et al (2007) <papid> D07-1112 </papid>report on frustrating?</citsent>
<aftsection>
<nextsent>results on the conll 2007 semi-supervised adaptation task for dependency parsing, i.e. no team was able to improve target domain performance substantially over state-of-the-art baseline?.
</nextsent>
<nextsent>on the other hand, there have been positive results aswell.
</nextsent>
<nextsent>for instance, mcclosky et al (2006) <papid> N06-1020 </papid>improved statistical parser by self-training.</nextsent>
<nextsent>structural correspondence learning (blitzer et al, 2006) <papid> W06-1615 </papid>was effective for pos tagging and sentiment analysis (blitzer et al, 2006; <papid> W06-1615 </papid>blitzer et al, 2007),<papid> P07-1056 </papid>while only modest gains were obtained for structured output tasks like parsing.for parsing, most previous work on domain adaptation has focused on data-driven systems (gildea, 2001; <papid> W01-0521 </papid>mcclosky et al, 2006;<papid> N06-1020 </papid>dredze et al, 2007), <papid> D07-1112 </papid>i.e. systems employing (constituent or dependency based) treebank gram mars.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4955">
<title id=" W10-2105.xml">grammar driven versus data driven which parsing system is more affected by domain shifts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>results on the conll 2007 semi-supervised adaptation task for dependency parsing, i.e. no team was able to improve target domain performance substantially over state-of-the-art baseline?.
</prevsent>
<prevsent>on the other hand, there have been positive results aswell.
</prevsent>
</prevsection>
<citsent citstr=" N06-1020 ">
for instance, mcclosky et al (2006) <papid> N06-1020 </papid>improved statistical parser by self-training.</citsent>
<aftsection>
<nextsent>structural correspondence learning (blitzer et al, 2006) <papid> W06-1615 </papid>was effective for pos tagging and sentiment analysis (blitzer et al, 2006; <papid> W06-1615 </papid>blitzer et al, 2007),<papid> P07-1056 </papid>while only modest gains were obtained for structured output tasks like parsing.for parsing, most previous work on domain adaptation has focused on data-driven systems (gildea, 2001; <papid> W01-0521 </papid>mcclosky et al, 2006;<papid> N06-1020 </papid>dredze et al, 2007), <papid> D07-1112 </papid>i.e. systems employing (constituent or dependency based) treebank gram mars.</nextsent>
<nextsent>only few studies examined the adaptation of grammar-based systems (hara et al, 2005; <papid> I05-1018 </papid>plank and van noord, 2008), <papid> W08-1302 </papid>i.e. systems employ inga hand-crafted grammar with statistical disambiguation component.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4956">
<title id=" W10-2105.xml">grammar driven versus data driven which parsing system is more affected by domain shifts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>on the other hand, there have been positive results aswell.
</prevsent>
<prevsent>for instance, mcclosky et al (2006) <papid> N06-1020 </papid>improved statistical parser by self-training.</prevsent>
</prevsection>
<citsent citstr=" W06-1615 ">
structural correspondence learning (blitzer et al, 2006) <papid> W06-1615 </papid>was effective for pos tagging and sentiment analysis (blitzer et al, 2006; <papid> W06-1615 </papid>blitzer et al, 2007),<papid> P07-1056 </papid>while only modest gains were obtained for structured output tasks like parsing.for parsing, most previous work on domain adaptation has focused on data-driven systems (gildea, 2001; <papid> W01-0521 </papid>mcclosky et al, 2006;<papid> N06-1020 </papid>dredze et al, 2007), <papid> D07-1112 </papid>i.e. systems employing (constituent or dependency based) treebank gram mars.</citsent>
<aftsection>
<nextsent>only few studies examined the adaptation of grammar-based systems (hara et al, 2005; <papid> I05-1018 </papid>plank and van noord, 2008), <papid> W08-1302 </papid>i.e. systems employ inga hand-crafted grammar with statistical disambiguation component.</nextsent>
<nextsent>this may be motivated bythe fact that potential gains for this task are inherently bound by the grammar.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4958">
<title id=" W10-2105.xml">grammar driven versus data driven which parsing system is more affected by domain shifts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>on the other hand, there have been positive results aswell.
</prevsent>
<prevsent>for instance, mcclosky et al (2006) <papid> N06-1020 </papid>improved statistical parser by self-training.</prevsent>
</prevsection>
<citsent citstr=" P07-1056 ">
structural correspondence learning (blitzer et al, 2006) <papid> W06-1615 </papid>was effective for pos tagging and sentiment analysis (blitzer et al, 2006; <papid> W06-1615 </papid>blitzer et al, 2007),<papid> P07-1056 </papid>while only modest gains were obtained for structured output tasks like parsing.for parsing, most previous work on domain adaptation has focused on data-driven systems (gildea, 2001; <papid> W01-0521 </papid>mcclosky et al, 2006;<papid> N06-1020 </papid>dredze et al, 2007), <papid> D07-1112 </papid>i.e. systems employing (constituent or dependency based) treebank gram mars.</citsent>
<aftsection>
<nextsent>only few studies examined the adaptation of grammar-based systems (hara et al, 2005; <papid> I05-1018 </papid>plank and van noord, 2008), <papid> W08-1302 </papid>i.e. systems employ inga hand-crafted grammar with statistical disambiguation component.</nextsent>
<nextsent>this may be motivated bythe fact that potential gains for this task are inherently bound by the grammar.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4963">
<title id=" W10-2105.xml">grammar driven versus data driven which parsing system is more affected by domain shifts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for instance, mcclosky et al (2006) <papid> N06-1020 </papid>improved statistical parser by self-training.</prevsent>
<prevsent>structural correspondence learning (blitzer et al, 2006) <papid> W06-1615 </papid>was effective for pos tagging and sentiment analysis (blitzer et al, 2006; <papid> W06-1615 </papid>blitzer et al, 2007),<papid> P07-1056 </papid>while only modest gains were obtained for structured output tasks like parsing.for parsing, most previous work on domain adaptation has focused on data-driven systems (gildea, 2001; <papid> W01-0521 </papid>mcclosky et al, 2006;<papid> N06-1020 </papid>dredze et al, 2007), <papid> D07-1112 </papid>i.e. systems employing (constituent or dependency based) treebank gram mars.</prevsent>
</prevsection>
<citsent citstr=" I05-1018 ">
only few studies examined the adaptation of grammar-based systems (hara et al, 2005; <papid> I05-1018 </papid>plank and van noord, 2008), <papid> W08-1302 </papid>i.e. systems employ inga hand-crafted grammar with statistical disambiguation component.</citsent>
<aftsection>
<nextsent>this may be motivated bythe fact that potential gains for this task are inherently bound by the grammar.
</nextsent>
<nextsent>yet, domain adaptation poses challenge for both kinds of parsing systems.
</nextsent>
<nextsent>but to what extent do these different kinds of systems suffer from the problem?
</nextsent>
<nextsent>we test the hypothesis that grammar-driven systems are less affected by domain changes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4964">
<title id=" W10-2105.xml">grammar driven versus data driven which parsing system is more affected by domain shifts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for instance, mcclosky et al (2006) <papid> N06-1020 </papid>improved statistical parser by self-training.</prevsent>
<prevsent>structural correspondence learning (blitzer et al, 2006) <papid> W06-1615 </papid>was effective for pos tagging and sentiment analysis (blitzer et al, 2006; <papid> W06-1615 </papid>blitzer et al, 2007),<papid> P07-1056 </papid>while only modest gains were obtained for structured output tasks like parsing.for parsing, most previous work on domain adaptation has focused on data-driven systems (gildea, 2001; <papid> W01-0521 </papid>mcclosky et al, 2006;<papid> N06-1020 </papid>dredze et al, 2007), <papid> D07-1112 </papid>i.e. systems employing (constituent or dependency based) treebank gram mars.</prevsent>
</prevsection>
<citsent citstr=" W08-1302 ">
only few studies examined the adaptation of grammar-based systems (hara et al, 2005; <papid> I05-1018 </papid>plank and van noord, 2008), <papid> W08-1302 </papid>i.e. systems employ inga hand-crafted grammar with statistical disambiguation component.</citsent>
<aftsection>
<nextsent>this may be motivated bythe fact that potential gains for this task are inherently bound by the grammar.
</nextsent>
<nextsent>yet, domain adaptation poses challenge for both kinds of parsing systems.
</nextsent>
<nextsent>but to what extent do these different kinds of systems suffer from the problem?
</nextsent>
<nextsent>we test the hypothesis that grammar-driven systems are less affected by domain changes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4969">
<title id=" W10-2105.xml">grammar driven versus data driven which parsing system is more affected by domain shifts </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>most previous work has focused on single parsing system in isolation (gildea, 2001; <papid> W01-0521 </papid>hara et al., 2005; <papid> I05-1018 </papid>mcclosky et al, 2006).<papid> N06-1020 </papid></prevsent>
<prevsent>however, there is an observable trend towards combining different parsing systems to exploit complementary strengths.</prevsent>
</prevsection>
<citsent citstr=" P08-1108 ">
for instance, nivre and mcdonald (2008) <papid> P08-1108 </papid>combine two data-driven systems to im prove dependency accuracy.</citsent>
<aftsection>
<nextsent>similarly, two studies successfully combined grammar-based and data driven systems: sagae et al (2007) <papid> P07-1079 </papid>incorporate data-driven dependencies as soft-constraint in hpsg-based system for parsing the wallstreetjournal.</nextsent>
<nextsent>in the same spirit (but the other direction), zhang and wang (2009) <papid> P09-1043 </papid>use deep grammar based backbone to improve data-driven parsing accuracy.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4970">
<title id=" W10-2105.xml">grammar driven versus data driven which parsing system is more affected by domain shifts </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, there is an observable trend towards combining different parsing systems to exploit complementary strengths.
</prevsent>
<prevsent>for instance, nivre and mcdonald (2008) <papid> P08-1108 </papid>combine two data-driven systems to im prove dependency accuracy.</prevsent>
</prevsection>
<citsent citstr=" P07-1079 ">
similarly, two studies successfully combined grammar-based and data driven systems: sagae et al (2007) <papid> P07-1079 </papid>incorporate data-driven dependencies as soft-constraint in hpsg-based system for parsing the wallstreetjournal.</citsent>
<aftsection>
<nextsent>in the same spirit (but the other direction), zhang and wang (2009) <papid> P09-1043 </papid>use deep grammar based backbone to improve data-driven parsing accuracy.</nextsent>
<nextsent>they incorporate features from the grammar-based backbone into the data-drivensystem to achieve better generalization across do mains.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4971">
<title id=" W10-2105.xml">grammar driven versus data driven which parsing system is more affected by domain shifts </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>for instance, nivre and mcdonald (2008) <papid> P08-1108 </papid>combine two data-driven systems to im prove dependency accuracy.</prevsent>
<prevsent>similarly, two studies successfully combined grammar-based and data driven systems: sagae et al (2007) <papid> P07-1079 </papid>incorporate data-driven dependencies as soft-constraint in hpsg-based system for parsing the wallstreetjournal.</prevsent>
</prevsection>
<citsent citstr=" P09-1043 ">
in the same spirit (but the other direction), zhang and wang (2009) <papid> P09-1043 </papid>use deep grammar based backbone to improve data-driven parsing accuracy.</citsent>
<aftsection>
<nextsent>they incorporate features from the grammar-based backbone into the data-drivensystem to achieve better generalization across domains.
</nextsent>
<nextsent>this is the work most closest to ours.
</nextsent>
<nextsent>however, which kind of system (hand-crafted versus purely statistical) is more affected by the domain, and thus more sensitive to domain shift sto the best of our knowledge, no study has yet addressed this issue.
</nextsent>
<nextsent>we thus assess the performance variation of three dependency parsing systems for dutch across domains, and propose simple measure to quantify domain sensitivity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4972">
<title id=" W10-2105.xml">grammar driven versus data driven which parsing system is more affected by domain shifts </title>
<section> parsing systems.  </section>
<citcontext>
<prevsection>
<prevsent>furthermore, the maximum entropy disambiguation component does good job in selecting good parses from those.
</prevsent>
<prevsent>accuracy is given here in terms of f-score of named dependencies.
</prevsent>
</prevsection>
<citsent citstr=" H05-1066 ">
sents parses oracle arbitrary model 536 45011 95.74 76.56 89.39 (2) mst parser (mcdonald et al, 2005) <papid> H05-1066 </papid>is 26 data-driven graph-based dependency parser.</citsent>
<aftsection>
<nextsent>the system couples minimum spanning tree search procedure with separate second stage classifier to label the dependency edges.(3) malt parser (nivre et al, 2007) is data driven transition-based dependency parser.
</nextsent>
<nextsent>malt parser uses svms to learn classifier that predicts the next parsing action.
</nextsent>
<nextsent>instances represent parser configurations and the label to predict determines the next parser action.
</nextsent>
<nextsent>both data-driven parsers (mst and malt) are thus not specific for the dutch language, however, they can be trained on variety of languages given that the training corpus complies with the column based format introduced in the 2006 conll shared task (buchholz and marsi, 2006).<papid> W06-2920 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4973">
<title id=" W10-2105.xml">grammar driven versus data driven which parsing system is more affected by domain shifts </title>
<section> parsing systems.  </section>
<citcontext>
<prevsection>
<prevsent>malt parser uses svms to learn classifier that predicts the next parsing action.
</prevsent>
<prevsent>instances represent parser configurations and the label to predict determines the next parser action.
</prevsent>
</prevsection>
<citsent citstr=" W06-2920 ">
both data-driven parsers (mst and malt) are thus not specific for the dutch language, however, they can be trained on variety of languages given that the training corpus complies with the column based format introduced in the 2006 conll shared task (buchholz and marsi, 2006).<papid> W06-2920 </papid></citsent>
<aftsection>
<nextsent>additionally, both parsers implement projective and non-projective parsing algorithms, where the latter will be used in our experiments on the relatively free word order language dutch.
</nextsent>
<nextsent>despite that, wetrain the data-driven parsers using their default settings (e.g. first order features for mst, svm with polynomial kernel for malt).
</nextsent>
<nextsent>the source domain on which all parsers are trained is cdb, the alpino treebank (van noord, 2006).
</nextsent>
<nextsent>for our cross-domain evaluation, we consider wikipedia and dpc (dutch parallel corpus) as target data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4983">
<title id=" W10-2105.xml">grammar driven versus data driven which parsing system is more affected by domain shifts </title>
<section> datasets and experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>as the dutch tagger used in the conll2006 shared task did not have the concept of multi words, the organizers chose to treat them as single token (buchholz and marsi, 2006).<papid> W06-2920 </papid></prevsent>
<prevsent>we here follow the conll 2006 task setup.</prevsent>
</prevsection>
<citsent citstr=" C00-2137 ">
to determine whether results are significant, we us the approximate randomization test (see yeh (2000)) <papid> C00-2137 </papid>with 1000 random shuffles.</citsent>
<aftsection>
<nextsent>the problem of domain dependence poses challenge for both kinds of parsing systems, data driven and grammar-driven.
</nextsent>
<nextsent>however, to what extent?
</nextsent>
<nextsent>which kind of parsing system is more affected by domain shifts?
</nextsent>
<nextsent>we may rephrase our question as: which parsing system is more robust to different input texts?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4989">
<title id=" W10-1704.xml">limsirsquos statistical translation systems for wmtrsquo10 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>limsi took part in the wmt 2010 evaluation campaign and developed systems for two languages pairs: french-english and german english in both directions.
</prevsent>
<prevsent>for german-english, we focused on preprocessing issues and performed series of experiments aimed at normalizing the german side by removing some of the lexical redundancy and by splitting compounds.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
for this pair, all the experiments were performed using the moses decoder (koehn et al, 2007)<papid> P07-2045 </papid></citsent>
<aftsection>
<nextsent>for french english, we studied two extensions of our n-gram based system: first, the effect of integrating new bilingual reordering model; second, the use of adaptation techniques for the translation model.
</nextsent>
<nextsent>decoding is performed using our in-house -code (marino et al, 2006) decoder.
</nextsent>
<nextsent>in this section, we describe the main characteristics of the phrase-based systems developed for this evaluation and the resources that were used to train our models.
</nextsent>
<nextsent>as far as resources go, we used all the data supplied by the 2010 evaluation organizers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4991">
<title id=" W10-1704.xml">limsirsquos statistical translation systems for wmtrsquo10 </title>
<section> german-english systems.  </section>
<citcontext>
<prevsection>
<prevsent>when aligning parallel texts atthe word level, german compound words typically tend to align with more than one english word; this, in turn, tends to increase the number of possible translation counterparts for each english type, and to make the corresponding alignment scores less reliable.
</prevsent>
<prevsent>in decoding, new compounds or unseen morphological variants of existing words artificially increase the number out of-vocabulary (oov) forms, which severely hurts the overall translation quality.
</prevsent>
</prevsection>
<citsent citstr=" J04-2003 ">
several researchers have proposed normalization (niessen and ney,2004; <papid> J04-2003 </papid>corston-oliver and gamon, 2004; goldwater and mcclosky, 2005) <papid> H05-1085 </papid>and compound splitting (koehn and knight, 2003; <papid> E03-1076 </papid>stymne, 2008; stymne, 2009) <papid> E09-3008 </papid>methods.</citsent>
<aftsection>
<nextsent>our approach here is similar, yet uses different implementations; we also studied the joint effect of combining both techniques.
</nextsent>
<nextsent>3.1 reducing the lexical redundancy.
</nextsent>
<nextsent>in german, determiners, pronouns, nouns and adjectives carry inflection marks (typically suffixes) 54 input pos lemma analysis in appr in appr.in der* art art.def.dat.sg.fem folge nn folge n.reg.dat.sg.fem befand vvfin befinden vfin.full.3.sg.past.ind die* art art.def.nom.sg.fem derart adv derart adv gestarkte* adja gestarkt adja.pos.nom.sg.fem justiz nn justiz n.reg.nom.sg.fem wiederholt adjd wiederholt adjd.pos gegen appr gegen appr.acc die* art art.def.acc.sg.fem regie rung nn regie rung n.reg.acc.sg.fem und kon und conj.coord.-2 insbesondere adv insbesondere adv gegen appr gegen appr.acc deren* pdat pro.dem.subst.-3.gen.sg.fem geheimdienste* nn geheimdienst n.reg.acc.pl.masc . $.
</nextsent>
<nextsent>sym.pun.sent table 1: tree tagger and rftagger outputs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4992">
<title id=" W10-1704.xml">limsirsquos statistical translation systems for wmtrsquo10 </title>
<section> german-english systems.  </section>
<citcontext>
<prevsection>
<prevsent>when aligning parallel texts atthe word level, german compound words typically tend to align with more than one english word; this, in turn, tends to increase the number of possible translation counterparts for each english type, and to make the corresponding alignment scores less reliable.
</prevsent>
<prevsent>in decoding, new compounds or unseen morphological variants of existing words artificially increase the number out of-vocabulary (oov) forms, which severely hurts the overall translation quality.
</prevsent>
</prevsection>
<citsent citstr=" H05-1085 ">
several researchers have proposed normalization (niessen and ney,2004; <papid> J04-2003 </papid>corston-oliver and gamon, 2004; goldwater and mcclosky, 2005) <papid> H05-1085 </papid>and compound splitting (koehn and knight, 2003; <papid> E03-1076 </papid>stymne, 2008; stymne, 2009) <papid> E09-3008 </papid>methods.</citsent>
<aftsection>
<nextsent>our approach here is similar, yet uses different implementations; we also studied the joint effect of combining both techniques.
</nextsent>
<nextsent>3.1 reducing the lexical redundancy.
</nextsent>
<nextsent>in german, determiners, pronouns, nouns and adjectives carry inflection marks (typically suffixes) 54 input pos lemma analysis in appr in appr.in der* art art.def.dat.sg.fem folge nn folge n.reg.dat.sg.fem befand vvfin befinden vfin.full.3.sg.past.ind die* art art.def.nom.sg.fem derart adv derart adv gestarkte* adja gestarkt adja.pos.nom.sg.fem justiz nn justiz n.reg.nom.sg.fem wiederholt adjd wiederholt adjd.pos gegen appr gegen appr.acc die* art art.def.acc.sg.fem regie rung nn regie rung n.reg.acc.sg.fem und kon und conj.coord.-2 insbesondere adv insbesondere adv gegen appr gegen appr.acc deren* pdat pro.dem.subst.-3.gen.sg.fem geheimdienste* nn geheimdienst n.reg.acc.pl.masc . $.
</nextsent>
<nextsent>sym.pun.sent table 1: tree tagger and rftagger outputs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4993">
<title id=" W10-1704.xml">limsirsquos statistical translation systems for wmtrsquo10 </title>
<section> german-english systems.  </section>
<citcontext>
<prevsection>
<prevsent>when aligning parallel texts atthe word level, german compound words typically tend to align with more than one english word; this, in turn, tends to increase the number of possible translation counterparts for each english type, and to make the corresponding alignment scores less reliable.
</prevsent>
<prevsent>in decoding, new compounds or unseen morphological variants of existing words artificially increase the number out of-vocabulary (oov) forms, which severely hurts the overall translation quality.
</prevsent>
</prevsection>
<citsent citstr=" E03-1076 ">
several researchers have proposed normalization (niessen and ney,2004; <papid> J04-2003 </papid>corston-oliver and gamon, 2004; goldwater and mcclosky, 2005) <papid> H05-1085 </papid>and compound splitting (koehn and knight, 2003; <papid> E03-1076 </papid>stymne, 2008; stymne, 2009) <papid> E09-3008 </papid>methods.</citsent>
<aftsection>
<nextsent>our approach here is similar, yet uses different implementations; we also studied the joint effect of combining both techniques.
</nextsent>
<nextsent>3.1 reducing the lexical redundancy.
</nextsent>
<nextsent>in german, determiners, pronouns, nouns and adjectives carry inflection marks (typically suffixes) 54 input pos lemma analysis in appr in appr.in der* art art.def.dat.sg.fem folge nn folge n.reg.dat.sg.fem befand vvfin befinden vfin.full.3.sg.past.ind die* art art.def.nom.sg.fem derart adv derart adv gestarkte* adja gestarkt adja.pos.nom.sg.fem justiz nn justiz n.reg.nom.sg.fem wiederholt adjd wiederholt adjd.pos gegen appr gegen appr.acc die* art art.def.acc.sg.fem regie rung nn regie rung n.reg.acc.sg.fem und kon und conj.coord.-2 insbesondere adv insbesondere adv gegen appr gegen appr.acc deren* pdat pro.dem.subst.-3.gen.sg.fem geheimdienste* nn geheimdienst n.reg.acc.pl.masc . $.
</nextsent>
<nextsent>sym.pun.sent table 1: tree tagger and rftagger outputs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4994">
<title id=" W10-1704.xml">limsirsquos statistical translation systems for wmtrsquo10 </title>
<section> german-english systems.  </section>
<citcontext>
<prevsection>
<prevsent>when aligning parallel texts atthe word level, german compound words typically tend to align with more than one english word; this, in turn, tends to increase the number of possible translation counterparts for each english type, and to make the corresponding alignment scores less reliable.
</prevsent>
<prevsent>in decoding, new compounds or unseen morphological variants of existing words artificially increase the number out of-vocabulary (oov) forms, which severely hurts the overall translation quality.
</prevsent>
</prevsection>
<citsent citstr=" E09-3008 ">
several researchers have proposed normalization (niessen and ney,2004; <papid> J04-2003 </papid>corston-oliver and gamon, 2004; goldwater and mcclosky, 2005) <papid> H05-1085 </papid>and compound splitting (koehn and knight, 2003; <papid> E03-1076 </papid>stymne, 2008; stymne, 2009) <papid> E09-3008 </papid>methods.</citsent>
<aftsection>
<nextsent>our approach here is similar, yet uses different implementations; we also studied the joint effect of combining both techniques.
</nextsent>
<nextsent>3.1 reducing the lexical redundancy.
</nextsent>
<nextsent>in german, determiners, pronouns, nouns and adjectives carry inflection marks (typically suffixes) 54 input pos lemma analysis in appr in appr.in der* art art.def.dat.sg.fem folge nn folge n.reg.dat.sg.fem befand vvfin befinden vfin.full.3.sg.past.ind die* art art.def.nom.sg.fem derart adv derart adv gestarkte* adja gestarkt adja.pos.nom.sg.fem justiz nn justiz n.reg.nom.sg.fem wiederholt adjd wiederholt adjd.pos gegen appr gegen appr.acc die* art art.def.acc.sg.fem regie rung nn regie rung n.reg.acc.sg.fem und kon und conj.coord.-2 insbesondere adv insbesondere adv gegen appr gegen appr.acc deren* pdat pro.dem.subst.-3.gen.sg.fem geheimdienste* nn geheimdienst n.reg.acc.pl.masc . $.
</nextsent>
<nextsent>sym.pun.sent table 1: tree tagger and rftagger outputs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4995">
<title id=" W10-1704.xml">limsirsquos statistical translation systems for wmtrsquo10 </title>
<section> german-english systems.  </section>
<citcontext>
<prevsection>
<prevsent>in nutshell, normalizing amounts to collapsing several german forms of given lemma into unique representative, using manually written normalization patterns.
</prevsent>
<prevsent>a pattern typically specifies which forms of given morphological paradigm should be considered equivalent when translating into english.
</prevsent>
</prevsection>
<citsent citstr=" C08-1098 ">
these normalization patterns use the lemma information computed by the tree tagger and the fine-grained pos information computed by the rftagger (schmid andlaws, 2008), <papid> C08-1098 </papid>which uses tagset containing approximately 800 tags.</citsent>
<aftsection>
<nextsent>table 1 displays the analysis of an example sentence.
</nextsent>
<nextsent>2 in most cases, normalization patterns replace aword form by its lemma; in order to partially pre 1for the plural forms, gender distinctions are neutralized and the same 4 forms are used for all genders .2the english reference: subsequently , the energized judiciary continued ruling against government decisions , embarrassing the government ? especially its intelligence agencies . serve some inflection marks, we introduced two generic suffixes, +s and +en which respectively denote plural and genitive wherever needed.
</nextsent>
<nextsent>typical normalization rules take the following form:?
</nextsent>
<nextsent>for articles, adjectives, and pronouns (indef inite , possessive, demonstrative, relative and reflexive), if token has; ? genitive case: replace with lemma+en (ex.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4997">
<title id=" W10-1704.xml">limsirsquos statistical translation systems for wmtrsquo10 </title>
<section> french-english systems.  </section>
<citcontext>
<prevsection>
<prevsent>4.1 baseline -coder systems.
</prevsent>
<prevsent>for this language pair, we used our in-housen -code system, which implements the n-grambased approach to smt.
</prevsent>
</prevsection>
<citsent citstr=" J04-2004 ">
in nutshell, the translation model is implemented as stochastic finite state transducer trained using n-gram model of (source,target) pairs (casacuberta and vidal, 2004).<papid> J04-2004 </papid></citsent>
<aftsection>
<nextsent>training this model requires to reorder source sentences so as to match the target wordorder.
</nextsent>
<nextsent>this is performed by stochastic finite state reordering model, which uses part-of-speechinformation3 to generalize reordering patterns beyond lexical regularities.in addition to the translation model, our system implements eight feature functions which are optimally combined using discriminative training framework (och, 2003): <papid> P03-1021 </papid>target-languagemodel; two lexicon models, which give complementary translation scores for each tuple; two lexicalized reordering models aiming at predicting the orientation of the next translation unit; weak?</nextsent>
<nextsent>distance-based distortion model; and finally word-bonus model and tuple-bonusmodel which compensate for the system preference for short translations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4998">
<title id=" W10-1704.xml">limsirsquos statistical translation systems for wmtrsquo10 </title>
<section> french-english systems.  </section>
<citcontext>
<prevsection>
<prevsent>in nutshell, the translation model is implemented as stochastic finite state transducer trained using n-gram model of (source,target) pairs (casacuberta and vidal, 2004).<papid> J04-2004 </papid></prevsent>
<prevsent>training this model requires to reorder source sentences so as to match the target wordorder.</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
this is performed by stochastic finite state reordering model, which uses part-of-speechinformation3 to generalize reordering patterns beyond lexical regularities.in addition to the translation model, our system implements eight feature functions which are optimally combined using discriminative training framework (och, 2003): <papid> P03-1021 </papid>target-languagemodel; two lexicon models, which give complementary translation scores for each tuple; two lexicalized reordering models aiming at predicting the orientation of the next translation unit; weak?</citsent>
<aftsection>
<nextsent>distance-based distortion model; and finally word-bonus model and tuple-bonusmodel which compensate for the system preference for short translations.
</nextsent>
<nextsent>one novelty this yearare the introduction of lexicalized reordering models (tillmann, 2004).<papid> N04-4026 </papid></nextsent>
<nextsent>such models require to estimate reordering probabilities for each phrase pairs, typically distinguishing three case, depending whether the current phrase is translated monotone, swapped or dis contiguous with respect to the 3part-of-speech information for english and french is computed using the abovementioned treetagger.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG4999">
<title id=" W10-1704.xml">limsirsquos statistical translation systems for wmtrsquo10 </title>
<section> french-english systems.  </section>
<citcontext>
<prevsection>
<prevsent>this is performed by stochastic finite state reordering model, which uses part-of-speechinformation3 to generalize reordering patterns beyond lexical regularities.in addition to the translation model, our system implements eight feature functions which are optimally combined using discriminative training framework (och, 2003): <papid> P03-1021 </papid>target-languagemodel; two lexicon models, which give complementary translation scores for each tuple; two lexicalized reordering models aiming at predicting the orientation of the next translation unit; weak?</prevsent>
<prevsent>distance-based distortion model; and finally word-bonus model and tuple-bonusmodel which compensate for the system preference for short translations.</prevsent>
</prevsection>
<citsent citstr=" N04-4026 ">
one novelty this yearare the introduction of lexicalized reordering models (tillmann, 2004).<papid> N04-4026 </papid></citsent>
<aftsection>
<nextsent>such models require to estimate reordering probabilities for each phrase pairs, typically distinguishing three case, depending whether the current phrase is translated monotone, swapped or dis contiguous with respect to the 3part-of-speech information for english and french is computed using the abovementioned treetagger.
</nextsent>
<nextsent>previous (respectively next phrase pair).
</nextsent>
<nextsent>in our implementation, we modified the three orientation types originally introduced and con sider: consecutive type, where the original monotone and swap orientations are lumped together, forward type, specifying discontiguousforward orientation, and backward type, specifying dis contiguous backward orientation.
</nextsent>
<nextsent>empirical results showed that in our case, the new orientations slightly outperform the original ones.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG5000">
<title id=" W10-1704.xml">limsirsquos statistical translation systems for wmtrsquo10 </title>
<section> language models.  </section>
<citcontext>
<prevsection>
<prevsent>to take the diversity of the available parallel corpora into account, we independently trained several translation models on subpart of the training data.
</prevsent>
<prevsent>these translation models were then linearly interpolated, where the interpolation weights are chosen so as to minimize the perplexity on the development set.
</prevsent>
</prevsection>
<citsent citstr=" W09-0417 ">
the english and french language models (lms) are the same as for the last years french-english task (allauzen et al, 2009) <papid> W09-0417 </papid>and are heavily tuned to the newspaper/newswire genre, using the first part of the wmt09 official development data (dev2009a).</citsent>
<aftsection>
<nextsent>we used all the authorized news corpora, including the french and english gigaword corpora, for translating both into french(1.4 billion tokens) and english (3.7 billion to kens).
</nextsent>
<nextsent>to estimate such lms, vocabulary was defined for both languages by including all tokens in the wmt parallel data.
</nextsent>
<nextsent>this initial vocabulary of 130k words was then extended with the most frequent words observed in the training data, yielding vocabulary of one million words in both languages.
</nextsent>
<nextsent>the training data was divided into several sets based on dates and genres (resp.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZG5003">
<title id=" W10-1839.xml">a hybrid model for annotating named entity training corpora </title>
<section> background </section>
<citcontext>
<prevsection>
<prevsent>once identified and labeled, we then add corresponding entries to our semantic index for improved ranking and retrieval.
</prevsent>
<prevsent>we scoped each type in the repertoire mentioned above in an attempt to most effectively support our parser and the end-to-end retrieval task.
</prevsent>
</prevsection>
<citsent citstr=" M98-1001 ">
while this taxonomy resembles the one used in the 7th message understanding conference (muc-7) ner shared task (chinchor, 1998), <papid> M98-1001 </papid>our specification is in fact slightly nuanced.</citsent>
<aftsection>
<nextsent>for example, the organization and location classes used in our production system are much more limited, disallowing governmental committees, subcommittees, and other organizations that fall under the muc-7 definition of organization.
</nextsent>
<nextsent>indeed, the determination of types to tag and the definitions of these types is very much dependent upon the application for which given ner system is being designed.
</nextsent>
<nextsent>accurate 243 training and evaluation of ner systems therefore requires application-specific corpora.
</nextsent>
<nextsent>previously, we collected training documents for our system with more automated two-pass system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
</paper>